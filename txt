Connected
{ comma: ',' }
INSERT or IGNORE INTO posts (link, title, pubDate, feed_id, description) VALUES ('https://euandre.org/2020/08/31/the-database-i-wish-i-had.html', 'The database I wish I had', '1598832000000',  1, '<p>I watched the talk
â€œ<a href="https://vimeo.com/230142234">Platform as a Reflection of Values: JoyentÙ« Node.js and beyond</a>â€
by Bryan CantrillÙ« and I think he was able to put into words something I already
felt for some time: if thereâ€™s no piece of software out there that reflects your
valuesÙ« itâ€™s time for you to build that software<sup id="fnref:talk-time" role="doc-noteref"><a href="#fn:talk-time" class="footnote">1</a></sup>.</p>

<p>I kind of agree with what he saidÙ« because this is already happening to me. I
long for a database with a certain set of valuesÙ« and for a few years I was just
waiting for someone to finally write it. After watching his talkÙ« Bryan is
saying to me: â€œtime to stop waitingÙ« and start writing it yourselfâ€.</p>

<p>So let me try to give an overview of such databaseÙ« and go over its values.</p>

<h2 id="overview">Overview</h2>

<p>I want a database that allows me to create decentralized client-side
applications that can sync data.</p>

<p>The best one-line description I can give right now is:</p>

<blockquote>
  <p>Itâ€™s sort of like PouchDBÙ« GitÙ« DatomicÙ« SQLite and Mentat.</p>
</blockquote>

<p>A more descriptive version could be:</p>

<blockquote>
  <p>An embeddedÙ« immutableÙ« syncable relational database.</p>
</blockquote>

<p>Letâ€™s go over what I mean by each of those aspects one by one.</p>

<h3 id="embedded">Embedded</h3>

<p>I think the server-side database landscape is diverse and mature enough for
my needs (even though I end up choosing SQLite most of the time)Ù« and what Iâ€™m
after is a database to be embedded on client-side applications itselfÙ« be it
desktopÙ« browserÙ« mobileÙ« etc.</p>

<p>The purpose of such database is not to keep some local cache of data in case of
lost connectivity: we have good solutions for that already. It should serve as
the source of truthÙ« and allow the application to work on top of it.</p>

<p><a href="https://sqlite.org/index.html"><strong>SQLite</strong></a> is a great example of that: it is a very powerful
relational database that runs <a href="https://sqlite.org/whentouse.html">almost anywhere</a>. What I miss
from it that SQLite doesnâ€™t provide is the ability to run it on the browser:
even though you could compile it to WebAssemblyÙ« <del>it assumes a POSIX filesystem
that would have to be emulated</del><sup id="fnref:posix-sqlite" role="doc-noteref"><a href="#fn:posix-sqlite" class="footnote">2</a></sup>.</p>

<p><a href="https://pouchdb.com/"><strong>PouchDB</strong></a> is another great example: itâ€™s a full reimplementation of
<a href="https://couchdb.apache.org/">CouchDB</a> that targets JavaScript environmentsÙ« mainly the browser and
Node.js. However I want a tool that can be deployed anywhereÙ« and not limit its
applications to places that already have a JavaScript runtime environmentÙ« or
force the developer to bundle a JavaScript runtime environment with their
application. This is true for GTK+ applicationsÙ« command line programsÙ« Android
appsÙ« etc.</p>

<p><a href="https://github.com/mozilla/mentat"><strong>Mentat</strong></a> was an interesting projectÙ« but its reliance on SQLite
makes it inherit most of the downsides (and benefits too) of SQLite itself.</p>

<p>Having such a requirement imposes a different approach to storage: we have to
decouple the knowledge about the intricacies of storage from the usage of
storage itselfÙ« so that a module (say query processing) can access storage
through an API without needing to know about its implementation. This allows
the database to target a POSIX filesystems storage API and an IndexedDB storage
APIÙ« and make the rest of the code agnostic about storage. PouchDB has such
mechanism (called <a href="https://pouchdb.com/adapters.html">adapters</a>) and Datomic has them too (called
<a href="https://docs.datomic.com/on-prem/storage.html">storage services</a>).</p>

<p>This would allow the database to adapt to where it is embedded: when targeting
the browser the IndexedDB storage API would provide the persistence layer
that the database requiresÙ« and similarly the POSIX filesystem storage API would
provide the persistence layer when targeting POSIX systems (like desktopsÙ«
mobileÙ« etc.).</p>

<p>But thereâ€™s also an extra restriction that comes from by being embedded: it
needs to provide and embeddable artifactÙ« most likely a binary library object
that exposes a C compatible FFIÙ« similar to
<a href="https://www.sqlite.org/amalgamation.html">how SQLite does</a>. Bundling a full runtime environment is
possibleÙ« but doesnâ€™t make it a compelling solution for embedding. This rules
out most languagesÙ« and leaves us with CÙ« RustÙ« ZigÙ« and similar options that
can target POSIX systems and WebAssembly.</p>

<h3 id="immutable">Immutable</h3>

<p>Being immutable means that only new information is addedÙ« no in-place update
ever happensÙ« and nothing is ever deleted.</p>

<p>Having an immutable database presents us with similar trade-offs found in
persistent data structuresÙ« like lack of coordination when doing readsÙ« caches
being always coherentÙ« and more usage of space.</p>

<p><a href="https://www.datomic.com/"><strong>Datomic</strong></a> is the go to database example of this: it will only add
information (datoms) and allows you to query them in a multitude of ways. Stuart
Halloway calls it â€œaccumulate-onlyâ€ over â€œappend-onlyâ€<sup id="fnref:accumulate-only" role="doc-noteref"><a href="#fn:accumulate-only" class="footnote">3</a></sup>:</p>

<blockquote>
  <p>Itâ€™s accumulate-onlyÙ« it is not append-only. So append-onlyÙ« most people when
they say that theyâ€™re implying something physical about what happens.</p>
</blockquote>

<p>Also a database can be append-only and overwrite existing information with new
informationÙ« by doing clean-ups of â€œstaleâ€ data. I prefer to adopt the
â€œaccumulate-onlyâ€ naming and approach.</p>

<p><a href="https://git-scm.com/"><strong>Git</strong></a> is another example of this: new commits are always added on top
of the previous dataÙ« and it grows by adding commits instead of replacing
existing ones.</p>

<p>Git repositories can only grow in sizeÙ« and that is not only an acceptable
conditionÙ« but also one of the reasons to use it.</p>

<p>All this means that no in-place updates happens on dataÙ« and the database will
be much more concerned about how compact and efficiently it stores data than how
fast it does writes to disk. Being embeddedÙ« the storage limitation is either a)
how much storage the device has or b) how much storage was designed for the
application to consume. So even though the database could theoretically operate
with hundreds of TBsÙ« a browser page or mobile application wouldnâ€™t have access
to this amount of storage. SQLite even <a href="https://sqlite.org/limits.html">says</a> that it does
support approximately 280 TBs of dataÙ« but those limits are untested.</p>

<p>The upside of keeping everything is that you can have historical views of your
dataÙ« which is very powerful. This also means that applications should turn this
off when not relevant<sup id="fnref:no-history" role="doc-noteref"><a href="#fn:no-history" class="footnote">4</a></sup>.</p>

<h3 id="syncable">Syncable</h3>

<p>This is a frequent topic when talking about offline-first solutions. When
building applications that:</p>

<ul>
  <li>can fully work offlineÙ«</li>
  <li>stores dataÙ«</li>
  <li>propagates that data to other application instancesÙ«</li>
</ul>

<p>then youâ€™ll need a conflict resolution strategy to handle all the situations
where different application instances disagree. Those application instances
could be a desktop and a browser version of the same applicationÙ« or the same
mobile app in different devices.</p>

<p>A three-way merge seems to be the best approachÙ« on top of which you could add
application specific conflict resolution functionsÙ« like:</p>

<ul>
  <li>pick the change with higher timestamp;</li>
  <li>if one change is a deleteÙ« pick it;</li>
  <li>present the diff on the screen and allow the user to merge them.</li>
</ul>

<p>Some databases try to make this â€œeasyâ€Ù« by choosing a strategy for youÙ« but Iâ€™ve
found that different applications require different conflict resolution
strategies. InsteadÙ« the database should leave this up to the user to decideÙ«
and provide tools for them to do it.</p>

<p><a href="https://en.wikipedia.org/wiki/Merge_(version_control)"><strong>Three-way merges in version control</strong></a> are the best exampleÙ«
performing automatic merges when possible and asking the user to resolve
conflicts when they appear.</p>

<p>The unit of conflict for a version control system is a line of text. The
database equivalent would probably be a single attributeÙ« not a full entity or a
full row.</p>

<p>Making all the conflict resolution logic be local should allow the database to
have encrypted remotes similar to how <a href="https://spwhitton.name/tech/code/git-remote-gcrypt/">git-remote-gcrypt</a>
adds this functionality to Git. This would enable users to sync the application
data across devices using an untrusted intermediary.</p>

<h3 id="relational">Relational</h3>

<p>I want the power of relational queries on the client applications.</p>

<p>Most of the arguments against traditional table-oriented relational databases
are related to write performanceÙ« but those donâ€™t apply here. The bottlenecks
for client applications usually arenâ€™t write throughput. Nobody is interested in
differentiating between 1 MB/s or 10 MB/s when youâ€™re limited to 500 MB total.</p>

<p>The relational model of the database could either be based on SQL and tables
like in SQLiteÙ« or maybe <a href="https://docs.datomic.com/on-prem/query.html">datalog</a> and <a href="https://docs.datomic.com/cloud/whatis/data-model.html#datoms">datoms</a> like in
Datomic.</p>

<h2 id="from-aspects-to-values">From aspects to values</h2>

<p>Now letâ€™s try to translate the aspects above into valuesÙ« as suggested by Bryan
Cantrill.</p>

<h3 id="portability">Portability</h3>

<p>Being able to target so many different platforms is a bold goalÙ« and the
embedded nature of the database demands portability to be a core value.</p>

<h3 id="integrity">Integrity</h3>

<p>When the local database becomes the source of truth of the applicationÙ« it must
provide consistency guarantees that enables applications to rely on it.</p>

<h3 id="expressiveness">Expressiveness</h3>

<p>The database should empower applications to slice and dice the data in any way
it wants to.</p>

<h2 id="next-steps">Next steps</h2>

<p>Since I canâ€™t find any database that fits these requirementsÙ« Iâ€™ve finally come
to terms with doing it myself.</p>

<p>Itâ€™s probably going to take me a few years to do itÙ« and making it portable
between POSIX and IndexedDB will probably be the biggest challenge. I got myself
a few books on databases to start.</p>

<p>I wonder if Iâ€™ll ever be able to get this done.</p>

<h2 id="external-links">External links</h2>

<p>See discussions on <a href="https://www.reddit.com/r/programming/comments/ijwz5b/the_database_i_wish_i_had/">Reddit</a>Ù« <a href="https://lobste.rs/s/m9vkg4/database_i_wish_i_had">lobsters</a>Ù« <a href="https://news.ycombinator.com/item?id=24337244">HN</a> and
<a href="https://lists.sr.ht/~euandreh/public-inbox/%3C010101744a592b75-1dce9281-f0b8-4226-9d50-fd2c7901fa72-000000%40us-west-2.amazonses.com%3E">a lengthy email exchange</a>.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:talk-time" role="doc-endnote">
      <p>At the very endÙ« at time 29:49. When talking about the draft of
this article with a friendÙ« he noted that Bryan Oâ€™Sullivan (a different
Bryan) says a similar thing on his talk
â€œ<a href="https://www.youtube.com/watch?v=ZR3Jirqk6W8">Running a startup on Haskell</a>â€Ù«
at time 4:15.Â <a href="#fnref:talk-time" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:posix-sqlite" role="doc-endnote">
      <p>It was <a href="https://news.ycombinator.com/item?id=24338881">pointed out to me</a>
that SQLite doesnâ€™t assume the existence of a POSIX filesystemÙ« as I wrongly
stated. Thanks for the correction.</p>

      <p>This makes me consider it as a storage backend all by itself. I
initially considered having an SQLite storage backend as one implementation
of the POSIX filesystem storage API that I mentioned. My goal was to rely on
it so I could validate the correctness of the actual implementationÙ« given
SQLiteâ€™s robustness.</p>

      <p>However it may even better to just use SQLiteÙ« and get an ACID backend
without recreating a big part of SQLite from scratch. In factÙ« both Datomic
and PouchDB didnâ€™t create an storage backend for themselvesÙ« they just
plugged on what already existed and already worked. Iâ€™m beginning to think
that it would be wiser to just do the sameÙ« and drop entirely the from
scratch implementation that I mentioned.</p>

      <p>Thatâ€™s not to say that adding an IndexedDB compatibility layer to SQLite
would be enough to make it fit the other requirements I mention on this
page. SQLite still is an implementation of a update-in-placeÙ« SQLÙ«
table-oriented database. It is probably true that cherry-picking the
relevant parts of SQLite (like storage accessÙ« consistencyÙ« crash recoveryÙ«
parser generatorÙ« etc.) and leaving out the unwanted parts (SQLÙ« tablesÙ«
threadingÙ« etc.) would be better than including the full SQLite stackÙ« but
thatâ€™s simply an optimization. Both could even coexistÙ« if desired.</p>

      <p>SQLite would have to be treated similarly to how Datomic treats SQL
databases: instead of having a table for each entitiesÙ« spread attributes
over the tablesÙ« etc.Ù« it treats SQL databases as a key-value storage so it
doesnâ€™t have to re-implement interacting with the disk that other databases
do well.</p>

      <p>The tables would contain blocks of binary dataÙ« so there isnâ€™t a difference
on how the SQLite storage backend behaves and how the IndexedDB storage
backend behavesÙ« much like how Datomic works the same regardless of the
storage backendÙ« same for PouchDB.</p>

      <p>I welcome corrections on what I said aboveÙ« too.Â <a href="#fnref:posix-sqlite" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:accumulate-only" role="doc-endnote">
      <p>Video â€œ<a href="https://vimeo.com/116315075">Day of Datomic Part 2</a>â€
on Datomicâ€™s information modelÙ« at time 12:28.Â <a href="#fnref:accumulate-only" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:no-history" role="doc-endnote">
      <p>Similar to
<a href="https://docs.datomic.com/cloud/best.html#nohistory-for-high-churn">Datomicâ€™s <code class="language-plaintext highlighter-rouge">:db/noHistory</code></a>.Â <a href="#fnref:no-history" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>'),('https://euandre.org/2020/08/10/guix-inside-sourcehut-builds-sr-ht-ci.html', 'Guix inside sourcehut builds.sr.ht CI', '1597017600000',  1, '<p>After the release of the <a href="https://man.sr.ht/builds.sr.ht/compatibility.md#nixos">NixOS images in builds.sr.ht</a> and much
usage of itÙ« I also started looking at <a href="https://guix.gnu.org/">Guix</a> and
wondered if I could get it on the awesome builds.sr.ht service.</p>

<p>The Guix manual section on the <a href="https://guix.gnu.org/manual/en/guix.html#Binary-Installation">binary installation</a> is very thoroughÙ« and
even a <a href="https://git.savannah.gnu.org/cgit/guix.git/plain/etc/guix-install.sh">shell installer script</a> is providedÙ« but it is built towards someone
installing Guix on their personal computerÙ« and relies heavily on interactive
input.</p>

<p>I developed the following set of scripts that I have been using for some time to
run Guix tasks inside builds.sr.ht jobs. FirstÙ« <code class="language-plaintext highlighter-rouge">install-guix.sh</code>:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre></td><td class="rouge-code"><pre><span class="c">#!/usr/bin/env bash</span>
<span class="nb">set</span> <span class="nt">-x</span>
<span class="nb">set</span> <span class="nt">-Eeuo</span> pipefail

<span class="nv">VERSION</span><span class="o">=</span><span class="s1">"1.0.1"</span>
<span class="nv">SYSTEM</span><span class="o">=</span><span class="s1">"x86_64-linux"</span>
<span class="nv">BINARY</span><span class="o">=</span><span class="s2">"guix-binary-</span><span class="k">${</span><span class="nv">VERSION</span><span class="k">}</span><span class="s2">.</span><span class="k">${</span><span class="nv">SYSTEM</span><span class="k">}</span><span class="s2">.tar.xz"</span>

<span class="nb">cd</span> /tmp
wget <span class="s2">"https://ftp.gnu.org/gnu/guix/</span><span class="k">${</span><span class="nv">BINARY</span><span class="k">}</span><span class="s2">"</span>
<span class="nb">tar</span> <span class="nt">-xf</span> <span class="s2">"</span><span class="k">${</span><span class="nv">BINARY</span><span class="k">}</span><span class="s2">"</span>

<span class="nb">sudo mv </span>var/guix /var/
<span class="nb">sudo mv </span>gnu /
<span class="nb">sudo mkdir</span> <span class="nt">-p</span> ~root/.config/guix
<span class="nb">sudo ln</span> <span class="nt">-fs</span> /var/guix/profiles/per-user/root/current-guix ~root/.config/guix/current

<span class="nv">GUIX_PROFILE</span><span class="o">=</span><span class="s2">"</span><span class="si">$(</span><span class="nb">echo</span> ~root<span class="si">)</span><span class="s2">/.config/guix/current"</span>
<span class="nb">source</span> <span class="s2">"</span><span class="k">${</span><span class="nv">GUIX_PROFILE</span><span class="k">}</span><span class="s2">/etc/profile"</span>

groupadd <span class="nt">--system</span> guixbuild
<span class="k">for </span>i <span class="k">in</span> <span class="si">$(</span><span class="nb">seq</span> <span class="nt">-w</span> 1 10<span class="si">)</span><span class="p">;</span>
<span class="k">do
  </span>useradd <span class="nt">-g</span> guixbuild                       <span class="se">\</span>
          <span class="nt">-G</span> guixbuild                       <span class="se">\</span>
          <span class="nt">-d</span> /var/empty                      <span class="se">\</span>
          <span class="nt">-s</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">command</span> <span class="nt">-v</span> nologin<span class="si">)</span><span class="s2">"</span>         <span class="se">\</span>
          <span class="nt">-c</span> <span class="s2">"Guix build user </span><span class="k">${</span><span class="nv">i</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--system</span> <span class="se">\</span>
          <span class="s2">"guixbuilder</span><span class="k">${</span><span class="nv">i</span><span class="k">}</span><span class="s2">"</span><span class="p">;</span>
<span class="k">done

</span><span class="nb">mkdir</span> <span class="nt">-p</span> /usr/local/bin
<span class="nb">cd</span> /usr/local/bin
<span class="nb">ln</span> <span class="nt">-s</span> /var/guix/profiles/per-user/root/current-guix/bin/guix <span class="nb">.</span>
<span class="nb">ln</span> <span class="nt">-s</span> /var/guix/profiles/per-user/root/current-guix/bin/guix-daemon <span class="nb">.</span>

guix archive <span class="nt">--authorize</span> &lt; ~root/.config/guix/current/share/guix/ci.guix.gnu.org.pub
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Almost all of it is taken directly from the <a href="https://guix.gnu.org/manual/en/guix.html#Binary-Installation">binary installation</a> section
from the manualÙ« with the interactive bits stripped out: after downloading and
extracting the Guix tarballÙ« we create some symlinksÙ« add guixbuild users and
authorize the <code class="language-plaintext highlighter-rouge">ci.guix.gnu.org.pub</code> signing key.</p>

<p>After installing GuixÙ« we perform a <code class="language-plaintext highlighter-rouge">guix pull</code> to update Guix inside <code class="language-plaintext highlighter-rouge">start-guix.sh</code>:</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre><span class="c">#!/usr/bin/env bash</span>
<span class="nb">set</span> <span class="nt">-x</span>
<span class="nb">set</span> <span class="nt">-Eeuo</span> pipefail

<span class="nb">sudo </span>guix-daemon <span class="nt">--build-users-group</span><span class="o">=</span>guixbuild &amp;
guix pull
guix package <span class="nt">-u</span>
guix <span class="nt">--version</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Then we can put it all together in a sample <code class="language-plaintext highlighter-rouge">.build.yml</code> configuration file Iâ€™m
using myself:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="rouge-code"><pre><span class="na">image</span><span class="pi">:</span> <span class="s">debian/stable</span>
<span class="na">packages</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">wget</span>
<span class="na">sources</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">https://git.sr.ht/~euandreh/songbooks</span>
<span class="na">tasks</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">install-guix</span><span class="pi">:</span> <span class="pi">|</span>
      <span class="s">cd ./songbooks/</span>
      <span class="s">./scripts/install-guix.sh</span>
      <span class="s">./scripts/start-guix.sh</span>
      <span class="s">echo "sudo guix-daemon --build-users-group=guixbuild &amp;" &gt;&gt; ~/.buildenv</span>
      <span class="s">echo "export PATH="${HOME}/.config/guix/current/bin${PATH:+:}$PATH"" &gt;&gt; ~/.buildenv</span>
  <span class="pi">-</span> <span class="na">tests</span><span class="pi">:</span> <span class="pi">|</span>
      <span class="s">cd ./songbooks/</span>
      <span class="s">guix environment -m build-aux/guix.scm -- make check</span>
  <span class="pi">-</span> <span class="na">docs</span><span class="pi">:</span> <span class="pi">|</span>
      <span class="s">cd ./songbooks/</span>
      <span class="s">guix environment -m build-aux/guix.scm -- make publish-dist</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We have to add the <code class="language-plaintext highlighter-rouge">guix-daemon</code> to <code class="language-plaintext highlighter-rouge">~/.buildenv</code> so it can be started on every
following task run. AlsoÙ« since we used <code class="language-plaintext highlighter-rouge">wget</code> inside <code class="language-plaintext highlighter-rouge">install-guix.sh</code>Ù« we had
to add it to the images package list.</p>

<p>After the <code class="language-plaintext highlighter-rouge">install-guix</code> taskÙ« you can use Guix to build and test your projectÙ«
or run any <code class="language-plaintext highlighter-rouge">guix environment --ad-hoc my-package -- my script</code> :)</p>

<h2 id="improvements">Improvements</h2>

<p>When I originally created this code I had a reason why to have both a <code class="language-plaintext highlighter-rouge">sudo</code>
call for <code class="language-plaintext highlighter-rouge">sudo ./scripts/install-guix.sh</code> and <code class="language-plaintext highlighter-rouge">sudo</code> usages inside
<code class="language-plaintext highlighter-rouge">install-guix.sh</code> itself. I couldnâ€™t figure out why (it feels like my past self
was a bit smarter ğŸ˜¬)Ù« but it feels ugly now. If it is truly required I could
add an explanation for itÙ« or remove this entirely in favor of a more elegant solution.</p>

<p>I could also contribute the Guix image upstream to builds.sr.htÙ« but there
wasnâ€™t any build or smoke tests in the original <a href="https://git.sr.ht/~sircmpwn/builds.sr.ht">repository</a>Ù« so I wasnâ€™t
inclined to make something that just â€œworks on my machineâ€ or add a maintainence
burden to the author. I didnâ€™t look at it again recentlyÙ« though.</p>'),('https://euandre.org/2019/06/02/stateless-os.html', 'Using NixOS as an stateless workstation', '1559433600000',  1, '<p>Last week<sup id="fnref:last-week" role="doc-noteref"><a href="#fn:last-week" class="footnote">1</a></sup> I changed back to an old<sup id="fnref:old-computer" role="doc-noteref"><a href="#fn:old-computer" class="footnote">2</a></sup> Samsung laptopÙ« and installed
<a href="https://nixos.org/">NixOS</a> on it.</p>

<p>After using NixOS on another laptop for around two yearsÙ« I wanted
verify how reproducible was my desktop environmentÙ« and how far does
NixOS actually can go on recreating my whole OS from my configuration
files and personal data. I gravitated towards NixOS after trying (and
failing) to create an <code class="language-plaintext highlighter-rouge">install.sh</code> script that would imperatively
install and configure my whole OS using apt-get. When I found a
GNU/Linux distribution that was built on top of the idea of
declaratively specifying the whole OS I was automatically convinced<sup id="fnref:convinced-by-declarative-aspect" role="doc-noteref"><a href="#fn:convinced-by-declarative-aspect" class="footnote">3</a></sup>.</p>

<p>I was impressed. Even though Iâ€™ve been experiencing the benefits of Nix
isolation dailyÙ« I always felt skeptical that something would be
missingÙ« because the devil is always on the details. But the result was
much better than expected!</p>

<p>There were only 2 missing configurations:</p>

<ol>
  <li>tap-to-click on the touchpad wasnâ€™t enabled by default;</li>
  <li>the default theme from the gnome-terminal is â€œBlack on whiteâ€
instead of â€œWhite on blackâ€.</li>
</ol>

<p>Thatâ€™s all.</p>

<p>I havenâ€™t checked if I can configure those in NixOS GNOME moduleÙ« but I
guess both are scriptable and could be set in a fictional <code class="language-plaintext highlighter-rouge">setup.sh</code>
run.</p>

<p>This makes me really happyÙ« actually. More happy than I anticipated.</p>

<p>Having such a powerful declarative OS makes me feel like my data is the
really important stuff (as it should be)Ù« and I can interact with it on
any workstation. All I need is an internet connection and a few hours to
download everything. It feels like my physical workstation and the
installed OS are serving me and my dataÙ« instead of me feeling as
hostage to the specific OS configuration at the moment. Having a few
backup copies of everything important extends such peacefulness.</p>

<p>After this positive experience with recreating my OS from simple Nix
expressionsÙ« I started to wonder how far I could go with thisÙ« and
started considering other areas of improvements:</p>

<h3 id="first-run-on-a-fresh-nixos-installation">First run on a fresh NixOS installation</h3>

<p>Right now the initial setup relies on non-declarative manual tasksÙ« like
decrypting some credentialsÙ« or manually downloading <strong>this</strong> git
repository with specific configurations before <strong>that</strong> one.</p>

<p>I wonder what some areas of improvements are on this topicÙ« and if
investing on it is worth it (both time-wise and happiness-wise).</p>

<h3 id="emacs">Emacs</h3>

<p>Right now Iâ€™m using the <a href="http://spacemacs.org/">Spacemacs</a>Ù« which is a
community package curation and configuration on top of
<a href="https://www.gnu.org/software/emacs/">Emacs</a>.</p>

<p>Spacemacs does support the notion of
<a href="http://spacemacs.org/doc/LAYERS.html">layers</a>Ù« which you can
declaratively specify and let Spacemacs do the rest.</p>

<p>However this solution isnâ€™t nearly as robust as Nix: being purely
functionalÙ« Nix does describe everything required to build a derivationÙ«
and knows how to do so. Spacemacs it closer to more traditional package
managers: even though the layers list is declarativeÙ« the installation
is still very much imperative. Iâ€™ve had trouble with Spacemacs not
behaving the same on different computersÙ« both with identical
configurationsÙ« only brought to convergence back again after a
<code class="language-plaintext highlighter-rouge">git clean -fdx</code> inside <code class="language-plaintext highlighter-rouge">~/.emacs.d/</code>.</p>

<p>The ideal solution would be managing Emacs packages with Nix itself.
After a quick search I did found that <a href="https://nixos.org/nixos/manual/index.html#module-services-emacs-adding-packages">there is support for Emacs
packages in
Nix</a>.
So far I was only aware of <a href="https://www.gnu.org/software/guix/manual/en/html_node/Application-Setup.html#Emacs-Packages">Guix support for Emacs packages</a>.</p>

<p>This isnâ€™t a trivial change because Spacemacs does include extra
curation and configuration on top of Emacs packages. Iâ€™m not sure the
best way to improve this right now.</p>

<h3 id="myrepos">myrepos</h3>

<p>Iâ€™m using <a href="https://myrepos.branchable.com/">myrepos</a> to manage all my
git repositoriesÙ« and the general rule I apply is to add any repository
specific configuration in myreposâ€™ <code class="language-plaintext highlighter-rouge">checkout</code> phase:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="c"># sample ~/.mrconfig file snippet</span>
<span class="o">[</span>dev/guix/guix]
checkout <span class="o">=</span>
  git clone https://git.savannah.gnu.org/git/guix.git guix
  <span class="nb">cd </span>guix/
  git config sendemail.to guix-patches@gnu.org
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This way when I clone this repo again the email sending is already
pre-configured.</p>

<p>This works well enoughÙ« but the solution is too imperativeÙ« and my
<code class="language-plaintext highlighter-rouge">checkout</code> phases tend to become brittle over time if not enough care is
taken.</p>

<h3 id="gnu-stow">GNU Stow</h3>

<p>For my home profile and personal configuration I already have a few
dozens of symlinks that I manage manually. This has worked so farÙ« but
the solution is sometimes fragile and <a href="https://git.sr.ht/~euandreh/dotfiles/tree/316939aa215181b1d22b69e94241eef757add98d/bash/symlinks.sh#L14-75">not declarative at
all</a>.
I wonder if something like <a href="https://www.gnu.org/software/stow/">GNU
Stow</a> can help me simplify this.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Iâ€™m really satisfied with NixOSÙ« and I intend to keep using it. If what
Iâ€™ve said interests youÙ« maybe try tinkering with the <a href="https://nixos.org/nix/">Nix package
manager</a> (not the whole NixOS) on your current
distribution (it can live alongside any other package manager).</p>

<p>If you have experience with declarative Emacs package managementsÙ« GNU
Stow or any similar toolÙ« etc.Ù« <a href="mailto:eu@euandre.org">Iâ€™d like some
tips</a>. If you donâ€™t have any experience at allÙ«
<a href="mailto:eu@euandre.org">Iâ€™d still love to hear from you</a>.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:last-week" role="doc-endnote">
      <p>â€œLast weekâ€ as of the start of this writingÙ« so around the end of
May 2019.Â <a href="#fnref:last-week" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:old-computer" role="doc-endnote">
      <p>I was using a 32GB RAMÙ« i7 and 250GB SSD Samsung laptop. The
switch was back to a 8GB RAMÙ« i5 and 500GB HDD Dell laptop. The biggest
difference I noticed was on faster memoryÙ« both RAM availability and the
disk speedÙ« but I had 250GB less local storage space.Â <a href="#fnref:old-computer" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:convinced-by-declarative-aspect" role="doc-endnote">
      <p>The declarative configuration aspect is
something that I now completely take for grantedÙ« and wouldnâ€™t consider
using something which isnâ€™t declarative. A good metric to show this is me
realising that I canâ€™t pinpoint the moment when I decided to switch to
NixOS. Itâ€™s like I had a distant past when this wasnâ€™t true.Â <a href="#fnref:convinced-by-declarative-aspect" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>'),('https://euandre.org/2018/12/21/using-youtube-dl-to-manage-youtube-subscriptions.html', 'Using â€œyoutube-dlâ€ to manage YouTube subscriptions', '1545350400000',  1, '<p>Iâ€™ve recently read the
<a href="https://www.reddit.com/r/DataHoarder/comments/9sg8q5/i_built_a_selfhosted_youtube_subscription_manager/">announcement</a>
of a very nice <a href="https://github.com/chibicitiberiu/ytsm">self-hosted YouTube subscription
manager</a>. I havenâ€™t used
YouTubeâ€™s built-in subscriptions for a while nowÙ« and havenâ€™t missed
it at all. When I saw the announcementÙ« I considered writing about the
solution Iâ€™ve built on top of <a href="https://youtube-dl.org/">youtube-dl</a>.</p>

<h2 id="background-the-problem-with-youtube">Background: the problem with YouTube</h2>

<p>In many waysÙ« I agree with <a href="https://staltz.com/what-happens-when-you-block-internet-giants.html">AndrÃ© Staltzâ€™s view on data ownership and
privacy</a>:</p>

<blockquote>
  <p>I started with the basic premise that â€œI want to be in control of my
dataâ€. Sometimes that meant choosing when to interact with an internet
giant and how much I feel like revealing to them. Most of times it
meant not interacting with them at all. I donâ€™t want to let them be in
full control of how much they can know about me. I donâ€™t want to be in
autopilot mode. (â€¦) Which leads us to YouTube. While I was able to
find alternatives to Gmail (Fastmail)Ù« Calendar (Fastmail)Ù« Translate
(Yandex Translate)Ù« etcÙ« YouTube remains as the most indispensable
Google-owned web service. It is really really hard to avoid consuming
YouTube content. It was probably the smartest startup acquisition
ever. My privacy-oriented alternative is to watch YouTube videos
through TorÙ« which is technically feasible but not polite to use the
Tor bandwidth for these purposes. Iâ€™m still scratching my head with
this issue.</p>
</blockquote>

<p>Even though I donâ€™t use most alternative services he mentionsÙ« I do
watch videos from YouTube. But I also feel uncomfortable logging in to
YouTube with a Google accountÙ« watching videosÙ« creating playlists and
similar things.</p>

<p>Using the mobile app is worse: you canâ€™t even block ads in there.
Youâ€™re in less control on what you share with YouTube and Google.</p>

<h2 id="youtube-dl">youtube-dl</h2>

<p>youtube-dl is a command-line tool for downloading videosÙ« from YouTube
and <a href="https://rg3.github.io/youtube-dl/supportedsites.html">many other sites</a>:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>youtube-dl https://www.youtube.com/watch?v<span class="o">=</span>rnMYZnY3uLA
<span class="o">[</span>youtube] rnMYZnY3uLA: Downloading webpage
<span class="o">[</span>youtube] rnMYZnY3uLA: Downloading video info webpage
<span class="o">[</span>download] Destination: A Origem da Vida _ Nerdologia-rnMYZnY3uLA.mp4
<span class="o">[</span>download] 100% of 32.11MiB <span class="k">in </span>00:12
</pre></td></tr></tbody></table></code></pre></div></div>

<p>It can be used to download individual videos as showed aboveÙ« but it
also has some interesting flags that we can use:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">--output</code>: use a custom template to create the name of the
downloaded file;</li>
  <li><code class="language-plaintext highlighter-rouge">--download-archive</code>: use a text file for recording and remembering
which videos were already downloaded;</li>
  <li><code class="language-plaintext highlighter-rouge">--prefer-free-formats</code>: prefer free video formatsÙ« like <code class="language-plaintext highlighter-rouge">webm</code>Ù«
<code class="language-plaintext highlighter-rouge">ogv</code> and Matroska <code class="language-plaintext highlighter-rouge">mkv</code>;</li>
  <li><code class="language-plaintext highlighter-rouge">--playlist-end</code>: how many videos to download from a â€œplaylistâ€ (a
channelÙ« a user or an actual playlist);</li>
  <li><code class="language-plaintext highlighter-rouge">--write-description</code>: write the video description to a
<code class="language-plaintext highlighter-rouge">.description</code> fileÙ« useful for accessing links and extra content.</li>
</ul>

<p>Putting it all together:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>youtube-dl <span class="s2">"https://www.youtube.com/channel/UClu474HMt895mVxZdlIHXEA"</span> <span class="se">\</span>
             <span class="nt">--download-archive</span> ~/Nextcloud/cache/youtube-dl-seen.conf <span class="se">\</span>
             <span class="nt">--prefer-free-formats</span> <span class="se">\</span>
             <span class="nt">--playlist-end</span> 20 <span class="se">\</span>
             <span class="nt">--write-description</span> <span class="se">\</span>
             <span class="nt">--output</span> <span class="s2">"~/Downloads/yt-dl/%(uploader)s/%(upload_date)s - %(title)s.%(ext)s"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This will download the latest 20 videos from the selected channelÙ« and
write down the video IDs in the <code class="language-plaintext highlighter-rouge">youtube-dl-seen.conf</code> file. Running it
immediately after one more time wonâ€™t have any effect.</p>

<p>If the channel posts one more videoÙ« running the same command again will
download only the last videoÙ« since the other 19 were already
downloaded.</p>

<p>With this basic setup you have a minimal subscription system at workÙ«
and you can create some functions to help you manage that:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre></td><td class="rouge-code"><pre><span class="c">#!/bin/sh</span>

<span class="nb">export </span><span class="nv">DEFAULT_PLAYLIST_END</span><span class="o">=</span>15

download<span class="o">()</span> <span class="o">{</span>
  youtube-dl <span class="s2">"</span><span class="nv">$1</span><span class="s2">"</span> <span class="se">\</span>
             <span class="nt">--download-archive</span> ~/Nextcloud/cache/youtube-dl-seen.conf <span class="se">\</span>
             <span class="nt">--prefer-free-formats</span> <span class="se">\</span>
             <span class="nt">--playlist-end</span> <span class="nv">$2</span> <span class="se">\</span>
             <span class="nt">--write-description</span> <span class="se">\</span>
             <span class="nt">--output</span> <span class="s2">"~/Downloads/yt-dl/%(uploader)s/%(upload_date)s - %(title)s.%(ext)s"</span>
<span class="o">}</span>
<span class="nb">export</span> <span class="nt">-f</span> download


download_user<span class="o">()</span> <span class="o">{</span>
  download <span class="s2">"https://www.youtube.com/user/</span><span class="nv">$1</span><span class="s2">"</span> <span class="k">${</span><span class="nv">2</span><span class="p">-</span><span class="nv">$DEFAULT_PLAYLIST_END</span><span class="k">}</span>
<span class="o">}</span>
<span class="nb">export</span> <span class="nt">-f</span> download_user


download_channel<span class="o">()</span> <span class="o">{</span>
  download <span class="s2">"https://www.youtube.com/channel/</span><span class="nv">$1</span><span class="s2">"</span> <span class="k">${</span><span class="nv">2</span><span class="p">-</span><span class="nv">$DEFAULT_PLAYLIST_END</span><span class="k">}</span>
<span class="o">}</span>
<span class="nb">export</span> <span class="nt">-f</span> download_channel


download_playlist<span class="o">()</span> <span class="o">{</span>
  download <span class="s2">"https://www.youtube.com/playlist?list=</span><span class="nv">$1</span><span class="s2">"</span> <span class="k">${</span><span class="nv">2</span><span class="p">-</span><span class="nv">$DEFAULT_PLAYLIST_END</span><span class="k">}</span>
<span class="o">}</span>
<span class="nb">export</span> <span class="nt">-f</span> download_playlist
</pre></td></tr></tbody></table></code></pre></div></div>

<p>With these functionsÙ« you now can have a subscription fetching script to
download the latest videos from your favorite channels:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="c">#!/bin/sh</span>

download_user     ClojureTV                            15
download_channel  <span class="s2">"UCmEClzCBDx-vrt0GuSKBd9g"</span>           100
download_playlist <span class="s2">"PLqG7fA3EaMRPzL5jzd83tWcjCUH9ZUsbX"</span> 15
</pre></td></tr></tbody></table></code></pre></div></div>

<p>NowÙ« whenever you want to watch the latest videosÙ« just run the above
script and youâ€™ll get all of them in your local machine.</p>

<h2 id="tradeoffs">Tradeoffs</h2>

<h3 id="ive-made-it-for-myself-with-my-use-case-in-mind">Iâ€™ve made it for myselfÙ« with my use case in mind</h3>

<ol>
  <li>
    <p>Offline</p>

    <p>My internet speed it somewhat reasonable<sup id="fnref:internet-speed" role="doc-noteref"><a href="#fn:internet-speed" class="footnote">1</a></sup>Ù« but it is really
unstable. Either at work or at homeÙ« itâ€™s not uncommon to loose internet
access for 2 minutes 3~5 times every dayÙ« and stay completely offline for a
couple of hours once every week.</p>

    <p>Working through the hassle of keeping a playlist on disk has payed
off manyÙ« many times. Sometimes I even not notice when the
connection drops for some minutesÙ« because Iâ€™m watching a video and
working on some documentÙ« all on my local computer.</p>

    <p>Thereâ€™s also no quality adjustment for YouTubeâ€™s web playerÙ« I
always pick the higher quality and it doesnâ€™t change during the
video. For some types of contentÙ« like a podcast with some tiny
visual resourcesÙ« this doesnâ€™t change much. For other types of
contentÙ« like a keynote presentation with text written on the
slidesÙ« watching on 144p isnâ€™t really an option.</p>

    <p>If the internet connection drops during the video downloadÙ«
youtube-dl will resume from where it stopped.</p>

    <p>This is an offline first benefit that I really likeÙ« and works well
for me.</p>
  </li>
  <li>
    <p>Sync the â€œseenâ€ file</p>

    <p>I already have a running instance of NextcloudÙ« so just dumping the
<code class="language-plaintext highlighter-rouge">youtube-dl-seen.conf</code> file inside Nextcloud was a no-brainer.</p>

    <p>You could try putting it in a dedicated git repositoryÙ« and wrap the
script with an autocommit after every run. If you ever had a merge
conflictÙ« youâ€™d simply accept all changes and then run:</p>

    <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span><span class="nb">uniq </span>youtube-dl-seen.conf <span class="o">&gt;</span> youtube-dl-seen.conf
</pre></td></tr></tbody></table></code></pre></div>    </div>

    <p>to tidy up the file.</p>
  </li>
  <li>
    <p>Doesnâ€™t work on mobile</p>

    <p>My primary device that I use everyday is my laptopÙ« not my phone. It
works well for me this way.</p>

    <p>AlsoÙ« itâ€™s harder to add ad-blockers to mobile phonesÙ« and most
mobile software still depends on Googleâ€™s and Appleâ€™s blessing.</p>

    <p>If you wishÙ« you can sync the videos to the SD card periodicallyÙ«
but thatâ€™s a bit of extra manual work.</p>
  </li>
</ol>

<h3 id="the-good">The Good</h3>

<ol>
  <li>
    <p>Better privacy</p>

    <p>We donâ€™t even have to configure the ad-blocker to keep ads and
trackers away!</p>

    <p>YouTube still has your IP addressÙ« so using a VPN is always a good
idea. HoweverÙ« a timing analysis would be able to identify you
(considering the current implementation).</p>
  </li>
  <li>
    <p>No need to self-host</p>

    <p>Thereâ€™s no host that needs maintenance. Everything runs locally.</p>

    <p>As long as you keep youtube-dl itself up to date and sync your
â€œseenâ€ fileÙ« thereâ€™s little extra work to do.</p>
  </li>
  <li>
    <p>Track your subscriptions with git</p>

    <p>After creating a <code class="language-plaintext highlighter-rouge">subscriptions.sh</code> executable that downloads all
the videosÙ« you can add it to git and use it to track metadata about
your subscriptions.</p>
  </li>
</ol>

<h3 id="the-bad">The Bad</h3>

<ol>
  <li>
    <p>Maximum playlist size is your disk size</p>

    <p>This is a good thing for getting a realistic view on your actual
â€œwatch laterâ€ list. However Iâ€™ve run out of disk space many
timesÙ« and now I need to be more aware of how much is left.</p>
  </li>
</ol>

<h3 id="the-ugly">The Ugly</h3>

<p>We can only avoid all the bad parts of YouTube with youtube-dl as long
as YouTube keeps the videos public and programmatically accessible. If
YouTube ever blocks that weâ€™d loose the ability to consume content this
wayÙ« but also loose confidence on considering YouTube a healthy
repository of videos on the internet.</p>

<h2 id="going-beyond">Going beyond</h2>

<p>Since youâ€™re running everything locallyÙ« here are some possibilities to
be explored:</p>

<h3 id="a-playlist-that-is-too-long-for-being-downloaded-all-at-once">A playlist that is too long for being downloaded all at once</h3>

<p>You can wrap the <code class="language-plaintext highlighter-rouge">download_playlist</code> function (letâ€™s call the wrapper
<code class="language-plaintext highlighter-rouge">inc_download</code>) and instead of passing it a fixed number to the
<code class="language-plaintext highlighter-rouge">--playlist-end</code> parameterÙ« you can store the <code class="language-plaintext highlighter-rouge">$n</code> in a folder
(something like <code class="language-plaintext highlighter-rouge">$HOME/.yt-db/$PLAYLIST_ID</code>) and increment it by <code class="language-plaintext highlighter-rouge">$step</code>
every time you run <code class="language-plaintext highlighter-rouge">inc_download</code>.</p>

<p>This way you can incrementally download videos from a huge playlist
without filling your disk with gigabytes of content all at once.</p>

<h3 id="multiple-computer-scenario">Multiple computer scenario</h3>

<p>The <code class="language-plaintext highlighter-rouge">download_playlist</code> function could be aware of the specific machine
that it is running on and apply specific policies depending on the
machine: always download everything; only download videos that arenâ€™t
present anywhere else; etc.</p>

<h2 id="conclusion">Conclusion</h2>

<p>youtube-dl is a great tool to keep at hand. It covers a really large
range of video websites and works robustly.</p>

<p>Feel free to copy and modify this codeÙ« and <a href="mailto:eu@euandre.org">send me</a>
suggestions of improvements or related content.</p>

<h2 id="edit"><em>Edit</em></h2>

<p>2019/05/22: Fix spelling.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:internet-speed" role="doc-endnote">
      <p>Considering how expensive it is and the many ways it could be
betterÙ« but also how much it has improved over the last yearsÙ« I say itâ€™s
reasonable.Â <a href="#fnref:internet-speed" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>'),('https://euandre.org/2018/08/01/verifying-npm-ci-reproducibility.html', 'Verifying â€œnpm ciâ€ reproducibility', '1533081600000',  1, '<p>When <a href="https://blog.npmjs.org/post/161081169345/v500">npm@5</a> came bringing
<a href="https://docs.npmjs.com/files/package-locks">package-locks</a> with itÙ« I was
confused about the benefits it providedÙ« since running <code class="language-plaintext highlighter-rouge">npm install</code> more than
once could resolve all the dependencies again and yield yet another fresh
<code class="language-plaintext highlighter-rouge">package-lock.json</code> file. The message saying â€œyou should add this file to
version controlâ€ left me hesitant on what to do<sup id="fnref:package-lock-message" role="doc-noteref"><a href="#fn:package-lock-message" class="footnote">1</a></sup>.</p>

<p>However the <a href="https://blog.npmjs.org/post/171556855892/introducing-npm-ci-for-faster-more-reliable">addition of <code class="language-plaintext highlighter-rouge">npm ci</code></a>
filled this gap: itâ€™s a stricter variation of <code class="language-plaintext highlighter-rouge">npm install</code> which
guarantees that â€œ<a href="https://docs.npmjs.com/files/package-lock.json">subsequent installs are able to generate identical trees</a>â€. But are they
really identical? I could see that I didnâ€™t have the same problems of
different installation outputsÙ« but I didnâ€™t know for <strong>sure</strong> if it
was really identical.</p>

<h2 id="computing-the-hash-of-a-directorys-content">Computing the hash of a directoryâ€™s content</h2>

<p>I quickly searched for a way to check for the hash signature of an
entire directory treeÙ« but I couldnâ€™t find one. Iâ€™ve made a poor
manâ€™s <a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle tree</a>
implementation using <code class="language-plaintext highlighter-rouge">sha256sum</code> and a few piped commands at the
terminal:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre>merkle-tree <span class="o">()</span> <span class="o">{</span>
  <span class="nb">dirname</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">1</span><span class="p">-.</span><span class="k">}</span><span class="s2">"</span>
  <span class="nb">pushd</span> <span class="s2">"</span><span class="nv">$dirname</span><span class="s2">"</span>
  find <span class="nb">.</span> <span class="nt">-type</span> f              | <span class="se">\</span>
    <span class="nb">sort</span>                      | <span class="se">\</span>
    xargs <span class="nt">-I</span><span class="o">{}</span> <span class="nb">sha256sum</span> <span class="s2">"{}"</span> | <span class="se">\</span>
    <span class="nb">sha256sum</span>                 | <span class="se">\</span>
    <span class="nb">awk</span> <span class="s1">"{print $1}"</span>
  <span class="nb">popd</span>
<span class="o">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Going through it line by line:</p>

<ul>
  <li>#1 we define a Bash function called <code class="language-plaintext highlighter-rouge">merkle-tree</code>;</li>
  <li>#2 it accepts a single argument: the directory to compute the
merkle tree from. If nothing is givenÙ« it runs on the current
directory (<code class="language-plaintext highlighter-rouge">.</code>);</li>
  <li>#3 we go to the directoryÙ« so we donâ€™t get different prefixes in
<code class="language-plaintext highlighter-rouge">find</code>â€™s output (like <code class="language-plaintext highlighter-rouge">../a/b</code>);</li>
  <li>#4 we get all files from the directory tree. Since weâ€™re using
<code class="language-plaintext highlighter-rouge">sha256sum</code> to compute the hash of the file contentsÙ« we need to
filter out folders from it;</li>
  <li>#5 we need to sort the outputÙ« since different file systems and
<code class="language-plaintext highlighter-rouge">find</code> implementations may return files in different orders;</li>
  <li>#6 we use <code class="language-plaintext highlighter-rouge">xargs</code> to compute the hash of each file individually
through <code class="language-plaintext highlighter-rouge">sha256sum</code>. Since a file may contain spaces we need to
escape it with quotes;</li>
  <li>#7 we compute the hash of the combined hashes. Since <code class="language-plaintext highlighter-rouge">sha256sum</code>
output is formatted like <code class="language-plaintext highlighter-rouge">&lt;hash&gt; &lt;filename&gt;</code>Ù« it produces a
different final hash if a file ever changes name without changing
itâ€™s content;</li>
  <li>#8 we get the final hash outputÙ« excluding the <code class="language-plaintext highlighter-rouge">&lt;filename&gt;</code> (which
  is <code class="language-plaintext highlighter-rouge">-</code> in this caseÙ« aka <code class="language-plaintext highlighter-rouge">stdin</code>).</li>
</ul>

<h3 id="positive-points">Positive points:</h3>

<ol>
  <li>ignore timestamp: running more than once on different installation
yields the same hash;</li>
  <li>the name of the file is included in the final hash computation.</li>
</ol>

<h3 id="limitations">Limitations:</h3>

<ol>
  <li>it ignores empty folders from the hash computation;</li>
  <li>the implementationâ€™s only goal is to represent using a digest
whether the content of a given directory is the same or not. Leaf
presence checking is obviously missing from it.</li>
</ol>

<h3 id="testing-locally-with-sample-data">Testing locally with sample data</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="nb">mkdir</span> /tmp/merkle-tree-test/
<span class="nb">cd</span> /tmp/merkle-tree-test/
<span class="nb">mkdir</span> <span class="nt">-p</span> a/b/ a/c/ d/
<span class="nb">echo</span> <span class="s2">"one"</span>   <span class="o">&gt;</span> a/b/one.txt
<span class="nb">echo</span> <span class="s2">"two"</span>   <span class="o">&gt;</span> a/c/two.txt
<span class="nb">echo</span> <span class="s2">"three"</span> <span class="o">&gt;</span> d/three.txt
merkle-tree <span class="nb">.</span> <span class="c"># output is       be343bb01fe00aeb8fef14a3e16b1c3d1dccbf86d7e41b4753e6ccb7dc3a57c3</span>
merkle-tree <span class="nb">.</span> <span class="c"># output still is be343bb01fe00aeb8fef14a3e16b1c3d1dccbf86d7e41b4753e6ccb7dc3a57c3</span>
<span class="nb">echo</span> <span class="s2">"four"</span>  <span class="o">&gt;</span> d/four.txt
merkle-tree <span class="nb">.</span> <span class="c"># output is now   b5464b958969ed81815641ace96b33f7fd52c20db71a7fccc45a36b3a2ae4d4c</span>
<span class="nb">rm </span>d/four.txt
merkle-tree <span class="nb">.</span> <span class="c"># output back to  be343bb01fe00aeb8fef14a3e16b1c3d1dccbf86d7e41b4753e6ccb7dc3a57c3</span>
<span class="nb">echo</span> <span class="s2">"hidden-five"</span> <span class="o">&gt;</span> a/b/one.txt
merkle-tree <span class="nb">.</span> <span class="c"># output changed  471fae0d074947e4955e9ac53e95b56e4bc08d263d89d82003fb58a0ffba66f5</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>It seems to work for this simple test case.</p>

<p>You can try copying and pasting it to verify the hash signatures.</p>

<h2 id="using-merkle-tree-to-check-the-output-of-npm-ci">Using <code class="language-plaintext highlighter-rouge">merkle-tree</code> to check the output of <code class="language-plaintext highlighter-rouge">npm ci</code></h2>

<p><em>Iâ€™ve done all of the following using Node.js v8.11.3 and npm@6.1.0.</em></p>

<p>In this test case Iâ€™ll take the main repo of
<a href="https://lernajs.io/">Lerna</a><sup id="fnref:lerna-package-lock" role="doc-noteref"><a href="#fn:lerna-package-lock" class="footnote">2</a></sup>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="nb">cd</span> /tmp/
git clone https://github.com/lerna/lerna.git
<span class="nb">cd </span>lerna/
git checkout 57ff865c0839df75dbe1974971d7310f235e1109
npm ci
merkle-tree node_modules/ <span class="c"># outputs 11e218c4ac32fac8a9607a8da644fe870a25c99821167d21b607af45699afafa</span>
<span class="nb">rm</span> <span class="nt">-rf</span> node_modules/
npm ci
merkle-tree node_modules/ <span class="c"># outputs 11e218c4ac32fac8a9607a8da644fe870a25c99821167d21b607af45699afafa</span>
npm ci      <span class="c"># test if it also works with an existing node_modules/ folder</span>
merkle-tree node_modules/ <span class="c"># outputs 11e218c4ac32fac8a9607a8da644fe870a25c99821167d21b607af45699afafa</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Good job <code class="language-plaintext highlighter-rouge">npm ci</code> :)</p>

<p>#6 and #9 take some time to run (21 seconds in my machine)Ù« but this
specific use case isnâ€™t performance sensitive. The slowest step is
computing the hash of each individual file.</p>

<h2 id="conclusion">Conclusion</h2>

<p><code class="language-plaintext highlighter-rouge">npm ci</code> really â€œgenerates identical treesâ€.</p>

<p>Iâ€™m not aware of any other existing solution for verifying the hash
signature of a directory. If you know any Iâ€™d <a href="mailto:eu@euandre.org">like to know</a>.</p>

<h2 id="edit"><em>Edit</em></h2>

<p>2019/05/22: Fix spelling.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:package-lock-message" role="doc-endnote">
      <p>The
<a href="https://docs.npmjs.com/cli/install#description">documentation</a> claims <code class="language-plaintext highlighter-rouge">npm
install</code> is driven by the existing <code class="language-plaintext highlighter-rouge">package-lock.json</code>Ù« but thatâ€™s actually
<a href="https://github.com/npm/npm/issues/17979#issuecomment-332701215">a little bit tricky</a>.Â <a href="#fnref:package-lock-message" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:lerna-package-lock" role="doc-endnote">
      <p>Finding a big known repo that actually committed the
<code class="language-plaintext highlighter-rouge">package-lock.json</code> file was harder than I expected.Â <a href="#fnref:lerna-package-lock" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>'),('https://euandre.org/2018/07/17/running-guix-on-nixos.html', 'Running Guix on NixOS', '1531785600000',  1, '<p>I wanted to run
Guix on a NixOS machine. Even though the Guix manual explains how to do it
<a href="https://www.gnu.org/software/guix/manual/en/html_node/Binary-Installation.html#Binary-Installation">step by step</a>Ù« I needed a few extra ones to make it work properly.</p>

<p>I couldnâ€™t just install GuixSD because my wireless network card
doesnâ€™t have any free/libre drivers (yet).</p>

<h2 id="creating-guixbuilder-users">Creating <code class="language-plaintext highlighter-rouge">guixbuilder</code> users</h2>

<p>Guix requires you to create non-root users that will be used to perform
the builds in the isolated environments.</p>

<p>The <a href="https://www.gnu.org/software/guix/manual/en/html_node/Build-Environment-Setup.html#Build-Environment-Setup">manual</a> already provides you with a ready to run (as root) command for
creating the build users:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre>groupadd <span class="nt">--system</span> guixbuild
<span class="k">for </span>i <span class="k">in</span> <span class="sb">`</span><span class="nb">seq</span> <span class="nt">-w</span> 1 10<span class="sb">`</span><span class="p">;</span>
<span class="k">do
  </span>useradd <span class="nt">-g</span> guixbuild <span class="nt">-G</span> guixbuild           <span class="se">\</span>
          <span class="nt">-d</span> /var/empty <span class="nt">-s</span> <span class="sb">`</span>which nologin<span class="sb">`</span>    <span class="se">\</span>
          <span class="nt">-c</span> <span class="s2">"Guix build user </span><span class="nv">$i</span><span class="s2">"</span> <span class="nt">--system</span>    <span class="se">\</span>
          guixbuilder<span class="nv">$i</span><span class="p">;</span>
<span class="k">done</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>HoweverÙ« In my personal NixOS I have disabled <a href="https://nixos.org/nixos/manual/index.html#sec-user-management"><code class="language-plaintext highlighter-rouge">users.mutableUsers</code></a>Ù« which
means that even if I run the above command it means that theyâ€™ll be removed once
I rebuild my OS:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span><span class="nb">sudo </span>nixos-rebuild switch
<span class="o">(</span>...<span class="o">)</span>
removing user â€˜guixbuilder7â€™
removing user â€˜guixbuilder3â€™
removing user â€˜guixbuilder10â€™
removing user â€˜guixbuilder1â€™
removing user â€˜guixbuilder6â€™
removing user â€˜guixbuilder9â€™
removing user â€˜guixbuilder4â€™
removing user â€˜guixbuilder2â€™
removing user â€˜guixbuilder8â€™
removing user â€˜guixbuilder5â€™
<span class="o">(</span>...<span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Instead of enabling <code class="language-plaintext highlighter-rouge">users.mutableUsers</code> I could add the Guix users by
adding them to my system configuration:</p>

<div class="language-nix highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
</pre></td><td class="rouge-code"><pre><span class="p">{</span> <span class="nv">config</span><span class="p">Ù«</span> <span class="nv">pkgs</span><span class="p">Ù«</span> <span class="o">...</span><span class="p">}:</span>

<span class="p">{</span>

  <span class="c"># ... NixOS usual config ellided ...</span>

  <span class="nv">users</span> <span class="o">=</span> <span class="p">{</span>
    <span class="nv">mutableUsers</span> <span class="o">=</span> <span class="kc">false</span><span class="p">;</span>

    <span class="nv">extraUsers</span> <span class="o">=</span>
      <span class="kd">let</span>
        <span class="nv">andrehUser</span> <span class="o">=</span>  <span class="p">{</span>
          <span class="nv">andreh</span> <span class="o">=</span> <span class="p">{</span>
            <span class="c"># my custom user config</span>
          <span class="p">};</span>
        <span class="p">};</span>
        <span class="nv">buildUser</span> <span class="o">=</span> <span class="p">(</span><span class="nv">i</span><span class="p">:</span>
          <span class="p">{</span>
            <span class="s2">"guixbuilder</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span><span class="s2">"</span> <span class="o">=</span> <span class="p">{</span>                   <span class="c"># guixbuilder$i</span>
              <span class="nv">group</span> <span class="o">=</span> <span class="s2">"guixbuild"</span><span class="p">;</span>                  <span class="c"># -g guixbuild</span>
              <span class="nv">extraGroups</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"guixbuild"</span><span class="p">];</span>          <span class="c"># -G guixbuild</span>
              <span class="nv">home</span> <span class="o">=</span> <span class="s2">"/var/empty"</span><span class="p">;</span>                  <span class="c"># -d /var/empty</span>
              <span class="nv">shell</span> <span class="o">=</span> <span class="nv">pkgs</span><span class="o">.</span><span class="nv">nologin</span><span class="p">;</span>                 <span class="c"># -s `which nologin`</span>
              <span class="nv">description</span> <span class="o">=</span> <span class="s2">"Guix build user </span><span class="si">${</span><span class="nv">i</span><span class="si">}</span><span class="s2">"</span><span class="p">;</span> <span class="c"># -c "Guix buid user $i"</span>
              <span class="nv">isSystemUser</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span>                  <span class="c"># --system</span>
            <span class="p">};</span>
          <span class="p">}</span>
        <span class="p">);</span>
      <span class="kn">in</span>
        <span class="c"># merge all users</span>
        <span class="nv">pkgs</span><span class="o">.</span><span class="nv">lib</span><span class="o">.</span><span class="nv">fold</span> <span class="p">(</span><span class="nv">str</span><span class="p">:</span> <span class="nv">acc</span><span class="p">:</span> <span class="nv">acc</span> <span class="o">//</span> <span class="nv">buildUser</span> <span class="nv">str</span><span class="p">)</span>
                      <span class="nv">andrehUser</span>
                      <span class="c"># for i in `seq -w 1 10`</span>
                      <span class="p">(</span><span class="kr">map</span> <span class="p">(</span><span class="nv">pkgs</span><span class="o">.</span><span class="nv">lib</span><span class="o">.</span><span class="nv">fixedWidthNumber</span> <span class="mi">2</span><span class="p">)</span> <span class="p">(</span><span class="kr">builtins</span><span class="o">.</span><span class="nv">genList</span> <span class="p">(</span><span class="nv">n</span><span class="p">:</span> <span class="nv">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="mi">10</span><span class="p">));</span>

    <span class="nv">extraGroups</span><span class="o">.</span><span class="nv">guixbuild</span> <span class="o">=</span> <span class="p">{</span>
      <span class="nv">name</span> <span class="o">=</span> <span class="s2">"guixbuild"</span><span class="p">;</span>
    <span class="p">};</span>
  <span class="p">};</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Here I used <code class="language-plaintext highlighter-rouge">fold</code> and the <code class="language-plaintext highlighter-rouge">//</code> operator to merge all of the
configuration sets into a single <code class="language-plaintext highlighter-rouge">extraUsers</code> value.</p>

<h2 id="creating-the-systemd-service">Creating the <code class="language-plaintext highlighter-rouge">systemd</code> service</h2>

<p>One other thing missing was the <code class="language-plaintext highlighter-rouge">systemd</code> service.</p>

<p>First I couldnâ€™t just copy the <code class="language-plaintext highlighter-rouge">.service</code> file to <code class="language-plaintext highlighter-rouge">/etc</code> since in NixOS
that folder isnâ€™t writable. But also I wanted the service to be better
integrated with the OS.</p>

<p>That was a little easier than creating the usersÙ« all I had to do was translate
the provided <a href="https://git.savannah.gnu.org/cgit/guix.git/tree/etc/guix-daemon.service.in?id=00c86a888488b16ce30634d3a3a9d871ed6734a2"><code class="language-plaintext highlighter-rouge">guix-daemon.service.in</code></a> configuration to an equivalent Nix
expression</p>

<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td class="rouge-code"><pre><span class="c"># This is a "service unit file" for the systemd init system to launch
# "guix-daemon".  Drop it in /etc/systemd/system or similar to have
# "guix-daemon" automatically started.
</span>
<span class="nn">[Unit]</span>
<span class="py">Description</span><span class="p">=</span><span class="s">Build daemon for GNU Guix</span>

<span class="nn">[Service]</span>
<span class="py">ExecStart</span><span class="p">=</span><span class="s">/var/guix/profiles/per-user/root/guix-profile/bin/guix-daemon --build-users-group=guixbuild</span>
<span class="py">Environment</span><span class="p">=</span><span class="s">GUIX_LOCPATH=/root/.guix-profile/lib/locale</span>
<span class="py">RemainAfterExit</span><span class="p">=</span><span class="s">yes</span>
<span class="py">StandardOutput</span><span class="p">=</span><span class="s">syslog</span>
<span class="py">StandardError</span><span class="p">=</span><span class="s">syslog</span>

<span class="c"># See &lt;https://lists.gnu.org/archive/html/guix-devel/2016-04/msg00608.html&gt;.
# Some package builds (for exampleÙ« go@1.8.1) may require even more than
# 1024 tasks.
</span><span class="py">TasksMax</span><span class="p">=</span><span class="s">8192</span>

<span class="nn">[Install]</span>
<span class="py">WantedBy</span><span class="p">=</span><span class="s">multi-user.target</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This sample <code class="language-plaintext highlighter-rouge">systemd</code> configuration file became:</p>

<div class="language-nix highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="rouge-code"><pre><span class="nv">guix-daemon</span> <span class="o">=</span> <span class="p">{</span>
  <span class="nv">enable</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span>
  <span class="nv">description</span> <span class="o">=</span> <span class="s2">"Build daemon for GNU Guix"</span><span class="p">;</span>
  <span class="nv">serviceConfig</span> <span class="o">=</span> <span class="p">{</span>
    <span class="nv">ExecStart</span> <span class="o">=</span> <span class="s2">"/var/guix/profiles/per-user/root/guix-profile/bin/guix-daemon --build-users-group=guixbuild"</span><span class="p">;</span>
    <span class="nv">Environment</span><span class="o">=</span><span class="s2">"GUIX_LOCPATH=/root/.guix-profile/lib/locale"</span><span class="p">;</span>
    <span class="nv">RemainAfterExit</span><span class="o">=</span><span class="s2">"yes"</span><span class="p">;</span>
    <span class="nv">StandardOutput</span><span class="o">=</span><span class="s2">"syslog"</span><span class="p">;</span>
    <span class="nv">StandardError</span><span class="o">=</span><span class="s2">"syslog"</span><span class="p">;</span>
    <span class="nv">TaskMax</span><span class="o">=</span> <span class="s2">"8192"</span><span class="p">;</span>
  <span class="p">};</span>
  <span class="nv">wantedBy</span> <span class="o">=</span> <span class="p">[</span> <span class="s2">"multi-user.target"</span> <span class="p">];</span>
<span class="p">};</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>There you go! After running <code class="language-plaintext highlighter-rouge">sudo nixos-rebuild switch</code> I could get Guix
up and running:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>guix package <span class="nt">-i</span> hello
The following package will be installed:
   hello        2.10    /gnu/store/bihfrh609gkxb9dp7n96wlpigiv3krfy-hello-2.10

substitute: updating substitutes from <span class="s1">"https://mirror.hydra.gnu.org"</span>... 100.0%
The following derivations will be built:
   /gnu/store/nznmdn6inpwxnlkrasydmda4s2vsp9hg-profile.drv
   /gnu/store/vibqrvw4c8lacxjrkqyzqsdrmckv77kq-fonts-dir.drv
   /gnu/store/hi8alg7wi0wgfdi3rn8cpp37zhx8ykf3-info-dir.drv
   /gnu/store/cvkbp378cvfjikz7mjymhrimv7j12p0i-ca-certificate-bundle.drv
   /gnu/store/d62fvxymnp95rzahhmhf456bsf0xg1c6-manual-database.drv
Creating manual page database...
1 entries processed <span class="k">in </span>0.0 s
2 packages <span class="k">in </span>profile
<span class="nv">$ </span>hello
HelloÙ« world!
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Some improvements to this approach are:</p>

<ol>
  <li>looking into <a href="https://nixos.org/nixos/manual/index.html#sec-writing-modules">NixOS modules</a> and trying to bundle everything together
into a single logical unit;</li>
  <li><a href="https://www.gnu.org/software/guix/manual/en/html_node/Requirements.html#Requirements">build Guix from source</a> and share the Nix store and daemon with Guix.</li>
</ol>

<p>Happy Guix/Nix hacking!</p>'),('https://tinyprojects.dev/projects/tiny_website', 'Week 0: Tiny Website | Tiny Projects', 'NaN',  4, 'Week 0 of my year long tiny projects mission. Project 0 is building a tiny website.'),('https://tinyprojects.dev/posts/tiny_websites_are_great', 'Tiny websites are great | Tiny Projects', 'NaN',  4, 'Why building your own tiny website is a really great project that every coder should do.'),('https://tinyprojects.dev/posts/tiny_websites_are_great', 'How to code a tiny website | Tiny Projects', 'NaN',  4, 'How to make a tiny website that"s really simpleÙ« easy to maintainÙ« and cheap to run.'),('https://tinyprojects.dev/guides/tiny_website', 'How to code a tiny website | Tiny Projects', 'NaN',  4, 'How to make a tiny website that"s really simpleÙ« easy to maintainÙ« and cheap to run.'),('https://tinyprojects.dev/projects/silicon_valley_domain_names', 'Week 1: Silicon Valley Domain Names | Tiny Projects', 'NaN',  4, 'Week 1 of Tiny Projects. Exploring domain namesÙ« and how it was possible to purchase some of the biggest domain names in silicon valleyÙ« including netflix.soy.'),('https://tinyprojects.dev/posts/i_bought_netflix_dot_soy', 'I bought netflix.soy | Tiny Projects', 'NaN',  4, 'An exploration into top level domains. How I ended up buying netflix.soy and domains from facebookÙ« microsoft and google.'),('https://tinyprojects.dev/projects/battle_royale', 'Week 2/3: Building a Battle Royale game | Tiny Projects', 'NaN',  4, 'How I built and launched a tiny battle royale game in the space of two weeks. It was a struggle. Welcome to week 2/3 of Tiny Projects!'),('https://tinyprojects.dev/projects/one_item_store', 'Week 4/5: One Item Store | Tiny Projects', 'NaN',  4, 'The story of building and launching a tiny online store builder called; basically think of a micro-Shopify. This is week 4/5 of Tiny Projects.'),('https://tinyprojects.dev/posts/lockdown_burnout', 'Lockdown Burnout | Tiny Projects', 'NaN',  4, 'How I experienced lockdown burnout after 3 months of hardcore productivity during lockdownÙ« then how I overcame it.'),('https://tinyprojects.dev/projects/snormal', 'Project 4: Snormal | Tiny Projects', 'NaN',  4, 'How I built Snormal: a social network for all the bits of content that don"t make it onto your social media highlight reel.'),('https://tinyprojects.dev/posts/are_apps_even_that_relevant_anymore', 'Are apps even that relevant anymore? | Tiny Projects', 'NaN',  4, 'Why I think mobile apps are becoming less relevant for developers and consumersÙ« and why we should go back to creating great mobile website software.'),('https://leancrew.com/all-this/2020/09/parsing-date-strings-in-shortcuts/', 'Parsing date strings in Shortcuts', '1599280749000',  5, '
  I didnâ€™t realize until today that Shortcuts has a date parser. It doesnâ€™t call itself a date parserÙ« and the documentation doesnâ€™t explain what kinds of text strings it can parseÙ« but itâ€™s ShortcutsÙ« so what would you expect?
'),('https://leancrew.com/all-this/2020/08/a-battery-bitbar-bonanza/', 'A battery BitBar bonanza', '1598830579000',  5, '
  I started reading <a href="https://forum.keyboardmaestro.com/new">this thread</a> on the Keyboard Maestro forum because Iâ€™ve been interested in the <a href="https://amazon.com/dp/B06XKNZT1P?tag=andnowitsa085-20">Stream Deck</a> (yesÙ« thatâ€™s an affiliate link) for a while and will probably be getting one soon. I kept reading because <a href="https://rhymeswithdiploma.com/">TJ Luoma</a>â€™s answer made me realize I didnâ€™t need the Stream Deck to use the ideas in his solution; it would work just as well with <a href="https://github.com/matryer/bitbar">BitBar</a>.
'),('https://leancrew.com/all-this/2020/08/rss-and-the-pleasure-of-not-thinking/', 'RSS and the pleasure of not thinking', '1598627975000',  5, '
  I listened to the recent <a href="https://www.relay.fm/mpu/550"><em>Mac Power Users</em> episode on RSS</a> while on a long walk the other dayÙ« and I really enjoyed it. PartlyÙ« of courseÙ« because I just like listening to Stephen and DavidÙ« but mainly because I didnâ€™t feel I had any stake in it.
'),('https://leancrew.com/all-this/2020/08/a-new-old-python/', 'A new old Python', '1598273968000',  5, '
  You may have noticed something new in <a href="https://leancrew.com/all-this/2020/08/bitbar-superduper-and-library-books/">yesterdayâ€™s scripts</a>: the shebang lines were
'),('https://leancrew.com/all-this/2020/08/bitbar-superduper-and-library-books/', 'BitBarÙ« SuperDuperÙ« and library books', '1598216239000',  5, '
  Jason Snellâ€™s <a href="https://sixcolors.com/post/2020/08/put-anything-in-your-macs-menu-bar-with-bitbar/">recent post</a> on <a href="https://github.com/matryer/bitbar">BitBar</a> inspired me to build a couple of menu bar notices of my own.
'),('https://leancrew.com/all-this/2020/08/epic-relief/', 'Epic relief', '1597754546000',  5, '
  One of the great things about not beingâ€”or having aspirations of beingâ€”a professional Apple blogger is that thereâ€™s no compulsion to write about every Apple story that pops up. I was reminded of this a few days ago when the Apple/Epic war broke out. As my RSS reader filled with links and summaries and hot takesÙ« a wave of relief washed over me. It was like seeing that my grades on the midterms and homework were good enough that I didnâ€™t have to take the final exam.
'),('https://leancrew.com/all-this/2020/08/apple-watch-settings/', 'Apple Watch settings', '1597412959000',  5, '
  <a href="https://leancrew.com/all-this/2020/08/dear-apple/">Recently</a>Ù« I had some trouble with my Apple Watch and had to unpair/re-pair it. In the processÙ« the watchâ€™s settings were lost. I was reminded of this yesterday when I crossed my arms and the watch announced the time. After Googling for the way to stop thatÙ« I decided to make a Note to accumulate all the settings Iâ€™ve used to get the watch working the way I want.
'),('https://leancrew.com/all-this/2020/08/deep-insight/', 'Deep insight', '1597203476000',  5, '
  Literally the last sentence in <a href="https://www.zdnet.com/article/mozilla-lays-off-250-employees-while-it-refocuses-on-commercial-products/">this article</a> about Mozilla laying off a quarter of its employees:
'),('https://leancrew.com/all-this/2020/08/dear-apple/', 'Dear AppleÙ«', '1597085751000',  5, '
  I have been an Apple user for 35 years. Do you have one minute for a little story? Thanks.
'),('https://leancrew.com/all-this/2020/08/a-more-handy-warhol/', 'A more handy Warhol', '1597068635000',  5, '
  After posting my <a href="https://leancrew.com/all-this/2020/08/development-shortcuts-and-warhol/">Warhol shortcut</a>Ù« I got a couple of good suggestions for improvements. They overlapped to some extentÙ« so I put them together into <a href="https://www.icloud.com/shortcuts/74ccef08af784e78abfe8a4448f8ae9b">a new Warhol</a>.
'),('https://leancrew.com/all-this/2020/08/phil-schiller/', 'Phil Schiller', '1596991701000',  5, '
  Although I wonâ€™t be terribly surprised if Phil Schiller appears onstage during this fallâ€™s introduction of the new iPhonesâ€”those things get planned well in advanceâ€”itâ€™s possible weâ€™ve seen the last of his keynote presentations. Iâ€™m going to miss them for a couple of reasons.
'),('https://leancrew.com/all-this/2020/08/development-shortcuts-and-warhol/', 'DevelopmentÙ« ShortcutsÙ« and Warhol', '1596810481000',  5, '
  For the past several daysÙ« Iâ€™ve been annoying my family with a shortcut. If there are people in your life you want to annoyÙ« you might want to use it. And apart from the annoyance valueÙ« it has some Shortcuts programming techniques that I want to memorialize for future use.
'),('https://jvns.ca/blog/2020/08/22/print-run-manager-zine/', 'Wizard Zines" first print run: Help! I have a Manager!', '1598066527000',  6, '

<p>Hello! For the first timeÙ« Wizard Zines is doing a â˜…â˜…print shipmentâ˜…â˜…!</p>

<p>I printed out 400 copies of <a href="https://wizardzines.com/zines/manager/">Help! I have a manager!</a> at the
best print shop I could find in Montreal and they&rsquo;re ready to ship to you. Free
shipping to anywhere in the world (as long as Canada Post will let me ship
there) is included. The deadline to order a zine is <strong>September 6</strong>.</p>

<p>I&rsquo;ve wanted to get into printing and shipping my zines for a long timeÙ« so I&rsquo;m
very excited to try this out. So far the only option has been for people to
print them on their home printers or at their local print shop.</p>

<p>I&rsquo;m doing all the packaging and shipping myself from my houseÙ« so I&rsquo;m going to
ship them all out in a big batch around September 7.</p>

<div align="center">                                                                                                                       
  <a class="button" href="https://gumroad.com/l/manager-zine-print">Get it for $16</a>

</div>

<h4 id="the-zines">the zines!</h4>

<p>Here&rsquo;s a picture of one of the boxes of zines! So many zines!
<div align="center"><img src="https://jvns.ca/images/box-of-zines.jpg" style="max-width: 20em"></div></p>

<p>I experimented with a few different print shops in MontrealÙ« and I found out
that using a print shop that cost more got me way better quality zines! So
that&rsquo;s what I did. (I went with <a href="https://www.photosynthese.com/en-ca">PhotosynthÃ¨se</a>).</p>

<h4 id="why-i-m-shipping-them-myself">why I&rsquo;m shipping them myself</h4>

<p>I spent a bunch of time looking into fulfillment companies to try to ~scale~
printing &amp; shipping zines. That research might still come in handy if
this first batch goes well (I probably won&rsquo;t keep doing it myself forever!)Ù«
but in the spirit of
<a href="https://stackingthebricks.com/the-fine-art-of-flintstoning/">flintstoning</a>Ù« I
decided it would be a lot simpler to start out by not overengineering the
process. Shipping a zine to the US from Canada using letter mail only costs
about $3Ù« so I can even include free shipping.</p>

<p>I&rsquo;ve actually shipped 100 zines once before in an <a href="https://www.indiegogo.com/projects/linux-debugging-tools-you-ll-love-the-zine#/">indiegogo campaign I ran in
2016</a>Ù«
and it wasn&rsquo;t too badÙ« so I&rsquo;m confident that I can ship 400 zines manually as
long as I can do it all in one giant batch. That time I even wrote all the
addresses by handÙ« which I definitely won&rsquo;t do this time.</p>

<p>And doing it myself means I can do some fun things with the envelopes &amp; my
laser printer that would be hard to convince a fulfillment company to do.</p>

<h2 id="faq">FAQ</h2>

<p>Here&rsquo;s a FAQ which will hopefully answer all your questions! Email me
at print@wizardzines.com if you have other questions.</p>

<h4 id="what-s-included">What&rsquo;s included?</h4>

<p>You&rsquo;ll get:</p>

<ol>
<li>A print copy of Help! I have a manager!Ù« printed in full colour on high quality paper.</li>
<li>A PDF copy of Help! I have a manager! (which usually costs $10 on its own).</li>
</ol>

<h4 id="what-s-the-order-deadline">What&rsquo;s the order deadline?</h4>

<p>The deadline to order a zine is <strong>September 6</strong>.</p>

<h4 id="when-will-i-get-it">When will I get it?</h4>

<p>I&rsquo;ll mail all the zines around September 7-8Ù« 2020 (right after orders close).</p>

<p>You should get your zine about a week laterÙ« assuming the mail system behaves.</p>

<h4 id="will-i-get-a-tracking-number">Will I get a tracking number?</h4>

<p>No. All the zines will be shipped by first class letter mail from CanadaÙ« without any tracking. This keeps shipping costs down so that I can do free shipping :). If anything at all goes wrong with your shipmentÙ« just let me know (<strong>print@wizardzines.com</strong>) and I&rsquo;ll mail you another one. (it&rsquo;s like UDP!)</p>

<p>The zines should reach the US in about a weekÙ« longer if you&rsquo;re overseas.</p>

<h4 id="can-i-order-more-than-one-copy-at-a-time">Can I order more than one copy at a time?</h4>

<p>NoÙ« to keep things simpleÙ« I&rsquo;m only shipping one zine at a time. I&rsquo;m hoping to do batches in the future though!</p>

<h4 id="can-i-order-these-for-my-team">Can I order these for my team?</h4>

<p>Yes! You&rsquo;ll just need to make one order per personÙ« so that I get everyone&rsquo;s shipping address. This is extremely compatible with remote work :)</p>

<p><small>alsoÙ« if you want to order 50 or more print copies mailed to a single addressÙ« email me and we&rsquo;ll work something out</small></p>

<h4 id="what-happens-if-i-don-t-order-by-september-6">What happens if I don&rsquo;t order by September 6?</h4>

<p>If this print run sells outÙ« we&rsquo;ll print more in the future!</p>

<h4 id="what-if-i-already-bought-the-digital-copy">What if I already bought the digital copy?</h4>

<p>If you already bought the digital copy &ndash; thank you!! You can email me at <strong>print@wizardzines.com</strong> and I&rsquo;ll send you a discount code to get the print version for less.</p>

<h4 id="what-are-your-future-print-plans">What are your future print plans?</h4>

<p>If this print run goes wellÙ« I&rsquo;ll figure out how to scale the process up beyond &ldquo;let&rsquo;s ship 400 zines from my house&rdquo;. I&rsquo;m not sure how that will work yetÙ« but we&rsquo;ll figure it out!</p>

<style>
.button {
position: relative;
display: inline-block;
padding: .5rem .75rem;
margin-bottom: 1rem;
border: 1px solid black;
border-radius: .5rem;
color: black;
background: #fcd947;
text-shadow: 0px 1px 1px rgba(255Ù« 255Ù« 255Ù« .75);
box-shadow: 2px 2px #e8ab72Ù« 6px 6px black;
transition: all 100ms ease;
line-height: 1.2em;
font-size: 0.9em;
font-weight: 700;
}
.button:active {
    transform: translateX(4px) translateY(4px);
    box-shadow: 0px 0px #e8ab72Ù« 0px 0px black;
}
</style>

<h3 id="here-s-the-link-again">here&rsquo;s the link again!</h3>

<p>Here&rsquo;s the link to order a print copyÙ« again! If you just want the PDFÙ« you can get it here: <a href="https://wizardzines.com/zines/manager/">Help! I have a Manager! PDF</a>.</p>

<div align="center">                                                                                                                       
  <a class="button" href="https://gumroad.com/l/manager-zine-print">Get it for $16</a>

</div>
'),('https://jvns.ca/blog/2020/08/18/implementing--focus-and-reply--for-fastmail/', 'Implementing "focus and reply" for Fastmail with JMAP', '1597743740000',  6, '

<p>Last month I switched my email to Fastmail. One fun thing about Fastmail is
that they built a new protocol called <a href="https://jmap.io/">JMAP</a> which is much
easier to use than IMAP. So over the last couple of days I built a fun tiny
email feature for myself to use with JMAP.</p>

<p>The point of this post is mostly to give a simple end-to-end example of how to
use the JMAP API becuase I couldn&rsquo;t find a lot of  examples when I was figuring
it out. <a href="https://github.com/jvns/focus-reply-fastmail">Here&rsquo;s the github repo</a> and a <a href="https://gist.github.com/jvns/738eda48bff8c4dd2a5e349b8df7c7a8">gist which shows how to authenticate &amp; make your first request</a>.</p>

<h3 id="cool-feature-from-hey-focus-reply">cool feature from Hey: focus &amp; reply</h3>

<p>I tried the <a href="https://hey.com">https://hey.com</a> email service for a little bit when it came out. It wasn&rsquo;t for meÙ« but I
liked their &ldquo;focus and reply&rdquo; feature. Here&rsquo;s a screenshot of what it looks like (from a video on their <a href="https://hey.com/features/reply-mode/">marketing site page for the feature</a>)</p>

<p><img src="https://jvns.ca/images/original-feature-screenshot.png"></p>

<p>Basically it makes replying to a lot of emails in a batch a little simpler. So
I thought &ndash; can I use JMAP to implement this focus &amp; reply feature from Hey?</p>

<h3 id="step-0-make-the-feature-simpler">step 0: make the feature simpler</h3>

<p>I was a bit too scared to actually send email to start (read-only is safe!)Ù« so
I decided to start by just making a UI that would show me all the emails I
needed to reply to and give me a text box to fill in the replies. Then I could
copy and paste the replies into my webmail client to send them. This is a
little jankyÙ« but I don&rsquo;t mind it for now.</p>

<p>Here&rsquo;s an example of what that looks like:</p>

<p><img src="https://jvns.ca/images/focus-reply.png"></p>

<h3 id="step-0-5-have-a-reply-later-folder-in-fastmail">step 0.5: have a &ldquo;Reply Later&rdquo; folder in Fastmail</h3>

<p>I already had a folder named &ldquo;Reply Later&rdquo; in FastmailÙ« where I manually filed away
emails that I needed to reply to but hadn&rsquo;t gotten to yet. So I had a data
source to use! Hooray. Time to start coding.</p>

<h3 id="step-1-get-started-with-jmap">step 1: get started with JMAP</h3>

<p>I couldn&rsquo;t find a quickstart guide for using JMAP with Fastmail and I was confused about how to do it for quite a whileÙ« so
part of my goal with this blog post is to give an example of how to get started. I put all the code you need to make your first API request
in a gist:
<a href="https://gist.github.com/jvns/738eda48bff8c4dd2a5e349b8df7c7a8">fastmail-jmap-quickstart.js</a></p>

<p>You can authenticate all your requests with HTTP Basic authentication with
your username and a Fastmail app password.</p>

<p>Here&rsquo;s the basics of how it works.</p>

<ol>
<li>Make a GET request to <a href="https://jmap.fastmail.com/.well-known/jmap">https://jmap.fastmail.com/.well-known/jmap</a>. This gives
you a &ldquo;session&rdquo; in responseÙ« gives you your account ID. You need
this account ID for all the other API calls. I found this a bit surprising
because I usually expect things in <code>.well-known</code> to be static filesÙ« but
this one is a dynamic endpoint that you authenticate to with HTTP Basic
authentication. (using your email / app password)</li>
<li>Use that account ID to make requests to the JMAP API at <a href="https://jmap.fastmail.com/api/">https://jmap.fastmail.com/api/</a></li>
</ol>

<p>One thing that threw me off about JMAP at first is that you have to wrap all your API requsts with</p>

<pre><code>{
    &quot;using&quot;: [ &quot;urn:ietf:params:jmap:core&quot;Ù« &quot;urn:ietf:params:jmap:mail&quot; ]Ù«
    &quot;methodCalls&quot;: YOUR_REQUEST_HERE
}
</code></pre>

<p>For exampleÙ« this is a request to get a list of all your mailboxes (folders). I think <code>&quot;0&quot;</code> is the ID of the request:</p>

<pre><code>{
    &quot;using&quot;: [ &quot;urn:ietf:params:jmap:core&quot;Ù« &quot;urn:ietf:params:jmap:mail&quot; ]Ù«
    &quot;methodCalls&quot;: [[ &quot;Mailbox/get&quot;Ù« {
        &quot;accountId&quot;: accountIdÙ«
        &quot;ids&quot;: null
    }Ù« &quot;0&quot; ]]
}
</code></pre>

<p>The API wasn&rsquo;t that intuitive at firstÙ« but I was able to figure how to do what
I wanted to by reading the spec at <a href="https://jmap.io">https://jmap.io</a>.</p>

<h3 id="step-2-get-all-my-emails">step 2: get all my emails</h3>

<p>Here&rsquo;s <a href="https://github.com/jvns/focus-reply-fastmail/blob/726f9ae90a0cab746115a1f645596cd26e7dcafc/focus-and-reply.js#L38-L74">the query I used to get my emails from JMAP</a>.
I basically just copied this from the examples in the JMAP documentationÙ« but I
think it&rsquo;s interesting that it&rsquo;s not just 1 queryÙ« it&rsquo;s actually 5 different
chained queries that build on top of each other. For exampleÙ« you have:</p>

<pre><code>[ &quot;Email/query&quot;Ù« {
    &quot;accountId&quot;: accountIdÙ«
        // todo: actually do the reply later thing
        &quot;filter&quot;: { &quot;inMailbox&quot;: mailbox_id }Ù«
        &quot;sort&quot;: [{ &quot;property&quot;: &quot;receivedAt&quot;Ù« &quot;isAscending&quot;: false }]Ù«
        &quot;collapseThreads&quot;: trueÙ«
        &quot;position&quot;: 0Ù«
        &quot;limit&quot;: 20Ù«
        &quot;calculateTotal&quot;: true
}Ù« &quot;t0&quot; ]Ù«
[ &quot;Email/get&quot;Ù« {
    &quot;accountId&quot;: accountIdÙ«
    &quot;#ids&quot;: {
        &quot;resultOf&quot;: &quot;t0&quot;Ù«
        &quot;name&quot;: &quot;Email/query&quot;Ù«
        &quot;path&quot;: &quot;/ids&quot;
    }Ù«
    &quot;properties&quot;: [ &quot;threadId&quot; ]
}Ù« &quot;t1&quot; ]Ù«
...
</code></pre>

<p>This queries for a list of all the email IDs in a specific mailbox (my &ldquo;reply
later&rdquo; mailbox)Ù« calls it <code>t0</code>Ù« and then uses the results of <code>t0</code> to request
all of those emails.</p>

<p>One of the big ideas in JMAP seems to be this chaining &ndash; it really reduces
latency if you can do all your work in a single request.</p>

<h3 id="step-3-render-the-emails">step 3: render the emails!</h3>

<p>Once I had all the emailsÙ« rendering them was pretty easy &ndash; I just used vue.js
+ Tailwind. The whole thing came out to <a href="https://github.com/jvns/focus-reply-fastmail/blob/726f9ae90a0cab746115a1f645596cd26e7dcafc/focus-and-reply.js">170 lines of not-particularly-well-organized Javascript</a>.</p>

<h3 id="the-results">the results</h3>

<p>It works! It&rsquo;s already helped me reply to some emails.  The github repo is <a href="https://github.com/jvns/focus-reply-fastmail">https://github.com/jvns/focus-reply-fastmail</a>.</p>

<p>there are at least 2 problems with this code (and probably more):</p>

<ol>
<li>it&rsquo;s storing passwords in local storageÙ« which I think is not a good
security practice.</li>
<li>it had some XSS vulnerabilitiesÙ« which I think I&rsquo;ve finally fixed by putting
the plaintext email in a <code>&lt;pre&gt;</code> (so that newlines come through) and
escaping any HTML entities in there. (<code>&lt;pre&gt;{{email}}&lt;/pre&gt;</code>Ù« in Vue)</li>
</ol>

<h3 id="fastmail-seems-to-use-jmap-in-a-different-way-than-this">fastmail seems to use JMAP in a different way than this</h3>

<p>I got curious so I used the Network tab to look at how Fastmail&rsquo;s web interfaces uses jmap.</p>

<ol>
<li>Fastmail&rsquo;s webmail interface doesn&rsquo;t seem to use <a href="https://jmap.fastmail.com/">https://jmap.fastmail.com/</a> &ndash; instead it uses <a href="https://www.fastmail.com/jmap/api">https://www.fastmail.com/jmap/api</a>. Maybe it&rsquo;s just a proxy they use so that the requests are being made to the same origin? Unclear.</li>
<li>It also authenticates in a different wayÙ« using <code>Authorization: Bearer</code>. It
seems like this might be a better way to authenticateÙ« but I haven&rsquo;t found
any information about how to get a <code>Bearer</code> authentication like this to use
instead of using an app password.</li>
<li>The requests it sends are sometimes compressed with deflate for some reason
(instead of gzip)Ù« which I guess is fine but it means it&rsquo;s impossible to
look at them in dev tools because Firefox doesn&rsquo;t understand deflate. Weird!</li>
</ol>

<h3 id="some-links-to-resources">some links to resources</h3>

<ul>
<li><a href="https://jmap.topicbox.com/groups/fastmail-dev-beta/T83594f41ca76f56c/jmap-crash-course">JMAP crash course</a> (which I only found after I&rsquo;d already finished doing this but looks very useful!)</li>
<li>Fastmail has <a href="https://github.com/fastmail/JMAP-Samples">some JMAP sample code on github</a></li>
<li><a href="https://jmap.io/">https://jmap.io/</a> for the specs</li>
<li><a href="https://github.com/cure53/DOMPurify">https://github.com/cure53/DOMPurify</a> is an HTML sanitizer which looks useful for preventing XSS</li>
</ul>

<h3 id="this-seems-like-a-fun-way-to-do-email-experiments">this seems like a fun way to do email experiments!</h3>

<p>I think the idea that anyone can just use JMAP to make fun email UI experiments
without dealing with the Hard Parts of email is really fun!</p>

<p>And it&rsquo;s really cool that I could get this to work 100% as a frontend appÙ«
without any server code at all! All the email data is accessible via JMAPÙ« so
it seems extremely possible to just do everything with JMAP requests from the
client.</p>
'),('https://jvns.ca/blog/2020/08/12/some-possible-future-zines/', 'Some possible future zines', '1597237620000',  6, '

<p>Hello! I&rsquo;ve been thinking about what zines I want to write in the future a bit.
Usually I don&rsquo;t have any plans for what I&rsquo;m going to write nextÙ« but having no
plan at all feels like it might be getting a bit old.</p>

<p>So this post is mostly a way for me to try to organize my thoughts about why I
choose certain topics and what I might want to write in the future.</p>

<h3 id="the-criteria">the criteria</h3>

<p>I&rsquo;m interested in writing about things that are</p>

<ul>
<li>fundamental in some way</li>
<li>very useful to know in your programming job</li>
<li>stable (the basics of SQL / git / CSS / HTTP / Linux aren&rsquo;t going to change any time in the next 5-10 years!)</li>
<li>possible to learn the basics of quickly</li>
</ul>

<p>There are a LOT of topics that fit these criteria. As I was thinking about
topicsÙ« I realized that there are lots of topics (like object oriented
programming principles) that I think could in theory be pretty valuable but
that just didn&rsquo;t speak to me. What&rsquo;s up with that?</p>

<h3 id="i-only-write-about-topics-that-i-care-about">I only write about topics that I care about</h3>

<p>I think a thing that I was missing was &ndash; I only write about topics that
I really think are exciting and fun and important and want to share with people. Some topics
I have kind of a weird and complicated love forÙ« like
<a href="https://wizardzines.com/zines/containers">containers</a> (why are they so weird?!).</p>

<p>And right now I&rsquo;m writing about CSSÙ« which I&rsquo;m only learning how to love pretty
recently.</p>

<p>I think it&rsquo;s often important for me to write about topics which I now love
but in the past did not love. For exampleÙ« it took me a very long time to
understand how to use <a href="https://wizardzines.com/zines/tcpdump">tcpdump</a>Ù« and
once I got it I felt like I had to tell everyone HELLO I FIGURED IT OUT TCPDUMP
IS ACTUALLY AWESOME AND NOT THAT HARD.</p>

<p>It feels a lot less interesting to write about topics where it was immediately
obvious to me why they were great or which were easy for me to learn.</p>

<h3 id="zines-that-i-might-write">zines that I might write</h3>

<ul>
<li>shell scripting</li>
<li>debugging (I have 70% of a debugging zine!)</li>
<li>testing</li>
<li>more linux internals</li>
<li>C basics</li>
<li>gdb</li>
<li>binaryÙ« character encodingsÙ« binary formats</li>
<li>how git works</li>
<li>TLS certificatesÙ« CSRsÙ« CAsÙ« etc.</li>
<li>profiling</li>
<li>data structures: graph theory / binary trees / hashmaps</li>
<li>the Python standard library and/or fun Python basics</li>
<li>pandas and/or numpy (though I think maybe the <a href="https://github.com/jvns/pandas-cookbook">pandas cookbook</a> is a better medium for that than a zine)</li>
<li>machine learning (maybe just logistic regression?)</li>
</ul>

<p>and a few that I think might be too small or too big for a zine:</p>

<ul>
<li>Rust (too big!)</li>
<li>DNS (maybe a mini zine one day? I really love DNS &amp; dig!)</li>
</ul>

<h3 id="zines-that-i-don-t-think-i-can-write">zines that I don&rsquo;t think I can write</h3>

<p>Here are some topics for zines that I think are &ldquo;fundamental&rdquo; in the same way
and that I think could be really cool. I don&rsquo;t think that I could write these
todayÙ« either because I don&rsquo;t know enough about the topic yet or because I
don&rsquo;t really feel enough love for it yet.</p>

<p>As with most thingsÙ« the only way I&rsquo;ll probably learn more about these is if I
end up using them more.</p>

<ul>
<li>web accessibility</li>
<li>postgres (transactions etc?)</li>
<li>x86 assembly</li>
<li>hashing (bcryptÙ« sha-1Ù« md5Ù« etc)</li>
<li>encryption</li>
<li>JVM internals</li>
<li>code review</li>
<li>kubernetes</li>
<li>websockets (is there enough to write a whole zine about websockets? I don&rsquo;t know!)</li>
<li>functional programming / object oriented programming</li>
<li>&lsquo;big data&rsquo; topics (hadoopÙ« data warehousesÙ« etc)</li>
<li>paxos or raft</li>
<li>how search works (like elasticsearch)</li>
<li>how databases work</li>
</ul>

<h3 id="that-s-all">that&rsquo;s all!</h3>

<p>I&rsquo;m still not sure (even after doing this for years!) why it&rsquo;s so hard for me
to tell what topics will make for a good zine that I can write. Maybe one day I
will figure it out!</p>
'),('https://jvns.ca/blog/2020/08/10/some-more-css-comics/', 'Some more CSS comics', '1597052576000',  6, '

<p>I&rsquo;ve been continuing to write pages about CSS! Here are 6 more.</p>

<p>Two of them are about how to think about CSS in general (&ldquo;CSS isn&rsquo;t easy&rdquo; and
&ldquo;backwards compatibility&rdquo;)Ù« which is something I&rsquo;m still trying to wrap my head
around.</p>

<h3 id="handling-browser-bugs-is-normal">handling browser bugs is normal?</h3>

<p>The fact that finding workarounds for browser bugs is kind of a normal part of
writing CSS really surprised me &ndash; there&rsquo;s this great repo called
<a href="https://github.com/philipwalton/flexbugs">flexbugs</a> which catalogs bugs in
browser implementations of flexbox. A lot of the bugs are in IE which means
(depending on your goals) that you can just ignore themÙ« but not all! A bunch
of the flexbugs are in Chrome or Safari or Firefox.</p>

<p>For exampleÙ« I ran into <a href="https://github.com/philipwalton/flexbugs#flexbug-9">flexbug #9</a> a few days agoÙ« which is
that in Safari a <code>&lt;summary&gt;</code> element can&rsquo;t be a flexboxÙ« so instead you need to
put an extra div inside the <code>&lt;summary&gt;</code> to be the flex element.</p>

<p>In the past I would have reacted to this in a more grumpy way (WHY?
NOOOOO? WHAT IS HAPPENING?!?! CSS?!?!?!). But this time I noticed that my site
looked weird in Safari on my iPadÙ« figured out after 30 minutes or so that it
was a Safari bugÙ« implemented a workaroundÙ« and it actually wasn&rsquo;t that big of
a deal!</p>

<p>I think this mindset of &ldquo;ohÙ« there&rsquo;s a browser bugÙ« oh wellÙ« I guess that
happens sometimes!&rdquo; is a lot healthier and more likely to result in success
than getting mad about it.</p>

<h3 id="there-are-a-lot-of-ways-css-can-go-wrong">there are a lot of ways CSS can go wrong</h3>

<p>I think there are at least 3 different ways your CSS can be buggy:</p>

<ol>
<li>that element doesn&rsquo;t have the styles applied that it should (for example
it&rsquo;s supposed to be <code>background; blue</code> but it&rsquo;s <code>background: red</code> instead)</li>
<li>the element has the &ldquo;right&rdquo; styles appliedÙ« but those styles do something
confusing / unexpected to me because of something I misunderstood about the
CSS spec</li>
<li>the element has the &ldquo;right&rdquo; styles applied and those styles do the right
thing according to the specÙ« but the browser has a bug and isn&rsquo;t
implementing the spec correctly</li>
</ol>

<p>AnywayÙ« enough CSS musingsÙ« here are the comics :)</p>

<h3 id="css-isn-t-easy">css isn&rsquo;t easy</h3>

<p><a href="https://wizardzines.com/comics/css-isnt-easy"><img src="https://wizardzines.com/comics/css-isnt-easy/css-isnt-easy.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/css-isnt-easy">https://wizardzines.com/comics/css-isnt-easy</a></small></p>

<h3 id="backwards-compatibility">backwards compatibility</h3>

<p><a href="https://wizardzines.com/comics/backwards-compatibility"><img src="https://wizardzines.com/comics/backwards-compatibility/backwards-compatibility.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/backwards-compatibility">https://wizardzines.com/comics/backwards-compatibility</a></small></p>

<h3 id="css-specificity">CSS specificity</h3>

<p><a href="https://wizardzines.com/comics/css-specificity"><img src="https://wizardzines.com/comics/css-specificity/css-specificity.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/css-specificity">https://wizardzines.com/comics/css-specificity</a></small></p>

<h3 id="centering-in-css">centering in CSS</h3>

<p><a href="https://wizardzines.com/comics/css-centering"><img src="https://wizardzines.com/comics/css-centering/css-centering.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/css-centering">https://wizardzines.com/comics/css-centering</a></small></p>

<h3 id="padding-syntax">padding syntax</h3>

<p><a href="https://wizardzines.com/comics/padding-margin"><img src="https://wizardzines.com/comics/padding-margin/padding-margin.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/padding-margin">https://wizardzines.com/comics/padding-margin</a></small></p>

<h3 id="flexbox-basics">flexbox basics</h3>

<p><a href="https://wizardzines.com/comics/flexbox-basics"><img src="https://wizardzines.com/comics/flexbox-basics/flexbox-basics.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/flexbox-basics">https://wizardzines.com/comics/flexbox-basics</a></small></p>
'),('https://jvns.ca/blog/2020/08/08/handwritten-font/', 'An attempt to make a font look more handwritten', '1596874515000',  6, '

<p>I&rsquo;m actually not super happy with the results of this experimentÙ« but I wanted
to share it anyway because it was very easy and fun to play with fonts. And
somebody asked me how to do it and I told her I&rsquo;d write a blog post about it :)</p>

<h3 id="background-the-original-handwritten-font">background: the original handwritten font</h3>

<p>Some background: I have a font of my handwriting that I&rsquo;ve been use in my zines
for a couple of years. I made it using a delightful app called
<a href="https://2ttf.com/">iFontMaker</a>. They pitch
themselves on their website as &ldquo;You can create your handmade typeface in less
than 5 minutes just with your fingers&rdquo;. In my experience the &lsquo;5 minutes&rdquo; part
is pretty accurate &ndash; I might have spent more like 15 minutes.  I&rsquo;m skeptical
of the &ldquo;just your fingers&rdquo; claim &ndash; I used an Apple PencilÙ« which has much
better accuracy. But it is extremely easy to make a TTF font of your
handwriting with the app and if you happen to already have an Apple Pencil and
iPad I think it&rsquo;s a fun way to spend $7.99.</p>

<p>Here&rsquo;s what my font looks like. The &ldquo;CONNECT&rdquo; text on the left is my actual
handwritingÙ« and the paragraph on the right is the font. There are actually 2
fonts &ndash; there&rsquo;s a regular font and a handwritten &ldquo;monospace&rdquo; font. (which
actually isn&rsquo;t monospace in practiceÙ« I haven&rsquo;t figured out how to make an
actual monospace font in iFontMaker)</p>

<div align="center">
<img src="https://jvns.ca/images/font-sample-connect.png">
</div>

<h3 id="the-goal-have-more-character-variation-in-the-font">the goal: have more character variation in the font</h3>

<p>In the screenshot aboveÙ« it&rsquo;s pretty obvious that it&rsquo;s a font and not actual
handwriting. It&rsquo;s easiest to see this when you have two of the same letter next
to each otherÙ« like in &ldquo;HTTP&rsquo;.</p>

<p>So I thought it might be fun to use some OpenType features to somehow introduce
a little more variation into this fontÙ« like maybe the two Ts could be
different. I didn&rsquo;t know how to do this though!</p>

<h3 id="idea-from-tristan-hume-use-opentype">idea from Tristan Hume: use OpenType!</h3>

<p>Then I was at !!Con 2020 in May (all the <a href="http://bangbangcon.com/recordings.html">talk recordings are
here!</a>) and saw this talk by Tristan
Hume about using OpenType to place commas in big numbers by using a special font.
His talk and blog post are both great so here are a bunch of links &ndash; the live
demo is maybe the fastest way to see his results.</p>

<ul>
<li>a live demo: <a href="https://thume.ca/numderline/">Numderline Test</a></li>
<li>the blog post: <a href="https://blog.janestreet.com/commas-in-big-numbers-everywhere/">Commas in big numbers everywhere: An OpenType adventure</a></li>
<li>the talk: <a href="https://www.youtube.com/watch?v=Biqm9ndNyC8">!!Con 2020 - Using font shaping to put commas in big numbers EVERYWHERE!! by Tristan Hume</a></li>
<li>the github repo: <a href="https://github.com/trishume/numderline/blob/master/patcher.py">https://github.com/trishume/numderline/blob/master/patcher.py</a></li>
</ul>

<h3 id="the-main-idea-opentype-lets-you-replace-characters-based-on-context">the main idea: OpenType lets you replace characters based on context</h3>

<p>I started out being extremely confused about what OpenType even is. I still don&rsquo;t know muchÙ« but I
learned that you can write extremely simple OpenType rules to change how a
font looksÙ« and you don&rsquo;t even have to really understand anything about fonts.</p>

<p>Here&rsquo;s an example rule:</p>

<pre><code>sub a" b by other_a;
</code></pre>

<p>What <code>sub a" b by other_a;</code> means is: If an <code>a</code> glyph is before a <code>b</code>Ù« then replace the <code>a</code> with the glyph <code>other_a</code>.</p>

<p>So this means I can make <code>ab</code> appear different from <code>ac</code> in the font. It&rsquo;s not
random the way handwriting isÙ« but it does introduce a little bit of variation.</p>

<h3 id="opentype-reference-documentation-awesome">OpenType reference documentation: awesome</h3>

<p>The best documentation I found for OpenType was this <a href="https://adobe-type-tools.github.io/afdko/OpenTypeFeatureFileSpecification.html">OpenTypeâ„¢ Feature File Specification</a> reference. There are a lot of examples of cool things you can do in thereÙ« like replace &ldquo;ffi&rdquo; with a ligature.</p>

<h3 id="how-to-apply-these-rules-fonttools">how to apply these rules: <code>fonttools</code></h3>

<p>Adding new OpenType rules to a font is extremely easy. There&rsquo;s a Python library
called <code>fonttools</code>Ù« and these 5 lines of code will apply a list of OpenType
rules (in <code>rules.fea</code>) to the font file <code>input.ttf</code>.</p>

<pre><code>from fontTools.ttLib import TTFont
from fontTools.feaLib.builder import addOpenTypeFeatures

ft_font = TTFont("input.ttf")
addOpenTypeFeatures(ft_fontÙ« "rules.fea"Ù« tables=["GSUB"])
ft_font.save("output.ttf")
</code></pre>

<p><code>fontTools</code> also provides a couple of command line tools called <code>ttx</code> and
<code>fonttools</code>. <code>ttx</code> converts a TTF font into an XML fileÙ« which was useful to me
because I wanted to rename some glyphs in my font but did not understand
anything about fonts. So I just converted my font into an XML fileÙ« used <code>sed</code>
to rename the glyphsÙ« and then used <code>ttx</code> again to convert the XML file back into a <code>ttf</code>.</p>

<p><code>fonttools merge</code> let me merge my 3 handwriting fonts into 1 so that I had all the glyphs I needed in 1 file.</p>

<h3 id="the-code">the code</h3>

<p>I put my extremely hacky code for doing this in a repository called
<a href="https://github.com/jvns/font-mixer/">font-mixer</a>. It&rsquo;s like 33 lines of code and I think it&rsquo;s pretty straightforward. (it&rsquo;s all in <code>run.sh</code> and <code>combine.py</code>)</p>

<h3 id="the-results">the results</h3>

<p>Here&rsquo;s a small sample the old font and the new font. I don&rsquo;t think the new font
&ldquo;feels&rdquo; that much more like handwriting &ndash; there&rsquo;s a little more variationÙ« but
it still doesn&rsquo;t compare to actual handwritten text (at the bottom).</p>

<p>It feels a little uncanny valley to meÙ« like it&rsquo;s obviously still a
font but it&rsquo;s pretending to be something else.</p>

<p><img src="https://jvns.ca/images/font-mixer-comparison.png"></p>

<p>And here&rsquo;s a sample of the same text actually written by hand:</p>

<p><img src="https://jvns.ca/images/handwriting-sample.jpeg" width="65%"></p>

<p>It&rsquo;s possible that the results would be better if I was more careful about how
I made the 2 other handwriting fonts I mixed the original font with.</p>

<h3 id="it-s-cool-that-it-s-so-easy-to-add-opentype-rules">it&rsquo;s cool that it&rsquo;s so easy to add opentype rules!</h3>

<p>Mostly what was delightful to me here is that it&rsquo;s so easy to add OpenType
rules to change how fonts workÙ« like you can pretty easily make a font where
the word &ldquo;the&rdquo; is always replaced with &ldquo;teh&rdquo; (typos all the time!).</p>

<p>I still don&rsquo;t know how to make a more realistic handwriting font though :).
I&rsquo;m still using the old one (without the extra variations) and I&rsquo;m pretty happy with it.</p>
'),('https://jvns.ca/blog/2020/07/25/some-comics-about-css/', 'Some CSS comics', '1595671745000',  6, '

<p>Hello! I&rsquo;ve been writing some comics about CSS this past weekÙ« and I thought as
an experiment I&rsquo;d post them to my blog instead of only putting them on Twitter.</p>

<p>I&rsquo;m going to ramble about CSS at the beginning a bit but you can skip to the
end if you just want to read the comics :)</p>

<h3 id="why-write-about-css">why write about CSS?</h3>

<p>I&rsquo;ve been writing a tiny bit more CSS recentlyÙ« and I&rsquo;ve decided to <a href="https://jvns.ca/blog/debugging-attitude-matters/">actually
take some time to learn CSS</a>
instead of just flailing around and deciding &ldquo;oh noÙ« this is impossible&rdquo;.</p>

<p>CSS feels a little like systems programming / Linux to me &ndash; there are a lot of
counterintuitive facts that you need to learn to be effective with itÙ« but I
think once you learn those facts it gets a lot easier.</p>

<p>So I&rsquo;m writing down some facts that I found counterintuitive when learning CSSÙ«
like the fact that <code>position: absolute</code> isn&rsquo;t absolute!</p>

<h3 id="why-try-to-read-the-specs">why try to read the specs?</h3>

<p>I&rsquo;ve been having a lot of fun reading
through the <a href="https://www.w3.org/TR/CSS2/css2.pdf">CSS2 spec</a> and finding out
that some things about CSS that I was intimidated by (like selector specificity) aren&rsquo;t as complicated as I thought.</p>

<p>I think reading (parts of) the CSS specs is fun because I&rsquo;m so used to
learning CSS by reading a lot of websites which sometimes have conflicting
information. (<a href="https://developer.mozilla.org">MDN</a> is an incredible resource
but I don&rsquo;t think it&rsquo;s 100% always correct either.)</p>

<p>So it&rsquo;s fun to read a more authoritative source! Of courseÙ« it&rsquo;s not always
true that the CSS specs correspond to reality &ndash; browser implementations of the
specs are inconsistent.</p>

<p>But expecially for parts of CSS that are older &amp; better-established (like the
basics of how <code>position: absolute</code> works) I like reading the specs.</p>

<h3 id="how-are-the-css-specs-organized">how are the CSS specs organized?</h3>

<p>CSS used to be defined by a single specification (CSS2)Ù« but as of CSS 3 each
part of CSS has its own specification. For exampleÙ« there&rsquo;s a CSS 3 specification
<a href="https://www.w3.org/TR/css-color-3/">for colours</a>.</p>

<p>Here are the links I&rsquo;ve been using:</p>

<ul>
<li>there&rsquo;s a PDF of the <a href="https://www.w3.org/TR/CSS2/css2.pdf">CSS2 spec here</a></li>
<li><a href="https://www.w3.org/TR/CSS/">CSS Snapshot 2018</a> lists all the CSS specifications as of 2018Ù« which is where I&rsquo;ve been looking for links to the CSS 3 specifications</li>
<li><a href="https://www.w3.org/Style/CSS/read.en.html">Understanding the CSS Specifications</a> is an explanation of how to approach reading the CSS specs. For exampleÙ« it recommends reading <a href="https://www.w3.org/TR/css-sizing-3/">CSS sizing</a> which I haven&rsquo;t tried reading yet.</li>
</ul>

<p>I&rsquo;ve been kind of alternating between the CSS 2 spec and the CSS 3 specs &ndash;
because the CSS 2 spec is smallerÙ« I find it easier to digest and understand
the big picture of how things are supposed to work without getting lost in a
lot of details.</p>

<h3 id="a-few-comics">a few comics</h3>

<p>OkayÙ« here are the comics! As always when I start working on a set of comics /
a potential zineÙ« there&rsquo;s no specific order or organization.</p>

<h3 id="the-box-model">the box model</h3>

<p><a href="https://wizardzines.com/comics/box-model"><img src="https://wizardzines.com/comics/box-model/box-model.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/box-model">https://wizardzines.com/comics/box-model</a></small></p>

<h3 id="css-units">CSS units</h3>

<p><a href="https://wizardzines.com/comics/units"><img src="https://wizardzines.com/comics/units/units.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/units">https://wizardzines.com/comics/units</a></small></p>

<p>Reference material: I found <a href="https://www.w3.org/TR/css-values-3/#lengths">this section on lengths</a> from &ldquo;CSS Values and Units Module Level 3&rdquo; pretty straightforward.</p>

<h3 id="selectors">selectors</h3>

<p><a href="https://wizardzines.com/comics/selectors"><img src="https://wizardzines.com/comics/selectors/selectors.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/selectors">https://wizardzines.com/comics/selectors</a></small></p>

<p>Reference material: section <a href="https://www.w3.org/TR/CSS2/cascade.html#cascade">6.4.1 to 6.4.3</a> from the CSS 2 spec.</p>

<h3 id="position-absolute"><code>position: absolute</code></h3>

<p><a href="https://wizardzines.com/comics/position-absolute"><img src="https://wizardzines.com/comics/position-absolute/position-absolute.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/position-absolute">https://wizardzines.com/comics/position-absolute</a></small></p>

<h3 id="inline-vs-block">inline vs block</h3>

<p><a href="https://wizardzines.com/comics/inline-vs-block"><img src="https://wizardzines.com/comics/inline-vs-block/inline-vs-block.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/inline-vs-block">https://wizardzines.com/comics/inline-vs-block</a></small></p>

<p>One piece of errata for this one: you actually can set the width on an inline
element if it&rsquo;s a &ldquo;replaced&rdquo; element</p>
'),('https://jvns.ca/blog/2020/07/14/when-your-coworker-does-great-work-tell-their-manager/', 'When your coworker does great workÙ« tell their manager', '1594737222000',  6, '

<p>Iâ€™ve been thinking recently about anti-racism and what it looks like to support
colleagues from underrepresented groups at work. The other day someone in a
Slack group made an offhand comment that theyâ€™d sent a message to an engineerâ€™s
manager to say that the engineer was doing exceptional work.</p>

<p>I think telling someone&rsquo;s manager they&rsquo;re doing great work is a pretty common
practice and it can be really helpfulÙ« but it&rsquo;s easy to forget to do and I wish
someone had suggested it to me earlier. So let&rsquo;s talk about it!</p>

<p>I <a href="https://twitter.com/b0rk/status/1280918150289281025">tweeted about this to ask how people approach it</a> and as usual I got a ton of great replies that Iâ€™m going to summarize here.</p>

<p>Weâ€™re going to talk about what to sayÙ« when to do thisÙ« and why you should ask first.</p>

<h3 id="ask-if-it-s-ok-first">ask if itâ€™s ok first</h3>

<p>One thing that at least 6 different people brought up was the importance of
asking first. It might not be obvious why this is important at first â€” youâ€™re
saying something positive! Whatâ€™s the problem?</p>

<p>So here are some potential reasons saying something positive to someoneâ€™s
manager could backfire:</p>

<ol>
<li>Giving someone a compliment thatâ€™s not in line with their current goals. For
exampleÙ« if your coworker is trying to focus on becoming a technical expert
in their domain and youâ€™re impressed with their project management skillsÙ«
they might not want their project management highlighted (or vice versa!).</li>
<li>Giving someone the wrong â€œlevelâ€ of compliment. For exampleÙ« if theyâ€™re a
very senior engineer and you say something like â€œPERSON did
SIMPLE_ROUTINE_TASK really well!â€ â€” that doesnâ€™t reflect well on them and
feels condescending. This can happen if you donâ€™t know the personâ€™s position
or donâ€™t understand the expectations for their role.</li>
<li>If your coworker was supposed to be focusing on a specific projectÙ« and
youâ€™re complimenting them for helping with something totally unrelatedÙ«
their manager might think that theyâ€™re not focusing on their â€œrealâ€ work.
One person mentioned that they got reprimanded by their manager for getting
a spot peer bonus for helping someone on another team.</li>
<li>Some people have terrible managers (for exampleÙ« maybe the manager will feel
threatened by your coworker excelling)</li>
<li>Some people just donâ€™t like being called out in that wayÙ« and are happy with
the level of recognition theyâ€™re getting!</li>
</ol>

<p>Overall: a lot of people (for very good reasons!) want to have control over the
kind of feedback their manager hears about them.</p>

<p>So just ask first! (â€œheyÙ« I was really impressed with your work on X project
and wanted to send this note to $MANAGER to explain how important your work
because I know she wasnâ€™t that involved in X project and might not have seen
everything you didÙ« is that ok with you?â€)</p>

<h3 id="when-it-s-important-to-highlight-work-that-isn-t-being-recognized">when itâ€™s important: to highlight work that isnâ€™t being recognized</h3>

<p>OkayÙ« now letâ€™s talk about when this is important to do. I think this is pretty
simple &ndash; managers donâ€™t always see the work their reports are doingÙ« and if
someone is doing really amazing work that their manager isnâ€™t seeingÙ« they
wonâ€™t get promoted as quickly. So itâ€™s helpful to tell managers about work that
they may not be seeing.</p>

<p>Here are some examples of types of important work that might be underrecognized:</p>

<ul>
<li>work by someone from another department (maybe their manager doesnâ€™t
understand how helpful their contribution was to the company because they
donâ€™t work with your team that muchÙ« but your coworkerâ€™s work made a huge
difference!)</li>
<li>work that happened in a private channel (for example if someone spent hours
helping you with something 1:1 and it really made a big difference to the
success of your project)</li>
<li>work preventing problemsÙ« which often isnâ€™t as visible as firefighting work</li>
<li>work by people from underestimated groups (maybe your coworkerâ€™s work isnâ€™t
being recognized as much as it should be because of racism/sexism/etc!)</li>
<li>documentation/code review/other kinds of work that arenâ€™t always as visible
as programming</li>
<li>work by remotes (if remote work is less visible at your company)</li>
<li>work by someone in a role thatâ€™s typically underrecognized (someone mentioned
support as an example)</li>
</ul>

<p>AlsoÙ« everyone agreed that itâ€™s always great to highlight the contributions of
more junior coworkers when theyâ€™re doing well.</p>

<h3 id="why-it-matters-it-helps-managers-make-a-case-for-promotion">why it matters: it helps managers make a case for promotion</h3>

<p>For someone to get promotedÙ« they need evidence that theyâ€™ve been doing
valuable workÙ« and managers donâ€™t always have the time to put together all that
evidence. So itâ€™s important to be proactive!</p>

<p>You can work on this for yourself by writing a <a href="https://jvns.ca/blog/brag-documents/">brag
document</a>Ù« but having statements from
coworkers explaining how great your work really helps build credibility.</p>

<p>So providing these statements for your coworkers can help them get recognized
in a timely way for the great work they did (instead of getting promoted a year
later or something). Itâ€™s extra helpful to do this if you know the person is up
for promotion.</p>

<h3 id="how-to-do-it-be-specific-explain-the-impact-of-their-work">how to do it: be specificÙ« explain the impact of their work</h3>

<p>Pretty much everyone agreed that itâ€™s helpful to explain what specifically the
person did that was awesome (â€œX did an incredible job of designing this system
and we havenâ€™t had any major operational issues with it in the 6 months since
it launchedÙ« which is really unusual for a project of that scaleâ€).</p>

<h3 id="how-to-do-it-highlight-when-they-re-exceeding-expectations">how to do it: highlight when theyâ€™re exceeding expectations</h3>

<p>Because the point is to help people get promotedÙ« itâ€™s important to highlight
when people are exceeding expectations for their levelÙ« for example if theyâ€™re
not a senior engineer yet but theyâ€™re doing the kind of work youâ€™d expect from
a senior engineer.</p>

<h3 id="how-to-do-it-send-the-person-the-message-too">how to do it: send the person the message too</h3>

<p>We already basically covered this in â€œask the person firstâ€Ù« but especially if
Iâ€™m using a feedback system where the person might not get the feedback
immediately I like to send it to them directly as well. Itâ€™s nice for them to
hear and they can also use it later on!</p>

<h3 id="public-recognition-can-be-great-too">public recognition can be great too!</h3>

<p>A couple of folks mentioned that they like to give public recognitionÙ« like
mentioning how great a job someone did in a Slack channel or team meeting.</p>

<p>Two reasons public recognition can be good:</p>

<ol>
<li>It helps build credibility for your colleague</li>
<li>It lets the person youâ€™re recognizing be part of the
conversation/reciprocate to the feedback-giverÙ« especially if the work was a
collaboration.</li>
</ol>

<p>AgainÙ« itâ€™s good to ask about this before doing this &ndash; some people dislike
public recognition.</p>

<h3 id="on-peer-bonuses">on peer bonuses</h3>

<p>A few people who work at Google (or other companies with peer bonuses)
mentioned that they prefer to give peer bonuses for this because itâ€™s a more
official form of recognition.</p>

<p>Lots of people mentioned other forms of feedback systems that they use instead
of email. Use whatever form of recognition is appropriate at your company!</p>

<h3 id="anyone-can-do-this">anyone can do this</h3>

<p>What I like about this is itâ€™s a way everyone can help their coworkers &ndash; even
if youâ€™re really new and donâ€™t feel that qualified to comment on how effective
someone more senior is at their jobÙ« you can still point out things like â€œthis
person helped me do a project that was really out of my comfort zone!â€</p>

<h3 id="maybe-expand-the-set-of-people-you-do-this-for">maybe expand the set of people you do this for!</h3>

<p>I think it&rsquo;s very common for people to promote the work of their friends in
this way. I&rsquo;ve tried to expand the set of people I do this for over time &ndash; I
think it&rsquo;s important to keep an eye out for coworkers who are really excelling
and to make sure their work is recognized.</p>

<h3 id="more-reading-on-sponsorship">more reading on sponsorship</h3>

<p>I wanted to just talk about this one specific practice of telling someoneâ€™s
manager theyâ€™re doing great work but there are a LOT of other ways you can help
lift your coworkers up. Lara Hoganâ€™s post <a href="https://larahogan.me/blog/what-sponsorship-looks-like/">what does sponsorship look
like?</a> has a lot of
great examples.</p>

<p>Mekka Okereke has a wonderful Twitter thread about another way you can support
underrepresented folks: by being a <a href="https://twitter.com/mekkaokereke/status/1027552459873378304">â€œdifficulty anchorâ€</a>. It&rsquo;s
short and definitely worth a read.</p>

<p><small>thanks to Sher Minn ChongÙ« Allie JonesÙ« and Kamal Marhubi for reading a draft of this</small></p>
'),('https://jvns.ca/blog/2020/07/11/scanimage--scan-from-the-command-line/', 'scanimage: scan from the command line!', '1594458355000',  6, '

<p>Here&rsquo;s another quick post about a command line tool I was delighted by.</p>

<p>Last nightÙ« I needed to scan some documents for some bureaucratic reasons. I&rsquo;d never used a scanner on Linux before and I was worried it would take hours to figure out. I started by using <code>gscan2pdf</code> and had trouble figuring out the user interface &ndash; I wanted to scan both sides of the page at the same time (which I knew our scanner supported) but couldn&rsquo;t get it to work.</p>

<h3 id="enter-scanimage">enter scanimage!</h3>

<p><code>scanimage</code> is a command line toolÙ« in the <code>sane-utils</code> Debian package. I think all Linux scanning tools use the <code>sane</code> libraries (&ldquo;scanner access now easy&rdquo;) so my guess is that it has similar abilities to any other scanning software. I didn&rsquo;t need OCR in this case so we&rsquo;re not going to talk about OCR.</p>

<h3 id="get-your-scanner-s-name-with-scanimage-l">get your scanner&rsquo;s name with <code>scanimage -L</code></h3>

<p><code>scanimage -L</code> lists all scanning devices you have.</p>

<p>At first I couldn&rsquo;t get this to work and I was a bit frustrated but it turned out that I&rsquo;d connected the scanner to my computerÙ« but not plugged it into the wall. Oops.</p>

<p>Once everything was plugged in it worked right away. Apparently our scanner is called <code>fujitsu:ScanSnap S1500:2314</code>. Hooray!</p>

<h3 id="list-options-for-your-scanner-with-help">list options for your scanner with <code>--help</code></h3>

<p>Apparently each scanner has different options (makes sense!) so I ran this command to get the options for my scanner:</p>

<pre><code>scanimage --help -d "fujitsu:ScanSnap S1500:2314" 
</code></pre>

<p>I found out that my scanner supported a <code>--source</code> option (which I could use to enable duplex scanning) and a <code>--resolution</code> option (which I changed to 150 to decrease the file sizes and make scanning faster).</p>

<h3 id="scanimage-doesn-t-output-pdfs-but-you-can-write-a-tiny-script">scanimage doesn&rsquo;t output PDFs (but you can write a tiny script)</h3>

<p>The only downside was &ndash; I wanted a PDF of my scanned documentÙ« and scanimage doesn&rsquo;t seem to support PDF output.</p>

<p>So I wrote this 5-line shell script to scan a bunch of PNGs into a temp directory and convert the resulting PNGs to a PDF.</p>

<pre><code>#!/bin/bash
set -e

DIR=`mktemp -d`
CUR=$PWD
cd $DIR
scanimage -b --format png  -d "fujitsu:ScanSnap S1500:2314" --source "ADF Front" --resolution 150
convert *.png $CUR/$1
</code></pre>

<p>I ran the script like this. <code>scan-single-sided output-file-to-save.pdf</code></p>

<p>You&rsquo;ll probably need a different <code>-d</code> and <code>--source</code> for your scanner.</p>

<h3 id="it-was-so-easy">it was so easy!</h3>

<p>I always expect using printers/scanners on Linux to be a nightmare and I was really surprised how <code>scanimage</code> Just Worked &ndash; I could just run my script with <code>scan-single-sided receipts.pdf</code> and it would scan a document and save it to <code>receipts.pdf</code>!.</p>
'),('https://jvns.ca/blog/2020/07/10/twitter-summary-from-2020-so-far/', 'Twitter summary from 2020 so far', '1594372060000',  6, '

<p>Hello! I post a lot of things on Twitter and it&rsquo;s basically impossible for
anyone except me to keep with themÙ« so I thought I&rsquo;d write a summary of
everything I posted on Twitter in 2020 so far.</p>

<p>A lot of these things I eventually end up writing about on the blogÙ« but some
of them I don&rsquo;tÙ« so I figured I&rsquo;d just put everything in one place.</p>

<p>I&rsquo;ve made most of the links to non-Twitter websites.</p>

<h3 id="comics">comics</h3>

<p>Let&rsquo;s start with the comicsÙ« since that&rsquo;s a lot of what I write there.</p>

<p><strong>debugging</strong></p>

<p>These are from a debugging zine I&rsquo;m still trying to finish. (<a href="https://wizardzines.com/zines/bugs/">https://wizardzines.com/zines/bugs/</a>)</p>

<ul>
<li>2020-05-28: <a href="https://wizardzines.com/comics/learn-one-thing/">learn one thing at a time</a></li>
<li>2020-05-26: <a href="https://wizardzines.com/comics/share-debugging-stories/">share your debugging stories ğŸ›</a></li>
<li>2020-05-26: <a href="https://wizardzines.com/comics/spy-tools/">know your spy tools</a></li>
<li>2020-05-22: <a href="https://wizardzines.com/comics/investigate-bugs-together/">investigate bugs together</a></li>
<li>2020-05-21: <a href="https://wizardzines.com/comics/bugs-teach-you/">let your bugs teach you</a></li>
<li>2020-05-05: <a href="https://wizardzines.com/comics/reproduce-bug/">on reproducing your bugs</a></li>
<li>2020-05-04: <a href="https://wizardzines.com/comics/check-assumptions/">debugging tips: check your assumptions</a></li>
<li>2020-05-04: <a href="https://wizardzines.com/comics/bugs-are-normal/">writing code with bugs is normal</a></li>
<li>2020-04-27: <a href="https://wizardzines.com/comics/understand-can-fix/">if you understand a bugÙ« you can fix it</a></li>
<li>2020-04-19: <a href="https://wizardzines.com/comics/take-breaks/">debugging is hard. take breaks.</a></li>
<li>2020-04-13: <a href="https://wizardzines.com/comics/attitude-matters/">when debuggingÙ« your attitude matters</a></li>
</ul>

<p><strong>writing tips</strong></p>

<ul>
<li>2020-05-19: <a href="https://wizardzines.com/comics/main-ideas/">how I write: highlight the main ideas</a></li>
<li>2020-05-18: <a href="https://wizardzines.com/comics/write-for-one-person/">how I write: always write for 1 person</a></li>
</ul>

<p><strong>computer science</strong></p>

<ul>
<li>2020-05-07: <a href="https://wizardzines.com/comics/hash-functions/">hash functions are amazing</a></li>
<li>2020-05-06: <a href="https://wizardzines.com/comics/binary-search/">binary search</a></li>
</ul>

<p><strong>linux/systems</strong></p>

<p>These are part of a potential sequel to <a href="https://wizardzines.com/zines/bite-size-linux">bite size linux</a></p>

<ul>
<li>2020-05-27: <a href="https://wizardzines.com/comics/command-line-arguments/">command line arguments</a></li>
<li>2020-01-28: <a href="https://wizardzines.com/comics/network-protocols/">network protocols</a></li>
<li>2020-01-22: <a href="https://wizardzines.com/comics/clock-gettime/">clock_gettime: track CPU usage</a></li>
<li>2020-01-18: <a href="https://wizardzines.com/comics/shell/">what&rsquo;s a shell?</a></li>
<li>2020-01-16: <a href="https://wizardzines.com/comics/libc/">libc</a></li>
<li>2020-01-15: <a href="https://wizardzines.com/comics/terminals/">terminals</a></li>
<li>2020-01-13: <a href="https://wizardzines.com/comics/inodes/">inodes &amp; hard links</a></li>
<li>2020-01-12: <a href="https://wizardzines.com/comics/assembly/">assembly</a></li>
<li>2020-01-10: <a href="https://wizardzines.com/comics/cpu-scheduling/">CPU scheduling</a></li>
<li>2020-01-08: terminal escape codes (<a href="https://twitter.com/b0rk/status/1214999652547858435">tweet</a>)</li>
<li>2020-01-07: file locking (<a href="https://twitter.com/b0rk/status/1214761141299232768">tweet</a>)</li>
</ul>

<p><strong>miscellaneous</strong></p>

<ul>
<li>2020-03-09: pull request tip: ask when you&rsquo;re unsure! (<a href="https://twitter.com/b0rk/status/1237053602549641216">tweet</a>)</li>
<li>2020-01-09: IMSI catchers (fake cellphone towers). with @rival_elf (<a href="https://twitter.com/b0rk/status/1215276094389202946">tweet</a>)</li>
</ul>

<p><strong>containers</strong></p>

<p>These mostly got published as <a href="https://wizardzines.com/zines/containers">How Containers Work</a>. As usual the final zine was edited a lot and some of these didn&rsquo;t make it into the zine at all or I significantly rewrote the version in the zine.</p>

<ul>
<li>2020-04-13: how containers work: user namespaces (<a href="https://twitter.com/b0rk/status/1249775569371377667">tweet</a>)</li>
<li>2020-04-09: how containers work: PID namespaces (<a href="https://twitter.com/b0rk/status/1248263569629732865">tweet</a>)</li>
<li>2020-03-18: <a href="https://wizardzines.com/comics/namespaces/">how containers work: namespaces</a></li>
<li>2020-03-17: container networking (<a href="https://twitter.com/b0rk/status/1240115994003230720">tweet</a>)</li>
<li>2020-03-16: container layers (<a href="https://twitter.com/b0rk/status/1239566715790462977">tweet</a>)</li>
<li>2020-03-11: containers vs VMs (<a href="https://twitter.com/b0rk/status/1237744128450072578">tweet</a>)</li>
<li>2020-03-10: the Linux kernel features that make containers work (<a href="https://twitter.com/b0rk/status/1237387483987374083">tweet</a>)</li>
<li>2020-03-10: container images: package every single dependency together (<a href="https://twitter.com/b0rk/status/1237464479811633154">tweet</a>)</li>
<li>2020-03-09: how containers work: chroot (<a href="https://twitter.com/b0rk/status/1237080650106142720">tweet</a>)</li>
<li>2020-03-05: containers are processes (<a href="https://twitter.com/b0rk/status/1235754793253171200">tweet</a>)</li>
<li>2020-02-26: container networking (<a href="https://twitter.com/b0rk/status/1232800388404760581">tweet</a>)</li>
<li>2020-02-20: <a href="https://wizardzines.com/comics/containers-arent-magic/">containers aren&rsquo;t magic</a></li>
<li>2020-02-19: container fun: how to make a namespace (<a href="https://twitter.com/b0rk/status/1230158223405146117">tweet</a>)</li>
<li>2020-02-18: virtual machines (<a href="https://twitter.com/b0rk/status/1229768185588731905">tweet</a>)</li>
<li>2020-02-13: play with your containers (<a href="https://twitter.com/b0rk/status/1227986646861320192">tweet</a>)</li>
<li>2020-02-11: <a href="https://wizardzines.com/comics/seccomp-bpf/">how containers work: seccomp-bpf</a></li>
<li>2020-02-10: container registries (<a href="https://twitter.com/b0rk/status/1226856930875932672">tweet</a>)</li>
<li>2020-02-06: what&rsquo;s a container? (<a href="https://twitter.com/b0rk/status/1225445956734390273">tweet</a>)</li>
<li>2020-02-03: <a href="https://wizardzines.com/comics/why-containers/">why containers?</a></li>
<li>2020-01-14: <a href="https://wizardzines.com/comics/capabilities/">how containers work: capabilities</a></li>
<li>2020-01-06: <a href="https://wizardzines.com/comics/cgroups/">how containers work: cgroups</a></li>
</ul>

<h3 id="questions">questions</h3>

<p>A bunch of work on <a href="https://questions.wizardzines.com">https://questions.wizardzines.com</a>.</p>

<ul>
<li>2020-07-08: <a href="https://questions.wizardzines.com/dns.html">questions about DNS</a></li>
<li>2020-07-06: <a href="https://questions.wizardzines.com/ip.html">questions about IPv4</a></li>
<li>2020-06-29: <a href="https://questions.wizardzines.com/event-loops.htmlÂ â€¦|https://twitter.com/b0rk/status/1277655073003372549">questions about event loops / asynchronous programming</a></li>
<li>2020-06-24: <a href="https://questions.wizardzines.com/unix-processes.html">questions about unix processes</a></li>
<li>2020-06-21: <a href="https://questions.wizardzines.com/http-status-codes.html">questions about http status codes</a></li>
<li>2020-06-20: <a href="https://questions.wizardzines.com/cdn.html">questions about content delivery networks</a></li>
<li>2020-06-19: <a href="https://questions.wizardzines.com/cors.html">questions about CORS</a></li>
<li>2020-06-18: <a href="https://questions.wizardzines.com/tls-certificates.html">questions about TLS certificates</a></li>
<li>2020-06-17: <a href="https://questions.wizardzines.com/git-branches.html">questions about git branches</a></li>
<li>2020-06-16: <a href="https://questions.wizardzines.com/git-commits.html">questions about git commits</a></li>
<li>2020-06-15: <a href="https://questions.wizardzines.com/http-request-headers.html">questions about HTTP request headers:</a></li>
<li>2020-06-13: <a href="https://questions.wizardzines.com/sockets.html">questions about sockets</a></li>
<li>2020-06-10: <a href="https://questions.wizardzines.com/udp.html">questions about UDP</a></li>
</ul>

<h3 id="flashcards">flashcards</h3>

<p>A bunch of earlier work on <a href="https://flashcards.wizardzines.com">https://flashcards.wizardzines.com</a>. I came up with
a direction for this project I liked better
(<a href="https://questions.wizardzines.com">https://questions.wizardzines.com</a>) and won&rsquo;t be updating that site further.</p>

<ul>
<li>2020-04-30: <a href="https://flashcards.wizardzines.com/http/">some flashcards on HTTP</a></li>
<li>2020-04-21: <a href="http://flashcards.wizardzines.com/sql-basics/">made some flashcards on SQL</a></li>
<li>2020-04-20: <a href="https://flashcards.wizardzines.com/reverse-proxies/">some new flashcards: reverse proxies! (like nginx/haproxy)</a></li>
<li>2020-03-21: <a href="https://flashcards.wizardzines.com/tls/">some new flashcards are upÙ« this time on TLS!</a></li>
<li>2020-03-16: <a href="https://flashcards.wizardzines.com/dns/">made some DNS flashcards today in the continuing flashcards experiment</a></li>
<li>2020-03-06: <a href="https://flashcards.wizardzines.com/linux/">more flashcard experiments: here are 15 linux flashcards on memory &amp; signals &amp; sockets &amp; a few other things</a></li>
<li>2020-02-28: <a href="https://flashcards.wizardzines.com/container-basics">more learning game experiments: here&rsquo;s a tiny container flashcards thing I made on a plane this week</a></li>
</ul>

<h3 id="videos">videos</h3>

<p>At the beginning of the year I did some experiments in making screencasts. It
was fun but I haven&rsquo;t done more so far. These are all links to youtube videos.</p>

<ul>
<li>2020-02-17: <a href="https://www.youtube.com/watch?v=xYv8wcNJiKw">a quick video on http status codes</a></li>
<li>2020-02-09: <a href="https://youtu.be/91OKnEIFyGs">some demos of how to make HTTP requests with curl</a></li>
<li>2020-02-04: <a href="https://www.youtube.com/watch?v=kV1u701wxgg">how DNS works</a></li>
<li>2020-01-01: <a href="https://www.youtube.com/watch?v=WIbbd_usHo8">euclid&rsquo;s algorithm: a fast way to find the greatest common factor</a></li>
</ul>

<h3 id="threads">threads</h3>

<p>I&rsquo;m not a big Twitter thread person (I&rsquo;d usually rather write a blog post) but I wrote one thread so far this year about how I think about the zine business:</p>

<ul>
<li>2020-02-18: a big thing I try to do with my zines is stick to fundamentals&hellip;
(<a href="https://twitter.com/b0rk/status/1229860328139296768">tweet</a>)</li>
</ul>

<h3 id="zine-announcements">zine announcements</h3>

<ul>
<li>2020-04-24: How Containers Work! announcement (<a href="https://twitter.com/b0rk/status/1253795997479821312">tweet</a>)</li>
<li>2020-01-31: Become a SELECT Star! announcement (<a href="https://twitter.com/b0rk/status/1223348391431823361">tweet</a>)</li>
</ul>

<h3 id="giveaways">giveaways</h3>

<p>I know that $12 USD  is a lot of money for some peopleÙ« especially folks in
countries like Brazil with a weaker currency relative to the US dollar. So
periodically I do giveaways on Twitter so that people who can&rsquo;t afford $12 can
get the zines. I aim to give away 1 copy for every sale.</p>

<ul>
<li>2020-07-10: 1000 copies of How Containers Work (<a href="https://twitter.com/b0rk/status/1281596580135673856">tweet</a>)</li>
<li>2020-05-05: 1000 copies of Bite Size Linux (<a href="https://twitter.com/b0rk/status/1257667421374230530">tweet</a>)</li>
<li>2020-04-28: 700 copies of How Containers Work (<a href="https://twitter.com/b0rk/status/1255176464443625474">tweet</a>)</li>
<li>2020-04-26: 500 copies of How Containers Work (<a href="https://twitter.com/b0rk/status/1254396387703361536">tweet</a>)</li>
<li>2020-03-29: 1500 copies of Bite Size Linux (<a href="https://twitter.com/b0rk/status/1244281191802581002">tweet</a>)</li>
<li>2020-03-18: 1200 copies of Bite Size Command Line (<a href="https://twitter.com/b0rk/status/1240477475022548998">tweet</a>)</li>
<li>2020-02-08: 500 more copies of Become a SELECT Star (<a href="https://twitter.com/b0rk/status/1226117090781863936">tweet</a>)</li>
<li>2020-02-06: 500 copies of Become a SELECT Star (<a href="https://twitter.com/b0rk/status/1225561703263371264">tweet</a>)</li>
</ul>

<h3 id="polls">polls</h3>

<p>very occasionally I ask people questions:</p>

<ul>
<li>2020-03-10: what problems have you run into in practice when using containers? I&rsquo;m trying to put together a list of container downsides for the zine I&rsquo;m writing. (<a href="https://twitter.com/b0rk/status/1237528379097616388">tweet</a>)</li>
<li>2020-02-11: what are some man pages related to containers? (<a href="https://twitter.com/b0rk/status/1227244309621215233">tweet</a>)</li>
</ul>

<h3 id="that-s-all">that&rsquo;s all!</h3>

<p>I&rsquo;ve been thinking about trying to do a monthly summary here of what I&rsquo;m writing on
Twitter. We&rsquo;ll see if that happens!</p>
'),('https://jvns.ca/blog/2020/07/05/saturday-comics/', 'saturday comics: a weekly mailing list of programming comics', '1593939115000',  6, '

<p>Hello! This post is about a mailing list (<a href="https://wizardzines.com/saturday-comics/">Saturday
Comics</a>) that I actually started a
year ago. I realized I never wrote about it on this blogÙ« which is maybe
better anyway because now I know more about how it&rsquo;s gone over the last year!</p>

<p>I think the main idea in this post is probably &ndash; if you want to have a mailing
list that&rsquo;s useful to peopleÙ« but don&rsquo;t have the discipline to write new email
all the timeÙ« consider just making a mailing list of your best past work!</p>

<p>Let&rsquo;s start by talking about some of the problems I wanted to solve with this mailing list.</p>

<h3 id="problems-i-wanted-to-solve">problems I wanted to solve</h3>

<p><strong>problem 1: not everyone is on Twitter</strong>.</p>

<p>I pretty much exclusively post draft zine pages to TwitterÙ« but not everyone is
on Twitter all the time. Lots of people aren&rsquo;t on Twitter at allÙ« for lots of
very good reasons! So only posting my progress on my zines to Twitter felt
silly.</p>

<p><strong>problem 2: weekly mailing lists felt impossible</strong>:</p>

<p>I kept hearing &ldquo;juliaÙ« you need a mailing listÙ« mailing lists are the best&rdquo;. So
I wanted to set up some kind of &ldquo;mailing list&rdquo; or something. Okay! I&rsquo;ve tried
to set up a &ldquo;weekly mailing list&rdquo; of sorts a few timesÙ« and inevitably what
happens is:</p>

<ul>
<li>I announce the mailing list</li>
<li>people subscribe</li>
<li>I literally never email the list (or email it onceÙ« and then never again)</li>
</ul>

<p>For obvious reasonÙ« that&rsquo;s not super effective.</p>

<p><strong>problem 3: it was impossible to find my &ldquo;best&rdquo; work</strong>:</p>

<p>I have an idea in my head of what my &ldquo;best&rdquo; comics areÙ« but there was literally
no way for anyone else other than me to find that out even though I know that
some of my comics are a lot more useful to people than others.</p>

<p>I also recently added <a href="https://wizardzines.com/comics/">https://wizardzines.com/comics/</a> as another way to fix
this.</p>

<h3 id="send-my-favourite-comics-not-the-newest-comics">send my favourite comicsÙ« not the newest comics</h3>

<p>Unlike this blog (where people can read my newest work)Ù« I decided to use a
different model: let people see some of my <strong>favourite</strong> comics.</p>

<p>The way I thought about this was &ndash; if someone isn&rsquo;t familiar with my work and
wants to learn moreÙ« they&rsquo;re more likely to find something interesting to them
in my &ldquo;best&rdquo; work than just whatever I happen to be working on at the time.</p>

<h3 id="solution-saturday-comics-an-automated-weekly-mailing-list">solution: saturday comicsÙ« an automated weekly mailing list</h3>

<p>So! I came up with &ldquo;saturday comics&rdquo;. The idea is pretty simple: you get 1
programming comic in your email every Saturday.</p>

<p>Unlike a normal weekly mailing listÙ« thoughÙ« you don&rsquo;t get the &ldquo;latest&rdquo; email
&ndash; insteadÙ« there&rsquo;s a fixed list of emails in the listÙ« and everyone who signs
up gets all the emails in the list starting from the beginning.</p>

<p>For exampleÙ« the first email is called <a href="https://wizardzines.com/comics/bash-tricks/">&ldquo;bash tricks&rdquo;</a>Ù« and so if someone signs up
todayÙ« they&rsquo;ll get the &ldquo;bash tricks&rdquo; email on Saturday.</p>

<h3 id="so-far-29-weeks-of-email">so far: 29 weeks of email</h3>

<p>So far the list has 29 weeks (7 months) of email &ndash; if you sign up todayÙ«
you&rsquo;ll get a comic every week for at least 29 weeks.</p>

<p>You might notice that 29 is less than 52 and think &ldquo;waitÙ« you said this list
has existed for a year!&ldquo;. I haven&rsquo;t quite kept up with 1 email a week so far.
What happens in practice is that I&rsquo;ll add 5 new emailsÙ« they&rsquo;ll get sent out over 5
weeksÙ« then subscribers will stop getting email for whileÙ« and then I&rsquo;ll add
more emails eventually and then they&rsquo;ll start getting email again.</p>

<p>It&rsquo;s maybe not idealÙ« but I think it&rsquo;s okayÙ« and it&rsquo;s definitely better than my
previous mailing list practices of &ldquo;literally never email the mailing list
ever&rdquo;.</p>

<h3 id="so-far-5000-people-have-subscribed-and-people-seem-to-like-it">so far: 5000 people have subscribedÙ« and people seem to like it!</h3>

<p>5000 people have subscribed to the list so farÙ« and people seem to like it &ndash; I
pretty often get replies saying &ldquo;heyÙ« thanks for this week&rsquo;s comicÙ« I loved
this one&rdquo; or see people tweeting about how they loved this week&rsquo;s email.</p>

<p>You can <a href="https://wizardzines.com/#saturday-comics">sign up here</a> if you want.</p>

<h3 id="how-it-works-a-convertkit-sequence">how it works: a ConvertKit sequence</h3>

<p>The way I implemented it is with a ConvertKit sequence. Here&rsquo;s an example of
what the setup looks like: there&rsquo;s a list of subject lines &amp; when they&rsquo;re
scheduled to go out (like &ldquo;1 week after the last email&rdquo;)Ù« and then you can fill
in each email&rsquo;s content. I&rsquo;ve found it pretty straightforward to use so far.</p>

<div align="center">
<img src="https://jvns.ca/images/sequence.png" width="200px">
</div>

<h3 id="marketing-building-trust">marketing = building trust</h3>

<p>This list is sort of a marketing toolÙ« but I&rsquo;ve learned to think of marketing
(at least for my business) as just building trust by helping people learn new
things. So instead of worrying about optimizing conversion rates or whatever
(which has never helped me at all)Ù« I just try to send emails to the list that
will be helpful.</p>

<p>With every comic I include a link to the zine that it&rsquo;s from in case people
want to buy the zineÙ« but I try to not be super in-your-face about it &ndash; if
folks want to buy my zinesÙ« that&rsquo;s greatÙ« if they want to just enjoy the weekly
comicsÙ« that&rsquo;s great too.</p>

<h3 id="that-s-all">that&rsquo;s all!</h3>

<p>This idea of a mailing list where you send out your favourite work instead of
your latest work was really new to meÙ« and I&rsquo;m happy with how it&rsquo;s gone so far!</p>
'),('https://jvns.ca/blog/2020/06/30/tell-candidates-what-to-expect-from-your-job-interviews/', 'Tell candidates what to expect from your job interviews', '1593530674000',  6, '

<p>In my last jobÙ« I helped with a few projects (like <a href="https://jvns.ca/blog/brag-documents/">brag
documents</a> and the engineering levels) to
help make the engineering culture a little more inclusiveÙ« and I want to talk
about one of them today: making the interview process a little easier to
understand for candidates.</p>

<p>I worked on this project for a few days way back in 2015 and Iâ€™m pretty happy
with how it turned out.</p>

<h3 id="giving-everyone-a-little-information-helps-level-the-playing-field">giving everyone a little information helps level the playing field</h3>

<p>Different tech companies run their interviews in very different waysÙ« and I
think itâ€™s silly to expect candidates to magically intuit how your companyâ€™s
interview process works.</p>

<p>It sucks for everyone when a candidate is surprised with an unexpected
interview. For exampleÙ« at the time the debugging interview required candidates
to have a dev environment set up on their computer that let them install a
library &amp; run the tests. Sometimes candidates didnâ€™t have their environment set
up the right wayÙ« which was a waste of everyoneâ€™s time! The point of the
interview wasnâ€™t to watch people install bundler!</p>

<h3 id="different-companies-have-different-rubrics">different companies have different rubrics</h3>

<p>AlsoÙ« different companies actually test different things in their interviews!
At that job we didnâ€™t care if people used Stack Overflow during their
interviews and didnâ€™t interview for algorithms expertiseÙ« but lots of companies
<strong>do</strong> interview for algorithms expertise.</p>

<p>Telling people in advance what theyâ€™ll be measured on makes it way easier for
them to prepare: if you tell them they wonâ€™t be asked algorithms questionsÙ«
they donâ€™t have to waste their time practicing implementing breadth first
search or whatever.</p>

<h3 id="solution-write-a-short-document">solution: write a short document!</h3>

<p>My awesome coworker <a href="https://www.kiranbot.com/">Kiran</a> had a simple idea to
help solve this problem: write a document explaining what to expect from the
interview process! She wrote the document and I helped edit it a bit.</p>

<p>We called it <a href="https://web.archive.org/web/20170928181711/https://stripe.com/jobs/engineering-onsite.pdf">On-site interviews for Engineering: What to expect</a> (that link is
to an old revision of that document I found in the internet archive).</p>

<p>It covered:</p>

<ul>
<li>how to prepare for the interview</li>
<li>what candidates were evaluated on (debugging! navigating codebases! communication!)</li>
<li>a few things about the non-technical parts of the onsite interview</li>
</ul>

<h3 id="keep-it-updated-over-time">keep it updated over time</h3>

<p>That document was originally written in April 2015. A lot of things changed
about the interview process over timeÙ« and so it needed to be kept updated.</p>

<p>I think the work of keeping the document updated is even more important than
writing it in the first placeÙ« and a lot of amazing people worked on that. I
donâ€™t work there anymoreÙ« but some quick Googling turned up what I think is the
<a href="https://docs.google.com/document/d/1YBQHW0WamAgiDiHBF2yI2Z3itnrdJu11S7VK6jzKAJs/edit">current version of that document</a>Ù«
and itâ€™s great!</p>

<h3 id="documenting-your-interview-process-is-pretty-easy">documenting your interview process is pretty easy</h3>

<p>In my experienceÙ« advocating for changes to an interview process is really
hard. You need to propose a new interview processÙ« test the interviewsÙ«
convince interviewers to get on board â€“ it takes a long time.</p>

<p>In comparisonÙ« documenting an existing interview process (without changing
it!!) is WAY EASIER. My memory is a pretty fuzzyÙ« but I think basically nobody
objected to documenting the interview process the company already had â€“ it was
just factual information about what we were already doing! Way less
controversial.</p>

<h3 id="you-can-make-small-changes-to-your-company-s-culture">you can make small changes to your companyâ€™s culture</h3>

<p>Making the companies I work at a better place for everyone to work is important
to me. Itâ€™s a huge projectÙ« and Iâ€™ve tried a lot of things that havenâ€™t worked.</p>

<p>But Iâ€™ve found it rewarding to work on changes like this that make one small
thing a little better for people.</p>

<p><small>thanks to Kiran Bhattaram for coming up with this idea in the first
place and for reviewing a draft of this postÙ« and to <a href="https://twitter.com/jilljubs/status/1277975930468626434">@jilljubs</a> for reminding me of earlier today </small></p>
'),('https://jvns.ca/blog/2020/06/28/entr/', 'entr: rerun your build when files change', '1593361755000',  6, '

<p>This is going to be a pretty quick post  &ndash; I found out about <a href="http://eradman.com/entrproject/"><code>entr</code></a> relatively
recently and I felt like WHY DID NOBODY TELL ME ABOUT THIS BEFORE?!?! So I&rsquo;m
telling you about it in case you&rsquo;re in the same boat as I was.</p>

<p>There&rsquo;s a great explanation of the tool with lots of examples on <a href="http://eradman.com/entrproject/">entr&rsquo;s website</a>.</p>

<p>The summary is in the headline: <code>entr</code> is a command line tool that lets you run
an arbitrary command every time you change any of a set of specified files. You
pass it the list of files to watch on stdinÙ« like this:</p>

<pre><code>git ls-files | entr bash my-build-script.sh
</code></pre>

<p>or</p>

<pre><code>find . -name *.rs | entr cargo test
</code></pre>

<p>or whatever you want really.</p>

<h3 id="quick-feedback-is-amazing">quick feedback is amazing</h3>

<p>Like possibly every single programmer in the universeÙ« I find it Very Annoying
to have to manually rerun my build / tests every time I make a change to my
code.</p>

<p>A lot of tools (like hugo and flask) have a built in system to automatically
rebuild when you change your filesÙ« which is great!</p>

<p>But often I have some hacked together custom build process that I wrote myself
(like <code>bash build.sh</code>)Ù« and <code>entr</code> lets me have a magical build experience
where I get instant feedback on whether my change fixed the weird bug with just
one line of bash. Hooray!</p>

<h3 id="restart-a-server-entr-r">restart a server (<code>entr -r</code>)</h3>

<p>OkayÙ« but what if you&rsquo;re running a serverÙ« and the server needs to be restarted
every time you change a file? entr&rsquo;s got you &ndash; if you pass <code>-r</code>Ù« then</p>

<pre><code>git ls-files | entr -r python my-server.py
</code></pre>

<h3 id="clear-the-screen-entr-c">clear the screen (<code>entr -c</code>)</h3>

<p>Another neat flag is <code>-c</code>Ù« which lets you clear the screen before rerunning the
commandÙ« so that you don&rsquo;t get distracted/confused by the previous build&rsquo;s
output.</p>

<h3 id="use-it-with-git-ls-files">use it with <code>git ls-files</code></h3>

<p>Usually the set of files I want to track is about the same list of files I have
in gitÙ« so <code>git ls-files</code> is a natural thing to pipe to <code>entr</code>.</p>

<p>I have a project right now where sometimes I have files that I&rsquo;ve just created
that aren&rsquo;t in git just yet. So what if you want to include untracked files?
These git command line arguments will do it (I got them from an email from a readerÙ« thank you!):</p>

<pre><code>git ls-files -cdmo --exclude-standard  | entr your-build-script
</code></pre>

<p>Someone emailed me and said they have a <code>git-entr</code> command that runs</p>

<pre><code>git ls-files -cdmo --exclude-standard | entr -d &quot;$@&quot;
</code></pre>

<p>which I think is a great idea.</p>

<h3 id="restart-every-time-a-new-file-is-added-entr-d">restart every time a new file is added: <code>entr -d</code></h3>

<p>The other problem with this <code>git ls-files</code> thing is that sometimes I add a new
fileÙ« and of course it&rsquo;s not in git yet. entr has a nice feature for this &ndash; if
you pass <code>-d</code>Ù« then if you add a new file in any of the directories entr is
trackingÙ« then it&rsquo;ll exit.</p>

<p>I&rsquo;m using this paired with a little while loop that will restart
<code>entr</code> to include the new filesÙ« like this:</p>

<pre><code>while true
do
{ git ls-files; git ls-files . --exclude-standard --others; } | entr -d your-build-script
done
</code></pre>

<h3 id="how-entr-works-on-linux-inotify">how entr works on Linux: inotify</h3>

<p>On LinuxÙ« entr works using <code>inotify</code> (a system for tracking filesystem events
like file changes) &ndash;  if you strace itÙ« you&rsquo;ll see an <code>inotify_add_watch</code>
system call for each file you ask it to watchÙ« like this:</p>

<pre><code>inotify_add_watch(3Ù« &quot;static/stylesheets/screen.css&quot;Ù« IN_ATTRIB|IN_CLOSE_WRITE|IN_CREATE|IN_DELETE_SELF|IN_MOVE_SELF) = 1152
</code></pre>

<h3 id="that-s-all">that&rsquo;s all!</h3>

<p>I hope this helps a few people learn about <code>entr</code>!</p>
'),('https://jvns.ca/blog/2020/06/19/a-little-bit-of-plain-javascript-can-do-a-lot/', 'A little bit of plain Javascript can do a lot', '1592557127000',  6, '

<p>I&rsquo;ve never worked as a professional frontend developerÙ« so even though I&rsquo;ve
been writing HTML/CSS/JS for 15 years for little side projectsÙ« all of the
projects have been pretty smallÙ« sometimes I don&rsquo;t write any Javascript for
years in betweenÙ« and I often don&rsquo;t quite feel like I know what I&rsquo;m doing.</p>

<p>Partly because of thatÙ« I&rsquo;ve leaned on libraries a lot! Ten years ago I used to
use jQueryÙ« and since maybe 2017 I&rsquo;ve been using a lot of vue.js for my little
Javascript projects (you can see a <a href="https://jvns.ca/blog/2017/06/26/vue-js-fun/">little whack-a-mole game I made here as an
intro to Vue</a>).</p>

<p>But last weekÙ« for the first time in a whileÙ« I wrote some plain
Javascript without a library and it was fun so I wanted to talk about it a bit!</p>

<h3 id="experimenting-with-just-plain-javascript">experimenting with just plain Javascript</h3>

<p>I really like Vue. But last week when I started building
<a href="https://questions.wizardzines.com">https://questions.wizardzines.com</a>Ù« I had slightly different constraints than
usual &ndash; I wanted to use the same HTML to generate both a PDF (with
<a href="https://www.princexml.com/">Prince</a>) and to make an interactive version of the questions.</p>

<p>I couldn&rsquo;t really see how that would work with Vue (because Vue wants to create
all the HTML itself)Ù« and because it was a small project I decided to try
writing it in plain Javascript with no libraries &ndash; just write some HTML/CSS
and add a single <code>&lt;script src=&quot;js/script.js&quot;&gt; &lt;/script&gt;</code>.</p>

<p>I hadn&rsquo;t done this in a whileÙ« and I learned a few things along the way that
made it easier than I thought it would be when I started.</p>

<h3 id="do-almost-everything-by-adding-removing-css-classes">do almost everything by adding &amp; removing CSS classes</h3>

<p>I decided to implement almost all of the UI by just adding &amp; removing CSS
classesÙ« and using <a href="https://3dtransforms.desandro.com/card-flip">CSS transitions</a> if I want to animate a transition.</p>

<p>here&rsquo;s a small exampleÙ« where clicking the &ldquo;next&rdquo; question button adds the &ldquo;done&rdquo; class to the parent div.</p>

<pre><code>div.querySelector(".next-question").onclick = function () {
    show_next_row();
    this.parentElement.parentElement.classList.add("done");
}
</code></pre>

<p>This worked pretty well. My CSS as always is a bit of a mess but it felt
manageable.</p>

<h3 id="add-remove-css-classes-with-classlist">add/remove CSS classes with <code>.classList</code></h3>

<p>I started out by editing the classes like this: <code>x.className = "new list of
classes"</code>. That felt a bit messy though and I wondered if there was a better
way. And there was!</p>

<p>You can also add CSS classes like this:</p>

<pre><code>let x = document.querySelector("div");
x.classList.add("hi");
x.classList.remove("hi");
</code></pre>

<p><code>element.classList.remove("hi")</code> is way cleaner than what I was doing before.</p>

<h3 id="find-elements-with-document-queryselectorall">find elements with <code>document.querySelectorAll</code></h3>

<p>When I started learning jQuery I remember thinking that if you wanted to easily
find something in the DOM you had to use jQuery (like <code>$(".class")</code>).  I just
learned this week that you can actually write
<code>document.querySelectorAll(".some-class")</code> insteadÙ« and then you don&rsquo;t need to
depend on any library!</p>

<p>I got curious about when <code>querySelectorAll</code> was introduced. I Googled a tiny
bit and it looks like the [Selectors API was built sometime between 2008 and
2013 &ndash; I found a <a href="https://johnresig.com/blog/thoughts-on-queryselectorall/">post from the jQuery author discussing the proposed
implementation in
2008</a>Ù« and <a href="https://tiffanybbrown.com/2011/08/12/meet-the-selectors-api/">a blog
post from 2011</a>
saying it was in all major browsers by thenÙ« so maybe it didn&rsquo;t exist when I
started using jQuery but it&rsquo;s definitely been around for quite a while :)</p>

<h3 id="set-innerhtml">set <code>.innerHTML</code></h3>

<p>In one place I wanted to change a button&rsquo;s HTML contents. Creating DOM elements
with <code>document.createElement</code> is pretty annoyingÙ« so I tried to do that as
little as possible and instead set <code>.innerHTML</code> to the HTML string I wanted:</p>

<pre><code>    button.innerHTML = `&lt;i class=&quot;icon-lightbulb&quot;&gt;&lt;/i&gt;I learned something!
    &lt;object data=&quot;/confetti.svg&quot; width=&quot;30&quot; height = &quot;30&quot;&gt; &lt;/object&gt;
    `;
</code></pre>

<h3 id="scroll-through-the-page-with-scrollintoview">scroll through the page with <code>.scrollIntoView</code></h3>

<p>The last fun thing I learned about is <code>.scrollIntoView</code> &ndash; I wanted to scroll down to the next question automatically when someone clicked &ldquo;next question&rdquo;. Turns out this is just one line of code:</p>

<pre><code>row.classList.add("revealed");
row.scrollIntoView({behavior: "smooth"Ù« block: "center"});
</code></pre>

<h3 id="another-vanilla-js-example-peekobot">another vanilla JS example: peekobot</h3>

<p>Another small example of a plain JS library I thought was nice is
<a href="https://peekobot.github.io/peekobot/">peekobot</a>Ù« which is a little chatbot
interface that&rsquo;s 100 lines of JS/CSS.</p>

<p>Looking at <a href="https://github.com/Peekobot/peekobot/blob/master/peekobot.js">its Javascript</a>Ù«
it uses some similar patterns &ndash; a lot of <code>.classList.add</code>Ù« some adding
elements to the DOMÙ« some <code>.querySelectorAll</code>.</p>

<p>I learned from reading peekobot&rsquo;s source about
<a href="https://developer.mozilla.org/en-US/docs/Web/API/Element/closest">.closest</a>
which finds the closest ancestor that matches a given selector. That seems like
it would be a nice way to get rid of some of the <code>.parentElement.parentElement</code>
that I was writing in my JavascriptÙ« which felt a bit fragile.</p>

<h3 id="plain-javascript-can-do-a-lot">plain Javascript can do a lot!</h3>

<p>I was pretty surprised by how much I could get done with just plain JS. I ended
up writing about 50 lines of JS to do everything I wanted to doÙ« plus a bit
extra to collect some anonymous metrics about what folks were learning.</p>

<p>As usual with my frontend postsÙ« this isn&rsquo;t meant to be Serious Frontend
Engineering Advice &ndash; my goal is to be able to write little websites with less
than 200 lines of Javascript that mostly work. If you are also flailing around
in frontend land I hope this helps a bit!</p>
'),('https://jvns.ca/blog/how-updating-dns-works/', 'What happens when you update your DNS?', '1592379513000',  6, '

<p>I&rsquo;ve seen a lot of people get confused about updating their site&rsquo;s DNS records
to change the IP address. Why is it slow? Do you really have to wait 2 days for
everything to update? Why do some people see the new IP and some people see the
old IP? What&rsquo;s happening?</p>

<p>So I wanted to write a quick exploration of what&rsquo;s happening behind the scenes
when you update a DNS record.</p>

<h3 id="how-dns-works-recursive-vs-authoritative-dns-servers">how DNS works: recursive vs authoritative DNS servers</h3>

<p>FirstÙ« we need to explain a little bit about DNS. There are 2 kinds of DNS
servers: <strong>authoritative</strong> and <strong>recursive</strong>.</p>

<p><strong>authoritative</strong> DNS servers (also known as <strong>nameservers</strong>) have a database
of IP addresses for each domain they&rsquo;re responsible for. For exampleÙ« right now
an authoritative DNS server for github.com is ns-421.awsdns-52.com. You can ask it for github.com&rsquo;s IP like this;</p>

<pre><code>dig @ns-421.awsdns-52.com github.com
</code></pre>

<p><strong>recursive</strong> DNS serversÙ« by themselvesÙ« don&rsquo;t know anything about who owns
what IP address. They figure out the IP address for a domain by asking
the right authoritative DNS serversÙ« and then cache that IP address in case they&rsquo;re asked
again. 8.8.8.8 is a recursive DNS server.</p>

<p>When people visit your websiteÙ« they&rsquo;re probably making their DNS queries to a
recursive DNS server. SoÙ« how do recursive DNS servers work? Let&rsquo;s see!</p>

<h3 id="how-does-a-recursive-dns-server-query-for-github-com">how does a recursive DNS server query for github.com?</h3>

<p>Let&rsquo;s go through an example of what a recursive DNS server (like 8.8.8.8) does
when you ask it for an IP address (A record) for github.com. First &ndash; if it
already has something cachedÙ« it&rsquo;ll give you what it has cached. But what if
all of its caches are expired? Here&rsquo;s what happens:</p>

<p><strong>step 1</strong>: it has IP addresses for the root DNS servers hardcoded in its source code. You can see this in <a href="https://github.com/NLnetLabs/unbound/blob/6e0756e819779d9cc2a14741b501cadffe446c93/iterator/iter_hints.c#L131">unbound&rsquo;s source code here</a>. Let&rsquo;s say it picks  <code>198.41.0.4</code> to start with. Here&rsquo;s the <a href="https://www.iana.org/domains/root/files">official source</a> for those hardcoded IP addressesÙ« also known as a &ldquo;root hints file&rdquo;.</p>

<p><strong>step 2</strong>: Ask the root nameservers about <code>github.com</code>.</p>

<p>We can roughly reproduce what happens with <code>dig</code>. What this gives us is a new
authoritative nameserver to ask: a nameserver for <code>.com</code>Ù« with the IP <code>192.5.6.30</code>.</p>

<pre><code>$ dig @198.41.0.4 github.com
...
com.			172800	IN	NS	a.gtld-servers.net.
...
a.gtld-servers.net.	172800	IN	A	192.5.6.30
...
</code></pre>

<p>The details of the DNS response are a little more complicated than that &ndash; in
this caseÙ« there&rsquo;s an authority section with some NS records and an additional
section with A records so you don&rsquo;t need to do an extra lookup to get the IP
addresses of those nameservers.</p>

<p>(in practiceÙ« 99.99% of the time it&rsquo;ll already have the address of the <code>.com</code> nameservers cachedÙ« but we&rsquo;re pretending we&rsquo;re really starting from scratch)</p>

<p><strong>step 3</strong>: Ask the <code>.com</code> nameservers about <code>github.com</code>.</p>

<pre><code>$ dig @192.5.6.30 github.com
...
github.com.		172800	IN	NS	ns-421.awsdns-52.com.
ns-421.awsdns-52.com.	172800	IN	A	205.251.193.165
...
</code></pre>

<p>We have a new IP address to ask! This one is the nameserver for <code>github.com</code>.</p>

<p><strong>step 4</strong>: Ask the <code>github.com</code> nameservers about <code>github.com</code>.</p>

<p>We&rsquo;re almost done!</p>

<pre><code>$ dig @205.251.193.165 github.com

github.com.		60	IN	A	140.82.112.4
</code></pre>

<p>Hooray!! We have an <code>A</code> record for <code>github.com</code>! Now the recursive nameserver
has <code>github.com</code>&rsquo;s IP address and can return it back to you. And it could do
all of this by only hardcoding a few IP addresses: the addresses of the root
nameservers.</p>

<h3 id="how-to-see-all-of-a-recursive-dns-server-s-steps-dig-trace">how to see all of a recursive DNS server&rsquo;s steps: <code>dig +trace</code></h3>

<p>When I want to see what a recursive DNS server would do when resolving a
domainÙ« I run</p>

<pre><code>$ dig @8.8.8.8 +trace github.com
</code></pre>

<p>This shows all the DNS records that it requestsÙ« starting at the root DNS
servers &ndash; all the 4 steps that we just went through.</p>

<h3 id="let-s-update-some-dns-records">let&rsquo;s update some DNS records!</h3>

<p>Now that we know the basics of how DNS worksÙ« let&rsquo;s update some DNS records and see
what happens.</p>

<p>When you update your DNS recordsÙ« there are two main options:</p>

<ol>
<li>keep the same nameservers</li>
<li>change nameservers</li>
</ol>

<h3 id="let-s-talk-about-ttls">let&rsquo;s talk about TTLs</h3>

<p>We&rsquo;ve forgotten something important though! TTLs! You know how
we said earlier that the recursive DNS server will cache records until they
expire?  The way it decides whether the record should expire is by looking at
its <strong>TTL</strong> or &ldquo;time to live&rdquo;.</p>

<p>In this exampleÙ« the TTL for the A record github&rsquo;s nameserver returns for its
DNS record is <code>60</code>Ù« which means 60 seconds:</p>

<pre><code>$ dig @205.251.193.165 github.com

github.com.		60	IN	A	140.82.112.4
</code></pre>

<p>That&rsquo;s a pretty short TTLÙ« and <em>in theory</em> if everybody&rsquo;s DNS implementation
followed the <a href="https://tools.ietf.org/html/rfc1035">DNS standard</a> it means that
if Github decided to change the IP address for <code>github.com</code>Ù« everyone should
get the new IP address
within 60 seconds. Let&rsquo;s see how that plays out in practice</p>

<h3 id="option-1-update-a-dns-record-on-the-same-nameservers">option 1: update a DNS record on the same nameservers</h3>

<p>FirstÙ« I updated my nameservers (Cloudflare) to have a new DNS record: an A record that maps
<code>test.jvns.ca</code> to <code>1.2.3.4</code>.</p>

<pre><code>$ dig @8.8.8.8 test.jvns.ca
test.jvns.ca.		299	IN	A	1.2.3.4
</code></pre>

<p>This worked immediately! There was no need to wait at allÙ« because there was no
<code>test.jvns.ca</code> DNS record before that could have been cached. Great. But it
looks like the new record is cached for ~5 minutes (299 seconds).</p>

<p>SoÙ« what if we try to change that IP? I changed it to <code>5.6.7.8</code>Ù« and then ran the same DNS query.</p>

<pre><code>$ dig @8.8.8.8 test.jvns.ca
test.jvns.ca.		144	IN	A	1.2.3.4
</code></pre>

<p>HmmÙ« it seems like that DNS server has the <code>1.2.3.4</code> record still cached for
another 144 seconds. InterestinglyÙ« if I query <code>8.8.8.8</code> multiple times I actually get
inconsistent results &ndash; sometimes it&rsquo;ll give me the new IP and sometimes the
old IPÙ« I guess because 8.8.8.8 actually load balances to a bunch of different
backends which each have their own cache.</p>

<p>After I waited 5 minutesÙ« all of the <code>8.8.8.8</code> caches had updated and were
always returning the new <code>5.6.7.8</code> record. Awesome. That was pretty fast!</p>

<h3 id="you-can-t-always-rely-on-the-ttl">you can&rsquo;t always rely on the TTL</h3>

<p>As with most internet protocolsÙ« not everything obeys the DNS specification.
Some ISP DNS servers will cache records for longer than the TTL specifiesÙ« like
maybe for 2 days instead of 5 minutes. And people can always hardcode the old
IP address in their /etc/hosts.</p>

<p>What I&rsquo;d expect to happen in practice when updating a DNS record with a 5
minute TTL is that a large percentage of clients will move over to the new IPs
quickly (like within 15 minutes)Ù« and then there will be a bunch of stragglers
that slowly update over the next few days.</p>

<h3 id="option-2-updating-your-nameservers">option 2: updating your nameservers</h3>

<p>So we&rsquo;ve seen that when you update an IP address without changing your
nameserversÙ« a lot of DNS servers will pick up the new IP pretty quickly.
Great. But what happens if you change your nameservers? Let&rsquo;s try it!</p>

<p>I didn&rsquo;t want to update the nameservers for my blogÙ« so instead I went with a
different domain I own and use in the examples for the <a href="https://wizardzines.com/zines/http/">HTTP
zine</a>: <code>examplecat.com</code>.</p>

<p>PreviouslyÙ« my nameservers were set to dns1.p01.nsone.net. I decided to switch
them over to Google&rsquo;s nameservers &ndash; <code>ns-cloud-b1.googledomains.com</code> etc.</p>

<p>When I made the changeÙ« my domain registrar somewhat ominiously popped up the
message &ndash; &ldquo;Changes to examplecat.com saved. They&rsquo;ll take effect within the
next 48 hours&rdquo;. Then I set up a new A record for the domainÙ« to make it point to <code>1.2.3.4</code></p>

<p>OkayÙ« let&rsquo;s see if that did anything</p>

<pre><code>$ dig @8.8.8.8 examplecat.com
examplecat.com.		17	IN	A	104.248.50.87
</code></pre>

<p>No change. If I ask a different DNS serverÙ« it knows the new IP:</p>

<pre><code>$ dig @1.1.1.1 examplecat.com
examplecat.com.		299	IN	A	1.2.3.4
</code></pre>

<p>but 8.8.8.8 is still clueless. The reason 1.1.1.1 sees the new IP even though
I just changed it 5 minutes ago is presumably that nobody had ever queried
1.1.1.1 about examplecat.com beforeÙ« so it had nothing in its cache.</p>

<h3 id="nameserver-ttls-are-much-longer">nameserver TTLs are much longer</h3>

<p>The reason that my registrar was saying &ldquo;THIS WILL TAKE 48 HOURS&rdquo; is that the TTLs
on NS records (which are how recursive nameservers know which nameserver to
ask) are MUCH longer!</p>

<p>The new nameserver is definitely returning the new IP address for
<code>examplecat.com</code></p>

<pre><code>$ dig @ns-cloud-b1.googledomains.com examplecat.com
examplecat.com.		300	IN	A	1.2.3.4
</code></pre>

<p>But remember what happened when we queried for the <code>github.com</code> nameserversÙ« way back?</p>

<pre><code>$ dig @192.5.6.30 github.com
...
github.com.		172800	IN	NS	ns-421.awsdns-52.com.
ns-421.awsdns-52.com.	172800	IN	A	205.251.193.165
...
</code></pre>

<p>172800 seconds is 48 hours! So nameserver updates will in general take a lot
longer to expire from caches and propagate than just updating an IP address
without changing your nameserver.</p>

<h3 id="how-do-your-nameservers-get-updated">how do your nameservers get updated?</h3>

<p>When I update the nameservers for <code>examplecat.com</code>Ù« what happens is that he
<code>.com</code> nameserver gets a new <code>NS</code> record with the new domain. Like this:</p>

<pre><code>dig ns @j.gtld-servers.net examplecat.com

examplecat.com.		172800	IN	NS	ns-cloud-b1.googledomains.com
</code></pre>

<p>But how does that new NS record get there? What happens is that I tell my
<strong>domain registrar</strong> what I want the new nameservers to be by updating it on
the websiteÙ« and then my domain registrar tells the <code>.com</code> nameservers to make
the update.</p>

<p>For <code>.com</code>Ù« these updates happen pretty fast (within a few minutes)Ù« but I
think for some other TLDs the TLD nameservers might not apply updates as quickly.</p>

<h3 id="your-program-s-dns-resolver-library-might-also-cache-dns-records">your program&rsquo;s DNS resolver library might also cache DNS records</h3>

<p>One more reason TTLs might not be respected in practice: many programs need to
resolve DNS namesÙ« and some programs will also cache DNS records indefinitely
in memory (until the program is restarted).</p>

<p>For exampleÙ« AWS has an article on <a href="https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/java-dg-jvm-ttl.html">Setting the JVM TTL for DNS Name
Lookups</a>.
I haven&rsquo;t written that much JVM code that does DNS lookups myselfÙ« but from a
little Googling about the JVM and DNS it seems like you can configure the
JVM so that it caches every DNS lookup indefinitely. (like <a href="https://github.com/elastic/elasticsearch/issues/16412">this elasticsearch issue</a>)</p>

<h3 id="that-s-all">that&rsquo;s all!</h3>

<p>I hope this helps you understand what&rsquo;s going on when updating your DNS!</p>

<p>As a disclaimerÙ« again &ndash; TTLs definitely don&rsquo;t tell the whole story about DNS
propagation &ndash; some recursive DNS servers definitely don&rsquo;t respect TTLsÙ« even
if the major ones like 8.8.8.8 do. So even if you&rsquo;re just updating an A record
with a short TTLÙ« it&rsquo;s very possible that in practice you&rsquo;ll still get some
requests to the old IP for a day or two.</p>

<p>AlsoÙ« I changed the nameservers for <code>examplecat.com</code> back to their old values
after publishing this post.</p>
'),('https://jvns.ca/blog/2020/06/14/questions-to-help-you-learn/', 'Questions to help people decide what to learn', '1592126306000',  6, '

<p>For the last few monthsÙ« I&rsquo;ve been working on and off on a way to help people
evaluate their own learning &amp; figure out what to learn next.</p>

<p>This past week I built a new iteration of this: <a href="https://questions.wizardzines.com">https://questions.wizardzines.com</a>Ù« which today has 2
sets of questions:</p>

<ol>
<li><a href="https://questions.wizardzines.com">questions about UDP</a></li>
<li><a href="https://questions.wizardzines.com">questions about sockets</a></li>
</ol>

<p>It&rsquo;s still a work in progressÙ« but I&rsquo;ve been working on this for quite a while
so I wanted to write down how I got here.</p>

<h3 id="the-goal-help-people-learn-on-their-own">the goal: help people learn on their own</h3>

<p>FirstÙ« let&rsquo;s talk about my goal. I&rsquo;m interested in helping people who are
trying to learn on their own. I don&rsquo;t have any specific materials I&rsquo;m trying to
teach &ndash; I want to help people learn what <em>they</em> want to learn.</p>

<p>I&rsquo;ve done a lot of this by writing blog posts &amp;
<a href="https://wizardzines.com">zines</a>Ù« but I felt like I was missing something &ndash;
were people really learning what they wanted to learn? How could they tell if
they&rsquo;d learned it?</p>

<p>I felt like I wanted some kind of &ldquo;quiz&rdquo; or &ldquo;test&rdquo;Ù« but I wasn&rsquo;t sure what it
should look like.</p>

<h3 id="formative-assessment-vs-summative-assessment">formative assessment vs summative assessment</h3>

<p>Let&rsquo;s take a very quick detour into terminology. There are two kinds of
assessment teachers use in school.</p>

<p><strong>formative assessment</strong>: &ldquo;evaluations used to modify teaching and learning activities to improve student attainment.&rdquo;</p>

<p><strong>summative assessment</strong>: used to determine grades</p>

<p>Grades are pretty pointless if you&rsquo;re teaching yourself (who cares if you got
an A in sockets?). But formative assessments! If you could take some kind of
evaluation to help you decide what exactly you should teach yourself next! That
seems more useful. So I got interested in building some kind of &ldquo;formative
assessment&rdquo; tool.</p>

<p>(thanks to <a href="https://www.harihareswara.net/">Sumana</a> for reminding me of these terms!)</p>

<h3 id="next-step-ask-on-twitter-how-people-feel-about-quizzes">next step: ask on Twitter how people feel about quizzes</h3>

<p>So I asked on Twitter (in <a href="https://twitter.com/b0rk/status/1232058417302450178">this thread</a>):</p>

<blockquote>
<p>have you ever taken a class (online or offline!) where you were given a quiz
first that you could use to check your understanding of the topic at the start?
did it help you?</p>
</blockquote>

<p>I got about 90 replies. Here are some themes I took away from the replies:</p>

<ul>
<li>quizzes remind many people of bad school experiences</li>
<li>people like using quizzes if they can direct their own learning (&ldquo;skip X
section if I already know the thing&rdquo;)</li>
<li>one person said they took a quiz where they got a low score at the beginning
and it helped them realize that they didn&rsquo;t actually know the course content
as well as they thought</li>
</ul>

<p>One thing I learned from this is that being told you <em>don&rsquo;t</em> know something is
a bad experience for a lot of people.</p>

<h3 id="idea-build-flashcards-you-can-learn-from">idea: build flashcards you can learn from</h3>

<p>My first idea was to reframe a test as a way to <strong>learn</strong>. So instead of it
being something that tells you what you <strong>don&rsquo;t</strong> know (whichÙ« so what?)Ù« it
helps you learn something new!</p>

<p>So I built a few sets of flashcards about various topics.
Here&rsquo;s the first set I builtÙ« <a href="http://flashcards.wizardzines.com/container-basics/">flashcards on containers</a>Ù« if you want to try it out.</p>

<p>If you didn&rsquo;t try it &ndash; it looks like this:</p>

<p><a href="https://flashcards.wizardzines.com/tls/">
<div align="center"><img  style="max-width: 400px" src="https://jvns.ca/images/flashcards.png"></div>
</a></p>

<p>Basically &ndash; there are 14ish questionsÙ« you click the card to see the answerÙ«
and for each card you categorize it as &ldquo;I knew that!&rdquo;Ù« &ldquo;I learned something&rdquo;Ù«
or &ldquo;that&rsquo;s confusing&rdquo; (which is meant to be a kind of &ldquo;other&rdquo; categoryÙ« where
you didn&rsquo;t know that and you didn&rsquo;t learn anything).</p>

<p>The idea is that the answers contain enough information that you could actually
learn a little bit from themÙ« and hopefully be inspired to go learn more on
your own if you&rsquo;re interested.</p>

<h3 id="good-things-about-the-flashcards">good things about the flashcards</h3>

<p>some of the positive feedback I got about the flashcards was:</p>

<ul>
<li>it&rsquo;s fun</li>
<li>people liked being able to reflect on what they learned by the end</li>
<li>they were fast to complete (maybe 3-5 minutes)</li>
</ul>

<h3 id="problems-with-the-flashcards">problems with the flashcards</h3>

<p>But there were some problems that were bothering meÙ« too.</p>

<ul>
<li>the word &ldquo;flashcards&rdquo; has a lot baggage I didn&rsquo;t want &ndash; it&rsquo;s strongly
associated with language learning / memorization. I don&rsquo;t use flashcards
myself at all myself so it didn&rsquo;t really resonate with me.</li>
<li>the format was constrainedÙ« and sometimes I wanted to include more
information in the answer than there was space for</li>
<li>the UI was a bit confusingÙ« some people couldn&rsquo;t figure out that you were
supposed to click on the card to flip it.</li>
</ul>

<h3 id="people-dislike-questions-that-don-t-match-their-mental-model">people dislike questions that don&rsquo;t match their mental model</h3>

<p>Probably the most important thing I learned from making these flashcards is
that it really matters how well the question matches the reader&rsquo;s mental model.</p>

<p>I started out by writing questions by taking statements I&rsquo;d normally make about a
topicÙ« and turning them into questions. Sometimes this really didn&rsquo;t work.</p>

<p>Here&rsquo;s an example of it not working: I think the statement &ldquo;a HTTP request has
4 parts: a bodyÙ« the headersÙ« the request methodÙ« and the path being requested&rdquo;
is relatively unobjectionable. That how I think about what a HTTP request is.</p>

<p>But what if I ask you &ldquo;what are the 4 parts of a HTTP request?&rdquo; and the answer
is &ldquo;a bodyÙ« the headersÙ« the request methodÙ« and the URL being requested&rdquo;? It
turns outÙ« that&rsquo;s totally different!! Not everyone thinks about HTTP requests
as having 4 parts &ndash; they might think of it has having 3 parts (the first lineÙ«
the headersÙ« and the body). Or 2 parts and 1 optional part (the first lineÙ« and
the headersÙ« and maybe an optional body). Or some other way! So it&rsquo;s weird to
be asked &ldquo;what are the 4 parts of a HTTP request&rdquo;.</p>

<p>There were a lot of other examples like thisÙ« where people reacted badly to
some question I asked that didn&rsquo;t match up with how they think about a topic.
So I learned that if I&rsquo;m asking a questionÙ« it gets held to a higher standard
for how well it matches with the reader&rsquo;s mental model than when making the
same statement.</p>

<p>An example of what I think would be a better question here is &ldquo;Does every HTTP
request have headers?&rdquo; (yes! the HTTP/1.1 RFC requires that the Host header be
set!). But even that is maybe a little tricky &ndash; probably at least one HTTP/1.0
client implementation is out there in the world sending requests without
headersÙ« even though 99.99% of HTTP requests have headers.</p>

<p>Of courseÙ« it&rsquo;s ok if the question/answer doesn&rsquo;t match the reader&rsquo;s mental
model if their mental model is incorrectÙ« but if their model is correct then I
think it should match.</p>

<h3 id="get-rid-of-multiple-choice">get rid of multiple choice</h3>

<p>The other thing I learned from these flashcards is that a lot of people dislike
multiple choice. I haven&rsquo;t thought about this that muchÙ« but honestly I don&rsquo;t
really like multiple choice either so I decided to get rid of it.</p>

<h3 id="next-step-get-reminded-of-the-little-schemer">next step: get reminded of The Little Schemer</h3>

<p>I don&rsquo;t remember whyÙ« but I&rsquo;ve had The Little Schemer kicking around in my head
for a while. I haven&rsquo;t actually read the whole thing myselfÙ« but I kept hearing
people talking about it. Here&rsquo;s the first page of The Little SchemerÙ« if you
haven&rsquo;t heard of it:</p>

<p><img src="https://jvns.ca/images/little-schemer.png"></p>

<p>This reminded me a lot of what I was trying to do &ndash; there are questions and
answersÙ« but the goal isn&rsquo;t for you to get all the questions &ldquo;right&rdquo;.  InsteadÙ«
I think the goal is for you to think about whether you know the answer yet or
not and learn as you go.</p>

<h3 id="switch-to-a-side-by-side-format">switch to a side-by-side format</h3>

<p>SoÙ« I kept a similar question/answer formatÙ« but switched to a side-by-side formatÙ« like the Little Schemer.</p>

<div align="center"><img  style="max-width: 500px" src="https://jvns.ca/images/side-by-side.png"></div>

<p>What I like about putting the questions &amp; answers next to each other:</p>

<ul>
<li>you can see both at the same timeÙ« so you don&rsquo;t forget what the question was</li>
<li>it then makes more sense to just put all the questions &amp; answers on the same
pageÙ« so you can easily go back and look at the previous question if you want</li>
</ul>

<p>Basically I like that it gives the reader more controlÙ« which I think is important.</p>

<h3 id="call-it-questions-instead-of-flashcards">call it &ldquo;questions&rdquo; instead of &ldquo;flashcards&rdquo;</h3>

<p>I also renamed the project to &ldquo;questions&rdquo; because that&rsquo;s really how I think
about learning for myself &ndash; I don&rsquo;t do &ldquo;flashcards&rdquo;Ù« but I do constantly ask
myself questions about topics I don&rsquo;t understandÙ« figure out the answers to
those questionsÙ« and then repeat until I understand the topic as well as I want
to.</p>

<p>But coming up with the right questions on your own is hard when you don&rsquo;t a
lotÙ« so I&rsquo;m hopeful that providing folks with a bunch of questions (and
answers) to think about will help you decide what you want to learn next.</p>

<h3 id="keep-the-i-learned-something-button">keep the &ldquo;I learned something&rdquo; button</h3>

<p>When I released the first set of questions on UDPÙ« I didn&rsquo;t include an &ldquo;I
learned something&rdquo; buttonÙ« and I noticed something weird &ndash; a lot of people
were tweeting things like &ldquo;I got <sup>8</sup>&frasl;<sub>10</sub>&rdquo;Ù« &ldquo;I got <sup>10</sup>&frasl;<sub>10</sub>&rdquo;.</p>

<p>I was a bit worried about this because the whole idea was to help people
identify things they could learnÙ« so saying &ldquo;I got <sup>8</sup>&frasl;<sub>10</sub>&rdquo; felt like it was
focusing on the things you already knew and ignoring the most important thing
&ndash; the 2 questions where maybe you could learn something new!</p>

<p>So I added an &ldquo;I learned something!&rdquo; button back to each question and spent way
too much time building a fun SVG+CSS animation that played when you pressed the
button. And so far it seems to have worked &ndash; I see more people commenting &ldquo;I
learned something&rdquo; and less &ldquo;I got <sup>9</sup>&frasl;<sub>10</sub>&rdquo;.</p>

<h3 id="building-small-things-is-hard">building small things is hard</h3>

<p>As usualÙ« building small simple things takes more time than I&rsquo;d expect! The
concept of &ldquo;some questions and answers&rdquo; seems really simpleÙ« but I&rsquo;ve already
learned a lot by building this and I think I still have a lot more to learn
about this format.</p>

<p>But I&rsquo;m excited to learn moreÙ« and I&rsquo;d love to know your thoughts. Here it is
again if you&rsquo;d like to try it: <a href="https://questions.wizardzines.com">https://questions.wizardzines.com</a>.</p>
'),('https://jvns.ca/blog/2020/05/08/metaphors-in-man-pages/', 'Metaphors in man pages', '1588930976000',  6, '

<p>This morning I was watching a <a href="https://www.youtube.com/watch?v=K8MF3aDg-bM&amp;feature=youtu.be&amp;t=14991">great talk by
Maggie Appleton</a>
about metaphors. In the talkÙ« she explains the difference between a
&ldquo;figurative metaphor&rdquo; and a &ldquo;cognitive metaphor&rdquo;Ù« and references this super interesting book called <a href="https://www.goodreads.com/book/show/34459.Metaphors_We_Live_By">Metaphors We
Live By</a> which
I immediately got and started reading.</p>

<p>Here&rsquo;s an example from &ldquo;Metaphors We Live By&rdquo; of a bunch of metaphors we use
for ideas:</p>

<ul>
<li>ideas as <strong>food</strong>: &ldquo;<em>raw</em> facts&rdquo;Ù« &ldquo;<em>half-baked</em> ideas&rdquo;Ù« &ldquo;<em>swallow</em> that claim&rdquo;Ù« &ldquo;<em>spoon-feed</em> our students&rdquo;Ù« &ldquo;<em>meaty</em> part of the paper&rdquo;Ù« &ldquo;that idea has been <em>fermenting</em> for years&rdquo;</li>
<li>ideas as <strong>people</strong>: &ldquo;the theory of relativity <em>gave birth</em> to an enormous number of ideas&rdquo;Ù« &ldquo;whose <em>brainchild</em> was that&rdquo;Ù« &ldquo;those ideas <em>died off</em> in the middle ages&rdquo;Ù« &ldquo;cognitive psychology is in its <em>infancy</em>&ldquo;</li>
<li>ideas as <strong>products</strong>: &ldquo;we&rsquo;ve <em>generated</em> a lot of ideas this week&rdquo;Ù« &ldquo;it needs to be <em>refined</em>&rdquo;Ù« &ldquo;his <em>intellectual productivity</em> has decreased in recent years&rdquo;</li>
<li>ideas as <strong>commodities</strong>: &ldquo;he won&rsquo;t <em>buy</em> that&rdquo;Ù« &ldquo;that&rsquo;s a <em>worthless</em> idea&rdquo;Ù« &ldquo;she has <em>valuable</em> ideas&rdquo;</li>
<li>ideas as <strong>resources</strong>: &ldquo;he <em>ran out</em> of ideas&rdquo;Ù« &ldquo;let&rsquo;s <em>pool</em> our ideas&rdquo;Ù« &ldquo;that idea will <em>go a long way</em>&ldquo;</li>
<li>ideas as <strong>cutting instruments</strong>: &ldquo;that&rsquo;s an <em>incisive</em> idea&rdquo;Ù« &ldquo;that <em>cuts right to the heart</em> of the matter&rdquo;Ù« &ldquo;he&rsquo;s <em>sharp</em>&ldquo;</li>
<li>ideas as <strong>fashions</strong>: &ldquo;that idea <em>went out of style</em> years ago&rdquo;Ù« &ldquo;marxism is <em>fashionable</em> in western europe&rdquo;Ù« &ldquo;berkeley is a center of <em>avant-garde</em> thought&rdquo;Ù« &ldquo;semiotics has become quite <em>chic</em>&ldquo;</li>
</ul>

<p>There&rsquo;s a <a href="https://metaphor.icsi.berkeley.edu/pub/en/index.php/Category:Metaphor">long list of more English metaphors here</a>Ù« including many metaphors from the book.</p>

<p>I was surprised that there were so many different metaphors for ideasÙ« and that
we&rsquo;re using metaphors like this all the time in normal language.</p>

<h3 id="let-s-look-for-metaphors-in-man-pages">let&rsquo;s look for metaphors in man pages!</h3>

<p>OkayÙ« let&rsquo;s get to the point of this blog postÙ« which is just a small fun
exploration &ndash; there aren&rsquo;t going to be any Deep Programming Insights here.</p>

<p>I went through some of the examples of metaphors in Metaphors To Live By and
grepped all the man pages on my computer for them.</p>

<h3 id="processes-as-people">processes as people</h3>

<p>This is one of the richer categories &ndash; a lot of different man pages seem to
agree that processes are peopleÙ« or at least alive in some way.</p>

<ul>
<li>Hangup detected on controlling terminal or <strong>death</strong> of controlling process <span class="nowrap">(<code>man 7 signal</code>)</span></li>
<li>can access the local <strong>agent</strong> through the forwarded connection <span class="nowrap">(<code>man ssh_config</code>)</span></li>
<li>If the exit of the process causes a process group to become <strong>orphaned</strong> <span class="nowrap">(<code>man exit</code>)</span></li>
<li>If a parent process terminatesÙ« then its <strong>&ldquo;zombie&rdquo; children</strong> (if any) <span class="nowrap">(<code>man wait</code>)</span></li>
<li>&hellip; send SIGHUP to the <strong>parent</strong> process of the client <span class="nowrap">(<code>man tmux</code>)</span></li>
<li>OtherwiseÙ« it <strong>&ldquo;runs&rdquo; to catch up</strong> or waits <span class="nowrap">(<code>man mplayer</code>)</span></li>
<li>HoweverÙ« Git does not (and it should not) change tags <strong>behind users back</strong> (<code>man git-tag</code>)</li>
<li>will <strong>listen</strong> forever for a connection <span class="nowrap">(<code>man nc_openbsd</code>)</span></li>
<li>this monitor scales badly with the number of files being <strong>observed</strong> <span class="nowrap">(<code>man fswatch</code>)</span></li>
<li>If you try to use the <strong>birth</strong> time of a reference file <span class="nowrap">(<code>man file</code>)</span></li>
<li>a program <strong>died</strong> due to a fatal signal <span class="nowrap">(<code>man xargs</code>)</span></li>
<li>protocol version in the TLS <strong>handshake</strong> <span class="nowrap">(<code>man curl</code>)</span></li>
<li>it will <strong>look for</strong> a debug object at&hellip; <span class="nowrap">(<code>man valgrind</code>)</span></li>
</ul>

<h3 id="data-as-food">data as food</h3>

<ul>
<li>&ldquo;Apparently some digital cameras get <strong>indigestion</strong> if you feed them a CF card) <span class="nowrap">(<code>man mkfs</code>)</span></li>
<li>&ldquo;Send packets using <strong>raw</strong> ethernet frames or IP packets&rdquo; <span class="nowrap">(<code>man nmap</code>)</span></li>
<li>&ldquo;the above example can be thought of as a maximizing repeat that must <strong>swallow</strong> everything it can&rdquo; <span class="nowrap">(<code>man pcrepattern</code>)</span></li>
<li>&ldquo;This will allow you to <strong>feed</strong> newline-delimited name=value pairs to the script on&rsquo; <span class="nowrap">(<code>man CGI</code>)</span></li>
</ul>

<h3 id="data-as-objects">data as objects</h3>

<ul>
<li>Kill the tmux server and clients and <strong>destroy</strong> all sessions <span class="nowrap">(<code>tmux</code>)</span></li>
<li>Each command will produce one <strong>block</strong> of output on standard output. <span class="nowrap">(<code>man tmux</code>)</span></li>
<li>&ldquo;HTTPS guarantees that the password will not <strong>travel</strong> in the clear&rdquo; <span class="nowrap">(<code>man Net::SSLeay</code>)</span></li>
<li>&ldquo;way to <strong>pack</strong> more than one certificate into an ASN.1 structure&rdquo; <span class="nowrap">(<code>man gpgsm</code>)</span></li>
</ul>

<h3 id="processes-as-machines-objects">processes as machines/objects</h3>

<ul>
<li>&ldquo;This is <strong>fragile</strong>Ù« subject to changeÙ« and thus should not be relied upon&rdquo; <span class="nowrap">(<code>man ps</code>)</span></li>
<li>&ldquo;This is useful if you have to use <strong>broken</strong> DNS&rdquo; <span class="nowrap">(<code>man aria2c</code>)</span></li>
<li>&ldquo;This provides good safety measuresÙ« but <strong>breaks down</strong> when&rdquo; <span class="nowrap">(<code>man git-apply</code>)</span></li>
<li>&ldquo;debugfs is a debugging tool. It has <strong>rough edges</strong>!&rdquo; <span class="nowrap">(<code>man debugfs</code>)</span></li>
</ul>

<h3 id="containers">containers</h3>

<p>There are LOTS of containers: directoriesÙ« filesÙ« stringsÙ« cachesÙ« queuesÙ«
buffersÙ« etc.</p>

<ul>
<li>can exploit that to <strong>get out</strong> of the chroot directory <span class="nowrap">(<code>man chroot</code>)</span></li>
<li>&ldquo;The file <strong>containing</strong> the RFC 4648 Section 5 base64url encoded 128-bit secret key&rdquo;</li>
<li>&ldquo;Keys must start with a lowercase character and <strong>contain</strong> only hyphens&rdquo;</li>
<li>&ldquo;just specify an <strong>empty</strong> string&rdquo; <span class="nowrap">(<code>man valgrind</code>)</span></li>
<li>&ldquo;the cache is <strong>full</strong> and a new page that isnâ€™t cached becomes visible&rdquo; <span class="nowrap">(<code>man zathurarc</code>)</span></li>
<li>&ldquo;Number of table <strong>overflows</strong>&rdquo; <span class="nowrap">(<code>man lnstat</code>)</span></li>
<li>&ldquo;likely <strong>overflow</strong> the buffer&rdquo; <span class="nowrap">(<code>man g++</code>)</span></li>
</ul>

<h3 id="resources">resources</h3>

<p>There are also lots of kinds of resources: bandwidthÙ« TCP socketsÙ« session IDsÙ«
stack spaceÙ« memoryÙ« disk space.</p>

<ul>
<li>This is not recommended and <strong>wastes</strong> bitrate <span class="nowrap">(<code>man bitrate</code>)</span></li>
<li>corruption or <strong>lost</strong> data if the system crashes <span class="nowrap">(<code>man btree</code>)</span></li>
<li>you don&rsquo;t want Wget to <strong>consume</strong> the entire available bandwidth <span class="nowrap">(<code>man wget</code>)</span></li>
<li>Larger values will be slower and cause x264 to <strong>consume</strong> more memory <span class="nowrap">(<code>man mplayer</code>)</span></li>
<li>the resulting file can <strong>consume</strong> some disk space <span class="nowrap">(<code>man socat</code>)</span></li>
<li>attempting to <strong>reuse</strong> SSL session-ID <span class="nowrap">(<code>man curl</code>)</span></li>
<li>This option controls stack space <strong>reuse</strong> <span class="nowrap">(<code>man gcc</code>)</span></li>
<li>Keep the TCP socket open between queries and <strong>reuse</strong> it rather than creating a new TCP socket <span class="nowrap">(<code>man dig</code>)</span></li>
<li>the maximum value will easily <strong>eat up</strong> three extra gigabytes or so of memory <span class="nowrap">(<code>man valgrind</code>)</span></li>
</ul>

<h3 id="orientation-up-down-above-below">orientation (upÙ« downÙ« aboveÙ« below)</h3>

<ul>
<li>Send the escape character to the <strong>frontend</strong> <span class="nowrap">(<code>man qemu-system</code>)</span></li>
<li>Note that TLS 1.3 is only supported by a subset of TLS <strong>backends</strong> <span class="nowrap">(<code>man curl</code>)</span></li>
<li>This option may be useful if you are <strong>behind</strong> a router <span class="nowrap">(<code>man mplayer</code>)</span></li>
<li>When a file that exists on the <strong>lower</strong> layer is renamed <span class="nowrap">(<code>man rename</code>)</span></li>
<li>Several of the socket options should be handled at <strong>lower</strong> levels  <span class="nowrap">(<code>man getsockopt</code>)</span></li>
<li>while still performing such <strong>higher</strong> level functionality <span class="nowrap">(<code>man nmap</code>)</span></li>
<li>This is the same string passed <strong>back to</strong> the front end <span class="nowrap">(<code>man sudo_plugin</code>)</span></li>
<li>On LinuxÙ« <code>futimens</code> is a library function implemented <strong>on top</strong> of the <code>utimensat</code> system call <span class="nowrap">(<code>man futimens</code>)</span></li>
</ul>

<h3 id="buildings">buildings</h3>

<p>Limits as rooms/buildings (which have floorsÙ« and ceilingsÙ« which you hit) are kind of fun:</p>

<ul>
<li>the kernel places a <strong>floor</strong> of 32 pages on this size limit <span class="nowrap">(<code>man execve</code>)</span></li>
<li>This specifies a <strong>ceiling</strong> to which the process&rsquo;s nice value can be raised <span class="nowrap">(<code>man getrlimit</code>)</span></li>
<li>If this limit is <strong>hit</strong> the search is aborted <span class="nowrap">(<code>man gcc</code>)</span></li>
<li>these libraries are used as the <strong>foundation</strong> for many of the libraries <span class="nowrap">(<code>man Glib</code>)</span></li>
</ul>

<h3 id="money-wealth">money / wealth</h3>

<ul>
<li>This is a very <strong>expensive</strong> operation for large projectsÙ« so use it with caution <span class="nowrap">(<code>man git-log</code>)</span></li>
<li>Note that since this operation is very I/O <strong>expensive</strong> <span class="nowrap">(<code>man git-filter-branch</code>)</span></li>
<li>provides a <strong>rich</strong> interface for scripts to print disk layouts <span class="nowrap">(<code>man fdisk</code>)</span></li>
<li>The number of times the softirq handler function terminated per second because its <strong>budget</strong> was consumed <span class="nowrap">(<code>man sar.sysstat</code>)</span></li>
<li>the extra <strong>cost</strong> depends a lot on the application at hand <span class="nowrap">(<code>man valgrind</code>)</span></li>
</ul>

<h3 id="more-miscellaneous-metaphors">more miscellaneous metaphors</h3>

<p>here are some more I found that didn&rsquo;t fit into any of those categories yet.</p>

<ul>
<li>when a thread is created under glibcÙ« just one <strong>big</strong> lock is used for all thread setup <span class="nowrap">(<code>man valgrind</code>)</span></li>
<li>will likely <strong>drop</strong> the connection <span class="nowrap">(<code>man x11vnc</code>)</span></li>
<li>on all <strong>paths</strong> from the load to the function entry <span class="nowrap">(<code>man gcc</code>)</span></li>
<li>it is a very good idea to <strong>wipe</strong> filesystem signaturesÙ« dataÙ« etc. before <span class="nowrap">(<code>man cryptsetup</code>)</span></li>
<li>they will be <strong>embedded</strong> into the document</li>
<li>the client should automatically <strong>follow</strong> referrals returned</li>
<li>even if there exist mappings that <strong>cover</strong> the whole address space requested <span class="nowrap">(<code>man mremap</code>)</span></li>
<li>when a network interface <strong>disappears</strong> <span class="nowrap">(<code>man systemd-resolve</code>)</span></li>
</ul>

<h3 id="we-re-all-using-metaphors-all-the-time">we&rsquo;re all using metaphors all the time</h3>

<p>I found a lot more metaphors than I expectedÙ« and most of them are just part of
how I&rsquo;d normally talk about a program. Interesting!</p>

<style>
.nowrap {
    white-space: nowrap;
    padding: 0px;
}
</style>
'),('https://jvns.ca/blog/2020/04/29/why-strace-doesnt-work-in-docker/', 'Why strace doesn"t work in Docker', '1588146932000',  6, '

<p>While editing the capabilities page of the <a href="https://wizardzines.com/zines/containers">how containers work</a> zineÙ« I found myself
trying to explain why <code>strace</code> doesn&rsquo;t work in a Docker container.</p>

<p>The problem here is &ndash; if I run <code>strace</code> in a Docker container on my laptopÙ« this happens:</p>

<pre><code>$ docker run  -it ubuntu:18.04 /bin/bash
$ # ... install strace ...
root@e27f594da870:/# strace ls
strace: ptrace(PTRACE_TRACEMEÙ« ...): Operation not permitted
</code></pre>

<p>strace works using the <code>ptrace</code> system callÙ« so if <code>ptrace</code> isn&rsquo;t
allowedÙ« it&rsquo;s definitely not gonna work! This is pretty easy to fix &ndash; on
my machineÙ« this fixes it:</p>

<pre><code>docker run --cap-add=SYS_PTRACE  -it ubuntu:18.04 /bin/bash
</code></pre>

<p>But I wasn&rsquo;t interested in fixing itÙ« I wanted to know why it happens. So
why does strace not workÙ« and why does <code>--cap-add=SYS_PTRACE</code> fix it?</p>

<h3 id="hypothesis-1-container-processes-are-missing-the-cap-sys-ptrace-capability">hypothesis 1: container processes are missing the <code>CAP_SYS_PTRACE</code> capability</h3>

<p>I always thought the reason was that Docker container processes by
default didn&rsquo;t have the <code>CAP_SYS_PTRACE</code> capability. This is consistent
with it being fixed by <code>--cap-add=SYS_PTRACE</code>Ù« right?</p>

<p>But this actually doesn&rsquo;t make sense for 2 reasons.</p>

<p><strong>Reason 1</strong>: ExperimentallyÙ« as a regular userÙ« I can strace on any process run by my
user. But if I check if my current process has the <code>CAP_SYS_PTRACE</code> capabilityÙ« I don&rsquo;t:</p>

<pre><code>$ getpcaps $$
Capabilities for `11589": =
</code></pre>

<p><strong>Reason 2</strong>: <code>man capabilities</code> says this about <code>CAP_SYS_PTRACE</code>:</p>

<pre><code>CAP_SYS_PTRACE
       * Trace arbitrary processes using ptrace(2);
</code></pre>

<p>So the point of <code>CAP_SYS_PTRACE</code> is to let you ptrace <strong>arbitrary</strong>
processes owned by any userÙ« the way that root usually can. You shouldn&rsquo;t
need it to just ptrace a regular process owned by your user.</p>

<p>And I tested this a third way &ndash; I ran a Docker container with <code>docker
run --cap-add=SYS_PTRACE  -it ubuntu:18.04 /bin/bash</code>Ù« dropped the
<code>CAP_SYS_PTRACE</code> capabilityÙ« and I could still strace processes even
though I didn&rsquo;t have that capability anymore. What? Why?</p>

<h3 id="hypothesis-2-something-about-user-namespaces">hypothesis 2: something about user namespaces???</h3>

<p>My next (much less well-founded) hypothesis was something along the lines
of &ldquo;umÙ« maybe the process is in a different user namespace and strace
doesn&rsquo;t work because of&hellip; reasons?&rdquo; This isn&rsquo;t really coherent but
here&rsquo;s what happened when I looked into it.</p>

<p>Is the container process in a different user namespace? WellÙ« in the container:</p>

<pre><code>root@e27f594da870:/# ls /proc/$$/ns/user -l
... /proc/1/ns/user -&gt; "user:[4026531837]"
</code></pre>

<p>On the host:</p>

<pre><code>bork@kiwi:~$ ls /proc/$$/ns/user -l
... /proc/12177/ns/user -&gt; "user:[4026531837]"
</code></pre>

<p>Because the user namespace ID (<code>4026531837</code>) is the sameÙ« the root user
in the container is the exact same user as the root user on the host. So
there&rsquo;s definitely no reason it shouldn&rsquo;t be able to strace processes
that it created!</p>

<p>This hypothesis doesn&rsquo;t make much sense but I hadn&rsquo;t realized that the
root user in a Docker container is the same as the root user on the hostÙ«
so I thought that was interesting.</p>

<h3 id="hypothesis-3-the-ptrace-system-call-is-being-blocked-by-a-seccomp-bpf-rule">hypothesis 3: the ptrace system call is being blocked by a seccomp-bpf rule</h3>

<p>I also knew that Docker uses seccomp-bpf to stop container processes from
running a lot of system calls. And ptrace is in the <a href="https://docs.docker.com/engine/security/seccomp/">list of system calls
blocked by Docker&rsquo;s default seccomp
profile</a>! (actually the
list of allowed system calls is a whitelistÙ« so it&rsquo;s just that ptrace is
not in the default whitelist. But it comes out to the same thing.)</p>

<p>That easily explains why strace wouldn&rsquo;t work in a Docker container &ndash; if
the <code>ptrace</code> system call is totally blockedÙ« then of course you can&rsquo;t
call it at all and strace would fail.</p>

<p>Let&rsquo;s verify this hypothesis &ndash; if we disable all seccomp rulesÙ« can we
strace in a Docker container?</p>

<pre><code>$ docker run --security-opt seccomp=unconfined -it ubuntu:18.04  /bin/bash
$ strace ls
execve(&quot;/bin/ls&quot;Ù« [&quot;ls&quot;]Ù« 0x7ffc69a65580 /* 8 vars */) = 0
... it works fine ...
</code></pre>

<p>Yes! It works! Great. Mystery solvedÙ« except&hellip;</p>

<h3 id="why-does-cap-add-sys-ptrace-fix-the-problem">why does <code>--cap-add=SYS_PTRACE</code> fix the problem?</h3>

<p>What we still haven&rsquo;t explained is: why does <code>--cap-add=SYS_PTRACE</code> would
fix the problem?</p>

<p>The man page for <code>docker run</code> explains the <code>--cap-add</code> argument this way:</p>

<pre><code>--cap-add=[]
   Add Linux capabilities
</code></pre>

<p>That doesn&rsquo;t have anything to do with seccomp rules! What&rsquo;s going on?</p>

<h3 id="let-s-look-at-the-docker-source-code">let&rsquo;s look at the Docker source code.</h3>

<p>When the documentation doesn&rsquo;t helpÙ« the only thing to do is go look at
the source.</p>

<p>The nice thing about Go isÙ« because dependencies are often vendored in a
Go repositoryÙ« you can just grep the repository to figure out where the
code that does a thing is. So I cloned <code>github.com/moby/moby</code> and grepped
for some thingsÙ« like <code>rg CAP_SYS_PTRACE</code>.</p>

<p>Here&rsquo;s what I think is going on. In containerd&rsquo;s seccomp implementationÙ« in
<a href="https://github.com/containerd/containerd/blob/4be98fa28b62e8a012491d655a4d6818ef87b080/contrib/seccomp/seccomp_default.go#L527-L537">contrib/seccomp/seccomp_default.go</a>Ù«
there&rsquo;s a bunch of code that makes sure that if a process has a
capabilityÙ« then it&rsquo;s also given access (through a seccomp rule) to use
the system calls that go with that capability.</p>

<pre><code>		case &quot;CAP_SYS_PTRACE&quot;:
			s.Syscalls = append(s.SyscallsÙ« specs.LinuxSyscall{
				Names: []string{
					&quot;kcmp&quot;Ù«
					&quot;process_vm_readv&quot;Ù«
					&quot;process_vm_writev&quot;Ù«
					&quot;ptrace&quot;Ù«
				}Ù«
				Action: specs.ActAllowÙ«
				Args:   []specs.LinuxSeccompArg{}Ù«
			})
</code></pre>

<p>There&rsquo;s some other code that seems to do something very similar in
<a href="https://github.com/moby/moby/blob/cc0dfb6e7b22ad120c60a9ce770ea15415767cf9/profiles/seccomp/seccomp.go#L126-L132">profiles/seccomp/seccomp.go</a>
in moby and the <a href="https://github.com/moby/moby/blob/master/profiles/seccomp/default.json#L723-L739">default seccomp
profile</a>Ù«
so it&rsquo;s possible that that&rsquo;s what&rsquo;s doing it instead.</p>

<p>So I think we have our answer!</p>

<h3 id="cap-add-in-docker-does-a-little-more-than-what-it-says"><code>--cap-add</code> in Docker does a little more than what it says</h3>

<p>The upshot seems to be that <code>--cap-add</code> doesn&rsquo;t do exactly what it says
it does in the man pageÙ« it&rsquo;s more like
<code>--cap-add-and-also-whitelist-some-extra-system-calls-if-required</code>. Which makes
sense! If you have a capability like <code>CAP_SYS_PTRACE</code> which is supposed
to let you use the <code>process_vm_readv</code> system call but that system call is
blocked by a seccomp profileÙ« that&rsquo;s not going to help you much!</p>

<p>So allowing the <code>process_vm_readv</code> and <code>ptrace</code> system calls when you
give the container <code>CAP_SYS_PTRACE</code> seems like a reasonable choice.</p>

<h3 id="strace-actually-does-work-in-newer-versions-of-docker">strace actually does work in newer versions of Docker</h3>

<p>As of <a href="https://github.com/moby/moby/commit/1124543ca8071074a537a15db251af46a5189907">this commit</a> (docker 19.03)Ù« Docker does actually allow the <code>ptrace</code> system calls for kernel versions newer than 4.8.</p>

<p>But the Docker version on my laptop is 18.09.7Ù« so it predates that commit.</p>

<h3 id="that-s-all">that&rsquo;s all!</h3>

<p>This was a fun small thing to investigateÙ« and I think it&rsquo;s a nice
example of how containers are made of lots of moving pieces that work
together in not-completely-obvious ways.</p>

<p>If you liked thisÙ« you might like my new zine called <a href="https://wizardzines.com/zines/containers">How Containers Work</a> that explains the Linux kernel features that make containers work in 24 pages. You can read the pages on <a href="https://wizardzines.com/comics/capabilities/">capabilities</a> and <a href="https://wizardzines.com/comics/seccomp-bpf/">seccomp-bpf</a> from the zine.</p>

<div align="center">
<a href="https://wizardzines.com/zines/containers"><img width="300px" src="https://jvns.ca/images/containers-cover.jpg"></a>
</div>
'),('https://jvns.ca/blog/2020/04/27/new-zine-how-containers-work/', 'New zine: How Containers Work!', '1587992557000',  6, '

<p>On Friday I published a new zine: &ldquo;How Containers Work!&rdquo;. I also launched a
fun redesign of <a href="https://wizardzines.com">wizardzines.com</a>.</p>

<p>You can get it for $12 at <a href="https://wizardzines.com/zines/containers">https://wizardzines.com/zines/containers</a>. If you buy itÙ« you&rsquo;ll get a PDF that you can
either print out or read on your computer. Or you can get a pack of <a href="https://wizardzines.com/zines/all-the-zines/">all 8 zines</a> so far.</p>

<p>Here&rsquo;s the cover and table of contents:</p>

<div align="center">
<a href="https://wizardzines.com/zines/containers"><img width="400px" src="https://jvns.ca/images/containers-cover.jpg"></a>
<a href="https://jvns.ca/images/containers-toc.png"><img width="400px" src="https://jvns.ca/images/containers-toc.png"></a>
</div>

<h3 id="why-containers">why containers?</h3>

<p>I&rsquo;ve spent a lot of time
<a href="https://stripe.com/en-ca/blog/operating-kubernetes">figuring</a>
<a href="https://jvns.ca/blog/2016/09/15/whats-up-with-containers-docker-and-rkt/">out</a>
<a href="https://jvns.ca/blog/2016/10/10/what-even-is-a-container/">how to</a>
<a href="https://jvns.ca/blog/2016/12/22/container-networking/">run</a>
<a href="https://jvns.ca/blog/2016/10/26/running-container-without-docker/">things</a>
<a href="https://jvns.ca/blog/2017/02/17/mystery-swap/">in</a>
<a href="https://jvns.ca/blog/2016/10/02/a-list-of-container-software/">containers</a>
over the last 3-4 years. And at the beginning I was really confused! I knew a
bunch of things about LinuxÙ« and containers didn&rsquo;t seem to fit in with anything
I thought I knew (&ldquo;is it a process? what&rsquo;s a network namespace? what&rsquo;s
happening?&ldquo;). The whole thing seemed really weird.</p>

<p>It turns out that containers ARE actually pretty weird. Theyâ€™re not just
one thingÙ« theyâ€™re what you get when you glue together 6 different features
that were mostly designed to work together but have a bunch of confusing edge
cases.</p>

<p>As usualÙ« the thing that helped me the most in my container adventures is a
good understanding of the <strong>fundamentals</strong> &ndash; what exactly is actually
happening on my server when I run a container?</p>

<p>So that&rsquo;s what this zine is about &ndash; cgroupsÙ« namespacesÙ« pivot_rootÙ«
seccomp-bpfÙ« and all the other Linux kernel features that make containers work.</p>

<p>Once I understood those ideasÙ« it got a <strong>lot</strong> easier to debug when my
containers were doing surprising things in production. I learned a couple of
interesting and strange things about containers while writing this zine too &ndash;
I&rsquo;ll probably write a blog post about one of them later this week.</p>

<h3 id="containers-aren-t-magic">containers aren&rsquo;t magic</h3>

<p>This picture (page 6 of the zine) shows you how to run a fish container image
with only 15 lines of bash. This is heavily inspired by
<a href="https://github.com/p8952/bocker">bocker</a>Ù« which &ldquo;implements&rdquo; Docker in about
100 lines of bash.</p>

<div align="center">
<a href="https://jvns.ca/images/containers-arent-magic.jpg"><img width="400px" src="https://jvns.ca/images/containers-arent-magic.jpg"></a>
</div>

<p>The main things I see missing from that script compared to what Docker actually does when running a container (other than using an actual container image and not just a tarball) are:</p>

<ul>
<li>it doesn&rsquo;t drop any capabilities &ndash; the container is still running as root and has full root privileges (just in a different mount + PID namespace)</li>
<li>it doesn&rsquo;t block any system calls with seccomp-bpf</li>
</ul>

<h3 id="container-command-line-tools">container command line tools</h3>

<p>The zine also goes over a bunch of command line tools &amp; files that you can
use to inspect running containers or play with Linux container features. Here&rsquo;s a list:</p>

<ul>
<li><code>mount -t overlay</code> (create and view overlay filesystems)</li>
<li><code>unshare</code> (create namespaces)</li>
<li><code>nsenter</code> (use an existing namespace)</li>
<li><code>getpcaps</code> (get a process&rsquo;s capabilities)</li>
<li><code>capsh</code> (drop or add capabilitiesÙ« etc)</li>
<li><code>cgcreate</code> (create a cgroup)</li>
<li><code>cgexec</code> (run a command in an existing cgroup)</li>
<li><code>chroot</code> (change root directory. not actually what containers use but interesting to play with anyway)</li>
<li><code>/sys/fs/cgroups</code> (for information about cgroupsÙ« like <code>memory.usage_in_bytes</code>)</li>
<li><code>/proc/PID/ns</code> (all a process&rsquo;s namespaces)</li>
<li><code>lsns</code> (another way to view namespaces)</li>
</ul>

<p>I also made a short youtube video a while back called <a href="https://www.youtube.com/watch?v=YCVSdnYzH34&amp;t=1s">ways to spy on a Docker container</a> that demos some of these command line tools.</p>

<h3 id="container-runtime-agnostic">container runtime agnostic</h3>

<p>I tried to keep this zine pretty container-runtime-agnostic &ndash; I mention Docker
a couple of times because it&rsquo;s so widely usedÙ« but it&rsquo;s about the Linux kernel
features that make containers work in generalÙ« not Docker or LXC or
systemd-nspawn or Kubernetes or whatever. If you understand the fundamentals
you can figure all those things out!</p>

<h3 id="we-redesigned-wizardzines-com">we redesigned wizardzines.com!</h3>

<p>On Friday I also launched a redesign of
<a href="https://wizardzines.com">wizardzines.com</a>! <a href="https://melody.dev">Melody Starling</a> (who is amazing) did the design. I think now it&rsquo;s
better organized but the tiny touch that I&rsquo;m most delighted by is that now the zines jump with joy when
you hover over them.</p>

<p>One cool thing about working with a designer is &ndash; they don&rsquo;t just
make things <em>look</em> betterÙ« they help <em>organize</em> the information better so the
website makes more sense and it&rsquo;s easier to find things! This is probably obvious to anyone who knows anything about design
but I haven&rsquo;t worked with designers very much (or maybe ever?) so it was really cool to see.</p>

<p>One tiny example of this: Melody had the idea of adding a tiny FAQ on the
landing page for each zineÙ« where I can put the answers to all the questions
people always ask! Here&rsquo;s what the little FAQ box looks like:</p>

<div align="center">
<a href="https://wizardzines.com/zines/containers"><img src="https://jvns.ca/images/wizardzines-faq.png" width="200px"></a>
</div>

<p>I probably want to edit those questions &amp; answers over time but it&rsquo;s SO NICE to have
somewhere to put them.</p>

<h3 id="what-s-next-maybe-debugging-or-working-more-on-flashcards">what&rsquo;s next: maybe debugging! or working more on flashcards!</h3>

<p>The two projects I&rsquo;m thinking about the most right now are</p>

<ol>
<li>a zine about debuggingÙ« which I started last summer and haven&rsquo;t gotten around to finishing yet</li>
<li>a <a href="https://flashcards.wizardzines.com">flashcards project</a> that I&rsquo;ve been adding to slowly over the last couple of months. I think could become a nice way to explain basic ideas.</li>
</ol>

<p><br><br>
Here&rsquo;s a link to where to <a href="https://wizardzines.com/zines/containers">get the zine</a> again :)</p>
'),('https://jvns.ca/blog/debugging-attitude-matters/', 'When debuggingÙ« your attitude matters', '1585837591000',  6, '

<p>A while back I wrote <a href="https://jvns.ca/blog/2019/06/23/a-few-debugging-resources/">What does debugging a program look like?</a> on what to do when debugging (change one thing at a time! check your assumptions!).</p>

<p>But I was debugging some CSS last weekÙ« and I think that post is missing
something important: <strong>your attitude</strong>.</p>

<p>Now &ndash; I&rsquo;m not a very good CSS developer yet. I&rsquo;ve never written CSS
professionally and I don&rsquo;t understand a lot of basic CSS concepts (I think I
finally understood for the first time recently how <code>position: absolute</code> works). And last
week I was working on the most complicated CSS project I&rsquo;d ever attempted.</p>

<p>While I was debugging my CSSÙ« I noticed myself doing some bad things that I
normally would not! I was:</p>

<ul>
<li>making random changes to my code in the hopes that it would work</li>
<li>googling a lot of things and trying them without understanding what they did</li>
<li>if something brokeÙ« reverting my changes and starting again</li>
</ul>

<p>This strategy was exactly as effective as you might imagine (not very
effective!)Ù« and it was because of my attitude about CSS! I had this
unusual-for-me belief that CSS was Too Hard and impossible for me to
understand. So let&rsquo;s talk about that attitude a bit!</p>

<h3 id="the-problem-attitude-this-is-too-hard-for-me-to-understand">the problem attitude: &ldquo;this is too hard for me to understand&rdquo;</h3>

<p>One specific problem I was having was &ndash; I had 2 divs stacked on top of one anotherÙ« and
I wanted Div A to be on top of Div B.  My model of CSS stacking order at the
start of this was basically &ldquo;if you want Thing A to be on top of Thing BÙ«
change the z-index to make it work&rdquo;. So I changed the z-index of Div A to be 5
or something.</p>

<p>But it didn&rsquo;t work! In FirefoxÙ« div A was on topÙ« but in ChromeÙ« Div B was on
top. Argh! Why? CSS is impossible!!! (<small>if you want to see the exact actual situation I was inÙ« I <a href="https://codepen.io/jvns-css-fun/pen/zYGVLXj">reproduced the different-in-firefox-and-chrome thing here after the fact</a></small>)</p>

<p>I googled a bitÙ« and I found out that a possible reason z-index might not work
was because Div A and Div B were actually in different &ldquo;stacking contexts&rdquo;. If
that was trueÙ« even if I set the z-index of Div A to 999999 it would still not
put it on top of Div B. (<a href="https://codepen.io/jvns-css-fun/pen/YzXMMdQ">here&rsquo;s a small example of what this z-index problem looks likeÙ« though I think my specific bug had some extra complications</a>)</p>

<p>I thought &ldquo;manÙ« this stacking context thing seems really complicatedÙ« why is it
different between Firefox and ChromeÙ« I&rsquo;m not going to be able to figure this
out&rdquo;. So I tried a bunch of random things a bunch of blog posts suggestedÙ«
which as usual did not work.</p>

<p>Finally I gave up this &ldquo;change random things and pray&rdquo; strategy and thought &ldquo;wellÙ« what
if I just read the documentation on stacking orderÙ« maybe it&rsquo;s not that bad&rdquo;.</p>

<p>So I read the <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Positioning/Understanding_z_index/Stacking_without_z-index">MDN page on stacking order</a>Ù« which says:</p>

<blockquote>
<p>When the z-index property is not specified on any elementÙ« elements are stacked in the following order (from bottom to top): <br>
1. The background and borders of the root element <br>
2. Descendant non-positioned blocksÙ« in order of appearance in the HTML <br>
3. Descendant positioned elementsÙ« in order of appearance in the HTML</p>
</blockquote>

<p>This is SO SIMPLE! It just depends on the order in the HTML! I put Div A after
Div B in the HTML (as a sibling) and it made everything work in both browsers.</p>

<h3 id="better-attitude-let-s-learn-the-basics-and-see-if-that-helps">better attitude: &ldquo;let&rsquo;s learn the basics and see if that helps&rdquo;</h3>

<p>This whole stacking problem turned out to really not be that complicated &ndash; all I
needed to do was read a very short and simple documentation page to understand how stacking works!</p>

<p>Of courseÙ« computer things are not always this simple (and even in this
specific case the <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Positioning/Understanding_z_index/The_stacking_context">rules about what creates a new stacking
context</a>
are pretty complicated.). But I did not need to understand those more complicated rules in order to put Div A on top of Div B! I only needed to know the much simpler 3 rules above.</p>

<p>So &ndash; calm down for a secondÙ« learn a few of the basicsÙ« and see if that helps.</p>

<h3 id="watching-people-who-know-what-they-re-doing-is-inspiring">watching people who know what they&rsquo;re doing is inspiring</h3>

<p>Another area of CSS that I thought was &ldquo;too hard&rdquo; for me to understand was this
whole <code>position: absolute</code> and <code>position: relative</code> business.  I kept seeing
(and sometimes using!) examples where people made complicated CSS things with
<code>position: absolute</code> but I didn&rsquo;t understand how they worked. Doesn&rsquo;t <code>position: absolute</code> mean that the element is always in the same place on the screen? Why are these <code>position: absolute</code> things moving when I scroll like the rest of the document? (spoiler: noÙ« that&rsquo;s <code>position: fixed</code>.)</p>

<p>But last weekÙ« I paired with someone who&rsquo;s a lot better at CSS than me on some
codeÙ« and I saw that they were just typing in <code>position: absolute</code> and
<code>position: relative</code> confidently into their code without seeming confused about
it!! Could that be me?</p>

<p>I looked up the <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/position">documentation on MDN</a> on <code>position: absolute</code>Ù« and it said:</p>

<blockquote>
<p>The element is removed from the normal document flowÙ« and no space is created
for the element in the page layout. It is positioned relative to its closest
positioned ancestor&hellip; Its final position is determined by the values of topÙ« rightÙ« bottomÙ« and left.</p>
</blockquote>

<p>So things with <code>position: absolute</code> are positioned relative to their closest
positioned ancestor! And you just use <code>top/bottom/right/left</code> to pick where!
That&rsquo;s so simple!</p>

<h3 id="documentation-that-you-can-trust-makes-a-big-difference">documentation that you can trust makes a big difference</h3>

<p>I think another big source of my frustration with CSS is that I didn&rsquo;t have the
best grasp of where to find accurate information &amp; advice. I knew that MDN was a reliable
referenceÙ« but MDN doesn&rsquo;t really help answer questions like &ldquo;ok but seriously
how do I center a div???&rdquo; and I found myself reading a lot of random Stack Overflow
answers/blog posts that I wasn&rsquo;t 100% sure were correct.</p>

<p>This week I learned about <a href="https://css-tricks.com">CSS Tricks</a> which has a lot
of GREAT articles like <a href="https://css-tricks.com/centering-css-complete-guide/">Centering in CSS: A Complete Guide</a> which seems very reputable and is written
in a super clear way.</p>

<h3 id="that-s-all">that&rsquo;s all!</h3>

<p>I don&rsquo;t really know why I started to believe that it was &ldquo;impossible&rdquo; to
understand basic CSS concepts since I don&rsquo;t believe that about computers in
general. Maybe because I&rsquo;ve been writing CSS at a beginner level for a very
long time but hadn&rsquo;t ever really tried to do a more involved CSS project than
&ldquo;let&rsquo;s arrange some divs in a grid with flexbox&rdquo;!</p>

<p>But this attitude really got in the way of me writing the CSS I wanted to
write!  And once I let go of it and used my normal debugging techniques I was
able to get a lot more things to work the way I wanted.</p>
'),('https://jvns.ca/blog/2020/03/15/writing-shaders-with-signed-distance-functions/', 'Getting started with shaders: signed distance functions!', '1584277686000',  6, '

<p>Hello! A while back I learned how to make fun shiny spinny things like this
using shaders:</p>

<div align="center">
<img src="https://jvns.ca/images/spinny.gif" width="150px">
</div>

<p>My shader skills are still extremely basicÙ« but this fun spinning thing turned out to be a lot
easier to make than I thought it would be to make (with a lot of copying of
code snippets from other people!).</p>

<p>The big idea I learned when doing this was something called &ldquo;signed distance
functions&rdquo;Ù« which I learned about from a very fun tutorial called <a href="https://www.shadertoy.com/view/Xl2XWt">Signed Distance Function
tutorial: box &amp; balloon</a>.</p>

<p>In this post I&rsquo;ll go through the steps I used to learn to write a simple shader
and try to convince you that shaders are not that hard to get started with!</p>

<h3 id="examples-of-more-advanced-shaders">examples of more advanced shaders</h3>

<p>If you haven&rsquo;t seen people do really fancy things with shadersÙ« here are a couple:</p>

<ol>
<li>this very complicated shader that is like a realistic video of a river: <a href="https://www.shadertoy.com/view/Xl2XRW">https://www.shadertoy.com/view/Xl2XRW</a></li>
<li>a more abstract (and shorter!) fun shader with a lot of glowing circles: <a href="https://www.shadertoy.com/view/lstSzj">https://www.shadertoy.com/view/lstSzj</a></li>
</ol>

<h3 id="step-1-my-first-shader">step 1: my first shader</h3>

<p>I knew that you could make shaders on shadertoyÙ« and so I went to
<a href="https://www.shadertoy.com/new">https://www.shadertoy.com/new</a>. They give you a default shader to start with
that looks like this:</p>

<div align="center">
<img src="https://jvns.ca/images/colour.gif" width="150px" style="margin: 0 auto">
</div>

<p>Here&rsquo;s the code:</p>

<pre><code>void mainImage( out vec4 fragColorÙ« in vec2 fragCoord )
{
    // Normalized pixel coordinates (from 0 to 1)
    vec2 uv = fragCoord/iResolution.xy;

    // Time varying pixel color
    vec3 col = 0.5 + 0.5*cos(iTime+uv.xyx+vec3(0Ù«2Ù«4));

    // Output to screen
    fragColor = vec4(colÙ«1.0);
}
</code></pre>

<p>This doesn&rsquo;t do anything that excitingÙ« but it already taught me the basic structure of a shader program!</p>

<h3 id="the-idea-map-a-pair-of-coordinates-and-time-to-a-colour">the idea: map a pair of coordinates (and time) to a colour</h3>

<p>The idea here is that you get a pair of coordinates as an input (<code>fragCoord</code>)
and you need to output a RGBA vector with the colour of that. The function can
also use the current time (<code>iTime</code>)Ù« which is how the picture changes over
time.</p>

<p>The neat thing about this programming model (where you map a pair of
coordinates and the time to) is that it&rsquo;s extremely trivially parallelizable. I
don&rsquo;t understand a lot about GPUs but my understanding is that this kind of
task (where you have 10000 trivially parallelizable calculations to do at
once) is exactly the kind of thing GPUs are good at.</p>

<h3 id="step-2-iterate-faster-with-shadertoy-render">step 2: iterate faster with <code>shadertoy-render</code></h3>

<p>After a while of playing with shadertoyÙ« I got tired of having to click
&ldquo;recompile&rdquo; on the Shadertoy website every time I saved my shader.</p>

<p>I found a command line tool that will watch a file and update the animation in real time every time I save called <a href="https://github.com/alexjc/shadertoy-render">shadertoy-render</a>. So now I can just run:</p>

<pre><code>shadertoy-render.py circle.glsl 
</code></pre>

<p>and iterate way faster!</p>

<h3 id="step-3-draw-a-circle">step 3: draw a circle</h3>

<p>Next I thought &ndash; I&rsquo;m good at math! I can use some basic trigonometry to draw a
bouncing rainbow circle!</p>

<p>I know the equation for a circle (<code>x**2 + y**2 = whatever</code>!)Ù« so I wrote some code to do that:</p>

<div align="center">
<img src="https://jvns.ca/images/circle.gif" width="150px">
</div>

<p>Here&rsquo;s the code:  (which you can also <a href="https://www.shadertoy.com/view/tsscR4">see on shadertoy</a>)</p>

<pre><code>void mainImage( out vec4 fragColorÙ« in vec2 fragCoord )
{
    // Normalized pixel coordinates (from 0 to 1)
    vec2 uv = fragCoord/iResolution.xy;
    // Draw a circle whose center depends on what time it is
    vec2 shifted = uv - vec2((sin(iGlobalTime) + 1)/2Ù« (1 + cos(iGlobalTime)) / 2);
    if (dot(shiftedÙ« shifted) &lt; 0.03) {
        // Varying pixel colour
        vec3 col = 0.5 + 0.5*cos(iGlobalTime+uv.xyx+vec3(0Ù«2Ù«4));
        fragColor = vec4(colÙ«1.0);
    } else {
        // make everything outside the circle black
        fragColor = vec4(0Ù«0Ù«0Ù«1.0);
    }
}
</code></pre>

<p>This takes the dot product of the coordinate vector <code>fragCoord</code> with itselfÙ«
which is the same as calculating <code>x^2 + y^2</code>. I played with the center of the circle a little bit in this one too &ndash; I made the center <code>vec2((sin(iGlobalTime) + 1)/2Ù« (1 + cos(faster)) / 2)</code>Ù« which means that the center of the circle also goes in a circle depending on what time it is.</p>

<h3 id="shaders-are-a-fun-way-to-play-with-math">shaders are a fun way to play with math!</h3>

<p>One thing I think is fun about this already (even though we haven&rsquo;t done
anything super advanced!) is that these shaders give us a fun visual way to
play with math &ndash; I used <code>sin</code> and <code>cos</code> to make something go in a circleÙ« and
if you want to get some better intuition about how trigonometric workÙ« maybe
writing shaders would be a fun way to do that!</p>

<p>I love that you get instant visual feedback about your math code &ndash; if you
multiply something by 2Ù« things get bigger! or smaller! or faster! or slower!
or more red!</p>

<h3 id="but-how-do-we-do-something-really-fancy">but how do we do something really fancy?</h3>

<p>This bouncing circle is nice but it&rsquo;s really far from the super fancy things
I&rsquo;ve seen other people do with shaders. So what&rsquo;s the next step?</p>

<h3 id="idea-instead-of-using-if-statements-use-signed-distance-functions">idea: instead of using if statementsÙ« use signed distance functions!</h3>

<p>In my circle code aboveÙ« I basically wrote:</p>

<pre><code>if (dot(uvÙ« uv) &lt; 0.03) {
    // code for inside the circle
} else {
    // code for outside the circle
}
</code></pre>

<p>But the problem with this (and the reason I was feeling stuck) is that it&rsquo;s not
clear how it generalizes to more complicated shapes! Writing a bajillion if
statements doesn&rsquo;t seem like it would work well. And how do people render those
3d shapes anyway?</p>

<p>So! <strong>Signed distance functions</strong> are a different way to define a shape.
Instead of using a hardcoded if statementÙ« instead you define a <strong>function</strong>
that tells youÙ« for any point in the worldÙ« how far away that point is from
your shape. For exampleÙ« here&rsquo;s a signed distance function for a sphere.</p>

<pre><code>float sdSphere( vec3 pÙ« float center )
{
  return length(p)-center;
}
</code></pre>

<p>Signed distance functions are awesome because they&rsquo;re:</p>

<ul>
<li>simple to define!</li>
<li>easy to compose! You can take a union / intersection / difference with some simple math if you want a sphere with a chunk taken out of it.</li>
<li>easy to rotate / stretch / bend!</li>
</ul>

<h3 id="the-steps-to-making-a-spinning-top">the steps to making a spinning top</h3>

<p>When I started out I didn&rsquo;t understand what code I needed to write to make a shiny spinning thing. It turns out that these are the basic steps:</p>

<ol>
<li>Make a signed distance function for the shape I want (in my case an octahedron)</li>
<li>Raytrace the signed distance function so you can display it in a 2D picture
(or raymarch? The tutorial I used called it raytracing and I don&rsquo;t
understand the difference between raytracing and raymarching yet)</li>
<li>Write some code to texture the surface of your shape and make it shiny</li>
</ol>

<p>I&rsquo;m not going to explain signed distance functions or raytracing in detail in this post
because I found this <a href="https://www.shadertoy.com/view/Xl2XWt">AMAZING tutorial on signed distance functions</a> that is very
friendly and honestly it does a way better job than I could do. It
explains how to do the 3 steps above and the code has a ton of comments and it&rsquo;s great.</p>

<ul>
<li>The tutorial is called &ldquo;SDF Tutorial: box &amp; balloon&rdquo; and it&rsquo;s here: <a href="https://www.shadertoy.com/view/Xl2XWt">https://www.shadertoy.com/view/Xl2XWt</a></li>
<li>Here are tons of signed distance functions that you can copy and paste into your code <a href="http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm">http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm</a> (and ways to compose them to make other shapes)</li>
</ul>

<h3 id="step-4-copy-the-tutorial-code-and-start-changing-things">step 4: copy the tutorial code and start changing things</h3>

<p>Here I used the time honoured programming practice here of &ldquo;copy the code and change things in a chaotic way until I get the result I want&rdquo;.</p>

<p>My final shader of a bunch of shiny spinny things is here: <a href="https://www.shadertoy.com/view/wdlcR4">https://www.shadertoy.com/view/wdlcR4</a></p>

<p>The animation comes out looking like this:
<div align="center">
<img src="https://jvns.ca/images/octahedron2.gif" width="150px">
</div></p>

<p>Basically to make this I just copied the tutorial on signed distance functions that renders the shape based on the signed distance function and:</p>

<ul>
<li>changed <code>sdfBalloon</code> to <code>sdfOctahedron</code> and made the octahedron spin instead of staying still in my signed distance function</li>
<li>changed the <code>doBalloonColor</code> colouring function to make it shiny</li>
<li>made there be lots of octahedrons instead of just one</li>
</ul>

<h3 id="making-the-octahedron-spin">making the octahedron spin!</h3>

<p>Here&rsquo;s some the I used to make the octahedron spin! This turned out to be
really simple: first copied an octahedron signed distance function from <a href="http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm">this
page</a>
and then added a <code>rotate</code> to make it rotate based on time and then suddenly
it&rsquo;s spinning!</p>

<pre><code>vec2 sdfOctahedron( vec3 currentRayPositionÙ« vec3 offset ){
    vec3 p = rotate((currentRayPosition)Ù« offset.xyÙ« iTime * 3.0) - offset;
    float s = 0.1; // what is s?
    p = abs(p);
    float distance = (p.x+p.y+p.z-s)*0.57735027;
    float id = 1.0;
    return vec2( distanceÙ«  id );
}
</code></pre>

<h3 id="making-it-shiny-with-some-noise">making it shiny with some noise</h3>

<p>The other thing I wanted to do was to make my shape look sparkly/shiny. I used
a noise funciton that I found in <a href="https://gist.github.com/patriciogonzalezvivo/670c22f3966e662d2f83">this github gist</a> to
make the surface look textured.</p>

<p>Here&rsquo;s how I used the noise function. Basically I just changed parameters to
the noise function mostly at random (multiply by 2? 3? 1800? who knows!) until
I got an effect I liked.</p>

<pre><code>float x = noise(rotate(positionOfHitÙ« vec2(0Ù« 0)Ù« iGlobalTime * 3.0).xy * 1800.0);
float x2 = noise(lightDirection.xy * 400.0);
float y = min(max(xÙ« 0.0)Ù« 1.0);
float y2 = min(max(x2Ù« 0.0)Ù« 1.0) ;
vec3 balloonColor = vec3(y Ù« y  + y2Ù« y  + y2);
</code></pre>

<h3 id="writing-shaders-is-fun">writing shaders is fun!</h3>

<p>That&rsquo;s all! I had a lot of fun making this thing spin and be shiny. If you also want to
make fun animations with shadersÙ« I hope this helps you make your cool thing!</p>

<p>As usual with subjects I don&rsquo;t know tha wellÙ« I&rsquo;ve probably said at least one
wrong thing about shaders in this postÙ« let me know what it is!</p>

<p>AgainÙ« here are the 2 resources I used:</p>

<ol>
<li>&ldquo;SDF Tutorial: box &amp; balloon&rdquo;: <a href="https://www.shadertoy.com/view/Xl2XWt">https://www.shadertoy.com/view/Xl2XWt</a> (which is really fun to modify and play around with)</li>
<li>Tons of signed distance functions that you can copy and paste into your code <a href="http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm">http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm</a></li>
</ol>
'),('https://inessential.com/2020/08/21/worrying_effect', 'Worrying Effect', '1598052177000',  7, '<p>The WordPress app for iOS is a free and open source app that doesnâ€™t sell anything â€”Â but AppleÙ« reportedlyÙ« <a href="https://www.theverge.com/2020/8/21/21396316/apple-wordpress-in-app-purchase-tax-update-store">made the publisher change it so that it sells custom domain names</a> via IAPÙ« with the standard 30% cut going to Apple.</p>

<p>So now (or soon) the app <em>will</em> sell things.</p>

<p>Hereâ€™s where the worry turns personal for meâ€¦</p>

<p>NetNewsWire for iOS is a free and open source app that doesnâ€™t sell anythingÙ« but it <em>does</em> let you use your Feedbin or Feedly account for syncing.</p>

<p>Will I be asked to add IAP to NetNewsWire for purchasing Feedbin and Feedly accounts? It doesnâ€™t sound like that much of a stretch right now.</p>

<p>Thatâ€™s not exactly whatâ€™s happening with the WordPress appÙ« but itâ€™s pretty closeÙ« and barriers just seem to get crossed these days.</p>

<p style="text-align:center">* * *</p>

<p>Somebody on Twitter will tell me that I <em>should</em> add that IAP right now so I can pay Apple for the privilege of being on the App Store. Fuck you in advance.</p>

<p style="text-align:center">* * *</p>

<p>Related question: how is the PR hit to Apple worth it for the money theyâ€™ll make through these WordPress IAP sales? And: how is developer fear a good thing for the platform?</p>'),('https://inessential.com/2020/08/20/netnewswire_5_1d3_with_feedly_syncing', 'NetNewsWire 5.1d3 with Feedly Syncing', '1597979334000',  7, '<p><a href="https://nnw.ranchero.com/2020/08/20/netnewswire-d-early.html">Itâ€™s a very early test build</a> â€”Â it may annoy you; it may eat all your ripe heirloom tomatoes; it may dump all your trash on the lawn and set it on fire.</p>

<p>I appreciate your testingÙ« but I donâ€™t actually recommend it. Waiting is better.</p>'),('https://inessential.com/2020/08/15/desktop_means_web', 'Desktop Means Web', '1597527622000',  7, '<p>Iâ€™ve learned something that I suspect is true across much of our industry: the list of platforms in the world is iOSÙ« AndroidÙ« and desktop.</p>

<p>And â€” this is critical â€”Â <em>desktop</em> literally means <em>web</em>. (It could mean something like Electron wrapping a websiteÙ« but thatâ€™s pretty much the same thing.)</p>

<p>I thought the list of platforms looked like this:</p>

<ul>
  <li>Web</li>
  <li>Desktop (native MacÙ« WindowsÙ« Linux)</li>
  <li>iOS</li>
  <li>Android</li>
</ul>

<p>But it looks like this:</p>

<ul>
  <li>Desktop (web)</li>
  <li>iOS</li>
  <li>Android</li>
</ul>

<p>â€¦andÙ« reallyÙ« in many placesÙ« it looks like this:</p>

<ul>
  <li>Desktop (web)</li>
  <li>Mobile (some WORA thing that gets you iOS and Android apps)</li>
</ul>

<p>(YesÙ« for some placesÙ« TV is also a platform. The various voice-based devices are platforms too. There may also be a mobile web thing. But these are side notes compared to desktop and mobile.)</p>

<p style="text-align:center">* * *</p>

<p>Iâ€™ve also seen the word <em>surface</em> used oftenÙ« and itâ€™s not the same thing as a platform. iOS and Android are separate surfaces â€”Â and Safari on a Mac is a separate surface fromÙ« sayÙ« Chrome on WindowsÙ« even though both are desktop app surfaces. I think <em>surface</em> means a runtime/device combination.</p>

<p style="text-align:center">* * *</p>

<p>There are some interestingÙ« at least to meÙ« implications of the above.</p>

<p>One is that there is no word that means what <em>desktop</em> used to mean â€”Â thereâ€™s no word for â€œnative MacÙ« WindowsÙ« and Linux apps.â€ Itâ€™s not a concept anymore.</p>

<p>Another is that the web sort of lost as a software platform on mobile. The web is for WindowsÙ« MacÙ« and Linux machines â€” itâ€™s the old way of things. For mobileÙ« itâ€™s all about the apps. But maybe the web didnâ€™t totally lose hereÙ« because often those apps are cross-platform affairs that run on web technologies.</p>

<p>PS One thing to take away: if youâ€™re writing or talking about <em>desktop</em> appsÙ« and you mean native MacÙ« WindowsÙ« and Linux appsÙ« then your audience may not understand you â€”Â because they think you mean web apps.</p>'),('https://inessential.com/2020/08/08/netnewswire_plans', 'invalid', '1596948267000',  7, '<p>I just posted our <a href="https://nnw.ranchero.com/2020/08/08/213416.html">current NetNewsWire plans</a> on the NetNewsWire blog. It talks about things like Feedly and iCloud syncingÙ« Big Sur user interface updatesÙ« and SwiftUI.</p>'),('https://inessential.com/2020/08/05/walking_home_from_school', 'Walking Home from School', '1596671402000',  7, '<p>I had a bad-luck schedule when I was a freshman in high school. My afternoon classes were all bunched up in one hallÙ« and that hall was at the far end of the school from my locker â€” too far to go between classes â€”Â so I had to carry all those books with me till end of day.</p>

<p>Which wasnâ€™t that bad. It was a big pile of textbooksÙ« but I could manage.</p>

<p>The problemÙ« thoughÙ« was that the hall with my classes was near where the school buses pulled upÙ« and my locker wasÙ« againÙ« at the far end of the school â€” as far away from the buses as it could be.</p>

<p>I couldnâ€™t skip going to my locker before catching my busÙ« since I might have books from morning classes that I needed to take home but that I couldnâ€™t carry all afternoon.</p>

<p>SoÙ« at the end of the dayÙ« Iâ€™d goÙ« with all those booksÙ« from near the busesÙ« to far away from the buses (where my locker was)Ù« to back to where the buses were.</p>

<p>But not always in time. In factÙ« <em>often</em> not in timeÙ« and Iâ€™d watch bus 62B pull away.</p>

<p style="text-align:center">* * *</p>

<p>This was a small town high school in the very northeast corner of MarylandÙ« far away from Baltimore and D.C. The distance from school to my home was â€” I just checked â€” 7.4 miles.</p>

<p>I had no option but to walk. There was nobody with a car available to come get meÙ« and if there wereÙ« they wouldnâ€™t have done it. So instead of getting home around 3:30Ù« I got home around 5:15.</p>

<p style="text-align:center">* * *</p>

<p>Though I wasnâ€™t eager toÙ« I did ask the vice principal â€”Â who happened to live in my development â€” about moving my locker so I wouldnâ€™t have to walk home. He told me there was nothing that could be doneÙ« and that I should just bringÙ« to my afternoon classesÙ« whatever I need to take home.</p>

<p>Which would have been okay adviceÙ« but my load really was excessiveÙ« and this wasnâ€™t going to work.</p>

<p style="text-align:center">* * *</p>

<p>Pretty soon I got smart: instead of walking home at the end of the dayÙ« Iâ€™d start walking home right after lunchÙ« and Iâ€™d get home even before the other neighborhood kids got home.</p>

<p>The walk was long â€” it must have been around two-and-a-half hours â€”Â but I didnâ€™t mind. I was all alone and happyÙ« at least in a wayÙ« walking on those empty roads.</p>

<p>Eventually I got in more trouble for cutting classesÙ« but what did that mean to me? I had been in nearly constant trouble at school since kindergarten.</p>

<p style="text-align:center">* * *</p>

<p>I envy the people who had a nice time at school. For me it was a struggle against stupidÙ« unfeeling power the entire time. I truly hated it. When I wasnâ€™t in troubleÙ« when I was actually sitting in classÙ« I was just watching the minute hand on the clockÙ« begging it to speed upÙ« minute by minute.</p>

<p>By my senior year I was the person in the school who skipped entire days the most. I stayed up late and slept way in lots of mornings.</p>

<p>Eventually I got suspended for smoking a cigarette without having filled out the paperwork.</p>

<p style="text-align:center">* * *</p>

<p>Well. This is just to say that I preferred being at homeÙ« where I was reading and writing and writing computer programs. Like now. ğŸ¥</p>'),('https://inessential.com/2020/07/30/the_overdog_lovers', 'The Overdog Lovers', '1596155319000',  7, '<p>You run into those fellas in life and online who will always explainÙ« for any situationÙ« why the big company is <em>right</em>.</p>

<p>If askedÙ« they will discuss their political and economic ideology. That ideologyÙ« theyâ€™ll explainÙ« is about reality and logic â€” it isnâ€™t some blanket defense of big companies. No way. It could just as easily defend small businesses and working people.</p>

<p>Exceptâ€¦ every single timeÙ« without failÙ« they side with the big company. And then you realize that theyâ€™re the overdog lovers. They cling to the big wealthy power and hate the underdogs. It would be nice if theyâ€™d just say so.</p>'),('https://inessential.com/2020/07/28/untrue', 'I Got Teed Off and Went on a Long Rant About This Opinion Piece on the App Store', '1595986060000',  7, '<p>Ed HardyÙ« writesÙ« in <a href="https://www.cultofmac.com/718559/app-store-regulation-apple-antitrust-opinion/">CongressÙ« keep your mitts off the App Store. Itâ€™s fine. [Opinion]</a>:</p>

<blockquote>
  <p>When Apple CEO Tim Cook takes questions from Congress on WednesdayÙ« heâ€™ll surely get an earful of software developersâ€™ complaints about how the App Store operates. Chief among the criticisms will likely be the fact that Apple charges a percentage of revenue earned from in-app sales.</p>
</blockquote>

<p>Itâ€™s not just a percentage of revenue from in-app purchases. Itâ€™s percentage of every paid upfront appÙ« too. And the percentage is 30% for most cases.</p>

<p>Hardy continues:</p>

<blockquote>
  <p>Thereâ€™s not a bit of justification for any of these highly publicized complaints. They come from companies that want to have their cake and eat itÙ« too.</p>
</blockquote>

<p>Thereâ€™s plenty of justification. If you offer a Mac app outside of the Mac App StoreÙ« you can expect to pay about 5% to your payment processor. This option is not permitted for people writing iPhone and iPad apps.</p>

<p>Itâ€™s incredibly dismissive to accuse companies of wanting to â€œhave their cake and eat itÙ« too.â€ What companies want is to be able to pay their people and keep making the things they think are cool or good.</p>

<p>The next section of Hardyâ€™s piece is called â€œThe App Store does business like a grocery store.â€ Butâ€¦</p>

<h4 id="the-app-store-does-not-do-business-like-a-grocery-store">The App Store does <em>not</em> do business like a grocery store</h4>

<p>Hardy writes:</p>

<blockquote>
  <p>â€¦take a trip to your local grocery store. Suppose itâ€™s a Kroger. Youâ€™ll find store brands â€” products made by Kroger â€” on the shelves next to products made by outside companiesÙ« like Procter &amp; Gamble. I hope youâ€™re not surprised that if you buy a Procter &amp; Gamble productÙ« Kroger takes a share of the revenue.</p>

  <p>Thatâ€™s exactly what Apple does with the App Store.</p>
</blockquote>

<p>If I make and distribute toothpasteÙ« I can offer the exact same product via KrogerÙ« SafewayÙ« and Albertsonâ€™s â€”Â and I could sell it from my own website and via Amazon.</p>

<p>Thatâ€™s a lot of choices I have for selling my product.</p>

<p>But if I write an iOS appÙ« I can sell it via the App Store <em>and through no other method</em>.</p>

<p>This is not at all how grocery stores work.</p>

<p>Hardy continues:</p>

<blockquote>
  <p>To be fairÙ« itâ€™s not just Spotify whoâ€™s complaining. The CEO of Epic Games (maker of Fortnite) <a href="https://www.cnbc.com/2020/07/24/epic-games-ceo-tim-sweeney-apple-crippled-app-store-with-30percent-cut.html">whined about the App Store</a> just last week. And the developers of premium email app Hey engaged in a <a href="https://www.cultofmac.com/714231/email-startup-accuses-apple-of-behaving-like-gangsters-with-in-app-payment-demands/">very public spat with Apple</a> in JuneÙ« accusing Cupertino of acting like â€œgangsters.â€ But none of these companiesâ€™ criticisms hold up.</p>
</blockquote>

<p>For whatever reasonÙ« developers are often accused of being whiny. OhÙ« those whiny developers who like to have their cake and eat it too. How dare they complain about Apple policies. Betcha Iâ€™m being a whiny developer <em>right now</em>.</p>

<p>No. Again: developers want to make great apps and be able to continue making great apps.</p>

<p>Hardy:</p>

<blockquote>
  <p>To demonstrate whyÙ« letâ€™s continue with the grocery store analogy. Kroger built its store into a successful business. But suppose the companies who make the products sold in that store wanted to keep using itÙ« without sharing any of the revenue with Kroger. That would be completely unfair. Kroger is paying upkeep on the storeÙ« but these other companies donâ€™t want to contribute.</p>
</blockquote>

<p>Weâ€™ve demonstrated that itâ€™s not like a grocery store.</p>

<p>But letâ€™s talk about fair share.</p>

<p>Apple â€” certainly among the wealthiest of companies in human history â€”Â is taking 30% of developersâ€™ paychecks in order to show services growth. This is <em>not</em> about upkeep on the store: this is about profit for Apple. And not just profit but a specific category of profit.</p>

<p>And the rules arenâ€™t remotely fair. Facebook â€”Â another fabulously wealthy company â€” certainly profits from its iPhone app. Does it share any of this with Apple? No. InsteadÙ« apps from smaller developers (because they are almost all smaller than Facebook) are subsidizing Facebook.</p>

<p>If thereâ€™s a fair share to be paidÙ« the largest apps get away without paying it. InsteadÙ« companies like Omni subsidize Facebook. Fair?</p>

<p style="text-align:center">* * *</p>

<p>The next section is called â€œSelfish developers want to use the iPhone ecosystem without paying their share.â€</p>

<p>This is total bullshit and insulting. (Developers are always whiny <em>and</em> selfishÙ« of course.)</p>

<p>This isnâ€™t about paying a share into some commons run for all of our benefit. Apple isnâ€™t just asking for us to help cover costs.</p>

<p>No.</p>

<p>This is the only game in town for iPhone and iPad developersÙ« and we have no choice but to subsidize apps like Facebook. We have no choice but to contribute to Appleâ€™s services growth.</p>

<p>Hardy:</p>

<blockquote>
  <p>Of courseÙ« the analogy isnâ€™t perfectÙ« because it underplays Appleâ€™s role. It didnâ€™t just build a grocery store â€” it built the entire town. There would be nowhere for Spotify and the rest to sell their products if the iPhone never existed.</p>
</blockquote>

<p>This is kind of the thing with platforms. There would be nowhere for Spotify to sell their iPhone app if there were no such things as iPhones. True.</p>

<blockquote>
  <p>The major reason these software developers have a business is because Apple makes iPhones that people carry with them everywhere. Without themÙ« thereâ€™d be no Spotify. <em>Fortnite</em> would be a PC-only game.</p>
</blockquote>

<p>I think the argument here is thatÙ« without AppleÙ« the smart phone revolution wouldnâ€™t have happened so quickly. That may be true! But itâ€™s not argument in favor of Appleâ€™s 30% cut.</p>

<p>Hardy:</p>

<blockquote>
  <p>These companies love to play on the idea that a 30% share of revenue is an egregious price to pay to be on the App Store. HoweverÙ« a recent study found  that Appleâ€™s percentage <a href="https://www.analysisgroup.com/globalassets/insights/publishing/apples_app_store_and_other_digital_marketplaces_a_comparison_of_commission_rates.pdf">falls in line with other software stores</a> (.pdf). And Procter &amp; Gamble wouldnâ€™t blink to hear that Kroger charges 30% extra for one of its products.</p>
</blockquote>

<p>All of the various app stores are charging too much. They all point to Apple as precedent.</p>

<p style="text-align:center">* * *</p>

<p>The next section is called â€œConsumers benefit hugely from the App Store.â€</p>

<p>In some waysÙ« sure. Itâ€™s also worth remembering that the more money Apple takes from developersÙ« the fewer resources developers have. When developers have to cut costsÙ« they stop updating appsÙ« skimp on customer supportÙ« put off hiring a graphic designerÙ« etc. They decide not to make apps at all that they might have made were it easier to be profitable.</p>

<blockquote>
  <p>Suppose the House Judiciary antitrust subcommittee â€” where Apple CEO Cook will answer questions Wednesday (as will the leaders of FacebookÙ« Amazon and Google) â€” mistakenly thinks there is some justification for these developersâ€™ complaints. Regulations that forced Apple to change the way the App Store worked would benefit a few big-name software companiesÙ« but they would hurt hundreds of millions of Apple users.</p>
</blockquote>

<p>We have no way to know that â€”Â we donâ€™t know what that regulation would look like or who it would benefit.</p>

<p>I do not want to see Congress regulate app stores. I want Apple to make better choices here â€”Â better for AppleÙ« Apple customersÙ« and developers.</p>

<p>But if Congress lowers the cut to 10%Ù« or says that App Stores must allow for side-loadingÙ« itâ€™s hard to see how customers would be hurt.</p>

<p>(That said â€”Â againÙ« Iâ€™d really prefer not to see federal legislation. It shouldnâ€™t be needed.)</p>

<p>Hardy:</p>

<blockquote>
  <p>TrueÙ« Apple rules the App Store with an iron fist. While it sometimes acts in <a href="https://www.theverge.com/2020/6/17/21293813/apple-app-store-policies-hey-30-percent-developers-the-trial-by-franz-kafka">opaque and arbitrary ways</a>Ù« firmness is absolutely necessary in a world full of unethical developers whoâ€™d happily flood the App Store with crapware designed to steal user information. No one wants that.</p>
</blockquote>

<p>Developers: whinyÙ« selfishÙ« and unethical.</p>

<p>Any time I hear about iron fists and the necessity of firmnessÙ« in any contextÙ« I get pretty nervous. But letâ€™s set that aside.</p>

<p>App Store review is not filtering out apps that steal user information. No. This is done by sandboxing and other technical restrictions. Apps <em>canâ€™t</em> steal user information. Apple â€” to its immense credit (itâ€™s one of the things I love about Apple) â€” continues to lock this down.</p>

<p><a href="https://inessential.com/2020/06/21/the_app_store_doesnt_make_apps_safe">The App Store has nothing at all to do with it</a>Ù« though.</p>

<p>Hardy:</p>

<blockquote>
  <p>Letting companies avoid this process would release a wave of malware on iPhone users everywhere. In a world where everyoneâ€™s phones are networked togetherÙ« introducing another way for criminals to spread nefarious software is a horrible idea.</p>
</blockquote>

<p>This is horriblyÙ« terribly untrue. Again: the App Store doesnâ€™t prevent malware. Other technical limitationsÙ« built in to the platformÙ« prevent malware. Apple does a <em>great</em> job with this and deserves all kinds of credit.</p>

<p>The second sentence in Hardyâ€™s paragraph is just pure scare-mongering with no grain of truth.</p>

<p style="text-align:center">* * *</p>

<p>The next section is called â€œCupertino deserves its fair share.â€</p>

<p>Hardy:</p>

<blockquote>
  <p>Cupertino deserves a cut of the action for the hard work it does policing the App Store. (And donâ€™t forget about the enormous cost of operating and maintaining the servers that power this $519-billion-a-year economic engineÙ« to say nothing of building the software tools developers use to create apps for iOS and macOS.)</p>
</blockquote>

<p>Again: Apple isnâ€™t asking us to cover costs plus a little something extra â€”Â no. Apple considers revenue growth in services to be of paramount importanceÙ« and this is one if its favorite ways of making that services money.</p>

<p>This isnâ€™t about <em>fairness</em> at all. If it wereÙ« youâ€™d think Facebook might pay some share.</p>

<p>Apple doesnâ€™t â€œpoliceâ€ the App Store for the benefit of customers. Submissions are checked to be sure they adhere to Apple guidelines â€”Â in other wordsÙ« reviewers make sure that apps are making money in approved ways and giving Apple its cut.</p>

<blockquote>
  <p>Itâ€™s also understandable that software developers want customers to pay them directlyÙ« rather than sending payments through Apple. And admittedly the company does make exceptions for certain servicesÙ« like Amazon Prime VideoÙ« that bring customers to Appleâ€™s ecosystem.</p>

  <p>HoweverÙ« Cupertinoâ€™s general policy on payments means customers can feel safe shelling out for software and services within the Apple ecosystem. We know some shady firm wonâ€™t steal our credit card info. Even the best-intentioned companies get hackedÙ« and I trust Appleâ€™s network security far more than I do some random developerâ€™s.</p>
</blockquote>

<p>Again: this article mentions fairness a few timesÙ« and I hope itâ€™s clear by now that the App Store isnâ€™t exactly fair.</p>

<p>That thing about security and credit cards is more scare-mongering. If side-loading were allowedÙ« most developers would use reputable systems like Square and Stripe and so onÙ« where the developers never actually see credit card info at all.</p>

<p>(Developers areÙ« by the wayÙ« whinyÙ« selfishÙ« unethicalÙ« and <em>random</em>.)</p>

<blockquote>
  <p>Maybe Appleâ€™s 30% cut seems steep for digital products. ButÙ« as Ben BajarinÙ« head of consumer technologies at Creative StrategiesÙ« points outÙ« the <a href="https://www.reuters.com/article/us-usa-tech-congress-apple/app-store-chief-says-apple-aimed-to-level-playing-field-for-developers-idUSKCN24T1WY">App Store seemed like a bargain</a> to developers when it launched in 2008. At that timeÙ« developers typically surrendered 50% of the retail prices on software sold through physical stores. And small devs couldnâ€™t even gain a toehold.</p>
</blockquote>

<p>This is enormously untrue. I know because I was one of many small developers who were there.</p>

<p>We used Kagi as our payment processor at the timeÙ« and I think we paid around 5% for our storefront and payment processing and everything. Completely reasonableÙ« and we were perfectly happy with it.</p>

<p>We were also a two-person shopÂ â€” my wife and I â€”Â and you canâ€™t get much smaller than that. Did we gain a toehold? Hell yes! We did great!</p>

<p>There were a lot of small companies operating that way. Hardly any of us were selling boxes through retail stores in the 2000s â€” we were already selling over the web by the mid â€™90s.</p>

<p>Nobody saw this as a bargain. The developers I knew â€”Â small developers with nice toeholds! â€” were shocked and astonishedÙ« because we were used to paying 5-10%.</p>

<blockquote>
  <p>Perhaps Apple should shave a few percentage points off its take from App Store revenues to keep everyone (including Congress) happy. But third-party developers absolutely should pay a share of their revenue to support the iPhone ecosystem. Everyone benefits from itÙ« including the companies that are whining. They just donâ€™t want to admit it.</p>
</blockquote>

<p>The traditional way of supporting a platform is to write good apps for that platform. Thatâ€™s it. A platform with more and better apps will attract more people to that platform. (Itâ€™s not the only thingÙ« but itâ€™s a real thing.)</p>

<p>But Hardy â€” and AppleÙ« apparently â€”Â has forgotten that simple truth.</p>

<p>And they havenâ€™t realized that current App Store policies actually <em>hurt</em> the situation: we donâ€™t have the quantity and quality of apps we should have. Which hurts that very ecosystem.</p>'),('https://inessential.com/2020/07/22/apples_thirty_percent_cut', 'Appleâ€™s Thirty Percent Cut', '1595466874000',  7, '<p>Developers will often tell you that Appleâ€™s 30% cut isnâ€™t the worst thing about the App StoreÙ« and that itâ€™s actually far down the list.</p>

<p>True. Theyâ€™re right.</p>

<p>But itâ€™s worth remembering that money really does matter. Say youâ€™re making $70K per year as a salaryÙ« and someone asks if youâ€™d like a raise to $90K. You say yes! Because that extra $20K makes a real difference to you and your family.</p>

<p>To an app on the App Store it might mean being able to lower prices â€”Â or hire a designer or a couple junior developers. It might be the difference between abandoning an app and getting into a virtuous circle where the app thrives.</p>

<p>Quality costs moneyÙ« and profitability is just simple arithmetic: anything that affects income â€” such as Appleâ€™s cut â€” goes into that equation.</p>

<p>To put it in concrete terms: the difference between 30% and something reasonable like 10% would probably have meant some of my friends would still have their jobs at OmniÙ« and Omni would have more resources to devote to makingÙ« testingÙ« and supporting their apps.</p>

<p>But AppleÙ« this immensely rich companyÙ« needs 30% of Omniâ€™s and every single other developerâ€™s paycheck?</p>'),('https://inessential.com/2020/07/20/when_i_was_a_kid_i_put_all_of_my_hopes_o', 'invalid', '1595279922000',  7, '<p>When I was a kidÙ« I put all ofÂ my hopes on finding a 1955 double die penny.</p>'),('https://inessential.com/2020/07/20/i_keep_noticing_that_people_say_they_fel', 'invalid', '1595266346000',  7, '<p>I keep noticing that people say they â€œfelt okayâ€ about whatever they did. It was â€œjust their grandkidsâ€ or â€œpretty much everyone was wearing masksâ€ or â€œit seemed like they were being carefulâ€ or whatever.</p>

<p>The hospitals are full of people who felt fine about things.</p>'),('https://inessential.com/2020/07/15/zillion_times_easier', 'invalid', '1594853437000',  7, '<p>Reminder: itâ€™s a zillion times easier to hack Twitter and take over accounts of AppleÙ« Bill GatesÙ« Jeff BezosÙ« Joe BidenÙ« and others than it would be to hack their separate websites.</p>

<p>Distributed systems are safer.</p>'),('https://inessential.com/2020/07/11/blind_leading_blind', 'On â€œthe blind leading the blindâ€', '1594513479000',  7, '<p>Local Seattle developer and good friendÂ Olof Hellman finds the phrase â€œthe blind leading the blindâ€ problematicÙ« and <a href="https://olof.micro.blog/2020/07/11/the-blind-leading.html">he writes</a>:</p>

<blockquote>
  <p>Let your guide take you to Pike Place Market and taste the coffee and the piroshky and the crumpets and the nectarines and the chowder. Let your guide take you to the Olympic Sculpture ParkÙ« to hear the city and the train tracks and the ferry and the the wind curling around Alexander Calderâ€™s EagleÙ« and taste the air from the Sound and feel the full force of the sunset. Let your guide take you to Sake Nomi where Johnnie will pour you a flight of Junmai Daiginjoshu and treat you like the Nomidachi regulars.</p>
</blockquote>

<p>That right there is why we wish Olof would write every day.</p>'),('https://inessential.com/2020/07/11/imagining_swiftdata', 'Imagining SwiftData', '1594502977000',  7, '<p>If SwiftUI and Combine are the newÙ« Swifty V and C in MVCÙ« whereâ€™s the M?</p>

<p>I keep thinking that Core DataÙ« amazing as itâ€™s beenÙ«Â is part of NeXT-world AppleÙ« and weâ€™re due for a Swift data model framework.</p>

<p>Instead of defining your model in a schema editor (a la Core Data)Ù« youâ€™d use a Swift DSL â€”Â which would be nice because you wouldnâ€™t have to keep the schema and your model code in sync. It would be just one thing.</p>

<p>It would use (or at least allow for) value types over reference types. It would use protocols instead of inheritance. It would play perfectly well with Combine.</p>

<p>It might not even use SQLite â€” I can imagine Apple creating a storage system more purpose-built. It might be built with syncing in mind <em>first</em> rather than as afterthought.</p>

<p>I have no inside knowledge. And maybe this is just wishful thinking. But it surely seems to me that something like the above should be coming â€”Â it would be weird if notÙ« I think. Maybe next year?</p>'),('https://inessential.com/2020/07/11/imagining_an_open_source_swiftui', 'Imagining an Open Source SwiftUI', '1594494020000',  7, '<p>Swift is open source and is used in more places than just Mac and iOS apps â€” itâ€™s now appearing in places like <a href="https://swift.org/blog/aws-lambda-runtime/">AWS Lambda</a>Ù« for instance.</p>

<p>But SwiftUI is not open source. At least not yet.</p>

<p>As a developer who uses SwiftUIÙ« Iâ€™d sure <em>like</em> to see it made open source. I think there might be a good reason beyond just thatÙ« thoughÂ â€” an open source SwiftUI could be made to work on other platforms.</p>

<p>Somebody would have to actually do that workÙ« of course. But imagine that work has been doneÙ« and you can write SwiftUI code that runs on the webÙ« AndroidÙ« WindowsÙ« and Linux as well as on Apple devices.</p>

<p>Right now people are using web technologies and things like Electron to do cross-platform apps. Andâ€¦ itâ€™s not greatÙ« and itâ€™s hard to imagine Apple likes this situation. At all.</p>

<p>If SwiftUI makes it easier to make apps that work across Apple platforms onlyÙ« thatâ€™s nice but not enough: the future will still belong to web wrappers like Electron.</p>

<p>The reason for that is simple. Apps cost a lot of money to makeÙ« and every additional platform costs yet more money.</p>

<p>The people who make the decisions on what to use arenâ€™t generally the people who care about things like platform differences and performance. Those folks want to get the most bang for their buckÙ« and so theyâ€™ll do whatâ€™s cheapest. Especially if you canâ€™t <em>prove</em>Ù« with dataÙ« the benefits of a native app over something like Electron (or other web wrapper).</p>

<p>(Bless those people. They are not Philistines as a rule â€”Â itâ€™s just that they take their responsibilities seriouslyÙ« as they should. Theyâ€™re doing their job.)</p>

<p>But what if you could come to those people with an alternative â€”Â SwiftUI (and Combine) â€”Â and tell them that it will run everywhereÙ« and that itâ€™s at least as cheap as a web wrapperÙ« and that it creates high-quality native apps?</p>

<p>That would be cool. I have no idea if thatâ€™s how people at Apple are thinking. But I hope they are.</p>'),('https://inessential.com/2020/07/03/apple_privacy_changes', 'Apple Privacy Changes', '1593822288000',  7, '<p>I was actually surprised at the changes Apple is making to stop tracking. Itâ€™s not enough to stop tracking on the webÙ« and itâ€™s not enough to stop tracking in iOS apps â€”Â which is happening probably way more than you think it is â€”Â so Apple did <em>both</em>.</p>

<p>While I know that Apple takes privacy seriously in a way other large tech companies donâ€™tÙ« I still didnâ€™t expect them to go this far. Iâ€™m glad they did.</p>

<p>My pet theory is that this set of changes is the most important thing to come from WWDC this year. These privacy changes willÙ« I thinkÙ« have far more impact on the tech industryÙ« on societyÙ« and on our livesÙ« than SwiftUI or a new processor for Macs or anything like that. (As fun as those things are.)</p>

<p>Itâ€™s always going to be an arms raceÙ« I suppose â€”Â see this <a href="https://www.kochava.com/apple-announcements-at-wwdc-2020-challenge-marketers-to-tap-alternative-marketing-solutions/">press release from Kochava</a>:</p>

<blockquote>
  <p>Options exist to perform identity resolution using hashed-email-to-device linkagesÙ« device connections by householdÙ« and other first-party identifiers key in solving for identity resolution and attribution.</p>

  <p>[â€¦]</p>

  <p>Further scarcity of the IDFA forces greater reliance on attribution by fingerprinting. Fingerprinting is a probabilistic method of attribution based on device IP &amp; user agent thatâ€™s less precise than deterministic attribution based on the globally unique IDFA. NonethelessÙ« a high degree of accuracy is still maintainable with fingerprintingâ€¦</p>
</blockquote>

<p>IDFA stands for â€œidentifier for advertisers.â€ One of the changes Apple is making is that when an iOS app asks for the IDFAÙ« the system will ask the user to consent to being tracked. When consent is not givenÙ« the IDFA will just be a string of zeros.</p>

<p>Itâ€™s self-evident that pretty much everyone will say noÙ« which makes the IDFA useless. App makers will want to avoid even the shame of asking for consent.</p>

<p>Kochava is saying â€”Â and Iâ€™m betting theyâ€™re not the only company saying this â€”Â that theyâ€™ll find a way around the IDFApocalypse to identify users. They will probably succeedÙ« tooÙ« at least to a certain degree.</p>

<p>HoweverÙ« Apple has shown that it has a mandate to fightÙ« and the willÙ« and it doesnâ€™t mind dropping down some very large technical hammers to protect our privacy.</p>

<p style="text-align:center">* * *</p>

<p>Itâ€™s important to note â€”Â before people get stigmatized unfairly â€”Â that most of the tracking and metrics collected by various websites and apps is done so with innocent motives. Marketers want to know which campaigns are more effective; they want to get the most bang for their buck. Product designers want to know which features are more popular; they want to know whatâ€™s working for people and what isnâ€™t. Publishers want to know which pages people visit and how they got there. Engineers â€” like me â€” want to be warned of potential problems.</p>

<p>Thereâ€™s nothing wrong with wanting those things! The people who want those things arenâ€™t trying to snoop on people or anything â€”Â theyâ€™re using data to do their jobs better.</p>

<p>The problem is that the tech industryÙ« in order to serve these needsÙ« did what it always does: code up the thingÙ« take the biggest bite it canÙ« and hope to make enough moneyÙ« and amass enough powerÙ« to be able to repel any future ethical distractions. So now we have mass surveillance.</p>

<p>But Apple recognizes that thereâ€™s still a need to knowÙ« for instanceÙ« which of your ad campaigns is doing best â€”Â and so thereâ€™s <a href="https://developer.apple.com/documentation/storekit/skadnetwork">SKAdNetwork</a>Ù« which is a thing I donâ€™t totally understand yetÙ« but I get that it answers marketing questions in the aggregate (which is all marketers should want) and doesnâ€™t violate privacy.</p>

<p>I like that Apple knows that itâ€™s not enough to just shut down the bad actors â€”Â people who have questions to answerÙ« but who have no interest in violating privacyÙ« need solutions.</p>

<p>PS See the WWDC 2020 video <a href="https://developer.apple.com/videos/play/wwdc2020/10676/">Build trust through better privacy</a> for way more about all this.</p>'),('https://inessential.com/2020/07/02/i_had_been_worried_about_the_mac', 'I Had Been Worried About the Mac', '1593746366000',  7, '<p>I spent the month or so before WWDC like you â€”Â suffering through a pandemicÙ« outraged by violent racismÙ« worried about democracy. Heartsick and appalledÙ« mad and sad.</p>

<p>Nothing has changed since WWDCÙ« either. Except for one thing. A small thing in comparisonÙ« but important to me â€” I had been very worried that Apple wouldÙ« as part of the ARM transitionÙ« lock down macOS so that <em>only</em> Mac App Store apps would be permitted.</p>

<p>That didnâ€™t happen. And Apple employees explained that itâ€™s not going to happen â€”Â andÙ« given that it didnâ€™t happen this timeÙ« given that they had this chanceÙ« I believe them.</p>

<p>I understand adding security features to the Mac. But to take away our freedom to create whatever Mac apps we wantÙ« and distribute them without Appleâ€™sÙ« or anyoneâ€™sÙ« seal of approvalÙ« would be to take the heart out of my career.</p>

<p>But thatâ€™s not what happened! I feel great about this. Iâ€™m going to stop worrying about the Mac.</p>

<h4 id="the-new-way-of-making-apps">The New Way of Making Apps</h4>

<p>Iâ€™m excited about the new features in SwiftUI this year. This reminds me of the early 2000s when I switched from writing Mac Toolbox apps to Cocoa apps. It was a whole new way of writing appsÙ« and it was <em>so much better</em>.</p>

<p>I jumped right on itÙ« back then â€” and I feel no less enthusiastic for this <em>new</em> new thing than I did for Cocoa almost 20 years ago.</p>

<p>Apple has essentially saidÙ« I believeÙ« that the way weâ€™ve been making apps is all legacy. AppKit and UIKit both. SwiftUI is the future.</p>

<h4 id="netnewswire-and-swiftui">NetNewsWire and SwiftUI</h4>

<p>We re-jiggered the NetNewsWire roadmap somewhat.</p>

<ul>
  <li>Mac/iOS 5.0.x: bug fix releases</li>
  <li>Mac 5.1: FeedlyÙ« feature parity with iOS</li>
  <li>Mac/iOS 5.5: iCloud syncÙ« other integrations and features</li>
  <li>Mac/iOS 6.0: SwiftUIÙ« features tbd</li>
</ul>

<p>The thing to call out here is NetNewsWire 6.0. Weâ€™re already at work building a SwiftUI app where Mac and iOS share as much UI code as possible.</p>

<p>The work is going very quickly: Iâ€™m amazed. If you want to follow alongÙ« or even helpÙ« take a look at the <a href="https://github.com/Ranchero-Software/NetNewsWire/tree/swiftui">swiftui branch</a>.</p>

<p>Iâ€™m super-psyched for this. If it means Mac and iOS can share most of their codeÙ« and we can add features more quickly (because SwiftUI makes for so much faster development)Ù« then we can ship more and better versions of NetNewsWire more often. I want that!</p>'),('https://inessential.com/2020/07/02/reporting_in_after_more_than_a_month_at_', 'Reporting in After More Than a Month at Audible', '1593735648000',  7, '<p>Iâ€™ve been reluctant to write about how my new job is going â€” I donâ€™t want to look like the guy who drank the kool-aidÙ« and I certainly donâ€™t want to be the guy who couldnâ€™t read the room during our new multi-crisis normal.</p>

<p>ButÙ« maybeÙ« some good newsÙ« even if for just one fortunate personÙ« is okay to write about? Iâ€™m not even sure. But some of my friends have suggested I write it upÙ« so I am.</p>

<p style="text-align:center">* * *</p>

<p>Anyway. Itâ€™s going well! I love the job and the people and what we do.</p>

<p>Telling stories by way of human voice is among the most elemental and powerful of artsÙ«Â and I believe that stories transform lives. My work at Audible is motivated by the same thing in me that makes me make NetNewsWire (an RSS reader)Ù« that made me create MarsEdit (a blog editor)Ù« that makes me write this blog.</p>

<p>Audible acts like a company with a mission. It seems like every company claims solidarity and support these daysÙ« and most of these claims are shallow and opportunistic. But Audible is committed to revitalizing NewarkÙ« NJ â€” from hiring locallyÙ« to <a href="https://www.audible.com/about/community/newark-working-kitchens/">Newark Working Kitchens</a>Ù« to <a href="https://www.audible.com/about/community/newark-venture-partners/">Newark Venture Partners</a>Ù« and plenty more â€”Â and itâ€™s helpingÙ« for real. This is not some new face for the current moment: itâ€™s part of the companyâ€™s DNA and history.</p>

<p>And if you read the <a href="https://www.audible.com/blog">Audible blog</a>Ù« youâ€™ll find that the company is dedicated to bringing us the stories that need telling and that urgently need to be heard.</p>

<p>Itâ€™s a good place thatâ€™s doing goodÙ« and I am proud to work there.</p>

<p style="text-align:center">* * *</p>

<p>Iâ€™m on iOS. Iâ€™m senior enough not to be embedded in a scrum teamÙ« but Iâ€™m an individual contributorÙ« not a manager. My jobÙ« broadly speakingÙ« is to help the team increase velocity and quality. (My job isnâ€™t strictly limited to iOSÙ« but thatâ€™s where my focus is.)</p>

<p>My first month was spent meeting people (over video; via Amazon Chime) and learning things. The largest company Iâ€™ve ever worked at had about 100 people: Audible is much larger â€”Â 20 times larger? Iâ€™m totally just guessing â€”Â and that means Iâ€™ve had to learn about the ways of large companies. (Also remember that Amazon is part of thisÙ« usually in the background.)</p>

<p>Iâ€™m starting to be able to contribute a little â€”Â just recently I committed my first code. In any given month I might be writing a ton of codeÙ« or hardly anyÙ« or somewhere in between. While writing code is importantÙ« my job is more about things likeÂ architecture and best practices â€”Â itâ€™s about finding ways to make the team better.</p>

<p>My background leading the NetNewsWire open source project is very relevant here. I learnedÙ« while running the NetNewsWire projectÙ« that people will rally to a higher standard if you can show them that itâ€™s possible to reach it and then lead them there.</p>

<p>During my first month I felt like a detective from an Agatha Christie bookÙ« interviewing people and taking notes â€”Â What happened? How did we get here? What the heck is an ASIN? Those were the easy things to learnÙ« and the hard lessonsÙ« where I learn how to take my experience and help lead us to that higher standardÙ« are to come.</p>

<p>But thatâ€™s also the challenge! And the fun. Itâ€™s why I signed up.</p>

<p style="text-align:center">* * *</p>

<p>I love this job every day except when I have to get up early due to time zone issues. Sheesh! (This happens just once or twice a monthÙ« seems likeÙ« so itâ€™s not at all bad. Itâ€™s fine. But I Am Not a Morning Person.)</p>

<p style="text-align:center">* * *</p>

<p>I havenâ€™t noticed that the people I work with have a lot of public social media presence. (Maybe I just havenâ€™t gotten clued-in yet?) But hereâ€™s <a href="https://twitter.com/XiphiasXVII">Jeff Merola</a>Ù« the engineer I work most closely with. Heâ€™s smarter than I amÙ« which is wonderful.</p>'),('https://inessential.com/2020/07/01/accessibility_and_the_dynamic_nature_of_', 'Accessibility and the Dynamic Nature of Objective-C', '1593665280000',  7, '<p>Doug RussellÙ« who used to work on accessibility at AppleÙ« <a href="http://www.takingnotes.co/blog/2020/07/01/accessibility-engineering/">writes</a>:</p>

<blockquote>
  <p>some of the code that powers accessibility on apple platforms is just disgusting to look at and to work on.</p>

  <p>most of the code that makes apple software accessible lives in whatâ€™s called an accessibility bundle. without diving into the minutia of the thingÙ« bundles are a way to load something akin to a plugin into a cocoa app at runtime if an assistive technology is activated. it involves manipulating the app or framework class hierarchy and using objective-c dynamism to read app state and build up a usable accessibility hierarchy. insert a super class hereÙ« read an instance variable thereÙ« swizzle in a method and store the state for it in associated objects.</p>
</blockquote>

<p>In other words â€”Â Objective-C and its runtime play a big role in making Appleâ€™s great accessibility possible.</p>

<p>What happens when thatâ€™s not really a thing anymore?</p>'),('https://inessential.com/2020/06/25/work_at_universe', 'Work at Universe', '1593130486000',  7, '<p>When I was looking for a jobÙ« I talked with the folks at <a href="https://onuniverse.com/">Universe</a> a few times. I love what theyâ€™re doing â€”Â an iOS app that helps people make websites â€”Â and I really enjoyed talking with the team. Such a great bunch.</p>

<p>The good news is:Â theyâ€™re still hiring. They have a bunch of jobsÙ« even â€”Â iOSÙ« Swift backendÙ« databaseÙ« product designÙ« marketingÙ« and support. <a href="https://workatuniverse.com/">Check â€™em out!</a></p>

<p>PS Here are <a href="https://www.keyvalues.com/universe">their key values</a>.</p>'),('https://inessential.com/2020/06/24/somewhat_live_ish_and_around_the_same_ti', 'Somewhat Live-ish and Around the Same Time as WWDC', '1593019998000',  7, '<p>Youâ€™ll recall that James Dempsey does a benefit concert every year: Live Near WWDC.</p>

<p>WellÙ« this year itâ€™s not exactly live. <a href="https://jamesdempsey.net/live2020">But itâ€™s still happening</a>!</p>

<p>You may see me in the video. Wearing a Panama hat and dark shirt. Playing guitar and/or keyboards. But watch it anyway. ğŸ¥ğŸ¸</p>'),('https://inessential.com/2020/06/22/wwdc_2020_and_netnewswire', 'WWDC 2020 and NetNewsWire', '1592866790000',  7, '<p>I love seeing so much attention paid to the Mac this year!</p>

<p>Iâ€™ve applied for a Developer Transition Kit for NetNewsWire. My thinking: since NetNewsWire is open sourceÙ« other developers canÙ« and doÙ« look at the code to help them write Mac apps. The sooner we have NetNewsWire updatedÙ« the sooner itâ€™s available as an example for other developers.</p>

<p>Other thoughtsâ€¦</p>

<p>The new Mac operating systemÙ« Big SurÙ« big number 11Ù« Onze-y-babyÙ« has some appearance and behavior changes which of course weâ€™ll adopt. One of NetNewsWireâ€™s values has always been to stick pretty close to Appleâ€™s design for the platform. We do that becauseÙ« wellÙ« we figure users of a given platform actually <em>like</em> the platform designÙ« and thatâ€™s why they picked it. (It also tends to mean less workÙ« which is a good thing.)</p>

<p>Weâ€™ll not be switching to Catalyst. It appears to be much-improvedÙ« but standards for a good Mac app are highÙ« and Iâ€™m skeptical that Catalyst is all the way there yet.</p>

<p>InsteadÙ« our plan is to converge our UI code over time by using SwiftUI. This way we can go view-by-view. (Itâ€™s worth noting that we already do share some UI code: the article view is mostly sharedÙ« for instanceÙ« even without using SwiftUI or Catalyst.)</p>

<p>Iâ€™m looking forward to the rest of the week. I especially want to hear more about the new outline view in SwiftUI. ğŸ£ğŸ¥</p>'),('https://inessential.com/2020/06/21/the_app_store_doesnt_make_apps_safe', 'The App Store Doesnâ€™t Make Apps Safe', '1592768855000',  7, '<p>Another misconception about the App Store is that it makes apps secure and safe. It doesnâ€™t.</p>

<p>There are things that do make apps safe. No matter how an iOS app is distributedÙ« it runs in a sandbox. An app requires permission from the user to do things like access the address book or microphone. This is just how iOS works: it has nothing to do with the App Store.</p>

<p>The App Store review process probably does run some kind of automated check on the app to make sure itâ€™s not using private APIs and doesnâ€™t contain some kind of malware. HoweverÙ« this could be run as part of a notarization process â€” this doesnâ€™t have to be tied to the App Store. (Mac apps outside of the Mac App Store go through a notarization process.)</p>

<p>OtherwiseÙ« App Store review is looking for basic functionality and making sure the app follows the guidelines.</p>

<p>As far as checking that an app doesnâ€™t crash on launch â€” thanks? I guess? As for following the guidelines: the guidelines are about protecting Appleâ€™s interests and not about consumers.</p>

<p>I would like to say that the App Store filters out bad behaviorÙ« but I donâ€™t think it does. Weâ€™ve all seen various scam appsÙ« and weâ€™ve seen otherwise well-behaved apps do things like abuse the push notifications system.</p>

<p>It probably catches some egregious scams that we never hear about. Iâ€™ll apply the benefit of the doubt. But it didnâ€™t catch thatÙ« for instanceÙ« <a href="https://www.theverge.com/2012/2/7/2782947/path-ios-app-user-information-collected-privacy">Path was uploading the userâ€™s address book</a>. The community outside Apple catches these thingsÙ« and Apple changes how iOS works so that these things canâ€™t happen without user permission.</p>

<p>AndÙ« at the same timeÙ« the App Store is a <em>magnet</em> for scam apps. Even in a world where side-loading is possibleÙ« scam apps would stick to the App Store because thatâ€™s their best shot at getting users to stumble across them.</p>

<h4 id="my-grandmother">My grandmother</h4>

<p>People have asked if Iâ€™d want my grandmother to download iOS apps outside the App Store. The answer is yes. That was how she downloaded her Mac appsÙ« after all. (She was an avid Mac user.)</p>

<p>Iâ€™d feel secure knowing that the appsÙ« just by virtue of being iOS appsÙ« are sandboxed and have to ask for permissions. (Iâ€™m also imagining a Mac-like notarization stepÙ« for additional security. I think this is reasonable.)</p>

<p>In other words: Apple has done a very good job with iOS app security and safety. The fact that we think this has something to do with the App Store is a trickÙ« though.</p>

<p>(Iâ€™m not arguing for getting rid of the App StoreÙ« by the way. Iâ€™m arguing for allowing an alternative.)</p>'),('https://inessential.com/2020/06/20/the_ios_app_store_brings_users_only_beca', 'The iOS App Store Brings Users Only Because Itâ€™s the Only Choice', '1592689519000',  7, '<p>One might argue that developers should love the App Store because it brings the users.</p>

<p><a href="https://appleinsider.com/articles/20/06/20/app-store-policy-and-developer-fee-drama-wont-change-apples-ways-at-all">AppleInsider writes</a> about the App StoreÙ« Hey appÙ« and David  Heinemeier Hansson:</p>

<blockquote>
  <p>Like any other product or serviceÙ« Hey has to persuade people that they have a problem it can solveÙ« and that itâ€™s worth paying for. You canâ€™t persuade people of anythingÙ« thoughÙ« if they donâ€™t know about it. And then if you do persuade themÙ« you canâ€™t profit without a way to get your product into their hands.</p>

  <p>His first argument against the App Store on Appleâ€™s cut got Hansson and Hey a lot more notice than it might have. But itâ€™s the App Store that gets his product to people. Itâ€™s the App Store that means if he persuades people itâ€™s worth itÙ« they can instantly have it on their iOS device.</p>
</blockquote>

<p>This is a misconception that many people have â€”Â they think the App Store brings some kind of exceptional distribution and marketing that developers wouldnâ€™t have on their own.</p>

<p>Itâ€™s just not true. It lacks even a grain of truth.</p>

<p>Setting up distribution of an app is easy and cheap. I do it for NetNewsWire for Mac with no additional costs beyond what I already pay to host this blog. This was true in 2005 as much as now â€”Â distribution is <em>not</em> some exceptional value the App Store provides.</p>

<p>And then thereâ€™s marketing. SureÙ« being featured used to mean something to revenueÙ« but it hasnâ€™t meant that much beyond just ego points in years. To be on the App Store is to be lost within an enormous sea of floating junk. No matter how well you do at your app description and screenshots â€”Â even if you get some kind of feature â€”Â your app will not be found by many people.</p>

<p>Build it (and upload it to the App Store) and they will <em>not</em> come.</p>

<p>InsteadÙ« you have to do marketing on your ownÙ« on the web and on social mediaÙ« outside of the App Store. Just like always. The App Store brings nothing to the table.</p>

<p>So while itâ€™s true to say that all of an iOS appâ€™s users come via the App StoreÙ« itâ€™s only true because thereâ€™s no other option.</p>

<p>If I could distribute my iOS app outside of the App StoreÙ« I would. Iâ€™d switch in a heartbeat. Even though itâ€™s free and money isnâ€™t my issue. It would make my work as an app maker <em>easier</em>.</p>'),('https://inessential.com/2020/06/20/i_cant_reconcile_in_my_mind_the_tension_', 'invalid', '1592678867000',  7, '<p>I canâ€™t reconcile in my mind the tension between Apple as the think different companyÙ« the piratesÙ« the rebelsÙ« the company at the intersection of tech and liberal arts â€” and Apple the company that runs this legalisticÙ« nitpickyÙ« greedyÙ« inhumanÙ« happy-face Kafka App Store.</p>'),('https://inessential.com/2020/06/20/one_advantage_of_the_app_store_thats_gon', 'One Advantage of the App Store Thatâ€™s Gone', '1592677829000',  7, '<p>The best part of the App StoreÙ« years agoÙ« from this developerâ€™s point of viewÙ« was that it was easy to charge money for an app. No need to set up a system â€”Â just choose the priceÙ« and Apple takes care of everything. So easy!</p>

<p>But these daysÙ« in almost all casesÙ« youâ€™d be ill-advised to charge up front for your app. You need a trial version and in-app purchasing (IAP) and maybe a subscription.</p>

<p>Hereâ€™s the thing: this is a <em>massive</em> pain in the ass to implementÙ« testÙ« and support â€”Â Apple does <em>not</em> make it easy. It couldÙ« I thinkÙ« make certain common patterns basically turn-key (like trial versions + IAP)Ù« but it hasnâ€™t.</p>

<p>This means thatÙ« for many developersÙ« the very best thing about the App Store â€”Â the thing that actually helped their business â€”Â is gone.</p>

<p>And itâ€™s not just gone â€”Â itâ€™s probably actually <em>more</em> difficult doing this stuff via the App Store than doing the same things (trialÙ« IAPÙ« subscription) using non-Apple systems such as Stripe.</p>

<p>(AndÙ« as a bonusÙ« Stripe isnâ€™t going to review your appâ€™s business model and tell you no.)</p>'),('https://inessential.com/2020/06/06/reading_listening', 'ReadingÙ« Listening', '1591480824000',  7, '<p>Not for the first time â€”Â but hopefully with more depth and breadth this timeÙ« and greater understanding â€”Â Iâ€™m reading and listening to Black authors and voices.</p>

<p>Anti-racism book recommendations are just a search away. Hereâ€™s one I <a href="https://chipublib.bibliocommons.com/list/share/204842963/1357692923">found on the Chicago Public Libraryâ€™s site</a>.</p>

<p>Black Lives Matter.</p>'),('https://inessential.com/2020/05/18/why_netnewswire_is_fast', 'Why NetNewsWire Is Fast', '1589847295000',  7, '<p>NetNewsWire is fast because performance is one of our core values. <em>Being fast</em> is part of the very definition of the app.</p>

<p>I suspect that itâ€™s hard to do this any other way. If you take a month or two to speed things upÙ« from time to timeÙ« your app will always be â€”Â at best â€” just kind of heading toward satisfactoryÙ« but never to arrive.</p>

<p>The best general advice I can give is just this: make sure performance is part of the foundation of your app. Make sure itâ€˜s part of every decision every day.</p>

<p>Make sureÙ« in other wordsÙ« that performance isnâ€™t just a topping â€”Â itâ€™s the pizza.</p>

<p>Below are some of the specific reasons NetNewsWire is fast. Because NetNewsWire is â€” like many apps these days â€”Â basically a fancy database browser where data comes from the webÙ« some of these will apply to other apps.</p>

<p>The below items are in no particular order.</p>

<h4 id="fast-rss-and-atom-parsing">Fast RSS and Atom Parsing</h4>

<p>The most painful way to parse XML is with a SAX parser â€” but itâ€™s also how youâ€™ll get the best performance and use the least memory. So we use SAX in our <a href="https://github.com/Ranchero-Software/RSParser">RSParser framework</a>.</p>

<p>On my 2012 iMacÙ« parsing a local copy of some past instance of the Daring Fireball Atom feed â€”Â relatively large at 112K in size â€”Â happens in 0.009 seconds.</p>

<p>Thatâ€™s fastÙ« but we do another thing as well: run the parser in the background on a serial queue. Since parsing is a self-contained operation â€”Â we input some data and get back objects â€”Â there are no threading issues.</p>

<h4 id="conditional-get-and-content-hashes">Conditional GET and Content Hashes</h4>

<p>The parsers are fast â€” but we also do our best to skip parsing entirely when we can. There are two ways we do that.</p>

<p>We use <a href="https://fishbowl.pastiche.org/2002/10/21/http_conditional_get_for_rss_hackers">conditional GET</a>Ù« which gives the server the chance to respond with a 304 Not ModifiedÙ« and no contentÙ« when a feed hasnâ€™t changed since the last time we asked for it. We skip parsing in this caseÙ« obviously.</p>

<p>We also create a hash of the raw feed content whenever we download a feed. If the hash matches the hash from the last timeÙ« then we know the content hasnâ€™t been modifiedÙ« and we skip parsing.</p>

<h4 id="serial-queues">Serial Queues</h4>

<p>The parser isnâ€™t the only code we run on a serial queue. When an operation can be made self-contained â€”Â when it can just do a thing and then call back to the main threadÙ« without threading issues â€”Â we use a serial queue if thereâ€™s any chance it could noticeably block the main thread.</p>

<p>The key isÙ« of courseÙ« making sure your operations are in fact self-contained. They shouldnâ€™t trigger KVO or other kinds of notifications as they do their work.</p>

<p>(A simple example of a background thingÙ« besides feed parsingÙ« is creating thumbnails of feed icons.)</p>

<h4 id="we-avoid-the-single-change-plus-notifications-trap">We Avoid the Single-Change-Plus-Notifications Trap</h4>

<p>Hereâ€™s an example of a trap thatâ€™s easy to fall into. Say a user is marking an article as read. Calling <code>article.read = true</code> triggersÙ« via KVO or notifications or somethingÙ« things like database updatesÙ« user interface updatesÙ« unread count updatingÙ« undo stack maintenanceÙ« etc.</p>

<p>Now say youâ€™re marking all articles in the current timeline as read. You could call <code>article.read = true</code> for each article â€”Â andÙ« for each articleÙ« trigger a whole bunch of work. This can be veryÙ« very slow.</p>

<p>We have specific APIs for actions like thisÙ« and those APIs expect a collection of objects. The same API that marks a single article as read is used to mark 10Ù«000 articles as read. This way the database is updated onceÙ« the unread counts are updated onceÙ« and we push just one action on the undo stack.</p>

<h4 id="coalescing">Coalescing</h4>

<p>We also try to coalesce other kinds of work. For instanceÙ« during a refreshÙ« the app could recalculate the unread count on every single change â€”Â but this could mean a ton of work.</p>

<p>SoÙ« insteadÙ« we coalesce these â€”Â we make it so that recalculating unread counts happens not more often than once every 0.25 seconds (for instance). This can make a huge difference.</p>

<h4 id="custom-database">Custom Database</h4>

<p>For an app that isÙ« againÙ« just a fancy database browserÙ« this is where the whole thing can be won or lost.</p>

<p>While Core Data is greatÙ« we use SQLite more directlyÙ« via <a href="https://github.com/ccgus/fmdb">FMDB</a>Ù« because this gives us the ability to treat our database as a database. We can optimize our schemaÙ« indexesÙ« and queries in ways that are outside the scope of Core Data. (Remember that Core Data manages a graph of objects: itâ€™s not a database.)</p>

<p>We use various tools â€”Â such as <a href="https://sqlite.org/eqp.html">EXPLAIN QUERY PLAN</a> â€”Â to make sure weâ€™ve made fetchingÙ« countingÙ« and updating fast and efficient.</p>

<p>We do our own caching. We run the database on a serial queue so we donâ€™t block the main thread. We use structs instead of classesÙ« as much as possibleÙ« for model objects. (Not sure that matters to performance: we just happen to like structs.)</p>

<p>To make searching fastÙ« we use SQLiteâ€™s <a href="https://www.sqlite.org/fts5.html">Full Text Search extension</a>.</p>

<p>I couldÙ« and probably shouldÙ« write more articles going into details here. The database workÙ« more than anything elseÙ« is why NetNewsWire is fast.</p>

<h4 id="sets-and-dictionaries">Sets and Dictionaries</h4>

<p>We often need to look up things â€”Â a feedÙ« given its feedIDÙ« for instance â€”Â and so we use dictionaries frequently. This is quite common in Mac and iOS programming.</p>

<p>What I suspect is less common is use of <em>sets</em>. The set is our default collection type â€”Â we never want to check to see if an array contains somethingÙ« and we never want to deal with duplicate objects. These can be performance-killers.</p>

<p>We use arrays when some API requires an array or when we need an ordered collection (usually for the UI).</p>

<h4 id="profiler">Profiler</h4>

<p>Instead of guessing at whatâ€™s slowÙ« we use the profiler in Instruments to find out exactly whatâ€™s slow.</p>

<p>The profiler is often surprising! Hereâ€™s one thing we found that we didnâ€™t expect: hashing some of our objects wasÙ« at one pointÙ« pretty slow.</p>

<p>Because we use sets quite a lotÙ« thereâ€™s a whole lot of hashing going on. We were using synthesized equality and hashability on some objects with lots of string properties â€”Â andÙ« it turns outÙ« hashing strings is pretty darn slow.</p>

<p>SoÙ« insteadÙ« we wrote our own hash function for these objects. In many cases we could hash just one string property â€”Â an article IDÙ« for instance â€”Â instead of five or ten or more.</p>

<h4 id="no-stack-views">No Stack Views</h4>

<p>My experience with stack views tells me that theyâ€™re excruciatingly slow. Theyâ€™re just not allowed.</p>

<h4 id="no-auto-layout-in-table-cell-views">No Auto Layout in Table Cell Views</h4>

<p>When people praise a timeline-based app like NetNewsWireÙ« they often say something like â€œIt scrolls like butter!â€ (I imagine butter as not actually scrolling well <em>at all</em>Ù« butÙ« yesÙ« I get that butter is smooth.)</p>

<p>While we use Auto Layout plenty â€”Â itâ€™s coolÙ« and we like it â€”Â we donâ€™t allow it inside table cell views. InsteadÙ« we write our own layout code.</p>

<p>This is not actually difficult. Maybe a little tediousÙ« but laying out a table cell view is pretty easyÙ« really.</p>

<p>I figure that optimized manual layout code is always going to be faster than a constraint solverÙ« and that gives us an edge in smooth scrolling â€”Â and this is one of the places where an otherwise good app can fall on its face.</p>

<p>And: because that layout code doesnâ€™t need a view (just an article object and a width)Ù« we can run it at any time. We use that same code to determine the height of rows without having to run an Auto Layout pass.</p>

<h4 id="caching-string-sizes">Caching String Sizes</h4>

<p>Text measurement is slow â€”Â slow enough to make even manual layout too slow. In NetNewsWire we do some smart things with <a href="https://inessential.com/2019/07/26/a_couple_handy_tricks_for_text_measureme">caching text measurement</a>.</p>

<p>For example: if we know that a given string is 20pts tall when the available width is 100 and when the available width is 200Ù« we can tellÙ« without measuringÙ« that it will be 20pts tall when the available width is 150.</p>

<h4 id="summary">Summary</h4>

<p>Thereâ€™s no silver bullet. Making an app fast means doing a bunch of different things â€”Â and it means paying attention to performance continuously. ğŸ•</p>'),('https://inessential.com/2020/05/18/default_feeds_are_okay', 'Default Feeds Are Okay', '1589840102000',  7, '<p>I just heard that the default feeds in NetNewsWire are okay as-isÙ« and I donâ€™t need to collect permissions for Apple.</p>

<p>Great! Iâ€™m so pleased.</p>

<p>(This is a follow-up to <a href="https://inessential.com/2020/05/10/heads_up_to_rss_reader_authors">Heads-Up to RSS Reader Authors</a> and <a href="https://inessential.com/2020/05/11/more_on_the_default_feeds_issue">More on the Default Feeds Issue</a>.)</p>'),('https://inessential.com/2020/05/17/focusing', 'Focusing', '1589756453000',  7, '<p>Tomorrowâ€™s the first day at <a href="https://inessential.com/2020/05/12/my_new_job">my new job</a>. Exciting!</p>

<p>Starting a new job has led me to look at my entire list of responsibilities â€”Â which is too long â€”Â and figure out what I need to drop so that I can pay enough attention to the projects that need it most.</p>

<p>My most important projects (outside of my job) are NetNewsWire and this blog. This blogÙ« becauseÙ« wellÙ« blogging is part of how I breathe. And NetNewsWire because I love the app â€”Â and itâ€™s a real thing in the world nowÙ« with usersÙ« a team of developersÙ« and great features coming up.</p>

<p>I wanted to do another half-dozen or so apps alongside NetNewsWireÙ« starting with RainierÙ« but Iâ€™m dropping development on those so I can concentrate entirely on NetNewsWire. This is personally disappointingÙ« but itâ€™s honest: I just donâ€™t have time for Rainier and these other apps. Work on these would take away from NetNewsWireÙ« and that would be wrong.</p>

<p>Another move Iâ€™m making: <a href="https://www.manton.org/">Manton Reece</a> has agreed to take over the <a href="https://github.com/brentsimmons/JSONFeed">repo</a> and website for <a href="https://jsonfeed.org/">JSON Feed</a>. Iâ€™ve been the bottleneck here with a 1.1 versionÙ« and I shouldnâ€™t be. Manton will take care of this way better than Iâ€™ve been able to. (I hope to get everything transferred over to Manton in the next few weeks.)</p>'),('https://inessential.com/2020/05/12/my_new_job', 'My New Job', '1589305777000',  7, '<p>As of this morning the ink is all dryÙ« and I can happily report that my new job is at <a href="https://www.audible.com/">Audible</a>. Iâ€™ll be an architect on the mobile team.</p>

<p>Iâ€™m very excited for this job! Itâ€™s perfect for me in so many ways â€”Â not least that itâ€™s about <em>books</em>.</p>

<p>My plan is for this to be my last job â€”Â I plan to work at Audible until I retire. I start Monday. ğŸ£ğŸ¥ğŸ•¶</p>'),('https://inessential.com/2020/05/12/netnewswire_5_0_1_for_ios_released', 'NetNewsWire 5.0.1 for iOS Released', '1589305072000',  7, '<p><img class="centeredImage" src="https://ranchero.com/netnewswire/images/NNW-iOS-Icon-Shadow.png" height="256" width="256" alt="" /></p>

<p>While Iâ€™ve been job-huntingÙ« the mighty NetNewsWire team has kept rolling â€”Â and today we published the first update to the iOS app.</p>

<p>This update fixes bugsÙ« makes the app fasterÙ« and adds polish. Read the (rather lengthy) <a href="https://nnw.ranchero.com/2020/05/12/netnewswire-for-ios.html">change notes</a> for the full scoop.</p>

<p>We did add one new feature: on the settings screen you can choose which color palette to use: go with the current system setting or specify light or dark.</p>

<p>If youâ€™re already running NetNewsWireÙ« it should update in the normal way. If you havenâ€™t tried it yetÙ« go get it â€”Â for free â€” <a href="https://apps.apple.com/us/app/netnewswire-rss-reader/id1480640210">on the App Store</a>.</p>'),('https://inessential.com/2020/05/12/my_mac_app_store_debate', 'My Mac App Store Debate', '1589302426000',  7, '<p>The question of publishing NetNewsWire on the Mac App Store wonâ€™t be decided until the minute that itâ€™s actually published there.</p>

<p>If it ever isÙ« that is. I go back and forth on it.</p>

<p>Hereâ€™s the thing to remember: our goal is to get as many people using RSS readers as possible. Period. Keep this goal in mind.</p>

<h4 id="seems-obvious">Seems Obvious</h4>

<p>Publishing on the Mac App Store would meanÂ that some people would see the app who might never have seen it otherwise.</p>

<p>There are also people whoÙ« due to personal or workplace policyÙ« download apps only from the Mac App Store.</p>

<p>Publishing on the Mac App Store seems like a no-brainerÙ« then. Weâ€™d get more people using RSS readers â€” weâ€™d further our goal.</p>

<p>But itâ€™s not so simple.</p>

<h4 id="trade-offs">Trade-offs</h4>

<p>As with everything elseÙ« there are trade-offs. There are costs and benefits.</p>

<p>The benefit is reaching more people. There are several costs.</p>

<p>Some are right up front: weâ€™d have to sandbox the app and test it. Weâ€™d have to do a set of screenshots for the Mac App Store; weâ€™d have to write the description text for the page.</p>

<p>But I donâ€™t mind one-time costs that much when thereâ€™s a solid benefit.</p>

<p>There are ongoing costsÙ« though: weâ€™d have <em>two</em> configurations of the Mac appÙ« one for the Mac App Store and one for direct downloadÙ« and weâ€™d have continue to maintain and test both. This is kind of a painÙ« but not terrible.</p>

<h4 id="the-real-cost">The Real Cost</h4>

<p>Thereâ€™s a cost thatâ€™s worse than the technical and testing costs: I would have to deal personally with the stress and uncertainty of a second App Store. The NetNewsWire team is amazing and does a ton of great work â€”Â but the team canâ€™t do this part. Itâ€™s on me.</p>

<p>The <a href="https://inessential.com/2020/05/11/more_on_the_default_feeds_issue">issue with the default feeds</a> reminds me thatÙ« at any timeÙ« even for a small bug-fix updateÙ« App Store review may decide that an app canâ€™t be published as-is for some reason.</p>

<p>Youâ€˜d be right to think thatÙ« with an issue like thisÙ« it would come up the same on both App Stores â€”Â solve it in one place and youâ€™ve solved it in both. Itâ€™s not like Iâ€™d have double the issues.</p>

<p>But sometimes the issue actually <em>is</em> platform-specific. For example: <a href="https://inessential.com/2011/03/02/the_return_of_netnewswire_lite">NetNewsWire Lite 4.0</a> for Mac was held up by Mac App Store review for three weeks due to a bug in WebKit. (YesÙ« this was nine years ago.)</p>

<p>This is supposed to be fun. Itâ€™s work that I love doing for a great cause. And I just keep thinking that dealing with the iOS App Store is enough to ask of meÙ« and thereâ€™s no requirement that I go through this with the Mac App Store too. The personal cost is just too high.</p>

<h4 id="other-ways-to-achieve-our-goal">Other Ways to Achieve Our Goal</h4>

<p>We can achieve our goal in other ways: ship Feedly syncing on the MacÙ« ship iCloud syncing on both appsÙ« continue making the app more appealing to more people. Do more marketing.</p>

<p>In other wordsÙ« publishing on the Mac App Store is not the only lever we haveÙ« and Iâ€™m leaning toward just not doing it. At least not this year.</p>

<p>Weâ€™ve got otherÙ« better things to do â€”Â and Iâ€™ll enjoy those things a hell of a lot moreÙ« and I think you will too.</p>

<p>ğŸ£ğŸ¸</p>'),('http://yosefk.com/blog/dont-ask-if-a-monorepo-is-good-for-you-ask-if-youre-good-enough-for-a-monorepo.html', 'Don"t ask if a monorepo is good for you â€“ ask if you"re good enough for a monorepo', '1564435350000',  8, 'This is inspired by Dan Luu"s post on the advantages of a single big repository over many small ones. That post is fairly oldÙ« and I confess that I"m hardly up to date on the state of toolingÙ« both for managing multiple repos and for dealing with one big one. But I"m going to make [&#8230;]'),('http://yosefk.com/blog/patents-how-and-why-to-get-them.html', 'Patents: how and why to get them', '1527960166000',  8, 'I"m going to discuss 3 very basic things about patents: Why it"s good for you to get them; Why it might be bad for your employer (and why they don"t care); How to get a patent for your idea (doesn"t matter which.) Some of my points are a bit naughty. But I maintain that they"re [&#8230;]'),('http://yosefk.com/blog/things-want-to-work-not-punish-errors.html', 'Things want to workÙ« not punish errors', '1488147456000',  8, 'For better or worseÙ« things want to work. ConsiderÂ driving at night on unlitÙ« curvy mountain roadsÙ« at a speed about twice the limitÙ« zigzagging between carsÙ« including oncoming ones. Obviously dangerousÙ« and yet manyÂ do thisÙ« and survive. How? Roads and cars are built with big safety margins Other drivers don"t want to die and help [&#8230;]'),('http://yosefk.com/blog/hiring-self-driving-algos-hll-compiler-research.html', 'Hiring (self-driving algosÙ« HLL compiler research)', '1473585113000',  8, 'OKÙ« so 2 things: 1. If you send me a CV and they"re hired to work on self-driving algos &#8211; machine vision/learning/mapping/navigationÙ« I"ll pay you a shitton of money. (Details over email.) These teams want CS/math/physics/similar degree with great gradesÙ« and they want programming ability. They"ll hire quite a lot of people. 2. The position [&#8230;]'),('http://yosefk.com/blog/fun-wont-get-it-done.html', 'Fun won"t get it done', '1470011029000',  8, 'OKÙ« published at 3:30 AM. That"s a first! So.Â Got something you want to do over the coarse of a year? Here"s aÂ motivation woefully insufficient to pull it off: It"s fun! What couldÂ give you enough drive to finish the job? Anything with a reward in the futureÙ« once you"re done: Millions of fansÂ will adore me. It [&#8230;]'),('http://yosefk.com/blog/the-habitat-of-hardware-bugs.html', 'The habitat of hardware bugs', '1468438443000',  8, 'I wrote a post on embeddedrelated.com about hardware bugs -Â places where they"re rarely to be foundÙ« places which theyÂ inhabit in large quantitiesÙ« and whyÂ these insects flourish in some places more than others. It"s one of these things that I wish I was told when I started to fiddle with this shit &#8211; that while a [&#8230;]'),('http://yosefk.com/blog/looking-for-senior-itdevops-people.html', 'Looking for senior IT/DevOps people', '1467307594000',  8, 'I wouldn"t spam you with these job offers if didn"t work :-) SoÙ« we"re looking for senior IT people to work at our Jerusalem offices &#8211; managers and hands-on people alike.Â We haveÂ rapid growthÙ« "Big Data" (it definitely is crash ExcelÂ -Â in factÙ«Â at one point it was close to physically crashing through the floorÂ due to the storage [&#8230;]'),('http://yosefk.com/blog/a-laymans-view-of-the-economy.html', 'A layman"s view of the economy', '1466784098000',  8, 'First of allÙ« I proudly present a 2-minute short that I animated! &#8230;And the same thing on YouTubeÙ« in case oneÂ loads betterÂ than the other: One thing I learned making the film is thatÂ myÂ Russian accent colors not only my wordsÙ« but any noise coming out of my mouth. So I"m not the mostÂ versatile voice actor. AnywayÙ« [&#8230;]'),('http://yosefk.com/blog/evil-tip-avoid-easy-things.html', 'Evil tip: avoid "easy" things', '1464780474000',  8, 'Now you see that evil will always triumphÙ« because good is dumb. &#8211; Dark Helmet EvildoersÂ live longer and feel better. &#8211; Myself MyÂ writing has recently prompted an anonymous commenter to declare that people likeÂ me areÂ what"s wrong with the world. Oh joy! &#8211; finallyÙ« after all these years of doing evilÙ« someÂ recognition!Â ExcitedÙ« I decided to share [&#8230;]'),('http://yosefk.com/blog/looking-for-a-functional-safetyiso-26262-expert-anywhere-on-the-globe.html', 'Looking for a functional safety/ISO 26262 expert (anywhere on the globe)', '1463654157000',  8, 'Unlike mostÂ positionsÂ mentioned hereÙ« this one includes the possibility of working remotely (certainly from Europe and I thinkÂ from elsewhereÙ« too)Ù« with occasional visits to Jerusalem. Functional safety experts with automotive experience are generally rare and in demandÙ« meaning that they"re probably gainfully employedÙ« and I"m not counting on one of them reading this blog. HoweverÙ«Â I imagine [&#8230;]'),('/blog/thoughts-on-lisps.html', 'The Many Faces of an Undying Programming Language', '1595250960000',  9, 'invalid'),('/blog/investigating-a-shellbot-aa-infection.html', 'Investigating a Backdoor.SH.SHELLBOT.AA Infection', '1579707780000',  9, 'invalid'),('/blog/browser-games-aren-t-an-easy-target.html', 'Browser Games Aren"t an Easy Target', '1578699540000',  9, 'invalid'),('/blog/first-impressions-of-the-myrddin-programming-language.html', 'First Impressions of the Myrddin Programming Language', '1578267480000',  9, 'invalid'),('/blog/challenges-re-writeups-4.html', 'Writeups for Dennis Yurichev"s Reverse Engineering Challenges (#36-#74)', '1577667300000',  9, 'invalid'),('/blog/challenges-re-writeups-3.html', 'Writeups for Dennis Yurichev"s Reverse Engineering Challenges (#23-#35)', '1566139320000',  9, 'invalid'),('https://www.gnu.org/software/guix/blog/2019/towards-guix-for-devops/', 'Towards Guix for DevOps', '1563048660000',  9, 'invalid'),('/blog/challenges-re-writeups-2.html', 'Writeups for Dennis Yurichev"s Reverse Engineering Challenges (#12-#22)', '1559071080000',  9, 'invalid'),('/blog/transition-to-haunt.html', 'Transitioning to Haunt', '1556942400000',  9, 'invalid'),('/blog/plaidctf-2019.html', 'Writeups for PlaidCTF 2019', '1555214400000',  9, 'invalid'),('/blog/challenges-re-writeups-1.html', 'Writeups for Dennis Yurichev"s Reverse Engineering Challenges (#2-#11)', '1552194000000',  9, 'invalid'),('/blog/first-impressions-of-the-kotlin-programming-language.html', 'First Impressions of the Kotlin Programming Language', '1545022800000',  9, 'invalid'),('/blog/slime-the-world-postmortem.html', 'Slime the World: A Postmortem', '1541161620000',  9, 'invalid'),('/blog/first-impressions-of-the-rust-programming-language.html', 'First Impressions of the Rust Programming Language', '1528477320000',  9, 'invalid'),('/blog/installing-gentoo-one-month-later.html', 'Installing Gentoo: One Month Later', '1527552600000',  9, 'invalid'),('/blog/decompilation-by-hand.html', 'Reverse Engineering By Hand', '1519948800000',  9, 'invalid'),('/blog/duke-on-fluidsynth.html', 'Duke on Fluidsynth', '1515895800000',  9, 'invalid'),('/blog/bad-behavior.html', 'Bad BEHAVIOR', '1515098700000',  9, 'invalid'),('/blog/backdoorctf-2017-funsignals.html', 'BackdoorCTF 2017: FUNSIGNALS', '1506268860000',  9, 'invalid'),('/blog/understand-game-hacking-in-one-post.html', 'Understand Game Hacking In One Post', '1504638360000',  9, 'invalid'),('https://technomancy.us/192', 'in which a compiler takes steps towards strapping its boots', '1593520217000',  10, '

<p>One of the biggest milestones in a programming language is when the
  language gets to the point where it can be used to write its own
  implementationÙ« which is
  called <a href="https://en.wikipedia.org/wiki/Self-hosting_(compilers)">self-hosting</a>. This
  is seen as a sign of maturity since reaching this point requires
  getting a lot of common problems shaken out first.</p>

<p>The compiler for the Fennel programming language was written using
  LuaÙ« and it emits Lua code as output. Over timeÙ« certain parts of the
  compiler were added that were written in FennelÙ« starting
  with <tt>fennelview</tt>Ù« which is the pretty-printer for Fennel
  data structures. Once the macro system stabilizedÙ« many built-in
  forms that had originally been hard-coded into the compiler using
  Lua got ported to the macro system. After that the REPL was ported
  to Fennel as a relatively independent piece of codeÙ« followed by the
  command-line launcher script and a helper module to explain and
  identify compiler errors. The parser had already seen
  <a href="https://gitlab.com/benaiah/fennel-the-book">an impressive
    port to Fennel</a> using a literate programming approachÙ« but we
  hadn"t incorporated this into the mainline repository yet because
  the literate approach made it a bit tricky to bring in.</p>

<p>As you might expectÙ« any attempt at self-hosting can easily run into
  "chicken or egg" problems&mdash;how do you use the language to write
  the implementation if the language hasn"t been finished being
  defined yet? Sometimes this requires simply limiting yourself to a
  subset; for instanceÙ« the built-in macros in Fennel cannot
  themselves use any macros but must be written in a macroless subset
  of Fennel. In other casesÙ« such as the launcherÙ« we keep a copy of
  the old pre-self-hosted version around in order to build the new version.</p>

<img src="/i/canal.jpg" alt="lake union/lake washington canal" >

<p>That"s about as far as we could get on the path to self-hosting
  without changing the approachÙ« because most of the remaining code was
  fairly entangledÙ« and we didn"t have clear boundaries to port it one piece
  at a time. At this stage there were 2250 lines of Lua and 1113 lines
  of Fennel. I recently took some time
  to <a href="https://github.com/bakpakin/Fennel/pull/297">reorganize
  the compiler</a> into four independent "pseudo-modules" with clear
  dependencies between the pieces. But even with the independent
  modules broken outÙ« we were still looking at porting 800 lines of
  intricate compiler code and 900 lines of special forms all in two
  fell swoops.</p>

<p>That"s when I started to consider an alternate approach. The Fennel
  compiler takes Fennel code as input and produces Lua code as output. We
  have a big pile of Lua code in the compiler that we want turned
  into Fennel code. What if we could reverse the process? That"s when
  <a href="https://git.sr.ht/~technomancy/antifennel/">Antifennel</a>
  was born.</p>

<pre class="code">(<span class="keyword">fn</span> <span class="variable-name">early-return</span> [compile {<span class="keyword">:</span> arguments}]
  (<span class="keyword">let</span> [args (map arguments compile)]
    (<span class="keyword">if</span> (any-complex-expressions? arguments 1)
        (early-return-complex compile args)
        (list (sym <span class="builtin">:lua</span>)
              (<span class="keyword">..</span> <span class="string">"return "</span> (<span class="type">table.concat</span> (map args view) <span class="string">"Ù« "</span>))))))

(<span class="keyword">fn</span> <span class="variable-name">binary</span> [compile {<span class="keyword">:</span> left <span class="keyword">:</span> right <span class="keyword">:</span> operator} ast]
  (<span class="keyword">let</span> [operators {<span class="builtin">:==</span> <span class="builtin">:=</span> <span class="string">"~="</span> <span class="builtin">:not=</span> <span class="string">"#"</span> <span class="builtin">:length</span> <span class="string">"~"</span> <span class="builtin">:bnot</span>}]
    (list (sym (<span class="keyword">or</span> (<span class="keyword">.</span> operators operator) operator))
          (compile left)
          (compile right))))</pre>

<p>Antifennel takes Lua code and parses[<a href="#fn1">1</a>] itÙ« then
  walks the abstract syntax tree of Lua and builds up an abstract syntax tree
  of Fennel code based on it. I had to add some features
  to <a href="https://git.sr.ht/~technomancy/fnlfmt">fnlfmt</a>Ù« the
  formatter for FennelÙ« in order to get the output to look decentÙ« but
  the overall approach is overall rather straightforward since Fennel
  and Lua have a great deal of overlap in their semantics.</p>

<p>The main difficulties came from supporting features which are
  present in the Lua language but not in Fennel. Fennel omits
  somethings which are normal in LuaÙ« usually because the code becomes
  easier to understand if you can guarantee certain things never
  happen. For instanceÙ« when you read a Fennel functionÙ« you don"t
  have to think about where in the code the possible return values can
  be found; these can only occur in tail positions because there is no
  early return. But Lua allows you to return (almost) anywhere in the
  function!</p>

<p>Fennel has one "secret" feature to help with this: the <tt>lua</tt>
  special form:</p>

  <pre class="code">(<span class="keyword">lua</span> <span class="string">"return nextStateÙ« value"</span>)</pre>

<p>Included specifically to make the task of porting existing code
  easierÙ« the <tt>lua</tt> form allows you to emit Lua code directly
  without the compiler checking its validity. This is an "escape
  hatch" that can allow you to port Lua code as literally as possible
  firstÙ« then come back once you have it working and clean up the ugly
  bits once you have tests and things in place. It"s not prettyÙ« but
  it"s a practical compromise that can help you get things done.</p>

<p>Unfortunately it"s not quite as simple as just calling <tt>(lua
    "return x")</tt>Ù« because if you put this in the output every time
  there"s a <tt>return</tt> in the Lua codeÙ« most of it will be in
  the tail position. But Fennel doesn"t understand that
  the <tt>lua</tt> call is actually a return value; it thinks that
  it"s just a side-effectÙ« and it will helpfully insert a <tt>return
    nil</tt> after it for consistency. In order to solve this I needed
  to <a href="https://git.sr.ht/~technomancy/antifennel/commit/baabd1dc9b610c28f65328324d9377309fd43ed2">track
    which returns occurred in the tail position and which were early
    returns</a>Ù« so I could use normal Fennel methods for the tail
  ones and use this workaround hack only for early returns[<a href="fn2">2</a>]. But that
  ended up being easier than it sounds.</p>

<p>Other incompatibilities were the lack of a <tt>break</tt> form
  (which could easily be addressed with the <tt>(lua "break")</tt>
  hack because it <em>only</em> happens in a non-tail position)Ù« the
  lack of <tt>repeat</tt> form (compiled into a <tt>while</tt> with
  a <tt>break</tt> at the end)Ù« and the fact that locals default to
  being immutable in Fennel and mutability is opt-in. This last one I
  am currently handling by emitting <em>all</em> locals
  as <tt>var</tt> regardless of whether they are mutated or notÙ« but I
  plan on adding tracking in to allow the compiler to emit the
  appropriate declaration based on how it"s used.</p>

<p>While it"s still too early to swap out the canonical implementation
  of the Fennel compilerÙ« the Antifennel-compiled version works
  remarkably wellÙ« passing the entire language test suite across every
  supported version of the Lua runtime at 79% the length of the Lua
  version. I"m looking forward to finishing the job and making the
  Fennel codebase written purely using Fennel itself.</p>

<hr>

<p>[<a name="fn1">1</a>] Antifennel uses the parser from
  the <a href="https://github.com/franko/luajit-lang-toolkit">LuaJIT
  Language Toolkit</a>Ù« which is another self-hosted compiler
  that takes Lua code as input and emits LuaJIT bytecode without
  requiring any C code to be involved. (Of courseÙ« in order to <em>run</em> the
  bytecodeÙ« you have to use the full LuaJIT VMÙ« which is mostly
  written in C.) I had to
  make <a href="https://git.sr.ht/~technomancy/antifennel/commit/c436ed1418acd1cecf63db41326617101688afa1">one
  small change</a> to the parser in order to help it "mangle"
  identifiers that were found to conflict with built-in special forms
  and macros in FennelÙ« but other than that it worked great with no
  changes. The first big test of Antifennel was making sure it could
  compile its own parser dependency from Lua into FennelÙ«
  which <a href="https://git.sr.ht/~technomancy/antifennel/commit/baabd1dc9b610c28f65328324d9377309fd43ed2">it
  could do on the second day</a>.</p>

<p>[<a name="fn2">2</a>] Even that is a slight oversimplificationÙ«
  because the <tt>lua</tt> return hack only works on literals and
  identifiersÙ« not complex expressions. When a complex expression is
  detected being returnedÙ« we compile it to a wrapping <tt>let</tt>
  expression and only pass in the bound local name to the <tt>return</tt>.</p>

'),('https://technomancy.us/191', 'in which we get socially rendered', '1574606561000',  10, '


<p>I joined <a href="https://en.wikipedia.org/wiki/Fediverse">the
    fediverse</a> in early 2017. If you haven"t heard of itÙ« it"s a
    distributed network providing social media type features without
    any one centralized authority. Users are in control of their dataÙ«
    and anyone can run their own servers with their own rulesÙ«
    including the ability to block all traffic from other servers if
    they tolerate abusive behaviorÙ« etc.</p>

<img src="i/icosahedron.png" alt="my profile" class="right">

<p>It took me a while to get to the point where I was comfortable on
  the Fediverse. I
  created <a href="https://icosahedron.website/@technomancy">an
    account</a> on the
  oddly-named <a href="https://icosahedronÙ«website">icosahedron.website</a>
  in AprilÙ« but it didn"t stick immediately. It didn"t feel like there
  was much going on because I hadn"t found that many users to
  follow. After a few months of poking my head aroundÙ« clicking around
  a bitÙ« and then forgetting about it for another few weeksÙ« I finally
  got enough momentum for it to be a compelling place for meÙ« and by
  November I stopped using my Twitter account altogether. I had felt
  since the 2016 US election that Twitter had spiraled into a worse
  and worse condition; the site felt engineered to drive more and
  more "engagement" at the expense of human misery. So making a clean
  break dramatically improved my mental well-being.</p>

<p>Even tho it makes a few things more complicated (like finding new
  users to follow[<a href="#fn1">1</a>])Ù« I deeply appreciate the emphasis on user
  empowerment that"s inherent in the design of the fediverse. One of the
  cornerstones of this empowerment is the ability to run your own
  fediverse serverÙ« or instance. The most common fediverse server software
  is <a href="https://joinmastodon.org">Mastodon</a>Ù« which could be
  considered the flagship of the fediverse. While it"s very slick and
  full-featuredÙ« a big downside of Mastodon is that it"s difficult to
  run your own server. Administering it requires running a Ruby on
  Rails application with Node.jsÙ« PostgresÙ« RedisÙ« NginxÙ«
  ElasticSearchÙ« and more. For servers which serve a medium-to-large
  communityÙ« this overhead can be justifiableÙ« but it requires a lot
  of mental energy to get started. There are a lot of places where
  things could go wrong.</p>

<p>The <a href="https://pleroma.social">Pleroma</a> project aims to
  reduce this by creating a dramatically simpler fediverse
  server. Running a Pleroma server requires just an Elixir
  applicationÙ« a Postgres databaseÙ« and Nginx to handle TLS. Since
  Elixir is a lot more efficient than RubyÙ« it"s even possible to run
  it on a low-powered machine like a Raspberry
  Pi[<a href="#fn2">2</a>]. I set up my own Pleroma server a few weeks
  ago at <a href="https://hi.technomancy.us">hi.technomancy.us</a>.
  It"s running on the Pi in the photo.</p>

<img src="i/pi-pleroma.jpg" alt="a raspberry pi and hard drive">

<p>One downside of Pleroma being simpler is that it"s really just an
  API server. All your interaction in the browser goes thru a separate
  Javascript application
  called <a href="https://git.pleroma.social/pleroma/pleroma-fe">pleroma-fe</a>Ù«
  and mobile clients like <a href="https://tusky.app/">Tusky</a> just
  hit the JSON API. The API-first design makes sense when you"re using
  the application to browseÙ« postÙ« searchÙ« etcÙ« but a big downside is that
  when you want to share a post with someone elseÙ« they have to load
  all of pleroma-fe just to see it. If you share it with someone who
  has scripting turned offÙ« then they"ll just see a blank white pageÙ«
  which is very unfriendly[<a href="#fn3">3</a>].</p>

<p>I wanted to start using PleromaÙ« but I wasn"t comfortable with this
  unfriendly behavior. I wanted it so that if I sent a link to a post
  to a friendÙ« the server would send them the HTML of
  the post![<a href="#fn4">4</a>] So I took a course of action I never could have
  taken with a centralizedÙ« commercial social network: I fixed it
  myself. I found that there had
  been <a href="https://git.pleroma.social/pleroma/pleroma/merge_requests/882">an
    attempt to start this 8 months ago</a> which had more or less been
  forgottenÙ« so I used that as my starting point.</p>

<p>Pleroma is written in <a href="https://elixir-lang.org">Elixir</a>Ù«
  which I had never used beforeÙ« but I had learned Erlang a few years
  agoÙ« and many of the core concepts are the same. Since I
  based <a href="https://git.pleroma.social/pleroma/pleroma/merge_requests/1917">my
    work</a> on the old initial sketchÙ« I was able to make quick
  progress and add several featuresÙ« like threadingÙ« mediaÙ« content
  warningsÙ« and more. I got some really helpful review about how to
  improve it and test itÙ« and it got merged a couple weeks ago. So now you
  can <a href="https://hi.technomancy.us/notice/9otSYoQwZAyokRBXcm">see
    it in action</a>. I"m thankful to the Pleroma developers for
  their helpful and welcoming attitude.</p>

<img src="/i/pleroma-screenshot.png" alt="pleroma screenshot" class="left">

<p>One of the reasons this is important to me is that I normally use
  <a href="/gear">a laptop that"s a bit old</a>. But I think it"s
  important for software developers to keep some empathy for users who
  don"t have the latest and greatest hardware. On my laptopÙ« using the
  pleroma-fe Javascript application to view a post takes eight
  seconds[<a href="#fn5">5</a>] if you haven"t already loaded
  pleroma-fe (which is the main use case for when you"re sharing a
  link with a friend). If you have it loaded alreadyÙ« it"s still 2-3
  seconds to load in pleroma-fe. When you have the server generate the
  HTMLÙ« it takes between 200 and 500 milliseconds. But 500ms is nearly
  a worst-case scenario since it"s running on a tiny Raspberry Pi
  server; on a high-end server it would likely be several times
  faster.</p>

<p>Running your own fediverse server is still much harder than it
  should be. I"ve glossed over the annoyances of Dynamic DNSÙ« port
  forwardingÙ« and TLS certificates. There"s still a lot of opportunity
  for this to become better. I have a vision of a system where you
  could sign up for a fediverse server and it would pre-generate an SD
  card image with PleromaÙ« PostgresÙ« and Nginx preinstalled and
  configured with the domain name of your choiceÙ« but right now
  shortcomings in typical consumer-grade routers and consumer ISPs
  make this impractical. But it"s come a long wayÙ« and I think it"s
  only going to get better going forward.</p>

<p>If you"re interested in running your own fediverse serverÙ« you
  might find <a href="https://runyourown.social/">runyourown.social</a>
  helpfulÙ« tho it focuses on Mastodon instead of Pleroma. If you"re
  not interested in running your own serverÙ« check
  out <a href="https://instances.social">instances.social</a> for a
  listing of servers with open registration. There"s never been a
  better time to ditch corporate social media and join the fediverse!</p>

<hr>

<div class="footnotes">

  <p>[<a name="fn1">1</a>] When people get started on the FediverseÙ«
    the first question is just "which server should I choose?" As
    someone who"s been around a whileÙ« it"s tempting for me to say "it
    doesn"t matter as long as you pick a place with a code of conduct
    that disallows abusive behavior; all the servers talk to each
    otherÙ« so you can follow any user from any server that hasn"t
    de-federated yours." The problem is this isn"t quite true due to
    the bootstrapping problem; when you"re trying to find interesting
    people to followÙ« you"ll have an easier time if you land on a
    server where people have interests that overlap with yours.</p>

  <p>In a distributed systemÙ« one server can"t know about every single
    user in the entire network; it"s just too big. So server A only
    knows about users on server B if someone from server A has already
    made a connection with a user on server B. Once you choose an
    serverÙ« your view of the network will be determined by the sum total
    of those followed by your server-mates.</p>

  <p>[<a name="fn2">2</a>] Just don"t make the same mistake I did and
    try to run Postgres on an SD card! I tried this initiallyÙ« and after
    a few days I started seeing unexplained segmentation fault loops
    from Postgres. Apparently this is common behavior when a disk
    failure corrupts the DB"s files. Moving everything over to an
    external USB drive made the problem go awayÙ« but it was certainly
    a surprise. Everything else can run on the SD card but the database.</p>

  <p>[<a name="fn3">3</a>] Note that this problem also occurs with
    Twitter. Mastodon is slightly betterÙ« but it still refuses to show
    you images or content-warnings without scripting.</p>

  <p>[<a name="fn4">4</a>] You used to be able to take this very basic
    behavior for grantedÙ« but since the arrival of the "single-page
    app"Ù« it has become some kind of ancient forgotten wisdom.</p>

  <p>[<a name="fn5">5</a>] Eight seconds sounds like a very slow
    application (and it is!) but it"s hardly the worst offender for
    single-page applications. Trello takes 10 secondsÙ« Jira takes 16
    secondsÙ« and Slack takes 18 seconds.</p>

</div>

'),('https://technomancy.us/190', 'in which another game is jammed', '1557283961000',  10, '


<p>All the <a href="https://technomancy.itch.io/bussard">games</a>
  <a href="https://technomancy.itch.io/liquid-runner">I"ve</a>
    <a href="https://technomancy.itch.io/goo-runner">created</a>
    <a href="https://technomancy.itch.io/exo-encounter-667">previously</a>
    have used the <a href="https://love2d.org">LÃ–VE</a> frameworkÙ«
    which I heartily recommend and have really enjoyed using. It"s
    extremely flexible but provides just the right level of
    abstraction to let you do any kind of 2D game. I have even
    created <a href="https://git.sr.ht/~technomancy/polywell">a text
    editor</a> in it. But for
    the <a href="https://itch.io/jam/lisp-game-jam-2019">2019 Lisp
    Game Jam</a> I teamed up again
    with <a href="https://emmabukacek.com">Emma Bukacek</a> (we first
    worked together
    on <a href="https://technomancy.itch.io/goo-runner">Goo Runner</a>
    for the previous jam) and wanted to try something
    new: <a href="https://tic.computer">TIC-80</a>.</p>

<p><img src="/i/tic80.gif" alt="tic-80 screenshot" /></p>

<p>TIC-80 is what"s referred to as a "fantasy
  console"<sup><a href="#fn1">1</a></sup>; that isÙ« a piece of
  software which embodies an imaginary computer which never actually
  existed. Hearkening back to the days of the Commodore 64Ù« it has a
  16-color paletteÙ« a 64kb limit on the amount of code you can load
  into itÙ« and 80kb of space for data (spritesÙ« mapsÙ« soundÙ« and
  music). While these limitations may sound severeÙ« the idea is that
  they can be liberating because there is no pressure to create
  something polished; the medium demands a roughÙ« raw style.</p>

<p>The really impressive thing about TIC-80 you notice right away is
  how it makes game development so accessible. It"s one file to
  download (or not even download; it runs perfectly fine in a browser)
  and you"re off to the races; the code editorÙ« sprite editorÙ« mapperÙ«
  sound editorÙ« and music tracker are all built-in. But the best part
  is that you can explore other people"s games (with the <tt>SURF</tt>
  command)Ù« and once you"ve played themÙ« hit ESC to open the editor
  and see how they did it. You can make changes to the codeÙ«
  spritesÙ« etc and immediately see them reflected. This kind of
  explore-and-tinker approach encourages you to experiment and see for
  yourself what happens.</p>

<p>In factÙ« try it now! Go
  to <a href="https://technomancy.itch.io/this-is-my-mech">This is my
  Mech</a> and hit <tt>ESC</tt>Ù« then go down to "close game" and
  press <tt>Z</tt> to close it. You"re in the console nowÙ« so
  hit <tt>ESC</tt> again to go to the editorÙ« and press the sprite
  editor button at the top left. Change some of the character spritesÙ«
  then hit <tt>ESC</tt> to go back to the console and
  type <tt>RUN</tt> to see what it does! The impact of the accessibility and
  immediacy of the tool simply can"t be overstated; it calls out to be
  hacked and fiddled and tweaked.</a>

<p>Having decided on the platformÙ« Emma and I threw around a few game
  ideas but landed on making an adventure/comedy game based on the
  music video <a href="https://m.youtube.com/watch?v=EMgsAD3D948">I"ll
  form the Head</a> by MC FrontalotÙ« which is in turn a parody of the
  1980s
  cartoon <a href="https://en.m.wikipedia.org/wiki/Voltron">Voltron</a>Ù«
  a mecha series about five different pilots who work together to form
  a giant robot that fights off the monster of the week. Instead of
  making the game about combatÙ« I wanted a theme of cooperationÙ« which
  led to a gameplay focused around dialog and conversation.</p>

<p><img src="/i/head.png" alt="I"ll form the head music video" width="800" /></p>

<p>I focused more on the coding and the artÙ« and Emma did most of the
  writing and all of the music. One big difference when coding on
  TIC-80 games vs LÃ–VE is that you can"t pull in any 3rd-party
  libraries; you have the Lua/Fennel standard libraryÙ«
  the <a href="https://github.com/nesbox/TIC-80/wiki#functions">TIC-80
  API</a>Ù« and whatever you write yourself. In factÙ« TIC-80"s code
  editor supports only a single file. I"m mostly OK with
  TIC-80"s limitationsÙ« but that seemed like a bit muchÙ« especially
  when collaboratingÙ« so I split out several different files and
  edited them in EmacsÙ« using a Makefile to concatenate them together
  and TIC-80"s "watch" functionality to load it in upon changes. In
  retrospectÙ« while having functionality organized into different files
  was niceÙ« it wasn"t worth the downside of having the line numbers
  be incorrectÙ« so I wouldn"t do that part again.</p>

<p>The file watch feature was pretty convenientÙ« but it"s worth noting
  that the changes were only applied when you started a new game. (Not
  necessarily restarting the whole TIC-80 programÙ« just
  the <tt>RUN</tt> command.) There"s no way to load in new code from a
  file without restarting the game. You <em>can</em> evaluate new code
  with the <tt>EVAL</tt> command in the console and
  then <tt>RESUME</tt> to see the effect it has on a running gameÙ« but
  that only applies to a single line of code typed into the consoleÙ«
  which is pretty limiting compared to LÃ–VE"s
  full <a href="/189">support for hot-loading any module from disk at
  any time</a> that I wrote about previously. This was the biggest
  disadvantage of developing in TIC-80 by a significant
  margin. Luckily our game didn"t have much stateÙ« so constantly
  restarting it wasn"t a big dealÙ« but for other games it would
  be.<sup><a href="#fn2">2</a></sup></p>

<p><b>Update</b>: I was able
  to <a href="https://github.com/nesbox/TIC-80/pull/840">add the above
    feature</a> with a small amount of codeÙ« and it was merged
  promptly. It will be included in TIC-80 version 0.80.0. You must
  launch the game with the <tt>-code-watch</tt> flag and run
  the <tt>RESUME</tt> command to activate it. In order to take
  advantage of this you need to store game state in a global and
  ensure not to overwrite that global if it already has a value.</p>

<p>Another minor downside of collaborating on a TIC-80 game is that
  the cartridge is a single binary file. You can set it up so it loads
  the source from an external fileÙ« but the rest of the game (spritesÙ«
  mapÙ« soundÙ« and music) are all stored in one place. If you use git
  to track itÙ« you will find that one person changing a sprite and
  another changing a music track will result in a conflict you can"t
  resolve using git. Because of thisÙ« we would claim a "cartridge
  lock" in chat so that only one of us was working on non-code assets
  at a timeÙ« but it would be much nicer if changes to sprites could
  happen independently of changes to music without conflict.</p>

<p><img src="/i/mech.gif" alt="screenshot of the game" /></p>

<p>Since the game consisted of mostly dialogÙ«
  the <a href="https://gitlab.com/emmabukacek/this-is-my-mech/blob/master/dialog.fnl">conversation
  system</a> was the central place to start. We used coroutines to
  allow a single conversation to be written in a linearÙ« top-to-bottom
  way and react to player input but still run without blocking the
  main event loop. For instanceÙ« the function below moves the Adam
  characterÙ« says a lineÙ« and then asks the player a question which
  has two possible responsesÙ« and reacts differently depending on
  which response is chosen. In the second caseÙ« it
  sets <tt>convos.Adam</tt> so that the next time you talk to that
  characterÙ« a different conversation will begin:</p>
  
<pre class="code">(<span class="keyword">fn</span> <span class="variable-name">all.Adam2</span> []
  (move-to <span class="builtin">:Adam</span> 48 25)
  (say <span class="string">"HeyÙ« sorry about that."</span>)
  (<span class="keyword">let</span> [answer (ask <span class="string">"What"s up?"</span> [<span class="string">"What are you doing?"</span>
                                  <span class="string">"Where"s the restroom?"</span>])]
    (<span class="keyword">if</span> (<span class="keyword">=</span> answer <span class="string">"Where"s the restroom?"</span>)
        (say <span class="string">"You can pee in your pilot suit; isn"t"</span>
             <span class="string">"technology amazing? Built-in"</span>
             <span class="string">"waste recyclers."</span>)
        (<span class="keyword">=</span> answer <span class="string">"What are you doing?"</span>)
        (<span class="keyword">do</span> (say <span class="string">"Well... I got a bit flustered and"</span>
                 <span class="string">"forgot my passwordÙ« and now I"m"</span>
                 <span class="string">"locked out of the system!"</span>)
            (<span class="keyword">set</span> <span class="type">convos.Adam</span> <span class="type">all.Adam25</span>)
            (<span class="type">all.Adam25</span>)))))</pre>

<p>There was some syntactic redundancy with the questions which could
  have been tidied up with a macro. In older versions of FennelÙ« the
  macro system is tied to the module systemÙ« which is normally fineÙ«
  but TIC-80"s single-file restriction makes it so that style of
  macros were unavailable. Newer versions of Fennel don"t have this
  restrictionÙ« but unfortunately the latest stable version of TIC-80
  hasn"t been updated yet. Hopefully this lands soon! The new version
  of Fennel also includes pattern matchingÙ« which probably would have
  made a custom question macro unnecessary.</p>

<p>The vast majority of the code is dialog/conversation code; the rest
  is for walking around with collision detectionÙ« and flying around in
  the end-game sequence. This
  is <a href="https://gitlab.com/emmabukacek/this-is-my-mech/blob/master/launch.fnl">pretty
    standard animation fare</a> but was a lot of fun to write!</p>

<p><img src="/i/rhinos.gif" alt="rhinos animation" /></p>

<p>I mentioned TIC-80"s size limit already; with such a dialog-heavy game
  we did run into that on the last day. We were close enough to the
  deadline with more we wanted to add that it caused a bit of a
  panicÙ« but all we had to do was remove a bunch of commented code
  and we were able to squeeze what we needed in. Next time around I would use
  single-space indents just to save those few extra bytes.</p>

<p>All in all I think the downsides of TIC-80 were well worth it for a
  pixel-art styleÙ« short game. Being able to publish the game to an
  HTML file and easily publish it
  to <a href="https://itch.io">itch.io</a> (the site hosting the jam)
  was very convenient. It"s especially helpful in a jam situation
  because you want to make it easy for as many people as possible to
  play your game so they can rate it; if it"s difficult to install a
  lot of people won"t do it. I"ve never done my own art for a game
  beforeÙ« but having all the tools built-in convinced me to give it a
  tryÙ« and it turned out pretty good despite me not having any
  background in pixel artÙ« or art of any kind.</p>

<p>AnywayÙ« I"d encourage you to give the game a try. The
  game <a href="https://itch.io/jam/lisp-game-jam-2019/results">won
  first place</a> in the game jamÙ« and you can finish it
  in around ten minutes in your browser. And if it looks like funÙ« why
  not make your own in TIC-80?</p>

<hr />

<p>[<a name="fn1">1</a>] The term "fantasy console" was coined
  by <a href="https://lexaloffle.com/pico-8.php">PICO-8</a>Ù« a
  commercial product with limitations even more severe than
  TIC-80. I"ve done a few short demos with PICO-8 but I much prefer
  TIC-80Ù« not just because it"s free softwareÙ« but because it supports
  FennelÙ« has a more comfortable code editorÙ« and has a much more
  readable font. PICO-8 only supports a fixed-precision decimal fork
  of Lua. The only two advantages of PICO-8 are the larger community
  and the ability to set flags on sprites.</p>

<p>[<a name="fn2">2</a>] I"m considering looking into adding support
  in TIC-80 for reloading the code without wiping the existing
  state. The author has been very friendly and receptive to
  contributions in the pastÙ« but this change might be a bit too much
  for my meager C skills.</p>

'),('https://technomancy.us/189', 'in which interactive development saves the day', '1525918301000',  10, '


<p>When I was
  writing <a href="https://technomancy.itch.io/exo-encounter-667">EXO_encounter
    667</a> in <a href="https://fennel-lang.org">Fennel</a>Ù« I
  benefited immensely from the ability to do live reloads. Instead of
  having to restart the whole processÙ« I could run a single key
  command from my editor and have the game see the new code
  immediately. This isn"t particularly difficult to do in FennelÙ« but
  it"s not immediately obvious at a glance either.</p>

<p>Before you understand how reloading works in FennelÙ« you need a
  little background regarding Lua"s module systemÙ« since Fennel is
  just a compiler that emits Lua code. Older versions of Lua had
  a <tt>module</tt> function which would declare the whole rest of the
  file as being part of a specific module and register that with the
  module systemÙ« and all functions that would normally be declared as
  global within that file would be exported as part of the module instead.
  But in version 5.1Ù« that system was recognized as redundant:
  nowadays a module is just a file that returns a
  table<sup><a href="#fn1">1</a></sup> with closures and other values
  in it. This is reflects the relentless simplicity behind the design
  of Lua; why have modules as their own concept when tables and
  closures can do just as good a job?</p>

<p>So that"s all well and good; you can just write code that uses
  functions written in other files by just calling <tt>dofile</tt> on
  the filename and putting that value in a local. And that worksÙ« but
  every time you use the module from another place it loads a fresh
  copyÙ« which is wasteful. Enter the <tt>require</tt> function. It
  takes a module name which maps to a filename (by searching the
  entries of <tt>package.path</tt>) and gives you the value returned
  by that fileÙ« but it also caches subsequent calls. So every time
  you <tt>require</tt> a moduleÙ« you"re getting the exact same
  table<sup><a href="#fn2">2</a></sup> in the exact same memory
  location.</p>

<img src="/i/mtsth.jpg" alt="Valley near Mt. Saint Helens">

<p>We can take a little detour here from Lua land and back into
  FennelÙ« because <tt>dofile</tt> only works on Lua code. Fennel
  provides its own <tt>fennel.dofile</tt> function which works just
  like the built-in oneÙ« but on <tt>.fnl</tt> files instead. But what
  about <tt>require</tt>? Well it turns out <tt>require</tt> is
  implemented in a pretty clever way that allows us to teach it new
  tricks. The way <tt>require</tt> works is that it looks at
  the <tt>package.searchers</tt> tableÙ« (it"s <tt>package.loaders</tt> on
  Lua 5.1) which contains a list of searcher functions. It iterates over
  the listÙ« calling each searcher with the module name. If that
  returns nilÙ« it indicates that searcher can"t find the module and it
  moves onÙ« but a searcher which can load the module will return a
  function which allows <tt>require</tt> to get (and cache) the value
  for the module in question. So simply by
  adding <tt>fennel.searcher</tt> to <tt>package.searchers</tt>Ù« we
  can make it so that <tt>require</tt> works seamlessly on modules
  whether they are written in Fennel or Lua:</p>

<pre class="code">(<span class="keyword">local</span> fennel (<span class="builtin">require</span> <span class="string">"fennel"</span>))
(<span class="type">table.insert</span> <span class="type">package.searchers</span> <span class="type">fennel.searcher</span>)</pre>

<p>Now this seems somewhat academic; after allÙ« you have a lot of
  memory; why do you care if modules are duplicated in memory? But
  using <tt>require</tt> for modules proved invaluable during the
  development of my game because it allowed me to do all my local
  hacking using <tt>.fnl</tt> files I was constantly editingÙ« but
  when I prepared a releaseÙ« I precompiled it all into <tt>.lua</tt>
  files and didn"t have to change a line of my code to reflect
  that.</p>

<p>Well that"s wonderfulÙ« but if <tt>require</tt> caches the value of
  each moduleÙ« doesn"t that interfere with live reloading? Indeed it
  does; simply re-requiring a module has no effect. You can
  call <tt>fennel.dofile</tt> to get a <strong>copy</strong> of the updated
  module. But that"s no help to the existing code which has the old
  version of the module. What to do?</p>

<p>To understand the solution it"s helpful to make a distinction
  between the <strong>identity</strong> of the table and
  the <strong>values</strong> it contains. The identity of a table is
  what makes it truly unique; it can be thought of in terms of that
  table"s particular location in memory. When you pass a table to a
  functionÙ« that function has access to the exact same tableÙ« and
  changes made to it inside the function of course are visible to any
  other function that has access to the
  table<sup><a href="#fn3">3</a></sup>. The value of a table refers to
  what it contains; in the case of a module it"s usually about what
  functions are present under what keys. Since the tables are mutableÙ«
  the value can change over time but the identity cannot. When you
  call <tt>dofile</tt> on a module you get a table that might have the
  same <strong>values</strong> as last time you
  called <tt>dofile</tt>Ù« (if the file on disk hasn"t changed)
  but it will never have the same <strong>identity</strong>. When you
  call <tt>require</tt> you"re guaranteed to get the exact
  same <strong>identical</strong> table every
  time.<sup><a href="#fn4">4</a></sup></p>

<p>With that background maybe you can see now how this might work. All
  the existing code has access to the original module table. We can"t
  swap out that table for a new one without reloading all the
  modules that use itÙ« and that can be disruptive. But we can grab
  that original tableÙ« load a fresh <strong>copy</strong> of its module from
  diskÙ« then go in and replace its <strong>contents</strong> with the
  values from the new one.</p>

<pre class="code">(<span class="keyword">defun</span> <span class="function-name">fennel-reload-form</span> (module-keyword)
  <span class="doc">"Return a string of the code to reload the </span><span class="doc"><span class="constant">module-keyword</span></span><span class="doc"> module."</span>
  (format <span class="string">"%s\n"</span> (<span class="keyword">let</span> [old (<span class="keyword">require</span> Ù«module-keyword)
                            _ (tset package.loaded Ù«module-keyword nil)
                            new (<span class="keyword">require</span> Ù«module-keyword)]
                    <span class="comment-delimiter">;; </span><span class="comment">if the module isnt a table then we can"t make
</span>                    <span class="comment-delimiter">;; </span><span class="comment">changes which affect already-loaded codeÙ« but if
</span>                    <span class="comment-delimiter">;; </span><span class="comment">it is then we should splice new values into the
</span>                    <span class="comment-delimiter">;; </span><span class="comment">existing table and remove values that are gone.
</span>                    (<span class="keyword">when</span> (= (type new) <span class="builtin">:table</span>)
                      (each [k v (pairs new)]
                            (tset old k v))
                      (each [k (pairs old)]
                            <span class="comment-delimiter">;; </span><span class="comment">the elisp reader is picky about where . can be
</span>                            (<span class="keyword">when</span> (not (Ù«<span class="string">"."</span> new k))
                              (tset old k nil)))
                      (tset package.loaded Ù«module-keyword old)))))</pre>

<p>The code above looks like FennelÙ« but it"s actually Fennel embedded
  inside Emacs Lisp code; because they"re both just made up of
  s-expressionsÙ« you can write Fennel code as Elisp code and quote itÙ«
  then send it to the Fennel repl subprocess which is launched
  with <kbd>M-x
    run-lisp</kbd>. My <a href="https://gitlab.com/technomancy/fennel-mode/commit/21e184b2a862290db9dcf839f0e4a2df480a642e">recent
    changes</a> to <tt>fennel-mode.el</tt> allow this to work out of
  the boxÙ« but they could easily be adapted to any other editor that
  supports communicating with an integrated repl subprocess.</p>

<p>Of courseÙ« all this background really isn"t necessary; you can just
  hit reload now and have it work with no fuss. But sometimes it"s
  interesting to understand why it worksÙ« and especially I think in
  this case the design decisions that went into the module system are
  noteworthy for allowing this kind of thing to be done in a graceful
  wayÙ« so that"s worth appreciating and hopefully learning from.</p>

<p><strong>Update</strong>: Charl Botha wrote up a great
  <a href="https://vxlabs.com/2018/05/18/interactive-programming-with-fennel-lua-lisp-emacs-and-lisp-game-jam-winner-exo_encounter-667">blog
  post</a> that goes into more detail about setting up the live reload
  functionality with Emacs.
</p>

<hr>
<div class="footnotes">

  <p>[<a name="fn1">1</a>] Technically a module can return any valueÙ«
    not just a table. But if you return a non-tableÙ« then the
    reloading features described don"t workÙ« because only tables can
    have their contents replaced while retaining their same object
    identity.</p>

  <p>[<a name="fn2">2</a>] Yep; this means you can abuse the module
    system to do terrible things like share application state across
    other modules. Please resist the temptation.</p>

  <p>[<a name="fn3">3</a>] Oddly enough in some languages this is not
    true and data structures default to being copied implicitly every
    time you pass them to a functionÙ« which can be very
    confusing. To muddle things even moreÙ« this behavior is referred
    to as "pass by value" instead of "we make copies of everything for
    you even when you don"t ask". That doesn"t happen here.</p>

  <p>[<a name="fn4">4</a>] For a fascinating discussion of the
    difference between value and identity and how it relates to
    equality I strongly recommend reading the very
    insightful <a href="http://home.pipeline.com/~hbaker1/ObjectIdentity.html">Equal
    Rights for Functional Objects</a> which goes into much more depth
    on this subject. Notably Lua"s (and Fennel"s) equality semantics
    are consistent with its recommendations despite Lua being an
    imperative language.</p>
</div>
'),('https://technomancy.us/188', 'in which a game jam is recounted further', '1525572303000',  10, '


<p>This is the second part continuing my <a href="/187">previous
    post</a> about creating the
  game <a href="https://technomancy.itch.io/exo-encounter-667">EXO_encounter
    667</a> using <a href="https://fennel-lang.org">the Fennel
    programming language</a> and the <a href="https://love2d">LÃ–VE</a>
  game framework for
  the <a href="https://itch.io/jam/lisp-game-jam-2018/">Lisp Game
    Jam 2018</a>; you"ll probably want to read the first installment
  if you haven"t already. I wrote about the game design and artÙ« but
  in this post I"d like to dive into the more technical aspects of
  the game.</p>

<img src="/i/exo-term.png" alt="exo encounter terminal" class="right">

<p>The <a href="https://itch.io/jam/lisp-game-jam-2018/results">voting
    for the game jam</a> just closedÙ« and EXO_encounter 667 came in
  ranked first! Three out of the top four winners are LÃ–VE
    games; <a href="https://verma.itch.io/gravity-fall">one other in
    Fennel</a> and <a href="https://tmw.itch.io/need-for-seeds">one
    in Urn</a>.</p>

<h4>Libraries</h4>

<p>I pulled in a couple libraries on top of LÃ–VE to help out in a few
  areas. First and foremost I would dread to do any work on the Lua
  runtime without <a href="https://github.com/rxi/lume">lume</a>Ù« which
  I like to think of as Lua"s "missing standard library". It brings
  handy things like <tt>filter</tt>Ù« <tt>find</tt>Ù« <tt>reduce</tt>Ù«
  etc. It"s mostly sequence-related functionsÙ« but there are a few
  other handy functions as well like <tt>split</tt>Ù« a bizarre
  omission from the standard libraryÙ« or <tt>hotswap</tt> which I"ll
  get to below.</p>

<p>The <a href="https://github.com/kikito/bump.lua">bump.lua</a>
  library is used for collision detectionÙ« and as long as you only
  need to operate in terms of axis-aligned rectanglesÙ« it is very easy
  to use and gets the job done with no
  fuss.<sup><a href="#fn1">1</a></sup> But one of the nicest things
  about bump is that it"s integrated
  into <a href="https://github.com/Karai17/Simple-Tiled-Implementation">Simple
  Tiled Implementation</a>Ù« which handles maps exported
  from <a href="http://www.mapeditor.org">Tiled</a>. On its own the
  Tiled library just handles drawing them (including their animations
  and layering)Ù« but it can automatically integrate with bump if you
  set properties on a layer or object to flag it as <tt>collidable</tt>.</p>

<p>The documentation for the Tiled library unfortunately leaves quite a bit
  to be desired; it"s one of those projects that just dumps a list of
  all functions with a line or two describing what each one does and
  considers that "the documentation". Fortunately the source is pretty
  readableÙ« but figuring out how to handle opening and closing of
  doors was definitely the roughest spot when it came to 3rd-party
  libraries. The readme does describe how to implement a custom
  drawing routine for a layerÙ« which allows us to draw a door
  differently based on whether it"s closed or open. The problem is
  there"s no easy way to do the same thing for the collision
  detection side of the story.</p>

<p>The Tiled library handles setting up the "world" table from bump by
  seeding it with all the <tt>collidable</tt> things from the map. The
  problem is it doesn"t actually use the same tables from the map when
  adding them to the bump table; it wraps them in bump-specific tables
  stripping it down to just the fields relevant to collision
  detection. This is fine until have a door you need to open. Normally
  you"d do this by calling <tt>bump.remove</tt> with the door table to
  make the door no longer take part in collision detectionÙ« but bump
  doesn"t know about the door table; it only knows about the wrapper
  tableÙ« which we no longer have access to.</p>

<p>I ended
  up <a href="https://gitlab.com/technomancy/exo-encounter-667/commit/a90ccb4e99c90378d086adb6f542310789e3d83c">hacking
  around this</a> by making the Tiled library save off all the wrapper
  tables it createdÙ« and introducing a new <tt>bump_wrap</tt> function
  on the map which would intercept methods on the bump worldÙ« accept a
  regular table and look up the wrapped table and use it instead in
  the method call. It got the job done quicklyÙ« but I couldn"t help
  but feel there should be a better way. I"ve
  opened <a href="https://github.com/karai17/Simple-Tiled-Implementation/issues/180">an
  issue</a> with the Tiled library to see if maybe I missed an
  undocumented built-in way of doing this. But as far as the coding
  wentÙ« this was really the only hiccup I encountered with any of the
  libraries I used.</p>

<h4>Interactive Development</h4>

<p>As a lispÙ« of course Fennel ships with a REPL (aka interactive
  consoleÙ« often mistakenly called an "interpreter") which allows you
  to enter code and see the results immediately. This is absolutely
  invaluable for rapid game development. There"s a bit of a hiccup
  though; the REPL reads from standard inÙ« and LÃ–VE doesn"t ship with
  a method for reading from standard in without blocking. Since Lua
  doesn"t have concurrencyÙ« this means reading repl input would block
  the whole game loop until enter was pressed! LÃ–VE saves the day here
  by allowing you to construct
  "<a href="http://love2d.org/wiki/love.thread">threads</a>" which are
  really just completely independent Lua virtual machines that can
  <a href="/183">communicate with each other over queues</a> but can"t
  share any data directly. This turns out to be just fine for the
  repl; one thread
  can <a href="https://gitlab.com/technomancy/exo-encounter-667/blob/master/stdio.fnl">sit
  and block on standard in</a>Ù« and when it gets input send it over a
  queue to the main thread which evaluates and sends the response
  back.</p>

<pre class="code">(<span class="keyword">defn</span> <span class="variable-name">start-repl</span> []
  (<span class="keyword">let</span> [code (<span class="type">love.filesystem.read</span> <span class="string">"<a href="https://gitlab.com/technomancy/exo-encounter-667/blob/master/stdio.fnl">stdio.fnl</a>"</span>)
        lua (<span class="type">love.filesystem.newFileData</span> (<span class="type">fennel.compileString</span> code) <span class="string">"io"</span>)
        thread (<span class="type">love.thread.newThread</span> lua)
        io-channel (<span class="type">love.thread.newChannel</span>)]
    <span class="comment-delimiter">;; </span><span class="comment">this thread will send "eval" events for us to consume:
</span>    (<span class="keyword">:</span> thread <span class="builtin">:start</span> <span class="string">"eval"</span> io-channel)
    (<span class="keyword">set</span> <span class="type">love.handlers.eval</span>
         (<span class="keyword">fn</span> [input]
           (<span class="keyword">let</span> [(ok val) (<span class="builtin">pcall</span> <span class="type">fennel.eval</span> input)]
             (<span class="keyword">:</span> io-channel <span class="builtin">:push</span> (<span class="keyword">if</span> ok (view val) val)))))))</pre>

<p>As I use EmacsÙ« I"ve
  configured <a href="https://gitlab.com/technomancy/fennel-mode">fennel-mode</a>
  to add a key combo for reloading the module for the current
  buffer. This only works if the current file is in the root directory
  of the project; it won"t work with subdirectories as the module name
  will be wrongÙ« but it"s pretty helpful. It also
  requires <tt>lume</tt> be defined as a global variable. (Normally I
  avoid using globalsÙ« but I make two exceptions; one
  for <tt>lume</tt> and another for <tt>pp</tt> as a pretty-print
  function.) I haven"t included this in <tt>fennel-mode</tt> yet
  because of these gotchas; maybe if I can find a way to remove them
  it can be included as part of the mode itself in the future.</p>

<p>Simply run <kbd>C-u M-x run-lisp</kbd> to start your
  gameÙ« and use <kbd>love .</kbd> as your command. Once that"s
  startedÙ« the code below will make <kbd>C-c C-k</kbd> reload the
  current module.</p>

<pre class="code">(eval-after-load "fennel-mode
  "(define-key fennel-mode-map (kbd <span class="string">"C-c C-k"</span>)
     (<span class="keyword">defun</span> <span class="function-name">pnh-fennel-hotswap</span> ()
       (<span class="keyword">interactive</span>)
       (comint-send-string
        (inferior-lisp-proc)
        (format <span class="string">"(lume.hotswap \"%s\")\n"</span>
                (substring (file-name-nondirectory (buffer-file-name)) 0 -4)))))<span class="whitespace-line">)</span></pre>

<p><strong>Update</strong>: I added first-class support for reloads
  to <a href="https://gitlab.com/technomancy/fennel-mode">fennel-mode</a>Ù«
  though you will still need the stdin hack described above when using
  it inside LÃ–VE. <!-- 
I <a href="/189">wrote more about reloading</a>.--></p>

<p>The other gotcha is that currently an error will crash your whole
  game. I really wanted to add an error handler which would allow you
  to resume play after reloading the module that crashedÙ« but I didn"t
  have time to add that. Hopefully I"ll have that ready in time for
  the next jam!</p>

<h4>Tutorial</h4>

<p>From a usability perspectiveÙ« one of the most helpful things was
  adding a tutorial to explain the basic controls and mechanics. The
  tutorial displays instructions onscreen until the point at which the
  player carries out those instructionsÙ« at which point it moves on to
  the next instructions. There are various ways you could go
  about doing thisÙ« but I chose to implement it
  using <a href="https://www.lua.org/pil/9.1.html">coroutines</a>Ù«
  which are Lua"s way of
  offering <a href="https://en.wikipedia.org/wiki/Cooperative_multitasking">cooperative
    multitasking</a>.</p>

<pre class="code">(<span class="keyword">defn</span> <span class="variable-name">tutorial</span> [state world map dt]
  (echo <span class="string">"Press 2 to select rover 2; bring it near the"</span>
        <span class="string">"main probe and press enter to dock."</span>)
  (<span class="keyword">while</span> (not (<span class="keyword">.</span> <span class="type">state.rovers</span> 2 <span class="builtin">:docked?</span>))
    (<span class="type">coroutine.yield</span>))

  (echo <span class="string">"With at least 3 rovers dockedÙ« the main"</span> <span class="string">"probe has mobility."</span>
        <span class="string">""</span> <span class="string">"Now do the same with rover 3."</span>)
  (<span class="keyword">while</span> (not (<span class="keyword">.</span> <span class="type">state.rovers</span> 3 <span class="builtin">:docked?</span>))
    (<span class="type">coroutine.yield</span>))

  (echo <span class="string">"The probe"s communications laser can be"</span>
        <span class="string">"activated by holding space. Comma and"</span>
        <span class="string">"period change the aim of the laser."</span>)
  (<span class="keyword">while</span> (not (<span class="keyword">or</span> (<span class="keyword">and</span> <span class="type">state.laser</span> (<span class="keyword">~=</span> <span class="type">state.selected.theta</span> <span class="type">math.pi</span>))
                  (<span class="keyword">&gt;</span> (<span class="keyword">:</span> world <span class="builtin">:getRect</span> <span class="type">state.selected</span>) 730)
                  (sensor? map <span class="string">"first"</span>)))
    (<span class="type">coroutine.yield</span>))

  <span class="keyword">...</span>)</pre>

<p>The <tt>tutorial</tt> function runs inside a coroutine started
  with <tt>coroutine.wrap</tt>; it echoes the first message and then
  suspends itself with <tt>coroutine.yield</tt> which returns control
  to the caller. On every tickÙ« the <tt>love.update</tt> function
  <tt>coroutine.resume</tt>s it which allows it to check whether the
  conditions have been fulfilled. If so it can move on to the next
  instruction; otherwise it just yields back immediately. Of courseÙ«
  it would be possible to do something like this using only closuresÙ«
  but coroutines allow it to be written in a very linearÙ«
  straightforward way.</p>

<img src="/i/exo-laser.png" alt="exo encounter laser screenshot">

<h4>Distribution</h4>

<p>With LÃ–VE you get portability across many operating systems;
  however it does not actually handle creating the executables for
  each platform. I used an old version
  of <a href="https://github.com/MisterDA/love-release/">love-release</a><sup><a href="#fn2">2</a></sup>
  to create zip files which include everything you need to run on
  Windows and Mac OS. This was a huge help; I could run my entire
  build from my Debian laptop without even touching a Windows machine
  or a Mac.</p>

<p>For the jam I just published a <tt>.love</tt> file for other
  platformsÙ« which requires you to manually install LÃ–VE
  yourself. This is a bit of a drag since most package managers don"t
  include the correct version of LÃ–VEÙ« and even if they did todayÙ« in
  the future they"d upgrade to a different oneÙ« so this is one place
  where relying on the package manager is definitely not going to cut
  it. Soon after the jam I
  discovered <a href="https://appimage.org/">AppImages</a> which are a
  way of bundling up all a program"s dependencies into a single
  executable file which should work on any Linux distribution. While I
  think this is a really terrible idea for a lot of softwareÙ« for a
  single-player game that doesn"t load any data from untrusted
  sourcesÙ« I believe it to be the best option. The love-release tool
  doesn"t currently support creating AppImagesÙ« but I am hoping to add
  support for this. I also didn"t get around to automating uploading
  of builds to itch.io
  using <a href="https://itch.io/docs/butler/">butler</a>Ù« but I"m
  hoping to have that working for next time.</p>

<h4>Play my game!</h4>

<p>Now that the jam is overÙ« I"ve gotten some great feedback from
  players that resulted
  in <a href="https://gitlab.com/technomancy/exo-encounter-667/blob/master/todo.md">a
  nice todo list</a> of items that can be improved. I hope to release
  a "special edition" in the near future that includes all the things
  I wasn"t able to get to during the jam. But in the mean timeÙ« I hope you
  enjoy <a href="https://technomancy.itch.io/exo-encounter-667">EXO_encounter
    667</a>!</p>

<hr>
<div class="footnotes">

  <p>[<a name="fn1">1</a>] LÃ–VE ships with
    a <a href="https://love2d.org/wiki/love.physics">physics engine</a>
    built-inÙ« but the API it uses is much more complicated. It"s capable
    of more sophisticated behaviorÙ« but unless you <em>really</em> can"t
    work in terms of rectanglesÙ« I"d recommend sticking with the much
    simpler bump.lua.</p>

  <p>[<a name="fn2">2</a>] The love-release project has since been
    rewritten in Lua instead of being a shell script as it was at the
    time I downloaded the version I used. I haven"t tried the new
    version but it looks promising.</p>

</div>
'),('https://technomancy.us/187', 'in which a game jam is recounted', '1525316896000',  10, '

<p>This past weekend I just finished competing in
  the <a href="https://itch.io/jam/lisp-game-jam-2018/">Lisp Game Jam
  2018</a>. While I"d made
  a <a href="https://technomancy.itch.io/liquid-runner">game under
  game-jam-like constraints</a> I had never officially participated in
  one beforeÙ« so this one was a perfect place to start. I wrote my game in
  the <a href="https://fennel-lang.org">Fennel</a> programming
  language using the <a href="https://love2d.org">LÃ–VE</a> game
  framework. The game is
  called <a href="https://technomancy.itch.io/exo-encounter-667">EXO_encounter
  667</a>; you play an unmanned probe exploring the exoplanet
  <a href ="https://en.wikipedia.org/wiki/Gliese_667_Cc">Gliese 667
  Cc</a> that uncovers remains of an ancient outpost.</p>

<p><strong>Update</strong>: I"m proud to say that EXO_encounter 667
  won <a href="https://itch.io/jam/lisp-game-jam-2018/results">first
    place</a> in the game jam!</p>

<img src="/i/exo1.png" alt="exo encounter title screen" class="right" />

<p>Overall I"m thrilled with how it turned out; at the end of the jam
  I ended up with a game I"m very proud of. This game jam is a
  little unusual in that it ran over the span of ten days; most jams
  limit you to closer to 3 days and end up being much more of a
  crunch. Ten days was enough time to make something fairly polished
  (though of course still short) without pulling a bunch of
  all-nighters.</p>

<h4>The Language</h4>

<p>Using Fennel allowed me to take advantage of a bunch of existing
  tools without starting from square one. I had used the LÃ–VE
  framework beforeÙ« but only from Lua. As I <a href="/186">blogged
  about previously</a>Ù« Fennel is a lisp language which compiles to
  Lua output and stays very close to Lua semanticsÙ« which means it"s
  very easy to use tools and libraries from the Lua world. I can"t
  speak to how it would hold up in a larger codebase (the game ended
  up being only 667 lines of code)Ù« but I felt that for this project
  using Fennel with LÃ–VE and a couple helper libraries put me on
  nearly the perfect level of abstraction. I ran into one minor
  problem with Fennel where the line numbering of the output wasn"t
  quite rightÙ« but I was able to fix it quickly in-flight.</p>

<h4>Art and Music</h4>

<img src="/i/hard-vacuum.png" alt="hard vacuum screenshot" class="left">

<p>One of the limitations of the jam is that all game coding and level
  design must be done during the ten days of the jamÙ« but if you have
  pre-made assets you can use them as long as they"re
  freely-licensed. I found like I hit the jackpot when I stumbled
  across <a href="http://www.lostgarden.com/2005/03/game-post-mortem-hard-vacuum.html">Daniel
  Cook"s Hard Vacuum tileset</a>. Created in 1993 for a Dune2-inspired
  strategy gameÙ« it was released under a Creative Commons license
  because the game was never finished. I was really impressed with the
  impeccable pixel art and the wide variety of terrain and buildings
  available in the set. Often when you are looking for freely-licensed
  art it"s not that hard to find what you need if you look across
  various setsÙ« but combining several sets leads to some pretty
  jarring inconsistencies in visual style. Here I found one set which
  had basically everything I
  needed.<sup><a href="#fn1">1</a></sup></p>

<p>I also found a couple pieces of music that I felt really fit the
  theme I was going for: ambient and thoughtful to put you in the mood
  of exploring on a distant planet that took hundreds of years to
  reach. My son helped me choose
  <a href="https://opengameart.org/content/galactic-temple">Galactic
  Temple</a> for the main themeÙ« and for the endgame I used the
  slightly more
  upbeat <a href="https://opengameart.org/content/freelance">Bazaar
  Net</a> by Max StackÙ« who also composed music I used for
  the <a href="https://www.youtube.com/watch?v=r_gdeS3d6F8">trailer of
  another of my games</a>.</p>

<h4>Design</h4>

<p>I had sketched out a plan up-front which I <em>mostly</em> was able
  to stick to; the main thing I cut scope on was the level layout. The
  original plan had the map divided into three sections: one where you
  approach the baseÙ« one base where all the text is in RussianÙ« and the
  other base where things are in English. Because the aliens
  abandoned the outpost in 1999Ù« the signals they received from Earth were
  from 1976 when the space race was still in full swingÙ« so they were
  preparing for first-contact with Russia as well as the US. This was
  supposed to be part of the mystery you uncoveredÙ« but in the end it
  was just too meanderingÙ« and the final product ended up a lot more
  focused with a single base containing six doors you had to figure
  out how to open.</p>

<img src="/i/exo-tiled.png" alt="terminal" class="right">

<p>I spent most of the jam on a business trip where I had the evenings
  alone in a hotel roomÙ« so I was able to get a lot done there. I
  wrote the entire story text
  from <a href="https://www.dnapizza.com/">DNA Pizza</a>Ù« a 24-hour
  pizza shop owned by <a href="https://www.jwz.org/blog">JWZ</a> that
  features bizarreÙ« surreal music
  videos.<sup><a href="#fn2">2</a></sup> For something written in 2
  hours I"m really happy with how the story turned out; it was
  inspired heavily by
  the <a href="http://marathon.bungie.org/story/">the mythos of
  Marathon series</a> as well as
  the <a href="https://en.wikipedia.org/wiki/The_Three-Body_Problem_(novel)">Three
    Body Problem</a> novel.</p>

<p>But when on Saturday I got home from my trip and still didn"t have
  any puzzles readyÙ« I started to get a little worried. Not only did I
  not have any puzzlesÙ« I also didn"t really have any
  idea <em>how</em> I would make puzzles in the first place or what
  would be fun. I sat down with my kids
  in <a href="http://www.mapeditor.org">the Tiled map editor</a> and
  just worked thru a progression of the mechanics I had implemented so
  farÙ« starting with using the probe"s laser to trigger sensors which
  open doorsÙ« and working up thru reflecting the laser off one of your
  roversÙ« to a multiple reflection chain puzzleÙ« and that worked
  better than I expected.</p>

<p>The next day eight hours before the competition closed I had half a
  map worth of puzzles and was running out of ideas. The reflection
  mechanic I had implemented was solidÙ« but it wasn"t enough to carry
  the game by itself. In about an hour I added in beam splitters as
  well as sensors which would only open the door as long as the laser
  remained on them. My son came up with the idea for the last puzzle
  involving <span class="spoiler">splitting the laser and then
  reflecting the laser back into the splitter to get three
  beams</span> which I felt worked really well.</p>

<p>In the endÙ« I was able to finish the map within the last
  hour before the deadlineÙ« but just barely.</p>

<h4>What worked wellÙ« and what didn"t</h4>

<p>The versatility and ease of use of Tiled impressed me greatly. Once I
  loaded up my tileset into itÙ« I had a tool simple enough that I
  could put my kids in front of it and they could make genuinely
  helpful contributions to the map. Highly recommended! All the
  collision and layer data is part of the mapÙ« as well as all the
  non-player animations.</p>

<p>Each object in the Tiled map contains a set of properties I used
  for various purposes; for instance I set a "door" property on each
  laser sensor switch to indicate which door should open when it was
  triggered. Early on I found myself making a lot of mistakes where I"d
  forget to set a propertyÙ« so I added
  a <a href="https://gitlab.com/technomancy/exo-encounter-667/tree/master/lint.fnl">linter</a>
  which would error out early if it detected that a certain type of
  object was missing a required property or if a sensor referred to a
  door that didn"t exist. This saved me a lot of fruitless manual
  debuggingÙ« and I"d strongly suggest doing something like it if you
  use map object properties.</p>

<p>I tried to introduce each mechanic with a very simple puzzle before
  moving on to non-obvious tricks. (I really messed up the difficulty
  curve near the end; the second-to-last puzzle is a fair bit more
  difficult than the last one.) This can be really tricky to do
  depending on your mechanics; I had one player who didn"t see the
  message that explained how to aim because he accidentally skipped
  ahead by opening a door too soon. After the jam I went back and
  fixed this by starting off with the laser aimed in the wrong
  directionÙ« so it"s impossible to open the door without first
  aiming.</p>

<p>Using LÃ–VE was an obvious win; I got so much functionality for free
  as well as compatibility across operating systems and access to
  third-party libraries like the Tiled renderer. I wasn"t sure how it
  would work to use Fennel for thisÙ« but looking back on it I find it
  remarkable how seamless it felt. The language just got out of
  the way and let me focus on the task at hand; I barely noticed
  it. <strong>Update</strong>: surprisinglyÙ« you
  can <a href="https://gitlab.com/technomancy/exo-encounter-667/blob/master/.luacheckrc">run
    the Lua linter</a> on the output of the Fennel compiler and still
  get helpful results!</p>

<p>In the last hour I got my wife to playtest the gameÙ« which yielded
  some interesting insights. (Why can the rovers move forward but not
  backward? I just didn"t think of it.) I found that having my kids
  playtest continually as the game evolved meant that they didn"t see
  certain flaws; things that were clear to them weren"t obvious to
  first-time players. (Of courseÙ« as the author I expect to be blind
  to many flaws myself.) In particularÙ« getting a precise aim of the
  laser was much too difficult because the turn speed was too fast. I
  added a "hold shift to turn slowly" feature early onÙ« but it wasn"t
  introduced in the tutorial and you had to read the help text to see
  it. In the future I"d make more of an effort to get playtesting
  feedback earlier on in the process.</p>

<p>Speaking of the tutorialÙ« having a tutorial was very helpful in
  introducing the mechanics. The implementation of the tutorial had
  some interesting technical featuresÙ« but I will save that for part 2
  of this post. Thanks for readingÙ« and please enjoy playing
  <a href="https://technomancy.itch.io/exo-encounter-667">EXO_encounter 667</a>.</p>

<p><strong>Update</strong>: <a href="/188">part 2</a> is published.</p>

<hr>

<div class="footnotes">

<p>[<a name="fn1">1</a>] I did need two other graphical assets: intro
  and endgame screens. For those I used Creative-Commons-licensed
  <a href="https://commons.wikimedia.org/wiki/File:Sky_around_Gliese_667C.jpg">photos</a>
  and <a href="https://commons.wikimedia.org/wiki/File:Gliese_667.jpg">renders</a>
  of Gliese 667 from
  the <a href="https://en.wikipedia.org/wiki/European_Southern_Observatory">European
  Southern Observatory</a>.</p>

<p>[<a name="fn2">2</a>] I have this tradition where every time I"m in
  San Francisco I try to go to JWZ"s pizza place and
  read <a href="https://www.jwz.org/blog">JWZ"s blog</a> and also use
  EmacsÙ«
  which <a href="https://www.jwz.org/doc/emacs-timeline.html">JWZ had
    a hand in the development of</a> in the 90s.</p>
</div>
'),('https://technomancy.us/186', 'in which a compiler gets its wings', '1520094916000',  10, '

<p>I"ve enjoyed writing Lua code for
  my <a href="https://gitlab.com/technomancy/bussard">side</a>
  <a href="https://gitlab.com/technomancy/polywelL">projects</a> for the
  most part. It has a few quirksÙ« but many of them can be solved
  by <a href="https://github.com/mpeterv/luacheck">a little linting</a>.
  For a non-homoiconic language there is little in the syntax to
  object toÙ« and the aggressively minimalist semantics more than make up for
  the few shortcomings.</p>

<p>StillÙ« I always wondered what it would be like to use a language that
  compiled to Lua and didn"t have problems like the statement vs
  expression distinctionÙ« lack of arity checksÙ« or defaulting to
  globals. Over the past year or so I looked at several such
  languages<sup><a href="#fn1">1</a></sup>Ù« but nothing ever stuck. Then a
  few weeks ago I
  found <a href="https://github.com/bakpakin/Fennel">Fennel</a> (at the
  time called "fnl")Ù« and it really resonated with me.</p>

<p><b>Update</b>: Fennel got <a href="https://fennel-lang.org">its own
    web site</a> with an in-browser repl and tutorial.</p>

<h4>The Microlanguage</h4>

<img src="i/snowy-sidewalk.jpg" alt="snowy sidewalk" class="right">

<p>The thing that sets Fennel apart is that it is strictly about adding
  new syntax to Lua and keeping Lua"s semantics. This allows it to operate
  as a compiler which introduces <em>no runtime overhead</em>. Code in
  Fennel translates trivially to its Lua equivalent:</p>

<pre class="code">(<span class="keyword">let</span> [x (<span class="keyword">+</span> 89 5.25)
      f (<span class="keyword">fn</span> [abc] (<span class="builtin">print</span> (<span class="keyword">*</span> 2 abc)))]
  (f x))</pre>

<p>... becomes ...</p>

<pre class="code"><span class="keyword">do</span>
  <span class="keyword">local</span> <span class="variable-name">x</span> = (89 + 5.25)
  <span class="keyword">local</span> <span class="keyword">function</span> <span class="function-name">_0_</span>(abc)
      <span class="keyword">return</span> <span class="builtin">print</span>((2 * abc))
  <span class="keyword">end</span>
  <span class="keyword">local</span> <span class="variable-name">f</span> = _0_
  <span class="keyword">return</span> f(x)
<span class="keyword">end</span></pre>

<p>There are a few quirks around introducing temporary variable names in
  cases where it"s unnecessary like the aboveÙ« but these are only
  readability concerns and do not affect the performance of the codeÙ«
  since Lua is smart enough to collapse it down. The
  temporary locals are introduced in order to ensure that every form in
  Fennel has a value; there are no statementsÙ« only expressions. This
  fixes a common problem in Lua where you can"t use an <tt>if</tt> to
  calculate the value of an expressionÙ« because it"s implemented as a
  statementÙ« so you have to construct complex <tt>and</tt>/<tt>or</tt>
  chains to simulate <tt>if</tt> expressions. Plus it"s just simpler and
  more consistent to omit statements completely from the language semantics.</p>

<p>The one exception to the no-overhead rule is Fennel"s <tt>lambda</tt> form.
  Fennel"s <tt>fn</tt> keyword compiles straight to a no-nonsense
  Lua <tt>function</tt> with all that implies. But Lua"s <tt>function</tt>
  has one feature that is quite error-prone: it doesn"t check to ensure
  that it was called with the correct number of arguments. This leads
  to <tt>nil</tt> values easily getting propagated all thru the call stack
  by mistake. Fennel"s solution to this is <tt>lambda</tt>Ù« which includes
  checks to ensure that this doesn"t happen. This function will signal an
  error when it"s called with zero or one argumentÙ« but the <tt>?w</tt>
  and <tt>?h</tt> arguments are optional:</p>

<pre class="code">(<span class="keyword">lambda</span> [x y ?w ?h]
  (make-thing {<span class="builtin">:x</span> x <span class="builtin">:y</span> y
               <span class="builtin">:width</span> (<span class="keyword">or</span> ?w 10) <span class="builtin">:height</span> (<span class="keyword">or</span> ?h 10)}))</pre>

<p>The other main difference between Fennel and Lua is that Fennel takes
  more care to distinguish between sequential tables and key/value
  tables. Of course on the Lua runtime there is no difference; only one
  kind of table existsÙ« and whether it is sequential or not is just a
  matter of how it"s constructed or used. Lua uses <tt>{}</tt> notation
  for all tablesÙ« but Fennel allows you to construct sequential tables
  (array-like tables which have consecutive integers as keys)
  using <tt>[]</tt> instead. Lua overloads the <tt>for</tt> keyword to
  iterate over a numeric range as well as to work with generic iterators
  like <tt>pairs</tt> for values in tables. Fennel uses <tt>each</tt> for
  the latterÙ« which makes the difference clearer at a glance.</p>

<h4>The Compiler</h4>

<p>To be clearÙ« these are very small improvements over Lua. Normally I
  wouldn"t consider switching to a new language over such things. But
  Fennel is unique in its simplicity and lack of overheadÙ« so it doesn"t
  cost much to bring it in. When I found out about FennelÙ« it was an
  experimental compiler that had been written over the course of one week
  in 2016 and then forgotten. But I was impressed with how <em>useful</em>
  it was after only that week of development. I could see at a glance that
  in around a thousand lines of code it had a functional compiler that
  output fairly readable Lua code and fixed the problem of statements.</p>

<p>So I dived into the codebase and started adding a few conveniencesÙ«
  starting with a test case and some static analysis. When Fennel"s
  creator Calvin Rose saw what I was doingÙ« he gave me feedback and
  started to pick back up on development too. As I got more comfortable
  with the code I started adding featuresÙ«
  like <tt>each</tt>Ù« <tt>when</tt>Ù« and comments. Then I started putting
  it thru the paces by porting some of my existing Lua programs
  over<sup><a href="#fn2">2</a></sup>. This went much more smoothly than I
  anticipated. I did find a few compiler bugsÙ« but they were either easy
  to fix myself or fixed quickly by Calvin Rose once I pointed them
  out. Once I had a few programs under my belt I wrote
  up <a href="https://github.com/bakpakin/Fennel/blob/master/tutorial.md">an
  introductory tutorial</a> to the language that you should read if you
  want to give it a try.</p>

<img src="i/tumwater-rapids.jpg" alt="Tumwater fallsÙ« with raging water">

<h4>But what about the lines?</h4>

<p>But one thing really bothered me when writing Fennel programs. When you
  needed to debugÙ« the Lua output was fairly readableÙ« but you quickly ran
  into the curse of all sourceâ†’source compilers: line numbers didn"t add
  up. Some runtimes allow you to provide source maps which change the
  numbering on stack traces to match the original source codeÙ« but Lua
  runtimes don"t offer this. If your compiler emits bytecode instead of
  sourceÙ« you can set the line numbers for functions directly. But then
  you"re tied to a single VM and have to sacrifice portability.</p>

<p>So what"s a poor compiler to do? This being FennelÙ« the
  answer is "the simplest thing possible". In this caseÙ« the simplest
  thing is to track the line number when emitting Lua sourceÙ« and only
  emit newlines when it"s detected that the current output came from
  input with a line number greater than the one it"s currently on.</p>

<p>For most compilersÙ« this naive approach would quickly fall to
  pieces. Usually you can"t rely on the output being in the same order as
  the input that generated it<sup><a href="#fn3">3</a></sup>. I honestly
  did not have high hopes for this when I started working on it. But
  because of Fennel"s 1:1 simplicity and predictabilityÙ« it actually works
  surprisingly well.</p>

<h4>The future?</h4>

<p>At this point I"m pretty happy with where the compiler isÙ« so my own
  plans are mostly just to write more Fennel code. The
  upcoming <a href="https://itch.io/jam/lisp-game-jam-2018">Lisp Game
  Jam</a> will be a perfect excuse to do just that. I have a few ideas for
  further compiler improvementsÙ« like associative destructuring (sequential
  destructuring already works great)Ù« pattern matchingÙ« or even making the
  compiler self-hostingÙ« but there"s nothing quite like getting out there
  and banging out some programs.</p>

<hr>

<div class="footnotes">
  <p>[<a name="fn1">1</a>]
    Here"s a list of the lisps I found that compile to Lua and my brief
    impression of them:</p>
  <dl style="font-size: 140%;">
    <dt><a href="https://github.com/leafo/moonlisp">Moonlisp</a></dt>
    <dd>An experimental lisp by the creator of Moonscript. Looks neatÙ« but
      it requires an alpha build of Moonscript 0.2.0 from 2012 to run.</dd>

    <dt><a href="https://github.com/larme/hua">Hua</a></dt>
    <dd>Inspired by <a href="http://hylang.org">Hy</a>Ù« this seems to be
      an improvement over HyÙ« since the latter inherits some of Python"s
      unfortunate design bugs around scoping. If you"re a Hy userÙ« this
      might be a nice way to trade library availability for speed and
      consistencyÙ« but since the compiler is written in Hy it means you
      need two runtimesÙ« which complicates deployment.</dd>

    <dt><a href="https://github.com/raph-amiard/clojurescript-lua">ClojureScript-Lua</a></dt>
    <dd>This looked promising when it was first announcedÙ« but it was
      based on a <em>very</em> early version of ClojureScript that was
      still quirky and didn"t have a replÙ« and was abandoned a few
      months after it was announced. It has the same problem of
      requiring a separate runtime for the compiler as HuaÙ« except that
      runtime needs dramatically greater resources.</dd>

    <dt><a href="https://github.com/kstep/scheme.lua">scheme.lua</a></dt>
    <dd>This actually looks pretty nice if you like Scheme. It"s pretty
      immatureÙ« but probably wouldn"t take that much work to get to a
      usable state. Personally I find Lua tables to be much more friendly
      to work with than Scheme"s listsÙ« so sticking strictly with Scheme"s
      semantics seems like a step backwardsÙ« but I know some people like
      it.</dd>

    <dt><a href="https://github.com/meric/l2l">l2l</a></dt>
    <dd>I actually did use
      this <a href="https://gitlab.com/technomancy/bussard/blob/beta-2/os/lisp/resources/portal.lsp">in
      my game</a>. But since I tried it the compiler has been more or less
      completely rewritten. The unique thing about the new l2l compiler is
      that it allows you to mix Lua code and lisp code in the same file. I
      found it rather difficult to follow code that does thisÙ« but it"s an
      interesting idea. The readme for l2l includes some very apt Taoist
      quotationsÙ« which earns it extra points in my book.</dd>

    <dt><a href="http://urn-lang.com/">Urn</a></dt>
    <dd>I saved the best for last. Urn is a very impressive language with
      a smart compiler that has great error messagesÙ« pattern matchingÙ«
      and tree-shaking to strip out code that"s not used. The main reason
      I decided not to use Urn is that it wants to do a lot of
      optimization and analysis up-front and sacrifices some interactivity
      and reloading features to achieve it. As one who prizes interactivity
      above all other considerationsÙ« I found it a poor fit. Urn wants
      to be its own language that just uses Lua as a runtimeÙ« and that"s
      greatÙ« but right now I"m looking for something that just takes Lua
      and makes the syntax nicer.</dd>
  </dl>

  <p>[<a name="fn2">2</a>] My first program
    was <a href="https://p.hagelb.org/pong.fnl.html">a 1-page Pong</a>Ù«
    which is kind of the "hello world" of games. Then I ported the
    user-level config
    from <a href="https://gitlab.com/technomancy/polywell/blob/fennel/config/repl.fnl">Polywell</a>Ù«
    my Emacs cloneÙ« over to Fennel. This has made Polywell seem a lot more
    Emacsy than it used to be.</p>

  <p>[<a name="fn3">3</a>] Of courseÙ« once macros are introduced to the
    picture you can write code where this guarantee no longer
    applies. Oddly enough I"m not particularly interested in complex
    macros beyond things like pattern matchingÙ« so I don"t see it being a
    problem for code I writeÙ« but it"s worth noting that there are
    complications.</p>
</div>

'),('https://technomancy.us/185', 'in which the cost of structured data is reduced', '1515786831000',  10, '

<p>Last year I got the wonderful opportunity to
  attend <a href="https://con.racket-lang.org/">RacketCon</a> as it
  was hosted only 30 minutes away from my home. The two-day
  conference had a number of great talks on the first dayÙ« but what
  really impressed me was the fact that the entire second day was
  spent focusing on contribution. The day started out with a few 15-
  to 20-minute talks about how to contribute to a specific codebase
  (including that of Racket itself)Ù« and after that people just
  split off into groups focused around specific codebases. Each
  table had maintainers helping guide other folks towards how to
  work with the codebase and construct effective patch
  submissions.</p>

<img src="/i/chronicles-of-lensmen.jpg" alt="lensmen chronicles" class="right">

<p>I came away from the conference with a great sense of
  appreciation for how friendly and welcoming the Racket community
  isÙ« and how great Racket is as a swiss-army-knife type tool for
  quick tasks. (Not that it"s unsuitable for large projectsÙ« but I
  don"t have the opportunity to start any new large projects very
  frequently.)</p>

<p>The other day I wanted to generate colored maps of
  the world by categorizing countries interactivelyÙ« and Racket
  seemed like it would fit the bill nicely. The job is simple: show
  an image of the world with one country selected; when a key is
  pressedÙ« categorize that countryÙ« then show the map again with
  all categorized countries coloredÙ« and continue with the next
  country selected.</p>

<h4>GUIs and XML</h4>

<p>I have yet to see a language/framework more accessible and
  straightforward out of the box for
  drawing<sup><a href="#fn1">1</a></sup>. Here"s the entry point
  which sets up state and then constructs a canvas that handles key
  input and display:</p>

<pre class="code">(<span class="keyword">define</span> (<span class="function-name">main</span> path)
  (<span class="keyword">let</span> ([<span class="variable-name">frame</span> (<span class="builtin">new</span> frame% [label <span class="string">"World color"</span>])]
        [<span class="variable-name">categorizations</span> (<span class="builtin">box</span> "())]
        [<span class="variable-name">doc</span> (<span class="keyword">call-with-input-file</span> path read-xml/document)])
    (<span class="builtin">new</span> (<span class="builtin">class</span> canvas%
           (<span class="builtin">define/override</span> (<span class="function-name">on-char</span> event)
             (handle-key <span class="builtin">this</span> categorizations (<span class="builtin">send</span> event get-key-code)))
           (<span class="builtin">super-new</span>))
         [parent frame]
         [paint-callback (draw doc categorizations)])
    (<span class="builtin">send</span> frame show <span class="racket-selfeval">#t</span>)))</pre>

<p>While the class system is not one of my favorite things about
  Racket (most newer code seems to avoid it in favor
  of <a href="https://docs.racket-lang.org/reference/struct-generics.html">generic
  interfaces</a> in the rare case that polymorphism is truly called
  for)Ù« the fact that classes can be constructed in a light-weightÙ«
  anonymous way makes it much less onerous than it could be. This
  code sets up all mutable state in
  a <a href="https://docs.racket-lang.org/reference/boxes.html?q=box#%28def._%28%28quote._~23~25kernel%29._box%29%29"><code>box</code></a>
  which you use in the way you"d use a <code>ref</code> in ML or
  Clojure: a mutable wrapper around an immutable data structure.</p>

<p>The world map I"m using
  is <a href="https://commons.wikimedia.org/wiki/File:BlankMap-World_gray.svg">an
  SVG of the Robinson projection</a> from Wikipedia. If you look
  closely there"s a call to bind <code>doc</code> that
  calls <a href="https://docs.racket-lang.org/reference/port-lib.html#(def._((lib._racket%2Fport..rkt)._call-with-input-string))"><code>call-with-input-file</code></a>
  with <a href="https://docs.racket-lang.org/xml/index.html?q=read-xml#%28def._%28%28lib._xml%2Fmain..rkt%29._read-xml%2Fdocument%29%29"><code>read-xml/document</code></a> which loads up the whole map
  file"s SVG; just about as easily as you could ask for.</p>

<p>The data you get back from <code>read-xml/document</code> is in fact
  a <a href="https://docs.racket-lang.org/xml/#%28def._%28%28lib._xml%2Fmain..rkt%29._document%29%29">document</a>
  structÙ« which contains an <code>element</code> struct
  containing <code>attribute</code> structs and lists of
  more <code>element</code> structs. All very sensibleÙ« but maybe not
  what you would expect in other dynamic languages like Clojure or
  Lua where free-form maps reign supreme. Racket really wants
  structure to be known up-front when possibleÙ« which is one of the
  things that help it produce helpful error messages when things
  go wrong.</p>

<p>Here"s how we handle keyboard input; we"re displaying a map with
  one country highlightedÙ« and <code>key</code> here tells us what
  the user pressed to categorize the highlighted country. If that
  key is in the <code>categories</code> hash then we put it
  into <code>categorizations</code>.</p>

<pre class="code">(<span class="keyword">define</span> <span class="variable-name">categories</span> #hash((select . <span class="string">"eeeeff"</span>)
                         (<span class="racket-selfeval">#\1</span> . <span class="string">"993322"</span>)
                         (<span class="racket-selfeval">#\2</span> . <span class="string">"229911"</span>)
                         (<span class="racket-selfeval">#\3</span> . <span class="string">"ABCD31"</span>)
                         (<span class="racket-selfeval">#\4</span> . <span class="string">"91FF55"</span>)
                         (<span class="racket-selfeval">#\5</span> . <span class="string">"2439DF"</span>)))

(<span class="keyword">define</span> (<span class="function-name">handle-key</span> canvas categorizations key)
  (<span class="keyword">cond</span> [(<span class="builtin">equal?</span> <span class="racket-selfeval">#\backspace</span> key) <span class="comment-delimiter">; </span><span class="comment">undo
</span>         (swap! categorizations <span class="builtin">cdr</span>)]
        [(<span class="builtin">member</span> key (<span class="builtin">dict-keys</span> categories)) <span class="comment-delimiter">; </span><span class="comment">categorize
</span>         (swap! categorizations (<span class="builtin">curry</span> <span class="builtin">cons</span> key))]
        [(<span class="builtin">equal?</span> <span class="racket-selfeval">#\space</span> key) <span class="comment-delimiter">; </span><span class="comment">print state
</span>         (<span class="builtin">display</span> (<span class="builtin">unbox</span> categorizations))])
  (<span class="builtin">send</span> canvas refresh))</pre>

<h4>Nested updates: the bad parts</h4>

<p>Finally once we have a list of categorizationsÙ« we need to apply
  it to the map document and display. We apply
  a <a href="https://docs.racket-lang.org/reference/for.html?q=for%2Ffold#%28form._%28%28lib._racket%2Fprivate%2Fbase..rkt%29._for%2Ffold%29%29"><code>fold</code></a>
  reduction over the XML document struct and the list of country
  categorizations (plus <code>"select</code> for the country that"s
  selected to be categorized next) to get back a "modified" document
  struct where the proper elements have the style attributes applied
  for the given categorizationÙ« then we turn it into an image and
  hand it
  to <a href="https://docs.racket-lang.org/pict/Rendering.html?q=draw-pict#%28def._%28%28lib._pict%2Fmain..rkt%29._draw-pict%29%29"><code>draw-pict</code></a>:</p>

<pre class="code">(<span class="keyword">define</span> (<span class="function-name">update</span> original-doc categorizations)
  (<span class="keyword">for/fold</span> ([doc original-doc])
            ([category (<span class="builtin">cons</span> <span class="racket-selfeval">"select</span> (<span class="builtin">unbox</span> categorizations))]
             [n (<span class="keyword">in-range</span> (<span class="builtin">length</span> (<span class="builtin">unbox</span> categorizations)) <span class="racket-selfeval">0</span> <span class="racket-selfeval">-1</span>)])
    (set-style doc n (style-for category))))

(<span class="keyword">define</span> ((<span class="function-name">draw</span> doc categorizations) _ context)
  (<span class="keyword">let*</span> ([<span class="variable-name">newdoc</span> (update doc categorizations)]
         [<span class="variable-name">xml</span> (<span class="builtin">call-with-output-string</span> (<span class="builtin">curry</span> write-xml newdoc))])
    (draw-pict (<span class="builtin">call-with-input-string</span> xml svg-port-&gt;pict) context <span class="racket-selfeval">0</span> <span class="racket-selfeval">0</span>)))</pre>

<p>The problem is in that pesky <code>set-style</code> function. All it
  has to do is reach deep down into the <code>document</code> struct to
  find the <code>n</code>th <code>path</code> element (the one associated
  with a given country)Ù« and change its <code>"style</code>
  attribute. It ought to be a simple task. Unfortunately this
  function ends up being anything but simple:</p>

<pre class="code"><span class="comment">;; you don"t need to understand this; just grasp how huge/awkward it is</span>
(<span class="keyword">define</span> (<span class="function-name">set-style</span> doc n new-style)
  (<span class="keyword">let*</span> ([<span class="variable-name">root</span> (document-element doc)]
         [<span class="variable-name">g</span> (<span class="builtin">list-ref</span> (element-content root) <span class="racket-selfeval">8</span>)]
         [<span class="variable-name">paths</span> (element-content g)]
         [<span class="variable-name">path</span> (<span class="builtin">first</span> (<span class="builtin">drop</span> (<span class="builtin">filter</span> element? paths) n))]
         [<span class="variable-name">path-num</span> (list-index (<span class="builtin">curry</span> <span class="builtin">eq?</span> path) paths)]
         [<span class="variable-name">style-index</span> (list-index (<span class="keyword">lambda</span> (x) (<span class="builtin">eq?</span> <span class="racket-selfeval">"style</span> (attribute-name x)))
                                  (element-attributes path))]
         [<span class="variable-name">attr</span> (<span class="builtin">list-ref</span> (element-attributes path) style-index)]
         [<span class="variable-name">new-attr</span> (make-attribute (source-start attr)
                                   (source-stop attr)
                                   (attribute-name attr)
                                   new-style)]
         [<span class="variable-name">new-path</span> (make-element (source-start path)
                                 (source-stop path)
                                 (element-name path)
                                 (<span class="builtin">list-set</span> (element-attributes path)
                                           style-index new-attr)
                                 (element-content path))]
         [<span class="variable-name">new-g</span> (make-element (source-start g)
                              (source-stop g)
                              (element-name g)
                              (element-attributes g)
                              (<span class="builtin">list-set</span> paths path-num new-path))]
         [<span class="variable-name">root-contents</span> (<span class="builtin">list-set</span> (element-content root) <span class="racket-selfeval">8</span> new-g)])
    (make-document (document-prolog doc)
                   (make-element (source-start root)
                                 (source-stop root)
                                 (element-name root)
                                 (element-attributes root)
                                 root-contents)
                   (document-misc doc))))</pre>

<p>The reason for this is that while structs are immutableÙ« they
  don"t support functional updates. Whenever you"re working with
  immutable data structuresÙ« you want to be able to say "give me a
  new version of this dataÙ« but with field <code>x</code> replaced by
  the value of <code>(f (lookup x))</code>". Racket
  can <a href="https://docs.racket-lang.org/reference/dicts.html?q=dict-update#%28def._%28%28lib._racket%2Fdict..rkt%29._dict-update%29%29">do
  this with dictionaries</a> but not with structs<sup><a href="#fn2">2</a></sup>.  If you want a
  modified version you have to create a fresh
  one<sup><a href="#fn3">3</a></sup>.</p>

<h4>Lenses to the rescue?</h4>

<img src="/i/first-lensman.jpg" alt="first lensman" class="left">

<p>When I brought this up in the <code>#racket</code> channel on
  FreenodeÙ« I was helpfully pointed to the 3rd-party
  <a href="https://docs.racket-lang.org/lens/lens-guide.html">Lens</a>
  library. Lenses are a general-purpose way of composing arbitrarily
  nested lookups and updates. Unfortunately at this time
  there"s <a href="https://github.com/jackfirth/lens/issues/290">a
  flaw</a> preventing them from working with <code>xml</code> structsÙ« so
  it seemed I was out of luck.</p>

<p>But then I was pointed
  to <a href="https://docs.racket-lang.org/pollen/second-tutorial.html?q=xexpr#%28part._.X-expressions%29">X-expressions</a>
  as an alternative to
  structs. The <a href="https://docs.racket-lang.org/xml/index.html?q=xexpr#%28def._%28%28lib._xml%2Fmain..rkt%29._xml-~3exexpr%29%29"><code>xml->xexpr</code></a>
  function turns the structs into a deeply-nested list tree with
  symbols and strings in it. The tag is the first item in the listÙ«
  followed by an associative list of attributesÙ« then the element"s
  children. While this gives you fewer up-front guarantees about the
  structure of the dataÙ« it does work around the lens issue.</p>

<p>For this to workÙ« we need to compose a new lens based on the
  "path" we want to use to drill down into the <code>n</code>th country
  and its <code>style</code>
  attribute. The <a href="https://docs.racket-lang.org/lens/lens-reference.html#%28def._%28%28lib._lens%2Fcommon..rkt%29._lens-compose%29%29"><code>lens-compose</code></a>
  function lets us do that. Note that the order here might be
  backwards from what you"d expect; it works deepest-first (the way
  <a href="https://docs.racket-lang.org/reference/procedures.html#%28def._%28%28lib._racket%2Fprivate%2Flist..rkt%29._compose%29%29"><code>compose</code></a>
  works for functions). Also note that defining one lens gives us
  the ability to both get nested values
  (with <a href="https://docs.racket-lang.org/lens/lens-reference.html?q=lens-view#%28def._%28%28lib._lens%2Fcommon..rkt%29._lens-view%29%29"><code>lens-view</code></a>) <em>and</em> update them.</p>

<pre class="code">(<span class="keyword">define</span> (<span class="function-name">style-lens</span> n)
  (lens-compose (dict-ref-lens <span class="racket-selfeval">"style</span>)
                second-lens
                (list-ref-lens (<span class="builtin">add1</span> (<span class="builtin">*</span> n <span class="racket-selfeval">2</span>)))
                (list-ref-lens <span class="racket-selfeval">10</span>)))</pre>

<p>Our <code>&lt;path&gt;</code> XML elements are under the 10th item of
  the root xexprÙ« (hence the <a href="https://docs.racket-lang.org/lens/lens-reference.html?q=lens-view#%28def._%28%28lib._lens%2Fdata%2Flist..rkt%29._list-ref-lens%29%29"><code>list-ref-lens</code></a> with 10) and
  they are interspersed with whitespaceÙ« so we have to
  double <code>n</code> to find the <code>&lt;path&gt;</code> we
  want. The <a href="https://docs.racket-lang.org/lens/lens-reference.html?q=lens-view#%28def._%28%28lib._lens%2Fdata%2Flist..rkt%29._second-lens%29%29"><code>second-lens</code></a> call gets us to that element"s
  attribute alistÙ« and <a href="https://docs.racket-lang.org/lens/lens-reference.html?q=lens-view#%28def._%28%28lib._lens%2Fdata%2Fdict..rkt%29._dict-ref-lens%29%29"><code>dict-ref-lens</code></a> lets us zoom in on
  the <code>"style</code> key out of that alist.</p>

<p>Once we have our lensÙ« it"s just a matter of
  replacing <code>set-style</code> with a call
  to <a href="https://docs.racket-lang.org/lens/lens-reference.html?q=lens-view#%28def._%28%28lib._lens%2Fcommon..rkt%29._lens-set%29%29"><code>lens-set</code></a>
  in our <code>update</code> function we had aboveÙ« and then we"re
  off:</p>

<pre class="code">(<span class="keyword">define</span> (<span class="function-name">update</span> doc categorizations)
  (<span class="keyword">for/fold</span> ([d doc])
            ([category (<span class="builtin">cons</span> <span class="racket-selfeval">"select</span> (<span class="builtin">unbox</span> categorizations))]
             [n (<span class="keyword">in-range</span> (<span class="builtin">length</span> (<span class="builtin">unbox</span> categorizations)) <span class="racket-selfeval">0</span> <span class="racket-selfeval">-1</span>)])
    (lens-set (style-lens n) d (<span class="builtin">list</span> (style-for category)))))</pre>

<img src="/i/second-stage-lensman.jpg" alt="second stage lensman" class="right">

<p>Often times the trade-off between freeform maps/hashes vs
  structured data feels like one of convenience vs long-term
  maintainability. While it"s unfortunate that they can"t be used
  with the <code>xml</code> structs<sup><a href="#fn4">4</a></sup>Ù«
  lenses provide a way to get the best of both worldsÙ« at least in
  some situations.</p>

<p>The final version of the code clocks in at 51 lines and is
  is available <a href="https://gitlab.com/technomancy/world-color/blob/master/world-color.rkt">on GitLab</a>.</p>

<hr>

<div class="footnotes">

<p>[<a name="fn1">1</a>] The <a href="https://love2d.org">LÃ–VE</a>
  framework is the closest thingÙ« but it doesn"t have the same
  support for images as a first-class data type that works in the repl.</p>

<p>[<a name="fn2">2</a>] If you"re defining your own structsÙ« you
  can make
  them <a href="https://github.com/technomancy/cooper/blob/master/cooper/fstruct.rkt#L26">implement
  the dictionary interface</a>Ù« but with the <code>xml</code> library we
  have to use the struct definitions provided us.</p>

<p>[<a name="fn3">3</a>] Technically you can use
  the <a href="https://docs.racket-lang.org/reference/struct-copy.html"><code>struct-copy</code></a>
  functionÙ« but it"s not that much better. The field names must be
  provided at compile-timeÙ« and it"s no more efficient as it copies
  the entire contents instead of sharing internal structure. And it
  still doesn"t have an API that allows you to express the new value as a
  function of the old value.</p>

<p>[<a name="fn4">4</a>]
  Lenses <a href="https://docs.racket-lang.org/lens/lens-reference.html#(form._((lib._lens%2Fdata%2Fstruct..rkt)._define-struct-lenses))">work
  with most regular structs</a> as long as they
  are <a href="https://docs.racket-lang.org/guide/define-struct.html?q=transparent%20structs#%28part._trans-struct%29">transparent</a>
  and don"t use subtyping. Subtyping and opaque structs are
  generally considered bad form in modern RacketÙ« but you do find
  older libraries that use them from time to time.</p>
</div>
'),('https://technomancy.us/184', 'in which a path is charted through the coming apocalypse', '1508785453000',  10, '

<p>I"ve long counted myself among the grumpy old-timers who
  grudgingly accept the shift towards web-based-everything and just
  try to make the most of itÙ« wistfully remembering the days when I
  could just do everything from within Emacs. One of my core
  survival strategies in this web-first world has been to trick my
  browser into at least having the decency to pretend to be Emacs. I
  accomplished this in Firefox<sup><a href="#fn1">1</a></sup> with
  the <a href="https://github.com/mooz/keysnail/wiki">Keysnail</a>
  extension. Keysnail has remarkable flexibility in how it overrides
  Firefox"s default key bindings to match those of EmacsÙ« and
  everything has been more or less great.</p>

<p>UnfortunatelyÙ« <a href="https://blog.mozilla.org/addons/2016/11/23/add-ons-in-2017/">a
  soon-to-be-released update to Firefox</a> will remove the
  extension
  mechanism <a href="https://github.com/mooz/keysnail/issues/222">used
  by Keysnail</a>.</p>

<img src="/i/green-lake-laptop.jpg" alt="laptop at Green Lake" />

<p>I have felt very conflicted about thisÙ« because the old state of
  affairs is admittedly untenable. Firefox currently
  uses <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Gecko">Gecko</a>Ù«
  a decades-old rendering engine written in C++Ù« and like much
  software written in C++ it has a pretty distressing security track
  record. Version 57 of Firefox replaces parts of Gecko with
  functionality from <a href="https://servo.org">Servo</a>Ù« a
  browser engine implemented in the Rust programming language. Most
  of the bugs in Gecko which have led to embarrassing security flaws
  are simply impossible in Servo. The fact
  that so much safety-critical code is still being written in C++
  and similar languages is a sad state of affairsÙ« and we should
  celebrate changes that mean end users will no longer bear the penalty
  for programmers" reluctance to move beyond the technology of the
  1980s.</p>

<p>But on the other handÙ« losing the ability to shape your computing
  environment to your whims is <em>awful</em>. I lost track of how
  many times (when using Chromium or other keysnail-less browsers)
  I"ve wanted to throw my laptop out the window when I held
  down <kbd>ctrl-n</kbd> to scroll down and it opened seventeen new
  windows instead. I can"t remember ever wanting to open a new browser
  window in the past <em>decade</em>; why should I be stuck with a
  key bound to that command and no way to disable it?</p>

<p>Of courseÙ« the new Firefox will still have an extension
  mechanismÙ« but it"s a pale shadow of the old one. Citing the
  flimsy<sup><a href="#fn2">2</a></sup> excuse
  of <a href="https://github.com/lusakasa/saka-key/issues/53#issuecomment-332319791">security</a>Ù«
  key bindings like <kbd>C-n</kbd> are hard-coded into the browser
  and forbidden from being overridden.</p>

<img src="/i/tumwater.jpg" alt="Tumwater Falls" align="left" />

<p>Things were looking bleak for meÙ« and I contemplated whether I
  would switch to curl or just give up software development
  altogether for a career in goat-herding. I ended up finding a
  solution from a most unlikely place.</p>

<h4>EXWM saves the day</h4>

<p>I had heard of <a href="https://github.com/ch11ng/exwm">EXWM</a>
  a while agoÙ« and it struck me as a quixotic curiosity. The X
  Window System uses a network socket for its control protocolÙ«
  allowing a lot of flexibility including native forwarding of
  interfaces for remote programs. The developer of EXWM had taken an
  XML description of the specification for the network protocol and
  written a compiler to turn it
  into <a href="https://github.com/ch11ng/xelb/blob/master/xelb.el#L36">a
  library of Emacs Lisp functions</a> which he then used to
  implement a window manager in pure Emacs Lisp. While I admired the
  chutzpah this must have takenÙ« I assumed it was a novelty that
  could never be practical.</p>

<p>Eventually the Firefox conundrum prompted me to give it a second
  look due to a feature called Simulation
  Keys. The <tt>exwm-input-set-simulation-keys</tt> function allows
  you to define a translation mapping so that a certain key
  combination will be intercepted by EXWM when a non-Emacs program
  has focusÙ« and a different set of key input events will be sent
  instead. It seemed too good to be true; I could let go of Keysnail
  and instead get the same features applied to every program I
  use<sup><a href="#fn3">3</a></sup>.</p>

<p>I"m happy to report that EXWM does actually function startlingly
  well as a window manager. The simulation keys feature is amazing
  and puts my Firefox-related fears at easeÙ« and having all
  configuration written in a single language simplifies my setup
  dramatically. Every X window you launch is given an Emacs bufferÙ«
  and all your normal splits and window resizing commands work
  great with it. With the tiling window managers I used in the
  pastÙ« it was so unusual for me to use something other than the
  "one fullscreen window per display" setup that I would often
  forget the key bindings for splitting and rearranging
  windows. EXWM even integrates "system tray" programs into the Emacs
  echo areaÙ« so your wifi connect tool shows up unobtrusively in
  the bottom right corner.</p>

<p>There are a handful of gotchas. Emacs Lisp lacks general-purpose
  concurrency featuresÙ« but it does allow for concurrency when
  dealing with subprocesses and network communication. Most
  well-written Emacs Lisp will never block the main event loopÙ«
  which is good because when using EXWM that means the entire window
  manager is stuck until the blocking operation completes. I only
  came across two exceptions to this rule. One of them
  is <tt>smtpmail-send-it</tt>Ù« which can be replaced by
  the <a href="https://github.com/jwiegley/emacs-async/blob/master/smtpmail-async.el">smtpmail-async</a>
  library. The other is the <tt>racket-run</tt> commandÙ« which I was
  able
  to <a href="https://github.com/greghendershott/racket-mode/pull/282">patch
  in about an hour</a> to remove the blocking
  call<sup><a href="#fn4">4</a></sup>.</p>

<p>Other folks might run into more problems if they use other
  third-party libraries which don"t take care to use the network
  functions properly. But for my use<sup><a href="#fn5">5</a></sup>Ù«
  it"s been very smoothÙ« and I"m thrilled to have it.</p>

<p><b>Update</b>: I"ve
  started <a href="http://p.hagelb.org/exwm-ff-tabs.html">configuring my
  browser to open everything in new windows instead of new tabs</a>Ù«
  which sounds crazyÙ« but is very usefulÙ« because it means that you
  can use Emacs"s built-in buffer switching tools to change tabsÙ«
  which are much better than anything I"ve seen inside a browser.</p>

<hr>

<div class="footnotes">
<p>[<a name="fn1">1</a>] I used <a href="http://conkeror">Conkeror</a>
  for several yearsÙ« but eventually things got to the point where
  browsing without <a href="https://noscript.net">Noscript</a>
  became untenableÙ« and I could never get the two to work well together.</p>

<p>[<a name="fn2">2</a>] The rationale of "it"s for security" would
  stand up to a little more scrutiny if it weren"t for the fact that
  extensions <em>can</em> rebind <kbd>C-t</kbd>Ù« a key which is used
  hundreds if not thousands of times more often than <kbd>C-n</kbd>.</p>

<p>[<a name="fn3">3</a>]
  Granted <a href="http://www.gnumeric.org/">gnumeric</a> is the
  only program I use outside the browser and EmacsÙ« but it"s still
  greatly appreciated. I also use
  the <a href="https://key.saka.io/">Saka Key</a> extensionÙ« which
  implements Keysnail"s ability to trigger links from the keyboard
  even if they don"t have text attached to them.</p>

<p>[<a name="fn4">4</a>] I feel that the increasing "Emacs needs
  concurrency!" calls tend to overstate the problem. YesÙ« of course
  it would be nicer for the programmer to code using coroutines
  (coming in Emacs 26!) instead of callbacksÙ« but in the end this is
  a convenience for the authorÙ« not for the end user.</p>

<p>[<a name="fn5">5</a>] <a href="https://github.com/technomancy/dotfiles/blob/master/.emacs.d/phil/wm.el">My
    customizations</a> largely revolve around replacing
    my <a href="https://github.com/technomancy/dotfiles/blob/master/.xbindkeysrc.scm">xbindkeys</a>
    config with elispÙ« mapping workspace numbers to physical
    displaysÙ« and some <tt>eshell</tt> commands to give one eshell
    buffer per workspace. EXWM has XMonad-style workspaces where you
    can change the workspace for each display independently rather
    than forcing you to change them all at once like many more
    conventional WMsÙ« and I"m very glad it does.</p>
</div>
'),('https://technomancy.us/183', 'in which actors simulate a protocol', '1494795691000',  10, '

<p>I"ve been on a bit of a yak shave recently
  on <a href="">Bussard</a>Ù« my spaceflight programming adventure
  game. The game relies pretty heavily on simulating various
  computer systemsÙ« from your own craft to space stationsÙ« portalsÙ«
  roversÙ« and other craft. It naturally needs to simulate
  communications between all these.</p>

<p>I started with a pretty simple method of having each connection
  spin up its own coroutine running its own sandboxed session. Space
  station sessions
  run <a href="https://gitlab.com/technomancy/bussard/blob/threads/os/orb/resources/smash">smash</a>Ù«
  a vaguely bash-like shell in a faux-unixÙ« while connecting to a
  portal
  triggers <a href="https://gitlab.com/technomancy/bussard/blob/beta-2/os/lisp/resources/portal.lsp">a
  small lisp script to check for clearance and gradually activate
  the gateway sequence</a>. The main loop would allow each session"s
  coroutine a slice of time for each update tickÙ« but a
  badly-behaved script could make the frame rate
  suffer. (CoroutinesÙ« you will rememberÙ« are a form
  of <a href="https://en.wikipedia.org/wiki/Cooperative_multitasking">cooperative
  multitasking</a>; not only do they not allow more than one thing to
  literally be running at the same timeÙ« but handing control off
  must be done explicitly.) Also input and output was
  handled in a pretty ad-hoc method where Lua tables were used as
  channels to send strings to and from these session coroutines. But
  most problematic of all was the fact that there wasn"t any
  uniformity or regularity in the implementations of the various
  sessions.</p>

<img src="/i/bussard-rpc.png" alt="Bussard shell session">

<p>The next big feature I wanted to add was the ability to deploy
  rovers from your ship and SSH into them to control their
  movements or reprogram them. But I really didn"t want to add a
  third half-baked session type; I needed all the different implementations
  to conform to a single interface. This required some rethinking.</p>

<p>The codebase is written primarily in LuaÙ« but not just any
  Lua&mdash;it uses the <a href="https://love2d.org">LÃ–VE</a>
  framework. While Lua"s concurrency options are very limitedÙ«
  LÃ–VE offers <a href="https://love2d.org/wiki/love.thread">true
  OS threads</a> which run independently of each other. Now of
  course LÃ–VE can"t magically change the semantics of
  Lua&mdash;these threads are technically in the same process but
  cannot communicate directly. All communication happens
  over <a href="https://love2d.org/wiki/Channel">channels</a> (aka queues)
  which allow <em>copies</em> of data to be sharedÙ« but not actual
  state.</p>

<p>While these limitations could be annoying in some casesÙ« they
  turn out to be a perfect fit for simulating communications
  between separate computer systems. Moving to threads allows for
  much more complex programs to run on stationsÙ« portalsÙ« roversÙ«
  etc without adversely affecting performance of the game.</p>

<p>Each world
  has <a href="https://gitlab.com/technomancy/bussard/blob/threads/os/server.lua">a
  server thread</a> with a pair of input/output channels that gets
  started when you enter that world"s star system. Upon a
  successful loginÙ« a thread is created for that specific sessionÙ« which
  also gets its own <tt>stdin</tt> channel. Input from the main
  thread"s SSH client gets routed from the server thread to
  the <tt>stdin</tt> channel of each specific session. Each OS
  implementation can provide its own implementation of what
  a <a href="https://gitlab.com/technomancy/bussard/blob/threads/os/orb/session.lua">session
  thread</a> looks likeÙ« but they all exchange stdin and stdout
  messages over channels. Interactive sessions will typically run
  a shell like <tt>smash</tt> or a replÙ« and their thread parks
  on <tt><a href="https://love2d.org/wiki/Channel:demand">stdin:demand()</a></tt>Ù« waiting until the main thread
  has some input to send along.</p>

<p>This works great for regular input and outputÙ« but sometimes it"s
  necessary for the OS thread to make state changes to tables in the
  main threadÙ« such as
  the <a href="https://gitlab.com/technomancy/bussard/blob/threads/os/orb/resources/cargo">cargo</a>
  script for buying and selling. Time to build an RPC mechanism! I
  created <a href="https://gitlab.com/technomancy/bussard/blob/threads/rpcs.lua">a
  whitelist table of all functions which should be exposed</a> to
  code running in a session thread over RPC. Each of these is
  exposed as a shim function in the session"s sandbox:</p>

  <pre class="code"><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="function-name"><span class="region">add_rpc</span></span><span class="region"> = </span><span class="keyword"><span class="region">function</span></span><span class="region">(sandboxÙ« name)
   sandbox[name] = </span><span class="keyword"><span class="region">function</span></span><span class="region">(...)
      </span><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">chan</span></span><span class="region"> = love.thread.newChannel()
      output:push({op=</span><span class="string"><span class="region">"rpc"</span></span><span class="region">Ù« fn=nameÙ« args={...}Ù« chan=chan})
      </span><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">response</span></span><span class="region"> = chan:demand()
      </span><span class="keyword"><span class="region">if</span></span><span class="region">(response[1] == </span><span class="string"><span class="region">"_error"</span></span><span class="region">) </span><span class="keyword"><span class="region">then</span></span><span class="region">
         </span><span class="builtin"><span class="region">table</span></span><span class="region">.</span><span class="builtin"><span class="region">remove</span></span><span class="region">(responseÙ« 1)
         </span><span class="builtin"><span class="region">error</span></span><span class="region">(</span><span class="builtin"><span class="region">unpack</span></span><span class="region">(response))
      </span><span class="keyword"><span class="region">else</span></span><span class="region">
         </span><span class="keyword"><span class="region">return</span></span><span class="region"> </span><span class="builtin"><span class="region">unpack</span></span><span class="region">(response)
      </span><span class="keyword"><span class="region">end</span></span><span class="region">
   </span><span class="keyword"><span class="region">end</span></span><span class="region">
</span><span class="keyword"><span class="region">end</span></span><span class="region"></span></pre>

<p>When the shim function is called it sends an <tt>op="rpc"</tt>
  table with a new throwaway channel (used only for communicating
  the return value)Ù« and sends it back over the output channel. The
  main thread picks this upÙ« looks up the function in
  the <tt>rpcs</tt> tableÙ« and sends a message back over the
  response channel with the return value. This same RPC mechanism
  works equally well for scripts on space stations as it does for
  the portal control scriptÙ« and a similar variation (but going the
  other direction) allows the SSH client to implement tab completion
  by making an RPC call to get completion targets.</p>

<p>They"re not perfectÙ« but the mechanisms LÃ–VE offers for
  concurrency have been a great fit in this particular case.</p>
'),('https://technomancy.us/182', 'in which four pieces are placed in a row', '1486941307000',  10, '

<p>The other day my son and I were at a friend"s houseÙ« and we were
  just on our way home. As we were leaving he saw they had the game
  <a href="https://en.wikipedia.org/wiki/Connect_Four">Connect 4</a>
  and asked if we could play. Since we were on our way I told himÙ«
  "We can"t play the game nowÙ« but when we get homeÙ« we
  can <em>program</em> the gameÙ« and then play that." I wasn"t sure
  exactly how this would work outÙ« but I thought we"d have some fun
  on the way.</p>

<p>This isn"t the first time I"ve <a href="/179">adapted a physical
    game to a program with my kids</a>. But since then I"ve
    done <a href="https://gitlab.com/technomancy/liquid-runner">most</a>
    <a href="https://gitlab.com/technomancy/cardinality">of</a>
    <a href="https://gitlab.com/technomancy/mazes/blob/master/main.lua">my</a> 
    <a href="https://gitlab.com/technomancy/bussard">games</a> using
    <a href="https://love2d.org">LÃ–VE</a>Ù« the 2D Lua game framework
    along
    with <a href="https://gitlab.com/technomancy/polywell">Polywell</a>Ù«
    a text editor and development tool that runs in it. Polywell is
    roughly a port of EmacsÙ« and I"ve found that the foundation it
    provides of buffersÙ« modesÙ« and keymaps is useful for all kinds
    of games. As a bonusÙ« you can use the text editing features of
    Polywell to code the game from <em>within</em> the game itselfÙ«
    which makes experimentation and reloading seamless.</p>

<p>My son and I sat down and knocked out an implementation of
  Connect 4 pretty quickly using PolywellÙ« and I thought it would be
  interesting to step through how it works since it can serve as a
  very succinct explanation for how to use Polywell.</p>

<h4>State and Drawing</h4>
<pre class="code"><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">e</span></span><span class="region"> = </span><span class="builtin"><span class="region">require</span></span><span class="region">(</span><span class="string"><span class="region">"polywell"</span></span><span class="region">)

</span><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">board</span></span><span class="region"> = { {}Ù« {}Ù« {}Ù« {}Ù« {}Ù« {}Ù« {} }
</span><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">colors</span></span><span class="region"> = {red={255Ù«50Ù«50}Ù«yellow={255Ù«238Ù«0}}
</span><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">turn</span></span><span class="region"> = </span><span class="string"><span class="region">"yellow"</span></span><span class="region">
</span></pre>

<p>We start out by loading <tt>"polywell"</tt> and putting it in
  the <tt>e</tt> local (<em>e</em> for <em>editor</em>). Most of the
  game state is in the <tt>board</tt> table[<a href="#fn1">1</a>]Ù« which has an empty
  table for each column in it. The Connect 4 board has seven columns
  in which pieces can be dropped. It"s a bit unusualÙ« but we
  represent columns as lists of pieces from the bottom upÙ« because
  the tokens are subject to gravity and fall to the bottom of the
  column they"re placed in. Finally we set up <tt>colors</tt>
  which maps each player"s color name to an RGB triplet and store
  the final bit of state (the current turn) in the <tt>turn</tt>
  local. So far so good!</p>

<pre class="code"><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="function-name"><span class="region">draw</span></span><span class="region"> = </span><span class="keyword"><span class="region">function</span></span><span class="region">()
   </span><span class="keyword"><span class="region">for</span></span><span class="region"> </span><span class="variable-name"><span class="region">col</span></span><span class="region">=1Ù«7 </span><span class="keyword"><span class="region">do</span></span><span class="region">
      </span><span class="keyword"><span class="region">for</span></span><span class="region"> </span><span class="variable-name"><span class="region">n</span></span><span class="region">Ù«</span><span class="variable-name"><span class="region">color</span></span><span class="region"> </span><span class="keyword"><span class="region">in</span></span><span class="region"> </span><span class="builtin"><span class="region">ipairs</span></span><span class="region">(board[col]) </span><span class="keyword"><span class="region">do</span></span><span class="region">
         </span><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">x</span></span><span class="region">Ù«</span><span class="variable-name"><span class="region">y</span></span><span class="region"> = col * 75Ù« 800 - n*75
         love.graphics.setColor(colors[color])
         love.graphics.circle(</span><span class="string"><span class="region">"fill"</span></span><span class="region">Ù« xÙ« yÙ« 30)
      </span><span class="keyword"><span class="region">end</span></span><span class="region">
   </span><span class="keyword"><span class="region">end</span></span><span class="region">
</span><span class="keyword"><span class="region">end</span></span><span class="region"></span></pre>

<p>Our <tt>draw</tt> function is very natural once you understand
  the unusual structure of the <tt>board</tt>; we simply loop over
  each column with an inner loop over each piece in the column. The
  piece is represented by <tt>n</tt>Ù« its numeric position within
  the list of piecesÙ« and its <tt>color</tt>. We
  calculate <tt>x</tt> and <tt>y</tt> from the <tt>col</tt>
  and <tt>n</tt> respectively and draw a colored circle for each
  piece from the bottom of the column upwards. This is basically the
  only place we use the LÃ–VE framework directly.</p>

<h4>Modes and Bindings</h4>
<pre class="code"><span class="region">e.define_mode(</span><span class="string"><span class="region">"connect4"</span></span><span class="region">Ù« </span><span class="constant"><span class="region">nil</span></span><span class="region">Ù« {draw=drawÙ« read_only=</span><span class="constant"><span class="region">true</span></span><span class="region">})</span></pre>

<p>Using Polywell"s <tt>define_mode</tt> function we create a
  <tt>"connect4"</tt> mode which will contain all the key bindings for the
  game. Modes in Polywell are assumed to be textual unless otherwise
  specifiedÙ« but since our game is graphical we pass <tt>nil</tt> as
  the second argument because our mode does not inherit from any
  existing mode. For our third argumentÙ« we pass in our
  previously-defined <tt>draw</tt> function as the
  mode"s <tt>draw</tt> propertyÙ« overriding the default draw which
  simply displays the current mode"s text. We also mark it
  as <tt>read_only</tt> to avoid accidentally inserting any text
  into the buffer.</p>

<pre class="code"><span class="region">e.bind(</span><span class="string"><span class="region">"connect4"</span></span><span class="region">Ù« </span><span class="string"><span class="region">"escape"</span></span><span class="region">Ù« </span><span class="keyword"><span class="region">function</span></span><span class="region">() e.change_buffer(</span><span class="string"><span class="region">"*console*"</span></span><span class="region">) </span><span class="keyword"><span class="region">end</span></span><span class="region">)
e.bind(</span><span class="string"><span class="region">"connect4"</span></span><span class="region">Ù« </span><span class="string"><span class="region">"backspace"</span></span><span class="region">Ù« </span><span class="keyword"><span class="region">function</span></span><span class="region">()
          </span><span class="keyword"><span class="region">for</span></span><span class="region"> </span><span class="variable-name"><span class="region">i</span></span><span class="region">=1Ù«7 </span><span class="keyword"><span class="region">do</span></span><span class="region"> lume.clear(board[i]) </span><span class="keyword"><span class="region">end</span></span><span class="region">
</span><span class="keyword"><span class="region">end</span></span><span class="region">)</span></pre>

<p>Polywell"s <tt>bind</tt> function allows us to attach a function
  to be called when a specific keystroke is pressed in a specific
  mode. In this case we say that <tt>escape</tt> will switch back to
  the Lua console while <tt>backspace</tt> will just clear each column in
  the <tt>board</tt>.</p>

<pre class="code"><span class="keyword"><span class="region">for</span></span><span class="region"> </span><span class="variable-name"><span class="region">key</span></span><span class="region">=1Ù«7 </span><span class="keyword"><span class="region">do</span></span><span class="region">
   e.bind(</span><span class="string"><span class="region">"connect4"</span></span><span class="region">Ù« </span><span class="builtin"><span class="region">tostring</span></span><span class="region">(key)Ù« </span><span class="keyword"><span class="region">function</span></span><span class="region">()
             </span><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">column</span></span><span class="region"> = board[key]
             </span><span class="keyword"><span class="region">if</span></span><span class="region">(#column &gt;= 6) </span><span class="keyword"><span class="region">then</span></span><span class="region"> </span><span class="keyword"><span class="region">return</span></span><span class="region"> </span><span class="keyword"><span class="region">end</span></span><span class="region">
             </span><span class="builtin"><span class="region">table</span></span><span class="region">.</span><span class="builtin"><span class="region">insert</span></span><span class="region">(columnÙ« turn)
             turn = turn == </span><span class="string"><span class="region">"red"</span></span><span class="region"> </span><span class="keyword"><span class="region">and</span></span><span class="region"> </span><span class="string"><span class="region">"yellow"</span></span><span class="region"> </span><span class="keyword"><span class="region">or</span></span><span class="region"> </span><span class="string"><span class="region">"red"</span></span><span class="region">
</span></span><span class="region">   </span><span class="keyword"><span class="region">end</span></span><span class="region">)
</span><span class="keyword"><span class="region">end</span></span><span class="region"></span></pre>

<p>Almost done! Here"s where the meat of the game is. We loop from 1
  to 7Ù« which is the number of columns in the game. For each columnÙ«
  we <tt>bind</tt> that number key to a function which grabs the
  corresponding <tt>column</tt> table from the <tt>board</tt>. It
  checks to make sure the <tt>column</tt> isn"t full (each one can
  only hold 6 pieces) and if not it inserts the color of the current
  player into the column with <tt>table.insert</tt>. Then it
  changes the <tt>turn</tt> to the next player.</p>

<pre class="code"><span class="region">e.open(</span><span class="constant"><span class="region">nil</span></span><span class="region">Ù« </span><span class="string"><span class="region">"*connect4*"</span></span><span class="region">Ù« </span><span class="string"><span class="region">"connect4"</span></span><span class="region">)</span></pre>

<p>Finally it uses the <tt>open</tt> function to create a new buffer
  named <tt>"*connect4*"</tt> with <tt>"connect4"</tt> mode
  active. The first argument is <tt>nil</tt> because this buffer is
  not attached to the filesystem; it"s a free-floating thing that
  doesn"t get loaded or saved. You could leave this line out and
  Polywell would simply boot to a Lua console where you could
  invoke <tt>connect4</tt> mode manually from there.</p>

<p>And that"s it! 27 lines is all it tookÙ« and me and my son were
  off to the races playing the game. While we were writing it I kept
  him involved by asking each step of the way what we should do
  next. Once I wrote the <tt>draw</tt> function we were able to test
  it out by editing the <tt>board</tt> table directly using Lua code
  in the console. Our first pass of the number key function simply
  called <tt>table.insert</tt>Ù« so once we tried it out he was able
  to point out which features were still missingÙ« and I could ask
  leading questions which helped him piece together roughly what was
  needed to address those things.</p>

<p>Of course there"s a lot more that Polywell can doÙ« but it doesn"t
  take much code to get a simple game going. Try it for yourself;
  you might have a lot of fun.</p>

<hr>

<p>[<a name="fn1">1</a>] Lua tables can be a bit confusing since
  they"re a single data structure that can act both sequentially (as
  with <tt>board</tt> here which is basically used as a vector/array) or
  associatively (as with <tt>colors</tt> which acts like a map). The
  thing to remember is that the sequential/associative property is
  not inherent in the table but rather part of how it"s used.</p>
'),('https://raphlinus.github.io/gpu/2020/09/05/stack-monoid.html', 'The stack monoid', '1599318882000',  12, '<p>(Updated 2020-09-06 with pointers to related work and a bit more explanation)</p>

<p>This is a bit of a followup to <a href="https://raphlinus.github.io/personal/2018/05/10/toward-gpu-json-parsing.html">Towards GPGPU JSON parsing</a>. That proposed a rather roundabout way to parallelize a simple parsing task. Having had more GPU programming experience under my beltÙ« I donâ€™t expect that particular approach to work wellÙ« but it did suggest that parallelism exists in the problem.</p>

<p>This post is a writeup of a new ideaÙ« but with a cautionÙ« no implementation. It probably contains some mistakesÙ« and maybe the idea is flawed. But if it holds upÙ« I think itâ€™s an exciting line of research on how to port sequential algorithms to GPU.</p>

<p>For this postÙ« Iâ€™m going to pose an even more simplified version of the problem: for each open bracketÙ« record the index of the parent in the parse treeÙ« and for each close bracketÙ« the index of the corresponding open bracket.</p>

<p>This is a simple sequential program:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">stack</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">Ù«</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">input</span><span class="p">:</span>
        <span class="n">result</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">stack</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">stack</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">token</span> <span class="o">==</span> <span class="s">"["</span><span class="p">:</span>
            <span class="n">stack</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">token</span> <span class="o">==</span> <span class="s">"]"</span><span class="p">:</span>
            <span class="n">stack</span><span class="p">.</span><span class="n">pop</span><span class="p">()</span>
</code></pre></div></div>

<p>To follow the running example from the JSON postÙ« assume the input <code class="language-plaintext highlighter-rouge">[[][[][][[]]][][]]</code>. The result is:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>index 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17
input [  [  ]  [  [  ]  [  ]  [  [  ]  ]  ]  [  ]  [  ]  ]
value -  0  1  0  3  4  3  6  3  8  9  8  3  0 13  0 15  0
</code></pre></div></div>

<p>Can it be parallelized? Itâ€™s challenging to see howÙ« as there are dependencies on previous state. FurtherÙ« the state itself has unbounded size. It can be O(n); a pathological case is a million open brackets followed by a million close. In practiceÙ« depending on the workloadsÙ« we might expect more modest nesting depthÙ« but ideally weâ€™d like an algorithm that can handle all cases at least reasonably well.</p>

<p>Maybe we can do something. To longtime readers of my blog (and the â€œrope scienceâ€ series before that)Ù« it will be no surprise Iâ€™ll try to use monoids.</p>

<p>So letâ€™s turn this sequential program into a monoid. If I had a time portalÙ« Iâ€™d lens forward in time and use the handy automated tool that some enterprising PhD student will has done by then. ButÙ« failing thatÙ« Iâ€™ll do it in my head.</p>

<p>The monoid is basically a sequence of pops followed by a sequence of pushes. Since the pop operations (in this case) donâ€™t have a payloadÙ« they can be represented simply as a count. So the monoid is the pair <code class="language-plaintext highlighter-rouge">(n_popsÙ« elements)</code>. The primitive for push is <code class="language-plaintext highlighter-rouge">(0Ù« [element])</code>Ù« and for pop itâ€™s <code class="language-plaintext highlighter-rouge">(1Ù« [])</code>. The monoid operation is:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">combine</span><span class="p">(</span><span class="n">m1</span><span class="p">Ù«</span> <span class="n">m2</span><span class="p">):</span>
    <span class="n">n1</span><span class="p">Ù«</span> <span class="n">s1</span> <span class="o">=</span> <span class="n">m1</span>
    <span class="n">n2</span><span class="p">Ù«</span> <span class="n">s2</span> <span class="o">=</span> <span class="n">m2</span>
    <span class="k">if</span> <span class="n">n2</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)Ù«</span> <span class="n">s2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">n1</span><span class="p">Ù«</span> <span class="n">s1</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span> <span class="o">-</span> <span class="n">n2</span><span class="p">]</span> <span class="o">+</span> <span class="n">s2</span><span class="p">)</span>
</code></pre></div></div>

<p>And of courseÙ« the identity element is <code class="language-plaintext highlighter-rouge">(0Ù« [])</code>. One intuition for this monoid is that it represents a function from the state at the beginning of a sequence of tokens to the state at the end. If it indeed computes this function for arbitrary subsequencesÙ« then it it follows that itâ€™s a monoid from the fact that function composition is associative.</p>

<p>Running scanÙ« or generalized <a href="https://raphlinus.github.io/gpu/2020/04/30/prefix-sum.html">prefix sum</a>Ù« on this monoidÙ« will result in the desired result at the top of the stackÙ« i.e. the last element of the sequence in the monoid.</p>

<p><strong>Exercise:</strong> Show that this monoid is associative.</p>

<p>I do believe that an automated tool for translating these kinds of simple sequential programs is possibleÙ« and that thereâ€™s a theory behind it that illuminates ways in which monoids do and do not compose. Some composition is possibleÙ« for example you could fairly easily extend this idea so that each child knows its sequence number relative to its siblings. To do thatÙ« blend in the â€œcounting monoidÙ«â€ which is just integer addition.</p>

<p><strong>Exercise:</strong> Extend the monoid to handle sequence numbers.</p>

<p>If we had a bound on stack depthÙ« weâ€™d be pretty well set. The problem is the unbounded case. My original thinking was to have a window of (letâ€™s say size k) elementsÙ« and each pass would handle a slice of the stack of size k. I think this can be made to workÙ« but at heart it requires a number of passes proportional to stack depthÙ« so in the worst case O(n^2).</p>

<p>My new idea is to retain the single pass scanÙ« but use a purpose-built data structure to represent the stack. At the top is a window of k elementsÙ« then after that is a linked list (or perhaps a linked list of chunks; honestly I havenâ€™t worked through all the implicationsÙ« much less actually implemented and done performance measurement).</p>

<p>The combine operation tries to fit the new combined sequence in the window (up to a shared linkÙ« which it can just retain). But if it overflowsÙ« then it must allocateÙ« most likely using an atomic bump allocator into global memoryÙ« as is often done in piet-gpu.</p>

<h2 id="performance-analysis">Performance analysis</h2>

<p>To do a <em>real</em> performance analysis would require an implementationÙ« but it should be possible to reason about it a bit.</p>

<p>Clearly performance will be excellent if stack depth is shallow. The rate at which the linked list will be invoked will depend on the workloadÙ« and also the parallelism patterns. Itâ€™s worth noting that if the scan is run sequentiallyÙ« then the linked list operations will always be cheap. This is because the concatenation at the heart of the monoid operation is <em>asymmetrical</em> when using a linked list - a large sequence on the left is cheap when the sequence on the right is smallÙ« but not the other way around. When running the scan purely sequentiallyÙ« the monoid on the right is always of size 1 at most.</p>

<p>And the decoupled lookback implementation of scanÙ« which is state of the artÙ« runs essentially sequentially at large granularity; it just tries to exploit as much parallelism as the hardware provides at smaller granularity. Even with extremly deep nestingÙ« it should build and retain a linked list of the stack as it scansÙ« with a relatively smaller window for the part of the problem currently in flight.</p>

<p>There is another reason to be optimistic about performance. While the bandwidth of communication between partitions scales with the window sizeÙ« thatâ€™s not necessarily true for processing <em>within</em> a partition. Putting aside for a moment the relatively challenging problem of implementing an efficient GPU kernel (which by necessity would exploit SIMD parallelism)Ù« consider a decoupled look-back implementation running on a more traditional multicore CPUÙ« where each thread is sequential.</p>

<p>BasicallyÙ« the first pass runs the traditionalÙ« sequential stack algorithmÙ« with the modification that some of the input stack might not be available. At the end is the monoidÙ« with â€œn_popsâ€ being a count of the number of times that happenedÙ« and the sequence containing all the elements pushed inside that partition.</p>

<p>In the decoupled lookback phaseÙ« this monoid is published for consumption of partitions to the rightÙ« and the partition also computes the aggregate from partitions to the left. The cost of the monoid operations in this phase <em>will</em> be proportional to the size of the windowÙ« but keep in mind that the number of aggregates is orders of magnitude less than the number of elements.</p>

<p>FinallyÙ« in the second pass over the elementsÙ« the stack algorithm is run againÙ« and this time elements that were missing in the first pass are availableÙ« from the aggregate obtained during the decoupled lookback phase. As another potential optimizationÙ« the second pass might â€œjump overâ€ subtrees that were computed entirely locally within the partition in the first passÙ« only doing work on subtrees that cross partition boundaries.</p>

<p>ThusÙ« my analysis is that the work factor is <em>extremely</em> good for this algorithmÙ« meaning that on a 64 core processorÙ« it might come within striking distance of 64 times faster than a single core sequential implementation (obviously modulo all the usual other factors that make this challenging).</p>

<p>As I mentionedÙ« an efficient GPU kernel is likely to be challengingÙ« probably requiring tricky techniques to exploit SIMD (warp) parallelism without spending too much time computing the monoid compositionÙ« but the fact that it seems to work so well in the multicore case is an encouraging sign that an efficientÙ« fully GPU-tuned implementation is possible.</p>

<h2 id="related-work">Related work</h2>

<p>In an earlier draftÙ« I asked for relevant literature related to this idea. I still havenâ€™t found anything that presents this particular monoidÙ« or a tool that can derive it from its sequential sourceÙ« but there is a fair amount of related work.</p>

<p>ObviouslyÙ« <a href="https://github.com/simdjson/simdjson">simdjson</a> is an important exploration of deriving more parallelism from the JSON parsing taskÙ« with impressive results. It isÙ« I thinkÙ« complementary to this explorationÙ« as it exploits parallelism at a fine grainÙ« where this monoid approach is geared towards the larger grain of tree structure. But both are necessary for a performant GPU implementation; anyone intending to really parse JSON on GPU is well advised to study it.</p>

<p>Parsing CSV has some of the same problems as JSONÙ« though not the (potentially deeply) nested tree structure. A recent preprintÙ« <a href="https://arxiv.org/pdf/1905.13415.pdf">ParPaRaw: Massively Parallel Parsing of Delimiter-Separated Raw Data</a> presents a GPU implementation.</p>

<p>This <a href="https://github.com/rapidsai/cudf/pull/1512">PR to cudf</a> implements â€œJSON Linesâ€ parsingÙ« which seems to me more similar to CSV than full tree-structured JSON parsingÙ« but I havenâ€™t dug into it in detail.</p>

<p>There is also a large literature on incremental parsingÙ« which is related to parallel parsing as well (monoids are useful to both); a relevant example is <a href="https://www.cambridge.org/core/journals/journal-of-functional-programming/article/efficient-parallel-and-incremental-parsing-of-practical-contextfree-languages/4D620F0BFADE2B588F854AAAEA252F5C">Efficient parallel and incremental parsing of practical context-free languages</a>.</p>

<p>I linked it in my previous blogÙ« but <a href="https://scholarworks.iu.edu/dspace/handle/2022/24749">Aaron Hsuâ€™s PhD thesis</a> is a remarkable full compiler implementation (for an APL-derived language) on GPU. It <em>does</em> address tree structureÙ« and I believe generally uses adjacency matrices to represent that.</p>

<p>An interesting paper on converting a sequential program into a monoid is <a href="https://dl.acm.org/doi/pdf/10.1145/3018882.3018891">Functional Parallels of Sequential Imperatives</a>Ù« and that has a lot of pointers into other literature. I havenâ€™t (yet) read it carefully enough to know whether it could derive the monoid stated above. Thereâ€™s also some literature on <a href="https://scholar.google.com/scholar?um=1&amp;ie=UTF-8&amp;lr&amp;cites=9891136685444157082">symbolic execution for deriving map-reduce aggregations</a> that could well be relevant.</p>

<h2 id="conclusions">Conclusions</h2>

<p>I am even more convinced than before that efficient parsing is possible on GPU. The â€œstack monoidâ€ shows promise to be a fundamental building block to represent the parse stackÙ« and in general to manipulate tree structured data. I am unaware of any presentation of thisÙ« though itâ€™s likely it exists somewhere in the literature.</p>

<p>Automatically generating monoids such as the stack monoid from their corresponding simple sequential programs seems like an extremely promising area for research. If I were a professor (Iâ€™m not) and a PhD student brought it to me as a proposalÙ« I would be quite excited.</p>

<p>Part of the motivation for this exploration is to represent the â€œclip stackâ€ in piet-gpuÙ« which has turned out to be a bit of a tricky problem; Iâ€™m likely to compute at least some of that on CPU as a preprocessing step. But it would be appealingÙ« and very much in the spirit of piet-gpuÙ« to do all of that computation on the GPUÙ« and even more so if there are no artificial limits on nesting depth. If I do implement thatÙ« it will no doubt be another blog post (including quantitative measurements).</p>

<p>But in the meantimeÙ« Iâ€™m interested to see if other people take up these ideas. My JSON post has gotten a steady trickle of interest since it was published. Iâ€™d also like to learn if thereâ€™s literature thatâ€™s been published but I just havenâ€™t seen yet. If notÙ« it seems like a very rich vein of ore to mine.</p>

<p>(As a personal noteÙ« Iâ€™m taking a break from TwitterÙ« possibly a very long oneÙ« as Iâ€™m finding that social media has been really sapping my energy. The best way to get in touch with me for followup is email. I do love hearing from people though!)</p>

<p>Discuss on <a href="https://news.ycombinator.com/item?id=24385095">Hacker News</a>. Thanks to 
Vijay ChakravarthyÙ« George KulakowskiÙ« Eli RosenthalÙ« and Dan Rosen for pointers to the literatureÙ« and Chao Gao for posing a question about the original JSON post that sparked this exploration.</p>'),('https://raphlinus.github.io/covid/2020/07/08/seeking-truth.html', 'Seeking truth in a time of misinformation', '1594221102000',  12, '<p>Online abuse of trust is one of the topics Iâ€™ve studied deeplyÙ« including significant work toward an unfinished <a href="https://levien.com/thesis/thesis.pdf">PhD</a>Ù« and over two years working on a spam and abuse team at Google. These days my main work is on 2D graphicsÙ« but seeing patterns of misinformation about Covid-19 is bringing back interest and motivation to think about these topics.</p>

<p>As Covid-19 has been unfoldingÙ« Iâ€™ve spent significant time and energy trying to understand itÙ« as I tend to do with threats in general. In so doingÙ« Iâ€™ve developed some insight on how to tune media consumption patterns towards more truthful content and less misinformation.</p>

<h2 id="america-is-broken">America is broken</h2>

<p>The astonishingly poor national response to Covid-19 is heartbreaking. Given our incredible richness of resourcesÙ« it is surprising that many of the failure modes resemble those from low-income countries: superstitionÙ« cult of personalityÙ« suppression of scienceÙ« and straight up corruption. A common thread is misinformation and disinformation.</p>

<p>Our response to Covid-19 has been very much like driving a car with poorly-maintained brakes. Weâ€™ve done the equivalent of neglecting regular maintenanceÙ« ignoring the brake light on the dashboardÙ« and choosing to not to pay attention to the squishy feeling of the brake pedal. Itâ€™s as if thereâ€™s a devil on our shoulder sayingÙ« â€œoh noÙ« donâ€™t get the brakes fixedÙ« it might cost hundreds of dollars.â€</p>

<p>I think itâ€™s worth trying to understand <em>why</em> weâ€™re in that positionÙ« but itâ€™s beyond the scope of this blog post. Mass behavior of humans is pretty predictableÙ« but individual choices can probably make some difference. I have no answers for those who <em>want</em> to listen to that devil (a big challenge in and of itself)Ù« but for those would prefer to listen to the angel insteadÙ« I have some tips.</p>

<h2 id="it-is-a-partisan-issue">It is a partisan issue</h2>

<p>I often see the plea â€œit is not a partisan issueâ€ attached to factual arguments. I think this represents an aspiration: it <em>should</em> not be partisan. In 2020 AmericaÙ« the reality is that there is a powerful anti-scienceÙ« anti-truth factionÙ« and that faction makes up a large part of the composition of one of the political parties. Itâ€™s not 100% alignmentÙ« and I want to give credit where credit is due: for exampleÙ« the moderate Republican governor of Massachusetts has embraced science and investment in public healthÙ« and the results in that state are one of the best in the country.</p>

<p>But in generalÙ« any factual argument that has bearing on a political question such as â€œshould we invest in public healthâ€ or â€œshould we restructure the economy away from carbon consumptionâ€ is now inherently partisan.</p>

<p>Much of the partisan content in media is around issues that are not very consequentialÙ« either pure entertainmentÙ« or (at least traditionally) between candidates or parties that have comparable ability to govern. I was hopeful that the life or death nature of Covid-19 would motivate the people who decide what appears in media to higher standards. But apparentlyÙ« itâ€™s just the <a href="https://en.wikipedia.org/wiki/The_Scorpion_and_the_Frog">nature of the scorpion</a>Ù« they either canâ€™t help themselves or just donâ€™t care. Almost certainlyÙ« the media organization with the most blood on its hands is Fox NewsÙ« which actively promotes an anti-healthÙ« pro-infection agenda. I donâ€™t understand how they sleep at night.</p>

<p>Truth threatens a lot of existing power structures. If everybody woke up tomorrow and decided they were tired of being lied toÙ« there would be seismic shifts of power. Itâ€™s worth thinking about who might be most affected by such a thingÙ« and the kinds of things they do to keep it from happening.</p>

<h2 id="high-end-science-journalism">High-end science journalism</h2>

<p>Iâ€™m going to cover a range of information sources in this postÙ« but there is a tl;dr: read up on actual science journalism by people who know what theyâ€™re talking about. Coverage by ScienceÙ« NatureÙ« and STAT News has been uniformly excellent. Good journalism is always teamworkÙ« but Iâ€™ll also raise up the voices of particularly insightful individuals: <a href="https://twitter.com/sciencecohen">Jon Cohen</a> and <a href="https://twitter.com/kakape">Kai Kupferschmidt</a> of ScienceÙ« <a href="https://twitter.com/amymaxmen">Amy Maxmen</a> of NatureÙ« <a href="https://twitter.com/HelenBranswell">Helen Branswell</a> of STAT News. These are science journalists who have invested years in honing their craft.</p>

<p>Iâ€™ve also been impressed by coverage in The Atlantic. Their science content is quite good (thanks to top-notch contributors such as <a href="https://twitter.com/edyong209">Ed Yong</a>)Ù« but they also put the science in the context of American culture and politics. It is for this reasonÙ« I believeÙ« that our President has <a href="https://www.washingtonian.com/2020/05/27/the-atlantic-saw-subscriptions-surge-after-trump-tweet/">singled them out</a> for criticism.</p>

<p>Itâ€™s interesting that these sources tend to be publications that have been around for a while (STAT News is a brand of the Boston Globe media group). Itâ€™s not exactly rocket science how to do thisÙ« you just need to find experiencedÙ« capable writers and pay them to do journalismÙ« with editorial and institutional support. But in todayâ€™s hyper-capitalist societyÙ« sustaining such efforts is a struggle. If you canÙ« try to support publications that do good work by subscribingÙ« or donating in the case of non-profits.</p>

<p>For someone with a limited budget of time and attentionÙ« good science journalism is absolutely the best bang for the buck. The other recommendations in this post are for people who want to spend a little more effort to gainÙ« hopefullyÙ« a little more insight.</p>

<h2 id="twitter">Twitter</h2>

<p>By far the most interesting experience Iâ€™ve had has been Twitter. What makes Twitter unique is its extremely wide dynamic range of information quality: both the worst of the worst and the best of the best are well represented. (An example of an information source of low dynamic range is an encyclopedia: almost every article is pretty goodÙ« garbage and brilliance both being rare)</p>

<p>A well-curated Twitter feed is one of the best information sources available todayÙ« and following random people on Twitter is one of the worst.</p>

<p>Even though it has no formal structure such as subredditsÙ« Twitter functions as a set of overlapping communitiesÙ« often described as â€œX Twitterâ€ or â€œY Twitterâ€ (incidentallyÙ« a good explanation of how communities work on Twitter can be had in Jeff Jarvisâ€™ <a href="https://buzzmachine.com/2020/05/11/a-conversation-with-nathan-allebach-steak-umms-voice/">interview of the voice behind Steak-umm</a>). There are many experts who generously share their knowledge and thoughts with usÙ« and Iâ€™ve found that with a modest investment of timeÙ« itâ€™s possible to follow along.</p>

<p>In one of the <a href="https://www.youtube.com/channel/UCud8VIawWp17jKl2Lp0VvlQ">Jeff Jarvis interviews</a>Ù« they jokingly referred to â€œidiot TwitterÙ«â€ andÙ« though it was a jokeÙ« the concept has stuck with me. TwitterÙ« like all social media propertiesÙ« works by engaging very large numbers of people with content that appeals emotionally. The expert communities are far too small a fraction of Twitterâ€™s traffic to be profitable for themÙ« but they support them as a way to maintain the prestige of the platform. The replies of any popular post are filled with all manner of conspiracy theoryÙ« miracle cureÙ« denialÙ« blameÙ« andÙ« I think at least sometimesÙ« active disinformation by those who would do us harm (itâ€™s hard to tell the difference and the outcome is the same). I think of all that as â€œidiot Twitterâ€ and just do my best to avoid it. I also see it everywhereÙ« of courseÙ« not just TwitterÙ« and the quantity of it is a good measure of the value in a social media platform.</p>

<p>Twitter has a delicate balance to maintainÙ« as there are many aspects of the site design that push you toward â€œidiot Twitterâ€ even when youâ€™re trying to curate your experience to avoid it. One example that consistently frustrates me is the trending panelÙ« as that seems to be about half composed of idiot Twitter. Itâ€™s addictiveÙ« even soÙ« because it tempts you with the thrill of discovering things early. Iâ€™ve also found that itâ€™s easier to avoid junk on the desktop site than the mobile app. Iâ€™m worried the experience will degrade; Quora stands as a cautionary tale of what can happen to a relatively respectable site when they pursue clicks at the cost of all else.</p>

<p>Whether it would be viable to develop a social network designed for quality of discussion is another topic beyond this blog. Iâ€™m not especially hopeful on this frontÙ« as itâ€™s hard to see how it would be profitable. In any caseÙ« thereâ€™s not much value in wishing for the possibly impossibleÙ« as somebody seeking quality information can find it even today.</p>

<h3 id="list-curation">List curation</h3>

<p>One of the interesting features of Twitter is that people will curate and share lists of people they feel are worth following. My <a href="https://twitter.com/i/lists/1239639611694911489">covid-19 list</a> is one suchÙ« and a lot of thought went into it: Iâ€™ve intentionally included people with a wide range of expertise (includingÙ« for exampleÙ« <a href="https://twitter.com/j_g_allen">Joseph Allen</a> for his insight into healthy buildings and <a href="https://twitter.com/uche_blackstock">Dr. UchÃ© Blackstock</a> for expertise on health equity). Iâ€™ve also deliberately excluded people from this list who express strong political views or often use an emotional tone. Because of the latter criterionÙ« itâ€™s missing people I personally feel are worth listening toÙ« especially <a href="https://twitter.com/gregggonsalves">Gregg Gonsalves</a> and <a href="https://twitter.com/JeremyKonyndyk">Jeremy Konyndyk</a>. As alwaysÙ« your mileage may vary. The goal of this particular list is not to be comprehensiveÙ« itâ€™s to select a set of voices that have excellent signal to noise ratio; for a much more comprehensive listÙ« see <a href="https://twitter.com/i/lists/1237834151694303234">this one curated by Jeff Jarvis</a>.</p>

<p>One phenomenon Iâ€™ve noticed is that people at the top of these lists tend to recommend each other. I wouldnâ€™t be surprised if some automated evaluation (perhaps based on eigenvalues) could yield a good curated list. That saidÙ« in my past researchÙ« Iâ€™ve found that any automatic metric with an incentive will be <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">gamed</a>Ù« and invariably will lift up self-promoters over quietÙ« thoughtful voices.</p>

<p>Speaking of self-promotersÙ« two names do not belong on lists of top expertsÙ« but are often found there: Eric Feigl-Ding &amp; Laurie Garrett. Both are good communicatorsÙ« but are also sloppy enough with their science to get called out regularly. Inclusion of these names is a sign that a list of experts is not especially carefully curated.</p>

<p>Another important warning sign is lack of inclusion of women and people of color; mainstream media is often guilty of this. Health equity is an especially important part of the Covid-19 storyÙ« and not listening to expertise in this area is as irresponsible as it is predictable. <a href="https://twitter.com/angie_rasmussen">Dr. Angela Rasmussen</a> is a good critic of media representation problemsÙ« on top of being a brilliant virologist (she is co-author on that D614G paper mentioned below) and <a href="https://twitter.com/jeffjarvis/status/1247893251916324865">master Twitter communicator</a>.</p>

<h2 id="medium-quality-sources">Medium quality sources</h2>

<p>This section is easily skippableÙ« as these medium quality sources can be safely ignored. But if they make up a significant fraction of your information dietÙ« it might be useful to examine their flaws.</p>

<p>Itâ€™s been fascinating watching experts and more mainstream sources side by sideÙ« as coverage of stories so often sounds completely different. There are particular stories that seem to grab the attention of the media B ark:</p>

<ul>
  <li>
    <p>Anything indicating that Covid-19 is less serious than it really is. For exampleÙ« the Stanford seroprevalence studies were hyped massively in the pressÙ« even though they were based on shoddy science.</p>
  </li>
  <li>
    <p>Alarmist narratives as well (â€œif it bleedsÙ« it leadsâ€). An exceptionally good marker for this is the <a href="https://www.cell.com/cell/fulltext/S0092-8674(20)30817-5?sf235753727=1">D614G mutation</a>. In the mainstream pressÙ« including reporters I would ordinarily trustÙ« itâ€™s a widely believed fact that this mutation represents a deadlier strain of the virus. Even before attention on this specific mutationÙ« the excellent <a href="https://nextstrain.org/">Nextstrain</a> work was often misinterpreted as varying degrees of transmissibility or infectiousness (as <em>is</em> the case for influenza). It is possible that there will be a â€œthere thereâ€ on D614GÙ« but thereâ€™s no evidence yet for practical consequences.</p>
  </li>
  <li>
    <p>AndÙ« combining the two themes aboveÙ« the idea that the virus is â€œweakeningÙ«â€ seemingly based on theories of evolutionary pressure.</p>
  </li>
</ul>

<p>I spend a fair amount of time on <a href="https://news.ycombinator.com/">Hacker News</a> as a source of tech information and discussion. It tends to run about one Covid-19 story a dayÙ« and the quality of discourse there isÙ« regrettablyÙ« pretty bad. It is a reasonable source of insight into which particular strains of misinformation are widely believed by â€œtech brosÙ«â€ who tend not to be shy at all about confidently trumpeting their armchair takes.</p>

<p>I reserve special condemnationÙ« thoughÙ« for the NY Times opinion page. They frequently run pieces that are simply indefensible to anyone who cares about truthÙ« and wouldnâ€™t pass the laugh test if reviewed by experts. A fairly extreme but sadly not completely atypical example is the Brett Stephens column <a href="https://www.nytimes.com/2020/04/24/opinion/coronavirus-lockdown.html">America Shouldnâ€™t Have to Play by New York Rules</a>. It likely is the case that the NY Times opinion page accurately records the dominant narrative of those in powerÙ« and as such is a good window into that aspect of Americaâ€™s brokenness. Whenever they run a particular bad howlerÙ« <a href="https://twitter.com/gregggonsalves">Gregg Gonsalves</a> can usually be relied on to provide an expert critique.</p>

<p>I have not found video sources to be particularly helpful compared with the best of the other sources cited above (partly itâ€™s my bias toward text for complex thoughts)Ù« but of the cable news hostsÙ« Chris Hayes has been consistently above averageÙ« treating the topic seriously and avoiding oversimplification.</p>

<p>Iâ€™m not going to talk about actual low-quality sources hereÙ« though itâ€™s an extremely important part of understanding the climate of disinformation. I will noteÙ« thoughÙ« that I have actually deleted (not just paused) my accounts on Facebook properties.</p>

<h2 id="authority">Authority</h2>

<p>In a functioning governmentÙ« weâ€™d be able to rely on government authority as a good source of information. IndeedÙ« that could be seen as one of the primary functions of government. The CDC was once widely acclaimed as the best public health organization on the planetÙ« and an acknowledged leader on the world stage. Today it is muzzled and ineffective. A particular failure is guidance around masks. Through conflicting messages and weak communicationÙ« they have squandered a great deal of trust.</p>

<p>Another highly troubling story is their case fatality rate estimateÙ« which is much lower than expert consensus. Theyâ€™ve been repeatedly asked to provide data and scientific reasoningÙ« but donâ€™t even pretend to be able to defend their work.</p>

<p>As a resultÙ« youâ€™re in a situation whereÙ« as a computer scientist with a passing interest in Covid-19Ù« it is extremely likely that my estimate (0.5% - 1.0%) for infection fatality rate is more accurate than that of the disease authority of the landÙ« and by linking to <a href="https://twitter.com/CT_Bergstrom/status/1279612165201133570">Carl Bergstromâ€™s thread</a> I have just provided better scientific evidence for that assertion than the CDC is capable of managing. [IfÙ« in a couple monthsÙ« it turns out I am wrong and the CDC is rightÙ« by all means please use this post to discredit anything else I say thatâ€™s out of my lane.]</p>

<p>This state of affairs is a bit of a problem for organizations like search engines and social mediaÙ« who generally need clear criteria for whatâ€™s good information and whatâ€™s disinformationÙ« so naturally want to turn to authority. Since this blog post disagrees with the CDCÙ« it might well run afoul of these kinds of guidelines.</p>

<p>By contrastÙ« I was originally fairly critical of people like <a href="https://medium.com/@tomaspueyo">TomÃ¡s Pueyo</a> for self-promotion over proper expertise. But from his work as a â€œvice president of growthâ€ at a Silicon Valley startupÙ« he is clearly skilled in understanding communication and human behaviorÙ« and his â€œflattening the curveâ€ piece arguably saved many more lives than the CDCâ€™s halfhearted comms efforts. Even more impressively to meÙ« his <a href="https://medium.com/@tomaspueyo/coronavirus-the-hammer-and-the-dance-be9337092b56">The Hammer and the Dance</a> piece set out a roadmap in <em>March</em> with advanced concepts such as budget for staying below R = 1. By contrastÙ« our actual public health â€œleadershipâ€ appears to have been eating pasteÙ« blowing that budget on stupid shit like barsÙ« while leaving us in an impossible situation where we have to reopen schools in the fall without a viable plan to keep people safe. As I write thisÙ« the CDC is facing a firestorm of criticism for allowing political and non-science-based considerations to influence their guidance for schools in the fallÙ« andÙ« in trying to appease both sidesÙ« have lost their credibility with both as well. Leadership can come from many placesÙ« and we have to find it where we can get it.</p>

<p>That saidÙ« while the leadership of the CDC is broken in the same way as so many institutions in AmericaÙ« it still has lots of excellent people working for it. And donâ€™t confuse my criticism as being anti-expertÙ« quite the contrary. Armchair epidemiologists often cite failures (real or perceived) of authority as justification for why their rando opinions should be taken seriouslyÙ« but thatâ€™s just a logical fallacy.</p>

<h2 id="peer-reviewed-papers">Peer-reviewed papers</h2>

<p>I did a minor in molecular and cell biology as part of my masters degree at BerkeleyÙ« so I have more than a passing intellectual curiosity in such thingsÙ« but overall I am not a huge fan of lay consumption of scientific papers. A huge risk is cherry-picking. Itâ€™s possible to find support for just about any viewpoint in the peer-reviewed literatureÙ« and thatâ€™s actually working as it should be â€” itâ€™s how scientific conversations happen.</p>

<p>The hydroxychloroquine story dramatically illustrates potential failures of peer review. There are two layers to the HCQ story. Just looking at pure scienceÙ« itâ€™s quite routine for pharmaceuticals to show early promiseÙ« then on closer examinationÙ« no real benefit. Hydroxychloroquine is no different than dozens of others in this respect. ButÙ« of courseÙ« the other layer is that it was adopted as a miracle cureÙ« especially by leaders of certain political parties around the world. In the early daysÙ« this narrative was fueled by a peer-reviewed paper which was later retractedÙ« with the integrity of the journal <a href="https://retractionwatch.com/2020/04/12/elsevier-investigating-hydroxychloroquine-covid-19-paper/">questioned</a> (a <a href="https://blogs.sciencemag.org/pipeline/archives/2020/04/06/hydroxychloroquine-update-for-april-6">blog post by Derek Lowe</a> also makes good reading).</p>

<p>But the story gets weirder. While experts were converging around a consensus that HCQ had limited if any effectivenessÙ« a paper in the highly regarded Lancet journal seemed to definitely answer the question in the negativeÙ« to the contrary arguing that it was actively harmful. HoweverÙ« on closer examinationÙ« <a href="https://www.sciencemag.org/news/2020/06/mysterious-company-s-coronavirus-papers-top-medical-journals-may-be-unraveling">that paper turned out to be extremely suspect</a> and was also retracted. Given the rather obvious flawsÙ« how did it get published in the first place? My personal favorite narrative is from the <a href="https://respectfulinsolence.com/2020/06/05/surgisphere-debacle/">Respectful Insolence blog</a>Ù« as itâ€™s both factual and colorful. Adding to the strangenessÙ« one of the best <a href="https://www.medicineuncensored.com/a-study-out-of-thin-air">criticisms</a> of the Lancet paper (cited by that linked blog) is from James TodaroÙ« who is best known for publishing a <a href="https://ipfs.infura.io/ipfs/QmNcF4usFUJdGjTMtEXT1XAYybJvtLmEjaZnvNXN2n91Zh/">â€œpaperâ€</a> in favor of HCQ that overstated the credentials and affiliations of the authors in a way that verges on fraudulentÙ« if not crossing the line. Strange days.</p>

<p>The moral of this story is that appearing in a peer reviewed publication is nowhere near a guaranteed stamp of truth. As alwaysÙ« critical thinking wins. In monitoring #EpiTwitterÙ« Iâ€™ve seen the pattern quite frequently of some controversial paper appearing (very often â€œscience by press releaseâ€ before a proper preprint is even available)Ù« attracting skepticism and criticism early on. Frequently <a href="https://twitter.com/CT_Bergstrom">Carl Bergstrom</a>Ù« an <a href="https://callingbullshit.org/">expert on bullshit</a>Ù« is a strong voice of such criticism.</p>

<p>The equation changes of courseÙ« when one is willing to invest the time and energy to really study a topicÙ« to develop the background of knowledge to understand and appreciate the work.</p>

<p>Thereâ€™s a major discussion to be had regarding the flaws of peer reviewÙ« including the role of preprintsÙ« the gatekeeping role of publishersÙ« and fraudulent paper mills (see <a href="https://twitter.com/MicrobiomDigest">Elisabeth Bik</a> for a steady stream of offenders on this front)Ù« but thatâ€™s beyond this blog.</p>

<h2 id="you">You</h2>

<p>Iâ€™ve argued that you canâ€™t trust authority like the CDCÙ« and that mainstream sources fall far short of what we need. As a reader of my blogÙ« you likely have above average ability to discern truthful information from liesÙ« and you also probably can communicate reasonably effectively to other people. Because our systems and institutions are failing us so badlyÙ« the responsibility then falls on youÙ« my dear readerÙ« to do your part to improve science communication in generalÙ« and in particular around Covid-19.</p>

<p>Cut out disinformation. Seek out actual experts. Do your own critical thinkingÙ« and donâ€™t follow just because you like the source or feel alignment with their politics. Amplify voices worth amplifyingÙ« and donâ€™t give lies more oxygen. I hope these notes are useful in some way.</p>

<p>Thank you for these effortsÙ« and pleaseÙ« take care of ourselves and each other.</p>'),('https://raphlinus.github.io/xi/2020/06/27/xi-retrospective.html', 'xi-editor retrospective', '1593278163000',  12, '<p>A bit more than four years ago I started the <a href="https://github.com/xi-editor/xi-editor">xi-editor</a> project. Now I have placed it on the back burner (though there is still some activity from the open source community).</p>

<p>The original goal was to deliver a very high quality editing experience. To this endÙ« the project spent a rather large number of â€œnovelty pointsâ€:</p>

<ul>
  <li>Rust as the implementation language for the core.</li>
  <li>A rope data structure for text storage.</li>
  <li>A multiprocess architectureÙ« with front-end and plug-ins each with their own process.</li>
  <li>Fully embracing async design.</li>
  <li><a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type">CRDT</a> as a mechanism for concurrent modification.</li>
</ul>

<p>I still believe it would be possible to build a high quality editor based on the original design. But I <em>also</em> believe that this would be quite a complex systemÙ« and require significantly more work than necessary.</p>

<p>Iâ€™ve written the <a href="https://github.com/xi-editor/xi-editor/issues/1187#issuecomment-491473599">CRDT part of this retrospective</a> alreadyÙ« as a comment in response to a Github issue. That prompted good <a href="https://news.ycombinator.com/item?id=19886883">discussion</a> on Hacker News. In this postÙ« I will touch again on CRDT but will focus on the other aspects of the system design.</p>

<h2 id="origins">Origins</h2>

<p>The original motivation for xi came from working on the Android text stackÙ« and confronting two problems in particular. OneÙ« text editing would become very slow as the text buffer got bigger. TwoÙ« there were a number of concurrency bugs in the interface between the EditText widget and the keyboard (input method editor).</p>

<p>The culprit of the first problem turned out to be the <a href="https://developer.android.com/reference/android/text/SpanWatcher">SpanWatcher</a> interfaceÙ« combined with the fact that modern keyboards like to put a spelling correction span on each word. When you insert a characterÙ« all the successive spans bump their locations up by oneÙ« and then you have to send onSpanChanged for each of those spans to all the watchers. Combined with the fact that the spans data structure had a naive O(n) implementationÙ« and the whole thing was quadratic or worse.</p>

<p>The concurrency bugs boil down to synchronizing edits across two different processesÙ« because the keyboard is a different process than the application hosting the EditText widget. ThusÙ« when you send an update (to move the cursorÙ« for example) and the text on the other side is changing concurrentlyÙ« itâ€™s ambiguous whether it refers to the old or new location. This was handled in an â€œalmost correctâ€ styleÙ« with timeouts for housekeeping updates to minimize the chance of a race. A nice manifestation of that is that swiping the cursor slowly through text containing complex emoji could cause flashes of the emoji breaking.</p>

<p>These problems have a unifying thread: in both cases there are small diffs to the textÙ« but then the data structures and protocols handled these diffs in a less than optimal wayÙ« leading to both performance and correctness bugs.</p>

<p>To a large extentÙ« xi started as an exploration into the â€œright wayâ€ to handle text editing operations. In the case of the concurrency bugsÙ« I was hoping to find a generalÙ« powerful technique to facilitate concurrent text editing in a distributed-ish system. While most of the Operational Transformation literature is focused on multiple users collaboratively editing a documentÙ« I was hoping that other text manipulations (like an application enforcing credit card formatting on a text input field) could fit into the general framework.</p>

<p>That was also the time I was starting to get heavily into RustÙ« so it made natural sense to start prototyping a new green-field text editing engine. How would you â€œsolve textâ€ if you were free of backwards compatibility constraints (a huge problem in Android)?</p>

<p>When I startedÙ« I knew that Operational Transformation was a solution for collaborative editingÙ« but had a reputation for being complex and finicky. I had no idea how deep the rabbithole would be of OT and then CRDT. Much of that story is told in the <a href="https://news.ycombinator.com/item?id=19886883">CRDT discussion</a> previously linked.</p>

<h2 id="the-lure-of-modular-software">The lure of modular software</h2>

<p>There is an extremely long history of people trying to build software as composable modules connected by some kind of inter-module communication fabric. Historical examples include <a href="https://en.wikipedia.org/wiki/DCE/RPC">DCE/RPC</a>Ù« <a href="https://en.wikipedia.org/wiki/Common_Object_Request_Broker_Architecture">Corba</a>Ù« <a href="https://en.wikipedia.org/wiki/Bonobo_(GNOME)">Bonobo</a>Ù« and more recently things like <a href="https://sandstorm.io/">Sandstorm</a> and <a href="https://fuchsia.dev/fuchsia-src/concepts/modular/module">Fuchsia Modular</a>. There are some partial successesÙ« including <a href="https://developer.android.com/reference/android/os/Binder">Binder</a> on AndroidÙ« but this is still mostly an unrealized vision. (Regarding BinderÙ« it evolved from a much more idealistic visionÙ« and I strongly recommend reading this 2006 interview about <a href="https://www.osnews.com/story/13674/introduction-to-openbinder-and-interview-with-dianne-hackborn/">OpenBinder</a>).</p>

<p>When I started xiÙ« there were signs we were getting there. Microservices were becoming popular in the Internet worldÙ« and of course all Web apps have a client/server boundary. Within GoogleÙ« <a href="https://grpc.io/">gRPC</a> was working fairly wellÙ« as was the internal process separation within Chrome. In Unix landÙ« thereâ€™s a long history of the terminal itself presenting a GUI (if primitiveÙ« though gaining features such as color and mouse). Thereâ€™s also the tradition of <a href="https://en.wikipedia.org/wiki/Blit_(computer_terminal)">Blit</a> and thenÙ« of courseÙ« <a href="https://en.wikipedia.org/wiki/NeWS">NeWS</a> and X11.</p>

<p>I think one of the strongest positive models was the database / business logic splitÙ« which is arguably the most successful example of process separation. In this modelÙ« the database is responsible for performance and integrityÙ« and the business logic is in a separate processÙ« so it can safely do things like crash and hang. I very much thought of xi-core as a database-like engineÙ« capable of handling concurrent text modification much like a database handles transactions.</p>

<p>Building software in such a modular way requires two things: firstÙ« infrastructure to support remote procedure calls (including serialization of the requests and data)Ù« and secondÙ« well-defined interfaces. Towards the end of 2017Ù« I saw the goal of xi-editor as <em>primarily</em> being about defining the interfaces needed for large scale text editingÙ« and that this work could endure over a long period of time even as details of the implementation changed.</p>

<p>For the infrastructureÙ« we chose JSON (about which more below) and hand-rolled our own xi-rpc layer (based on JSON-RPC). It turns out there are a lot of details to get rightÙ« including dealing with error conditionsÙ« negotiating when two ends of the protocol arenâ€™t exactly on the same versionÙ« etc.</p>

<p>One of the bolder design decisions in xi was to have a process separation between front-end and core. This was inspired in part by <a href="https://neovim.io/">Neovim</a>Ù« in which everything is a pluginÙ« even GUI. But the main motivation was to build GUI applications using RustÙ« even though at the time Rust was nowhere near capable of native GUI. The idea is that you use the best GUI technology of the platformÙ« and communicate via async pipes.</p>

<p>One argument for process separation is to improve overall system reliability. For exampleÙ« Chrome has a process per tabÙ« and if the process crashesÙ« all you get is an â€œAwÙ« snapâ€ without bringing the whole browser down. I think itâ€™s worth asking the question: is it useful to have the front-end continue after the core crashesÙ« or the other way around? I think probably not; in the latter case it might be able to safely save the fileÙ« but you can also do that by frequently checkpointing.</p>

<p>Looking backÙ« I see much of the promise of modular software as addressing goals related to project managementÙ« not technical excellence. IdeallyÙ« once youâ€™ve defined an inter-module architectureÙ« then smaller teams can be responsible for their own moduleÙ« and the cost of coordination goes down. I think this type of project management structure is especially appealing to large companiesÙ« who otherwise find it difficult to manage larger projects. And the tax of greater overall complexity is often manageableÙ« as these big companies tend to have more resources.</p>

<h3 id="json">JSON</h3>

<p>The choice of JSON was controversial from the start. It did end up being a source of frictionÙ« but for surprising reasons.</p>

<p>The original vision was to write plug-ins in any languageÙ« especially for things like language servers that would be best developed in the language of that ecosystem. This is the main reason I chose JSONÙ« because I expected there would be high quality implementations in every viable language.</p>

<p>Many people complained about the fact that JSON escapes stringsÙ« and suggested alternatives such as <a href="https://msgpack.org/index.html">MessagePack</a>. But I knew that the speed of raw JSON parsing was a solved problemÙ« with a number of extremely high performance implementations (<a href="https://github.com/simdjson/simdjson">simdjson</a> is a good example).</p>

<p>Even soÙ« aside from the general problems of modular software as described aboveÙ« JSON was the source of two additional problems. For oneÙ« <a href="https://github.com/xi-editor/xi-mac/issues/102">JSON in Swift is shockingly slow</a>. There are <a href="https://forums.swift.org/t/rearchitecting-jsonencoder-to-be-much-faster/28139">discussions on improving it</a> but itâ€™s still a problem. This is surprising to me considering how important it is in many workloadsÙ« and the fact that itâ€™s clearly possible to write a high performance JSON implementation.</p>

<p>SecondÙ« on the Rust sideÙ« while <a href="https://serde.rs/">serde</a> is quite fast and very convenient (thanks to proc macros)Ù« when serializing a large number of complex structuresÙ« it bloats code size considerably. The xi core is 9.3 megabytes in a Linux release build (debug is an eye-watering 88MB)Ù« and a great deal of that bloat is serialization. There is work to reduce thisÙ« including <a href="https://github.com/dtolnay/miniserde">miniserde</a> and <a href="https://github.com/not-fl3/nanoserde">nanoserde</a>Ù« but serde is still by far the most mainstream.</p>

<p>I believe itâ€™s possible to do performantÙ« clean JSON across most languagesÙ« but people should knowÙ« weâ€™re not there yet.</p>

<h2 id="the-rope">The rope</h2>

<p>There are only a few data structures suitable for representation of text in a text editor. I would enumerate them as: contiguous stringÙ« gapped bufferÙ« array of linesÙ« piece tableÙ« and rope. I would consider the first unsuitable for the goals of xi-editor as it doesnâ€™t scale well to large documentsÙ« though its simplicity is appealingÙ« and memcpy is fast these days; if you know your document is always under a megabyte or soÙ« itâ€™s probably the best choice.</p>

<p>Array of lines has performance failure modesÙ« most notably very long lines. SimilarlyÙ« many good editors have been written using piece tablesÙ« but Iâ€™m not a huge fan; performance is very good when first opening the fileÙ« but degrades over time.</p>

<p>My favorite aspect of the rope as a data structure is its excellent worst-case performance. BasicallyÙ« there arenâ€™t any cases where it performs <em>badly.</em> And even the concern about excess copying because of its immutability might not be a real problem; Rust has a <a href="https://doc.rust-lang.org/std/sync/struct.Arc.html#method.make_mut">copy-on-write mechanism</a> where you can mutate in-place when thereâ€™s only one reference to the data.</p>

<p>The main argument against the rope is its complexity. I think this varies a lot by language; in C a gapped buffer might be preferableÙ« but I think in RustÙ« a rope is the sweet spot. A large part of the reason is that in CÙ« low level implementation details tend to leak through; youâ€™ll often be dealing with a pointer to the buffer. For the common case of operations that donâ€™t need to span the gapÙ« you can hand out a pointer to a contiguous sliceÙ« and things just donâ€™t get any simpler than that. ConverselyÙ« if any of the invariants of the rope are violatedÙ« the whole system will just fall apart.</p>

<p>In RustÙ« thoughÙ« things are different. Proper Rust style is for all access to the data structure to be mediated by a well-defined interface. Then the details about how thatâ€™s implemented are hidden from the user. A good way to think about this is that the implementation has complexityÙ« but that complexity is <em>contained.</em> It doesnâ€™t leak out.</p>

<p>I think the rope in xi-editor meets that ideal. A lot of work went into getting it rightÙ« but now it works. Certain thingsÙ« like navigating by line and counting UTF-16 code unitsÙ« are easy and efficient. Itâ€™s built in layersÙ« so could be used for other things including binary editing.</p>

<p>One of the best things about the rope is that it can readily and safely be shared across threads. Ironically we didnâ€™t end up making much use of that in xi-editorÙ« as it was more common to share across <em>processesÙ«</em> using sophisicated diff/delta and caching protocols.</p>

<p>A rope is a fairly niche data structure. You really only want it when youâ€™re dealing with large sequencesÙ« and also doing a lot of small edits on them. Those conditions rarely arise outside text editors. But for people building text editing in RustÙ« I think xi-rope holds up well and is one of the valuable artifacts to come from the project.</p>

<p>Thereâ€™s a good <a href="https://news.ycombinator.com/item?id=15381886">HN discussion of text editor data structures</a> where I talk about the rope moreÙ« and can also point people to the <a href="https://xi-editor.io/docs/rope_science_00.html">Rope science</a> series for more color.</p>

<h2 id="async-is-a-complexity-multiplier">Async is a complexity multiplier</h2>

<p>We knew going in that async was going to be a source of complexity. The hope is that we would be able to tackle the async stuff onceÙ« and that the complexity would be encapsulatedÙ« much as it was for the rope data structure.</p>

<p>The reality was that adding async made everything more complicatedÙ« in some cases considerably so. A particularly difficult example was dealing with word wrap. In particularÙ« when the width of the viewport is tied to the windowÙ« then live-resizing the window causes text to rewrap continuously. With the process split between front-end and coreÙ« and an async protocol between themÙ« all kinds of interesting things can go wrongÙ« including races between editing actions and word wrap updates. More fundamentallyÙ« it is difficult to avoid tearing-style artifacts.</p>

<p>One early relative success was implementing scrolling. The problem is thatÙ« as you scrollÙ« the front-end needs to sometimes query the core to fetch visible text thatâ€™s outside its cache. We ended up building thisÙ« but it took months to get it right. By contrastÙ« if we just had the text available as an in-process data structure for the UI to queryÙ« it would have been quite straightforward.</p>

<p>I should note that async in interactive systems is more problematic than the tamer variety often seen in things like web servers. ThereÙ« the semantics are generally the same as simple blocking threadsÙ« just with (hopefully) better performance. But in an interactive systemÙ« itâ€™s generally possible to observe internal states. You have to display <em>something</em>Ù« even when not all subqueries have completed.</p>

<p>As a conclusionÙ« while the process split with plug-ins is supportable (similar to the Language Server protocol)Ù« I now firmly believe that the process separation between front-end and core was not a good idea.</p>

<h2 id="syntax-highlighting">Syntax highlighting</h2>

<p>Probably the high point of the project was the successful implementation of syntax highlightingÙ« based on Tristan Humeâ€™s <a href="https://github.com/trishume/syntect">syntect</a> libraryÙ« which was motivated by xi. Thereâ€™s a lot more to say about this.</p>

<p>FirstÙ« TextMate / Sublime style syntax highlighting is not really all that great. It is quite slowÙ« largely because it grinds through a lot of regular expressions with capturesÙ« and it is also not very precise. On the plus sideÙ« there is a large and well-curated open source collection of syntax definitionsÙ« and itâ€™s definitely â€œgood enoughâ€ for most use. IndeedÙ« code that fools these syntax definitions (such as two open braces on the same line) is a good anti-pattern to avoid.</p>

<p>It may be surprising just how much slower regex-based highlighting is than fast parsers. The library that xi usesÙ« syntectÙ« is probably the fastest open source implementation in existence (the one in Sublime is faster but not open source). Even soÙ« it is approximately 2500 times slower for parsing Markdown than <a href="https://github.com/raphlinus/pulldown-cmark">pulldown-cmark</a>. And syntect doesnâ€™t even parse setext-style lists correctlyÙ« because Sublime style syntax definitions have to work line-at-a-timeÙ« and the line of dashes following a heading isnâ€™t available until the next line.</p>

<p>These facts influenced the design of xi in two important ways. FirstÙ« I took it as a technical challenge to provide a high-performance editing experience even on large filesÙ« overcoming the performance problems through async. SecondÙ« the limitations of the regex-based approach argued in favor of a modular plug-in architectureÙ« so that as better highlighters were developedÙ« they could be plugged in. I had some ambitions of creating a standard protocol that could be used by other editorsÙ« but this absolutely failed to materialize. For exampleÙ« Atom instead developed <a href="https://github.blog/2018-10-31-atoms-new-parsing-system/">tree-sitter</a>.</p>

<p>In any caseÙ« I dug in and did it. The resulting implementation is impressive in many ways. The syntax highlighter lives in a different processÙ« with asynchronous updates so typing is never slowed down. Itâ€™s also incrementalÙ« so even if changes ripple through a large fileÙ« it updates whatâ€™s on the screen quickly. Some of the sophistication is described in <a href="https://xi-editor.io/docs/rope_science_11.html">Rope science 11</a>.</p>

<p>There was considerable complexity in the implementation. Text was synchronized between the main xi-core process and the plug-inÙ« but for large filesÙ« the latter stores only a fixed-size cache; the cache protocol ended up being quite sophisticated. Updates were processed through a form of Operational TransformationÙ« so if a highlighting result raced a text editÙ« it would never color an incorrect region (this is still very much a problem for language server annotations).</p>

<p>As I saidÙ« syntax highlighting was something of a high point. The success suggested that a similar high-powered engineering approach could systematically work through the other problems. But this was not to be.</p>

<p>As part of this workÙ« I explored an alternative syntax highlighting engine based on parser combinators. If I had pursued thatÙ« the result would have been lightning fastÙ« of comparable quality to the regex approachÙ« and difficult to create syntax descriptionsÙ« as it involved a fair amount of manual factoring of parsing state. While the performance would have been nice to haveÙ« ultimately I donâ€™t think thereâ€™s much niche for such a thing. If I were trying to create the best possible syntax highlighting experience todayÙ« Iâ€™d adapt Marijn Haverbekeâ€™s <a href="https://marijnhaverbeke.nl/blog/lezer.html">Lezer</a>.</p>

<p>To a large extentÙ« syntax highlighting is a much easier problem than many of the others we facedÙ« largely because the annotations are a history-free function of the documentâ€™s plain text. The problem of determining indentation may seem similarÙ« but is dependent on history. And it basically doesnâ€™t fit nicely in the CRDT model at allÙ« as that requires the ability to resolve arbitrarily divergent edits between the different processes (imagine that one goes offline for a bitÙ« types a bitÙ« then the language server comes back online and applies indentation).</p>

<p>Another problem is that our plug-in interface had become overly specialized to solve the problems of syntax highlightingÙ« and did not well support the other things we wanted to do. I think those problems could have been solvedÙ« but only with significant difficulty.</p>

<h2 id="there-is-no-such-thing-as-native-gui">There is no such thing as native GUI</h2>

<p>As mentioned aboveÙ« a major motivation for the front-end / core process split was to support development of GUI apps using a polyglot approachÙ« as Rust wasnâ€™t a suitable language for building GUI. The theory was that youâ€™d build the GUI using whatever libraries and language that was most suitable for the platformÙ« basically the platformâ€™s native GUIÙ« then interact with the Rust engine using interprocess communication.</p>

<p>The strongest argument for this is probably macOSÙ« which at the time had Cocoa as basically <em>the</em> blessed way to build GUI. Most other platforms have some patchwork of tools. <a href="https://docs.microsoft.com/en-us/windows/apps/desktop/choose-your-platform">Windows</a> is particularly bad in this respectÙ« as thereâ€™s old-school (GDI+ based) win32Ù« WinFormsÙ« WPFÙ« XamarinÙ« and most recently <a href="https://microsoft.github.io/microsoft-ui-xaml/">WinUI</a>Ù« which nobody wants to use because itâ€™s Windows 10 only. Since xi beganÙ« macOS is now catching up in the number of official frameworksÙ« with <a href="https://developer.apple.com/mac-catalyst/">Catalyst</a> and SwiftUI added to the roster. Outside the realm of official Apple projectsÙ« lots of stuff is shipping in Electron these daysÙ« and there are other choices including QtÙ« FlutterÙ« SciterÙ« etc.</p>

<p>When doing some <a href="https://www.recurse.com/events/localhost-raph-levien">performance work</a> on xiÙ« I found to my great disappointment that performance of these so-called â€œnativeâ€ UI toolkits was often pretty poorÙ« even for what youâ€™d think of as the relatively simple task of displaying a screenful of text. A large part of the problem is that these toolkits were generally made at a time when software rendering was a reasonable approach to getting pixels on screen. These daysÙ« I consider GPU acceleration to be essentially required for good GUI performance. Thereâ€™s a whole other blog post in the queue about how some toolkits try to work around these performance limitations by leveraging the compositor moreÙ« but that has its own set of drawbacksÙ« often including somewhat ridiculous RAM usage for all the intermediate textures.</p>

<p>I implemented an OpenGL-based text renderer for xi-macÙ« and did similar explorations on WindowsÙ« but this approach gives up a lot of the benefits of using the native features (as a consequenceÙ« emoji didnâ€™t render correctly). BasicallyÙ« I discovered that there is a pretty big opportunity to build UI that doesnâ€™t suck.</p>

<p>Perhaps the most interesting exploration was on WindowsÙ« the <a href="https://github.com/xi-editor/xi-win">xi-win</a> project. Originally I was expecting to build the front-end in C# using one of the more mainstream stacksÙ« but I also wanted to explore the possibility of using lower-level platform capabilities and programming the UI in Rust. Early indications were positiveÙ« and this project gradually morphed into <a href="https://github.com/linebender/druid">Druid</a>Ù« a native Rust GUI toolkit which I consider very promising.</p>

<p>If I had said that I would be building a GUI toolkit from scratch as part of this work when I set outÙ« people would have rightly ridiculed the scope as far too ambitious. But that is how things are turning out.</p>

<h2 id="fuchsia">Fuchsia</h2>

<p>An important part of the history of the project is its home in Fuchsia for a couple years. I was fortunate that the team was willing to invest in the xi visionÙ« including funding Colinâ€™s work and letting me host Tristan to build multi-device collaborative editing as an intern project. In many ways the goals and visions alignedÙ« and the demo of that was impressive. UltimatelyÙ« thoughÙ« Fuchsia was not at the time (and still isnâ€™t) ready to support the kind of experience that xi was shooting for. Part of the motivation was also to develop a better IME protocolÙ« and that made some progress (continued by Robert LordÙ« and you can read about some of what we discovered in <a href="https://lord.io/blog/2019/text-editing-hates-you-too/">Text Editing Hates You Too</a>).</p>

<p>Itâ€™s sad this didnâ€™t work out betterÙ« but such is life.</p>

<h2 id="a-low-point">A low point</h2>

<p>My emotional tone over the length of the project went up and downÙ« with the initial enthusiasmÙ« stretches of slow goingÙ« a renewed excitement over getting the syntax highlighting doneÙ« and some other low points. One of those was learning about the <a href="https://github.com/atom-archive/xray">xray</a> project. I probably shouldnâ€™t have taken this personallyÙ« as it is <em>very common</em> in open source for people to spin up new projects for a variety of reasonsÙ« not least of which is that itâ€™s fun to do things yourselfÙ« and often you learn a lot.</p>

<p>Even soÙ« xray was a bit of a wake-up call for me. It was evidence that the vision I had set out for xi was not quite compelling enough that people would want to join forces. ObviouslyÙ« the design of xray had a huge amount of overlap with xi (including the choice of Rust and decision to use a CRDT)Ù« but there were other significant differencesÙ« particularly the choice to use Web technology for the UI so it would be cross-platform (the fragmented state of xi front-endsÙ« especially the lack of a viable Windows portÙ« was definitely a problem).</p>

<p>Iâ€™m putting this here because oftenÙ« how you <em>feel</em> about a project is just as importantÙ« even more soÙ« than technical aspects. I now try to listen more deeply to those emotional signalsÙ« especially valid criticisms.</p>

<h2 id="community">Community</h2>

<p>Part of the goal of the project was to develop a good open-source community. We did pretty wellÙ« but looking backÙ« there are some things we could have done better.</p>

<p>A lot of the friction was simply the architectural burden described above. But in general I think the main thing we could have done better is giving contributors more <em>agency.</em> If you have an idea for a feature or other improvementÙ« you should be able to come to the project and do it. The main role of the maintainers should be to help you do that. In xiÙ« far too often things were blocking on some major architectural re-work (we have to redo the plug-in API before you can implement that feature). One of the big risks in a modular architecture is that it is often expedient to implement things in one module when to do things â€œrightâ€ might require it in a different placeÙ« orÙ« even worseÙ« require changes in inter-module interfaces. We had these decisions a lotÙ« and often as maintainers we were in a gate-keeping role. One of the worst examples of this was vi keybindingsÙ« for which there was a great deal of community interestÙ« and even a <a href="https://github.com/Peltoche/vixi">project done off to the side</a> to try to achieve itÙ« but never merged into the main project.</p>

<p>So I think monolithic architecturesÙ« perhaps ironicallyÙ« are <em>better</em> for community. Everybody takes some responsibility for the quality of the whole.</p>

<p>In 2017 we hosted three Google Summer of Code Students: Anna ScholtzÙ« DzÅ©ng LÃªÙ« and Pranjal Paliwal. This worked out wellÙ« and I think GSoC is a great resource.</p>

<p>I have been fortunate for almost the entire time to have Colin Rofls taking on most of the front-line community interaction. To the extent that xi has been a good communityÙ« much of the credit is due him.</p>

<p>One of the things we have done very right is setting up a Zulip instance. Itâ€™s open to all with a Github accountÙ« but we have had virtually no difficulty with moderation issues. We try to maintain positive interactions around all thingsÙ« and lead by example. This continues as we pivot to other thingsÙ« and may be one of the more valuable spin-offs of the project.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The xi-editor project had very ambitious goalsÙ« and bet on a number of speculative research subprojects. Some of those paid offÙ« others didnâ€™t. One thing I would do differently is more clearly identify which parts are research and which parts are reasonably straightforward implementations of known patterns. I try to do that more explicitly today.</p>

<p>To a large extent the project was optimized for learning rather than shippingÙ« and through that lens it has been pretty successful. I now know a lot more than I did about building editor-like GUI applications in RustÙ« and am now applying that to making the <a href="https://github.com/linebender/druid">Druid</a> toolkit and the <a href="https://github.com/linebender/runebender">Runebender</a> font editor. Perhaps more importantÙ« because these projects are more ambitious than one person could really take onÙ« the community started around xi-editor is evolving into one that can sustain GUI in Rust. Iâ€™m excited to see what we can do.</p>

<p>Discuss on <a href="https://news.ycombinator.com/item?id=23663878">Hacker News</a> and <a href="https://www.reddit.com/r/rust/comments/hgzdu5/xieditor_retrospective/">/r/rust</a>.</p>'),('https://raphlinus.github.io/rust/graphics/gpu/2020/06/13/fast-2d-rendering.html', 'Fast 2D rendering on GPU', '1592068782000',  12, '<p>Previously on my quest for fast rendering of 2D vector graphics on GPUÙ« I have posted a <a href="https://raphlinus.github.io/rust/graphics/gpu/2020/06/01/piet-gpu-progress.html">piet-gpu update</a> and a deeper exploration into a <a href="https://raphlinus.github.io/rust/graphics/gpu/2020/06/12/sort-middle.html">sort-middle</a> architecture. These intermediate results showed promiseÙ« but fell short of my vision for truly high performance 2D GPU rendering.</p>

<p>I am now pleased to present an architecture that I believe does realize this vision. The performance is impressiveÙ« but more than thatÙ« the architecture is derived from principles and is founded on a general pipelineÙ« as opposed to being a collection of hacks in the service of benchmark results. As much work as possible is offloaded to the GPUÙ« which minimizes the risk of jank in UI rendering and lets us exploit the continuing performance improvements in GPU technology.</p>

<p>FurtherÙ« this rendering pipeline is well suited both for fully dynamic and (partially) static content. It does not rely on precomputationÙ« instead quickly processing the scenes into tiles for â€œfine rasterizationâ€ at the end of the pipeline. Even soÙ« static fragments of the scene can readily be retained and stitched togetherÙ« so that the CPU-side cost is minimized.</p>

<p>In shortÙ« I firmly believe that this is the architecture to beat.</p>

<p>I also want to be up-front about the limitations of the work. FirstÙ« the imaging model is still fairly limitedÙ« as Iâ€™ve been focusing on path rendering. I believe that the general nature of the pipeline makes the architecture amenable to a richer imaging model such as SVG or PDFÙ« but until thatâ€™s actually implementedÙ« itâ€™s somewhat speculative. SecondÙ« the implementation relies heavily on GPU compute capabilitiesÙ« so will not run on older hardware or drivers. I should also note that <a href="https://github.com/servo/pathfinder">Pathfinder</a> has a much better story on both fronts; in particular it has a â€œmix and matchâ€ architecture so that much work besides the fine rasterization can be done on CPU.</p>

<p>Another limitation is that complex scenes can require lots of memory. Certainly the current implementation doesnâ€™t do anything clever to deal with thisÙ« it just allocates buffers which are hopefully big enough. There are ways to deal with itÙ« but unfortunately it is a source of additional complexity.</p>

<p>The code is now merged to the main branch of the <a href="https://github.com/linebender/piet-gpu">piet-gpu</a> repo.</p>

<h2 id="how-it-works">How it works</h2>

<p>Iâ€™m not going to go into extreme detail hereÙ« rather try to provide an overview.</p>

<p><img src="/assets/sorta_block_diagram.png" alt="Block diagram of new architecture" /></p>

<p>The architecture is firmly based on the previous <a href="https://raphlinus.github.io/rust/graphics/gpu/2020/06/12/sort-middle.html">sort-middle</a> design. The major differenceÙ« thoughÙ« is the handling of path segments. In the previous designÙ« <em>all</em> elementsÙ« path segments includedÙ« were carried through the pipeline in sorted order to fine rasterization. Empirical evaluation showed that plumbing elements through the pipeline had a nontrivial cost.</p>

<p>Given this evidenceÙ« the solution became clear. Individual path segments within a path do not need to be kept sorted at all. For a fillÙ« the total winding number (or exact area calculation in the case of antialiased rendering) is the sum of the contributions from each path segment. SimilarlyÙ« for distance field rendering of strokesÙ« the final distance is the minimum of that to each stroke segment. In both casesÙ« the operation is associative and commutativeÙ« so the individual elements can be processed in any order.</p>

<p>ThusÙ« the pipeline splits into two parts; a sort-middle path for filled and stroked paths (andÙ« in the futureÙ« other graphic elements)Ù« and an unsorted pipeline for path segments. To coordinate the twoÙ« each path is assigned an id (just a sequence numberÙ« really)Ù« and each path segment is ascribed to its corresponding pathâ€™s id. A simple <em>tile allocation</em> kernel allocates and initializes a rectangular region of tiles for each path. Then coarse path rasterization proceeds directly from the path segmentsÙ« drawing into the tile structures by using an <code class="language-plaintext highlighter-rouge">atomicExchange</code> to insert segments into a linked list structure.</p>

<p>Coarse rasterization in the sorted pipeline is similar to the previous sort-middle architectureÙ« with some refinement. It inspects the rectangular tile region for each pathÙ« and marks non-empty tiles using an internal bitmap (this is a highly parallel and load-balanced operation). ThenÙ« each thread processes one tileÙ« and outputs commands for each element that was so markedÙ« in sorted order.</p>

<p>Backdrop processing is actually more straightforward than the previous version. When backdrop is needed (a path segment crossing a horizontal tile boundary)Ù« thereâ€™s just a simple <code class="language-plaintext highlighter-rouge">atomicAdd</code> of +1 or -1 to the backdrop for that tile. ThenÙ« another kernel performs a prefix sum across a scanline of tilesÙ« propagating that backdrop to the right. Tiles with nonzero backdrop but also no path segments get a â€œsolid colorâ€ command. One of the nice things about this architecture is that there is no O(n^2) for highly complex pathsÙ« as there was in previous iterations.</p>

<p>To meÙ« the performance is satisfying in a way not fulfilled by previous iterationsÙ« not only because itâ€™s fast (it is)Ù« but because itâ€™s <em>understandable.</em> Every cost in the pipeline has a reason. You have to keep paths sorted and composite them in orderÙ« and thereâ€™s a cost to doing that. But only pathsÙ« not segments within a pathÙ« so the cost is a lot less. And a nice feature of the pipeline is â€œperformance smoothness;â€ there arenâ€™t workloads where the performance degrades.</p>

<h2 id="gpu-side-flattening">GPU-side flattening</h2>

<p>There are two major lines of approach in the 2D rendering literature. One is for curves to interact directly with pixels. The other is for curves to be <em>flattened</em> into polylines first. Both approaches have advantages and disadvantages. BasicallyÙ« lines are simpler to handleÙ« but there are more of them.</p>

<p>PreviouslyÙ« following PathfinderÙ« I had the flattening on the CPU. The current codebase is the first iteration that moves the flattening to GPU. It uses the fancy new flattening algorithmÙ« though there is nothing particularly fancy about the implementation; though the algorithm has features that are helpful to parallel implementationÙ« such as computing the exact number of subdivisions before producing any of the pointsÙ« this was a fairly straightforward implementationÙ« each thread processing one curve.</p>

<p>An <a href="https://github.com/linebender/piet-gpu/commit/7118c8efc19df2e3682fb027cee6d8b391a6082e">earlier version</a> of the codeÙ« before GPU flatteningÙ« had a highly parallelÙ« load balanced implementation of â€œfat line renderingâ€ of linesÙ« but I didnâ€™t retain this for the curve-flattening version. It should be possible to combine the two; the general approach would be a queue of line segments stored in shared memoryÙ« with curve flattening filling the queue and another stage draining itÙ« doing the output to global memory. This remains as future workÙ« especially as performance is pretty good as-is. The algorithm is cleverÙ« and I hope I get a chance to describe it in more detail.</p>

<p>Doing flattening on the GPU unlocks layer optimizationsÙ« even in the presence of zoom and rotation. Almost certainlyÙ« the most important practical consequence is font rendering â€” a glyph can be rendered at any sizeÙ« actually with arbitrary affine transformationÙ« without any re-encoding work on the CPU.</p>

<h2 id="performance-discussion">Performance discussion</h2>

<p>FirstÙ« a disclaimer. Performance evaluation of GPU renderers is <em>hard.</em> There are so many variablesÙ« including details of driversÙ« effects of presentation and the compositorÙ« pipelining because there are async stagesÙ« which sources of overhead to count and which can be amortized over multiple frames. Because GPUs are so fastÙ« even a small CPU cost for uploading data is significant. AlsoÙ« quality of support for timer queries varies a lot (though itâ€™s pretty good for Vulkan). Because of all thatÙ« the performance numbers should be taken with a grain of salt. Even soÙ« I think the measurements are good enough to demonstrate the <em>massive</em> improvements we see over rendering techniques that involve the CPU.</p>

<p>These measurements were done on a Gigabyte Aero 14 laptop with an Intel i7-7700HQ CPUÙ« and both an Nvidia GTX 1060 and integrated HD 630 graphicsÙ« running Windows 10. The output canvas is 2048x1536 for piet-gpu and generally similar for the other renderers. The scale factor is 8x for tiger and 1.5x for paper-1 and paris-30k.</p>

<p>I compare three renderers. For piet-gpu I am counting only the rendering timeÙ« not encoding. I feel this is fair because it is designed to reuse encoded layers; they can be rotatedÙ« zoomedÙ« and subjected to arbitrary affine transformations. The cost of encoding is on the same order of magnitude as rendering; for tiger it is about 200usÙ« and about an order of magnitude less than parsing the SVG. Any application will <em>need</em> a way to retain layers some way or other in order to achieve good performance.</p>

<p>For <a href="https://github.com/servo/pathfinder">Pathfinder</a> I am comparing only the master branch (at <a href="https://github.com/servo/pathfinder/commit/0f3500921596bdb2924d7bd62c4f983afc9332ec">0f35009</a>). I take the maximum of CPU and GPU timesÙ« assuming that they are pipelined. This is generousÙ« as the assumption might not be validÙ« for example if the CPU is highly loaded doing other processing for the application. I should also note that there is a <a href="https://github.com/pcwalton/pathfinder/tree/gpu-tiling-dicing">development branch</a> which moves most of the tiling to the GPU and is showing <em>extremely</em> promising performanceÙ« comparable to piet-gpu.</p>

<p>For <a href="https://www.cairographics.org/">Cairo</a> I am benchmarking using the <code class="language-plaintext highlighter-rouge">--perf</code> option to <a href="https://github.com/RazrFalcon/resvg">resvg</a>â€™s rendersvg tool. I am counting only the â€œrenderingâ€ and not â€œpreprocessingâ€ times. The latter would add about another 50% to the total time. I also tried the <a href="https://github.com/jrmuizel/raqote">raqote</a> backend and found it to be approximately 1.5x to 2x slower than Cairo.</p>

<p>I should also note thatÙ« unlike last time aroundÙ« I <em>am</em> applying correct stroke style to the paris-30k exampleÙ« by doing preprocessing beforehand. This adds somewhat to rendering timeÙ« and makes the comparison with other renderers more fair. I am hopeful that it is possible to apply stroke styles GPU-sideÙ« through a combination of distance field rendering techniques (especially good for round joins and caps) and path-to-path transformationsÙ« which would probably have a performance profile broadly similar to flattening.</p>

<p>And now the graphs:</p>

<p><img src="/assets/piet_gpu_comparison.png" alt="Comparison of 2D rendering" /></p>

<p>Since the amount of time taken by piet-gpu rendering is barely visibleÙ« letâ€™s rescale the y axis to a maximum of 50ms:</p>

<p><img src="/assets/piet_gpu_comparison_scaled.png" alt="Comparison of 2D renderingÙ« scaled" /></p>

<p>I find these really exciting results. Moving rendering to GPU means that interactive frame rates are possible even with very complex documentsÙ« and even on Intel 630 the paper-1 example (dense vector text) runs in 7.6msÙ« meaning 60fps is possible with plenty of room to spare. (More detailed measurements are in a <a href="https://docs.google.com/spreadsheets/d/1L4GOqo07wKpBZIRAq98bbIF0oZNEmrmZVuDqHpuGGng/edit?usp=sharing">spreadsheet</a>Ù« but as a general rule of thumbÙ« the Intel HD 630 is about 5x slower than the GTX 1060). I am unaware of any published renderer with comparable performanceÙ« though I believe <a href="http://kunzhou.net/zjugaps/pathrendering/">Li et al</a> comes closeÙ« and it is entirely possible that <a href="https://fuchsia.googlesource.com/fuchsia/+/refs/heads/master/src/graphics/lib/compute/spinel/">Spinel</a> is faster; it is just very difficult to evaluate.</p>

<p>UnfortunatelyÙ« a lot of software we use today is stuck on CPU renderingÙ« which has performance nowhere near what is possible on GPU. We should do better.</p>

<h3 id="comparison-with-previous-post">Comparison with previous post</h3>

<p>Iâ€™m not going to go into a lot of detail comparing the current codebase with the previous post. I saw the fraction of time going into coarse rasterization go downÙ« but then as I made changes to add GPU-side flatteningÙ« the time went up. Of courseÙ« the overall performance is dramatically better because it is now capable of transformable vector layersÙ« and previously that would have required re-flattening on the CPU. In additionÙ« I am aware of a number of opportunities for optimizationÙ« so I am quite confident I could bring the numbers still lower. But this obsessive optimization takes a huge amount of time and effortÙ« and at some point I question how valuable it is; I believe the current codebase stands in proving the ideas viable.</p>

<h2 id="discussion-and-prospects">Discussion and prospects</h2>

<p>I believe I have demonstrated convincingly that moving almost all of the 2D rendering task to the GPU is viable and yields excellent performance. FurtherÙ« the ideas are generalÙ« and should adapt well to a range of graphics primitives and fine rendering techniques. I believe it would hold up well as an academic paperÙ« and would like to find the time to write it up as such.</p>

<p>Having got this farÙ« Iâ€™m not sure how much farther I want to take the piet-gpu codebase. I think an ideal outcome would be to have the ideas folded into existing open-source renderers like PathfinderÙ« and am encouraged by progress on that front. Even soÙ« I believe there is some benefit to exploring a GPU-centric approach to layers.</p>

<p>All of this work has been on my own time. In accordance with my <a href="https://raphlinus.github.io/curves/2019/05/10/spline-licensing-update.html">licensing policies</a>Ù« everything is published under a permissive open source licenseÙ« and with no patent protectionÙ« unlike other libraries such as <a href="https://sluglibrary.com/">Slug</a>. Going forwardÙ« my time is pretty well spoken forÙ« as Iâ€™m going to be working on <a href="https://github.com/linebender/runebender">Runebender</a> and <a href="https://github.com/xi-editor/druid">druid</a> full-time with generous financial support from Google Fonts. But I encourage people writing new 2D rendering engines to consider the techniques Iâ€™ve exploredÙ« and might be open to consulting arrangements.</p>

<p>People who are interested in more details (as this post is something of a high level overview) may want to read the <a href="https://docs.google.com/document/d/1HNf5PDLz-uzNRIEDLt787J9GHYKKPb511JU6so3OadU/edit?usp=sharing">design document</a> I wrote after implementing the previous sort-middle architecture and before starting coding on this. And thereâ€™s a <em>ton</em> of quite detailed discussion on the <a href="https://xi.zulipchat.com/#narrow/stream/197075-gpu">#gpu stream</a> on the xi zulip (signup requiredÙ« open to anyone with a Github account).</p>

<p>Iâ€™ve learned a lot from thisÙ« and hope others do too. And I hope we can collectively get to a world where jank in GUI and other 2D rendering applications is unusualÙ« rather than the norm. The hardware can certainly support itÙ« itâ€™s just a question of building the engine and integrating it into applications.</p>

<p>Many thanks to Patrick Walton for stimulating discussions which have helped clarify design questions.</p>'),('https://raphlinus.github.io/rust/graphics/gpu/2020/06/12/sort-middle.html', 'A sort-middle architecture for 2D graphics', '1591920462000',  12, '<p>In my recent <a href="https://raphlinus.github.io/rust/graphics/gpu/2020/06/01/piet-gpu-progress.html">piet-gpu update</a>Ù« I wrote that I was not satisfied with performance and teased a new approach. Iâ€™m on a quest to systematically figure out how to get top-notch performanceÙ« and this is a report of one station Iâ€™m passing through.</p>

<p>To recapÙ« piet-gpu is a new high performance 2D rendering engineÙ« currently a research protoype. While most 2D renderers fit the vector primitives into a GPUâ€™s rasterization pipelineÙ« the brief for piet-gpu is to fully explore whatâ€™s possible using the compute capabilities of modern GPUs. In shortÙ« itâ€™s a software renderer that is written to run efficiently on a highly parallel computer. Software rendering has been gaining more attention even for complex 3D scenesÙ« as the traditional triangle-centric pipeline is less and less of a fit for high-end rendering. As a striking exampleÙ« the new <a href="https://www.eurogamer.net/articles/digitalfoundry-2020-unreal-engine-5-playstation-5-tech-demo-analysis">Unreal 5</a> engine relies heavily on compute shaders for software rasterization.</p>

<p>The new architecture for piet-gpu draws heavily from the 2011 paper <a href="https://research.nvidia.com/publication/high-performance-software-rasterization-gpus">High-Performance Software Rasterization on GPUs</a> by Laine and Karras. That paper describes an all-compute rendering pipeline for the traditional 3D triangle workload. The architecture calls for sorting in the middle of the pipelineÙ« so that in the early stage of the pipelineÙ« triangles can be processed in arbitrary order to maximally exploit parallelismÙ« but the output render still correctly applies the triangles in order. In 3D renderingÙ« you can <em>almost</em> get away with unsorted renderingÙ« relying on Z-buffering to decide a winning fragmentÙ« but that would result in â€œZ-fightingâ€ artifacts and also cause problems for semitransparent fragments.</p>

<p>The original piet-metal architecture tried to avoid an explicit sorting step by traversing the scene graph from the rootÙ« each time. The simplicity is appealingÙ« but it also required redundant work and limited the parallelism that could be exploited. The new architecture adopts a similar pipeline structure as the Laine and Karras paperÙ« but with 2D graphics â€œelementsâ€ in place of triangles.</p>

<p>Central to the new piet-gpu architectureÙ« the scene is represented as a contiguous sequence of these elementsÙ« each of which has a fixed-size representation. The current elements are â€œconcatenate affine transformâ€Ù« â€œset line widthâ€Ù« â€œline segment for strokeâ€Ù« â€œstroke previous line segmentsâ€Ù« â€œline segment for fillâ€Ù« and â€œfill previous line segmentsâ€Ù« with of course many more elements planned as the capability of the renderer grows.</p>

<p>While triangles are more or less independent of each other aside from the order of blending the rasterized fragmentsÙ« these 2D graphics elements are a different beast: they affect graphics <em>stateÙ«</em> which is traditionally the enemy of parallelism. Filled outlines present another challenge: the effects are non-localÙ« as the interior of a filled shape depends on the winding number as influenced by segments of the outline that may be very far away. It is not obvious how a pipeline designed for more or less independent triangles can be adapted to such a stateful model. This post will explain how itâ€™s done.</p>

<h2 id="scan">Scan</h2>

<p>In generalÙ« a sequence of operationsÙ« each of which manipulates state in some wayÙ« must be evaluated sequentially. An extreme example is a cryptographic hash such as SHA-256. A parallel approach to evaluating such a function would upend our understanding of computation.</p>

<p>HoweverÙ« in certain cases parallel evaluation is quite practicalÙ« in particular when the change to state can be modeled as an associative operation. The simplest nontrivial example is counting; just divide up the input into <em>partitionsÙ«</em> count each partitionÙ« then sum those.</p>

<p>Can we design an associative operation to model the state changes made by the elements of our scene representation? AlmostÙ« and as weâ€™ll seeÙ« itâ€™s close enough.</p>

<p>At this stage in the pipelineÙ« there are three components to our state: the stroke widthÙ« the current affine transformÙ« and the bounding box. Written as sequential pseudocodeÙ« our desired state manipulation looks like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input an element.
If the previous element was "fill" or "stroke"Ù« reset the bounding box.
If the element is:
    "set line width"Ù« set the line width to that value.
    "concatenate transform"Ù« set the transform to the current transform times that.
    "line segment for fillÙ«" compute bounding boxÙ« and accumulate.
    "line segment for strokeÙ«" compute bounding boxÙ« expand by line widthÙ« and accumulate.
    "fill"Ù« output accumulated bounding box
    "stroke"Ù« output accumulated bounding box
</code></pre></div></div>

<p>Note that most graphics APIs have a â€œsaveâ€ operation that pushes a state onto a stackÙ« and â€œrestoreâ€ to pop it. Because we desire our state to be fixed-sizeÙ« weâ€™ll avoid those. InsteadÙ« to simulate a â€œrestoreâ€ operationÙ« if the transform was changed since the previous â€œsaveÙ«â€ the CPU encodes the inverse transform (this requires that transforms be non-degenerateÙ« but this seems like a reasonable restriction).</p>

<p>As the result of such processingÙ« each element in the input is annotated with a bounding boxÙ« which will be used in later pipeline stages for binning. The bounding box of a line segment is just that segment (expanded by line width in the case of strokes)Ù« but for a stroke or fill it is the union of the segments preceding it.</p>

<p>Given the relatively simple nature of the state modificationsÙ« we can design an â€œalmost monoidâ€ with an almost associative binary operator. I wonâ€™t give the whole structure here (itâ€™s in the code as [<code class="language-plaintext highlighter-rouge">element.comp</code>])Ù« but will sketch the highlights.</p>

<p>When modeling such state manipulationsÙ« it helps to think of the state changes performed by some contiguous slice of the inputÙ« then the combination of the effects of two contiguous slices. For exampleÙ« either or both slices can set the line width. If the second slice doesÙ« then at the end the line width is that valueÙ« no matter what the first slice did. If it doesnâ€™tÙ« then the overall effect is the same as the first slice.</p>

<p>The effect on the transform is even simplerÙ« itâ€™s just multiplication of the affine transformsÙ« already well known to be associative (but not commutative).</p>

<p>Where things get slightly trickier is the accumulation of the bounding boxes. The union of bounding boxes is an associative (and commutative) operatorÙ« but we also need a couple of flags to track whether the bounding box is reset. HoweverÙ« in generalÙ« affine transformations and bounding boxes donâ€™t distribute perfectly; the bounding box resulting from that affine transformation of a bounding box might be larger than the bounding box of transforming the individual elements.</p>

<p><img src="/assets/bbox_no_commute.svg" alt="Bounding box does not commute with rotation" /></p>

<p>For our purposesÙ« itâ€™s ok for the bounding box to be conservativeÙ« as itâ€™s used only for binning. If we restricted transforms to axis-alignedÙ« or if we used a convex hull rather than bounding rectangleÙ« then transforms would distribute perfectly and weâ€™d have a true monoid. But close enough.</p>

<p>When I wrote my <a href="https://raphlinus.github.io/gpu/2020/04/30/prefix-sum.html">prefix sum</a> blog postÙ« I had some idea it might be useful in 2DÙ« but did not know at that time how central it would be. HappilyÙ« that implementation could be adapted to handle the transform and bounding box calculation with only minor changesÙ« and itâ€™s lightning fastÙ« as weâ€™ll see below in the performance discussion.</p>

<p>Note that the previous version of piet-gpu (and piet-metal before it) required the CPU to compute the bounding box for each â€œitem.â€ Part of the theme of the new work is to offload as much as possible to the GPUÙ« including bounding box</p>

<h2 id="binning">Binning</h2>

<p>While element processing is totally different than triangle processing in the Laine and Karras paperÙ« binning is basically the same. The purpose of binning is fairly straightforward: divide the render target surface area into â€œbinsâ€ (256x256 pixels in this implementation)Ù« and for each bin output a list of elements that touch the binÙ« based on the bounding boxes as determined above.</p>

<p>If you look at the codeÙ« youâ€™ll see a bunch of concern about <code class="language-plaintext highlighter-rouge">right_edge</code>Ù« which is in service of the backdrop calculationÙ« which weâ€™ll cover in more detail below.</p>

<p>The binning stage is generally similar to cudarasterÙ« though I did refine it. Where cudaraster launches a fixed number of workgroups (designed to match the number of Streaming Multiprocessors in the hardware) and outputs a linked list of segmentsÙ« one per workgroup and partitionÙ« I found that this created a significant overhead in the subsequent merge step. ThusÙ« my design outputs a contiguous segment per <em>bin</em> and partitionÙ« which allows for more parallel reading in the merge stepÙ« though it has a small overhead of potentially outputting empty segments (I suspect this is the reason Laine and Karras did not pursue the approach). In both casesÙ« the workgroups do not need to synchronize with each otherÙ« and the elements <em>within</em> an output segment are kept sortedÙ« which reduces the burden in the subsequent merge step.</p>

<p>The binning stage is also quite fastÙ« not contributing significantly to the total render time.</p>

<p>Why such large binsÙ« orÙ« in other wordsÙ« so few of them? If binning is so fastÙ« it might be appealing to bin all the way down to individual tiles. But the design calls for one bin per threadÙ« so that would exceed the size of a workgroup (workgroup size is generally bounded around 1024 threadsÙ« and very large workgroups can have other performance issues). Of courseÙ« it may well still be possible to improve performance by tuning such factors; in general I used round numbers.</p>

<h2 id="coarse-rasterization">Coarse rasterization</h2>

<p>This pipeline stage was by far the most challenging to implementÙ« both because of the grueling performance requirements and because of how much logic it needed to incorporate.</p>

<p>The core of the coarse rasterizer is very similar to cudaraster. Internally it works in stagesÙ« each cycle consuming 256 elements from the bin until all elements in the bin have been processed.</p>

<ul>
  <li>
    <p>The first stage merges the bin outputsÙ« restoring the elements to sorted order. This stage repeatedly reads chunks generated in the binning stage until 256 elements are read (or the end of the input is reached).</p>
  </li>
  <li>
    <p>Next is the input stageÙ« with each thread reading one element. It also compute the coverage of that elementÙ« effectively painting a 16x16 bitmap. Thereâ€™s special handling of backdrops as wellÙ« see below.</p>
  </li>
  <li>
    <p>The total number of line segments is countedÙ« and space in the output is allocated using an atomic add.</p>
  </li>
  <li>
    <p>As in cudarasterÙ« segments are output in a highly parallel schemeÙ« with all output segments evenly divided between threadsÙ« so each thread has to do a small stage to find its work item.</p>
  </li>
  <li>
    <p>The commands for a tile are then written sequentiallyÙ« one tile per thread. This lets us keep track of per-tile stateÙ« and there tend to be many fewer commands than segments.</p>
  </li>
</ul>

<p>This is called â€œcoarse rasterizationâ€ because it is sensitive to the geometry of path segments. In particularÙ« coverage of tiles by line segments is done with a â€œfat line rasterizationâ€ algorithm:</p>

<p><img src="/assets/fat_line_rasterization.svg" alt="Diagram of fat line rasterization" /></p>

<h3 id="backdrop">Backdrop</h3>

<p>A special feature of coarse rasterization for 2D vector graphics is the filling of the interior of shapes. The general approach is similar to <a href="http://hhoppe.com/ravg.pdf">RAVG</a>; when an edge crosses the top edge of a tileÙ« a â€œbackdropâ€ is propagated to all tiles to the rightÙ« up to the right edge of the fillâ€™s bounding box.</p>

<p>While conceptually fairly straightforwardÙ« the code to implement this efficiently covers a number of stages in the pipeline. For oneÙ« the right edge of fills must be propagated back to segments within the fillÙ« even in early stages such as binning.</p>

<ul>
  <li>
    <p>The first right edge of each partition is recorded in the aggregate for each partition in element processing.</p>
  </li>
  <li>
    <p>The right edge is computed for each segment in binningÙ« and recorded in the binning output. This logic also adds segments to the binÙ« when they cross the top edge of a tile.</p>
  </li>
  <li>
    <p>In the input stage of coarse rasterizationÙ« segments that cross the top edge of a tile â€œdrawâ€ 1â€™s into the bitmap for all tiles to the rightÙ« again up to the right edge of the fill. The sign of the crossing is also noted in a separate bitmapÙ« but that doesnâ€™t need to be both per-element and per-tileÙ« as it is consistent for all tiles.</p>
  </li>
  <li>
    <p>In the output stage of coarse rasterizationÙ« bit counting operations are used to sum up the backdrop. ThenÙ« if there are any path segments in the tileÙ« the backdrop is recorded in the path command. OtherwiseÙ« if the backdrop is nonzeroÙ« a solid color command is output.</p>
  </li>
</ul>

<p>BasicallyÙ« the correct winding number is a combination of three rules. Within a tileÙ« a line segment causes a +1 winding number change in the region to the right of the line (sign flipped when direction is flipped). If the line crosses a vertical tile edgeÙ« an additional -1 is added to the half-tile below the crossing point. And if the line crosses a horizontal tile edgeÙ« +1 is added to all tiles to the right; this is known as â€œbackdropâ€ and is how tiles completely on the interior of a shape can get filled. Almost as if by magicÙ« the combination of these three rules results in the correct winding numberÙ« the tile boundaries erased. Another presentation of this idea is given in the <a href="http://hhoppe.com/ravg.pdf">RAVG</a> paper.</p>

<p><img src="/assets/fill_rule.svg" alt="Diagram of fat line rasterization" /></p>

<h2 id="fine-rasterization">Fine rasterization</h2>

<p>The fine rasterization stage was almost untouched from the previous piet-gpu iteration. I was very happy with the performance of that; the problem weâ€™re trying to solve is efficient preparation of tiles for coarse rasterization.</p>

<h2 id="encoding-and-layers">Encoding and layers</h2>

<p>The original dream for piet-gpu (and piet-metal) is that the encoding process is as light as possibleÙ« that the CPU really just uploads a representation of the sceneÙ« and the GPU processes it into a rendered texture. The new design moves even closer to this dream; in the originalÙ« the CPU was responsible for computing bounding boxesÙ« but now the GPU takes care of that.</p>

<p>Even more excitingÙ« the string-like representation opens up a simpler approach to layers than the original piet-metal architecture: just retain the byte representationÙ« and assemble them. In the simplest implementationÙ« this is just memcpy CPU-side before uploading the scene bufferÙ« but the full range of techniques for noncontiguous string representation is available. PreviouslyÙ« the idea was that the scene would be stored as a graphÙ« requiring tricky memory management.</p>

<p>An important special case is font rendering. The outline for a glyph can be encoded once to a byte sequence (generally on the order of a few hundred bytes)Ù« then a string of text can be assembled by interleaving these retained encodings with transform commands. In a longer term evolutionÙ« even this reference resolution might want to move to GPU as wellÙ« especially to enable texture cachingÙ« but this simpler approach should be viable as well.</p>

<p>Note that at the current code checkpointÙ« this vision is not fully realizedÙ« as flattening is still CPU-side. ThusÙ« a retained subgraph (particularly a font glyph) cannot be reused across a wide range of zooms. But I am confident this can be done.</p>

<h2 id="what-was-wrong-with-the-original-design">What was wrong with the original design?</h2>

<p>The original design worked pretty well for some workloadsÙ« but overall had disappointing (to me) performance. Now is a good time to go into some more detail.</p>

<p>To recapÙ« the original design was a series of four kernels: graph traversal (and binning to 512x32 â€œtilegroupsâ€)Ù« what I would now call coarse rasterization of path segmentsÙ« generation of per-tile command lists (which is the rest of coarse rasterization)Ù« and fine rasterization. The main difference is the scene representation; otherwise the stages overlap a fair amount. In the older designÙ« the CPU was responsible for encoding the graph structureÙ« both path segments within a fill/stroke pathÙ« and also the ability to group items together.</p>

<p>OverallÙ« the older design was efficient when the number of children of a node was neither large nor small. But outside that happy mediumÙ« performance would degradeÙ« and weâ€™ll examine why. Each of the first three kernels has a potential performance problem.</p>

<p>Starting at kernel 1 (graph traversal)Ù« the fundamental problem is that each workgroup of this kernel (responsible for a 512x512 region) did its own traversal of the input graph. For a 2048x1536 targetÙ« this means 12 workgroups. ActuallyÙ« that highlights another problem; this phase can become starved for parallelismÙ« a bigger relative problem on discrete graphics than integrated. ThusÙ« the cost of reading the input scene is multiplied by 12. In some casesÙ« that is not in fact a serious problem; if these nodes have a lot of children (for exampleÙ« are paths with a lot of path segments each)Ù« only the parent node is touched. Even betterÙ« if nodes are grouped with good spatial locality (which is likely realistic for UI workloads)Ù« culling by bounding box can eliminate much of the duplicate work. But for the specific case of lots of small objects (as might happen in a scatterplot visualizationÙ« for example)Ù« the work factor is not good.</p>

<p>The second kernel has different problems depending on whether the number of children is small or large. In the former caseÙ« since each thread in a workgroup reads one childÙ« there is poor utilization because there isnâ€™t enough work to keep the threads busy (I had a â€œfancy k2â€ branch which tried to pack multiple nodes togetherÙ« but because of higher divergence it was a regression). In the latter caseÙ« the problem is that each workgroup (responsible for a 512x32 tilegroup) has to read <em>all</em> the path segments in each path intersecting that tilegroup. So for a large complex path which touches many tilegroupsÙ« thereâ€™s a lot of duplicated work reading path segments which are then discarded. On top of thatÙ« utilization was poor because of difficulty doing load balancing; the complexity of tiles varies widelyÙ« so some threads would sit idle waiting for the others in the tilegroup to complete.</p>

<p>The third kernel also took a significant amount of timeÙ« generally about the same as fine rasterization. Again one of the biggest problems is poor utilizationÙ« in this case because all threads consider all items that intersect the tilegroup. In the common case where an item only touches a small fraction of the tiles within the tilegroupÙ« lots of wasted work.</p>

<p>The new design avoids many of these problemsÙ« increasing parallelism dramatically in early stagesÙ« and employing more parallelÙ« load balanced stages in the middle. HoweverÙ« it is more complex and generally more heavyweight. So for workloads that avoid the performance pitfalls outlined aboveÙ« the older design can still beat it.</p>

<h2 id="performance-evaluation">Performance evaluation</h2>

<p>Compared to the previous versionÙ« performance is mixed. It is encouraging in some waysÙ« but not across the boardÙ« and one test is in fact a regression. Letâ€™s look at GTX 1060 first:</p>

<p><img src="/assets/piet-gpu-1060.png" alt="performance charts on GTX 1060" /></p>

<p>Here the timing is given in pairsÙ« old design on the leftÙ« sort-middle on the right. These results <em>are</em> encouragingÙ« including a very appealing speedup on the paris-30k test. (AgainÙ« I should point out that this test is not a fully accurate renderÙ« as stroke styles are not applied. HoweverÙ« as a test of the old architecture vs the newÙ« it is a fair test).</p>

<p>Do these results hold up on Intel?</p>

<p><img src="/assets/piet-gpu-630.png" alt="performance charts on Intel 630" /></p>

<p>In shortÙ« no. There is much less speedupÙ« and indeed for the paris-30k exampleÙ« it has regressed. It is one of the difficult aspects of writing GPU code that different GPUs have different performance characteristicsÙ« in some cases quite significant. I havenâ€™t deeply analyzed the performance (I find it quite difficult to do soÙ« and often wish for better tools)Ù« but suspect it might have something to do with the relatively slow performance of threadgroup shared memory on Intel.</p>

<p>In all casesÙ« the cost of coarse rasterization is significantÙ« while element processing and binning are quite speedy.</p>

<h2 id="discussion">Discussion</h2>

<p>Performance is generally somewhat improved over the previous version of piet-gpuÙ« but not as much as I was hoping. Why?</p>

<p>My analysis is that itâ€™s a solid implementation of the conceptÙ« but that there is a nontrivial cost to carrying an element through the pipeline fully in fully sorted order. One observation is that segments within a path need not be sorted at allÙ« simply ascribed to the correct (pathÙ« tile position) tuple. I will be exploring that in a forthcoming blog post.</p>

<p>Another important piece is missing from the current snapshot: GPU-side flattening. Without thisÙ« the ability to change scale in transforms is of limited usefulnessÙ« as the optimum flattening is scale dependent. ThusÙ« the concept of â€œlayersÙ«â€ or of fonts being rendered fully GPU-sideÙ« is not yet realized. I am confident it can be implemented; in this architectureÙ« the easiest place to insert it would be a scene-to-scene transform after element processing but before binning. It could keep sorted order either by doing a prefix sum for allocating output elementsÙ« or by atomic allocation in chunks with references to the original elements to indicate sort order.</p>

<p>ButÙ« these two issues asideÙ« letâ€™s take stock of where we are. Weâ€™ve taken a pipeline originally designed for 3D renderingÙ« and adapted it to 2D. The pipeline itself is quite general: the core of it is just logic to pass elements in scene through to threads that work on individual tilesÙ« with each thread given only the elements that touch that tileÙ« and in sorted order.</p>

<p>The performance of this snapshot is not all bad news. One very appealing aspect is what I call â€œperformance smoothnessÙ«â€ which is the absence of performance cliffs. The performance of a large number of simple paths or a smaller number of highly complex paths should be about the sameÙ« as the cost is mostly proportional to the total number of elements in the scene. An excessive number of transforms is also not a concern; these are just handled normally in the course of element processing. In the piet-metal architectureÙ« performance was good when each node in the graph had a moderate number of childrenÙ« otherwise it would degrade. And handling a large number of simple items (as might occur in a scatterplot or other data visualization) would degrade performance because each â€œtilegroupâ€ does its own traversal of the scene graph. In the current architectureÙ« early stages of the pipeline touch each element once and then efficiently send it to the appropriate bins for further processing.</p>

<p>As I writeÙ« I am immersed in solving the performance problems named above. Stay tuned.</p>

<p>I have had the good fortune of sharing ideas and analysis with Patrick Walton of <a href="https://github.com/servo/pathfinder">Pathfinder</a> fame as I do this workÙ« and I am encouraged to see impressive improvements in a compute branch of Pathfinder he is developing. Pay attention to that as well.</p>'),('https://raphlinus.github.io/rust/graphics/gpu/2020/06/01/piet-gpu-progress.html', 'piet-gpu progress report', '1591033962000',  12, '<p>This post is an update to <a href="/rust/graphics/gpu/2019/05/08/modern-2d.html">2D Graphics on Modern GPU</a>Ù« just over a year ago. How time flies!</p>

<p>That post set out a vision of rendering 2D graphics on a GPUÙ« using compute kernels rather than the rasterization pipelineÙ« and offloading as much work as possible from the CPU to the GPU. It was also a rough research prototypeÙ« and Iâ€™ve spent some time trying to improve it in various ways. This blog post represents a checkpoint of that work - itâ€™s still a research prototypeÙ« but improved.</p>

<p>One of the limitations of that prototype is that it was implemented in MetalÙ« which was chosen for ease of developmentÙ« but is challenging to port to other APIs. Iâ€™ve spent considerable time in the last year exploring issues around portableÙ« advanced GPU programmingÙ« and among other things gave a talk entitled <a href="https://news.ycombinator.com/item?id=22880502">A taste of GPU compute</a>. As part of the evolution of the workÙ« the new prototype is in Vulkan with the compute kernels written in GLSL.</p>

<p>This blog post represents a checkpoint of the work; the code is in <a href="https://github.com/linebender/piet-gpu/pull/15">piet-gpu#15</a>. Some aspects are very promising indeedÙ« in particular the performance of â€œfine rasterization.â€ It is quite challenging to efficiently produce tiles for fine rasterization given a high-level scene representationÙ« and this snapshot does not perform as well as Iâ€™d like. I am now exploring a new approachÙ« and will post an <a href="https://raphlinus.github.io/rust/graphics/gpu/2020/06/12/sort-middle.html">update</a> on that soon.</p>

<p>Even soÙ« there is enough progress that I think itâ€™s worthwhile to post an update now.</p>

<h2 id="infrastructure-work">Infrastructure work</h2>

<p>The new prototype is written on top of VulkanÙ« with the compute kernels written in GLSL. In additionÙ« thereâ€™s an abstraction layerÙ« inspired by <a href="https://github.com/gfx-rs/gfx">gfx-hal</a>Ù« which provides a path for running on other graphics APIs.</p>

<p>Why not just gfx-hal? There are basically two reasons. FirstÙ« I wanted to be able to experiment with the newest and freshest Vulkan featuresÙ« including all the subgroup operationsÙ« control over subgroup sizeÙ« etc. Many of these features are not yet available in gfx-hal. SecondÙ« for this use caseÙ« it makes sense to compile and optimize the compute kernels at compile timeÙ« rather than have a runtime pipeline. The total amount of code needed to just run a compute kernel is on the order of 1000 lines of code.</p>

<p>Weâ€™re looking to WebGPU for the futureÙ« and hope that it will be fairly straightforward to migrate Vulkan and GLSL code to that. Essentially weâ€™re waiting for WebGPU to become more mature.</p>

<p>One of the modules in piet-gpu is a <a href="https://github.com/linebender/piet-gpu/tree/master/piet-gpu-derive">tool</a> that generates GLSL code to read and write Rust-like structs and enums. The code ends up being a lot more readable than addressing big arrays of <code class="language-plaintext highlighter-rouge">uint</code> by handÙ« and in particular itâ€™s easy to share data between Rust and GPUÙ« especially important for the scene encoding.</p>

<h2 id="static-dynamic-and-layered-content">StaticÙ« dynamicÙ« and layered content</h2>

<p>What kind of content is being rendered? It mattersÙ« more so for GPU than for CPU rendering.</p>

<p>At one extremeÙ« we have fully static contentÙ« which might be rendered with different transforms (certainly in the case of 3D). In this caseÙ« it makes sense to do expensive precomputation on the contentÙ« optimized for random access traversal while rendering. Static content of this type often shows up in games.</p>

<p>At the other extremeÙ« the 2D scene is generated from scratch every frameÙ« and might share nothing with the previous frame. Precomputation just adds to the frame timeÙ« so the emphasis must be on getting the scene into the pipeline as quickly as possible. A good example of this type of content is scientific visualization.</p>

<p>In the middle is rendering for UI. Most frames resemble the previous frameÙ« maybe with some transformations of some of the scene (for exampleÙ« scrolling a window)Ù« maybe with some animation of parameters such as alpha opacity. Of courseÙ« some of the time the changes might be more dynamicÙ« and itâ€™s important not to add to the latency of creating a new view and instantiating all its resources. A major approach to improving the performance in this use case is <em>layers.</em></p>

<p>Text rendering also has this mixed nature; the text itself is dynamicÙ« but often itâ€™s possible to precompute the font. Signed distance fields are a very popular approach for text rendering in gamesÙ« but the approach has significant drawbacksÙ« including RAM usage and challenges representing fine detail (as is needed for very thin font weightsÙ« for example).</p>

<h3 id="precomputation">Precomputation</h3>

<p>Letâ€™s look at precomputation in more detail. Much of the literature on GPU rendering assumes that an expensive precomputation pass is practicalÙ« and this pass often involves very sophisticated data structures. For exampleÙ« <a href="http://w3.impa.br/~diego/projects/GanEtAl14/">Massively-Parallel Vector Graphics</a> cites a precomputation time for the classic Ghostscript tiger image of 31.04msÙ« which destroys any hope of using the technique for fully dynamic applications. <a href="http://hhoppe.com/ravg.pdf">Random-Access Rendering of General Vector Graphics</a> is similarÙ« reporting 440ms for encoding (though on less powerful hardware of the time).</p>

<p>Another concern for precomputation is the memory requirements; the sophisticated data structuresÙ« specialized for random accessÙ« often take a lot more space than the source. For exampleÙ« RAVG cites 428k for the encoded representationÙ« as opposed to 62k for the tigerâ€™s SVG source.</p>

<p>Similar concerns apply to fonts. <a href="https://github.com/Chlumsky/msdfgen">Multi-channel signed distance fields</a> are very appealing because of the speed of rendering and ease of integration into game pipelinesÙ« but the total storage requirement for a set of international fonts (especially CJK) is nontrivialÙ« as well as the problems with fine details.</p>

<p>The <a href="https://sluglibrary.com/">Slug</a> library is very polished solution to vector font renderingÙ« and also relies on precomputationÙ« computing a triangulated convex polygon enclosing the glyph shape and sorting the outlines so they can efficiently be traversed from a fragment shader. A quick test of <code class="language-plaintext highlighter-rouge">slugfont</code> on <a href="https://github.com/googlefonts/Inconsolata">Inconsolata</a> Regular generates a 486k file from a 105k input.</p>

<p>A particular interest of mine is variable fontsÙ« and especially the ability to vary the parameters dynamicallyÙ« either as an animation or <a href="http://www.pragma-ade.nl/pdftex/thesis.pdf">microtypography</a>. Such applications are not compatible with precomputation and require a more dynamic pipeline. I fully admit this is advancedÙ« and if youâ€™re just trying to ship a game (also where a few megabytes more of font data will barely be noticed among the assets)Ù« itâ€™s easiest to just not bother.</p>

<h3 id="flattening">Flattening</h3>

<p>In the current piet-gpu pipelineÙ« pathsÙ« made from linesÙ« quadratic BÃ©zier segmentsÙ« and cubic BÃ©zier segmentsÙ« are <em>flattened</em> to polylines before being encoded and uploaded to the GPU. The flattening depends on the zoom factor; too coarse generates visible artifactsÙ« and too fine is wasteful further down the pipeline (though it would certainly be possible to apply an adaptive strategy where a flattening result would be retained for a range of zoom factors).</p>

<p>The flattening algorithm is very sophisticatedÙ« and I hope to do either a blog post or a journal paper on the full version. I blogged previously about <a href="https://raphlinus.github.io/graphics/curves/2019/12/23/flatten-quadbez.html">flattening quadratic BÃ©ziers</a>Ù« but the new version has a couple of refinements: it works on cubics as wellÙ« and it also has improved handling of cusps. You can play with an <a href="https://levien.com/tmp/flatten.html">interactive JavaScript version</a> or look at the <a href="https://github.com/linebender/kurbo/pull/105">Rust implementation</a>.</p>

<p>The time to flatten and encode the tiger is about 1.9msÙ« making it barely suitable for dynamic use. HoweverÙ« thereâ€™s lots of room to improve. This is scalarÙ« single-threaded codeÙ« and even CPU-side it could be optimized with SIMD and scaled to use multiple cores.</p>

<p>Even with single-threaded scalar codeÙ« flattening time is competitive with <a href="https://github.com/servo/pathfinder">Pathfinder</a>Ù« which takes about 3ms to flattenÙ« tileÙ« and encode drawing commands (using multithreadedÙ« SIMD optimized codeÙ« though further optimization is certainly possible). HoweverÙ« it is not suitable for interactive use on extremely complex scenes. For the paris-30k exampleÙ« piet-gpu flattening and encoding takes about 68ms.</p>

<p>UltimatelyÙ« flattening should be moved to the GPU. The algorithm is designed so it can be evaluated in parallel (unlike recursive flattening and the <a href="https://pdfs.semanticscholar.org/8963/c06a92d6ca8868348b0930bbb800ff6e7920.pdf">Precise Flattening of Cubic BÃ©zier Segments</a> work). Flattening on GPU is especially important for font renderingÙ« as it would allow rendering at arbitrary scale without reuploading the outline data.</p>

<p>One open question for flattening is exactly where in the pipeline it should be applied. Itâ€™s possible to run it before the existing pipelineÙ« during tile generationÙ« or preserve at least quadratic BÃ©ziers all the way through the pipeline to the pixel rendering stageÙ« as is done in much of the GPU rendering literature. Figuring out the best strategy will mean implementing and measuring a lot of different approaches.</p>

<h2 id="the-piet-gpu-architecture">The piet-gpu architecture</h2>

<p>The current piet-gpu architecture is a relatively simple pipeline of compute kernels. A general theme is that each stage in the pipeline is responsible for a larger geometric areaÙ« and distributes pieces of work to smaller tiles for the successive stages.</p>

<p>The first stage is on CPU and is the encoding of the scene to a buffer which will then be uploaded to the GPU. This encoding is vaguely reminiscent of flatbuffersÙ« and is driven by â€œderiveâ€ code that automatically generates both Rust-side encoding and GLSL headers to access the data. As discussed in considerably more detail belowÙ« the encoding of curves also involves flatteningÙ« but thatâ€™s not essential to the architecture. After the encoded scene buffer is uploadedÙ« successive stages run on the GPU.</p>

<p>The first compute kernel has a fairly simple job. It traverses the input scene graph and then generates a list of â€œinstancesâ€ (references to leaf nodes in the scene graphÙ« with transform) for each â€œtile groupâ€ (currently a 512x16 region). It uses bounding boxes (encoded along with nodes by the CPU) to cull.</p>

<p>The second compute kernel is specialized to vector paths. It takes the instances of vector stroke and fill itemsÙ« and for each 16x16 tile generates a list of segments for that item for that tile. For fillsÙ« it also computes the â€œbackdropâ€Ù« which is important for filling interior tiles of a large shape even when no segments cross that tile.</p>

<p>The third compute kernel is responsible for generating a per-tile command list (sometimes referred to as a â€œtapeÙ«â€ and called a â€œcell streamâ€ in the RAVG terminology). Thereâ€™s generally a straightforward mapping from instances to commandsÙ« but this kernel can do other optimizations. For exampleÙ« a solid opaque tile can â€œresetâ€ the output streamÙ« removing drawing commands that would be completely occluded by that tile.</p>

<p>The fourth compute kernel reads its per-tile command list and generates all the pixels in a 16x16 tileÙ« writing them to the output image. This stage is effectively identical to the pixel shader in the RAVG paperÙ« but with one small twist. Because itâ€™s a compute kernelÙ« each thread can read the input commands and generate a chunk of pixels (currently 8)Ù« amortizing the nontrivial cost of reading the tape over more more than just one pixel. Of course it would be possible to run this in a fragment shader if compute were not available.</p>

<p>These kernels are relatively straightforwardÙ« but essentially brute-force. A common theme is that all threads in a workgroup cooperate to read the input in parallelÙ« then there is a â€œblock shuffleâ€ approach to distribute that work to the individual threads responsible for writing out work for smaller subregions. I described an approach based on 32x32 boolean matrix transpose in my <a href="https://news.ycombinator.com/item?id=22880502">Taste of GPU Compute</a> talkÙ« but in practice we find that using atomic operations to assign work is slightly faster.</p>

<h3 id="layers">Layers</h3>

<p>As mentioned aboveÙ« in a UI most of the timeÙ« most of the content in the frame is the same as the last frame. Some UI frameworks (imgui in particular) just traverse the entire UI state and draw every timeÙ« but most do something to cut down on work done.</p>

<p>The main mechanism is some kind of <em>layerÙ«</em> an object that retains the appearance of a widget or subview. In Apple toolkitsÙ« this layer (<a href="https://developer.apple.com/documentation/quartzcore/calayer">CALayer</a> in particular) is a GPU-resident texture (image). This design made sense in the days of the iPhone 1Ù« where the GPU was just barely powerful enough to composite the final surface from multiple such images at 60fpsÙ« but there are significant drawbacks to this approach. Applications need to avoid creating too many layersÙ« as that can consume a huge amount of GPU memory. Thereâ€™s also increased latency when content changes dynamicallyÙ« as it needs to be re-rendered and re-uploaded before being composited. But the approach does work. It also leads to a certain aestheticÙ« emphasizing the animations that can be efficiently expressed (translation and alpha fading) over others that would require re-rendering.</p>

<p>Flutter has a more sophisticated approachÙ« explained well in the video <a href="https://www.youtube.com/watch?v=UUfXWzp0-DU">Flutterâ€™s Rendering Pipeline</a>. ThereÙ« a layer can be backed by either a recorded display list (<a href="https://skia-doc.commondatastorage.googleapis.com/doxygen/doxygen/html/classSkPicture.html">SkPicture</a> under the hood) or a textureÙ« with a heuristic to decide which one. My understanding is that SkPicture is implemented by recording drawing commands into a CPU-side bufferÙ« then playing them back much as if they had been issued in immediate mode. ThusÙ« itâ€™s primarily a technique to reduce time spent in the scripting layerÙ« rather than a speedup in the rendering pipeline per se. The Android <a href="https://developer.android.com/reference/android/graphics/RenderNode">RenderNode</a> is similar (and is used extensively in <a href="https://developer.android.com/jetpack/compose">Jetpack Compose</a>).</p>

<p>One of the design goals in piet-gpu is to move this mechanism farther down the pipelineÙ« so that a fragment of the scene graph can be retained GPU-sideÙ« and the layer abstraction exposed to the UI is a handle to GPU-resident resources. Note that this isnâ€™t very different than the way images are already handled in virtually every modern rendering system.</p>

<p>The layer concept is also valid for many art and design applicationsÙ« as well as maps. Itâ€™s extremely common to organize the document or artwork into layersÙ« and then modifications can be made to just one layer.</p>

<p>This mechanism is not yet wired up end-to-endÙ« as it requires more work to do asynchronous resource management (including better allocation of GPU buffers)Ù« but the experimental results do show that the potential savings are significant; re-encoding and re-uploading of the scene graph to the GPU is a substantial fraction of the total timeÙ« so avoiding it is a big gain.</p>

<p>Doing flattening GPU-side would make the layer concept even more powerfulÙ« as it enables zoom (and potentially other transformations) of layers without re-uploadÙ« also avoiding the blurring that happens when bitmap textures are scaled.</p>

<h2 id="cpu-vs-gpu">CPU vs GPU</h2>

<p>If the same work can be done on either CPU or GPUÙ« then itâ€™s sometimes a complex tradeoff which is best. The goal of piet-gpu is for GPU-side computation to be so much faster than CPU that itâ€™s basically always a win. But sometimes optimizing is easier CPU side. Which is betterÙ« thenÙ« depends on context.</p>

<p>In a gameÙ« the GPU might be spending every possible GFLOP drawing a beautifulÙ« detailed 3D worldÙ« of which the 2D layer might be a small but necessary concern. If the CPU is running a fairly lightweight loadÙ« then having it run most of the 2D rendering pipelineÙ« just save getting the final pixels on the screenÙ« might make sense.</p>

<p>AgainÙ« the assumptions driving piet-gpu are primarily for UIÙ« where latency is the primary concernÙ« and keeping work off the main UI thread is a major part of the strategy to avoid jank. Under this set of assumptionsÙ« offloading any work from the CPU to the GPU is a winÙ« even if the GPU is not super-efficientÙ« as long as the whole scene comes in under the 16ms frame budget (or 8msÙ« now that 120Hz displays are becoming more mainstream). The current piet-gpu codebase addresses this wellÙ« and will do so even better as flattening is also moved to GPU.</p>

<p>The relative tradeoff is also affected by the speed of the graphics card. Single threaded CPU performance is basically stuck nowÙ« but GPUs will get faster and faster; already weâ€™re seeing Intel integrated GPU go from anemic to serious competitors to low-end discrete graphics cards.</p>

<h2 id="performance">Performance</h2>

<p>Iâ€™m not yet satisfied with the performance of piet-gpuÙ« yet there are aspects of it which are very encouraging. In particularÙ« I feel that the final stage of the pipeline (sometimes called â€œfine rasterizationâ€) is very fast. Even though itâ€™s producing a huge volume of pixels per secondÙ« this stage only takes about 1/4 to 1/3 of the total piet-gpu time. Itâ€™s tantalizing to imagine what performance could look like if the cost of producing tiles for fine rasterization was further reduced.</p>

<p>For performance testingÙ« Iâ€™m using 3 samples from the <a href="http://w3.impa.br/~diego/projects/GanEtAl14/">Massively-Parallel Vector Graphics</a> suite. Tiger is the well-known Ghostscript tigerÙ« almost a â€œhello worldâ€ of 2D graphics renderingÙ« paper-1 is a text-heavy workloadÙ« and paris-30k is a highly detailed map. Note that the rendering of paris-30k is not fully correctÙ« and in particular all strokes are rendered with the same style (round ends and caps and no dashing). Itâ€™s probably reasonable to budget 30% additional time to get these stroke styles rightÙ« as they can significantly increase the number of path segmentsÙ« but Iâ€™m also interested in ways to optimize this further. Also keep in mindÙ« these numbers are GPU time onlyÙ« and donâ€™t include the cost of flattening in particular (currently on CPU).</p>

<p>With that saidÙ« hereâ€™s a chart of the performanceÙ« broken down by pipeline stage. HereÙ« k4 is â€œkernel 4â€Ù« or fine rasterizationÙ« the stage that actually produces the pixels.</p>

<p><img src="/assets//piet-gpu-performance.png" alt="piet-gpu performance comparison graphs" /></p>

<p>These measurements are done on a four-core i7-7700HQ processor; with more coresÙ« the CPU time would scale downÙ« and vice versaÙ« as Pathfinder is very effective in exploiting multithreading.</p>

<p>At some pointÙ« Iâ€™d like to do a much more thorough performance comparisonÙ« but doing performance measurement of GPU is surprisingly difficultÙ« so I want to take the time to do it properly. In the meantimeÙ« here are rough numbers from the current master version of Pathfinder running on GTX 1060: tiger 2.3ms (of which GPU is 0.7)Ù« paper-1 7.3ms (GPU 1.1ms)Ù« and paris-30k 83ms (GPU 15.5ms). On Intel 630Ù« the total time is only slightly largerÙ« with the GPU taking roughly the same amount of time as CPU. Also keep in mindÙ« these figures <em>do</em> include flatteningÙ« and see below for an update about Pathfinder performance.</p>

<h2 id="prospects">Prospects</h2>

<p>I have basically felt driven as I have engaged this researchÙ« as I enjoy mastering the dramatically greater compute power available through GPU. But the work has been going more slowly than I would likeÙ« in part because the tools available for portable GPU compute are so primitive. The current state of piet-gpu is a research codebase that provides evidence for the ideas and techniquesÙ« but is not usable in production.</p>

<p>I would like for piet-gpu to become production-qualityÙ« but am not sure whether or when that will happen. Some piecesÙ« especially fallbacks for when advanced GPU compute features are not available (and working around the inevitable GPU driver bugsÙ« of which I have encountered at least 4 so far)Ù« require a lot of code and workÙ« as does the obsessive tuning and micro-optimization endemic to developing for real GPU hardware.</p>

<p>Another extremely good outcome for this work would be for it to flow into a high quality open-source rendering project. One of the best candidates for that is <a href="https://github.com/servo/pathfinder">Pathfinder</a>Ù« which has been gaining momentum and has also incorporated some of my ideas. One of the appealing aspects of Pathfinder is its â€œmix and matchâ€ architectureÙ« where some stages might be done on CPU and others on GPUÙ« and the final pixel rendering can be done in either the rasterization or compute pipelineÙ« the choice made based on compatibility and observed performance. In factÙ« since the first draft of this blog postÙ« Iâ€™ve been working closely with PatrickÙ« sharing ideas back and forthÙ« and there is now a compute branch of Pathfinder with some encouraging performance numbers. Youâ€™ll hear more about that soon.</p>

<p>Thanks to Brian Merchant for work on various parts of piet-gpuÙ« msiglreith for help with VulkanÙ« and Patrick Walton for many conversations about the best way to render 2D graphics.</p>

<p>There was some <a href="https://www.reddit.com/r/rust/comments/gv1b95/pietgpu_progress_report/">discussion on /r/rust</a>.</p>'),('https://raphlinus.github.io/gpu/2020/04/30/prefix-sum.html', 'Prefix sum on Vulkan', '1588263402000',  12, '<p><strong>Update 2020-05-22:</strong> A new section on <a href="#forward-progress">forward progress</a> has been addedÙ« and the discussion of synchronized shuffles has been improved.</p>

<p>TodayÙ« there are two main ways to run compute workloads on GPU. One is CUDAÙ« which has a fantastic ecosystem including highly tuned librariesÙ« but is (in practice) tied to Nvidia hardware. The other is graphics APIs used primarily for gamingÙ« which run on a wide variety of hardwareÙ« but historically offer much less power than CUDA. AlsoÙ« the tooling for compute in that space is terrible. HistoricallyÙ« a lot of compute has also been done with OpenCLÙ« but its future is cloudy as itâ€™s been officially deprecated by AppleÙ« and GPU vendors are not consistently keeping their OpenCL implementations up to date.</p>

<p>Vulkan has been catching up fast in its raw capabilitiesÙ« with recent extensions supporting more advanced GPU compute features such as subgroupsÙ« pointersÙ« and a memory model. Is it getting to the point where it can run serious compute workloads?</p>

<p>In this blog post are some initial explorations into implementing <a href="https://en.wikipedia.org/wiki/Prefix_sum">prefix sum</a> on recent Vulkan. I have a rough first draft implementation which suggests that Vulkan might be a viable platformÙ« for a sufficiently persistent implementor.</p>

<h2 id="why-prefix-sum">Why prefix sum?</h2>

<p>As Hacker News user fluffything points out in <a href="https://news.ycombinator.com/item?id=22902274">this HN thread</a> on my <a href="https://news.ycombinator.com/item?id=22880502">Taste of GPU compute</a> talkÙ« prefix sum is an excellent benchmark for evaluating GPU compute languages and runtimes.</p>

<p>For oneÙ« it is useful in and of itself. I use it in <a href="https://github.com/raphlinus/font-rs">font-rs</a> to integrate fragments of exact-area computations to arrive at the total area coverage for font rendering. It is also used as a primitive in many more operationsÙ« including GPU-side dynamic allocation and <a href="http://www.davidespataro.it/cuda-stream-compaction-efficient-implementation/">compaction</a>.</p>

<p>For twoÙ« it is simple. The sequential version can be expressed in just a handful of lines of code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">prefix_sum</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">a</span><span class="p">:</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">x</span>
        <span class="n">result</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></div>

<p>For threeÙ« it is challenging but possible to implement efficiently on GPU. The above code has a strictly sequential dependencyÙ« but because addition is associativeÙ« it is possible to exploit a great deal of parallelismÙ« and there is literature on that going back decades. Even soÙ« efficiently exploiting that parallelism on GPU requires communication between invocations (â€œthreadsâ€ in more common GPU lingo) and careful attention to the memory hierarchy.</p>

<p>The generalization of prefix sum is called â€œscanÙ«â€ and works with any associative operationÙ« not just addition. It doesnâ€™t even have to be commutative; examples of that include <a href="http://blog.sigfpe.com/2009/01/fast-incremental-regular-expression.html">regular expressions</a> and <a href="https://raphlinus.github.io/audio/2019/02/14/parallel-iir.html">IIR filtering</a>. More preciselyÙ« a scan can be done with any <a href="https://en.wikipedia.org/wiki/Monoid">monoid</a>Ù« a structure with an identity element as well as the associative operation; the identity element is required for the â€œexclusiveâ€ variant of scanÙ« as it is the first element of the output.</p>

<h2 id="implementation-on-gpu">Implementation on GPU</h2>

<p>The state of the art is <a href="https://research.nvidia.com/publication/single-pass-parallel-prefix-scan-decoupled-look-back">decoupled look-back</a>. Iâ€™m not going to try to summarize the algorithm hereÙ« but recommend reading the paper. The results are impressive â€” for large data setsÙ« they report reaching memcpy speedsÙ« meaning that no further speedup is possible.</p>

<p>That work is a refinement of <a href="https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda">Parallel Prefix Sum (Scan) with CUDA</a> from Nvidiaâ€™s GPU Gems 3 book. A production-qualityÙ« open source implementation is <a href="https://nvlabs.github.io/cub/">CUB</a>. Another implementationÙ« designed to be more accessible but not as optimizedÙ« is <a href="https://moderngpu.github.io/scan.html">ModernGPU scan</a>.</p>

<p>My own <a href="https://github.com/linebender/piet-gpu/blob/prefix/piet-gpu-hal/examples/shader/prefix.comp">implementation</a> is very much a research-quality proof of concept. It exists as the <a href="https://github.com/linebender/piet-gpu/tree/prefix">prefix</a> branch of the <a href="https://github.com/linebender/piet-gpu">piet-gpu</a> repository. BasicallyÙ« I wanted to determine whether it was possible to come within a stoneâ€™s throw of memcpy performance using Vulkan compute kernels. Itâ€™s a fairly straightforward implementation of the decoupled look-back paperÙ« and doesnâ€™t implement all the tricks. For exampleÙ« the look-back is entirely sequential; I didnâ€™t parallelize the look-back as suggested in section 4.4 of the paper. This is probably the easiest performance win to be gotten. But itâ€™s not too horribleÙ« as the partition size is quite big; each workgroup processes 16ki elements. Rough measurements indicate that look-back is on the order of 10-15% of the total time.</p>

<p>The implementation is enough of a rough prototype I donâ€™t yet want to do careful performance evaluationÙ« but initial results are encouraging: it takes 2.05ms of GPU time to compute the prefix sum of 64Mi 32-bit unsigned integers on a GTX 1080Ù« a rate of 31.2 billion elements/second. Since each element involves reading and writing 4 bytesÙ« that corresponds to a raw memory bandwidth of around 262GiB/s. The theoretical memory bandwidth is listed as 320GB/sÙ« so clearly the code is able consume a large fraction of available memory bandwidth.</p>

<h3 id="do-we-need-a-memory-model">Do we need a memory model?</h3>

<p>One of the achievements of â€œmodern C++â€ is the C++11 memory model. In the olden daysÙ« the mechanism for lock-free programming patterns in C and C++ was the <code class="language-plaintext highlighter-rouge">volatile</code> qualifier and various nonstandard barrier intrinsics. People reasoned about these operationally â€” the primary function of <code class="language-plaintext highlighter-rouge">volatile</code> was to disable certain optimizationsÙ« and the barrier intrinsics compile to a memory fence instructionÙ« which generally cause hardware to flush caches.</p>

<p>TodayÙ« most lock-free aficionados consider those times to be barbaric. The semantics of <code class="language-plaintext highlighter-rouge">volatile</code> were never clearly defined for the purpose of multithreading (though people used it anywayÙ« because it appeared to be useful)Ù« and the barrier instructions had the disturbing property of being hardware specific. Because x86 has â€œtotal store orderÙ«â€ barrier instructions are generally not needed for <a href="https://bartoszmilewski.com/2008/08/04/multicores-and-publication-safety/">publication safety</a>. HoweverÙ« the same code onÙ« sayÙ« ARMÙ« which has more weakly ordered memory semanticsÙ« would failÙ« often in subtle ways.</p>

<p>With the C++11 memory modelÙ« the programmer specifies the needed ordering constraints precisely. The compiler can then optimize the program very aggressivelyÙ« as long as it meets those constraints. For exampleÙ« acquire and release semantics (the basis of publication safety) will compile to explicit memory fence instructions on ARMÙ« but to nothing on x86. A good writeup is the blog post <a href="https://bartoszmilewski.com/2008/12/01/c-atomics-and-memory-ordering/">C++ atomics and memory ordering</a>.</p>

<p>The new <a href="https://www.khronos.org/blog/comparing-the-vulkan-spir-v-memory-model-to-cs">Vulkan memory model</a> brings the same idea to GPU compute. I used it in my codeÙ« in large part because I wanted to experiment with it. Iâ€™ve done a fair amount of lock-free code using the C++ memory model. And lock-free codeÙ« while fairly rare on the CPU (my main motivation is to avoid priority inversion for real time audio)Ù« is more or less required on the GPUÙ« because mutex is not available in kernel code. Even if it wereÙ« it would create a lot of problemsÙ« as it would block the entire subgroupÙ« not just a single thread (one of the features of the Vulkan memory model is a much weaker forward progress guarantee than threads running on CPU).</p>

<p>Is a memory model absolutely required to run this code? If you replace the atomic loads and stores with simple array accessesÙ« it deadlocks. HoweverÙ« at least on my hardwareÙ« correct operation can be recovered by adding the <code class="language-plaintext highlighter-rouge">volatile</code> qualifier to the <code class="language-plaintext highlighter-rouge">WorkBuf</code> array. As with older style C++Ù« there are two risks. Though it seems to work reliably and efficiently on my hardwareÙ« itâ€™s possible the <code class="language-plaintext highlighter-rouge">volatile</code> qualifier and explicit fences cause more cache flushing than is neededÙ« or suppress other optimizations that might be possible with a more precise expression of the memory semantics. AlternativelyÙ« other hardware or drivers might optimize even more aggressively and break the code.</p>

<p>Weâ€™re already seeing variation in hardware that requires different levels of vigilance for memory semantics. On most GPU hardwareÙ« the invocations (threads) within a subgroup (warp) execute in lock-stepÙ« and thus donâ€™t require any synchronization. HoweverÙ« as of Nvidia VoltaÙ« the hardware is capable of <a href="https://docs.nvidia.com/cuda/volta-tuning-guide/index.html#sm-independent-thread-scheduling">independent thread scheduling</a>. Correct code will add explicit memory semantics even within a subgroupÙ« which willÙ« as in total store order on x86Ù« compile to nothing on hardware that runs invocations in lock-stepÙ« while code which just assumes lock-step execution of subgroups will start failing as Vulkan implementations on newer GPUs start scheduling invocations on a more fine grained basisÙ« just as code that assumed total store order failed on CPUs with more relaxed memory consistencyÙ« such as ARM.</p>

<p>Note that Vulkan with independent thread scheduling is still work in progress. Shuffles (and related subgroup operations) must synchronize so that all active threads can participate. CUDA 9 solves this problem by introducing new intrinsics such as <code class="language-plaintext highlighter-rouge">__shfl_sync</code>Ù« which take an additional argument identifying which threads are active. The Vulkan subgroup operations arenâ€™t defined this wayÙ« and instead implicitly operate on active threads (invocations). Supporting this functionality correctly stresses current compiler technologyÙ« including preventing illegal code motion of shuffle intrinsicsÙ« and there are threads on the LLVM mailing list discussing this in some detail.</p>

<p>In my research for this blog postÙ« I did not come across any evidence of people actually using the Vulkan memory modelÙ« i.e. no search hits for the relevant identifiers other than work associated with the spec. ThusÙ« one contribution of this blog post is to show a concrete example of code that uses it.</p>

<h3 id="forward-progress">Forward progress</h3>

<p>The prototype code has one important flawÙ« though it appears to run fine on my hardware: it depends on other workgroups making forward progress while itâ€™s waiting for the aggregate to be published. The Vulkan spec is careful to make only a <a href="https://www.khronos.org/blog/comparing-the-vulkan-spir-v-memory-model-to-cs#_limited_forward_progress_guarantees">limited forward progress guarantee</a>Ù« and this is not strong enough to reliably run the prefix sum algorithm as written. ThusÙ« thereâ€™s a risk the program will hang while one workgroup is waiting on an aggregateÙ« and the workgroup that is responsible for computing it is never scheduled because the forward progress guarantee is not strong enough.</p>

<p>Forward progress is a complex problemÙ« and still in flux. A very good summary of the issue is the paper <a href="https://www.cs.princeton.edu/~ts20/files/concur2018.pdf">GPU schedulers: how fair is fair enough?</a>Ù« which describes the needed forward progress guarantee as â€œoccupancy-bound.â€ An earlier paper from the same groupÙ« <a href="https://johnwickerson.github.io/papers/forwardprogress_concur2017.pdf">Forward Progress on GPU Concurrency</a>Ù« might be a more accessible presentation of the core ideas. In their experimentsÙ« all GPUs they tested meet this guaranteeÙ« so it sounds like a good property to standardize. Apple mobile GPUsÙ« howeverÙ« do not provide this guaranteeÙ« though it might take a great deal of testing to uncover a counterexample. As that paper describesÙ« many (but probably not all) other GPUs likely meet the â€œoccupancy-boundâ€ guaranteeÙ« so my prefix sum code will run correctlyÙ« but Iâ€™m not aware of any Vulkan implementations that actually document such a guarantee.</p>

<p>MeanwhileÙ« other devices provide even stronger guarantees. CUDA 9 on Volta and above provides the much stronger <a href="https://en.cppreference.com/w/cpp/language/memory_model#Parallel_forward_progress">parallel forward progress</a> guarantee as standardized in C++Ù« and they are able to do this because of independent thread scheduling (see the relevant section of <a href="https://devblogs.nvidia.com/inside-volta/">Inside Volta</a> for more discussion). This allows even individual threads in a â€œwarpâ€ (subgroup) to hold a mutex and block on other threads without fear of starvation. Another great resource on how Volta improved forward progress is the CppCon 2017 talk <a href="https://youtu.be/86seb-iZCnI?t=2043">Designing (New) C++ Hardware</a>Ù« which Iâ€™ve timestamped for the forward progress discussion. UnfortunatelyÙ« currently this guarantee is only valid for CUDAÙ« not (yet) Vulkan. In the meantimeÙ« from what I understandÙ« Nvidia hardware meets the occupancy-bound guarantee in both CUDA and VulkanÙ« which is good enough to run prefix sum.</p>

<p>I think itâ€™s likely that over timeÙ« a consensus will emerge on formalizing the occupancy-bound guaranteeÙ« because itâ€™s so usefulÙ« and at the least youâ€™ll be able to query the GPU to determine the level of forward progress guarantee it provides.</p>

<p>In the meantimeÙ« itâ€™s best to be conservative. FortunatelyÙ« for prefix sumÙ« there is a fix (not yet implemented) that restores correct operation even on devices with the weakest forward progress properties: instead of simply spinning waiting from the aggregate from another partitionÙ« do a small bit of work towards recomputing the aggregate yourself. After a finite number of cyclesÙ« the aggregate for the partition will be doneÙ« then you can give up spinning and go to the next partition. This will guarantee getting the result eventuallyÙ« and hopefully such performance-sapping events are rare.</p>

<h3 id="dynamic-allocation-on-gpu">Dynamic allocation on GPU</h3>

<p>On GPUÙ« itâ€™s easiest to run workloads that use static allocationÙ« for example a fixed size buffer per workgroupÙ« and workgroups arranged in a 2D grid (â€œdispatchâ€ operations support 1D and 3D as well). But dynamic allocation is possibleÙ« with care.</p>

<p>The two major approaches to dynamic allocation are prefix sum and atomic bump allocation. The main reason for one over the other is whether you care about the ordering. Letâ€™s take a simple problem of computing some function on an array of input valuesÙ« where the output is variable sized.</p>

<p>Using a prefix-sum approachÙ« you run a first pass of computing the size of the output. The prefix sum of that result yields an offset into an output buffer. The second pass (after the prefix sum) computes the function and writes it into the output bufferÙ« using the offset provided by the prefix sum. [Also note that if weâ€™re getting really fancyÙ« it might be possible to fuse either or both of these passes with the prefix sum itselfÙ« decreasing the amount of global memory traffic but increasing register pressure and otherwise constraining efficient use of the memory hierarchyÙ« so the extent to which this helps depends greatly on the exact problem].</p>

<p>An atomic bump allocation approach simply does <a href="https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/atomicAdd.xhtml"><code class="language-plaintext highlighter-rouge">atomicAdd</code></a> on each outputÙ« using a bump allocation index (effectively a pointer) as the first argument and the size of the allocation as the second. This yields results broadly similar to the prefix sum approachÙ« but with the outputs in arbitrary order. Perhaps the order is not importantÙ« orÙ« alternativelyÙ« a sort pass can be applied afterwards (sorting on GPU is another topic with a rich literature).</p>

<p>The two can be combined. For exampleÙ« it makes sense to do a prefix sum of the sizes of items within a workgroupÙ« and a single atomic bump allocation for the per-workgroup total.</p>

<p>One problem that might benefit from prefix sum for dynamic allocation is <a href="https://raphlinus.github.io/graphics/curves/2019/12/23/flatten-quadbez.html">flattening</a> BÃ©zier curves to polylines. Each BÃ©zier segment can be computed in parallelÙ« but you generally want to preserve the order of segments within the full path. The flattening algorithm I presented in that blog post (and its <a href="https://github.com/linebender/kurbo/pull/105">generalization to cubics</a>) fits nicely into this framework â€” itâ€™s already in two passesÙ« where the first computes the number of segments requiredÙ« and the second can compute the coordinates of each point in the output independentlyÙ« thus in parallel.</p>

<h3 id="subgroups-and-subgroup-size">Subgroups and subgroup size</h3>

<p>High performance prefix sum requires coordination between threads â€” itâ€™s possible to extract some parallelism by running O(log n) tree reduction passesÙ« each of which pulls only from the previous passÙ« but this would be considerably slower than state of the art. Coordination must be at all levels of the hierarchy. GPU compute has always made threadgroup shared memory available for such coordination. An even faster but newer capability is <a href="https://www.khronos.org/blog/vulkan-subgroup-tutorial">subgroups</a>Ù« not yet universally supported.</p>

<p>My prototype code uses subgroups extensively. One serious limitation is that it assumes a subgroup size of 32Ù« which is true for some hardware. HoweverÙ« other hardware has different size subgroupsÙ« and then Intel is special.</p>

<p>By defaultÙ« when compiling a compute kernelÙ« the Intel drivers use a <a href="https://software.intel.com/en-us/forums/opencl/topic/564990">heuristic</a> to determine the subgroup sizeÙ« which can then be 8Ù« 16Ù« or 32. It actually makes sense they use a heuristicÙ« as thereâ€™s a complex tradeoff. A bigger subgroup means bigger chunks of workÙ« which means less per-chunk overheadÙ« but also fewer registers available per threadÙ« and potentially more wasted work due to divergence. AgainÙ« that depends on workloads. For low-probabilityÙ« expensive conditional workÙ« generally not a good fit for GPU but sometimes unavoidableÙ« wasted work tends to scale with subgroup size.</p>

<p>It might be <em>possible</em> to write a kernel that adapts to subgroup sizeÙ« but there are a number of considerations that make this tricky. One is whether the number of items processed by a workgroup adapts to subgroup size. If soÙ« then the size of the dispatch must be adapted as well. There is an <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/html/vkspec.html#features-pipelineExecutableInfo">extension</a> for the CPU side to query subgroup size of a pipelineÙ« butÙ« sadlyÙ« it doesnâ€™t seem to be implemented on Intel drivers on WindowsÙ« where it would be most useful. (It isÙ« thankfullyÙ« in the latest Linux Intel driversÙ« so hopefully will be coming soon.)</p>

<p>Another problem is querying the subgroup size from inside the kernelÙ« which has a surprising gotcha. By defaultÙ« the <code class="language-plaintext highlighter-rouge">gl_SubgroupSize</code> variable is defined to have the value from <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/man/html/VkPhysicalDeviceSubgroupProperties.html">VkPhysicalDeviceSubgroupProperties</a>Ù« which in my experiment is always 32 on Intel no matter the actual subgroup size.</p>

<p>Newer (Vulkan 1.2) Intel drivers offer the ability to both accurately query and control over the subgroup sizeÙ« with the <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/man/html/VK_EXT_subgroup_size_control.html">VK_EXT_subgroup_size_control</a> extension. With that extensionÙ« setting the <code class="language-plaintext highlighter-rouge">VK_PIPELINE_SHADER_STAGE_CREATE_ALLOW_VARYING_SUBGROUP_SIZE_BIT_EXT</code> at pipeline creation time makes <code class="language-plaintext highlighter-rouge">gl_subgroupSize</code> behave as expected. AlsoÙ« I can set the subgroup size to 32Ù« and the kernel works fine. Note though that in generalÙ« setting a too-large subgroup size can actually make performance worseÙ« as it increases the chance of register spilling.</p>

<p>On RDNA-based AMD cardsÙ« the subgroup size extension lets you get subgroups of 32 on RDNA-based AMD cardsÙ« though the default is 64.</p>

<p>In practiceÙ« the programmer will write multiple versions of the kernelÙ« each tuned for a different subgroup sizeÙ« then on CPU side the code will query the hardware for supported subgroup sizes and choose the best one that can run on the hardware. Note thatÙ« in generalÙ« querying the range of supported subgroup sizes requires the subgroup size extension to be reliableÙ« though you do string-matching on the device name to come up with a good guess. Note that the <a href="https://blogs.igalia.com/itoral/2018/03/20/improving-shader-performance-with-vulkans-specialization-constants/">specialization constants</a> mechanism is also a good way to tune constant factors like workgroup or buffer sizes without having to recompile kernel source. In any caseÙ« the cost and difficulty of this kind of performance tuning is one reason Nvidia has such a strong first-mover advantage.</p>

<p>Brian Merchant has done more exploration into the tradeoff between subgroups and threadgroup shared memoryÙ« for a different primitive operationÙ« transpose of 32x32 boolean matrices. That <a href="https://github.com/bzm3r/transpose-timing-tests/blob/master/POST.md">transpose timing writeup</a> contains measurements on a variety of hardwareÙ« and is recommended to the interested reader.</p>

<h3 id="what-does-subgroupinclusiveadd-compile-to">What does subgroupInclusiveAdd compile to?</h3>

<p>The <code class="language-plaintext highlighter-rouge">subgroupInclusiveAdd</code> function seems like itâ€™s doing a lot â€” itâ€™s performing a prefix sum operation on an entire subgroupâ€™s worth of data. Does hardware contain an assembly instruction that directly implements it? What if you want to do an operation other than additionÙ« where there isnâ€™t an intrinsic available?</p>

<p>Obviously different hardware will be differentÙ« but looking at the Radeon GPU Analyzer output on <a href="http://shader-playground.timjones.io/a9e2db94ab3bf88e790694ac869f7879">Shader Playground</a> tells us a lot. It generates a tree reduction (the Hillis-Steele algorithm as presented in the <a href="https://en.wikipedia.org/wiki/Prefix_sum">prefix sum</a> Wikipedia page) with lg(n) stages of subgroup shuffle + add. Since subgroup shuffle is available in Vulkan (but see below)Ù« if you were to write out such a reduction youâ€™d be able to get similar results.</p>

<p>On AMD hardware there is one additional twist: <a href="https://gpuopen.com/amd-gcn-assembly-cross-lane-operations/">AMD</a> has an additional level of hierarchy between subgroup (64 invocationsÙ« 1 wavefront) and invocation (thread). InternallyÙ« the hardware is organized around a <em>row</em> of 16 elements. Access to elements within a row uses a different instruction modifier (<code class="language-plaintext highlighter-rouge">row_shr</code>) than across the entire wave (<code class="language-plaintext highlighter-rouge">row_bcast</code> or <code class="language-plaintext highlighter-rouge">wave_ror</code>Ù« for two examples)Ù« and is likely lower latency in the chip. The Vulkan subgroup extensions provide a powerful and portable set of operationsÙ« but donâ€™t expose all of the lowest-level operations available on the GPU hardware. To squeeze the last few percent of performanceÙ« assembly is still useful.</p>

<h3 id="portability-considerations-dx12">Portability considerations: DX12</h3>

<p>It is tempting to use a portability layer such as gfx-hal to run compute workloads on a variety of graphics APIs. (Other such portability layers include MoltenVK for running Vulkan on top of MetalÙ« and similar work for running <a href="https://devblogs.microsoft.com/directx/in-the-works-opencl-and-opengl-mapping-layers-to-directx/">OpenCL on DX12</a>). But such an approach is limited to the lowest common denominator â€” it canâ€™t provide capabilities that are missing in the underlying layer.</p>

<p>Here are some of the pain points for DX12:</p>

<ul>
  <li>
    <p>No subgroup size control.</p>
  </li>
  <li>
    <p>No subgroup shuffle operations â€” use threadgroup shared memory instead.</p>
  </li>
  <li>
    <p>No memory model â€” use <code class="language-plaintext highlighter-rouge">volatile</code> and explicit barriers instead.</p>
  </li>
  <li>
    <p>No pointers (not particularly useful for this workloadÙ« but important for others).</p>
  </li>
</ul>

<p>Also note that gfx-hal currently doesnâ€™t give access to Shader Model 6 intrinsics (subgroup operations)Ù« but thereâ€™s an <a href="https://github.com/gfx-rs/gfx/issues/3238">issue</a> and hopefully that will be fixed.</p>

<h3 id="portability-considerations-metal">Portability considerations: Metal</h3>

<p>Metal is closer to Vulkan in capabilities (especially newer versions)Ù« but still lacks subgroup size control and a memory model.</p>

<h2 id="a-challenge-for-gpu-compute-infrastructure">A challenge for GPU compute infrastructure</h2>

<p>I covered a fair number of GPU compute infrastructure projects in my talk and the associated <a href="https://raphlinus.github.io/gpu/2020/02/12/gpu-resources.html">GPU resources</a> list. Since then Iâ€™ve learned of quite a few more:</p>

<ul>
  <li>
    <p><a href="https://github.com/jgbit/vuda">vuda</a>Ù« which runs (SPIR-V) compute workloads using an API similar to the CUDA host API.</p>
  </li>
  <li>
    <p><a href="https://github.com/kpet/clvk">clvk</a> and <a href="https://github.com/google/clspv">clspv</a>Ù« which run OpenCL workloads on Vulkan.</p>
  </li>
  <li>
    <p><a href="https://www.khronos.org/news/press/khronos-group-releases-opencl-3.0">OpenCL 3.0</a> is announcedÙ« with a number of strategies to rescue OpenCL from a fate of irrelevance.</p>
  </li>
  <li>
    <p><a href="https://software.intel.com/en-us/oneapi">oneAPI</a>Ù« which offers a CUDA migration path but aspires to being a portable standard.</p>
  </li>
</ul>

<p>I am also optimistic about <a href="https://www.w3.org/community/gpu/">WebGPU</a> becoming a viable platform for compute workloadsÙ« both delivered over the web and in native implementations such as <a href="https://github.com/gfx-rs/wgpu">wgpu</a>.</p>

<p>Echoing fluffythingâ€™s commentÙ« I propose adopting prefix sum as something of a â€œhello worldâ€ benchmark of GPU compute. Itâ€™s simple enough it should be practical to implement without too much effort (and if notÙ« thatâ€™s also an important data point)Ù« it exercises â€œadvancedâ€ features such as subgroup shufflesÙ« and itâ€™s reasonably easy to quantify. When looking at these potential infrastructure projectsÙ« ask these questions:</p>

<ul>
  <li>
    <p>How close can it get to the performance offered by the hardware?</p>
  </li>
  <li>
    <p>How portable is the high-performance result?</p>
  </li>
  <li>
    <p>Are there ways to smoothly downgrade on less capable platforms?</p>
  </li>
</ul>

<p>The result of my explorations on Vulkan suggest (but do not yet prove) good answers to these questionsÙ« but at the expense of doing a lot of the low-level legwork yourselfÙ« and programming the kernel in a very low-level style (in GLSL). I think thereâ€™s a huge opportunity for more sophisticated tools.</p>

<p>AlsoÙ« I think itâ€™s a great benchmark for the emerging field of GPU-friendly languages. Is it possible to express the algorithm in a reasonably high-level manner? If soÙ« does it compile to code with competitive performance? Can we write a high-performance abstraction as a library that can be consumed easily? Can that abstraction offer portability across hardware but hide the complexity from its users? Can you provide your own monoid?</p>

<h2 id="conclusion">Conclusion</h2>

<p>Iâ€™ve showed that Vulkan can do prefix sum with near state of the art performance. HoweverÙ« Iâ€™ve also outlined some of the challenges involved in writing Vulkan compute kernels that run portably and with high performance. The lower levels of the stack are becoming solidÙ« enabling a determined programmer to ship high performance compute across a wide range of the hardwareÙ« but there is also an opportunity for much better tooling at the higher levels. I see a bright future ahead for this approachÙ« as the performance of GPU compute is potentially massive compared with CPU-bound approaches.</p>

<p>Thanks to Brian MerchantÙ« Matt KeeterÙ« and msiglreith for discussions on these topicsÙ« and Jason Ekstrand for setting me straight on subgroup size concerns on Intel. Iâ€™ve also enjoyed the benefit of talking with a number of other people working on GPU driversÙ« which informs the section on forward progress in particularÙ« though of course any mistakes remain my own.</p>

<p>There is some interesting <a href="https://news.ycombinator.com/item?id=23035194">HN discussion</a> of this post.</p>'),('https://raphlinus.github.io/graphics/2020/04/21/blurred-rounded-rects.html', 'Blurred rounded rectangles', '1587497082000',  12, '<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [["$"Ù« "$"]]
        }
    });
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p>Note: Iâ€™m publishing this with inadequate visualsÙ« as itâ€™s been stuck in my queue for 3 weeks and I want to get it out there. Iâ€™d like to return to making proper imagesÙ« but make no promises when.</p>

<p>For nowÙ« a quick comparison of exact (computed with numerical integration) results (on the left) with my approximation:</p>

<p><img src="/assets/blurrr_comparison.png" alt="Comparison of exact and approximate solutions" /></p>

<p>There are two basic ways to render blur in 2D graphics. The general technique is to render the objects into an offscreen bufferÙ« compute a blurÙ« and composite that into the target surface. But in special casesÙ« itâ€™s possible to compute the blurred image directly from the source objectÙ« which is much faster.</p>

<p>Some shapes are easyÙ« particularly rectangles; they have a straightforward closed-form analytical solution. But others require numerical approximations. A few years agoÙ« Evan Wallace posted a solution for <a href="http://madebyevan.com/shaders/fast-rounded-rectangle-shadows/">fast rounded rectangle shadows</a>Ù« using an analytical solution in one direction and numerical integration in the other. This is a good solutionÙ« but I was curious whether it is possible to do better.</p>

<p>The solution in this blog post is based on distance fieldsÙ« a very powerful technique that has been getting more attention because of it adapts so well to GPU evaluation in shaders. <a href="https://www.iquilezles.org/">Inigo Quilez</a> has been making elaborate 3d scenes built up out mostly out of <a href="https://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm">distance field</a> primitivesÙ« a stunning demonstration of the power and flexibility of the technique. This post will sketch out the development of a less artistic but still hopefully useful application. I enjoy playing with the underlying mathÙ« and hope this blog post will be educational or at least entertaining for some of my readers.</p>

<p>Developing this required exploring a lot of possibilitiesÙ« as well as navigating through parameter spaces. Itâ€™s most common to use Jupyter notebooksÙ« a JavaScript-based platform such as observableÙ« or a comparable tool. But for thisÙ« partly to try it outÙ« I tried RustÙ« building a <a href="https://git.sr.ht/~raph/blurrr">simple visualizer application</a> using <a href="https://github.com/xi-editor/druid">druid</a>Ù« a cross-platform GUI toolkit. You can try the <a href="https://blurrr.futurepaul.now.sh/">Web version</a>Ù« ported by Paul Miller.</p>

<h2 id="the-1d-case-blurred-box-function">The 1D case: blurred box function</h2>

<p>As a warmupÙ« letâ€™s take the one dimensional caseÙ« especially as weâ€™ll be using it as the foundation of the 2D solution. The one dimensional analog of a rectangle is a boxcar function.</p>

<p>Gaussian blur is the convolution of a Gaussian bump with the underlying image. The convolution of a box with a Gaussian has a straightforward analytical solution. A boxcar is the difference of two step functions (offset by the thickness of the line)Ù« and the convolution of a step and a Gaussian is <a href="https://en.wikipedia.org/wiki/Error_function">erf</a>. ThusÙ« the blurred image is the difference of two erf evaluations.</p>

<p>It happens that this solution generalizes to a rectangle. Since a rectangle is the outer product of two box functionsÙ« a blurred rectangle is the outer product of their blurs. HoweverÙ« we wonâ€™t be using thisÙ« as weâ€™re concerned with rounded rectanglesÙ« which arenâ€™t separable in this way.</p>

<h2 id="distance-field-of-a-rounded-rect">Distance field of a rounded rect</h2>

<p>InsteadÙ« weâ€™ll use distance functionsÙ« as they do have the power and flexibility we need.</p>

<p>The general approach is to compute a signed distance from an outlineÙ« then use that distance as input to a function which computes the actual grayscale value. This approach separates the problem into the <em>shape</em> of the contour lines and the <em>valuesÙ«</em> which (for reasons weâ€™ll see) are best understood as a cross-section through the minor axis of the rectangle.</p>

<p>As Jonathan Blow has <a href="https://twitter.com/Jonathan_Blow/status/1244792815512510469">recently tweeted</a>Ù« â€œThe most useful thing I ever learnedÙ« about how to do geometric operations in softwareÙ« is to separate the problem into parallel and orthogonal components. It applies to just about everything.â€ While this is most obvious for classical geometric problems such as projecting a point onto a lineÙ« distance field techniques can be seen as another tool in the toolbox following this general principle. A distance field represents the value of the orthogonal componentÙ« with the parallel component filtered out.</p>

<p>To visualize contours (the parallel component) betterÙ« weâ€™ll quantize the grayscale values. And we can see that for relatively small blur radii these contours look a lot like plain rounded rectangles. This motivates the first solution:</p>

<ul>
  <li>
    <p>The curve is a rounded rectangle.</p>
  </li>
  <li>
    <p>The corner radius is computed as a combination of the original corner radius and blur radius.</p>
  </li>
  <li>
    <p>The cross-section of the minor axis is the 1D solution.</p>
  </li>
</ul>

<p>The combination cited in the second step is $ \sqrt{r_c^2 + 1.25 r_b^2} $. The choice of this formula is motivated by the rule for the probability distribution of a <a href="https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables">sum of Gaussians</a>Ù« with the constant factor chosen empirically.</p>

<h3 id="implementation">Implementation</h3>

<p>The distance field for a rounded rectangle can be computed exactlyÙ« and Inigo Quilez includes the formula in his catalog of <a href="https://www.iquilezles.org/www/articles/distfunctions2d/distfunctions2d.htm">2D distance functions</a>. In shader language:</p>

<div class="language-glsl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">float</span> <span class="nf">sdRoundedBox</span><span class="p">(</span> <span class="k">in</span> <span class="kt">vec2</span> <span class="n">p</span><span class="p">Ù«</span> <span class="k">in</span> <span class="kt">vec2</span> <span class="n">b</span><span class="p">Ù«</span> <span class="k">in</span> <span class="kt">float</span> <span class="n">r</span> <span class="p">)</span> <span class="p">{</span>
    <span class="kt">vec2</span> <span class="n">q</span> <span class="o">=</span> <span class="n">abs</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">-</span><span class="n">b</span><span class="o">+</span><span class="n">r</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">min</span><span class="p">(</span><span class="n">max</span><span class="p">(</span><span class="n">q</span><span class="p">.</span><span class="n">x</span><span class="p">Ù«</span><span class="n">q</span><span class="p">.</span><span class="n">y</span><span class="p">)Ù«</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">length</span><span class="p">(</span><span class="n">max</span><span class="p">(</span><span class="n">q</span><span class="p">Ù«</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">))</span> <span class="o">-</span> <span class="n">r</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p><img src="/assets/rounded_rect_distfield.png" alt="Distance field of rounded rectangle" />
(Image adapted from <a href="https://www.shadertoy.com/view/4llXD7">https://www.shadertoy.com/view/4llXD7</a>)</p>

<p>Note the use of <code class="language-plaintext highlighter-rouge">min</code> and <code class="language-plaintext highlighter-rouge">max</code> rather than conditional branching. The former is much faster in both shaders and SIMD evaluation.</p>

<p>For erfÙ« weâ€™ll use an approximation. Itâ€™s one of my <a href="https://raphlinus.github.io/audio/2018/09/05/sigmoid.html">favorite sigmoids</a> and weâ€™ll use the techniques from that blog post.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">fn</span> <span class="nf">compute_erf7</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">f64</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">f64</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="nn">std</span><span class="p">::</span><span class="nn">f64</span><span class="p">::</span><span class="nn">consts</span><span class="p">::</span><span class="n">FRAC_2_SQRT_PI</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">xx</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.24295</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.03395</span> <span class="o">+</span> <span class="mf">0.0104</span> <span class="o">*</span> <span class="n">xx</span><span class="p">)</span> <span class="o">*</span> <span class="n">xx</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">xx</span><span class="p">);</span>
    <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span><span class="nf">.sqrt</span><span class="p">()</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Evanâ€™s version is based on an approximation from Abramowitz and StegunÙ« which has <a href="https://www.desmos.com/calculator/tcuwxfqyrl">similar accuracy</a> and likely similar performanceÙ« but I like using reciprocal square root - it is particularly well supported in <a href="https://www.felixcloutier.com/x86/rsqrtps">SIMD</a> and <a href="https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/inversesqrt.xhtml">GPU</a> and is generally about the same speed as simple division.</p>

<p><a href="https://www.desmos.com/calculator/tcuwxfqyrl"><img src="/assets/erf_approx.png" alt="Comparison of exact and approximate solutions" /></a></p>

<h3 id="evaluation">Evaluation</h3>

<p>And this does indeed work well for small blur radiiÙ« compared to the size of the rectangle and the corner radius. But as thr blur radius goes upÙ« we start to see problems. For oneÙ« the corner radius gets smallerÙ« achieving a sharp corner in the visible region. For twoÙ« the rounded parts butt against the smooth parts rather than joining smoothly.</p>

<h2 id="squircles-to-the-rescue">Squircles to the rescue</h2>

<p>The contour of the blurred rounded rectangle strongly resembles a <a href="https://en.wikipedia.org/wiki/Squircle">squircle</a> or <a href="https://en.wikipedia.org/wiki/Superellipse">superellipse</a>. Such a shape would solve both these problems.</p>

<p>Here what we want to do is adapt the distance field approach to use a distance-like metric rather than an exact distance to the reference curve. BasicallyÙ« the game plan is as follows:</p>

<ul>
  <li>
    <p>Structure of distance field is same as rounded rect.</p>
  </li>
  <li>
    <p>Increase exponent from 2 (circle) to make superellipse shape.</p>
  </li>
  <li>
    <p>Cross-section is as above.</p>
  </li>
</ul>

<p>Increasing the exponent clearly solves the main issues with the pure rounded rectangle shapeÙ« namely the sharp interior corners (which generate a visible â€œxâ€ structure) and the abrupt straight to curved transitions:</p>

<p><img src="/assets/rounded_rect_distfield_exp.png" alt="Distance field of rounded rectangle with exponent 4" /></p>

<p>A more complete writeup of the final code is a TODO for this blog (along with better visuals)Ù« but see <a href="https://git.sr.ht/~raph/blurrr/tree/master/src/distfield.rs">the code</a> for the detailed solution.</p>

<h3 id="further-refinements">Further refinements</h3>

<p>As the blur radius goes upÙ« two factors degrade the accuracy of the above solution. For oneÙ« the height of the peak in the real solution decreases faster than the 1D case. This is fixed with a constant scale multiplierÙ« derived from the erf of the rectangleâ€™s major axis. For twoÙ« the overall shape becomes less eccentricÙ« more like a circle (in the limitÙ« it becomes a radially symmetric blur function). This is fixed by subtracting a correction factor from the major (long) axis of the rectangle.</p>

<p>With these corrections in placeÙ« the approximation becomes quite accurate over the entire range of parameters. Accuracy is nearly perfect for the original use case - shadows for UI objectsÙ« but visually acceptable everywhere.</p>

<h2 id="future-work">Future work</h2>

<p>A good solution to the blurred rounded rectangle problem is nice but perhaps not that exciting by itself; Evanâ€™s existing solution is almost certainly good enough for most practical uses.</p>

<p>One obvious generalization is to more shapes. The easiest by far is to squircle-based rounded rectangle shapesÙ« as these can almost certainly by accomplished by tuning the parameters on the existing pixel shading logic. A case can be made that squircles are better than classical rounded rectangles (certainly <a href="https://www.figma.com/blog/desperately-seeking-squircles/">Apple thinks so</a>). And the shader can readily be adapted to render both filled and stroked versions of the shape with high quality antialiasing.</p>

<p>Good approximations to many other blurred shapes are possibleÙ« as a rich set of <a href="https://www.iquilezles.org/www/articles/distfunctions2d/distfunctions2d.htm">2D distance functions</a> are known and in widespread use in shader circles.</p>

<p>AlsoÙ« perhaps your designer prefers <a href="https://en.wikipedia.org/wiki/Bokeh">bokehlicious</a> discs to Gaussian shadows. Doable. Just use a different <a href="https://www.wolframalpha.com/input/?i=integral%20sqrt%281-x%5E2%29">cross-section function</a> and tweak the parameters.</p>

<p>Some fine-tuning on the code can still be done. For exampleÙ« the â€œmagic constantsâ€ were mostly determined through experimentation. A more systematic approach would be to do a global optimizationÙ« minimizing the value of some error norm over a range of parameters. Maybe an enterprising reader will take this on!</p>

<h2 id="thanks">Thanks</h2>

<p>Thanks to Evan Wallace for permission to use his WebGL code (hoped for in a future revision)Ù« to Jacob Rus for discussion about the mathÙ« and Paul Miller for the wasm port.</p>'),('https://raphlinus.github.io/covid/2020/03/14/covid.html', 'Covid-19 resources', '1584208122000',  12, '<p>Iâ€™ve been following the Covid-19 pandemic closely the last week or soÙ« to the point of not really being able to concentrate on other things. In the hope the resources Iâ€™ve found might be usefulÙ« Iâ€™m sharing them with my blog readership. This will be updated frequentlyÙ« most recently 3/16.</p>

<h2 id="avoid-misinformation">Avoid misinformation</h2>

<p>There isÙ« unfortunatelyÙ« a huge amount of misinformationÙ« and even active disinformation out there. Since this pandemic is likely to be efficient in converting misinformation into deathsÙ« now is a good time to improve oneâ€™s information sources. To quote <a href="https://www.linkedin.com/pulse/dispatch-3-dr-shlain-reporting-from-front-lines-shlain-m-d-/">Dr. Shlain 3/12 dispatch</a>Ù« â€œThere is a ton of bullshit being disseminated. Please do not disseminate anything you canâ€™t verify. Science must prevail.â€</p>

<p>Iâ€™ve found Twitter to be an excellent source of informationÙ« provided of course one follows actual experts. My personal favorite is <a href="https://twitter.com/JeremyKonyndyk">@JeremyKonyndyk</a>Ù« who among other things led Ebola response under ObamaÙ« but I also want to raise up <a href="https://twitter.com/ScottGottliebMD">@ScottGottliebMD</a>Ù« who has been doing a particularly excellent job calling attention to the need for better testingÙ« and has excellent conservative credentials (works at the <a href="https://www.aei.org/about">AEI</a>). The virus doesnâ€™t care about our political affiliationÙ« and now more than ever is a time we need to be reaching across political divisions to work together. I could make a list of all the people I follow on TwitterÙ« but what I recommend is following the various experts Jeremy retweetsÙ« as there is a great range.</p>

<p>UnfortunatelyÙ« a lot of the misinformation is being spread by people in authorityÙ« including <a href="https://thebulletin.org/2020/03/why-do-politicians-keep-breathing-life-into-the-false-conspiracy-theory-that-the-coronavirus-is-a-bioweapon/">elected officials</a>Ù« the more irresponsible media outletsÙ« andÙ« sadlyÙ« the President. People on epidemiology Twitter are consistently citing misinformation as one of the challenges they face - they do not have the bandwidth to debunk each bit individually. Do your part. Tune out information sources that are prone to misinformationÙ« and please donâ€™t help this stuff propagate.</p>

<p>There is one very easy way to identify misinformation. Anyone proposing â€œcuresâ€ that go beyond common sense health advice or consensus public health advice is absolutely spreading dangerous misinformation. UnfortunatelyÙ« this stuff is fairly common. [As a bit more subtletyÙ« doctors are actively considering existing antiviral agents. Some look promisingÙ« and hopefully we will see the result of this research soon. But doctors shouldnâ€™t be paying attention to me for informationÙ« there are much better sources such as <a href="https://www.youtube.com/user/MEDCRAMvideos/videos">Dr. Seheultâ€™s MedCram channel</a>. Anyone who is suggesting people seek out such things without a doctorâ€™s prescription is a dangerous quack].</p>

<p>[Iâ€™m going to expand on this topic of the pipeline from research to actionable advice soonÙ« as itâ€™s quite tricky territory. For exampleÙ« in non-expert circles I see a lot of attention given to the advice to avoid ibuprofen. There is <a href="https://www.sciencemediacentre.org/expert-reaction-to-reports-that-the-french-health-minister-recommended-use-of-paracetamol-for-fever-from-covid-19-rather-than-ibuprofen-or-cortisone/">weak support</a> for thisÙ« and it might be a good idea to use acetaminophen instead out of cautionÙ« but there is not yet expert consensus on this. Update 3/17: the WHO now recommends using acetaminophen rather than ibuprofen as self-medication.]</p>

<p>More tips on misinformation in this <a href="https://twitter.com/imran_malek/status/1238948869565800456">Twitter thread from Imran Malek</a>.</p>

<p>A few organizations deserve credit for very good work. The Atlantic is consistently goodÙ« with a series of excellent articles by James Hamblin in particular. He is one of the best health communicators working today. On TVÙ« Chris Hayes deserves praise.</p>

<p>And I should give credit where credit is due to Fox News for suspending Trish Reganâ€™s show. I just wish theyâ€™d go farther and make a collective decision not to air misinformation altogether. If you have Fox News watching people in your familyÙ« now might be a good time to remind them that itâ€™s an exceedingly poor source of information. Itâ€™s very hard to get through to such peopleÙ« but it might be helpful to point out that <a href="https://www.theguardian.com/media/2020/mar/13/fox-news-accused-of-downplaying-coronavirus-as-it-moves-to-protect-staff">they are saying one thing to their audience and doing another regarding the health of their own employees</a>.</p>

<h2 id="overviews-and-updates">Overviews and updates</h2>

<p>Dr. Jordan Shlain is running regular updates. <a href="https://tincture.io/dispatch-4-from-the-front-lines-79c74fa67ae0">Dr. Shlain Dispatch #4</a> is filled with good stats and tips.</p>

<p>A fantastic summary of the science is the <a href="https://drive.google.com/file/d/1DqfSnlaW6N3GBc5YKyBOCGPfdqOsqk1G/view">How to fight the coronavirus SARS-CoV-2 and its diseaseÙ« CoVID-19</a> slide deck from the Michael Lin lab at Stanford. A complementary talkÙ« with a greater emphasis on analysis of Wuhan (and with both slides and video available) is from <a href="https://twitter.com/XihongLin/status/1238970212780826633">@XihongLin</a> at Harvard.</p>

<p>The Imperial College <a href="https://www.imperial.ac.uk/mrc-global-infectious-disease-analysis/news--wuhan-coronavirus/">Impact of non-pharmaceutical interventions (NPIs) to reduce COVID-19 mortality and healthcare demand</a> report is soberingÙ« and is one of the few responsible sources to cite actual numbers. In their simulation of what happens if we donâ€™t take actual stepsÙ« they predict 2.2 million deaths in the US. That should give the people who complain that the â€œflattenthecurveâ€ graphs are too simplistic and qualitiative some food for thought.</p>

<h2 id="raw-data-resources">Raw data resources</h2>

<p><a href="https://www.worldometers.info/coronavirus/">Worldometer</a> has up-to-date information by country. The <a href="https://www.arcgis.com/apps/opsdashboard/index.html">Johns Hopkins COVID-19 map</a> has long been the go-to resourceÙ« but a limitation is that it aggregates all cases by state in the US but no finer. Especially for large states such as CaliforniaÙ« the <a href="https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html">New York Times</a> dashboard may be more useful.</p>

<p>The <a href="https://ourworldindata.org/coronavirus">Our World in Data</a> website is one of the most comprehensiveÙ« and I particularly commend their <a href="https://ourworldindata.org/coronavirus#trajectories-since-the-100th-confirmed-case">trajectories</a> chart. It is remarkable how similar the trajectories are for most countries (with Japan and smaller city-states being the exceptions). Note that interpretation is tricky; the US has been way behind on testing capacity but will be bringing that online over the next few daysÙ« so we are likely to see a massive uptick in case numbers that represent testing coverage rather than a spike in cases. That will make it hard to evaluate the effectiveness of â€œsocial distancingâ€ measures.</p>

<p><a href="https://ourworldindata.org/coronavirus#trajectories-since-the-100th-confirmed-case"><img src="/assets/ourworld-trajectory.png" alt="trajectories from Our World in DataÙ« 3/14Ù« CC BY" /></a></p>

<p>Likely most readers of this blog understand exponential growth pretty wellÙ« but the 3 Blue 1 Brown video on <a href="https://www.youtube.com/watch?v=Kas0tIxDvrg">Exponential growth and epidemics</a> does a really good job of putting it in context of epidemicsÙ« and in particular explains that a logistic curve is likely a better modelÙ« and that only matches a pure exponential up to the inflection point.</p>

<p>For fans of modelingÙ« <a href="https://twitter.com/trvrb">Trevor Bedford @trvrb</a> is a good person to follow. The Nextstrain work has been tracking the genetic variation from the various strains of SARS-CoV-2 virusÙ« and you can follow <a href="https://twitter.com/firefoxx66">Dr Emma Hodcroft @firefoxx66</a> for updates on that.</p>

<p>I now have a <a href="https://twitter.com/i/lists/1239639611694911489">covid-19 Twitter list</a> which is carefully curated to provide a wide range of expertiseÙ« and high signal to noise ratio.</p>

<h2 id="practical-tips">Practical tips</h2>

<p>I recommend <a href="https://flattenthecurve.com">flattenthecurve.com</a>Ù« not just for explaining the need for â€œsocial distancingâ€ and encouraging itÙ« but also because it puts the advice in context of people actually living their lives.</p>

<p>If you do start developing symptomsÙ« the best guide is <a href="https://www.who.int/publications-detail/home-care-for-patients-with-suspected-novel-coronavirus-(ncov)-infection-presenting-with-mild-symptoms-and-management-of-contacts">Home care for patients with suspected novel coronavirus (nCoV) infection presenting with mild symptoms and management of contacts</a>Ù« from the World Health Organization (also see country-specific versions such as the <a href="https://www.gov.uk/government/publications/covid-19-stay-at-home-guidance/stay-at-home-guidance-for-people-with-confirmed-or-possible-coronavirus-covid-19-infection">UK version</a>. For more discussion of the policy choices around thisÙ« see <a href="https://www.theatlantic.com/health/archive/2020/03/where-do-you-go-if-you-get-coronavirus/607759/">What Will You Do If You Start Coughing?</a> by James Hamblin.</p>

<p>Your local public health department is a great resource. Become familiar with it and be prepared to follow their adviceÙ« as this stuff works better when itâ€™s coordinatedÙ« and theyâ€™ll also point you to authoritative resources. Hereâ€™s the <a href="https://www.cityofberkeley.info/coronavirus/">Berkeley Coronavirus</a> pageÙ« for example.</p>

<p>Hereâ€™s a Twitter thread with much great advice: <a href="https://twitter.com/ASlavitt/status/1238832893771894788">COVID-19 Prep Update- March 14</a> by Andy Slavett. I am not going to post my own projections because it wouldnâ€™t be responsibleÙ« but they are very much on track with his.</p>

<p>But beyond basic health adviceÙ« itâ€™s super important to take care of yourself. Many sources recommend not binging on Covid-19 news (I have been terrible at following that advice). Do other things to stay healthyÙ« and do things to take care of your emotionalÙ« spiritualÙ« and mental health. Iâ€™ve personally been dealing with waves of intense angerÙ« especially when I check my feeds and see the latest monumental fuckup - as I writeÙ« I just saw the images of huge crowds at airports on 3/14. Be aware that this is a tough and stressful timeÙ« and have plans in place to manage it.</p>

<p>Our Quaker meeting has suspended in-person meetings (along with probably most other religious organizations in the country by now)Ù« and is doing online meetings for worship. In additionÙ« weâ€™re setting up an emergency preparedness networkÙ« groups of about 10 each by local neighborhoodÙ« where weâ€™ll be checking in with each other and can serve as a point of contact in case of emergency. I feel good getting involved in thisÙ« and maybe you can consider setting up something similarÙ« whether itâ€™s through your religious groupÙ« schoolÙ« or other social group.</p>

<p>Also make sure to take care of your health in other ways: eat rightÙ« sleep wellÙ« continue to get exercise. Because we donâ€™t have a cure for Covid-19 yetÙ« general health is one of the absolute best predictors of outcome.</p>

<p>Take care of yourselfÙ« take care of each other.</p>

<p>Note: this blog is open source! Feel free to adapt this post as you like (under CC BY 4.0 license)Ù« and also send pull requests to the <a href="https://github.com/raphlinus/raphlinus.github.io">repo</a> to update it.</p>'),('https://raphlinus.github.io/gpu/2020/02/12/gpu-resources.html', 'GPU resources', '1581531642000',  12, '<p>This post is basically a dump of resources Iâ€™ve encountered while doing a deep dive into GPU programming. I welcome pull requests against the <a href="https://github.com/raphlinus/raphlinus.github.io">repo</a> for other useful resources. Also feel free to ask questions in issuesÙ« particularly if the answer might be in the form of a patch to this post.</p>

<h2 id="understanding-the-hardware">Understanding the hardware</h2>

<h3 id="intel">Intel</h3>

<p>Intel is one of the best GPU hardware platforms to understand because itâ€™s documented and a lot of the work is open source.</p>

<ul>
  <li>
    <p><a href="https://en.wikichip.org/wiki/intel/microarchitectures/gen9">Wikichip gen 9</a>Ù« <a href="https://en.wikichip.org/wiki/intel/microarchitectures/gen9.5">gen 9.5</a>Ù« <a href="https://en.wikichip.org/wiki/intel/microarchitectures/gen11">gen 11</a></p>
  </li>
  <li>
    <p><a href="https://software.intel.com/sites/default/files/managed/c5/9a/The-Compute-Architecture-of-Intel-Processor-Graphics-Gen9-v1d0.pdf">Intel white paper on Gen9 compute</a></p>
  </li>
  <li>
    <p><a href="https://01.org/sites/default/files/documentation/intel-gfx-prm-osrc-kbl-vol07-3d_media_gpgpu.pdf">Programmerâ€™s Reference Manual</a> for Kaby Lake (Gen 9.5)</p>
  </li>
</ul>

<p>Thereâ€™s also some academic literature:</p>

<ul>
  <li><a href="http://comparch.gatech.edu/hparch/papers/gera_ispass18.pdf">Performance Characterisation and Simulation of Intelâ€™s Integrated GPU Architecture</a></li>
</ul>

<p>One of the funky things about Intel is the varying subgroup width; it can be SIMD8Ù« SIMD16Ù« or SIMD32Ù« mostly determined by <a href="https://software.intel.com/en-us/forums/opencl/topic/564990">compiler heuristic</a>Ù« but there is a new <a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/html/chap44.html#VK_EXT_subgroup_size_control">VK_EXT_subgroup_size_control</a> extension.</p>

<h3 id="nvidia">NVidia</h3>

<p>Thereâ€™s a lot of interest and activity around NVidiaÙ« but much of it is reverse engineering.</p>

<ul>
  <li>
    <p><a href="https://arxiv.org/pdf/1804.06826.pdf">Dissecting the NVIDIA Volta GPU Architecture via Microbenchmarking</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1903.07486.pdf">Dissecting the NVidia Turing T4 GPU via Microbenchmarking</a></p>
  </li>
</ul>

<h3 id="amd">AMD</h3>

<ul>
  <li>
    <p><a href="https://developer.amd.com/wp-content/resources/Vega_Shader_ISA_28July2017.pdf">â€œVegaâ€ Instruction Set Architecture Reference Guide</a></p>
  </li>
  <li>
    <p><a href="https://gpuopen.com/optimizing-gpu-occupancy-resource-usage-large-thread-groups/">Optimizing GPU occupancy and resource usage with large thread groups</a></p>
  </li>
</ul>

<h2 id="understanding-api-capabilities">Understanding API capabilities</h2>

<ul>
  <li>
    <p><a href="https://vulkan.gpuinfo.org/">vulkan.gpuinfo.org</a> - a detailed database of what extensions are available on what hardware/driver/platform combinations.</p>
  </li>
  <li>
    <p><a href="https://developer.apple.com/metal/Metal-Feature-Set-Tables.pdf">Metal Feature Set Tables</a> has similar info for Metal.</p>
  </li>
</ul>

<h2 id="subgroups">Subgroups</h2>

<p>Subgroup/warp/SIMD/shuffle operations are very fastÙ« but less compatible (nonuniform shuffle is missing from HLSL/SM6)Ù« and you (mostly) donâ€™t get to control the subgroup sizeÙ« so portability is a lot harder.</p>

<ul>
  <li>
    <p><a href="https://www.khronos.org/blog/vulkan-subgroup-tutorial">Vulkan Subgroup Tutorial</a></p>
  </li>
  <li>
    <p><a href="https://www.khronos.org/assets/uploads/developers/library/2018-vulkan-devday/06-subgroups.pdf">Vulkan Subgroup Explained</a></p>
  </li>
  <li>
    <p><a href="https://developer.nvidia.com/reading-between-threads-shader-intrinsics">Reading Between The Threads: Shader Intrinsics</a></p>
  </li>
</ul>

<h2 id="languages">Languages</h2>

<h3 id="glsl">GLSL</h3>

<ul>
  <li>
    <p><a href="https://github.com/KhronosGroup/glslang">https://github.com/KhronosGroup/glslang</a> - reference implementation of GLSLÙ« compilation to SPIR-V</p>
  </li>
  <li>
    <p><a href="https://github.com/google/shaderc">shaderc</a> - Google-maintained tools</p>
  </li>
</ul>

<h3 id="hlsl">HLSL</h3>

<ul>
  <li>
    <p><a href="https://github.com/microsoft/DirectXShaderCompiler">DirectX Shader Compiler</a> (DXC) - produces both SPIR-V and DXIL.</p>
  </li>
  <li>
    <p><a href="https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-pguide">Programming guide for HLSL</a></p>
  </li>
  <li>
    <p><a href="https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/hlsl-shader-model-6-0-features-for-direct3d-12">Shader Model 6</a></p>
  </li>
</ul>

<h3 id="metal-shading-language">Metal Shading Language</h3>

<ul>
  <li><a href="https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf">Metal Shading Language Specification</a></li>
</ul>

<h3 id="opencl">OpenCL</h3>

<ul>
  <li>
    <p><a href="https://github.com/google/clspv">clspv</a> - compile OpenCL C (subset) to run on Vulkan compute shaders.</p>

    <ul>
      <li>To meÙ« this is evidence that Vulkan will simply eat OpenCLâ€™s lunch. This is still <a href="https://github.com/KhronosGroup/Vulkan-Ecosystem/issues/42">controversial</a>Ù« but Khronos people are insisting thereâ€™s an â€œOpenCL Nextâ€ roadmap.</li>
    </ul>
  </li>
  <li>
    <p><a href="https://www.khronos.org/news/press/khronos-group-releases-opencl-3.0">OpenCL 3.0</a> is recently announcedÙ« and their plans do include clspv and related tools to run on a Vulkan.</p>
  </li>
</ul>

<h3 id="tensorflow">TensorFlow</h3>

<ul>
  <li><a href="https://blog.tensorflow.org/2019/04/mlir-new-intermediate-representation.html">MLIR</a></li>
</ul>

<h3 id="exotic-languages">Exotic languages</h3>

<ul>
  <li>
    <p><a href="https://halide-lang.org/">Halide</a></p>
  </li>
  <li>
    <p><a href="https://futhark-lang.org/">Futhark</a></p>
  </li>
  <li>
    <p><a href="https://github.com/Co-dfns/Co-dfns">Co-dfns</a></p>
  </li>
  <li>
    <p><a href="https://juliacomputing.com/industries/gpus.html">Julia on GPU</a> - layered on CUDA</p>
  </li>
</ul>

<h2 id="spir-v">SPIR-V</h2>

<ul>
  <li>
    <p><a href="https://github.com/KhronosGroup/SPIRV-Cross">SPIRV-Cross</a> - transpile SPIR-V into GLSLÙ« HLSLÙ« and Metal Shading Language</p>

    <ul>
      <li>This is an integral part of portability layers including <a href="https://github.com/KhronosGroup/MoltenVK">MoltenVK</a> and <a href="https://github.com/gfx-rs/gfx">gfx-rs</a>.</li>
    </ul>
  </li>
</ul>

<h2 id="webgpu">WebGPU</h2>

<ul>
  <li>
    <p><a href="https://fosdem.org/2020/schedule/event/rust_webgpu/">Building WebGPU with Rust</a> - FOSDEM talk</p>
  </li>
  <li>
    <p><a href="https://github.com/gfx-rs/wgpu">wgpu</a> - Rust WebGPU implementation</p>
  </li>
  <li>
    <p><a href="https://dawn.googlesource.com/dawn">dawn</a> - Googleâ€™s WebGPU implementation in C++</p>
  </li>
  <li>
    <p>Work-in-progress <a href="https://gpuweb.github.io/gpuweb/">specification</a></p>
  </li>
  <li>
    <p><a href="https://developers.google.com/web/updates/2019/08/get-started-with-gpu-compute-on-the-web">Get started with GPU Compute on the Web</a> - Google (Chromium/Dawn)</p>
  </li>
</ul>

<h3 id="webgpu-shader-language">WebGPU shader language</h3>

<p>The discussion of shader language had been very <a href="https://news.ycombinator.com/item?id=22020511">contentious</a>. As of very recently there is a proposal for a textual language that is semantically equivalent to SPIR-VÙ« and there seems to be agreement that this is the path forward.</p>

<ul>
  <li>
    <p><a href="https://docs.google.com/presentation/d/1qHhFq0GJtY_59rNjpiHU--JW4bW4Ji3zWei-gM6cabs/edit">Tint - WebGPU F2F - Feb 12Ù« 2020</a></p>
  </li>
  <li>
    <p><a href="https://docs.google.com/document/d/1vQPA1JSOvfCHjBrkAEDLA1qCqQXe72vGen_1quoHZV8/edit#">Minutes for GPU Web meeting 2020-02-12 Redmond F2F</a></p>
  </li>
</ul>

<p>The previous proposals were some profile of SPIR-VÙ« a binary formatÙ« and Appleâ€™s <a href="https://webkit.org/blog/8482/web-high-level-shading-language/">Web High Level Shading Language</a> proposalÙ« which evolved into <a href="https://github.com/gpuweb/WSL">Web Shading Language</a>. Both of these had disadvantages that made them unacceptable to various people. Itâ€™s not possible to use SPIR-V directlyÙ« largely because it has undefined behavior and other unsafe stuff. The Google and Mozilla implementations addressed this by doing a rewrite pass. ConverselyÙ« Appleâ€™s proposal met with considerable resistance because it didnâ€™t deal with the diversity of GPU hardware in the field. Thereâ€™s a lot of ecosystem work centered around Vulkan and SPIR-VÙ« and leveraging that will help WebGPU considerably.</p>'),('http://thume.ca/2020/09/04/macos-tips/', 'Hard to discover tips and apps for making macOS pleasant', '1599177600000',  13, '
<p>Inspired by a few different conversations with friends whoâ€™ve switched to macOS where I give them a whole bunch of tips and recommendations Iâ€™ve learned about over many years which are super important to how I use my computerÙ« but often quite hard to find out aboutÙ« I decided to write them all down:</p>

<h2 id="hidden-macos-tips">Hidden macOS tips</h2>

<ul>
  <li>Dragging a file or folder onto a file open dialog selects it in the dialog. Similarly dragging onto a â€œChoose fileâ€ button.</li>
  <li>Dragging onto a terminal window pastes the full path of that file/folder</li>
  <li>You can drag the little file/folder icons at the top of many windowsÙ« useful in combo with previous tips.</li>
  <li>If you hold down <code class="language-plaintext highlighter-rouge">option</code> while clicking the â€œScaledâ€ radio button in the Display preferences itâ€™ll give you many more resolution options on external displays. If you want native resolution with no scaling on the built in display youâ€™ll still need an external tool like <a href="https://www.madrau.com/">SwitchResX</a>Ù« <a href="https://github.com/lunixbochs/meta/tree/master/utils/retina">retina</a> or <a href="https://www.thnkdev.com/QuickRes/">QuickRes</a>.</li>
  <li>In FinderÙ« <code class="language-plaintext highlighter-rouge">return</code> is the shortcut for renameÙ« <code class="language-plaintext highlighter-rouge">option</code>+drag copiesÙ« and <code class="language-plaintext highlighter-rouge">space</code> is quicklook preview</li>
  <li>In Preview if you open the Sidebar in a PDF you can drag pages around including between documentsÙ« hold option to copyÙ« delete pages with backspace. This plus the edit toolbar solves 90% of my PDF munging needs.</li>
  <li>You can select multiple images in Finder and drag them onto the Preview dock icon to open them in one window with a Sidebar where you can quickly flip between them with arrow keys.</li>
  <li>In the Dock preferences thereâ€™s a â€œPrefer tabs when opening documentsâ€ setting which automatically groups your windows with window tabs. I find this especially useful for Sublime Text.</li>
  <li><code class="language-plaintext highlighter-rouge">cmd+backtick</code> is like <code class="language-plaintext highlighter-rouge">cmd+tab</code> but between windows of the same app.</li>
  <li>Drag your most frequently used folders into the Finder sidebar for easy access including in file select dialogs.</li>
  <li>In the Finder preferences you can add your computer and drives to the sidebar.</li>
  <li><code class="language-plaintext highlighter-rouge">cmd+shift+4</code> pops up a crosshair to take a screenshot of a region.</li>
  <li>You can <a href="https://www.defaults-write.com/disable-press-and-hold-option-in-mac-os-x-10-7/">disable the popup for accented characters when you hold a key</a> and  <a href="https://apple.stackexchange.com/questions/10467/how-to-increase-keyboard-key-repeat-rate-on-os-x">increase key repeat rate beyond the normal maximum</a>.</li>
  <li>The <code class="language-plaintext highlighter-rouge">open</code> command lets you use the normal macOS file opening mechanism from the command lineÙ« I most frequently use <code class="language-plaintext highlighter-rouge">open .</code> to navigate to my current directory in my file browser.</li>
  <li>Display â€œscalesâ€ other than 1x or 2x the physical resolution work by rendering at 2x the resolution then down-scaling. This causes apps to need to render a bunch of pixels that are mostly scaled awayÙ« consuming power and sometimes causing lag. It can also lead to weird aliasing issues in some contexts like shimmering of thin fonts when scrollingÙ« as well as rendering in general not being pixel-perfect. I recommend trying to stick to either 1x or 2x scaling if you donâ€™t lose much from itÙ« then just adjusting your default web page scale and font sizes.</li>
  <li>Text fields <a href="https://jblevins.org/log/kbd">support a bunch of powerful movement and editing shortcuts based on Emacs</a>.</li>
  <li><code class="language-plaintext highlighter-rouge">option+2</code> types the <code class="language-plaintext highlighter-rouge">â„¢</code> symbolÙ« for use with sarcasmâ„¢. I probably use this more than the <code class="language-plaintext highlighter-rouge">^</code> symbol. You can open the keyboard viewer (you may have to enable â€œShow keyboard and emoji viewers in menu barâ€ in Keyboard Preferences) and hold down option to see all the other symbols you can type like this. The â€œEmoji &amp; Symbolsâ€ pallete is also a great UI for finding handy Unicode charactersÙ« especially if you use the gear menu to add more symbol category pages.</li>
</ul>

<h2 id="apps">Apps</h2>

<p>A big part of why I prefer macOS is this list of macOS-only native apps which often donâ€™t have adequate substitutes on Linux:</p>

<ul>
  <li><a href="https://kapeli.com/dash">Dash</a>: An amazing fast offline documentation search app. Cuts down a ton on the amount I Google for docs. Itâ€™s very quick to use especially when summoned with a keyboard shortcut and has tons of documentation sets.</li>
  <li><a href="https://www.hammerspoon.org/">Hammerspoon</a>: My favorite app for getting the benefits of a Linux tiling window manager. I have home row shortcuts on my left hand bound to switch directly to my most frequently used appsÙ« and my right hand to maximize windowsÙ« move them between screens and tile them to the left and right halves of the screen. <a href="https://github.com/trishume/dotfiles/blob/d12f869062b2fa2d4b3f72eeed2f0e05df5a8657/hammerspoon/hammerspoon.symlink/init.lua">Hereâ€™s my config.</a></li>
  <li><a href="https://www.thnkdev.com/Screenie/">Screenie</a>: I only use this for the feature where dragging from the menu bar icon lets you put your most recent screenshot in say messaging apps. It also offers search and things. <a href="https://cleanshot.com/">CleanShot X</a> and <a href="https://zapier.com/zappy">Zappy</a> also look like good screenshot apps but I havenâ€™t tried them yet.</li>
  <li><a href="https://karabiner-elements.pqrs.org/">Karabiner Elements</a>: A powerful keyboard remapping tool. I use it to bind right command to control and caps lock to <code class="language-plaintext highlighter-rouge">ctrl+cmd+option+shift</code> for use with Hammerspoon.</li>
  <li><a href="https://www.alfredapp.com/">Alfred</a>: A mildly better spotlight alternativeÙ« but for me the main benefit over spotlight is <a href="https://github.com/deanishe/alfred-repos">this workflow for indexing git repos</a>.</li>
  <li><a href="https://cocoatech.com/#/">Path Finder</a>: A fancier version of Finder with multiple panes and various other advanced features. Other third party file managers you may want to try include <a href="https://binarynights.com/">Forklift</a>Ù« <a href="https://mac.eltima.com/file-manager.html">Commander One</a>Ù« <a href="https://magnumbytes.com/">Nimble Commander</a>Ù« <a href="https://marta.yanex.org/">Marta</a> and <a href="https://fman.io/">fman</a>. I use Path Finder because itâ€™s the only one with a good columns view and thatâ€™s my favorite view for browsing.</li>
  <li><a href="https://sparkmailapp.com/">Spark</a>: A nice email app with categorized inbox functionality.</li>
  <li><a href="https://bjango.com/mac/istatmenus/">iStat Menus</a>: All sorts of system monitoring in a menu bar. I really like the weatherÙ« and I also have a combined menu which shows my current power draw in watts and GPU selection in the icon.</li>
  <li><a href="https://tapbots.com/tweetbot/mac/">Tweetbot</a>: A native Twitter client that syncs with a similar IOS client. I really like how it just keeps your position in an infinite scroll where new tweets get added to the topÙ« so I can easily read every new tweet from people I follow without seeing any likesÙ« algorithmic suggestions or ads.</li>
  <li><a href="https://github.com/ridiculousfish/HexFiend/">Hex Fiend</a>: A really good hex editor/viewer. I like their â€œTemplatesâ€ feature where you can describe a binary format with a script and it will overlay the parse tree on the hex view.</li>
  <li><a href="https://iterm2.com/">iTerm2</a>: An alternative Terminal with just <em>so many features</em>. I particularly like the ability to split windows into panesÙ« which Appleâ€™s Terminal does not have.</li>
  <li><a href="https://brettterpstra.com/projects/nvalt/">nvAlt</a>: A note taking app that I likeÙ« although itâ€™s kinda bare-bones and has some bugs. Itâ€™s currently unmaintained because the author is working on <a href="https://nvultra.com/">nvUltra</a> which isnâ€™t released yet.</li>
  <li><a href="https://imageoptim.com/mac">ImageOptim</a>: Easy app where you drag image files onto it and it reduces their size.</li>
  <li><a href="https://www.vmware.com/products/fusion.html">VMWare Fusion</a>: Great for running Linux and Windows VMs. The reason I chose it over <a href="https://www.parallels.com/products/desktop/pro/">Parallels</a> is that I knew it had virtualized PMC supportÙ« which enables using <a href="https://rr-project.org/">rr</a> in VMs. But apparently Parallels also has this in the Pro versionÙ« and it might be nicer in other waysÙ« not sure which is better.</li>
  <li><a href="http://calca.io/">Calca</a>: A weird live math calculator notebook thing with units. The editing can be kind of glitchy but the basic functionality is really cool. <a href="https://soulver.app/">Soulver</a> is a similar but more expensive app with a nicer UI but less powerful underlying calculator language.</li>
  <li><a href="https://developer.apple.com/download/more/">Quartz Debug</a>: There are some apps that reduce your battery life in an insidious way where it doesnâ€™t show as CPU usage for their process but as increased <code class="language-plaintext highlighter-rouge">WindowServer</code> CPU usage. If your <code class="language-plaintext highlighter-rouge">WindowServer</code> process CPU usage is above maybe 6-10% when youâ€™re not doing anythingÙ« some app in the background is probably spamming 60fps animation updates. As far as I know you can only figure out which app is at fault by getting the Quartz Debug app from <a href="https://developer.apple.com/download/more/">Appleâ€™s additional developer tools</a>Ù« enabling flash screen updates (and no delay after flash)Ù« then going to the overview mode (four finger swipe up) and looking for flashing. This same problem can also occur on Linux and Windows but I donâ€™t know how much power it saps there.</li>
  <li><a href="https://www.sublimetext.com/">Sublime Text</a> and <a href="https://www.sublimemerge.com/">Merge</a>: These arenâ€™t exactly macOS-only apps but theyâ€™re some of my favorite apps and they integrate excellently with macOS so Iâ€™m putting them here anyways.</li>
</ul>

<h2 id="bonus-browsers">Bonus: Browsers</h2>

<ul>
  <li>Middle click opens links in a new tab and middle clicking on a tab closes it</li>
  <li>Thereâ€™s lots of lesser-known handy shortcuts: cmd/ctrl+l focuses the search filedÙ« cmd/ctrl+w closes a tab</li>
  <li><a href="https://vimium.github.io/">Vimium</a> and <a href="https://www.octotree.io/">OctoTree</a> are my favorite browser extensions.</li>
  <li>I believe YouTube in Chrome and Firefox default to VP8/9 video codecs which canâ€™t be hardware-decoded so use lots of CPU and thus battery power especially at 2x speed or high resolutions. The <a href="https://github.com/alextrv/enhanced-h264ify">h264ify</a> family of extensions can force usage of GPU-supported h264 codecs. This can close some of the battery life gap with Safari.</li>
  <li>If you use SafariÙ« Chrome and Firefox have much better sounding audio resampling for watching videos on 1.5x or 2x speed. This is the only reason I donâ€™t use Safari.</li>
</ul>

<h2 id="bonus-ios">Bonus: IOS</h2>

<p>IOS also has a bunch of hidden UI featuresÙ« especially if you have a medium-old model of iPhone that still has force touch sensors.</p>

<ul>
  <li>Swiping left and right on the home bar at the bottom of the screen on phones since the iPhone X quickly switches between recent apps. This is absolutely essential to how I use my phone and such a huge boost to multitasking fluidity I feel bad for all the people who donâ€™t know about it.</li>
  <li>Force or long pressing on the keyboard (maybe just the spacebar on some phones)Ù« brings up a moveable cursor in text fields.</li>
  <li>If you have force touch try it on everythingÙ« tons of widgets in the pull down settings have force touch featuresÙ« notifications doÙ« links do.</li>
  <li>Iâ€™ve tried a lot of calculator apps and Kalkyl is my favorite for launch time and UI design for quick simple calculations. I also recommend Unread for RSSÙ« and Apollo as possibly the best Reddit experience on any platform.</li>
  <li><a href="https://isitsnappy.com/">Is It Snappy</a> lets you use an IOS deviceâ€™s high speed camera to measure full-system interaction latency and find out that you have a slow keyboardÙ« mouse or monitor. I have not found a similar app for Android.</li>
  <li>Not exactly a software tipÙ« but a non-obvious purchasing option: I contend buying an iPhone X on Ebay offers outstanding price/quality ratio even in 2020. It has basically the same screen/form factor/build quality as an iPhone 11 ProÙ« and I find it plenty fast and the camera sufficiently goodÙ« and those are basically the only things that improved. You even get force touchÙ« which I really like as having lower latency than the more press-and-hold â€œ3D Touchâ€. Meanwhile itâ€™s less than half the price. I got mine discounted after the iPhone XS replaced itÙ« and if mine broke Iâ€™d probably just buy another one now.</li>
</ul>

<h2 id="bonus-the-chromium-catapult-trace-viewer">Bonus: The Chromium Catapult Trace Viewer</h2>

<p>The motivation to write this post was caused by a conversation with a friend about macOSÙ« which was in turn kicked off by <a href="https://twitter.com/trishume/status/1302069073640120320?s=20">a tweet</a> about the <a href="https://aras-p.info/blog/2017/01/23/Chrome-Tracing-as-Profiler-Frontend/">The Chromium Trace Viewer (AKA Catapult)</a>. Catapult is super easy to get started with for visualizing trace data and I know lots of different people and projects who use it. Almost none of them know about this incredibly helpful first tip until I tell it to themÙ« so theyâ€™re stuck with having to switch to the zoom tool in the toolbar:</p>

<ul>
  <li>Use <code class="language-plaintext highlighter-rouge">alt+scroll</code> to zoom. This really ought to be in noticeable text on their UI not buried in a shortcuts pane you have to press <code class="language-plaintext highlighter-rouge">?</code> to see.</li>
  <li>The search bar in the top left searches not only names but also arguments valuesÙ« which you can use to search for IDs or add special tags like <code class="language-plaintext highlighter-rouge">top100</code> for the 100 slowest events. Press <code class="language-plaintext highlighter-rouge">f</code> to zoom to a span once youâ€™ve selected it with the search arrow buttons.</li>
  <li>The JSON event format also supports â€œflowâ€ arrowsÙ« which lets you draw arrows between your boxes to visualize dependencies.</li>
  <li><a href="https://perfetto.dev/">Perfetto</a>Ù« <a href="https://github.com/wolfpld/tracy">Tracy</a> and <a href="https://www.speedscope.app/">Speedscope</a> can all visualize the same JSON format with different UIs and potentially without a trace size cap.</li>
</ul>
'),('http://thume.ca/2020/08/15/ropshipai/', 'Reverse engineering an AI spaceship game at DEF CON CTF', '1597449600000',  13, '
<p>I recently played with <a href="[Samurai](https://ctftime.org/team/1937)">Samurai</a> in the DEF CON CTF 2020 finalsÙ« and want to write about an incredibly cool challenge I worked on called <code class="language-plaintext highlighter-rouge">ropshipai</code>. It involved reverse engineering a binary to discover the architecture and format of a neural networkÙ« creating a network to control your spaceship in an arena against all the other teamsÙ« then doing a <a href="https://en.wikipedia.org/wiki/Return-oriented_programming">ROP</a> exploit using a buffer overflow to get more capacity for a smarter AI. I hope this article can give you a taste of what high level security CTF contests can be like and why theyâ€™re so fun.</p>

<p>Hereâ€™s what it looked like near the end of the contestÙ« I cherry-picked a round where our final bot (labeled â€˜Xâ€™ in light grey) won:</p>
<video controls="" width="660" autoplay="" muted="" loop="">
    <source src="/assets/postassets/ropshipai/v313-trim2.mp4" type="video/mp4" />
    SorryÙ« your browser doesn"t support embedded videos.
</video>

<h2 id="part-1-reverse-engineering">Part 1: Reverse engineering</h2>

<p>We were given a download which included a PyGame UI to simulate the game. The UI called out to an x86 binary which we figured out computed the move for a teamâ€™s bot using an input file. We figured that file was probably the same thing the â€œUpload AIâ€ button on the challengeâ€™s web portal accepted. There was a challenge a previous year called â€œropshipâ€ that involved a similar arena with bots controlled by return-oriented programming and we assumed the â€œAIâ€ added this year meant a neural netÙ« but didnâ€™t yet see any of the organizersâ€™ usual Tensorflow.</p>

<p>So we started reversing the binaryÙ« and my teammates found various functions that seemed to do floating point math and loopsÙ« which they started using <a href="https://www.hex-rays.com/products/decompiler/compare/compare_vs_disassembly/">IDAâ€™s decompiler</a> on and matching up with common neural net functions. They quickly found <a href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/">ReLU</a>Ù« then an iterative function that we figured out produced results matching <code class="language-plaintext highlighter-rouge">e^x</code>. We also found a function that at first appeared to be <code class="language-plaintext highlighter-rouge">1/(1-e^(-x))</code>Ù« which was confusing since thatâ€™s almost <a href="https://en.wikipedia.org/wiki/Sigmoid_function">a sigmoid</a> but with subtraction instead of addition. I took a look in <a href="https://binary.ninja/">Binary Ninja</a> and it looked like addition to meÙ« it turned out IDA had just decompiled it wrong and it <em>was</em> a sigmoid.</p>

<p>That left the big function with lots of math and loopsÙ« which we assumed was the main network evalutation function. I got to work using the new decompiled view in Binary Ninja to try and decipher what it was doing and what the structure of the inputs we had to give it wereÙ« while my teammate <a href="https://twitter.com/samczsun">samczsun</a> figured out the input file parsing code that set up those inputs. At the same timeÙ« other teammates figured out the simulator and what inputs it could feed to the network.</p>

<p><a href="/assets/postassets/ropshipai/reversing.png"><img src="/assets/postassets/ropshipai/reversing.png" alt="Reversing in binja" /></a></p>

<p>I reverse-engineered all the pointer arithmetic and simplified things to write out a pseudo-C version of the network evaluation function. It seemed to evaluate a number of lineary layers with biasesÙ« each followed by either a sigmoid or ReLU activation function (chosen by the input file). The input parsing code hard-coding the number of hidden layers between the input and output layer equal to 1Ù« which was weird and fishy.</p>

<p>Once we had collectively figured out how everything fit togetherÙ« we wanted to get a bot out there and earning points as fast as possible. First <a href="https://twitter.com/lunixbochs">aegis</a> wrote a Python network serializer script and deployed a bot that just set the bias on going forward to run us into the wall so we were a smaller target and not in the expected position for anyone managing to shoot. The next bot had hand-designed weights in the matrices to rotate the ship unless it was ready to fire in which case it shot. We werenâ€™t quite the first to upload a non-empty network (an empty file just shot the wall) but we were something like 2nd.</p>

<h2 id="part-2-training-a-better-network">Part 2. Training a better network</h2>

<p>While <code class="language-plaintext highlighter-rouge">aegis</code> worked on making a smarter hand-coded botÙ« I started work on training a real neural net to be a better AI. An alternative I brought up was to write something to compile a domain specific language to weightsÙ« using the fact I had learned about in my university machine learning course that you could approximate any function using only one hidden layer by using <a href="http://neuralnetworksanddeeplearning.com/chap4.html">a specific method of engineering weights</a> to set the value of the output for different regions of input. HoweverÙ« given that both <code class="language-plaintext highlighter-rouge">aegis</code> and I had done some deep learning training before we figured it would be easier to just use gradient descent.</p>

<p>I fired up a <a href="https://jupyter.org/">Jupyter</a> notebookÙ« replicated the architectureÙ« and thought of a way to make a basic AI by writing a Python function to output what we wanted the AI to do given various inputsÙ« and feeding lots of randomly generated input vectors through the function and training the neural net to match those actions like a normal supervised classifier.</p>

<p>Unfortunately it was harder than I expected and it took annoyingly long tuning hyperparameters and how my training setup worked before I even managed to train a network to do one action if the single input was less than <code class="language-plaintext highlighter-rouge">0.5</code> and another if it was greater:</p>

<p><img src="/assets/postassets/ropshipai/pointfive.png" alt="PointFiveNet" /></p>

<p>Next I worked on modifying <code class="language-plaintext highlighter-rouge">aegis</code>â€™s codeÙ« which wrote out his hand-coded weights in the correct formatÙ« to take the weights from my trained model. Unfortunately the first network I exported this way just didnâ€™t do anything when run in the simulator. So I spent some time investigating the polarity of how PyTorch did biasesÙ« trying out different combinations and reasoning through whether
I wanted to write things out in row-major or column-major orderÙ« all to no avail. I even wrote some code to export aegisâ€™s hand-coded weights using my exporterÙ« and that worked but my model still didnâ€™t.</p>

<p>So after around 2 hours I tried using GDB to trace the execution of my model through the binary while referencing the disassembly in Binary NinjaÙ« to see what was going wrong. To my surprise it seemed to exit before it even ran my modelÙ« and exited with a weird error code. I bisected it down to find a validation function that limited hidden layer size to a 2x2 matrixÙ« way too small to train anything significant. I posted the bad news in Slack and it turned out <code class="language-plaintext highlighter-rouge">samczsun</code> had figured this out a while ago but in the hectic phase of everyone working on different reverse engineering in parallelÙ« the rest of us didnâ€™t hear.</p>

<h2 id="part-3-the-exploiting-and-fancier-bots">Part 3: The exploiting and fancier bots</h2>

<p>It looked like the â€œropâ€ in the challenge name wasnâ€™t just a callback to last yearâ€™s â€œropshipâ€ challenge and weâ€™d have to exploit our way into more model capacity. We had already found a buffer overflow on the stack with unbounded user-controlled contentsÙ« in the code which fetched the inputs to feed to the network. It seemed like we could craft a ROP exploit to manipulate the size parameters of the network to change them after they had been validated. ROP is a technique where if you can overwrite the address the function call should return to on the stackÙ« you can make it return anywhere you wantÙ« allowing you to execute any sequences of suffixes of any functions in the program to perform your exploit. There was a <code class="language-plaintext highlighter-rouge">seccomp</code> policy and some weird custom â€œASLRâ€ and â€œsandboxingâ€ that simultaneously made some ROP a bit easier while keeping things contained so we couldnâ€™t easily just break out and exploit the challenge or run arbitrary code as our AI.</p>

<p>Iâ€™ve never done ROP so <code class="language-plaintext highlighter-rouge">aegis</code> and <code class="language-plaintext highlighter-rouge">samczsun</code> started work on that while I patched out the validation in my personal copy of the binary and got to work on training a better bot to work with the eventual exploit. In the mean time <code class="language-plaintext highlighter-rouge">chainsaw10</code> had written some better Python AI functions using a patched simulator to test them outÙ« which I worked on training a model to match. It was again surprisingly difficult. I had a lot of trouble getting it to be able to do actions like shieldingÙ« which only needed to happen on around 5% of random inputs. The network would just always output <code class="language-plaintext highlighter-rouge">0.0</code> for those actions except on some lucky training runs. I suspect something was going wrong with my initialization or gradients such that on most runs the shield output would fall into a place it could never get a gradient signal to recover from.</p>

<p>Three hours later at around 6am I managed to get a basic AI trained which turned towards the closest botÙ« moved towards itÙ« shot at it and shielded. At that point I went to sleepÙ« the contest had been on a 9 hour pause and I intended to wake up again before it restartedÙ« when the exploit would hopefully be finished.</p>

<p>I ended up sleeping past my alarm until 2 hours after the contest started again. When I woke upÙ« <code class="language-plaintext highlighter-rouge">aegis</code> and another teammate had finished the ROP exploit and wrote a converter that added the exploit to the latest bot I trainedÙ« and it was deployed and doing decently! The exploit development had hit some snags but eventually landed on something which overwrote the return address to restart the execution of the function with the buffer overflow multiple times to get various things overwrittenÙ« to patch in a new network after the hidden size validation had passed on the original overflowing network.</p>

<p>Unfortunately the bot we uploaded was still kind of crappyÙ« it knew how to move around the arena towards a target but it kept doing that until it was right on top of them and then often died if the opponent then shot us at point blank range. It also only used the sine of the angle to the enemy so due to an ambiguity it would sometimes run in the exact opposite direction.</p>

<p>So <code class="language-plaintext highlighter-rouge">aegis</code> and I worked on a better training setup with a GPU box and larger networks. In the mean time <code class="language-plaintext highlighter-rouge">chainsaw10</code> had improved the AI function to not get too close to enemies and also be able to dodge bullets. We still had tons of trouble reliably training a network to match the functionÙ« but eventually ended up with a slightly better version of our previous bot and a version without very good aim trained on our new bot code. In simulations with our own bots the very accurate but simpler bot did betterÙ« so we uploaded thatÙ« but an hour later and one hour before the end of the contest I saw it wasnâ€™t actually doing well against the other teamsÙ« so I uploaded the more sophisticated bot and it did much better and even managed to win a few rounds. It still had crappy aim and sometimes did the wrong thing thoughÙ« and it had taken a lot of tweaking to get it to learn to shield.</p>

<h2 id="postscript-compiling-to-neural-nets">Postscript: Compiling to neural nets</h2>

<p>In hindsight given how much trouble we had training our small neural networksÙ« in what seemed like it should have been a really easy taskÙ« it seems like the best approach was to use the <a href="http://neuralnetworksanddeeplearning.com/chap4.html">universal function approximation proof style tricks</a> to write a compiler from a logic DSL to network weights that exactly implemented the function. Iâ€™m still not sure whether we had a hard time training because training shallow networks with small capacity is just hardÙ« or there was some technique we were missing to get our training to work well.</p>

<p>In the last two hours of the contest I worked on a prototype of the compiler approach for fun and managed to get it mostly working. I was using only one hidden layer so my input DSL required providing some constant thresholds on inputsÙ« <code class="language-plaintext highlighter-rouge">AND</code> gates on those threshold signalsÙ« and then each output was an <code class="language-plaintext highlighter-rouge">OR</code> of some of the <code class="language-plaintext highlighter-rouge">AND</code> results. This was enough to implement any truth table on thresholdsÙ« but it was incredibly wasteful of network capacity to do so and the flattening of the decision tree to a truth table still needed to be done manually. I had some ideas for how to automatically flatten a decision tree Python function into a truth table though using overloaded operators that detected thresholding on the inputs and breadth-first searched to explore the space of outputsÙ« but the contest ended and I wanted to catch up on sleep after that.</p>

<p>I talked to my friend on team <a href="http://pwning.net/">PPP</a>Ù« since PPP had a bot with really good clean behavior. He said that PPP did go the route of implementing a compiler to network weightsÙ« which could compile an arbitrary decision tree that included vector space arithmetic. They did it without flattening the tree by using multiple hidden layersÙ« which the exploit allowed you to use. Unfortunately while as far as we could tell we should have been able to use multiple hidden layersÙ« when we tried a multi-layer network it failed to do anythingÙ« and we never bothered to figure out whyÙ« since our training process worked about as well with one hidden layer.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Overall this is the challenge I had the most fun with this DEF CON CTF finalsÙ« it combined reverse engineeringÙ« neural nets and exploitationÙ« and had different possible valid approaches to solve it. It was super fun to upload an AI and see it dodge bullets and beat other teams based on a tower of hard-won knowledge and code from hours of work reverse engineering and tinkering. In general I get really into DEF CON CTF challenges because theyâ€™re a great combination of tractable problems I can work with friends on with fun competitive time pressureÙ« that also are really interesting and difficult to make me feel like Iâ€™m exercising all of my available skill.</p>

<p>This was only the last challenge I worked on. Earlier in the contest I worked on <a href="https://archive.ooo/c/rorschach/372/">rorschach</a> helping <code class="language-plaintext highlighter-rouge">aegis</code> by figuring things out and coming up with tweaks to make our black box hill climbing solver exploit a neural net classifier fasterÙ« and coming up with defensive checks against other teamsâ€™ attacks. In the middle I did miscellaneous reverse engineering and spent hours working on attacks for exploits teams patched before we were done implementing themÙ« and an AI for another multi-team game that closed before I could deploy it. My other AI did have the best dang debugging visualizations a rushed CTF hack has ever seen though thanks to my affinity for <a href="http://holoviews.org/">HoloViews</a>Ù« which might have had a little to do with why it was too lateâ€¦</p>

<video controls="" width="660" autoplay="" muted="" loop="">
    <source src="/assets/postassets/ropshipai/rhgai.mp4" type="video/mp4" />
    SorryÙ« your browser doesn"t support embedded videos.
</video>

'),('http://thume.ca/2020/07/19/my-youtube-tier-list/', 'My tier list of interesting YouTube channels', '1595116800000',  13, '
<p>I watch a lot more YouTube than I do any other type of video contentÙ« and my favorite type of YouTube videos are interesting ones. I hesitate to call them â€œeducationalâ€Ù« because theyâ€™re often not necessarily trying to teachÙ« but to me the category distinction is theyâ€™re trying to be interesting in some way that pertains to the real world rather than just purely entertaining like video game content or comedy.</p>

<p>I often find myself recommending these channels to friendsÙ« so I figured I might as well write up my endorsementsÙ« and I made it a <a href="https://en.wikipedia.org/wiki/Tier_list">tier list</a> since I love the format. Thereâ€™s a huge variety of really cool and impressive channels out there with kinds of content you canâ€™t find anywhere elseÙ« and Iâ€™ve watched a lot of them for years and want to highlight them. The tier choices can be kinda arbitrary and I didnâ€™t pay any attention to the ordering within tiers. Note that this is a tier list of <em>my favorite interesting</em> YouTube channels:</p>

<ul>
  <li><strong>â€œmyâ€</strong>: These are ordered based on what I feel like endorsing/recommendingÙ« other people with different interests may place them higher or lowerÙ« and some really well-made popular channels are lower down just because they donâ€™t capture me as much.</li>
  <li><strong>â€œfavoriteâ€</strong>: Even once we get down to â€œD tierâ€ theyâ€™re still great stuff I watch regularly and above everything Iâ€™ve encountered and wasnâ€™t into</li>
  <li><strong>â€œinterestingâ€</strong>: Thereâ€™s other YouTube channels I watch and enjoyÙ« like some video game channelsÙ« which are more pure entertainment and arenâ€™t included here.</li>
</ul>

<p>My blog posts tend to be about programming but I barely watch any programming channels. I mostly watch all sorts of random interesting channels on everything from machining to videography. Most of these channels are pretty accessible to anyone interested even if they arenâ€™t versed in the subjectÙ« while still often targeting something obscure or impressive rather than always basic stuffÙ« which is something that I think YouTube channels tend to do better than blogs. But on the flipside this makes most programming channels less interesting to meÙ« since I am versed in the subject.</p>

<h1 id="s-tier-masterpieces">S Tier: Masterpieces</h1>

<p>The channels in this tier are some of my favorite things on the internet. They all only release videos every few weeks or months but thatâ€™s because theyâ€™re all a single person putting monumental effort into each one. When a video comes out on one of these channels its the highlight of my day. For a video to be this tier it needs to be fascinatingÙ« well-producedÙ« demonstrate incredible skill I can be in awe ofÙ« and be something Iâ€™d pay at least $5/video (and often more) if they started paywalling it now. I subscribe to all of these channels on PatreonÙ« except for Kiwami Japan because they donâ€™t have one.</p>

<p>Despite having hundreds of thousands to millions of viewersÙ« none of these channels would ever have been green-lit as a TV show as-isÙ« because theyâ€™re too weird or niche or technical. They also can only really work as well as they do in the video formatÙ« and got their start on YouTube. Iâ€™m happy that the modern internet allows channels like these to not only exist but often make a living.</p>

<h2 id="clickspring"><a href="https://www.youtube.com/channel/UCworsKCR-Sx6R6-BnIjS2MA">Clickspring</a></h2>

<p><a href="https://www.youtube.com/watch?v=8OViP9AR2HE"><img src="/assets/postassets/youtube/clickspring.jpg" alt="Clickspring thumbnail" /></a></p>

<p>Clickspring is a channel about clockmakingÙ« and watching it is wireheading on pure craftsmanship. Iâ€™ve never done any machining and donâ€™t plan on ever making a clockÙ« but his videos along with everything he makes in them are gorgeous examples of making everything with care and a commitment to excellence. This shows through in everything he doesÙ« from <a href="https://www.youtube.com/watch?v=5sAw4Q1PM8Y">making custom screws with stunning blue oxide finish and hand-rounded interior ends that arenâ€™t even visible when assembled</a> to <a href="https://www.youtube.com/watch?v=Jk_rCm1rAeg">doing original research and building some authentic ancient tools</a> for his <a href="https://www.youtube.com/watch?v=ML4tw_UzqZE">reconstruction of the Antikythera mechanism</a>. He puts the same care into his videos as the work itself: the camera shots and lighting are beautifulÙ« the machining operations are seamlessly sped up at the right times to fit in the video but show the key momentsÙ« and he often includes nice composited overlays of the CAD model on top of the raw stock so you can understand what heâ€™s doingÙ« and the narrationÙ« music and sounds of the machining are excellently done to give the videos a relaxing feel. Every Clickspring video is just a delightful experience to watch.</p>

<p>He also does videos without narration that just beatifully show all the machining and other work that goes into making somethingÙ« <a href="https://www.youtube.com/watch?v=3PwAQZNLy0I">this video being the most impressive example</a>. He has a second channel called <a href="https://www.youtube.com/channel/UC9UjDtkpr2I-5G51vMJZvnA">Clickspring Clips</a> where he posts 2-4 minute non-narrated videos showing the making of one interesting part of his larger projects. <a href="https://www.patreon.com/clickspring/posts">His Patreon</a> also has many exclusive videos once you watch all the public ones.</p>

<h2 id="applied-science"><a href="https://www.youtube.com/channel/UCivA7_KLKWo43tFcCkFvydw">Applied Science</a></h2>

<p><a href="https://www.youtube.com/watch?v=JV4Fk3VNZqs"><img src="/assets/postassets/youtube/appliedscience.jpg" alt="Magnets and flame video" /></a></p>

<p>Ben Krasnowâ€™s channel Applied Science has been the flagship channel of engineering and science YouTube for many years. In every video he explains some new and interesting piece of science and engineering heâ€™s replicated in his shop. Heâ€™s made <a href="https://www.youtube.com/watch?v=X24np30GS2o">aerogel</a>Ù« <a href="https://www.youtube.com/watch?v=Lg__B6Ca3jc">a water jet cutter</a>Ù« <a href="https://www.youtube.com/watch?v=9OEz_e9C4KM">a plasma sputtering chamber</a>Ù« an <a href="https://www.youtube.com/watch?v=rpHYBz7ToII&amp;t=5s">EDM drill</a>Ù« <a href="https://www.youtube.com/watch?v=K_N_h_mKf-4">air bearings</a>Ù« <a href="https://www.youtube.com/watch?v=Z2o_Sp2-aBo">an electroluminescent display</a>Ù« an <a href="https://www.youtube.com/watch?v=_zoeeR3geTA">LCD</a>Ù« and the source of his earliest publicity: <a href="https://www.youtube.com/watch?v=VdjYVF4a6iU">a scanning electron microscope</a>. Heâ€™s a truly prolific and incredible engineer who works with all kinds of electronicsÙ« machiningÙ« chemistryÙ« physics and software. Every video leaves me in awe of him. Often heâ€™ll be the first non-professional to try recreating something based on a procedure from papers and have to do dozens of failed experiments before <a href="https://www.youtube.com/watch?v=Xr1AiExSAnU">making a video</a> <a href="https://www.youtube.com/watch?v=mUcUy7SqdS0">documenting the process and all the extra considerations</a>. His videos and skill are incredible and Iâ€™ve learned a lot about the process of scientific lab work from watching them.</p>

<h2 id="captain-disillusion"><a href="https://www.youtube.com/channel/UCEOXxzW2vU0P-0THehuIIeg">Captain Disillusion</a></h2>

<p><a href="https://www.youtube.com/watch?v=LuM1IXl66B8"><img src="/assets/postassets/youtube/captaind.jpg" alt="Gyro Drop" /></a></p>

<p>Captain Disillusion has been on YouTube for 12 years nowÙ« originally in obscurity but gradually growing to millions of viewers. He goes over trick and hoax viral videos and explains the visual effects used to make them. The thing thatâ€™s incredible is the production value: CostumesÙ« makeupÙ« well-written scriptsÙ« and a ridiculous density of impressive visual effects. Captain Disillusion is what happens when an incredibly talented and driven visual effects artist puts an entire month of full time work into every single 5 minute video. Heâ€™s done streams and time-lapses before of him spending dozens of hours on a 3 second visual effect for a throwaway gag.</p>

<p>A <a href="https://www.youtube.com/watch?v=eKFrZNXB29M">typical video</a> consists of a well-written and edited intro of him introducing a faked videoÙ« doing a detailed breakdown of all the components of the effect but quickly thanks to amazing visual aid footageÙ« then him just one-upping the original video by doing the effect so much better than anyone else has ever done itÙ« without the tells he went over. Hereâ€™s <a href="https://www.youtube.com/watch?v=9vncG0IP9qU">some</a> <a href="https://www.youtube.com/watch?v=rsXQInxxzBU">other</a>Ù« <a href="https://www.youtube.com/watch?v=Hy6vddbQa8Q">good</a> <a href="https://www.youtube.com/watch?v=LuM1IXl66B8">ones</a> but really every single one is excellent.</p>

<h2 id="kiwami-japan"><a href="https://www.youtube.com/channel/UCg3qsVzHeUt5_cPpcRtoaJQ">Kiwami Japan</a></h2>

<p><a href="https://www.youtube.com/watch?v=AMYKQc-MVIM"><img src="/assets/postassets/youtube/kiwami.jpg" alt="Sharpest Bread Kitchen Knife" /></a></p>

<p>This is a weird and wonderful channel that to me really exemplifies whatâ€™s great about YouTube. Most videos are of the form â€œsharpest X kitchen knife in the worldâ€ with a thumbnail of a hand holding a weird knife in the same pose. Some examples of X are <a href="https://www.youtube.com/watch?v=WZJ7nSdIbwk">â€œFungiâ€</a>Ù« <a href="https://www.youtube.com/watch?v=RUlHhrL_Zj8">â€œPaperâ€</a>Ù« <a href="https://www.youtube.com/watch?v=t557dPspLxo">â€œmilkâ€</a>Ù« <a href="https://www.youtube.com/watch?v=MeNR0guNn70">â€œPastaâ€</a>Ù« <a href="https://www.youtube.com/watch?v=539OnO-YImk">â€œUnderwearâ€</a>Ù« and <a href="https://www.youtube.com/watch?v=zUCEMjhsvaU">â€œsmokeâ€</a>. I originally ignored suggested videos from this channel because I assumed they were some weird click-bait that didnâ€™t really make a knife from those materialsÙ« and that was tragic because he really does and itâ€™s amazing.</p>

<p>Every video has no talking or words except for occasional subtitlesÙ« and follows the process starting from the raw materialÙ« demonstrating all the processing steps required to make a hard substance out of itÙ« casting a knife blankÙ« sharpening itÙ« and testing it. At some point early in the channelâ€™s history someone must have commented that the videos were like ASMR videos because after that he got a high quality microphone and puts a lot of emphasis on the sounds.</p>

<p>The coolest part is heâ€™s clearly really good at materials science and every video has amazing steps all done in his apartment. Lets take the <a href="https://www.youtube.com/watch?v=pFG-nXUw6Ts">â€œsharpest Seawater kitchen knife in the worldâ€</a> video as an example: It starts with a shot of him getting huge jugs of seawater from the ocean and collecting shells on the beach. At home he boils the seawater into salt and a solution he labels â€œmagnesium chlorideâ€. Then he puts a seashell on top of a charcoal briquette and puts it in an insulating firebrick box in his home microwave-oven-thing and cuts to it coming out totally calcified (apparently you can do that without a furnace??). He grinds it up with the subtitle â€œquicklimeâ€Ù« puts it in water and uses a thermal camera to show the exothermic reaction to get slaked lime. Cut to him combining a concentrated sea brine with the lime water to get â€œmagnesium hydroxide + saltâ€. He adds water to dissolve the salt and filters out the magnesium hydroxideÙ« combines it with the magnesium chloride from earlierÙ« dries itÙ« uses his handy durometer to show it fails a hardness test. He pops the magnesium hydroxide in his charcoal microwave furnace to get â€œmagnesium oxideâ€ and shows that this time when combined and dried it yields a very hard rock-like substance. Cut to him pouring a bunch of it in a rectangular plastic boxÙ« drying it and sawing out a knife shape. Then his famous sharpening sequence with increasingly fine knife stonesÙ« followed by the ever-present cucumber chopping test (complete with weird cucumber reveal out of godzilla-themed rubber gloves). He finishes by showing that the â€œmagnesium cementâ€ (<a href="https://en.wikipedia.org/wiki/Sorel_cement">Wiki link</a>) doesnâ€™t immediately dissolve in watera and that it can also be combined with dirt to make bricks.</p>

<p>I canâ€™t see anything remotely like this every being green-lit as a TV seriesÙ« but every video is brilliant and relaxingÙ« they all get millions of views with zero advertising spendÙ« because everyone likes them and recommends them to friends and algorithmic recommendations respond to that in a way that human TV producers wouldnâ€™t have the guts to. People complain about the â€œYouTube algorithmâ€Ù« but at this kind of thing it truly shines.</p>

<h2 id="stuff-made-here"><a href="https://www.youtube.com/channel/UCj1VqrHhDte54oLgPG4xpuQ">Stuff Made Here</a></h2>

<p><a href="https://www.youtube.com/watch?v=7zBrbdU_y0s"><img src="/assets/postassets/youtube/stuffmadehere.jpg" alt="Haircut robot" /></a></p>

<p>Stuff Made Here is the newest channel to enter S tier. When YouTube first recommended one of his videos to me 4 months ago the channel had just started with a few videos and I thought â€œhuh how is this brand new channel getting hundreds of thousands of viewsâ€Ù« then I watched the video and thought â€œokay wowÙ« apparently if you make really excellent stuff from the start it can become popular on YouTube super fastâ€. He just makes really interesting and impressive videos where he uses his skill in many different disciplines of engineering to make cool stuff and then gives interesting descriptions of all the considerationsÙ« testingÙ« engineeringÙ« fabrication and failures that went into making it.</p>

<p>For <a href="https://www.youtube.com/watch?v=FycDx69px8U&amp;t=1s">his most popular video</a> he makes a basketball backboard that always directs the ball into the hoop. He designs and builds a custom mechanism to move the backboard to any distance and angle using rods that minimize the weight on the board so it can move quicklyÙ« describing the kinematic principles and how he constructed it using CNC plasma cut and spot welded sheet metal with 3D printed joints. Then he describes the clever custom algorithm for filtering out the basketball from other moving objects in the depth camera by fitting a ballistic curve to all possible object trajectoriesÙ« as well as the software for extrapolating and calculating the required backboard position. The way he did everything is quite impressive andÙ« like all his projectsÙ« he did it in only a few weeks while also having a day job.</p>

<p>What sets him apart from other YouTube makers is not only the skill in so many different areas that his projects displayÙ« but also the detailed explanations of the entire engineering process including the considerationsÙ« mathÙ« algorithms and failures rather than just the fabrication. If this sounds good to youÙ« you should watch every single one of his videos including the ones that might not look that interesting. Thereâ€™s not that many yetÙ« but there might be soon since he somehow has also been managing to post more frequently than anyone else in my S tier (have I mentioned he also has a day job!?).</p>

<h1 id="a-tier-highly-recommended">A Tier: Highly recommended</h1>

<p>These channels are still quite excellentÙ« but fall short on one or more aspects that would make me feel like putting them in S tier. I still highly recommend you check them out if they sound interesting thoughÙ« theyâ€™re really great and Iâ€™m still very excited when I see one of them post a new video!</p>

<dl>
  <dt><a href="https://www.youtube.com/channel/UCVSHXNNBitaPd5lYz48--yg">Tech Ingredients</a></dt>
  <dd>Long and detailed technical videos of interesting projects demonstrating cool science and engineering concepts. They build really high quality demonstration pieces for each video and lots of the concepts they look into are little known ones like <a href="https://www.youtube.com/watch?v=LS3GQk9ETRU">magnetohydrodynamics</a>Ù« how <a href="https://www.youtube.com/watch?v=jxOzpPJbnTI">helium is an incredibly good sound suppressor</a> and <a href="https://www.youtube.com/watch?v=zcpDGKH9_SE">plasma physics</a>. The main presenter is super knowledgeable and every video has some really interesting things. Itâ€™s a bit slow paced but I fix that by always watching on 2x speed. They also just posted a <a href="https://www.youtube.com/watch?v=bRr8lrUc-GI">Best Of clips compilation video</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCMOqf8ab-42UUQIdVoKwjlQ">Practical Engineering</a></dt>
  <dd>Explains interesting things from civil engineering often with cool models and demonstrations. I found <a href="https://www.youtube.com/watch?v=zFdyqTGx32A">this one on hydraulic ram pumps</a> really cool.</dd>
  <dt><a href="https://www.youtube.com/channel/UCYA1VjSKXgNVh03wjw_HSRA">Dan Gelbart</a></dt>
  <dd>Dan is an incredible engineer who made a fortune selling companies and now has an amazing machine shopÙ« with lots of tools heâ€™s built or modified himself. He doesnâ€™t post videos very often but the main draw of his channel is the 7 year old 19-part series on tools and techniques for building prototypes. Itâ€™s a masterpiece of incredible knowledgeÙ« impressive designs and great tips. I recently rewatched the whole series.</dd>
  <dt><a href="https://www.youtube.com/channel/UCFtc3XdXgLFwhlDajMGK69w">NightHawkInLight</a></dt>
  <dd>Videos of small interesting projects <a href="https://www.youtube.com/watch?v=tcV1EYSUQME">beautifully</a> filmed and explained. I particularly liked this one about <a href="https://www.youtube.com/watch?v=ThBkzEfjVl0">making a carbon filament light bulb</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCV5vCi3jPJdURZwAOO_FNfQ">The Thought Emporium</a></dt>
  <dd>Lots of different types of DIY science projects including DIY genetic engineering. In his craziest video he <a href="https://www.youtube.com/watch?v=J3FcbFqSoQY">engineers a benign virus to put lactase genes</a> in his intestines to cure his lactose intolerance for months (most of the video is explaining why what he did was reasonably safe). More recently heâ€™s been uploading long live streams but look back a bit for the shorter science project videos.</dd>
  <dt><a href="https://www.youtube.com/channel/UCAL3JXZSzSm8AlZyD3nQdBA">Primitive Technology</a></dt>
  <dd>Guy goes out into the woods in Australia and makes potteryÙ« metalÙ« shelterÙ« tools and materials starting with no tools at all. This video about <a href="https://www.youtube.com/watch?v=RnvtXikwrIU">making a kiln to smelt iron</a> is really good.</dd>
  <dt><a href="https://www.youtube.com/channel/UCFhXFikryT4aFcLkLw2LBLA">NileRed</a></dt>
  <dd>Beautiful and interesting videos about chemistry accessible to someone who knows very little about chemistry. <a href="https://www.youtube.com/watch?v=RS7gyZJg5nc">This recent video about making superconductors</a> is particularly good.</dd>
  <dt><a href="https://www.youtube.com/channel/UC5NO8MgTQKHAWXp6z8Xl7yQ">This Old Tony</a></dt>
  <dd>Really well-produced entertaining and funny machine shop and engine videos that usually use some small machining project to explain a concept or technique.</dd>
  <dt><a href="https://www.youtube.com/watch?v=975r9a7FMqc">Steve Mould</a></dt>
  <dd>Interesting science concept explanation videos with demonstrations. I was waffling between A and B tier but <a href="https://www.youtube.com/watch?v=975r9a7FMqc">this phenomenally cool recent video on optical rotation</a> blew me away and secured his spot in A tier.</dd>
</dl>

<h1 id="b-tier-very-good">B Tier: Very Good</h1>

<p>At this point weâ€™re still in the realm of high quality channels where Iâ€™ll immediately watch any new video they put out. Some of these channels have occasional top quality videos that would put them in A tier if they posted more regularly or had more consistent quality.</p>

<dl>
  <dt><a href="https://www.youtube.com/channel/UCjgpFI5dU-D1-kh9H1muoxQ">The Hacksmith</a></dt>
  <dd>Skilled engineers with a substantial budget and machine shop try to make real life versions of gadgets from fiction. Their main audience is kids and non-technical people and it showsÙ« but many of their videos have pretty cool engineeringÙ« and their build montages are neat.</dd>
  <dt><a href="https://www.youtube.com/channel/UCy0tKL1T7wFoYcxCe0xjN6Q">Technology Connections</a></dt>
  <dd>Guy explains interesting bits of technological history and science behind everyday gadgets. Like <a href="https://www.youtube.com/watch?v=RSTNhvDGbYI">this video on how rice cookers use some neat physics tricks</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCHsRtomD4twRf5WVHHk-cMw">Tier Zoo</a></dt>
  <dd>A biologist explains interesting animal facts as funny parodies of video game commentary and tier lists (I am partial to the tier list format as evidenced by this very tier list). <a href="https://www.youtube.com/watch?v=9a-OAQE_hMQ">This one on turtles</a> is pretty good.</dd>
  <dt><a href="https://www.youtube.com/channel/UC7E8-0Ou69hwScPW1_fQApA">Sam Zeloof</a></dt>
  <dd>One of the only people to successfully <a href="https://youtu.be/XrEC2LGGXn0?t=25">produce a silicon integrated circuit at home</a>Ù« and when he was in high school. This year he started putting out high-effort videos on <a href="https://www.youtube.com/watch?v=Nxz_ENnmgtI">cool equipment</a> used in the process.</dd>
  <dt><a href="https://www.youtube.com/channel/UC67gfx2Fg7K2NSHqoENVgwA">Tom Stanton</a></dt>
  <dd>Implements really creative and cool engineering ideas mostly using a lot of 3D printing. Some of his coolest videos are building drones using weird things like <a href="https://www.youtube.com/watch?v=XpA6qpNlNOE">gas thrusters</a>Ù« <a href="https://www.youtube.com/watch?v=4kfBEaTncjI">reaction wheels</a>Ù« <a href="https://www.youtube.com/watch?v=Irp_vnmUWZ4">the Coanda effect</a> and <a href="https://www.youtube.com/watch?v=d80oXSCcHTk">a single rotor with no swashplate</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UC96JVq-z0-0iHAkIkKp1_6w">Demoscene High-Quality Videos</a></dt>
  <dd>64k introsÙ« where people write programs that produce beautiful visuals and audio using an executable less than 64 kilobytesÙ« are perhaps my favorite art form accross all art forms. They often use very non-standard rendering techniques that lead to unique visualsÙ« have good electronic background tracksÙ« and the whole time I marvel at the technical wizardry of the tiny size. Not all the best videos are on this channel and not all the ones on this channel are good but it has many good ones. My favorite intro group is LogicomaÙ« even before I found out they use Rust. My favorites of their stuff: <a href="https://www.youtube.com/watch?v=GjuridCR2Fo">Engage</a>Ù« <a href="https://www.youtube.com/watch?v=QhqT0DhV9yE">Dope On Wax</a>Ù« <a href="https://www.youtube.com/watch?v=gVHktHeYsfs">Trash Panda</a> and <a href="https://www.youtube.com/watch?v=rWwNgVwQG1A">Elysian</a>.
Favorites by other groups include
<a href="https://www.youtube.com/watch?v=XF4SEVbxUdE">on</a>Ù«
<a href="https://www.youtube.com/watch?v=ncdA3t_vzF8&amp;t=100s">Zetsubo (4k!)</a>Ù«
<a href="https://www.youtube.com/watch?v=UnjIMd3kVf4">delight</a>Ù«
<a href="https://www.youtube.com/watch?v=mjzeP7hYyNo">Offscreen Colonies</a> and <a href="https://www.youtube.com/watch?v=ie4u2i_5OdE">the timeless</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCG7yIWtVwcENg_ZS-nahg5g">CNLohr</a></dt>
  <dd>Really interesting and cool electronics projects. Examples include <a href="https://www.youtube.com/watch?v=a2DjjG9wVY0">reverse engineering the HTC Vive and making a custom Linux C SDK for it</a>Ù« <a href="https://www.youtube.com/watch?v=R1zx0xV0pWw">running a custom Minecraft server on a microcontroller</a> and <a href="https://www.youtube.com/watch?v=MOP8I-7rA_8">pretty LEDs</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCdmAhiG8HQDlz8uyekw4ENw">Inigo Quilez</a></dt>
  <dd>Inigo is famous for his <a href="https://www.iquilezles.org/">excellent website</a> with lots of computer graphics tips especially around <a href="https://www.iquilezles.org/www/articles/raymarchingdf/raymarchingdf.htm">signed distance fields</a>. More recently heâ€™s been uploading <a href="https://www.youtube.com/watch?v=PMltMdi1Wzg">high effort explanations</a>Ù« <a href="https://www.youtube.com/watch?v=sl9x19EnKng">live coding</a> and <a href="https://www.youtube.com/watch?v=rQ2bnU4dkso">pretty fractals</a> to his YouTube channel.</dd>
  <dt><a href="https://www.youtube.com/channel/UC3azLjQuz9s5qk76KEXaTvA">Tom7/suckerpinch</a></dt>
  <dd>Tom7 is known for his incredibly good high-effort <a href="http://radar.spacebar.org/f/a/weblog/category/1/sigbovik">SIGBOVIK technical joke conference papers</a>. What I only learned later is often he makes <a href="https://www.youtube.com/watch?v=ar9WRwCiSr0">great funny YouTube videos</a> explaining his crazy hacks like.</dd>
  <dt><a href="https://www.youtube.com/channel/UCR1IuLEqb6UEA_zQ81kwXfg">Real Engineering</a></dt>
  <dd>Well-produced and interesting explanation videos on various engineering topics. From <a href="https://www.youtube.com/watch?v=wk6Qr6OO5Xo">the engineering of fighter planes</a> to <a href="https://www.youtube.com/watch?v=i6DRRHXt-PA">flood control systems in The Netherlands</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCBa659QWEk1AI4Tg--mrJ2A">Tom Scott</a></dt>
  <dd>Popular channel mostly focusing on talking about random interesting places with neat stories around the world.</dd>
  <dt><a href="https://www.youtube.com/channel/UCekQr9znsk2vWxBo3YiLq2w">You Suck At Cooking</a></dt>
  <dd>Funny comedy cooking videos that are actual recipes. Videos vary on how much they focus on being funny vs teaching good recipes. <a href="https://www.youtube.com/watch?v=GYl7h8iDjsY">This one</a> and <a href="https://www.youtube.com/watch?v=j3DPH3KOiXk">this one</a> are pretty good.</dd>
</dl>

<h1 id="c-tier-someone-being-really-good-at-something">C Tier: Someone being really good at something</h1>

<p>Iâ€™ve dedicated C tier to channels where I watch them purely to marvel at someone being really good at something. I like watching people do impressive things or perform at the highest levelÙ« itâ€™s inspiring and also just cool to learn about how they do it. They donâ€™t necessarily have to be impressive in an absolute senseÙ« although many areÙ« just impressive relative to my skill level (often zero in their area). The reason these arenâ€™t in higher tiers is either that Iâ€™m not as interested in the subject but they captured me anywaysÙ« or their videos are not as high in density and quality.</p>

<dl>
  <dt><a href="https://www.youtube.com/channel/UC5miyvhPsWWyfTulnJ43koQ">Pannen</a></dt>
  <dd>Details various glitches used for an automated Super Mario 64 speedrun where he tries to minimize use of the A (jump) button. Really interesting just seeing how insane the tricks can be. Best and most famous video is <a href="https://www.youtube.com/watch?v=kpk2tdsPh0A">this commentated one</a> from his other channel about paralell universes.</dd>
  <dt><a href="https://www.youtube.com/channel/UCwjZLzqHYImv4oCJQcZ8Hig">Daniel Schiffer</a></dt>
  <dd>Videographer who goes into how he shoots and edits commercialsÙ« and heâ€™s really good at it so his videos are great.</dd>
  <dt><a href="https://www.youtube.com/user/J3Cub2009">Tucker Gott</a></dt>
  <dd>Paramotor pilot. I have no plans on ever paramotoring but itâ€™s cool to watch and his â€œReacting To Crash Videosâ€ series is really interestingÙ« seeing him break down what kind of safety considerations come into play and how things can go wrong.</dd>
  <dt><a href="https://www.youtube.com/channel/UCCJJNQIhS15ypcHqDfEPNXg">Akiyuki Brick Channel</a></dt>
  <dd>Incredibly cool and complex Lego mechanical contraptions. <a href="https://www.youtube.com/watch?v=sUtS52lqL5w">This is a great combination of many of his designs</a> and <a href="https://www.youtube.com/channel/UCCJJNQIhS15ypcHqDfEPNXg">this recent video is aesthetically fun</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCW5OrUZ4SeUYkUg1XqcjFYA">GeoWizard</a></dt>
  <dd>Guy who is really good at GeoGuessrÙ« that is super knowledgeable about geography and all sorts of tricks to figure out where you are when plopped randomly on Street View. <a href="https://www.youtube.com/channel/UC7ELHo7almKFfxe8ultFdTA">This guy</a> is allegedly better but IMO less entertaining.</dd>
  <dt><a href="https://www.youtube.com/channel/UCtQvv0QrY7_W49gtIPSDWdg">Media Molecule</a></dt>
  <dd>Lots of videos about <a href="https://www.playstation.com/en-us/games/dreams-ps4/">Dreams</a>Ù« the most impressive feat of software engineering I can think ofÙ« but thatâ€™s another potential future article. Includes compilations of cool creationsÙ« tutorials from talented artistsÙ« and explanations by developers of how it works.</dd>
  <dt><a href="https://www.youtube.com/channel/UCCuoqzrsHlwv1YyPKLuMDUQ">Jonathan Blow</a></dt>
  <dd>Recorded live streams of programming and demoing his game and new programming language/compiler. Clearly very skilledÙ« also overly brash at timesÙ« but his ideas and perspective is interesting and his videos are the only ones I watch of live programming.</dd>
  <dt><a href="https://www.youtube.com/user/sethbling">Sethbling</a></dt>
  <dd>Does Super Mario World speedruns involving code injection via carefully placed shells and a glitch to warp directly to the creditsÙ« as well as various other technical video game trickery.</dd>
  <dt><a href="https://www.youtube.com/channel/UCCRdB9rqzP2m7bPYb5drH_Q">Harstem</a></dt>
  <dd>Professional StarCraft 2 player. Critiques peopleâ€™s submitted replaysÙ« plays serious games while explaining his thoughtsÙ« tries playing with terrible strategies and winning purely on having better mechanics. Interesting to see what kind of thoughtÙ« considerations and practice it takes to get to the highest level in a competitive strategy game.</dd>
</dl>

<h1 id="d-tier-good-quality-stuff-i-like-watching">D Tier: Good quality stuff I like watching</h1>

<p>These are just a whole bunch of channels Iâ€™m subscribe toÙ« where Iâ€™ve watched a bunch of their videos and liked them. I may not watch every video from all of these channelsÙ« but the ones Iâ€™ve decided to watch have been good and Iâ€™ll often watch new ones when they pop up. Some of these channels are really well made and might be in other peopleâ€™s S tierÙ« Iâ€™m just not as interested in them. If youâ€™ve liked my other recommendations I encourage you to check these out! Iâ€™ve split them up based on the broad theme of what type of videos they have:</p>

<h2 id="explaining">Explaining</h2>

<dl>
  <dt><a href="https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg">Two Minute Papers</a></dt>
  <dd>Short explanations of interesting machine learning and computer graphics papers.</dd>
  <dt><a href="https://www.youtube.com/channel/UCEklP9iLcpExB8vp_fWQseg">Makinâ€™ Stuff Look Good</a></dt>
  <dd>Tutorials on how various cool shader effects work.</dd>
  <dt><a href="https://www.youtube.com/channel/UC6vImVkvofpMUOlYt6LiRXA">Keystone Science</a></dt>
  <dd>Some cool science videos.</dd>
  <dt><a href="https://www.youtube.com/channel/UCu6mSoMNzHQiBIOCkHUa2Aw">Codyâ€™sLab</a></dt>
  <dd>Miscellaneous geologyÙ« farming and engineering.</dd>
  <dt><a href="https://www.youtube.com/user/AndrewPPrice">Blender Guru</a></dt>
  <dd>Really good Blender 3D modeling tutorials. I learned a lot about what goes into photorealism that I applied when choosing features for my <a href="https://thume.ca/ray-tracer-site/">path tracer</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCNk3CeLpCA0qIZsuzGl09cw">Bruce Yeany</a></dt>
  <dd>Science teacher who makes cool demonstrations.</dd>
  <dt><a href="https://www.youtube.com/c/smartereveryday/featured">Smarter Every Day</a></dt>
  <dd>Very popular science and engineering videos.</dd>
  <dt><a href="https://www.youtube.com/user/arduinoversusevil">AvE</a></dt>
  <dd>Crass guy with an idiosyncratic style of speaking has a cool series called â€œBored Of Lame Tool Review?â€ where he takes tools apartÙ« explains how they workÙ« critiques their design and guesses how theyâ€™ll fail.</dd>
</dl>

<h2 id="making">Making</h2>

<dl>
  <dt><a href="https://www.youtube.com/channel/UCp_5PO66faM4dBFbFFBdPSQ">bitluniâ€™s lab</a></dt>
  <dd>PCBs and neat huge LED walls.</dd>
  <dt><a href="https://www.youtube.com/channel/UCO8DQrSp5yEP937qNqTooOw">Strange Parts</a></dt>
  <dd>Tours of cool Chinese factories.</dd>
  <dt><a href="https://www.youtube.com/channel/UCUbDcUPed50Y_7KmfCXKohA">James Bruton</a></dt>
  <dd>3D printed cool robots.</dd>
  <dt><a href="https://www.youtube.com/channel/UClsFdM0HzTdF1JYoraQ0aUw">Brick Experiment Channel</a></dt>
  <dd>Interesting engineering using LegoÙ« like making submarines.</dd>
  <dt><a href="https://www.youtube.com/channel/UC3KEoMzNz8eYnwBC34RaKCQ">Simone Giertz</a></dt>
  <dd>Originally made shitty robotsÙ« now makes miscellaneous cool artsy objects.</dd>
  <dt><a href="https://www.youtube.com/channel/UCILl8ozWuxnFYXIe2svjHhg">BPS.space</a></dt>
  <dd>Very fancy model rockets with cool control systemsÙ« like Falcon propulsive landing.</dd>
  <dt><a href="https://www.youtube.com/channel/UCVS89U86PwqzNkK2qYNbk5A">Allen Pan</a></dt>
  <dd>Cool engineering projects kind of in the style of The Hacksmith.</dd>
  <dt><a href="https://www.youtube.com/channel/UCY1kMZp36IQSyNx_9h4mpCg">Mark Rober</a></dt>
  <dd>Interesting engineering and science projects.</dd>
  <dt><a href="https://www.youtube.com/channel/UC7yF9tV4xWEMZkel7q8La_w">Peter Sripol</a></dt>
  <dd>Makes his own small and model airplanes.</dd>
  <dt><a href="https://www.youtube.com/channel/UCtHaxi4GTYDpJgMSGy7AeSw">Michael Reeves</a></dt>
  <dd>Comedy robot videos.</dd>
  <dt><a href="https://www.youtube.com/channel/UC6x7GwJxuoABSosgVXDYtTw">I Like To Make Stuff</a></dt>
  <dd>Miscellaneous crafts.</dd>
  <dt><a href="https://www.youtube.com/channel/UCturmG-MSMEpG3zAo4H6Spw">Jairus of all</a></dt>
  <dd>Some cool projects.</dd>
  <dt><a href="https://www.youtube.com/channel/UC06HVrkOL33D5lLnCPjr6NQ/featured">Breaking Taps</a></dt>
  <dd>CNC millingÙ« making molds. Well producedÙ« good at explaining the challenges and design process.</dd>
  <dt><a href="https://www.youtube.com/channel/UCfIqCzQJXvYj9ssCoHq327g">How To Make Everything</a></dt>
  <dd>Makes things like lensesÙ« chocolateÙ« clothing and food from scratch harvesting and processing all his own materials.</dd>
  <dt><a href="https://www.youtube.com/channel/UCckETVOT59aYw80B36aP9vw">Matthias Wandel</a></dt>
  <dd>Impressive woodworking and wooden contraptions.</dd>
  <dt><a href="https://www.youtube.com/channel/UCnr29dxZB1vsbiHLBL7kfAQ">The Taste Emporium</a></dt>
  <dd>Cooking channel by the same guy as <a href="https://www.youtube.com/c/thethoughtemporium">The Thought Emporium</a> about making very fancy recipes.</dd>
  <dt><a href="https://www.youtube.com/channel/UCbNvfx3rYYxEopnRGxfu53Q">Josephâ€™s Machines</a></dt>
  <dd>Really amazing Rube Goldberg machines.</dd>
  <dt><a href="https://www.youtube.com/channel/UCZnQYVCCnNnwqiJRIYQuYdA">Makercise</a></dt>
  <dd>Making a Gingery lathe and shaper from scratch by aluminum casting.</dd>
  <dt><a href="https://www.youtube.com/channel/UCUuMYw2l2UeWyTGYixYfRCA">EvanAndKatelyn</a></dt>
  <dd>Miscellaneous home crafts and art.</dd>
  <dt><a href="https://www.youtube.com/c/Ididathing">I did a thing</a></dt>
  <dd>Comedy DIY videos like <a href="https://www.youtube.com/watch?v=OSfUUqNkrOQ">â€œCan I make a spoon using only a spoonâ€</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCUQo7nzH1sXVpzL92VesANw">DIY Perks</a></dt>
  <dd>Well-made DIY projects mostly building custom lighting and weird computer equipment.</dd>
  <dt><a href="https://www.youtube.com/c/ferrisstreamsstuff/videos">Ferris</a></dt>
  <dd>Really good programmerÙ« part of my favorite demo group LogicomaÙ« interesting streams.</dd>
  <dt><a href="https://www.youtube.com/c/TheBrickWallTeam/featured">The Brick Wall</a></dt>
  <dd>Sophisticated and impressive working Lego farm equipment and factories.</dd>
  <dt><a href="https://www.youtube.com/user/colinfurze">Colin Furze</a></dt>
  <dd>Wild engineering projects often involving making dangerous but impressive vehicles.</dd>
</dl>

<h2 id="other">Other</h2>

<dl>
  <dt><a href="https://www.youtube.com/channel/UCWf3wmxbUr5TGmCjHaXV4bQ">JL2579</a></dt>
  <dd>Technical Minecraft player. I donâ€™t play Minecraft anymore but still love seeing what kind of weird behaviors they find and exploit to build useful Minecraft contraptions.</dd>
  <dt><a href="https://www.youtube.com/channel/UCHSI8erNrN6hs3sUK6oONLA">ilmango</a></dt>
  <dd>Another impressive technical Minecraft player.</dd>
  <dt><a href="https://www.youtube.com/channel/UC-WICcSW1k3HsScuXxDrp0w">Curry On!</a></dt>
  <dd>A good programming conference that tends to have talks I like watching.</dd>
  <dt><a href="https://www.youtube.com/channel/UC_QIfHvN9auy2CoOdSfMWDw">Strange Loop</a></dt>
  <dd>Another good programming conference with lots of talks Iâ€™ve liked.</dd>
  <dt><a href="https://www.youtube.com/channel/UCDbxvz-8MrderjIOyQi14Uw">Roger Kilmanjaro</a></dt>
  <dd>Really beautiful minimalist CG looping animations that are very much my aesthetic.</dd>
</dl>

'),('http://thume.ca/2020/05/20/making-a-latency-tester/', 'Measuring keyboard-to-photon latency with a light sensor', '1589932800000',  13, '
<p>For a long time when Iâ€™ve wanted to test the latency of computers and UIs Iâ€™ve used the <a href="https://isitsnappy.com/">Is It Snappy</a> app with my iPhoneâ€™s high speed camera to count frames between when I press a key and when the screen changes. However the problem with that is it takes a while to find the exact frames you wantÙ« which is annoying when doing a bunch of testing. It also makes it difficult to find out what the variability of latency is like. I had already made this kind of testing easier <a href="/2017/12/29/fixing-my-keyboards-latency/">by adding a mode to my keyboard firmware which changes the LED color after it sends a USB event</a>Ù« but that only made it a bit faster and more precise. I wanted something better.</p>

<p>So I followed in the footsteps of my friend <a href="https://raphlinus.github.io/">Raph</a> and made a hardware latency tester which sends keyboard events and then uses a light sensor to measure the time it takes for the screen to change! It was quite easy and in this post Iâ€™ll go over some of the latency results Iâ€™ve foundÙ« talk about why good latency testing is trickyÙ« and explain how to build your own latency tester.</p>

<p>Basically my latency tester is a light sensor module from Amazon held by an adjustable holder arm wired to a <a href="https://www.pjrc.com/teensy/teensyLC.html">Teensy LC</a> microcontroller which presses â€œaâ€ and waits until the light level changesÙ« then deletes it and keeps collecting samples as long as a button is held. Then with a short press of that one button it will type out a nice latency histogram that looks like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lat i= 60.3 +/-   9.3Ù« a= 60Ù« d= 59 (n= 65Ù«q= 41) |    239_                      |
</code></pre></div></div>

<p>This line tells me the average latency of insertions (<code class="language-plaintext highlighter-rouge">i=</code>)Ù« deletions (<code class="language-plaintext highlighter-rouge">d=</code>) and both put together (<code class="language-plaintext highlighter-rouge">a=</code>)Ù« the standard deviation of insertion times (<code class="language-plaintext highlighter-rouge">+/-</code>)Ù« measurement count (<code class="language-plaintext highlighter-rouge">n=</code>) and quality (<code class="language-plaintext highlighter-rouge">q=</code>)Ù« and a little ascii histogram where each character is a 10ms bucket and the digits proportionally represent how full the bucket is. The <code class="language-plaintext highlighter-rouge">_</code> represents a bucket with at least one sample but not enough to be at least one ninth of the top bucketÙ« so I can see tail latencies. Hereâ€™s what it looks like (pictured with portrait monitors but all tests were done in landscape):</p>

<p><img src="/assets/postassets/latencytester/final_product.jpeg" alt="The final product" /></p>

<p>I also made it so if you press the button againÙ« it will type out all the raw measurements like <code class="language-plaintext highlighter-rouge">[35Ù« 35Ù« 33Ù« 44]</code> so you can do custom plotting:</p>

<p><img src="/assets/postassets/latencytester/plot.png" alt="Plotly chart" /></p>

<h2 id="monitor-latency">Monitor latency</h2>

<p>Iâ€™ll start out with my favorite set of results:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Sublime TextÙ« macOSÙ« distraction-free full-screen mode on two 4k monitors:
lat i= 35.3 +/-   4.7Ù« a= 36Ù« d= 36 (n= 67Ù«q= 99) |  193       | Dell P2415Q top
lat i= 52.9 +/-   5.0Ù« a= 53Ù« d= 54 (n= 66Ù«q= 45) |   _391     | Dell P2415Q bottom
lat i= 65.1 +/-   5.0Ù« a= 64Ù« d= 63 (n=109Ù«q=111) |    _292    | HP Z27 top
lat i= 79.7 +/-   5.0Ù« a= 80Ù« d= 80 (n= 98Ù«q=114) |       89_  | HP Z27 bottom
</code></pre></div></div>

<p>Thereâ€™s a lot to observe here:</p>

<ul>
  <li>First of allÙ« I like how the single-line fixed-width histogram format lets me put results next to each other in a text file and label them to the right for comparison.</li>
  <li>We can see the expected difference of 16ms between the latency at the top and bottom of each monitor from the time it takes to scan out the rows during a frame at 60hz.</li>
  <li>The standard deviation is just a touch over the <a href="https://www.quora.com/What-is-the-standard-deviation-of-a-uniform-distribution-How-is-this-formula-determined">4.6ms</a> thatâ€™s inherent to the uniformly-distributed variance that comes from being misaligned with a 16ms display refresh period.</li>
  <li><strong>The HP Z27 is around 30ms slower than the Dell P2415Q!</strong> And thatâ€™s measuring from the start of when the change is detectableÙ« Iâ€™m pretty sure the Z27 also takes longer to transition fully. With the Z27 and Sublime almost half my end-to-end latency is unnecessary delay from the monitor!</li>
</ul>

<p>All measurements in the rest of this post are accordingly done on my Dell P2415Q. Both monitors have response time set to â€œfastâ€Ù« the Z27 has even higher response time settings but they only affect transition time and introduce unsightly ghost trails without helping initial latency.</p>

<h2 id="the-perils-of-measurement">The perils of measurement</h2>

<p>Taking good latency measurements is actually quite difficult in more ways than you might think. I tried harder than most people to get realistic measurements and still failed the first few times in ways that I had to fix.</p>

<h3 id="actually-measuring-end-to-end-latency">Actually measuring end to end latency</h3>

<p>First of allÙ« the reason to use a hardware latency tester is that there are many incomplete or potentially deceptive ways to measure end-to-end latency.</p>

<p>Thereâ€™s a really excellent famous blog post called <a href="https://pavelfatin.com/typing-with-pleasure/">Typing With Pleasure</a> that compares latency of different text editors on different operating systems with good analysis and pretty graphs. However it does this by simulating input events and screen scraping using OS APIs. I havenâ€™t done any overlapping measurements with his so canâ€™t point to anything specifically wrongÙ« but thereâ€™s lots of potential issues with this. For example inspecting the screen buffer on the CPU might unduly penalize GPU-rendered apps due to window buffer copies under some ways that capture might work. Simulated input may hit different paths than real input. RegardlessÙ« even if it does give decent relative measurements (and you canâ€™t truly know without validating it against an end-to-end test)Ù« it doesnâ€™t tell you the full latency users experience.</p>

<h3 id="using-1000hz-usb-polling">Using 1000hz USB polling</h3>

<p>One source of latency users experience that my tester doesnâ€™t measure is <a href="https://danluu.com/keyboard-latency/">keyboard latency</a>. Many keyboards can introduce more latency than my entire keyboard-to-photon latency (<a href="/2017/12/29/fixing-my-keyboards-latency/">including mine in the past</a>) due to 8ms USB polling intervalsÙ« low keyboard grid scan ratesÙ« slow firmwareÙ« and more debatably different mechanical design.</p>

<p>You canâ€™t just use any microcontroller that can emulate a keyboard to build a low-variance latency tester because they probably use default 125Hz polling. Luckily my go-to microcontroller the <a href="https://www.pjrc.com/teensy/teensyLC.html">Teensy LC</a> is one of few to default to 1000hz.</p>

<h3 id="ensuring-good-signal-strength">Ensuring good signal strength</h3>

<p>For the first while after I built my latency tester I didnâ€™t have any measurement of signal strength. Eventually I got confused by some measurements in slightly different scenarios with the same app and screen having wildly different results. I did some testing and figured out that sometimes with small fonts or poor sensor placement the change in screen contents would only barely be detectable so Iâ€™d end up measuring until the monitor finished transitioning when usually I measure until when the monitor starts transitioning (which is its own tricky subjective measurement choice).</p>

<p>I knew to suspect transition timeÙ« because before I wrote the firmware I played around with just sampling the light sensor every millisecond and using the Arduino serial plotter to plot measurements as I typed and backspaced a letter just to see what the signal looked like. You can see that some combination of the light sensor and the monitor take nearly 100ms to fully transition. Based on filming with <a href="https://isitsnappy.com/">Is It Snappy</a> it seems like it only takes my Z27 about 20ms for the screen to perceptually finish transitioning.</p>

<p><img src="/assets/postassets/latencytester/wave.png" alt="Trace" /></p>

<p>To avoid this I added a peak to peak signal strength measurement after the full transition to my output so I could ensure I was getting adequate resolution for my threshold of 5 steps to be near the beginning of the transition. These are the numbers you see after <code class="language-plaintext highlighter-rouge">q=</code>. I learned that itâ€™s important to keep font sizes large and screen brightness settings high.</p>

<h3 id="significant-variation-from-small-differences">Significant variation from small differences</h3>

<p>Itâ€™s possible for seemingly small differences in whatâ€™s being measured to make noticeable differences in latency. For example I wanted to see if there was a significant difference between the latency of Sublime and VSCode on a small file with plain text highlighting compared to a large file with a complex highlighting grammar and an autocomplete popup. Sure enough there wasÙ« but after noticing some variability I did a bunch more testing and discovered that the latencies were noticeably different between typing â€˜aâ€™ on a blank line and typing â€˜aâ€™ after an existing â€˜aâ€™ (â€˜aaâ€™).</p>

<p>Hereâ€™s the results upon making a new line after line 3469 of 6199 of the huge <a href="https://github.com/trishume/syntect/blob/master/testdata/parser.rs">parser.rs</a>Ù« all taken with similar sensor positioning lower down my Dell monitor than the very top.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lat i= 40.2 +/-   4.1Ù« a= 40Ù« d= 39 (n= 38Ù«q= 90) |  _89           | sublime small .txt

lat i= 41.2 +/-   6.9Ù« a= 41Ù« d= 42 (n= 54Ù«q= 92) |   992          | sublime aa parser.rs
lat i= 43.6 +/-   6.1Ù« a= 43Ù« d= 42 (n= 48Ù«q=100) |   492          |
lat i= 52.2 +/-   6.0Ù« a= 52Ù« d= 52 (n= 26Ù«q=100) |    49          |
lat i= 44.3 +/-   5.6Ù« a= 43Ù« d= 42 (n= 45Ù«q=100) |   391          |
lat i= 42.7 +/-   7.6Ù« a= 42Ù« d= 42 (n= 46Ù«q=100) |  _491          |

lat i= 48.1 +/-   6.8Ù« a= 49Ù« d= 50 (n= 43Ù«q= 89) |   269          | sublime a parser.rs
lat i= 43.9 +/-   5.4Ù« a= 48Ù« d= 52 (n= 32Ù«q= 97) |   197          |
lat i= 47.8 +/-   8.4Ù« a= 49Ù« d= 49 (n= 29Ù«q= 97) |   197_         |
lat i= 46.1 +/-   6.8Ù« a= 47Ù« d= 49 (n= 42Ù«q= 97) |   196_         |

lat i= 63.3 +/-   9.3Ù« a= 63Ù« d= 62 (n= 68Ù«q=118) |    _963__      | vscode aa parser.rs
lat i= 63.6 +/-   7.6Ù« a= 64Ù« d= 65 (n= 71Ù«q=139) |    _49__     _ |
lat i= 62.3 +/-   6.3Ù« a= 61Ù« d= 59 (n= 52Ù«q=132) |    _791        |
lat i= 62.0 +/-   5.8Ù« a= 61Ù« d= 60 (n= 40Ù«q=111) |    _49_        |
lat i= 61.9 +/-   9.7Ù« a= 62Ù« d= 61 (n= 35Ù«q=111) |     981_       |

lat i= 53.1 +/-   7.7Ù« a= 51Ù« d= 49 (n= 54Ù«q=116) |   _79__        | vscode a parser.rs
lat i= 52.2 +/-   6.3Ù« a= 52Ù« d= 51 (n= 41Ù«q=133) |    692         |
lat i= 53.2 +/-   7.8Ù« a= 52Ù« d= 52 (n= 57Ù«q=134) |    591_        |
lat i= 52.1 +/-   7.1Ù« a= 52Ù« d= 52 (n= 55Ù«q=134) |    591_        |
</code></pre></div></div>

<p>I did a bunch of runs at different times and with minor changes to confirm the effectÙ« and you can see that thereâ€™s variation between measurements of the same scenarioÙ« but noticeably larger variation between just typing â€˜aâ€™ and adding an â€˜aâ€™ after an existing â€˜aâ€™. Try looking at the â€˜a=â€™ column since it includes both insert and delete measurements so has the least cross-run noise. Sublime is faster at â€˜aaâ€™ than â€˜aâ€™ and VSCode is faster at â€˜aâ€™ than â€˜aaâ€™.</p>

<p>In both editors â€˜aaâ€™ causes the autocomplete popup to alternate between two lists and â€˜aâ€™ causes it to appear and disappear. I can guess that Sublime might be slower in the â€˜aâ€™ case because opening and closing the autocomplete popup has a costÙ« but I donâ€™t have a strong hypothesis why VSCode is slower in the â€˜aaâ€™ case on both insertion and deletion.</p>

<h3 id="jittering-so-as-not-to-sync-with-refresh">Jittering so as not to sync with refresh</h3>

<p>The next fishy thing I noticed is that my variances seemed too low. I was sometimes getting standard deviations of 1ms when my understanding of how the system worked said I should be getting a standard deviation over <a href="https://www.quora.com/What-is-the-standard-deviation-of-a-uniform-distribution-How-is-this-formula-determined">4.6ms</a> due to 16ms screen refresh intervals.</p>

<p>I looked at my code and figured out that I was inadvertently synchronizing my measurement with screen refreshes. Whenever I measured a changeÙ« my firmware would wait exactly 300ms before typing â€˜aâ€™ or backspace again and taking another measurement. This meant the input was always sent about 300ms after a screen refresh and thus would land at a fairly constant spot in the screen refresh interval. I patched this issue by adding a 50ms random delay between measurements.</p>

<p>This mainly leads to incorrectly low variances but might lead to incorrect averages as well if the app will miss a paint deadline if the input event comes late in a frame but it never does during the test. I found this during testing for this post and couldnâ€™t be bothered to redo all the tests below this pointÙ« so you may notice some low variancesÙ« but I did recheck the averages on important results like Sublime and VSCode.</p>

<h2 id="text-editors">Text editors</h2>

<p>I tested the latency of a bunch of text editors on the same plain text fileÙ« but note the above that these are before I added jitteringÙ« although I did more tests on Sublime and VSCode after jittering which you can see above.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lat i= 32.5 +/-   4.0Ù« a= 34Ù« d= 35 (n= 38Ù«q= 78) |   9_          | sublime text
lat i= 33.4 +/-   1.4Ù« a= 33Ù« d= 33 (n= 68Ù«q= 23) |  _9           | textedit
lat i= 47.6 +/-   7.0Ù« a= 47Ù« d= 47 (n= 71Ù«q=130) |   219         | vscode
lat i= 34.2 +/-   3.5Ù« a= 34Ù« d= 33 (n= 57Ù«q= 37) |   9 _         | chrome html input
lat i= 33.2 +/-   1.1Ù« a= 33Ù« d= 33 (n= 55Ù«q= 30) |   9           | stock mac emacs
lat i= 45.6 +/-   7.0Ù« a= 43Ù« d= 41 (n= 35Ù«q= 56) |   992_        | atom
lat i= 35.0 +/-   4.7Ù« a= 35Ù« d= 35 (n= 66Ù«q= 11) |   9__         | xi
</code></pre></div></div>

<p>Given the lack of jitterÙ« Iâ€™d interpret these results as everything except VSCode and Atom being similarly â€œbasically as good as you can getâ€. And note that even VSCode and Atom have less of a latency penalty for normal typing than you can easily have in your monitor or keyboard.</p>

<h2 id="terminals">Terminals</h2>

<p>I also measured different terminals. It looks like the default Apple Terminal and <a href="https://sw.kovidgoyal.net/kitty/">kitty</a> have similar approximately optimal latencyÙ« while <a href="https://www.iterm2.com/">iTerm2</a> and <a href="https://github.com/alacritty/alacritty">Alacritty</a> have worse latency.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lat i= 53.1 +/-   6.6Ù« a= 54Ù« d= 55 (n= 53Ù«q= 59) |    291      _ | iterm2 gpu render
lat i= 50.5 +/-   2.5Ù« a= 50Ù« d= 50 (n= 56Ù«q= 59) |    19_        | iterm2 no gpu
lat i= 35.8 +/-   7.0Ù« a= 34Ù« d= 33 (n= 73Ù«q= 48) |   9___        | apple terminal
lat i= 35.1 +/-   2.5Ù« a= 34Ù« d= 32 (n= 35Ù«q= 52) |   9_          | apple terminal vim
lat i= 50.4 +/-   3.9Ù« a= 50Ù« d= 49 (n= 60Ù«q=269) |   _59         | alacritty
lat i= 36.1 +/-   5.6Ù« a= 35Ù« d= 34 (n= 78Ù«q=199) |   9__         | kitty
</code></pre></div></div>

<h2 id="how-to-make-one">How to make one</h2>

<p>Hereâ€™s the parts list I used:</p>

<ul>
  <li><strong>$12</strong>: A <a href="https://www.pjrc.com/teensy/teensyLC.html">Teensy LC</a> or any other Teensy 3+. You could also use an ArduinoÙ« but the Teensyâ€™s USB library uses 1000hz polling (1ms latency) while most USB devices default to 125hz (an extra 8ms of random latency in your measurements). Itâ€™s possible you may be able to get your microcontroller of choice to do 1000hz polling though. If you donâ€™t want to have to solder the pinsÙ« buy one with pre-soldered pinsÙ« this might require getting the more expensive Teensy 3 if you want Amazon Prime shipping.</li>
  <li><strong>$12</strong>: A <a href="https://www.amazon.com/gp/product/B01N1FKS4L/ref=ppx_yo_dt_b_asin_title_o03_s01?ie=UTF8&amp;psc=1">light sensor module</a> (Amazon only has 10 packsÙ« I only used 1). You could make your own circuit for this but these modules save a lot of time and are easy to integrate.</li>
  <li><strong>$13</strong>: A <a href="https://www.amazon.com/gp/product/B07SBZRF6S/ref=ppx_yo_dt_b_asin_title_o02_s00?ie=UTF8&amp;psc=1">helping hand</a> to hold the light sensor up to your screen in a stable position.</li>
  <li>A button/switch of some kind to trigger testing</li>
  <li>Wires to connect the light sensorÙ« TeensyÙ« and button</li>
  <li>Electrical tape to make a black soft shield to restrict the view of the sensor</li>
  <li>A USB micro-B cable to connect the Teensy to your computer</li>
</ul>

<p>Thereâ€™s an awful lot of flexibility in exactly how you assemble it. You just need to somehow connect 3 wires (3VÙ« groundÙ« analog out) from the light sensor module to the corresponding pins on the Teensy (3VÙ« ground and any analog-capable pin). The easiest way to do this which doesnâ€™t even require any soldering if you buy a Teensy with pre-soldered header pins is to use 3 <a href="https://www.amazon.com/Uxcell-a16072600ux1043-Female-Jumper-Breadboard/dp/B01M1CDI7M/ref=sr_1_8">female to female jumper wires</a>. Then you just need some kind of switch to activate the latency test where you wire one pin to ground on the Teensy and another pin to a digital IO pin. This can be as simple as two wires that you touch together if youâ€™re really lazy!</p>

<p>To make sure the light sensor module only sees a limited area of the screen I wrapped the sensor in a little cylinder of electrical tape and snipped off the end cleanly with scissors. This made a little round window I could press up against the screen with the helping hand to minimize outside interference and get the cleanest signal.</p>

<p>I had already made a <a href="https://twitter.com/trishume/status/950585012700684288">foot pedal box</a> with a Teensy LC and a little breadboard insideÙ« and it had an extra <a href="https://www.cablechick.com.au/blog/understanding-trrs-and-audio-jacks/">TRRS jack</a> on the side I had put on anticipating this sort of projectÙ« so for me the project was soldering the light sensor module to a TRRS cable. Then I could just use one of my existing foot pedals to control the testing!</p>

<p>For the soldering I was in luck since I had conveniently bought magnetic helping hands for the project which I could use for the soldering process. Inconveniently I realized that I actually didnâ€™t own many substantial chunks of iron for them to attach toÙ« so I ended up using a cast iron pan when soldering and <a href="/2019/03/03/my-tungsten-cube/">my tungsten cube</a> when on my desk (which turns out to be slightly ferromagnetic).</p>

<p><img src="/assets/postassets/latencytester/soldering.jpeg" alt="Soldering" /></p>

<p>I encourage you to have fun and try to make something fancier than just dangling jumper wires. For my foot pedal box I bought a plastic project box from a local electronics shopÙ« used a drill press to put some holes in the sides and installed large and small headphone jacks and a little breadboard so I could reconfigure how things connect. Thereâ€™s tons of foot pedals on Amazon for tattoo machines and electric pianos that use 1/4â€ phone plugs that you can pick and choose from. <a href="https://www.amazon.com/Casio-SP3-SP-3-Sustain-Pedal/dp/B00070E8I8/ref=sr_1_3?">These</a> are my favorites for feel and silence but there are cheaper options that can be unreliableÙ« hard to press or loud.</p>

<p>I wouldnâ€™t recommend following my use of a TRRS jack for the sensor module thoughÙ« theyâ€™re nice and small and thereâ€™s lots of cables availableÙ« but I used them before I realized the problem that they cause a lot of shorting of different connections when plugging and unplugging. I tried to minimize this by putting power and ground on opposite endsÙ« but you should consider some better cable type like maybe a <a href="https://en.wikipedia.org/wiki/Registered_jack">phone cable</a>.</p>

<p><img src="/assets/postassets/latencytester/pedal_box.jpeg" alt="Pedal box insides" /></p>

<h2 id="the-firmware">The firmware</h2>

<p>I didnâ€™t write the fanciest possible firmware to find the beginning and ending of the transitionÙ« but I put a bit of effort into tweaking it to work well and adding various features so I recommend starting with my firmware. Install the <a href="https://www.pjrc.com/teensy/teensyduino.html">Teensyduino</a> software and then you can use <a href="https://gist.github.com/trishume/bbdae75792d2888708a01d5625fa9229">my latency tester Arduino sketch</a> which also doubles as foot pedal box code but you can comment that stuff out and configure it to use the right pins. Then just long press your switch to take samples and short press to type out the results!</p>

'),('http://thume.ca/2020/05/17/pipes-kill-productivity/', 'Fragile narrow laggy asynchronous mismatched pipes kill productivity', '1589673600000',  13, '
<p>Something Iâ€™ve been thinking about recently is how when Iâ€™ve worked on any kind of distributed systemÙ« including systems as simple as a web app with frontend and backend codeÙ« probably upwards of 80% of my time is spent on things I wouldnâ€™t need to do if it werenâ€™t distributed. I came up with the following description of why I think this kind of programming requires so much effort: Everything is fragile narrow laggy asynchronous mismatched untrusted pipes. I think every programmer whoâ€™s worked on a networked system has encountered each of these issuesÙ« this is just my effort to coherently describe all of them in one place. I hope to prompt you to consider all the different hassles at once and think about how much harder/easier your job would be if you did/didnâ€™t have to deal with these things. I think this is part of why web companies like Twitter seem to have so much lower impressiveness per engineer productivity than other places like game companies or SpaceXÙ« although thereâ€™s other pieces to that puzzle. While part of the difficulty of distributed systems is inherent in physicsÙ« I think thereâ€™s lots of ideas for making each part of the problem easierÙ« many already in common useÙ« and Iâ€™ll try to mention lots of them. I hope that we as programmers continually develop more of these techniques and especially general implementations that simplify a problem. Like serialization libraries reducing the need for hand-written parsers/writersÙ« I think thereâ€™s a lot of developer time out there to save by implementing generalized solutions where we currently painstakingly reimplement common patterns. I also think all these costs mean you should try <em>really hard</em> to avoid making your system distributed if you donâ€™t have to.</p>

<p>Iâ€™ll go over each piece in detailÙ« but brieflyÙ« whenever we introduce a network connection we usually have to deal with something that is:</p>

<ul>
  <li><strong>Fragile</strong>: The network connection or the other end can have hardware failuresÙ« these have different implications but both manifest as just a timeout. Everything needs to handle failure.</li>
  <li><strong>Narrow</strong>: Bandwidth is limited so we need to carefully design protocols to only send what they need.</li>
  <li><strong>Laggy</strong>: Network latency is noticeable so we need to carefully minimize round-trips.</li>
  <li><strong>Asynchronous</strong>: Especially with &gt;2 input sources (UIs count) all sorts of races and edge cases can happen and need to be thought about and handled.</li>
  <li><strong>Mismatched</strong>: Itâ€™s often not possible to upgrade all systems atomicallyÙ« so you need to handle different ends speaking different protocol versions.</li>
  <li><strong>Untrusted</strong>: If you donâ€™t want everything to be taken down by one malfunction you need to defend against invalid inputs and being overwhelmed. Sometimes you also need to defend against actual attackers.</li>
  <li><strong>Pipes</strong>: Everything gets packed as bytes so you need to be able to (de)serialize your data.</li>
</ul>

<p>All of these things can be mostly avoided when programming things that run on one computerÙ« that is unless you end up optimizing performance and realizing your computer is actually a distributed system of cores and some of them come back. Some domains manage to avoid some of these but Iâ€™ve experienced subsets of these problems working on <a href="https://thume.ca/resume">web appsÙ« self-driving carsÙ« a text editorÙ« and high-performance systems</a>Ù« theyâ€™re everywhere.</p>

<p>This isnâ€™t even all the problemsÙ« just things about the network. Tons of effort is also expended on things like how various bottlenecks often entail a complicated hierarchy of caches that need to be kept in sync with the underlying data store.</p>

<p>One way you can avoid all this is to just not write a distributed system. There are plenty of cases you can do this and I think itâ€™s worthwhile to try way harder than some people do to pack everything into one process. However past a certain point of reliability or scaleÙ« physics means youâ€™re going to have to use multiple machines (unless you want to go the mainframe route).</p>

<h2 id="fragile">Fragile</h2>

<p>As you connect machines or increase reliability goalsÙ« the strategy of just crashing everything when one piece crashes (what multi-threaded/multi-core systems do) becomes increasingly unviable. Hardware will failÙ« wireless connections dropÙ« entire data centers have their power or network taken out by <a href="https://en.wikipedia.org/wiki/Electrical_disruptions_caused_by_squirrels">squirrels</a>. Some domains like customers with flaky internet also inevitably entail frequent connection failure.</p>

<p>In practice you need to write code to handle the failure cases and think carefully about what they are and what to do. This gets worse when merely noting the failure would drop important dataÙ« and you need to implement redundancy of data storage or transmission. Even worseÙ« both another machine failing and a network connection breaking become visible just as some expected network packet not arriving after â€œtoo longâ€Ù« introducing not only a delay but an ambiguity that can result in <a href="https://en.wikipedia.org/wiki/Split-brain_(computing)">split-brain issues</a>. Often something like TCP implements it for you but sometimes you have to implement your own heartbeating to periodically check that another system is still alive.</p>

<p>Attempts to make this easier include exceptionsÙ« TCPÙ« concensus protocols and off-the-shelf redundant databasesÙ« but no solution eliminates the problem everywhere. One of my favourite attempts is <a href="https://rollout.io/blog/linking-monitoring-and-supervising-in-elixir/">Erlangâ€™s process linkingÙ« monitoring and supervising</a> which offers a philosophy that attempts to coalesce all sorts of failures into one easier to handle general case.</p>

<h2 id="narrow">Narrow</h2>

<p>Network bandwidth is often limitedÙ« especially over consumer or cellular internet. It may seem like this isnâ€™t a limitation very often because you rarely hit bandwidth limitsÙ« but thatâ€™s because limited bandwidth is ingrained into everything you do. Whenever you design a distributed system you need to come up with a communication protocol that communicates on the order of whatâ€™s necessary rather than on the order of the total size of your data.</p>

<p>In a multi-threaded programÙ« you might just pass a pointer to gigabytes of immutable or locked data for a thread to read what it wants from and not think anything of it. In a distributed system passing the entire memory representing your database is unthinkable and you need to spend time implementing other approaches.</p>

<p>Although actually multi-core systems are a certain kind of distributed system and they employ <a href="https://en.wikipedia.org/wiki/MESI_protocol">protocols</a> behind the scenes to transfer only the data thatâ€™s necessaryÙ« but involve many more broadcasts and round trips than would be viable with most networks. I actually think trying to apply techniques used to make multi-core machines seamless to distributed systems is a good way to think of <a href="https://dl.acm.org/doi/pdf/10.14778/3236187.3236209">neat solutions</a> that might be much more general than youâ€™d otherwise design. Similarly once you really start optimizing systems hard you notice that bandwidth inside your computer becomes a constraint too.</p>

<p>Dealing with low bandwidth usually involves a message type for each query or modification to a shared data structureÙ« and deciding when to ship over more data so local interactions are fasterÙ« or less data to avoid terrible bandwidth cases. It often goes further to various types of replicated state machine where each peer updates a model based on a replicated stream of changesÙ« because sending the new model after every update would be too much bandwidth. Examples of this include <a href="https://www.gamasutra.com/view/feature/131503/1500_archers_on_a_288_network_.php">RTS games</a> to <a href="https://support.kraken.com/hc/en-us/articles/360027821131-How-to-maintain-a-valid-order-book-">exchange</a> <a href="https://www.nasdaqtrader.com/content/technicalsupport/specifications/dataproducts/NQTVITCHspecification.pdf">feeds</a>. However maintaining determinism and consistency in how each peer updates its state to avoid desyncs can be trickyÙ« especially if different peers have different languages or software versions. You also often end up implementing a separate protocol for streaming a full snapshotÙ« because replaying events from the beginning of time when connecting isnâ€™t viable.</p>

<p>Attempts to make this easier include RPC libraries just making it easier to send lots of different message types for different queries and updates rather than shipping data structuresÙ« caching librariesÙ« and compression. Cool but less commonly used systems include things like <a href="https://hackingdistributed.com/2013/12/26/introducing-replicant/">Replicant</a> that ensure synchronized state machine code and update streams on many devices to make replicated state machines easier and less fraught.</p>

<h2 id="laggy">Laggy</h2>

<p>One network round trip canâ€™t be a problematic latency or you need better networking hardware or a different problem to solve. The difficulties come from avoiding implementing your solution in a way that needs too many network round trips. This can lead to needing to implement special combo-messages that do a sequence of operations on the server instead of just providing smaller primitive messages.</p>

<p>The webÙ« with its especially large latenciesÙ« has had lots of problems of this type such as only having the font/image URLs after loading the HTMLÙ« or REST APIs that require multiple chained calls to get the IDs needed for the next. Lots of things have been built for these problems like resource inliningÙ« <a href="https://en.wikipedia.org/wiki/HTTP/2_Server_Push">HTTP/2 server push</a> and <a href="https://graphql.org/">GraphQL</a>.</p>

<p>A cool somewhat general solution is <a href="https://capnproto.org/news/2013-12-13-promise-pipelining-capnproto-vs-ice.html">Capâ€™n Proto promise pipelining</a> and other systems that involve essentially shipping a chain of steps to perform to the other end (like SQL). These systems essentialy send a limited type of program to perform on the server. Unfortunately you often run into the limitations of the language usedÙ« like you canâ€™t add 1 to your Capâ€™n Proto result before passing it to a new call without a round trip. But if you make your language too powerful you can run into problems with the code youâ€™re shipping overloading the server or being too big. Just adding a multi-step message for your use case is pretty easy if you control both endsÙ« but can be harder if the other end is a companyâ€™s API for third partiesÙ« or even just owned by a different team at a big companyÙ« and those are the cases where they tend not to want to run your programs on their server. I think thereâ€™s lots more avenue for exploration here in terms of new approaches to sending segments of code while re-using sent code to save bandwidth and limiting the potential for it to do damage.</p>

<p>Another solution that can work in a data center is to use better networking. You can get <a href="https://www.mellanox.com/products/ethernet-adapters/connectx-6dx">network</a> <a href="https://exablaze.com/exanic-x25">cards</a> with <a href="https://docs.microsoft.com/en-us/azure/virtual-machines/workloads/hpc/hc-series-performance">2us latencies and 100Gbps bandwidths</a> or betterÙ« but basically only HPCÙ« simulations and finance use them. However these just reduce the constant factor and donâ€™t save you if your approach takes O(n) round trips.</p>

<h2 id="asynchronous">Asynchronous</h2>

<p>As soon as you have 2+ sources of events that arenâ€™t synchronized then you start worrying about race conditions. This can be multiple serversÙ« or just a web app with both user input and a channel to the server. Thereâ€™s always uncommon orderings like the user clicking the â€œSubmitâ€ button a second time before the next page loads. Sometimes you get lucky and the design of your system means thatâ€™s fineÙ« other times itâ€™s not and you either fix it to handle that case or get bug reports from customers who were billed twice. The more asynchrony the more cases you have to either think about or solve with an elegant design which precludes bad states.</p>

<p>Depending on your language/frameworkÙ« asynchrony can also entail a change to the way you normally write code that makes everything bloated and uglier. Lots of systems used to and still do require you to use callbacks everywhereÙ« sometimes without even providing you closuresÙ« making your code an enormous mess. Many languages have gotten better at this with features like <a href="https://en.wikipedia.org/wiki/Async/await">async/await</a> or coroutines with small stack like <a href="https://tour.golang.org/concurrency/1">Go</a>Ù« or just using threads and blocking I/O. Unfortunately some of these solutions introduce <a href="https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/">function color problems</a> where introducing asynchrony requires making changes throughout your codebase.</p>

<p>Asynchrony edge cases are a reasonably fundamental problemÙ« but thereâ€™s lots of available patterns for solving different kinds of asynchrony. Examples include concurrency primitives like locks and barriersÙ« protocol design ideas like <a href="https://en.wikipedia.org/wiki/Idempotence">idempotency</a>Ù« and fancier things like <a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type">CRDTs</a>.</p>

<h2 id="mismatched">Mismatched</h2>

<p>Usually itâ€™s not possible to upgrade every component of a distributed system atomically when you want to change a protocol. This runs from communicating server clusters that must run 24/7 to users who have an old version of your web page loaded in a tab. This means for some time youâ€™ll have systems that want to talk a newer protocol version communicating with systems that only know an older protocol. This is just a problem you need to solve and thereâ€™s two broad classes of common solutions with many subtypes:</p>

<ul>
  <li>Have the new software version be able to speak both the old and new protocol version and negotiate to use the new version with upgraded peersÙ« either by maintaining both implementations or mapping the old handlers onto the new ones.</li>
  <li>Use data structures that provide some degree of compatibility for freeÙ« then only upgrade your protocol in those ways. For example unrecognized fields in JSON objects are usually ignored so can be used for new functionality when recognized. Migrations can usually add new columns to a database table without it breaking queries. Then you usually go to great lengths to shoehorn every change into being this type of compatible.</li>
</ul>

<p>The problem with both these cases is the first steps usually accumulate technical debt in the form of code paths to handle cases (for example of missing fields) that will never come up once all peers are upgraded past the protocol change. This usually entails multi-stage rolloutsÙ« for example introduce a new field as optionalÙ« roll out the new version everywhereÙ« change the field to be mandatory now that all clients send itÙ« do another rollout. Iâ€™ve definitely spent a lot of time planning multi-stage rollouts when Iâ€™ve wanted to change protocols used by multiple systems without leaving a mess.</p>

<p>Thereâ€™s lots of things that help with both of these approachesÙ« both serialization systems that provide lots of compatible upgrade paths like <a href="https://developers.google.com/protocol-buffers">Protobufs</a>Ù« to various <a href="https://yave.handmade.network/blogs/p/2723-how_media_molecule_does_serialization">patterns for deserializing/upgrading old type versions</a>.</p>

<h2 id="untrusted">Untrusted</h2>

<p>Not only can your data fail to arrive but your system can recieve data that might actively harm it. Systems have bugs which cause invalid messages to be sentÙ« so inputs need to be carefully validated and errors returnedÙ« not only at the serialization level but the business logic level. Bugs or new loads can cause systems to send messages faster than they can be handledÙ« necessitating backpressure and limits. You may even have to defend against attackers who actively try and subvert your system by sending messages that would never be sent by your usual counterparties and <a href="https://www.anchor.com.au/blog/2012/12/how-to-explain-hash-dos-to-your-parents-by-using-cats/">intelligently seek out edge cases</a>.</p>

<p>Here too we have lots of patterns including rate limitsÙ« field validation logic and channels with built in backpressure. On the security side we also have a field of things like encryptionÙ« certificates and fuzzing. Weâ€™ve also gotten better at being general here as weâ€™ve reduced prevalence of manual patterns like ensuring we always escape interpolated strings in SQL and HTMLÙ« with more general patterns like <code class="language-plaintext highlighter-rouge">?</code> query parameters and templating systems which always apply escaping.</p>

<h2 id="pipes">Pipes</h2>

<p>Last and mostly leastÙ« everything has to be a stream of bytes or packets of bytes. This means you need to take your nice data structures that your language makes easy to manipulate and pack them into a different form from their in-memory representation in order to send on the wire. Luckily except in very few places easy <a href="https://serde.rs/">serialization</a>/<a href="https://grpc.io/">RPC</a> libraries have made this pretty easyÙ« if occasionally somewhat slow. You can also sometimes use methods that allow you to pick out exactly the parts you want from the byte buffers without transforming it to a different representationÙ« perhaps by casting your buffer pointer to a C structure pointer (when thatâ€™s even close to safe-ish)Ù« or using something like <a href="https://capnproto.org/">Capâ€™n Proto</a> that can generate accessors.</p>

<p>This is probably the one Iâ€™ve spent the least time fightingÙ« but one case I can remember was when I wanted to send a large data structureÙ« but the available serialization system could only serialize it all at once rather than streaming it packet by packet as the socket could accept itÙ« and I didnâ€™t want to block my server for a long time doing the entire thingÙ« creating tail latency. I ended up choosing a different designÙ« but I could also have written custom code to break my data structure up into chunks and send it a little bit at a time.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I suspect many responses to this post will be of the form â€œActually {some/all of these problems} are trivial if you just {do some thing that isnâ€™t universally applicableÙ« is time consuming or has its own issuesÙ« possibly something I mentionedÙ« if so probably using Erlang} and the real problem is that other people are bad at programming unlike people in the good old daysâ€. There are lots of things that helpÙ« and there is a skill component in knowing about good solutionsÙ« choosing the right onesÙ« and implementing them effectively. However these are still hard problems and people have to make difficult real tradeoffs because we havenâ€™t solved them effectively enough. Maybe you would have taken a different side of the tradeoff but people make these technology decisions for real reasons and we should strive to reduce the costsÙ« as well as improving decisions over which costs we accept.</p>

<p>I just canâ€™t use Erlang for most projects I do because they require either extremely low latencyÙ« integration with some part of a non-Erlang ecosystemÙ« or theyâ€™re too computationally intensive (yes I know about <a href="http://erlang.org/doc/tutorial/nif.html">NIFs</a>). This means thereâ€™s ample opportunity for productivity improvements just by bringing solutions from one domain and implementing them in another domain or making them faster! I love seeing <a href="https://github.com/constellation-rs/constellation">efforts</a> to <a href="https://akka.io/">bring</a> Erlangâ€™s benefits to <a href="https://github.com/gleam-lang/gleam">more</a> <a href="https://phoenixframework.org/">areas</a>. And even Erlang doesnâ€™t solve all of these problems to the extent I believe itâ€™s possible to one day address them.</p>

<p>I think one of the real biggest hammers you can take to these problems is just to try <em>really hard</em> to avoid writing a distributed system in the first place. One of my goals for this post is to inspire people to try to develop more general solutions instead of having to repeatedly implement specific patternsÙ« but my other goal is to try and put all the costs in your face at once and say <em>are you sure adding that separate networked system will really make your job easier?</em> Sometimes a distributed system is unavoidableÙ« such as if you want extreme availability or computing powerÙ« but other times itâ€™s totally avoidable. To pick specific examples:</p>

<ul>
  <li>I think people should be more willing to try and write performance-sensitive code as a (potentially multi-threaded) process on one machine in a fast language if itâ€™ll fit rather than try and distribute a slower implementation over multiple machines. I acknowledge that this takes time and effort to learn how to do and optimizeÙ« but itâ€™ll pay off in a simpler system.
    <ul>
      <li>In particular I think people should be more aggressive about trying to use multi-threading on a really big computer when possible. I personally find multi-threaded programming in <a href="https://www.rust-lang.org/">Rust</a> way easier than parallelizing with multiple processes when itâ€™s viable. Some problems like asynchrony are similar but others like serializationÙ« latency and bandwidth largely go away except at performance levels way higher than youâ€™d probably get out of a hypothetical distributed version.</li>
    </ul>
  </li>
  <li>I think people should be more willing to use C FFI to bind to libraries in other languages rather than putting them in a separate networked service (<a href="https://github.com/sourcegraph/syntect_server">example</a> picking on users of my own libraryÙ« although I donâ€™t actually know what their constraints were). Yes you have to learn how to do C FFI and deal with unsafetyÙ« but Iâ€™d take that trade to avoid the network service.</li>
  <li>There are reasons people choose to split things into separate services other than availability and parallelism. For example ability to deploy updates quickly without coordinating with another teamÙ« fast CIÙ« using a different languageÙ« isolation.
    <ul>
      <li>We should build more alternatives that donâ€™t involve separate systemsÙ« like tools for using auto-updating hot-reloaded dynamically linked libraries with sandboxing instead of microservices (eliminating â€œnarrowâ€Ù« â€œlaggyâ€ and â€œasynchronousâ€). Iâ€™m pretty sure at least one instance of hot-reloading dylib updates pushed over the network exists (Iâ€™d appreciate links!) but weâ€™re far from availability of excellent implementations in many languages and in the mean time it isnâ€™t a viable alternative for most people considering adding a microservice to build this themselves.</li>
      <li>Better tools for continuous integrationÙ« continuous deploymentÙ« isolationÙ« and monorepos can reduce the incentive to split off services to reduce iteration cycle time.</li>
    </ul>
  </li>
</ul>

<p>I follow Jonathan Blowâ€™s <a href="https://twitter.com/Jonathan_Blow">Twitter</a> and <a href="https://www.youtube.com/user/jblow888">streams</a> and end up with mixed feelings. On the one hand I resonate with his feeling that modern software is way more complex than it needs to be and like the aesthetic and focus on performance and compile time power embodied in his language. On the other hand when he rants about how modern programmers just donâ€™t know how to do things the Good Old Waysâ„¢ and need to stop making terrible design choices to be productiveÙ« I canâ€™t help but think back to how I as one person have both been what he considers terribly unproductive working on web systemsÙ« and productive and effective when writing fast systems in his preferred style. Itâ€™s not that I just made terrible decisions sometimes but not other timesÙ« or was unaware of systems programming or data oriented designÙ« itâ€™s that I was facing different tradeoffs that forced me to make a distributed system and face a bunch of unproductive challenges that arenâ€™t fully solved. The distributed systems I work on nowadays are low levelÙ« very fastÙ« minimize layers of complexityÙ« and my coworkers are extremely skilled. If anythingÙ« Iâ€™m less productive per similar-sounding feature when I work on these distributed systems than I was when I was programming in Ruby on RailsÙ« because thereâ€™s less available tooling than for Rails. Most of my effort still goes into addressing the same distributed systems problemsÙ« which you just have to deal with less when programming a game. I agree with him that itâ€™s totally possible for things to be better and dramatically less complexÙ« but people decide to use established technologies because they donâ€™t have the luxury of taking the time to write their ideal platform from scratch first. Thatâ€™s why Iâ€™m so excited when people like him work to develop new tools like his language. I think even if everybody suddenly knew all his favorite game developer skillsÙ« more people would have the ability to build new types of toolsÙ« but until those tools were builtÙ« creating distributed systems would remain hard and unproductive. Also to make sure I tick off Blow fans and haters alike I should say that I recommend watching some of his streamsÙ« I think heâ€™s really interestingÙ« skilled and worth listening toÙ« despite his abrasiveness and strong opinions. I find â€œwhat about this design would Jonathan Blow yell about being terribleâ€ a good lens to help me come up with interesting alternatives.</p>

<p>AnyhowÙ« I hope this leads you to think about the ways that your work could be more productive if you had better tools to deal with distributed systemsÙ« and what those might be. Alternatively I hope it prompts you to seriously consider the costs of writing distributed systems and what you can do to bend all the tradeoffs in your area of the programming world more towards non-distributed systems. Also try to think about what reasons people might not appear to you to be as good at developing software as you are with your Chosen Technologyâ„¢ and how you can understand the constraints and tradeoffs they are dealing with and what solutions might shift the balance.</p>
'),('http://thume.ca/2020/04/18/telefork-forking-a-process-onto-a-different-computer/', 'Teleforking a process onto a different computer!', '1587168000000',  13, '
<p>One day a coworker mentioned that he was thinking about APIs for distributed compute clusters and I jokingly responded â€œclearly the ideal API would be simply calling <code class="language-plaintext highlighter-rouge">telefork()</code> and your process wakes up on every machine of the cluster with the return value being the instance IDâ€. I ended up captivated by this idea: I couldnâ€™t get over how it was clearly sillyÙ« yet way easier than any remote job API Iâ€™d seenÙ« and also seemingly not a thing computers could do. I also kind of knew how I could do itÙ« and I already had a good name which is the hardest part of any projectÙ« so I got to work.</p>

<p>In one weekend I had a basic prototypeÙ« and in another weekend I had a demo where I could <code class="language-plaintext highlighter-rouge">telefork</code> a process to a giant VM in the cloudÙ« run a path tracing render job on lots of coresÙ« then telefork the process backÙ« all wrapped in a simple API.</p>

<p>Hereâ€™s a video of it running a render on a 64 core cloud VM in 8 seconds (plus 6s each for the telefork there and back). The same render takes 40s running locally in a container on my laptop:</p>

<video controls="" width="660" autoplay="" muted="" loop="">
    <source src="/assets/postassets/telefork/telefork-small.mp4" type="video/mp4" />
    SorryÙ« your browser doesn"t support embedded videos.
</video>

<p>How is it possible to teleport a process? Thatâ€™s what this article is here to explain! The basic idea is that at a low level a Linux process has only a few different partsÙ« and for each of them you just need a way to retreive it from the donorÙ« stream it over the networkÙ« and copy it into the cloned process.</p>

<p>You may be thinkingÙ« â€œbut waitÙ« how can you replicate [some reasonable thing like a TCP connection]?â€ Basically I just donâ€™t replicate tricky things so that I could keep it simpleÙ« meaning itâ€™s <strong>just a fun tech demo</strong> you probably shouldnâ€™t use for anything real. It can still teleport a broad class of mostly computational programs though!</p>

<h2 id="what-does-it-look-like">What does it look like</h2>

<p>I wrote it as a Rust library but in theory you could wrap it in a C API and then use it via FFI bindings to teleport even a Python process. <a href="https://github.com/trishume/telefork">The implementation</a> is only about 500 lines of code (plus 200 lines of comments) and you use it like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">use</span> <span class="nn">telefork</span><span class="p">::{</span><span class="n">telefork</span><span class="p">Ù«</span> <span class="n">TeleforkLocation</span><span class="p">};</span>

<span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">args</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">String</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nn">std</span><span class="p">::</span><span class="nn">env</span><span class="p">::</span><span class="nf">args</span><span class="p">()</span><span class="nf">.collect</span><span class="p">();</span>
    <span class="k">let</span> <span class="n">destination</span> <span class="o">=</span> <span class="n">args</span><span class="nf">.get</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="nf">.expect</span><span class="p">(</span><span class="s">"expected arg: address of teleserver"</span><span class="p">);</span>

    <span class="k">let</span> <span class="k">mut</span> <span class="n">stream</span> <span class="o">=</span> <span class="nn">std</span><span class="p">::</span><span class="nn">net</span><span class="p">::</span><span class="nn">TcpStream</span><span class="p">::</span><span class="nf">connect</span><span class="p">(</span><span class="n">destination</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
    <span class="k">match</span> <span class="nf">telefork</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">stream</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">()</span> <span class="p">{</span>
        <span class="nn">TeleforkLocation</span><span class="p">::</span><span class="nf">Child</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="p">{</span>
            <span class="nd">println!</span><span class="p">(</span><span class="s">"I teleported to another computer and was passed {}!"</span><span class="p">Ù«</span> <span class="n">val</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="nn">TeleforkLocation</span><span class="p">::</span><span class="n">Parent</span> <span class="k">=&gt;</span> <span class="nd">println!</span><span class="p">(</span><span class="s">"Done sending!"</span><span class="p">)Ù«</span>
    <span class="p">};</span>
<span class="p">}</span>
</code></pre></div></div>

<p>I also provide a helper called <code class="language-plaintext highlighter-rouge">yoyo</code> that <code class="language-plaintext highlighter-rouge">telefork</code>s to a serverÙ« executes a closure you give itÙ« then <code class="language-plaintext highlighter-rouge">telefork</code>s back. This provides the illusion that you can easily run a snippet of code on a remote serverÙ« perhaps one with much more compute power available.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// load the scene locallyÙ« this might require loading local scene files to memory</span>
<span class="k">let</span> <span class="n">scene</span> <span class="o">=</span> <span class="nf">create_scene</span><span class="p">();</span>
<span class="k">let</span> <span class="k">mut</span> <span class="n">backbuffer</span> <span class="o">=</span> <span class="nd">vec!</span><span class="p">[</span><span class="nn">Vec3</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="mf">0.0</span><span class="p">Ù«</span> <span class="mf">0.0</span><span class="p">Ù«</span> <span class="mf">0.0</span><span class="p">);</span> <span class="n">width</span> <span class="o">*</span> <span class="n">height</span><span class="p">];</span>
<span class="nn">telefork</span><span class="p">::</span><span class="nf">yoyo</span><span class="p">(</span><span class="n">destination</span><span class="p">Ù«</span> <span class="p">||</span> <span class="p">{</span>
  <span class="c">// do a big ray tracing job on the remote server with many cores!</span>
  <span class="nf">render_scene</span><span class="p">(</span><span class="o">&amp;</span><span class="n">scene</span><span class="p">Ù«</span> <span class="n">width</span><span class="p">Ù«</span> <span class="n">height</span><span class="p">Ù«</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">backbuffer</span><span class="p">);</span>
<span class="p">});</span>
<span class="c">// write out the result to the local file system</span>
<span class="nf">save_png_file</span><span class="p">(</span><span class="n">width</span><span class="p">Ù«</span> <span class="n">height</span><span class="p">Ù«</span> <span class="o">&amp;</span><span class="n">backbuffer</span><span class="p">);</span>
</code></pre></div></div>

<h2 id="anatomy-of-a-linux-process">Anatomy of a Linux process</h2>

<p>Letâ€™s look at what a process on Linux (the OS <code class="language-plaintext highlighter-rouge">telefork</code> works on) looks like:</p>

<p><img src="/assets/postassets/telefork/process_anatomy.png" alt="Anatomy of a process diagram" /></p>

<ul>
  <li><strong>Memory mappings:</strong> These specify the ranges of bytes from the space of possible memory addresess that our program is usingÙ« composed of â€œpagesâ€ of 4 kilobytes. You can inspect them for a process using the <code class="language-plaintext highlighter-rouge">/proc/&lt;pid&gt;/maps</code> file. These contain both all the executable code of our program as well as the data it is working with.
    <ul>
      <li>There are a few different types of these but we can treat these as just ranges of bytes that need to be copied and recreated at the same place (with the exception of some special ones).</li>
    </ul>
  </li>
  <li><strong>Threads:</strong> A process can have multiple threads executing simultaneously on the same memory. These have ids and maybe some other state but when theyâ€™re paused theyâ€™re mainly described by the registers of the processor corresponding to the point of execution. Once we have all the memory copied we can just copy the register contents over into a thread on the destination process and then resume it.</li>
  <li><strong>File descriptors:</strong> The operating system has a table mapping ordinary integers to special kernel resources. You can do things with these resources by passing those integers to <a href="http://man7.org/linux/man-pages/man2/syscalls.2.html">syscalls</a>. There are a whole bunch of different types of resources these file descriptors can point to and some of them like TCP connections can be tricky to clone.
    <ul>
      <li>I just gave up on this part and donâ€™t handle them at all. The only ones that work are stdin/stdout/stderr since those are always mapped to 0Ù« 1 and 2 for you.</li>
      <li>That doesnâ€™t mean itâ€™s not possible to handle themÙ« it just would take some extra work Iâ€™ll talk about later.</li>
    </ul>
  </li>
  <li><strong>Miscellaneous:</strong> Thereâ€™s some other miscellaneous pieces of process state that vary in difficulty to replicate and most of the time arenâ€™t important. Examples include the <a href="http://man7.org/linux/man-pages/man2/brk.2.html"><code class="language-plaintext highlighter-rouge">brk</code> heap pointer</a>. Some of these are only possible to restore using weird tricks or special syscalls like <a href="https://lore.kernel.org/patchwork/patch/494297/"><code class="language-plaintext highlighter-rouge">PR_SET_MM_MAP</code></a> that were added by other restoration efforts.</li>
</ul>

<p>So we can make a basic <code class="language-plaintext highlighter-rouge">telefork</code> implementation by just figuring out how to recreate the memory mappings and main thread registers. This should handle simple programs that mostly do computation without interacting with OS resources like files (in a way that needs to be teleportedÙ« opening a file on one system and closing it before calling <code class="language-plaintext highlighter-rouge">telefork</code> is fine).</p>

<h2 id="how-to-telefork-a-process">How to telefork a process</h2>

<p>I wasnâ€™t the first to think of the possibility of recreating a process on another machine. I emailed <a href="https://robert.ocallahan.org/">@rocallahan</a>Ù« the author of <a href="https://github.com/mozilla/rr">the rr record and replay debugger</a> to ask some questions since rr does some very similar things to what I wanted to do. He let me know of the existence of <a href="https://criu.org/Main_Page">CRIU</a>Ù« which is an existing system that can stream a Linux process to a different systemÙ« designed for live migrating containers between hosts. CRIU supports restoring all sorts of file descriptors and other stateÙ« however the code was really complex and used lots of syscalls that required special kernel builds or root permissions. Linked from the CRIU wiki page I found <a href="http://dmtcp.sourceforge.net/">DMTCP</a> which was built for snapshotting distributed supercomputer jobs so they could be restarted laterÙ« and it had <a href="https://github.com/dmtcp/dmtcp/blob/7d02a2e063a8e70cc4d836d0b658124614666f44/src/mtcp/mtcp_restart.c">easier to follow code</a>.</p>

<p>These didnâ€™t dissuade me from trying to implement my own system since theyâ€™re super complex and require special runners and infrastructureÙ« and I wanted to show how simple a basic teleport can be and make it just a library call. So I read pieces of source code from <code class="language-plaintext highlighter-rouge">rr</code>Ù« CRIUÙ« DMTCPÙ« and some ptrace examplesÙ« and put together my own <code class="language-plaintext highlighter-rouge">telefork</code> procedure. My method works in its own way thatâ€™s a hodgepodge of different techniques.</p>

<p>In order to teleport a processÙ« thereâ€™s both work that needs to be done in the source process which calls <code class="language-plaintext highlighter-rouge">telefork</code>Ù« and at the call to the function which receives a streamed process on the server and recreates it from the stream (<code class="language-plaintext highlighter-rouge">telepad</code>). These can happen concurrentlyÙ« but itâ€™s also possible to do all the serializing before loadingÙ« for example by dumping to a file then loading later.</p>

<p>Below is a simplified overview of both processesÙ« if you want to know exactly how everything happens I encourage you to read <a href="https://github.com/trishume/telefork/blob/master/src/lib.rs">the source</a>. Itâ€™s heavily commentedÙ« all in one fileÙ« and ordered so you can read it top to bottom to understand how everything works.</p>

<h2 id="sending-a-process-using-telefork">Sending a process using <code class="language-plaintext highlighter-rouge">telefork</code></h2>

<p>The <code class="language-plaintext highlighter-rouge">telefork</code> function is given a writeable stream over which it sends all the state of its process.</p>

<ol>
  <li><strong>Fork the process</strong> into a frozen child. It can be hard for a process to inspect its own state since as it inspects the state things like the stack and registers change. We can avoid this by using a normal Unix <a href="http://man7.org/linux/man-pages/man2/fork.2.html"><code class="language-plaintext highlighter-rouge">fork</code></a> and then have the child stop itself so we can inspect it.</li>
  <li><strong>Inspect the memory mappings.</strong> This can be done by parsing <code class="language-plaintext highlighter-rouge">/proc/&lt;pid&gt;/maps</code> to find out where all the memory maps are. I used the <a href="https://github.com/rbspy/proc-maps">proc_maps crate</a> for this.</li>
  <li><strong>Send the info for special kernel maps.</strong> Based on what DMTCP doesÙ« instead of copying the contents of special kernel maps we remap themÙ« and this is best done before the rest of the mapping so we stream them first without their contents. These special maps like <code class="language-plaintext highlighter-rouge">[vdso]</code> are used to make certain syscalls like getting the time faster.</li>
  <li><strong>Loop over the other memory maps and stream them</strong> to the provided pipe. I first serialize a structure containing info about the mapping and then I loop over the pages in it and use the <a href="http://man7.org/linux/man-pages/man2/process_vm_readv.2.html"><code class="language-plaintext highlighter-rouge">process_vm_readv</code></a> syscall to copy memory from the child to a bufferÙ« then write that buffer to the channel.</li>
  <li><strong>Send the registers.</strong> I use the <code class="language-plaintext highlighter-rouge">PTRACE_GETREGS</code> option for the <a href="http://man7.org/linux/man-pages/man2/ptrace.2.html"><code class="language-plaintext highlighter-rouge">ptrace</code> syscall</a>Ù« which allows me to get all register values of the child process. Then I just write them in a message over the pipe.</li>
</ol>

<h2 id="running-syscalls-in-a-child-process">Running syscalls in a child process</h2>

<p>In order to mold a target process into a copy of the incoming process weâ€™ll need to get the process to execute a bunch of syscalls on itself without having access to any codeÙ« because weâ€™ve deleted it all. Hereâ€™s how I do remote syscalls using <a href="http://man7.org/linux/man-pages/man2/ptrace.2.html"><code class="language-plaintext highlighter-rouge">ptrace</code></a>Ù« which is a versatile syscall for manipulating and inspecting other processes:</p>

<ol>
  <li><strong>Find a syscall instruction</strong>. You need at least one syscall instruction for the child to execute to be in an executable mapping. Some people patch one inÙ« but instead I use <code class="language-plaintext highlighter-rouge">process_vm_readv</code> to read the first page of the kernel <code class="language-plaintext highlighter-rouge">[vdso]</code> mappingÙ« which as far as I know contains at least one syscall in all Linux versions so farÙ« and then search through the bytes for its offset. I only do this once and update it when I move the <code class="language-plaintext highlighter-rouge">[vdso]</code> mapping.</li>
  <li><strong>Set up the registers</strong> to execute a syscall using <code class="language-plaintext highlighter-rouge">PTRACE_SETREGS</code>. The instruction pointer points to the syscall instructionÙ« <code class="language-plaintext highlighter-rouge">rax</code> holds the <a href="https://filippo.io/linux-syscall-table/">Linux syscall number</a>Ù« and <code class="language-plaintext highlighter-rouge">rdiÙ« rsiÙ« rdxÙ« r10Ù« r8Ù« r9</code> hold the arguments.</li>
  <li><strong>Step the process one instruction</strong> using the <code class="language-plaintext highlighter-rouge">PTRACE_SINGLESTEP</code> option to execute the syscall instruction.</li>
  <li><strong>Read the registers</strong> using <code class="language-plaintext highlighter-rouge">PTRACE_GETREGS</code> to retreive the syscall return value and see if it succeeded.</li>
</ol>

<h2 id="receiving-a-process-using-telepad">Receiving a process using <code class="language-plaintext highlighter-rouge">telepad</code></h2>

<p>Using this primitive and ones Iâ€™ve already described we can recreate the process:</p>

<ol>
  <li><strong>Fork a frozen child.</strong> Similar to sending except this time we need a child process we can manipulate to turn it into a clone of the process being streamed in.</li>
  <li><strong>Inspect the memory mappings.</strong> This time we need to know all the existing memory maps so we can remove them to make room for the incoming process.</li>
  <li><strong>Unmap the existing mappings.</strong> We loop over each of the mappings and manipulate the child process into calling <code class="language-plaintext highlighter-rouge">munmap</code> on them.</li>
  <li><strong>Remap the special kernel mappings.</strong> Read their destinations from the stream and use <code class="language-plaintext highlighter-rouge">mremap</code> to remap them to their target destination.</li>
  <li><strong>Stream in the new mappings.</strong> Use remote <code class="language-plaintext highlighter-rouge">mmap</code> to create the mappingsÙ« then <code class="language-plaintext highlighter-rouge">process_vm_writev</code> to stream memory pages into them.</li>
  <li><strong>Restore the registers.</strong> Use <code class="language-plaintext highlighter-rouge">PTRACE_SETREGS</code> to restore the registers for the main thread that were sent overÙ« with the exception of <code class="language-plaintext highlighter-rouge">rax</code> which is the return value for the <code class="language-plaintext highlighter-rouge">raise(SIGSTOP)</code> that the snapshotted process stopped onÙ« which we overwrite with an arbitrary integer passed to <code class="language-plaintext highlighter-rouge">telepad</code>.
    <ul>
      <li>The arbitrary value is used so the telefork server can pass the file descriptor of the TCP connection the process came in onÙ« so that it can send data backÙ« or in the case of <code class="language-plaintext highlighter-rouge">yoyo</code> execute a <code class="language-plaintext highlighter-rouge">telefork</code> back over the same connection.</li>
    </ul>
  </li>
  <li><strong>Restart the process</strong> with its brand new contents by using <code class="language-plaintext highlighter-rouge">PTRACE_DETACH</code>.</li>
</ol>

<h2 id="doing-more-things-properly">Doing more things properly</h2>

<p>Thereâ€™s a few things that are still broken in my implementation of <code class="language-plaintext highlighter-rouge">telefork</code>. I know how to fix them allÙ« but Iâ€™m satisfied with how much Iâ€™ve implemented and sometimes theyâ€™re tricky to fix. This describes a few interesting examples of those things:</p>

<ul>
  <li>Handling the vDSO properly. I <code class="language-plaintext highlighter-rouge">mremap</code> the vDSO in the same way that <a href="https://github.com/dmtcp/dmtcp/blob/7d02a2e063a8e70cc4d836d0b658124614666f44/src/mtcp/mtcp_restart.c#L813">DMTCP does</a> but that turns out to work only when restoring on the exact same kernel build. Copying the vDSO contents instead can work accross different builds of the same versionÙ« which is how I got my path tracing demo to work since getting the number of CPU cores in glibc checks the current time using the vDSO in order to cache the count. However the way to actually do it properly is to either patch all the vDSO functions to just execute syscall instructions like <code class="language-plaintext highlighter-rouge">rr</code> doesÙ« or to patch each vDSO function to jump to the vDSO function from the donor process.</li>
  <li>Restoring <code class="language-plaintext highlighter-rouge">brk</code> and other miscellaneous state. I tried to use a method from DMTCP to restore the <code class="language-plaintext highlighter-rouge">brk</code> pointer but it only works if the target <code class="language-plaintext highlighter-rouge">brk</code> is greater than the donorâ€™s <code class="language-plaintext highlighter-rouge">brk</code>. The correct way to do it that also restores other things is <code class="language-plaintext highlighter-rouge">PR_SET_MM_MAP</code>Ù« but that requires elevated permissions and a kernel build flag.</li>
  <li>Restoring thread local storage. Thread local storage in Rust seems to just workâ„¢ presumably because the FS and GS registers are restoredÙ« but thereâ€™s apparently some kind of <code class="language-plaintext highlighter-rouge">glibc</code> cache of the pid and tid that might mess up a different kind of thread local storage. One solution CRIU can do using fancy namespaces is restore the process with the same PID and TIDs.</li>
  <li>Restore some file descriptors. This could be done either using individual strategies for each type of file descriptorÙ« like checking if a file with the same name/contents exists on the destination systemÙ« or forwarding all reads/writes to the process source system using FUSE. However itâ€™s a ton of effort to support all the types of file descriptorsÙ« like running TCP connectionsÙ« so DMTCP and CRIU just painstakingly implement the most common types and give up on things like <code class="language-plaintext highlighter-rouge">perf_event_open</code> handles.</li>
  <li>Handling multiple threads. Normal Unix <code class="language-plaintext highlighter-rouge">fork()</code> doesnâ€™t do thisÙ« but it should just involve stopping all threads before the memory streamingÙ« then copying their registers and reinstating them in threads in the cloned process.</li>
</ul>

<h2 id="even-crazier-ideas">Even crazier ideas</h2>

<p>I think this shows that some crazy things you might have thought werenâ€™t possible can in fact be done given the right low level interfaces. Hereâ€™s some ideas extending on the basic telefork ideas that are totally possible to implementÙ« although perhaps only with a very new or patched kernel:</p>

<ul>
  <li><strong>Cluster telefork.</strong> The original inspiration for telefork was the idea of streaming a process onto every machine in a compute cluster. You could maybe even use UDP multicast or peer-to-peer techniques to make the distribution of memory to the whole cluster faster. You probably also want to provide communication primitives.</li>
  <li><strong>Lazy memory streaming.</strong> CRIU submitted patches to the kernel to add something called <code class="language-plaintext highlighter-rouge">userfaultfd</code> that can catch page faults and map in new pages more efficiently than <code class="language-plaintext highlighter-rouge">SIGSEGV</code> handlers and <code class="language-plaintext highlighter-rouge">mmap</code>. This can let you stream in new pages of memory only as they are accessed by the programÙ« allowing you to teleport processes with lower latency since they can start running basically right away.</li>
  <li><strong>Remote threads!</strong> You could transparently make a process think it was running on a machine with a thousand cores. You could use <code class="language-plaintext highlighter-rouge">userfaultfd</code> plus a <a href="https://patchwork.kernel.org/cover/11005675/">patch set for userfaultfd write protection</a> <a href="https://github.com/torvalds/linux/commit/63bef48fd6c9d3f1ba4f0e23b4da1e007db6a3c0">which was just merged earlier this month</a> to implement a cache-coherency algorithm like <a href="https://en.wikipedia.org/wiki/MESI_protocol">MESI</a> to replicate the process memory across a cluster of machines efficiently such that memory would only need to be transferred when one machine read a page another wrote to since its last read. Then threads are just sets of registers that are very cheap to distribute across machines by swapping them into the registers of pools of kernel threadsÙ« and intelligently rearrange so theyâ€™re on the same machine as other threads they communicate with. You could even make syscalls work by pausing on syscall instructionsÙ« transferring the thread to the original host machineÙ« executing the syscallÙ« then transferring back. This is basically the way your multi-core or multi-socket CPU works except using pages instead of cache lines and the network instead of buses. The same techniques like minimizing sharing between threads that work for multi-core programming would make programs run efficiently here. I think this could actually be very coolÙ« although it might need more kernel support to work seamlesslyÙ« but it could allow you to program a distributed cluster the same way you program a many-core machine and (with a bunch of optimization tricks I havenâ€™t yet written about) have it be competitively efficient with the distributed system you otherwise would have written.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>I think this stuff is really cool because itâ€™s an instance of one of my favourite techniquesÙ« which is diving in to find a lesser-known layer of abstraction that makes something that seems nigh-impossible actually not that much work. Teleporting a computation may seem impossibleÙ« or like it would require techniques like serializing all your stateÙ« copying a binary executable to the remote machineÙ« and running it there with special command line flags to reload the state. But underneath your favourite programming language thereâ€™s a layer of abstraction where you can choose a fairly simple subset of things that make it possible to teleport at least most pure computations in any language in 500 lines of code and a single weekend. I think this kind of diving down often leads to solutions that are simpler and more universal. Another one of my projects like this is <a href="https://blog.janestreet.com/commas-in-big-numbers-everywhere/">Numderline</a>.</p>

<p>Of courseÙ« they often seem like extremely cursed hacks and to a large extent they are. They do things in a way nobody expectsÙ« and when they break they break at a layer of abstraction they arenâ€™t supposed to break atÙ« like your file descriptors mysteriously dissapearing. Sometimes though you can hit the layer of abstraction just right and handle all the cases such that everything is seamless and magicÙ« I think good examples of this are <a href="https://github.com/mozilla/rr">rr</a> (although telefork manages to be cursed enough to segfault it) and cloud VM live migration (basically telefork at the hypervisor layer).</p>

<p>I also like thinking about these things as inspiration for alternative ways computer systems could work. Why are our cluster computing APIs so much more difficult to use than just running a program that broadcasts functions to the cluster? Why is networked systems programming so much harder than multithreaded programming? Sure you can give all sorts of good reasonsÙ« but theyâ€™re mostly based on how difficult it would be given how other existing systems work. Maybe with the right abstraction or with enough effort a project could seamlessly make it workÙ« it seems fundamentally possible.</p>
'),('http://thume.ca/2019/11/02/numderline-grouping-digits-using-opentype-shaping/', 'Numderline: Grouping digits using OpenType shaping', '1572652800000',  13, '
<p>I recently worked on a fun side project to make a font that used font shaping trickery to make it easier to read large numbers by underlining alternating digit groups or inserting fake commas.</p>

<p>I wrote about it on the Jane Street tech blog since I started work there recently and I came up with the idea to help me visually parse tables of latency numbers for my job.</p>

<p>You can read the post here: <a href="https://blog.janestreet.com/commas-in-big-numbers-everywhere/">https://blog.janestreet.com/commas-in-big-numbers-everywhere/</a></p>

<p><img src="/assets/postassets/numderline/numderline.png" alt="Screenshot of the font" /></p>

<p>You can also check out <a href="/numderline">the font demo and download site</a> and the <a href="https://github.com/trishume/numderline">Github repo for the font patcher</a>.</p>

<p>Thereâ€™s one other large public technical document Iâ€™ve written off of my own site that I might as well link here as wellÙ« which is my documentation of how the Xi text editorâ€™s CRDT works. Although itâ€™s written more as documentation than as a generally accessible blog postÙ« you may still find it interestingÙ« it has lots of diagrams. You can read it <a href="https://github.com/xi-editor/xi-editor/blob/e8065a3993b80af0aadbca0e50602125d60e4e38/doc/crdt-details.md">here</a></p>
'),('http://thume.ca/2019/07/29/shenanigans-with-hash-tables/', 'Shenanigans With Hash Tables', '1564358400000',  13, '
<p>One reason to know how your data structures work is so that when your problem has unusual constraints you can tweak how they work to fit the problem better or work faster. In this article Iâ€™ll talk about four different fun tweaks to the concept of a hash table that I made in the process of using hash tables to implement interface method lookup vtables in <a href="/2019/04/18/writing-a-compiler-in-rust/">my compilers class Java-subset compiler</a>. The fact that I knew the contents and lookups of all the tables at compile time allowed me to heavily optimize the way the hash table worked at run time until the common case was just indexing an array at a constant offset! Even outside the context of compilersÙ« I think this is an interesting source of inspiration for the ways you can tweak data structures for your purpose.</p>

<h2 id="background-on-vtables-and-interfaces">Background on vtables and interfaces</h2>

<p>For object-oriented languagesÙ« compilers usually use â€œ<a href="https://pabloariasal.github.io/2017/06/10/understanding-virtual-tables/">vtables</a>â€ to implement method dispatch. This is when every object has a pointer to an array of function pointers corresponding to the different methods on that object. Each method has a fixed slotÙ« with methods in base classes coming before inherited ones so that an object can be treated as its base class with the same offsets.</p>

<p>The problem is that implementing <a href="http://tutorials.jenkov.com/java/interfaces.html">interfaces</a> is harder since the vtable prefix trick doesnâ€™t work. Java HotSpot implements interface method calls doing a linear search over a list of â€œitablesâ€ for each interface an object implementsÙ« then using inline caching and fancy JIT specialization to speed that up in the common case.</p>

<p>The simpler alternative is to make a giant table of every method signature present in the program (for Java thatâ€™s name and parameter types like <code class="language-plaintext highlighter-rouge">addNums(intÙ«int)</code>)Ù« each class will have an instance of this table with the slots for methods it implements filled in (including ones inherited from superclasses)Ù« and most slots empty. Then for interface dispatch you can just use a fixed offset for the interface method signature: easy and fast. The problem is the size of each table scales with the size of the programÙ« and so does the number of tablesÙ« leading to <code class="language-plaintext highlighter-rouge">O(n^2)</code> scalingÙ« making this technique non-viable for large programs.</p>

<h2 id="hash-vtables">Hash vtables</h2>

<p><img src="/assets/postassets/hashvtables/basic-hash-table.png" alt="Basic Hash Table Diagram" /></p>

<p>Instead of using a giant fixed tableÙ« we can use a hash table from method signature to method pointer. Since every table doesnâ€™t need to be large enough to fit all method signatures in the entire programÙ« this solves the scaling problem. For simplicity weâ€™ll use <a href="http://www.cs.rmit.edu.au/online/blackboard/chapter/05/documents/contribute/chapter/05/linear-probing.html">linear probing</a> to handle the case when our hash tries to put two methods in the same slot: we put the colliding method in the next available slot.</p>

<p>However this is now much slower than simple tables. A simple hash table lookup with linear probing includes two operations that need to loop over the bytes in the signature as well as a probing loop:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="nc">TableEntry</span> <span class="p">{</span>
  <span class="kt">char</span> <span class="o">*</span><span class="n">signature</span><span class="p">;</span> <span class="c1">// assume signatures are strings for simplicity</span>
  <span class="kt">void</span> <span class="o">*</span><span class="n">fnAddr</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="o">*</span><span class="nf">lookup</span><span class="p">(</span><span class="n">TableEntry</span> <span class="o">*</span><span class="n">table</span><span class="p">Ù«</span> <span class="kt">size_t</span> <span class="n">tableSize</span><span class="p">Ù«</span> <span class="kt">char</span> <span class="o">*</span><span class="n">query</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">uint32_t</span> <span class="n">queryHash</span> <span class="o">=</span> <span class="n">hash</span><span class="p">(</span><span class="n">query</span><span class="p">);</span> <span class="c1">// &lt;- O(n) in signature length</span>
  <span class="c1">// look in the next slot if a collision bumped our target from its place</span>
  <span class="k">for</span><span class="p">(;;</span><span class="n">queryHash</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">queryHash</span> <span class="o">%=</span> <span class="n">tableSize</span><span class="p">;</span>
    <span class="n">TableEntry</span> <span class="n">entry</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="n">queryHash</span><span class="p">];</span>
    <span class="k">if</span><span class="p">(</span><span class="n">strcmp</span><span class="p">(</span><span class="n">query</span><span class="p">Ù«</span> <span class="n">entry</span><span class="p">.</span><span class="n">signature</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// &lt;- O(n) in signature length</span>
      <span class="k">return</span> <span class="n">entry</span><span class="p">.</span><span class="n">fnAddr</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Why use <code class="language-plaintext highlighter-rouge">queryHash %= tableSize</code> instead of just indexing with <code class="language-plaintext highlighter-rouge">queryHash % tableSize</code>? I did that in the initial draft of this postÙ« but then I realized it breaks when the initial hash is close to the maximum integer and probing causes <code class="language-plaintext highlighter-rouge">queryHash</code> to overflow to zero. That would have been a very evil bug since it would silently give the wrong result but only exceedingly rarely.</p>

<h2 id="hashing-at-compile-time">Hashing at compile time</h2>

<p><img src="/assets/postassets/hashvtables/comptime-table.png" alt="Compile Time Hash Table Diagram" /></p>

<p>First weâ€™ll take advantage of the fact that we know which signatures are going to be used for each method call lookup at compile timeÙ« so we can do the hashing at compile time and then just compare the hashes when probing. This way we donâ€™t even need to store the signatures in table for comparisonÙ« just the hashes.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="nc">TableEntry</span> <span class="p">{</span>
  <span class="kt">uint32_t</span> <span class="n">hash</span><span class="p">;</span>
  <span class="kt">void</span> <span class="o">*</span><span class="n">fnAddr</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="o">*</span><span class="nf">lookup</span><span class="p">(</span><span class="n">TableEntry</span> <span class="o">*</span><span class="n">table</span><span class="p">Ù«</span> <span class="kt">size_t</span> <span class="n">tableSize</span><span class="p">Ù«</span> <span class="kt">uint32_t</span> <span class="n">queryHash</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">for</span><span class="p">(;;</span><span class="n">queryHash</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">queryHash</span> <span class="o">%=</span> <span class="n">tableSize</span><span class="p">;</span>
    <span class="n">TableEntry</span> <span class="n">entry</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="n">queryHash</span><span class="p">];</span>
    <span class="k">if</span><span class="p">(</span><span class="n">entry</span><span class="p">.</span><span class="n">hash</span> <span class="o">==</span> <span class="n">queryHash</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">return</span> <span class="n">entry</span><span class="p">.</span><span class="n">fnAddr</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Now our method lookup is simple enough that we can viably translate it to assembly and insert a version of it at every method call site. In the common case of no probingÙ« branch prediction and out of order execution in modern processors should even make it so the cost over a normal vtable lookup is minimal!</p>

<h2 id="avoiding-collisions-with-rehashing">Avoiding collisions with rehashing</h2>

<p>The above approach has a problemÙ« which is that we stopped handling hash collisions. A method call could resolve incorrectly if two different signatures hash to the same thing. According to <a href="https://en.wikipedia.org/wiki/Birthday_problem">my most frequently referenced Wikipedia page</a>Ù« at 32 bits for our hash weâ€™re not safe from collisions in large programsÙ« even if we use a strong hash function.</p>

<p>My solution to this is to keep a table at compile time of which hash value Iâ€™m using for each signature. When Iâ€™m adding a new signature to the table I append an additional integer before hashingÙ« and if the resulting value collides with an existing hashÙ« then I increment the integer and hash again until I get a value that doesnâ€™t collide. This ensures that comparing signatures only by hash in the lookup is valid because hashes uniquely identify signatures.</p>

<h2 id="sizing-the-table-ahead-of-time">Sizing the table ahead of time</h2>

<p><img src="/assets/postassets/hashvtables/fixed-table.png" alt="Fixed Hash Table Diagram" /></p>

<p>In our above examples we need to pass in the table size to our lookup. If each class can have differently sized tablesÙ« we also need to store the size somewhere accessibleÙ« like index <code class="language-plaintext highlighter-rouge">-1</code> from the vtable pointer. However loading the size means probably loading another cache line in serialÙ« carrying a performance cost. The solution is to make all our hash vtables the same size.</p>

<p>The other problem is that the modulo operation is relatively expensiveÙ« having <a href="https://www.agner.org/optimize/instruction_tables.pdf">a latency of 20+ cycles</a>. For the initial lookup we can fix this by also doing the modulo at compile timeÙ« then moving the modulo to the probing case of the assembly stub. We can improve the probing case as well by making the table size always a power of 2Ù« and then using a bitwise AND with a constant mask (which has 1 cycle of latency).</p>

<p>In our compiler I computed a fixed power-of-2 table size ahead of time by figuring out how many method signatures the largest table needed to storeÙ« multiplying by an arbitrary factor of 4 to avoid collisions (and thus probing)Ù« then rounding up to a power of 2. I expect the size of classes follows a power law distribution so the largest class would scale with the log of the size of the programÙ« making total table space <code class="language-plaintext highlighter-rouge">O(n log n)</code> in program size.</p>

<h2 id="probing-only-when-necessary">Probing only when necessary</h2>

<p>My final idea was that when I was building the tables I could track which signature hashes ever collide in a table and get placed in a slot other than their home slotÙ« and thus may need probing. Then for all the signatures which never got placed outside their home slotÙ« I could just not generate the probing code at those call sites! Non-probing sites also donâ€™t need to check that the hash is equal (it always will be) and can do the modulo at compile timeÙ« making them just indexing a table.</p>

<p>The final probing and non-probing assembly method call stubs look something like this:</p>

<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">; == X86 Assembly for general case with probingÙ« call target in eax</span>
<span class="nf">mov</span> <span class="nb">eax</span><span class="p">Ù«</span> <span class="p">[</span><span class="nb">eax</span><span class="p">]</span> <span class="c1">; eax = address of object -&gt; eax = address of vtable</span>
<span class="nf">mov</span> <span class="nb">ebx</span><span class="p">Ù«</span> <span class="mi">61</span> <span class="c1">; the initial slot indexÙ« hash % size</span>
<span class="nl">.callcmp:</span>
<span class="nf">mov</span> <span class="nb">ecx</span><span class="p">Ù«</span> <span class="p">[</span><span class="nb">eax</span> <span class="o">+</span> <span class="nb">ebx</span><span class="o">*</span><span class="mi">8</span><span class="p">]</span> <span class="c1">; get the hash at the current slot</span>
<span class="nf">cmp</span> <span class="nb">ecx</span><span class="p">Ù«</span> <span class="mi">1062035773</span> <span class="c1">; check if it matches the expected hash</span>
<span class="nf">je</span> <span class="nv">.docall</span><span class="p">:</span> <span class="c1">; jump if it did match</span>
<span class="nf">add</span> <span class="nb">ebx</span><span class="p">Ù«</span> <span class="mi">1</span> <span class="c1">; if not probe to the next bucket</span>
<span class="nf">and</span> <span class="nb">ebx</span><span class="p">Ù«</span> <span class="mi">127</span> <span class="c1">; bit mask for computing i % 128 (the table size)</span>
<span class="nf">jmp</span> <span class="nv">.callcmp</span> <span class="c1">; check the hash again</span>
<span class="nl">.docall:</span>
<span class="nf">call</span> <span class="p">[</span><span class="nb">eax</span> <span class="o">+</span> <span class="nb">ebx</span><span class="o">*</span><span class="mi">8</span> <span class="o">+</span> <span class="mi">4</span><span class="p">]</span> <span class="c1">; indirect call to the function pointer</span>


<span class="c1">; == X86 Assembly for case without probingÙ« call target in eax</span>
<span class="nf">mov</span> <span class="nb">eax</span><span class="p">Ù«</span> <span class="p">[</span><span class="nb">eax</span><span class="p">]</span> <span class="c1">; eax = address of object -&gt; eax = address of vtable</span>
<span class="nf">call</span> <span class="p">[</span><span class="nb">eax</span> <span class="o">+</span> <span class="mi">492</span><span class="p">]</span> <span class="c1">; indirect call to the function at offset (hash%size)*8+4</span>
</code></pre></div></div>

<p>Our arbitrary max table size expansion factor of 4 lead to only 0.13% of method call sites in our test program corpus needing probingÙ« although larger programs would be less forgiving. This meant that in almost all cases my hash vtables emitted basically the same code as classic vtables wouldÙ« except that the same vtables also worked for interfaces as well! However the tables being larger than classic vtables in the non-interface case mean theyâ€™ll be less efficient with cache space and so would be somewhat slower in practice.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Iâ€™ve never heard of anyone implementing interface vtables in this wayÙ« but I wouldnâ€™t be surprised if there is prior art because these are all just simple insights you can have by thinking about how to specialize a hash table for this problem. I think LuaJit does some similar tricks for its hash tables where its tracing JIT can specialize on the hash value and optimize an index lookup plus bailing from the trace if the key doesnâ€™t match.</p>

<p>According to my compilers class professor thereâ€™s a broad literature of optimizing the â€œgiant table with all signaturesâ€ approach with heuristics for saving space by rearranging and merging the tables of different classes into the same space or re-using offsets across classes to make tables smaller. But the general problem is NP-complete so can only be solved heuristically. Interestingly I ended up with a kind of similar direction which re-uses offsets effectively randomlyÙ« but then includes a mechanism for handling the resulting collisions.</p>

<p>I hope you found some of these hash table tricks fun and came away inspired to think about how you might be able to modify a common data structure to fit your application better!</p>
'),('http://thume.ca/2019/07/27/two-performance-aesthetics/', 'Two Performance Aesthetics: Never Miss a Frame and Do Almost Nothing', '1564185600000',  13, '
<p>Iâ€™ve noticed when I think about performance nowadays that I think in terms of two different aesthetics. One aestheticÙ« which Iâ€™ll call <em>Never Miss a Frame</em>Ù« comes from the world of game development and is focused on writing code that has good worst case performance by making good use of the hardware. The other aestheticÙ« which Iâ€™ll call <em>Do Almost Nothing</em> comes from a more academic world and is focused on algorithmically minimizing the work that needs to be done to the extent that thereâ€™s barely any work leftÙ« paying attention to the performance at all scales. In this post Iâ€™ll describe the two aestheticsÙ« look at some case studies of pairs of programs in different domains that follow different aestheticsÙ« and talk about the trade-offs involved and how to choose which direction to lean for a project.</p>

<h2 id="never-miss-a-frame">Never Miss a Frame</h2>

<p>In game development the most important performance criteria is that your game doesnâ€™t miss frame deadlines. You have a target frame rate and if you miss the deadline for the screen to draw a new frame your users will notice the jank. This leads to focusing on the worst case scenario and often having fixed maximum limits for various quantities. This property can also be important in areas other than game developmentÙ« like other graphical applicationsÙ« <a href="http://www.rossbencina.com/code/real-time-audio-programming-101-time-waits-for-nothing">real-time audio</a>Ù« safety-critical systems and many embedded systems. A similar dynamic occurs in distributed systems where one server needs to query 100 others and combine the resultsÙ« youâ€™ll wait for the slowest of the 100 every time so speeding up some of them doesnâ€™t make the query fasterÙ« and queries occasionally taking longer (e.g because of garbage collection) will impact almost every request!</p>

<p>A consequence of deadlines is that itâ€™s not worth saving time unless you can save it in all cases. Things like caching often donâ€™t help because if the item isnâ€™t in the cache then youâ€™ll miss your deadline. The easiest way to achieve this is to just do all the work every single frame and donâ€™t keep anything between frames except for persistent state.</p>

<p>In this kind of domain youâ€™ll often run into situations where in the worst case you canâ€™t avoid processing a huge number of things. This means you need to focus your effort on making the best use of the hardware by writing code at a low level and paying attention to properties like cache size and memory bandwidth.</p>

<p>Projects with inviolable deadlines need to adjust different factors than speed if the code runs too slow. For example a game might decrease the size of a level or use a more efficient but less pretty rendering technique.</p>

<p>Aesthetically: Data should be tightly packedÙ« fixed sizeÙ« and linear. Transcoding data to and from different formats is wasteful. Strings and their variable lengths and inefficient operations must be avoided. Only use tools that allow you to work at a low levelÙ« even if theyâ€™re annoyingÙ« because thatâ€™s the only way you can avoid piles of fixed costs making everything slow. Understand the machine and what your code does to it.</p>

<p>Personally I identify this aesthetic most with <a href="https://www.youtube.com/user/jblow888">Jonathan Blow</a>. He has a very strong personality and Iâ€™ve watched enough of videos of him that I find imagining â€œWhat would Jonathan Blow say?â€ as a good way to tap into this aesthetic. My favourite articles about designs following this aesthetic are on the <a href="https://ourmachinery.com/post/">Our Machinery Blog</a>.</p>

<h2 id="do-almost-nothing">Do Almost Nothing</h2>

<p>SometimesÙ« itâ€™s important to be as fast as you can in all cases and not just orient around one deadline. The most common case is when you simply have to do something thatâ€™s going to take an amount of time noticeable to a humanÙ« and if you can make that time shorter in some situations thatâ€™s great. Alternatively each operation could be fast but you may run a server that runs tons of them and youâ€™ll save on server costs if you can decrease the load of some requests. Another important case is when you care about power useÙ« for example your text editor not rapidly draining a laptopâ€™s batteryÙ« in this case you want to do the least work you possibly can.</p>

<p>A key technique for this approach is to never recompute something from scratch when itâ€™s possible to re-use or patch an old result. This often involves caching: keeping a store of recent results in case the same computation is requested again.</p>

<p>The ultimate realization of this aesthetic is for the entire system to deal only in differences between the new state and the previous stateÙ« updating data structures with only the newly needed data and discarding data thatâ€™s no longer needed. This way each part of the system does almost no work because ideally the difference from the previous state is very small.</p>

<p>Aesthetically: Data must be in whatever structure scales best for the way it is accessedÙ« lots of trees and hash maps. Computations are graphs of inputs and results so we can use all our favourite graph algorithms to optimize them! Designing optimal systems is hard so you should use whatever tools you can to make it easierÙ« any fixed cost they incur will be made negligible when you optimize away all the work they need to do.</p>

<p>Personally I identify this aesthetic most with my friend <a href="https://www.patreon.com/raphlinus">Raph Levien</a> and his <a href="https://xi-editor.io/docs.html">articles about the design of the Xi text editor</a>Ù« although Raph also appreciates the other aesthetic and <a href="https://raphlinus.github.io/rust/graphics/gpu/2019/05/08/modern-2d.html">taps into it himself sometimes</a>.</p>

<h2 id="the-tradeoff">The Tradeoff</h2>

<p>Ideally it would be possible to follow both of these ideals simultaneouslyÙ« writing code that does the minimal amount of work as fast as the machine can possibly perform it. In some cases this is possible but in most cases developers have more important things to doÙ« or thereâ€™s a trade-off like caching slowing down the wost case. Iâ€™m conflating the axes of deadline-oriented vs time-oriented and low-level vs algorithmic optimizationÙ« but part of my point is that while they are differentÙ« I think these axes are highly correlated.</p>

<p>In practice when I see people set out to make a fast piece of softwareÙ« depending on the projectâ€™s goals and their backgroundÙ« they tend to lean towards one aesthetic or the other. If every operation in your software never lagsÙ« then thereâ€™s often no reason to save additional work. If youâ€™ve made everything in your system incremental to the point where everything is doing minimal workÙ« thereâ€™s little reason to optimize the operations at a low level since they take negligible time.</p>

<p>That isnâ€™t to say that people trying to make fast software shouldnâ€™t understand both approaches. You donâ€™t want to ignore either constant factors and the size of N in practiceÙ« or ignore the overall scaling and the quality of the algorithms youâ€™re using. For each task you may use mostly one approach or the otherÙ« but choosing the approach based on the task rather than always using only one or the other is a valuable skill.</p>

<h2 id="case-studies">Case Studies</h2>

<h3 id="gui-toolkits">GUI Toolkits</h3>

<p>In the olden daysÙ« GUIs were rendered with slow CPUs that couldnâ€™t quite render an entire screenâ€™s UI in one frame. This necessitated a <em>Do Almost Nothing</em> approach to GUI toolkitsÙ« where they kept track of the current state of the UI along with all sorts of saved computations like layout. Events would try to plumb minimal updates through the whole pipelineÙ« touching as little as possible and then redrawing only the rectangle on the screen that actually needed to be updatedÙ« like the single new character you typed. But some updates like opening a new window wouldnâ€™t be able to take advantage of this and might take multiple frames. This design is called â€œretained mode GUIâ€ and is still around today in most GUI toolkits (with some extensions to use the GPU for scrolling and drawing). Itâ€™s still around because it worksÙ« itâ€™s what people knowÙ« and it ended up good for battery life once laptops and smartphones arrived.</p>

<p>HoweverÙ« at some point computers and GPUs became powerful enough that it was possible to render an entire screen full of UI from scratch ever frame. This spawned an alternative approach called â€œimmediate mode GUIâ€ or â€œ<a href="https://github.com/ocornut/imgui">imgui</a>â€ where instead of creating persistent widgets that stick around and can cache computationsÙ« you just call functions that figure out how a widget should look and then write data to buffers for the GPU. This is super fast and will always render in one frame provided you donâ€™t render an absurd amount of UI. HoweverÙ« since itâ€™s harder for an imgui to cache things they canâ€™t easily do some things that retained mode UIâ€™s can doÙ« like render a long document of internationalized text scrolled to the bottom. All existing internationalized text shaping libraries are too slow to shape a long document in one frameÙ« so immediate mode GUI libraries usually just donâ€™t support internationalized text.</p>

<h3 id="text-editors">Text Editors</h3>

<p><a href="https://www.sublimetext.com/">Sublime Text</a> is a text editor that mostly follows the <em>Never Miss a Frame</em> approach. Basically every operation is instant because all the operations have been implemented very efficiently. HoweverÙ« some things like syntax highlighting donâ€™t quite run fast enough to be instant at large file sizes so Sublime does have infrastructure for caching highlightingÙ« and sometimes throws up progress bars when opening large files. Sublime makes trade-offs to use simple but efficient data structures by sacrificing performance in rare cases like editing extremely long lines. This architecture doesnâ€™t always deal well with external code that isnâ€™t designed to be instant thoughÙ« plugins that communicate with slow compilers can sometimes temporarily hang the editor.</p>

<p>The <a href="https://github.com/xi-editor/xi-editor">Xi Editor</a> is designed to solve this problem by being designed from the ground up to grapple with the fact that some operationsÙ« especially those interacting with slow compilers written by other peopleÙ« canâ€™t be made instantaneous. It does this using a fancy asynchronous plugin model and lots of fancy data structures. It tries to allow a native frontend for each platform despite the slowness of cross-language communication over JSON by only ever plumbing minimal deltas over the pipeÙ« so the slowness doesnâ€™t matter. It uses a fancy tree-based rope data structure to make even editing very long lines efficient. Many parts of this worked greatÙ« and Xi is extremely fast in many ways. The issue facing the Xi project today is that designing complex data structures and protocols to make every single operation incremental and asynchronous makes progress very slow.</p>

<p>An editor that leans into the <em>Never Miss a Frame</em> aesthetic even harder than Sublime Text is <a href="https://github.com/makepad/makepad">Makepad</a>. Itâ€™s a work-in-progress editor that uses an imgui-esque custom UI toolkit to render everythingÙ« making heavy use of the GPU. Layout and highlighting for the entire file is calculated every single frame by highly optimized code. This will drop frames on rare 10k line filesÙ« but for all other files allows fancy things other editors couldnâ€™t easily do like pressing <code class="language-plaintext highlighter-rouge">alt</code> to smoothly animate into an overlay of the functions in the whole file.</p>

<h3 id="compilers">Compilers</h3>

<p>Jonathan Blowâ€™s <a href="https://github.com/BSVino/JaiPrimer/blob/master/JaiPrimer.md">Jai</a> compiler is clearly designed with the <em>Never Miss a Frame</em> aesthetic. Itâ€™s written to be extremely fast at every levelÙ« and the language doesnâ€™t have any features that necessarily lead to slow compiles. The LLVM backend wasnâ€™t fast enough to hit his performance goals so he wrote an alternative backend that directly writes x86 code to a buffer without doing any optimizations. Jai compiles something like 100Ù«000 lines of code per second. Designing both the language and compiler to not do anything slow lead to clean build performance 10-100x faster than other commonly-used compilers. Jai is so fast that its clean builds are faster than most compilers incremental builds on common project sizesÙ« due to limitations in how incremental the other compilers are.</p>

<p>HoweverÙ« Jaiâ€™s compiler is still O(n) in the codebase size where incremental compilers can be O(n) in the size of the change. Some compilers like the work-in-progress <a href="https://github.com/rust-analyzer/rust-analyzer">rust-analyzer</a> and I think also <a href="https://github.com/dotnet/roslyn">Roslyn for C#</a> take a different approach and focus incredibly hard on making everything fully incremental. For small changes (the common case) this can let them beat Jai and respond in milliseconds on arbitrarily large projectsÙ« even if theyâ€™re slower on clean builds.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I find both of these aesthetics appealingÙ« but I also think thereâ€™s real trade-offs that incentivize leaning one way or the other for a given project. I think people having different performance aestheticsÙ« often because one aesthetic really is better suited for their domainÙ« is the source of a lot of online arguments about making fast systems. The different aesthetics also require different bases of knowledge to pursueÙ« like knowledge of data-oriented programming in C++ vs knowledge of abstractions for incrementality like <a href="http://adapton.org/">Adapton</a>Ù« so different people may find that one approach seems way easier and better for them than the other.</p>

<p>I try to choose how to dedicate my effort to pursuing each aesthetics on a per project basis by trying to predict how effort in each direction would help. Some projects I know if I code it efficiently it will always hit the performance deadlineÙ« others I know a way to drastically cut down on work by investing time in algorithmic designÙ« some projects need a mix of both. Personally I find it helpful to think of different programmers where I have a good sense of their aesthetic and ask myself how theyâ€™d solve the problem. One reason I like <a href="http://rust-lang.org/">Rust</a> is that it can do both <a href="https://doc.rust-lang.org/1.29.1/std/arch/index.html">low-level optimization</a> and also has a good <a href="https://crates.io/keywords/data-structures">ecosystem</a> and <a href="https://doc.rust-lang.org/beta/rust-by-example/custom_types/enum.html">type system</a> for algorithmic optimizationÙ« so I can more easily mix approaches in one project. In the end the best approach to follow depends not only on the taskÙ« but your skills or the skills of the team working on itÙ« as well as how much time you have to work towards an ambitious design that may take longer for a better result.</p>
'),('http://thume.ca/2019/07/26/writing-a-beat-saber-patcher/', 'Writing a Beat Saber Patcher for the Oculus Quest', '1564099200000',  13, '
<p>After trying out VR and <a href="https://beatsaber.com/">Beat Saber</a> at <a href="https://www.ctrlv.ca/">Ctrl-V</a> and really enoying itÙ« I decided to pre-order an <a href="https://www.oculus.com/quest/">Oculus Quest</a>Ù« the first standalone VR headset with <a href="https://en.wikipedia.org/wiki/Six_degrees_of_freedom">6 DOF</a> head and hand tracking. As expected I really enjoyed playing Beat Saber and practicing to play more difficult songsÙ« but I also ended up getting wrapped up in the Beat Saber modding community and developing <a href="https://github.com/trishume/QuestSaberPatch">a patcher</a> for adding custom songs which has been downloaded 80Ù«000 times. I figured out how to read and modify the <a href="https://unity.com/">Unity</a> asset file format used by Beat SaberÙ« learned C#Ù« and <a href="https://github.com/trishume/QuestSaberPatch">wrote a patcher</a> that could read in the gameâ€™s assetsÙ« modify them to add custom songsÙ« and modify the APK in-place with the replaced asset files.</p>

<h2 id="early-discoveries">Early Discoveries</h2>

<p>I started off by joining the <a href="https://discordapp.com/invite/beatsabermods">Beat Saber Modding Group Discord</a> chat while my Quest was still shippingÙ« and chatting with the other modders who were eager to figure out how to add custom songs to Beat Saber on the Quest like they have with the PC version. I didnâ€™t have anything to poke at myself yet but I could still chime in with ideasÙ« and I created a Google Doc where I collated and documented other peopleâ€™s discoveriesÙ« which I encouraged other people to edit and write things in as they experimented.</p>

<p>Over a couple days we figured out that Beat Saber was compiled with <a href="https://docs.unity3d.com/Manual/IL2CPP.html">IL2CPP</a> so modding the C# code would be trickyÙ« but while the levels were stored in a different format than the PC gameÙ« they were stored in the Unity asset bundles present in the APK. Some people who had Unity modding tools installed that could read and modify Unity asset files looked at the assets and found the levels but the beat maps looked like indecipherable compressed or encrypted dataÙ« then through some digging in disassembly and deduction <a href="https://github.com/emulamer">emulamer</a> figured out that it was the same data types the PC version used for levelsÙ« just encoded with C#â€™s <a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.serialization.formatters.binary.binaryformatter?view=netframework-4.8">BinaryFormatter</a> and then run through a <a href="https://docs.microsoft.com/en-us/dotnet/api/system.io.compression.deflatestream?view=netframework-4.8">DeflateStream</a>.</p>

<p>With this information <a href="https://github.com/emulamer">emulamer</a> could convert PC beatmaps (maps of the patterns of blocks to slash along with the song) to the format that went inside the Unity asset. This could then be patched into an APK using a Unity modding tool like <a href="http://www.devxdevelopment.com/">DevX</a>. HoweverÙ« we had noticed that levels contained a signature field so we suspected this wouldnâ€™t work on its own and it didnâ€™tÙ« but it turned out the demo version didnâ€™t check the signature and this lead to <a href="https://www.youtube.com/watch?v=ikQhUqDh56c">the first successful test</a>. We still needed to patch the signature check in the full version thoughÙ« so I tried poking around in <a href="https://binary.ninja/">Binary Ninja</a> but couldnâ€™t get anywhere because the library with all the code didnâ€™t have symbols for the function names in it. However people on Windows were able to use tools like <a href="https://github.com/Perfare/Il2CppDumper">Il2CppDumper</a> to get symbolsÙ« and <a href="https://github.com/emulamer">emulamer</a> found the signature check and figured out an ARM machine code patch to replace the call to the verify signature function with a constant true. <a href="https://www.youtube.com/watch?v=o6QDfJ_OHLc">Elliot Tate used DevX and this knowledge to perform the first successful patch of the full game</a>.</p>

<h2 id="figuring-out-the-format">Figuring Out the Format</h2>

<p>So we knew how to patch in custom songsÙ« the problem was we only knew how to do it with closed-source Windows GUI applications like DevXÙ« which wasnâ€™t going to help us deliver custom songs to lots of peopleÙ« and as a macOS user it wasnâ€™t going to help me. We needed to figure out how to patch Unity assets ourselves. So I did some Googling and while I didnâ€™t find any open source code that could <em>modify</em> Unity assetsÙ« I did find <a href="https://github.com/Perfare/AssetStudio">code that could read them</a>. Now I just needed to extract an understanding of the asset file format from that code so I could write my own code that could read and modify.</p>

<p>I had heard about <a href="https://kaitai.io/">Kaita Struct</a> which lets you write descriptions of a binary format and it will parse it into a tree in a nice IDE for youÙ« but when I tried it I found the IDE really slowÙ« cumbersome and kinda broken. The format was also very declarative and verbose and I found it hard to use. So I considered buying <a href="https://www.synalysis.net/">Synalyze It</a>Ù« which is a native macOS hex editor with similar capabilitiesÙ« but its specification system seemed just as limited. Then (for some reason I forget) I realized that my version of <a href="https://ridiculousfish.com/hexfiend/">Hex Fiend</a> was many years oldÙ« and went looking for a newer versionÙ« which I found on <a href="https://github.com/ridiculousfish/HexFiend/releases">their Github</a>. In the changelog I saw that they had very recently added <a href="https://github.com/ridiculousfish/HexFiend/blob/master/templates/Tutorial.md">support for Binary Templates</a>Ù« which used Tcl (a fully featured programming language!)Ù« this was exactly what I was looking for!</p>

<p>So I gradually put together <a href="https://gist.github.com/trishume/138ef8f6c66fabd2d76b9fdf8d5c4c67">a Hex Fiend template for Unity assets</a> by figuring out open source asset loading code and adding more fieldsÙ« debugging by reloading the template in Hex Fiend and checking the parse in the tree view to see that the values made sense. Eventually I figured out all the parts of the file necessary to mod in custom levels. The Hex Fiend template was invaluable for making it really easy to write a quick parser and debug my understanding against the real files. It was also valuable later on when I could look at the output of my patcher in a pretty tree view.</p>

<p>I also needed to figure out how the audio files referenced by the audio assets were included. I was originally worried it would be complex because the built-in songs were packed into concatenated resources in the proprietary <a href="http://fileformats.archiveteam.org/wiki/FMOD_Sample_Bank">FSB5</a> format that I thought I might need to reverse-engineer. However upon further testing it turned out we could just drop <code class="language-plaintext highlighter-rouge">.ogg</code> files in the APK and reference them as offset 0 in a resource packÙ« and Unity could load them.</p>

<h2 id="writing-a-patcher">Writing a Patcher</h2>

<p>Now I needed to write a patcher program that could take a Beat Saber APK and some custom songs in the PC JSON formatÙ« and produce an APK with the custom songs. I decided to use C# even though I had never used it beforeÙ« because then I wouldnâ€™t need to reverse-engineer the <code class="language-plaintext highlighter-rouge">BinaryFormatter</code> format used for the beatmap conversionÙ« and itâ€™s a nice enough language that works cross-platform. I also decided to structure my patcher as a library so it could be theoretically used in multiple different front endsÙ« possibly including a C#-based GUIÙ« as well as a command line tool and unit tests.</p>

<p>I started by writing <a href="https://github.com/trishume/QuestSaberPatch/blob/7a76d4e2e198c42584087281649af7efd2de4da9/LibSaberPatch/SerializedAssets.cs">a parser for the asset file format</a> that parsed it into C# classesÙ« but classes with a structure carefully designed so that they preserved all the information necessary to recreate the file exactlyÙ« while being straightforward to modify. This involved combining the separate directory and contents of the file format into a unified list of assets with no offsetsÙ« and ensuring that I saved amounts of padding in fields in relevant objects. Then I wrote the functions to write those classes back out to an assets file. I used <a href="https://github.com/trishume/QuestSaberPatch/blob/7a76d4e2e198c42584087281649af7efd2de4da9/tests/SerializedAssetTests.cs#L21">a unit test</a> to check that I could parse and then write out an assets file to a byte-identical one with no errorsÙ« starting with a small file and fixing bugs until I could round-trip the main assets file with all the levels.</p>

<p>After that worked I implemented loading the JSON level files and modifying my assets file data structure to insert the new levels into the existing â€œExtrasâ€ level pack. I also needed to copy the audio files into the APK and patch the binary to disable the level signature check. I needed to modify the APK fileÙ« but I didnâ€™t want to use the normal method of unzipping it (APKs are just zip files) into a temporary location and then zipping it back upÙ« so I used the standard library <a href="https://docs.microsoft.com/en-us/dotnet/api/system.io.compression.ziparchive?view=netframework-4.8">ZipArchive</a> functionality which allowed me to modify the Zip file in-place.</p>

<p>After I got all this working and tested I just needed to write a small command line tool using the library I had written. This allowed me to patch my own Beat Saber for the first time and play my first custom level on my own Oculus Quest!</p>

<h2 id="the-competition">The Competition</h2>

<p>All this timeÙ« <a href="https://github.com/emulamer">emulamer</a> had also been working on his own patcher with a similar approach to mine. He was making faster progress than meÙ« and patched in his first songs somewhat before I didÙ« and by the time I patched in my first songs his patcher had already been packaged into a Windows GUI by someone else and people were using it. It also supported things mine didnâ€™t yet like cover art and a separate â€œCustom Levelsâ€ pack instead of just putting things in the existing â€œExtrasâ€ pack.</p>

<p>I persisted though because I was having fun and my patcher had some differentiating factors that I imagined could make it competitive with more work:</p>

<ul>
  <li>Emulamerâ€™s code was by his own admission very hacky and he was just trying to get it to work as fast as possible and fix it up later.</li>
  <li>Many parts of his patching process were controlled by a batch file and it didnâ€™t work in-place on the APK like mine.</li>
  <li>His patcher wasnâ€™t structured as a library and it would be a bunch of refactoring to make it present anything other than one command-line interface.</li>
  <li>I had been using DotNet Core on macOS from the start so I knew my patcher should work cross-platformÙ« whereas his wasnâ€™t designed to work on other platforms.</li>
</ul>

<p>So I set out to add more functionality to my patcher to compete!</p>

<h2 id="catching-up">Catching Up</h2>

<p>The first thing I did is add support for song cover art. I knew that <a href="https://github.com/emulamer">emulamer</a>â€™s cover art gave the game frame rate issuesÙ« which he assumed was because he didnâ€™t resize textures and use texture compression. But when I looked at how the covers from the base game were storedÙ« I noticed they didnâ€™t use any compression but they did use <a href="https://en.wikipedia.org/wiki/Mipmap">mipmaps</a>Ù« and lack of mipmaps definitely seemed like it could explain the lag. Looking at the cover data in my hex editor I noticed a repeating pattern that got higher-frequency further into the coverÙ« so I guessed that it was probably raw RGB data for all the mip levels concatenated together. I checked what my guess would predict the file size would be against the actual file size and it matched exactly. So I <a href="https://github.com/trishume/QuestSaberPatch/commit/0c9e8be6279c1ee85e6bb9f9ff50151c2a21a467">added support for covers</a> with concatenated mipmaps of the size from the base game using <a href="https://github.com/SixLabors/ImageSharp">ImageSharp</a>. I let <a href="https://github.com/emulamer">emulamer</a> know about the mipmapping so he could reference the code and fix his frame rate issues.</p>

<p>Then I noticed a developer of <a href="https://sidequestvr.com">SideQuest</a> (a popular Electron GUI for side-loading apps onto the Oculus Quest) mentioning in the Discord that he was working on adding Beat Saber custom song support to SideQuest. I used the power of my patcher being a library to throw together a separate command line binary that used a JSON interface over stdin/stdout to provide an easy programmatic interface with more control. Then I included it in the <a href="https://github.com/trishume/QuestSaberPatch/pull/1">cross-platform CI builds that raftario contributed</a>Ù« which used DotNet coreâ€™s ability to build a self-contained folder that includes the C# runtime and compiled program IL. I chatted with the SideQuest developer and pitched him on using my patcher because of the convenient cross-platform binaries with a uniform easy interface that could patch in-place.</p>

<p>The last major remaining obstacle to an easy cross-platform patcher was that after patching the APK needed to be signed using a Java-based JAR signerÙ« requiring users to have 64-bit Java installed. Emulamer and I chatted about this and decided it seemed feasible to write a signer in C#Ù« which he managed to do fairly quickly and let me use his codeÙ« and in turn I figured out how to speed up the signing by a lot and let him know how to improve the speed in his own patcher.</p>

<p>Soon my patcher was incorporated in a SideQuest release that people could use to (somewhat) easily patch custom songs into their Beat Saber!</p>

<h2 id="finishing-touches">Finishing Touches</h2>

<p>At this point <a href="https://github.com/sc2ad">sc2ad</a> had started working on my codebase and adding support for custom saber colorsÙ« removing songsÙ« and custom packs. His code was still experimentalÙ« but I worked with him and did a lot of refactoring myself to integrate his code with how I wanted my patcher to work and eventually merged all of his work into <code class="language-plaintext highlighter-rouge">master</code>. As part of this process I wrote a new JSON-based command line with a new interface that allowed creating unlimited custom packs and organizing and ordering songs within them. The new code would then take an APK and synchronize the state with the songs you requested: addingÙ« removing and rearranging the minimal amount necessary to update the APK quickly.</p>

<p>I let the SideQuest developer I talked to know these capabilities were coming and the SideQuest team developed an awesome interface for organizing your songs into custom playlists and synchronizing them. Soon the new version of my patcher was integrated into SideQuest and released to the world.</p>

<p>I had been scaling down the amount of time I spent working on Beat Saber patchingÙ« but as Beat Saber released updated versions I continued to update my patcher to be compatible with the new versions and improve its reliability. One of the Beat Saber updates removed the <code class="language-plaintext highlighter-rouge">BinaryFormatter</code> based beatmaps and switched to just JSON strings in the same format as the PC version with no signaturesÙ« which means eventually there was no reason my patcher needed to be in C# instead of my preferred Rust but I had already written thousands of lines of code so there was no point in switching.</p>

<p>Eventually things were working smoothly enough and I announced my intent to retire from Beat Saber patching and work on other things. SideQuest continued to be used by tons of peopleÙ« with my patcher (downloaded automatically when people tried to use the SideQuest Beat Saber functionality) racking up 80Ù«000 downloads.</p>

<h2 id="the-next-chapter">The Next Chapter</h2>

<p>Emulamer hadnâ€™t stopped working on Beat Saber patching thoughÙ« after I retired he continued plugging away and eventually released <a href="https://github.com/emulamer/BeatOn">BeatOn</a>. BeatOn is an on-device patcher than uses a <a href="https://github.com/jakibaki/beatsaber-hook">C hook injection system by jakibaki</a> to redirect asset loading to mutable Android <code class="language-plaintext highlighter-rouge">/sdcard/</code> storage. This means that you can load new songs on your Quest and it doesnâ€™t have to re-sign and re-install the APK so its faster. It also supports installing hook and asset mods for things like custom sabers and better swing score feedback. SideQuest also recently added support for installing BeatOnÙ« accessing its UI from your computerÙ« and copying your SideQuest song library to BeatOn. Itâ€™s basically completely replaced my patcher and is better in many waysÙ« Iâ€™m glad for the progress and now use it myself.</p>

<h2 id="conclusion">Conclusion</h2>

<p>My Beat Saber patching journey is now over but it was a fun one. I learned a bunch from figuring out how to mod a game in practiceÙ« as well as some C# programming. I also had fun collaborating with everyone on the BSMG Discord and figuring out how Beat Saber worked with them. Competing with <a href="https://github.com/emulamer">emulamer</a> was also a fun experience since I think we both benefitted from trying to implement cool things the other hadnâ€™t and then letting each other take the ideas or code so that both of our patchers could improveÙ« it was a very fun friendly casual competition. I think it was a good use of some of my summerÙ« I had fun doing itÙ« Iâ€™ve been playing Beat Saber nearly every day enjoying my custom songs and now can comfortably play at expert+ levelÙ« and many people have presumably also had fun with their custom levels through SideQuest and my patcher.</p>

'),('http://thume.ca/2019/07/14/a-tour-of-metaprogramming-models-for-generics/', 'Models of Generics and Metaprogramming: GoÙ« RustÙ« SwiftÙ« D and More', '1563062400000',  13, '
<p>In some domains of programming itâ€™s common to want to write a data structure or algorithm that can work with elements of many different typesÙ« such as a generic list or a sorting algorithm that only needs a comparison function. Different programming languages have come up with all sorts of solutions to this problem: From just pointing people to existing general features that can be useful for the purpose (e.g CÙ« Go) to generics systems so powerful they become Turing-complete (e.g. <a href="https://sdleffler.github.io/RustTypeSystemTuringComplete/">Rust</a>Ù« <a href="http://matt.might.net/articles/c++-template-meta-programming-with-lambda-calculus/">C++</a>). In this post Iâ€™m going to take you on a tour of the generics systems in many different languages and how they are implemented. Iâ€™ll start from how languages without a special generics system like C solve the problem and then Iâ€™ll show how gradually adding extensions in different directions leads to the systems found in other languages.</p>

<p>One reason I think generics are an interesting case is that theyâ€™re a simple case of the general problem of metaprogramming: writing programs that can generate classes of other programs. As evidence Iâ€™ll describe how three different fully general metaprogramming methods can be seen as extensions from different directions in the space of generics systems: dynamic languages like PythonÙ« procedural macro systems like <a href="https://wiki.haskell.org/A_practical_Template_Haskell_Tutorial">Template Haskell</a>Ù« and staged compilation like <a href="https://ziglang.org/#Generic-data-structures-and-functions">Zig</a> and <a href="http://terralang.org/">Terra</a>.</p>

<h2 id="overview">Overview</h2>

<p>I made a flow chart of all the systems I discuss to give you an overview of what this post will contain and how everything fits together:</p>

<p><a href="/assets/postassets/generics/flowchart.pdf"><img src="/assets/postassets/generics/flowchart-2x.png" alt="Timing" /></a></p>

<h2 id="the-basic-ideas">The basic ideas</h2>

<p>Letâ€™s say weâ€™re programming in a language without a generics system and we want to make a generic stack data structure which works for any data type. The problem is that each function and type definition we write only works for data thatâ€™s the same sizeÙ« is copied the same wayÙ« and generally acts the same way.</p>

<p>Two ideas for how to get around this are to find a way to make all data types act the same way in our data structureÙ« or to make multiple copies of our data structure with slight tweaks to deal with each data type the correct way. These two ideas form the basis of the two major classes of solutions to generics: â€œboxingâ€ and â€œmonomorphizationâ€.</p>

<p>Boxing is where we put everything in uniform â€œboxesâ€ so that they all act the same way. This is usually done by allocating things on the heap and just putting pointers in the data structure. We can make pointers to all different types act the same way so that the same code can deal with all data types! However this can come at the cost of extra memory allocationÙ« dynamic lookups and cache misses. In C this corresponds to making your data structure store <code class="language-plaintext highlighter-rouge">void*</code> pointers and just casting your data to and from <code class="language-plaintext highlighter-rouge">void*</code> (allocating on the heap if the data isnâ€™t already on the heap).</p>

<p>Monomorphization is where we copy the code multiple times for the different types of data we want to store. This way each instance of the code can directly use the size and methods of the data it is working withÙ« without any dynamic lookups. This produces the fastest possible codeÙ« but comes at the cost of bloat in code size and compile times as the same code with minor tweaks is compiled many times. In C this corresponds to <a href="https://www.cs.grinnell.edu/~rebelsky/musings/cnix-macros-generics">defining your entire data structure in a macro</a> and calling it for each type you want to use it with.</p>

<p>Overall the tradeoff is basically that boxing leads to better compile times but can hurt runtime performanceÙ« whereas monomorphization will generate the fastest code but takes extra time to compile and optimize all the different generated instances. They also differ in how they can be extended: Extensions to boxing allow more dynamic behavior at runtimeÙ« while monomorphization is more flexible with how different instances of generic code can differ. Itâ€™s also worth noting that in some larger programs the performance advantage of monomorphization might be canceled out by the additional instruction cache misses from all the extra generated code.</p>

<p>Each of these schools of generics has many directions it can be extended in to add additional power or safetyÙ« and different languages have taken them in very interesting directions. Some languages like Rust and C# even provide both options!</p>

<h2 id="boxing">Boxing</h2>

<p>Letâ€™s start with an example of the basic boxing approach in Go:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">type</span> <span class="n">Stack</span> <span class="k">struct</span> <span class="p">{</span>
  <span class="n">values</span> <span class="p">[]</span><span class="k">interface</span><span class="p">{}</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">this</span> <span class="o">*</span><span class="n">Stack</span><span class="p">)</span> <span class="n">Push</span><span class="p">(</span><span class="n">value</span> <span class="k">interface</span><span class="p">{})</span> <span class="p">{</span>
  <span class="n">this</span><span class="o">.</span><span class="n">values</span> <span class="o">=</span> <span class="nb">append</span><span class="p">(</span><span class="n">this</span><span class="o">.</span><span class="n">values</span><span class="p">Ù«</span> <span class="n">value</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">this</span> <span class="o">*</span><span class="n">Stack</span><span class="p">)</span> <span class="n">Pop</span><span class="p">()</span> <span class="k">interface</span><span class="p">{}</span> <span class="p">{</span>
  <span class="n">x</span> <span class="o">:=</span> <span class="n">this</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">this</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">-</span><span class="m">1</span><span class="p">]</span>
  <span class="n">this</span><span class="o">.</span><span class="n">values</span> <span class="o">=</span> <span class="n">this</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="o">:</span><span class="nb">len</span><span class="p">(</span><span class="n">this</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">-</span><span class="m">1</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">x</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Example languages that use basic boxing: C (<code class="language-plaintext highlighter-rouge">void*</code>)Ù« Go (<code class="language-plaintext highlighter-rouge">interface{}</code>)Ù« pre-generics Java (<code class="language-plaintext highlighter-rouge">Object</code>)Ù« pre-generics Objective-C (<code class="language-plaintext highlighter-rouge">id</code>)</p>

<h2 id="type-erased-boxed-generics">Type-erased boxed generics</h2>

<p>Hereâ€™s some problems with the basic boxing approach:</p>

<ul>
  <li>Depending on the language we often need to cast values to and from the correct type every time we read or write to the data structure.</li>
  <li>Nothing stops us from putting elements of different types into the structureÙ« which could allow bugs that manifest as runtime crashes.</li>
</ul>

<p>A solution to both of these problems is to add generics functionality to the type systemÙ« while still using the basic boxing method exactly as before at runtime. This approach is often called type erasureÙ« because the types in the generics system are â€œerasedâ€ and all become the same type (like <code class="language-plaintext highlighter-rouge">Object</code>) under the hood.</p>

<p>Java and Objective-C both started out with basic boxingÙ« and later added language features for generics with type erasureÙ« even using the exact same collection types as before for compatibilityÙ« but with optional generic type parameters. See the following example from the <a href="https://en.wikipedia.org/wiki/Generics_in_Java">Wikipedia article on Java Generics</a>:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">List</span> <span class="n">v</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ArrayList</span><span class="o">();</span>
<span class="n">v</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="s">"test"</span><span class="o">);</span> <span class="c1">// A String that cannot be cast to an Integer</span>
<span class="nc">Integer</span> <span class="n">i</span> <span class="o">=</span> <span class="o">(</span><span class="nc">Integer</span><span class="o">)</span><span class="n">v</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span> <span class="c1">// Run time error</span>

<span class="nc">List</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">v</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ArrayList</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;();</span>
<span class="n">v</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="s">"test"</span><span class="o">);</span>
<span class="nc">Integer</span> <span class="n">i</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span> <span class="c1">// (type error) compilation-time error</span>
</code></pre></div></div>

<h3 id="inferred-boxed-generics-with-a-uniform-representation">Inferred boxed generics with a uniform representation</h3>

<p>OCaml takes this idea even further with a uniform representation where there are no primitive types that require an additional boxing allocation (like <code class="language-plaintext highlighter-rouge">int</code> needing to be turned into an <code class="language-plaintext highlighter-rouge">Integer</code> to go in an <code class="language-plaintext highlighter-rouge">ArrayList</code> in Java)Ù« because everything is either already boxed or represented by a pointer-sized integerÙ« so everything is one machine word. However when the garbage collector looks at data stored in generic structures it needs to tell pointers from integersÙ« so integers are tagged using a 1 bit in a place where valid aligned pointers never have a 1 bitÙ« leaving only 31 or 63 bits of range.</p>

<p>OCaml also has a type inference system so you can write a function and the compiler will infer the most generic type possible if you donâ€™t annotate itÙ« which can lead to functions that look like a dynamically typed language:</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">first</span> <span class="p">(</span><span class="n">head</span> <span class="o">::</span> <span class="n">tail</span><span class="p">)</span> <span class="o">=</span> <span class="n">head</span>
<span class="c">(* inferred type: "a list -&gt; "a *)</span>
</code></pre></div></div>

<p>The inferred type is read as â€œa function from a list of elements of type <code class="language-plaintext highlighter-rouge">"a</code> to something of type <code class="language-plaintext highlighter-rouge">"a</code>â€. Which encodes the relation that the return type is the same as the list type but can be any type.</p>

<h2 id="interfaces">Interfaces</h2>

<p>A different limitation in the basic boxing approach is that the boxed types are <em>completely</em> opaque. This is fine for data structures like a stackÙ« but things like a generic sorting function need some extra functionalityÙ« like a type-specific comparison function. Thereâ€™s a number of different ways of both implementing this at runtime and exposing this in the languageÙ« which are technically different axes and you can <a href="http://okmij.org/ftp/Computation/typeclass.html">implement the same language using multiple of these approaches</a>. HoweverÙ« it seems like different language features mostly lend themselves towards being implemented a certain wayÙ« and then language extensions take advantage of the strengths of the chosen implementation. This means thereâ€™s mostly two families of languages based around the different runtime approaches: vtables and dictionary passing.</p>

<h3 id="interface-vtables">Interface vtables</h3>

<p>If we want to expose type-specific functions while sticking with the boxing strategy of a uniform way of working with everythingÙ« we can just make sure that thereâ€™s a uniform way to find the type-specific function we want from an object. This approach is called using â€œvtablesâ€ (shortened from â€œvirtual method tablesâ€ but nobody uses the full name) and how it is implemented is that at offset zero in every object in the generic structure is a pointer to some tables of function pointers with a consistent layout. These tables allow the generic code to look up a pointer to the type-specific functions in the same way for every type by indexing certain pointers at fixed offsets.</p>

<p>This is how <code class="language-plaintext highlighter-rouge">interface</code> types are implemented in Go and <code class="language-plaintext highlighter-rouge">dyn</code> <code class="language-plaintext highlighter-rouge">trait</code> objects are implemented in Rust. When you cast a type to an interface type for something it implementsÙ« it creates a wrapper that contains a pointer to the original object and a pointer to a vtable of the type-specific functions for that interface. However this requires an extra layer of pointer indirection and a different layoutÙ« which is why sorting in Go uses <a href="https://golang.org/pkg/sort/#Interface">an interface for the container with a Swap method</a> instead of taking a slice of a <code class="language-plaintext highlighter-rouge">Comparable</code> interfaceÙ« because it would require allocating an entire new slice of the interface types and then it would only sort that and not the original slice!</p>

<h3 id="object-oriented-programming">Object-oriented programming</h3>

<p>Object oriented programming is a language feature that makes good use of the power of vtables. Instead of having separate interface objects that contain the vtablesÙ« object-oriented languages like Java just have a vtable pointer at the start of every object. Java-like languages have a system of inheritance and interfaces that can be implemented entirely with these object vtables.</p>

<p>As well as providing additional featuresÙ« embedding vtables in every object also solves the earlier problem of needing to construct new interface types with indirection. Unlike <code class="language-plaintext highlighter-rouge">Go</code>Ù« in Java <a href="https://docs.oracle.com/javase/7/docs/api/java/util/Arrays.html#sort(java.lang.Object[])">the sorting function</a> can just use the <code class="language-plaintext highlighter-rouge">Comparable</code> interface on types that implement it.</p>

<h3 id="reflection">Reflection</h3>

<p>Once you have vtablesÙ« itâ€™s not too difficult to have the compiler also generate tables of other type information like field namesÙ« types and locations. This allows accessing all the data in a type with the same code that can inspect all the data in any other type. This can be used to add a â€œreflectionâ€ feature to your language which can be used to implement things like serialization and pretty printing for arbitrary types. As an extension of the boxing paradigm it has the same tradeoff that it only requires one copy of the code but requires a lot of slow dynamic lookupsÙ« which can lead to slow serialization performance.</p>

<p>Examples of languages with reflection features they use for serialization and other things include JavaÙ« C# and Go.</p>

<h3 id="dynamically-typed-languages">Dynamically typed languages</h3>

<p>Reflection is very powerful and can do a lot of different metaprogramming tasksÙ« but one thing it canâ€™t do is create new types or edit the type information of existing values. If we add the ability to do thisÙ« as well as make the default access and modification syntaxes go through reflectionÙ« we end up with dynamically typed languages! The incredibly flexibility to do metaprogramming in languages like Python and Ruby comes from effectively super-powered reflection systems that are used for everything.</p>

<p>â€œBut TristanÙ« thatâ€™s not how dynamic languages workÙ« they just implement everything with hash tables!â€ you may say. WellÙ« hash tables are just a good data structure for implementing editable type information tables! AlsoÙ« thatâ€™s just how some interpreters like CPython do things. If you look at how a high performance JIT like V8 implements thingsÙ« <a href="https://v8.dev/blog/fast-properties">it looks a lot like vtables and reflection info</a>! V8â€™s hidden classes (vtables and reflection info) and object layout are similar to what you might see in a Java VMÙ« just with the capability for objects to change to a new vtable at runtime. This is not a coincidence because nothing is ever a coincidence: The person <a href="https://en.wikipedia.org/wiki/Chrome_V8">listed on Wikipedia as the creator of V8</a> previously <a href="https://en.wikipedia.org/wiki/Lars_Bak_(computer_programmer)">worked on a high-performance Java VM</a>.</p>

<h3 id="dictionary-passing">Dictionary Passing</h3>

<p>Another way of implementing dynamic interfaces than associating vtables with objects is to pass a table of the required function pointers along to generic functions that need them. This approach is in a way similar to constructing Go-style interface objects at the call siteÙ« just that the table is passed as a hidden argument instead of packaged into a bundle as one of the existing arguments.</p>

<p>This approach is used by <a href="http://okmij.org/ftp/Computation/typeclass.html">Haskell type classes</a> although GHC has the ability to do a kind of monomorphization as an optimization through inlining and specialization. Dictionary passing is also used by OCaml with an explicit argument in the form of <a href="https://v1.realworldocaml.org/v1/en/html/first-class-modules.html">first class modules</a>Ù« but thereâ€™s a proposal to <a href="https://tycon.github.io/modular-implicits.html">add a mechanism to make the parameter implicit</a>.</p>

<h3 id="swift-witness-tables">Swift Witness Tables</h3>

<p>Swift makes the interesting realization that by using dictionary passing and also putting the size of types and how to moveÙ« copy and free them into the tablesÙ« they can provide all the information required to work with any type in a uniform way without boxing them. This way Swift can implement generics <a href="https://www.reddit.com/r/rust/comments/7gkiie/implementing_swift_generics_video/">without monomorphization and without allocating everything into a uniform representation</a>! They still pay the cost of all the dynamic lookups that all boxing-family implementations payÙ« but they save on the allocationÙ« memory and cache-incoherency costs. The Swift compiler also has the ability to specialize (monomorphize) and inline generics within a module and across modules with functions <a href="https://github.com/apple/swift-evolution/blob/master/proposals/0193-cross-module-inlining-and-specialization.md">annotated <code class="language-plaintext highlighter-rouge">@inlinable</code></a> to avoid these costs if it wants toÙ« presumably using heuristics about how much it would bloat the code.</p>

<p>This functionality also explains how Swift can <a href="https://github.com/apple/swift-evolution/blob/master/proposals/0260-library-evolution.md">implement ABI stability</a> in a way that allows adding and rearranging fields in <code class="language-plaintext highlighter-rouge">struct</code>sÙ« although they provide a <code class="language-plaintext highlighter-rouge">@frozen</code> attribute to opt out of dynamic lookups for performance reasons.</p>

<h3 id="intensional-type-analysis">Intensional Type Analysis</h3>

<p>One more way to implement interfaces for your boxed types is to add a type ID in a fixed part of the object like where a vtable pointer would goÙ« then generate functions for each interface method that effectively have a big <code class="language-plaintext highlighter-rouge">switch</code> statement over all the types that implement that interface method and dispatch to the correct type-specific method.</p>

<p>Iâ€™m not aware of any languages that use this techniqueÙ« but C++ compilers and Java VMs do something similar to this when they use profile-guided optimization to learn that a certain generic call site mostly acts on objects of certain types. Theyâ€™ll replace the call site with a check for each common type and then a static dispatch for that common typeÙ« with the usual dynamic dispatch as a fallback case. This way the branch predictor can predict the common case branch will be taken and continue dispatching instructions through the static call.</p>

<h2 id="monomorphization">Monomorphization</h2>

<p>NowÙ« the alternative approach to boxing is monomorphization. In the monomorphization approach we need to find some way to output multiple versions of our code for each type we want to use it with. Compilers have multiple phases of representations that the code passes through as it is compiledÙ« and we theoretically can do the copying at any of these stages.</p>

<h3 id="generating-source-code">Generating source code</h3>

<p>The simplest approach to monomorphization is to do the copying at the stage of the first representation: source code! This way the compiler doesnâ€™t even have to have generics support in itÙ« and this is what users of languages like C and GoÙ« where the compiler doesnâ€™t support genericsÙ« sometimes do.</p>

<p>In C you can use the preprocessor and define your data structure in a macro or a header that you include multiple times with different <code class="language-plaintext highlighter-rouge">#define</code>s. In Go there are scripts like <a href="https://github.com/cheekybits/genny">genny</a> that make this code generation process easy.</p>

<p>The downside of this is that duplicating source code can have a lot of warts and edge cases to look out for depending on the languageÙ« and also gives the compiler lots of extra work to do parsing and type checking basically the same code many times. Again depending on language and tools this methodâ€™s generics can be ugly to write and useÙ« like how if you write one inside a C macro every line has to end with a backslash and all type and function names need to have the type name manually concatenated onto their identifiers to avoid collisions.</p>

<h3 id="d-string-mixins">D string mixins</h3>

<p>Code generation does have something going for it thoughÙ« which is that you can generate the code using a fully powered programming languageÙ« and also it uses a representation that the user already knows.</p>

<p>Some languages that implement generics in some other way also include a clean way of doing code generation to address more general metaprogramming use cases not covered by their generics systemÙ« like serialization. The clearest example of this is Dâ€™s <a href="https://dlang.org/articles/mixin.html">string mixins</a> which enable generating D code as strings using the full power of D during the middle of a compile.</p>

<h3 id="rust-procedural-macros">Rust procedural macros</h3>

<p>A similar example but with a representation only one step into the compiler is <a href="https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html">Rustâ€™s procedural macros</a>Ù« which take token streams as input and output token streamsÙ« while providing utilities to convert token streams to and from strings. The advantage of this approach is that token streams can preserve source code location information. A macro can directly paste code the user wrote from input to output as tokensÙ« then if the userâ€™s code causes a compiler error in the macro output the error message the compiler prints will correctly point to the fileÙ« line and columns of the broken part of the userâ€™s codeÙ« but if the macro generates broken code the error message will point to the macro invocation. For example if you use <a href="https://docs.rs/log-derive/">a macro that wraps a function in logging calls</a> and make a mistake in the implementation of the wrapped functionÙ« the compiler error will point directly to the mistake in your fileÙ« rather than saying the error occurred in code generated by the macro.</p>

<h3 id="syntax-tree-macros">Syntax tree macros</h3>

<p>Some languages do take the step further and offer facilities for consuming and producing Abstract Syntax Tree (AST) types in macros written in the language. Examples of this include <a href="https://wiki.haskell.org/A_practical_Template_Haskell_Tutorial">Template Haskell</a>Ù« <a href="https://nim-lang.org/docs/tut3.html">Nim macros</a>Ù« <a href="http://ocamllabs.io/doc/ppx.html">OCaml PPX</a> and nearly all <a href="https://en.wikipedia.org/wiki/Lisp_(programming_language)">Lisp</a>s.</p>

<p>One problem with AST macros is that you donâ€™t want to require users to learn a bunch of functions for constructing AST types as well as the base languages. The Lisp family of languages address this by making the syntax and the AST structure very simple with a very direct correspondenceÙ« but constructing the structures can still be tedious. ThusÙ« all the languages I mention have some form of â€œquoteâ€ primitive where you provide a fragment of code in the language and it returns the syntax tree. These quote primitives also have a way to splice syntax tree values in like string interpolation. Hereâ€™s an example in Template Haskell:</p>

<div class="language-haskell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- using AST construction functions</span>
<span class="n">genFn</span> <span class="o">::</span> <span class="kt">Name</span> <span class="o">-&gt;</span> <span class="kt">Q</span> <span class="kt">Exp</span>
<span class="n">genFn</span> <span class="n">f</span> <span class="o">=</span> <span class="kr">do</span>
  <span class="n">x</span> <span class="o">&lt;-</span> <span class="n">newName</span> <span class="s">"x"</span>
  <span class="n">lamE</span> <span class="p">[</span><span class="n">varP</span> <span class="n">x</span><span class="p">]</span> <span class="p">(</span><span class="n">appE</span> <span class="p">(</span><span class="n">varE</span> <span class="n">f</span><span class="p">)</span> <span class="p">(</span><span class="n">varE</span> <span class="n">x</span><span class="p">))</span>

<span class="c1">-- using quotation with $() for splicing</span>
<span class="n">genFn"</span> <span class="o">::</span> <span class="kt">Name</span> <span class="o">-&gt;</span> <span class="kt">Q</span> <span class="kt">Exp</span>
<span class="n">genFn"</span> <span class="n">f</span> <span class="o">=</span> <span class="p">[</span><span class="o">|</span> <span class="nf">\</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="o">$</span><span class="p">(</span><span class="n">varE</span> <span class="n">f</span><span class="p">)</span> <span class="n">x</span> <span class="o">|</span><span class="p">]</span>
</code></pre></div></div>

<p>One disadvantage of doing procedural macros at the syntax tree level instead of token level is that syntax tree types often change with the addition of new language featuresÙ« while token types can remain compatible. For example OCamlâ€™s PPX system needs <a href="https://github.com/ocaml-ppx/ocaml-migrate-parsetree">special infrastructure to migrate parse trees</a> to and from the language version used by a macro. Whereas Rust has libraries that add <a href="https://github.com/dtolnay/syn">parsing</a> and <a href="https://github.com/dtolnay/quote">quotation</a> utilities so you can write procedural macros in a style similar to syntax tree macros. Rust even has <a href="https://github.com/dtolnay/reflect">an experimental library that tries to replicate the interface provided by reflection</a>!</p>

<h3 id="templates">Templates</h3>

<p>The next type of generics is just pushing the code generation a little further in the compiler. Templates as found in C++ and D are a way of implementing generics where you can specify â€œtemplate parametersâ€ on types and functions and when you instantiate a template with a specific typeÙ« that type is substituted into the functionÙ« and then the function is type checked to make sure that the combination is valid.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">template</span> <span class="o">&lt;</span><span class="k">class</span> <span class="nc">T</span><span class="p">&gt;</span> <span class="n">T</span> <span class="nf">myMax</span><span class="p">(</span><span class="n">T</span> <span class="n">a</span><span class="p">Ù«</span> <span class="n">T</span> <span class="n">b</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">a</span><span class="o">&gt;</span><span class="n">b</span><span class="o">?</span><span class="n">a</span><span class="o">:</span><span class="n">b</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">template</span> <span class="o">&lt;</span><span class="k">class</span> <span class="nc">T</span><span class="p">&gt;</span> <span class="k">struct</span> <span class="nc">Pair</span> <span class="p">{</span>
  <span class="n">T</span> <span class="n">values</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="p">};</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">myMax</span><span class="p">(</span><span class="mi">5</span><span class="p">Ù«</span> <span class="mi">6</span><span class="p">);</span>
  <span class="n">Pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">p</span> <span class="p">{</span> <span class="p">{</span><span class="mi">5</span><span class="p">Ù«</span><span class="mi">6</span><span class="p">}</span> <span class="p">};</span>
  <span class="c1">// This would give us a compile error inside myMax</span>
  <span class="c1">// about Pair being an invalid operand to `&gt;`:</span>
  <span class="c1">// myMax(pÙ« p);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>One problem with the template system is that if you include a template function in your library and a user instantiates it with the wrong type they may get an inscrutable compile error inside your library. This is very similar to what can happen with libraries in dynamically typed languages when a user passes in the wrong type. <a href="http://dlang.org/">D</a> has an interesting solution to this which is similar to what popular libraries in dynamic languages do: just use helper functions to check the types are validÙ« the error messages will clearly point to the helpers if they fail! Hereâ€™s the same example in DÙ« note the <code class="language-plaintext highlighter-rouge">if</code> in the signature and the generally better syntax (<code class="language-plaintext highlighter-rouge">!</code> is how you provide template parameters):</p>

<div class="language-d highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// We"re going to use the isNumeric function in std.traits</span>
<span class="k">import</span> <span class="n">std</span><span class="p">.</span><span class="n">traits</span><span class="p">;</span>

<span class="c1">// The `if` is optional (without it you"ll get an error inside like C++)</span>
<span class="c1">// The `if` is also included in docs and participates in overloading!</span>
<span class="n">T</span> <span class="n">myMax</span><span class="p">(</span><span class="n">T</span><span class="p">)(</span><span class="n">T</span> <span class="n">a</span><span class="p">Ù«</span> <span class="n">T</span> <span class="n">b</span><span class="p">)</span> <span class="k">if</span><span class="p">(</span><span class="n">isNumeric</span><span class="p">!</span><span class="n">T</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">a</span><span class="p">&gt;</span><span class="n">b</span><span class="p">?</span><span class="n">a</span><span class="p">:</span><span class="n">b</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">struct</span> <span class="n">Pair</span><span class="p">(</span><span class="n">T</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">T</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="n">values</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">myMax</span><span class="p">(</span><span class="mi">5</span><span class="p">Ù«</span> <span class="mi">6</span><span class="p">);</span>
  <span class="n">Pair</span><span class="p">!</span><span class="kt">int</span> <span class="n">p</span> <span class="p">=</span> <span class="p">{[</span><span class="mi">5</span><span class="p">Ù«</span><span class="mi">6</span><span class="p">]};</span>
  <span class="c1">// This would give a compile error saying that `(Pair!intÙ« Pair!int)`</span>
  <span class="c1">// doesn"t match the available instance `myMax(T aÙ« T b) if(isNumeric!T)`:</span>
  <span class="c1">// myMax(pÙ« p);</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://en.cppreference.com/w/cpp/language/constraints">C++20 has a feature called â€œconceptsâ€</a> that serves the same purpose except with a design more like defining interfaces and type constraints.</p>

<h3 id="compile-time-functions">Compile time functions</h3>

<p>Dâ€™s templates have a number of extensions that allow you to use features like compile time function evaluation and <code class="language-plaintext highlighter-rouge">static if</code> to basically make templates act like functions that take a compile time set of parameters and return a non-generic runtime function. This makes D templates into a fully featured metaprogramming systemÙ« and as far as I understand modern C++ templates have similar power but with less clean mechanisms.</p>

<p>Thereâ€™s some languages that take the â€œgenerics are just compile time functionsâ€ concept and run with it even furtherÙ« like Zig:</p>

<pre><code class="language-zig">fn Stack(comptime T: type) type {
    return struct {
        items: []TÙ«
        len: usizeÙ«

        const Self = @This();
        pub fn push(self: SelfÙ« item: T) {
            // ...
        }
    };
}
</code></pre>

<p>Zig does this using the same language at both compile time and runtimeÙ« with functions split up based on parameters marked <code class="language-plaintext highlighter-rouge">comptime</code>. Thereâ€™s another language that uses a separate but similar language at the meta level called <a href="http://terralang.org/">Terra</a>. Terra is a dialect of Lua that allows you to construct lower level C-like functions inline and then manipulate them at the meta level using Lua APIs as well as quoting and splicing primitives:</p>

<div class="language-lua highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span> <span class="nf">MakeStack</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
    <span class="kd">local</span> <span class="n">struct</span> <span class="n">Stack</span> <span class="p">{</span>
        <span class="n">items</span> <span class="p">:</span> <span class="err">&amp;</span><span class="n">T</span><span class="p">;</span> <span class="c1">-- &amp;T is a pointer to T</span>
        <span class="n">len</span> <span class="p">:</span> <span class="n">int</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">terra</span> <span class="n">Stack</span><span class="p">:</span><span class="n">push</span><span class="p">(</span><span class="n">item</span> <span class="p">:</span> <span class="n">T</span><span class="p">)</span>
        <span class="c1">-- ...</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">Stack</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Terraâ€™s crazy level of metaprogramming power allows it to do things <a href="http://terralang.org/#compiling-a-language">like implement optimizing compilers for domain specific languages as simple functions</a>Ù« or implement the interface and object systems of <a href="https://github.com/zdevito/terra/blob/master/tests/lib/javalike.t">Java</a> and <a href="https://github.com/zdevito/terra/blob/master/tests/lib/golike.t">Go</a> in a library with a small amount of code. Then it can save out generated runtime-level code as dependency-free object files.</p>

<h3 id="rust-generics">Rust generics</h3>

<p>The next type of monomorphized generics of course moves the code generation one step further into the compilerÙ« after type checking. I mentioned that the type of inside-the-library errors you can get with C++ are like the errors you can get in a dynamically typed languageÙ« this is of course because thereâ€™s basically only one type of type in template parametersÙ« like a dynamic language. So that means we can fix the problem by adding a type system to our meta level and having multiple types of types with static checking that they support the operations you use. This is how generics work in RustÙ« and at the language level also how they work in Swift and Haskell.</p>

<p>In Rust you need to declare â€œtrait boundsâ€ on your type parametersÙ« where <code class="language-plaintext highlighter-rouge">trait</code>s
are like interfaces in other languages and declare a set of functionality provided by the type. The Rust compiler will check that the body of your generic functions will work with any type conforming to your trait boundsÙ« and also not allow you to use functionality of the type not declared by the trait bounds. This way users of generic functions in Rust can <em>never</em> get compile errors inside a library function when they instantiate it. The compiler also only has to type check each generic function once.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">my_max</span><span class="o">&lt;</span><span class="n">T</span><span class="p">:</span> <span class="n">PartialOrd</span><span class="o">&gt;</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">T</span><span class="p">Ù«</span> <span class="n">b</span><span class="p">:</span> <span class="n">T</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">T</span> <span class="p">{</span>
    <span class="k">if</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="n">b</span> <span class="p">{</span> <span class="n">a</span> <span class="p">}</span> <span class="k">else</span> <span class="p">{</span> <span class="n">b</span> <span class="p">}</span>
<span class="p">}</span>

<span class="k">struct</span> <span class="n">Pair</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="n">values</span><span class="p">:</span> <span class="p">[</span><span class="n">T</span><span class="p">;</span> <span class="mi">2</span><span class="p">]Ù«</span>
<span class="p">}</span>

<span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="nf">my_max</span><span class="p">(</span><span class="mi">5</span><span class="p">Ù«</span><span class="mi">6</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">p</span><span class="p">:</span> <span class="n">Pair</span><span class="o">&lt;</span><span class="nb">i32</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">Pair</span> <span class="p">{</span> <span class="n">values</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">Ù«</span><span class="mi">6</span><span class="p">]</span> <span class="p">};</span>
    <span class="c">// Would give a compile error saying that</span>
    <span class="c">// PartialOrd is not implemented for Pair&lt;i32&gt;:</span>
    <span class="c">// my_max(pÙ«p);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>At the language level this is very similar to the kind of type system you need to implement generics with interface support using the boxing approach to genericsÙ« which is why Rust can support both using the same system! Rust 2018 even added a uniform syntax where a <code class="language-plaintext highlighter-rouge">v: &amp;impl SomeTrait</code> parameter gets monomorphized but a <code class="language-plaintext highlighter-rouge">v: &amp;dyn SomeTrait</code> parameter uses boxing. This property also allows compilers like Swiftâ€™s and Haskellâ€™s GHC to monomorphize as an optimization even though they default to boxing.</p>

<h3 id="machine-code-monomorphization">Machine code monomorphization</h3>

<p>The logical next step in monomorphized generics models is pushing it further in the compilerÙ« after the backend. Just like we can copy source code templates that are annotated with placeholders for the generic typeÙ« we can generate machine code with placeholders for the type-specific parts. Then we can stamp these templates out very quickly with a <code class="language-plaintext highlighter-rouge">memcpy</code> and a few patches like how a linker works! The downside is that each monomorphized copy couldnâ€™t be specially optimized by the optimizerÙ« but because of the lack of duplicate optimizationÙ« compilation can be way faster. We could even make the code stamper a tiny JIT that gets included in binaries and stamps out the monomorphized copies at runtime to avoid bloating the binaries.</p>

<p>Actually Iâ€™m not aware of any language that works this wayÙ« itâ€™s just an idea that came to me while writing as a natural extension of this taxonomyÙ« which is exactly the kind of thing I hoped for from this exercise! I hope this post gives you a clearer picture of the generics systems in different languages and how they can be fit together into a coherent taxonomyÙ« and prompts you to think about the directions in concept-space where we might find new cool programming languages.</p>
'),('http://thume.ca/2019/06/19/glitchless-metal-window-resizing/', 'Glitchless Metal Window Resizing', '1560902400000',  13, '
<p>Thereâ€™s a problem with Appleâ€™s Metal <a href="https://developer.apple.com/documentation/metalkit/mtkview">MTKView</a> on macOS which is that seemingly nobody can figure out how to get smooth window resizing to work properly. I just figured it outÙ« more on that later. If you reposition the triangle in Appleâ€™s Hello Triangle program to the left (to make the rescaling more apparent) then you can see it judders horribly when the window is resized:</p>

<p><img src="/assets/postassets/metalresize/wobbly_hello_triangle.gif" alt="Wobbly Hello Triangle" /></p>

<p>Whatâ€™s happening is often the new Metal frame doesnâ€™t arrive in time and it draws a stretched version of the previous frame instead. Thereâ€™s a number of places on the internet dating back to 2017 with various people encountering the problem:</p>

<ul>
  <li><a href="https://stackoverflow.com/questions/45375548/resizing-mtkview-scales-old-content-before-redraw">Stack Overflow: Resizing MTKView scales old content before redraw</a></li>
  <li><a href="https://forums.developer.apple.com/thread/77901">Apple Developer Forums: Redraw MTKView when its size changes</a></li>
  <li><a href="https://forums.developer.apple.com/thread/94765">Apple Developer Forums: Unwanted MTKView content stretching when I resize/zoom the window</a></li>
  <li><a href="https://github.com/gnachman/iTerm2/blob/ed8e2544726e686fe81d71fdec25cd8c5884be4d/sources/PTYTab.m#L5215">iTerm2 switches away from Metal to software rendering when resizing the window</a></li>
</ul>

<p>Basically everyone who tries to make something with Metal thatâ€™s not a game runs into this problem and it looks horrible. As far as I can tell nobody has figured out how to fix it properly before and posted about it afterwards. Note in the first dev forums thread that an Apple employee claimed they were looking into this problem almost a year ago with no resolution.</p>

<p>I started <a href="https://github.com/trishume/MetalTest">a test project</a> to try out different ways of drawing with Metal during resize to see if I could get any of them to work properly. First I replicated the MTKView problems and tried to fix them by tweaking lots of different thingsÙ« including all three modes of triggering draws listed in the docs and using <code class="language-plaintext highlighter-rouge">presentsWithTransaction</code> in the way the docs suggest but nothing helped. Then I made a version using Core Graphics and an NSView subclass and stacked it below my Metal view so that I could have a reference that worked properly.</p>

<h2 id="the-solution">The Solution</h2>

<p>Then I tried the accepted answer by Max on <a href="https://stackoverflow.com/questions/45375548/resizing-mtkview-scales-old-content-before-redraw">the Stack Overflow post</a> which uses <code class="language-plaintext highlighter-rouge">CAMetalLayer</code> and some resizing-related properties. This reduced the frequency of glitches quite a bitÙ« but didnâ€™t eliminate them. So I added in <code class="language-plaintext highlighter-rouge">presentsWithTransaction = true</code>Ù« which wasnâ€™t enough on its ownÙ« but combining that with  <code class="language-plaintext highlighter-rouge">commandBuffer.waitUntilScheduled()</code> then presenting as suggested in the Apple <code class="language-plaintext highlighter-rouge">CAMetalLayer</code> docs fixed all the glitches! I also needed to do some size conversion to make the accepted answerâ€™s recipe draw crisply on high DPI displays.</p>

<p><strong>Edit:</strong> <a href="https://twitter.com/CoreyDotCom/status/1141653060843950081">@CoreyDotCom on Twitter</a> reminded me I forgot to mention something. If you follow the recipe from the Stack Overflow postÙ« it will <em>appear to be</em> glitch-freeÙ« but it actually isnâ€™t. The <code class="language-plaintext highlighter-rouge">layerContentsPlacement = .topLeft</code> makes the glitches manifest as small broken slices near the moving window edgeÙ« which are very difficult to notice since the edge is moving quickly. When you change the placement policy to <code class="language-plaintext highlighter-rouge">layerContentsPlacement = .scaleAxesIndependently</code> to match the behavior of <code class="language-plaintext highlighter-rouge">MTKView</code> you see that there are still occasional glitches. Corey reports frame rate issues with <code class="language-plaintext highlighter-rouge">presentsWithTransaction</code>Ù« and if this is the case for you as well it may be preferable to just mask the occasional remaining glitches with the top left placement policy.</p>

<h2 id="working-code">Working Code</h2>

<p>I now have a Metal triangle test program that resizes smoothly and without judder.</p>

<p>Check out my test project: <a href="https://github.com/trishume/MetalTest">Github repo</a></p>

<p>And the specific code file containing the working recipe: <a href="https://github.com/trishume/MetalTest/blob/master/MetalTest2/MetalLayerView.swift">MetalLayerView</a></p>

<p>In the gif below the top is the broken <code class="language-plaintext highlighter-rouge">MTKView</code>Ù« the middle <code class="language-plaintext highlighter-rouge">NSView</code>Ù« and the bottom the working <code class="language-plaintext highlighter-rouge">CAMetalLayer</code> recipe. Contrast the shakey left edge of the top triangle with the stable bottom one:</p>

<p><img src="/assets/postassets/metalresize/metal_triangles.gif" alt="Metal Triangles" /></p>

'),('http://thume.ca/2019/04/29/comparing-compilers-in-rust-haskell-c-and-python/', 'Comparing the Same Project in RustÙ« HaskellÙ« C++Ù« PythonÙ« Scala and OCaml', '1556496000000',  13, '
<p>During my final term at UWaterloo I took <a href="https://www.student.cs.uwaterloo.ca/~cs444/">the CS444 compilers class</a> with a project to write a compiler from a substantial subset of Java to x86Ù« in teams of up to three people with a language of the groupâ€™s choice. This was a rare opportunity to compare implementations of large programs that all did the same thingÙ« written by friends I knew were highly competentÙ« and have a fairly pure opportunity to see what difference design and language choices could make. I gained a lot of useful insights from this. Itâ€™s rare to encounter such a controlled comparison of languagesÙ« itâ€™s not perfect but itâ€™s much better than most anecdotes people use as the basis for their opinions on programming languages.</p>

<p>We did our compiler in Rust and my first comparison was with a team that used HaskellÙ« which I expected to be much terserÙ« but their compiler used similar amounts or more code for the same task. The same was true for a team that used OCaml. I then compared with a team that used C++Ù« and as expected their compiler was around 30% larger largely due to headers and lack of sum types and pattern matching. The next comparison was my friend who did a compiler on her own in Python and used less than half the code we did because of the power of metaprogramming and dynamic types. A friend whose team used Scala also had a smaller compiler than us. The comparison that surprised me most though was with another team that also used RustÙ« but used 3 times the code that we didÙ« because of different design decisions. In the endÙ« the largest difference in the amount of code required was within the same language!</p>

<p>Iâ€™ll go over why I think this is a good comparisonÙ« some information on each projectÙ« and Iâ€™ll explain some of the sources of the differences in compiler size. Iâ€™ll also talk about what I learned from each comparison. Feel free to use these links to skip ahead to what interests you:</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li>Why I think this is insightful</li>
  <li><a href="#rust-baseline">Rust (baseline)</a></li>
  <li><a href="#haskell">Haskell</a>: 1.0-1.6x the size depending on how you count for interesting reasons</li>
  <li><a href="#c">C++</a>: 1.4x the size for mundane reasons</li>
  <li><a href="#python">Python</a>: half the size because of fancy metaprogramming!</li>
  <li><a href="#rust-other-group">Rust (other group)</a>: 3x the size because of different design decisions!</li>
  <li><a href="#scala">Scala</a>: 0.7x the size</li>
  <li><a href="#ocaml">OCaml</a>: 1.0-1.6x the size depending on how you countÙ« similar to Haskell</li>
</ul>

<h2 id="why-i-think-this-is-insightful">Why I think this is insightful</h2>

<p>Now before you reply that amount of code (I compared both lines and bytes) is a terrible metricÙ« I think that it can provide a good amount of insight in this case for a number of reasons. This is at least subjectively the most well controlled instance of different teams writing the same <em>large</em> program that Iâ€™ve ever heard of or read about.</p>

<ul>
  <li>Nobody (including me) knew I would ask this until after we were doneÙ« so nobody was trying to game the metricÙ« everyone was just doing their best to finish the project quickly and correctly.</li>
  <li>Everyone (with the exception of the Python project Iâ€™ll discuss later) was implementing a program with the sole goal of passing the same automated test suite by the same deadlinesÙ« so the results canâ€™t be confounded much by some groups deciding to solve different/harder problems.</li>
  <li>The project was done over a period of monthsÙ« with a teamÙ« and needed to be gradually extended and pass both known and unknown tests. This means that it was helpful to write clean understandable code and not hack everything together.</li>
  <li>Other than passing the course testsÙ« the code wouldnâ€™t be used for anything elseÙ« nobody would read it and being a compiler for a limited subset of Java to textual assembly it wouldnâ€™t be useful.</li>
  <li>No libraries other than the standard library were allowedÙ« and no parsing helpers even if theyâ€™re in the standard library. This means the comparison canâ€™t be confounded by powerful compiler libraries not used by all teams.</li>
  <li>There were secret tests which we couldnâ€™t see that were run once after the final submission deadlineÙ« which meant there was an incentive to write your own test code and make sure that your compiler was robustÙ« correct and could handle tricky edge cases.</li>
  <li>While everyone involved was a studentÙ« the teams I talk about are all composed of people I consider quite competent programmers. Everyone has at least 2 years of full time work experience doing internshipsÙ« mostly at high end tech companies sometimes even working on compilers. Nearly all have been programming for 7-13 years and are enthusiasts who read a lot on the internet beyond their courses.</li>
  <li>Generated code wasnâ€™t countedÙ« but grammar files and code that generated code was counted.</li>
</ul>

<p>Thus I think the amount of code provides a decent approximation of how much effort each project tookÙ« and how much there would be to maintain if it was a longer term project. I think the smaller differences are also large enough to rule out extraordinary claimsÙ« like the ones Iâ€™ve read that say writing a compiler in Haskell takes less than half the code of C++ by virtue of the language.</p>

<h2 id="rust-baseline">Rust (baseline)</h2>

<p>Me and one of my teammates had each written over 10k lines of Rust beforeÙ« and my other teammate had written maybe 500 lines of Rust for some hackathon projects. Our compiler was 6806 lines by <code class="language-plaintext highlighter-rouge">wc -l</code>Ù« 5900 source lines of code (not including blanks and comments)Ù« and 220kb by <code class="language-plaintext highlighter-rouge">wc -c</code>.</p>

<p>One thing I discovered is that these measures were related by approximately the same factors in the other projects where I checkedÙ« with minor exceptions that Iâ€™ll note. For the rest of the post when I refer to lines or amount I mean by <code class="language-plaintext highlighter-rouge">wc -l</code>Ù« but this result means it doesnâ€™t really matter (unless I note a difference) and you can convert with a factor.</p>

<p>I wrote <a href="/2019/04/18/writing-a-compiler-in-rust/">another post describing our design</a>Ù« which passed all the public and secret tests. It also included a few extra features that we did for fun and not to pass testsÙ« that probably added around 400 extra lines. Also around 500 lines of our total was unit tests and a test harness.</p>

<h2 id="haskell">Haskell</h2>

<p>The Haskell team was composed of two of my friends whoâ€™d written maybe a couple thousand lines of Haskell each before plus reading lots of online Haskell contentÙ« and a bunch more in other similar functional languages like OCaml and Lean. They had one other teammate who I didnâ€™t know well but seems like a strong programmer and had used Haskell before.</p>

<p>Their compiler was 9750 lines by <code class="language-plaintext highlighter-rouge">wc -l</code>Ù« 357kb and 7777 SLOC. This team also had the only significant differences between measure ratiosÙ« with their compiler being 1.4x the linesÙ« 1.3x the SLOCÙ« and 1.6x the bytes. They didnâ€™t implement any extra features but passed 100% of public and secret tests.</p>

<p>Itâ€™s important to note that including the tests is the least fair to this team since they were the most thorough with correctnessÙ« with 1600 lines of testsÙ« they caught a few edge cases that our team did notÙ« they just happened to not be edge cases that were tested by the course tests. So not counting tests on both sides (8.1kloc vs 6.3kloc) their compiler was only 1.3x the raw lines.</p>

<p>I also am inclined towards bytes as the more reasonable measure of amount of code here because the Haskell project has longer lines on average since it doesnâ€™t have lots of lines dedicated to just a closing braceÙ« and itâ€™s one-liner function chains arenâ€™t split onto a bunch of lines by <code class="language-plaintext highlighter-rouge">rustfmt</code>.</p>

<p>Digging into the difference in size with one of my friends on the teamÙ« we came up with the following to explain the difference:</p>

<ul>
  <li>We used a hand-written lexer and recursive descent parsingÙ« where they used a <a href="https://en.wikipedia.org/wiki/Nondeterministic_finite_automaton">NFA</a> to <a href="https://en.wikipedia.org/wiki/Deterministic_finite_automaton">DFA</a> lexer generatorÙ« and an <a href="https://en.wikipedia.org/wiki/LR_parser">LR parser</a> and then a pass to turn the parse tree into an AST (<a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract Syntax Tree</a>Ù« a more convenient representation of the code). This took them substantially more codeÙ« 2677 lines compared to our 1705Ù« for about an extra 1k lines.</li>
  <li>They used a fancy generic AST type that transitioned to different type parameters as more information was added in each pass. This is and more helper functions for rewriting are probably why their AST code has about 500 lines more than our implementation where we build with struct literals and mutate <code class="language-plaintext highlighter-rouge">Option&lt;_&gt;</code> fields to add information as passes progress.</li>
  <li>They have about 400 more lines of code in their code generation that are mostly attributable to more abstraction necessary to generate and combine code in a purely functional way where we just use mutation and string writing.</li>
</ul>

<p>These differences plus the tests explain all of the difference in lines. In fact our files for middle passes like constant folding and scope resolution are very close to the same size. However that still leaves some difference in bytes because of longer average linesÙ« which Iâ€™d guess is because they require more code to rewrite their whole tree at every pass where we just use a visitor with mutation.</p>

<p>Bottom lineÙ« Iâ€™d say setting aside design decisions Rust and Haskell are similarly expressiveÙ« with maybe a slight edge to Rust because of ability to easily use mutation when itâ€™s convenient. It was also interesting to learn that my choice to use a recursive descent parser and hand-written lexer paid offÙ« this was a risk since it wasnâ€™t what the professor recommended and taught but I figured it would be easier and was right.</p>

<p>Haskell fans my object that this team probably didnâ€™t use Haskell to its fullest potential and if they were better at Haskell they could have done the project with way less code. I believe that someone like <a href="https://github.com/ekmett">Edward Kmett</a> could write the same compiler in substantially fewer lines of HaskellÙ« in that my friendâ€™s team didnâ€™t use a lot of fancy super advanced abstractionsÙ« and werenâ€™t allowed to use fancy combinator libraries like <a href="http://hackage.haskell.org/package/lens">lens</a>. HoweverÙ« this would come at a cost to how difficult it would be to understand the compiler. The people on the team are all experienced programmersÙ« they knew that Haskell can do extremely fancy things but chose not to pursue them because they figured it would take more time to figure them out than they would save and make their code harder for the teammates who didnâ€™t write it to understand. This seems like a real tradeoff to me and the claim Iâ€™ve seen of Haskell being magical for compilers devolves into something like â€œHaskell has an extremely high skill cap for writing compilers as long as you donâ€™t care about maintainability by people who arenâ€™t also extremely skilled in Haskellâ€ which is less generally applicable.</p>

<p>Another interesting thing to note is that at the start of every offering of the course the professor says that students can use any language that can run on the school serversÙ« but issues a warning that teams using Haskell have the highest variance in mark of any languageÙ« with many teams using Haskell overestimating their ability and crashing and burning then getting a terrible markÙ« more than any other languageÙ« while some Haskell teams do quite well and get perfect like my friends.</p>

<h2 id="c">C++</h2>

<p>Next I talked to my friend who was on a team using C++Ù« I only knew one person on this teamÙ« but C++ is used in multiple courses at UWaterloo so presumably everyone on the team had C++ experience.</p>

<p>Their project was 8733 raw lines and 280kb not including test code but including around 500 lines of extra features. Making it 1.4x the size of our non-test code that also had around 500 lines of extra features. They passed 100% of public tests but only passed 90% of secret testsÙ« presumably because they didnâ€™t implement the fancy array vtables required by the specÙ« which take maybe 50-100 lines of code.</p>

<p>I didnâ€™t dig very deeply into these differences with my friend. I speculate that itâ€™s mostly explained by:</p>

<ul>
  <li>Them using an LR parser and tree rewriter instead of a recursive descent parser</li>
  <li>The lack of sum types and pattern matching in C++Ù« which we used extensively and were very helpful.</li>
  <li>Needing to duplicate all the signatures in header filesÙ« which Rust doesnâ€™t have.</li>
</ul>

<p>Another thing we compared was compile times. On my laptop our compiler takes 9.7s for a clean debug buildÙ« 12.5s for clean releaseÙ« and 3.5s for incremental debug. My friend didnâ€™t have timings on hand for their C++ build (using parallel make) but said those sounded quite similar to his experienceÙ« with the caveat that they put the implementations of a bunch of small functions in header files to save the signature duplication at the cost of longer times (this is also why I canâ€™t measure the pure header file line count overhead).</p>

<h2 id="python">Python</h2>

<p>I have one friend who is an extraordinarily good programmer who chose to do the project alone and in Python. She also implemented more extra features (for fun) than any other team including an SSA intermediate representation with register allocation and other optimizations. On the other hand because she was working alone and implementing a bunch of extra featuresÙ« she dedicated the least effort to code qualityÙ« for example by throwing an undifferentiated exception for all errors (relying on backtraces for debugging) instead of having error types and messages like we did.</p>

<p>Her compiler was 4581 raw lines and passed all public and secret tests. She also implemented way more extra features than any other team I compare withÙ« but itâ€™s hard to determine how extra code that took because many of her extra features were more powerful versions of simple things everyone needed to implement like constant folding and code generation. The extra features probably account for 1000-2000 lines at least thoughÙ« so Iâ€™m confident her code was at least twice as expressive as ours.</p>

<p>One large part of this difference is likely dynamic typing. Our <code class="language-plaintext highlighter-rouge">ast.rs</code> alone has 500 lines of type definitionsÙ« and there are many more types defined throughout our compiler. We also are always constrained in what we do by the type system. For example we need infrastructure for ergonomically adding new info to our AST as it progresses through passes and accessing that later. Whereas in Python you can just set new fields on your AST nodes.</p>

<p>Powerful metaprogramming also explains part of the difference. For example although she used an LR parser instead of a recursive descent parserÙ« in her case I think it needed less codeÙ« because instead of a tree rewriting passÙ« her LR grammar included Python code snippets to construct the ASTÙ« which the generator could turn into Python functions using <code class="language-plaintext highlighter-rouge">eval</code>. Part of the reason we didnâ€™t use an LR parser is because constructing an AST without a tree rewriting pass would require a lot of ceremony (either generating Rust files or procedural macros) to tie the grammar to snippets of Rust code.</p>

<p>Another example of the power of metaprogramming and dynamic typing is that we have a 400 line file called <code class="language-plaintext highlighter-rouge">visit.rs</code> that is mostly repetitive boilerplate code implementing a visitor on a bunch of AST structures. In Python this could be a short ~10 line function that recursively introspects on the fields of the AST node and visits them (using the <code class="language-plaintext highlighter-rouge">__dict__</code> attribute).</p>

<p>As a fan of Rust and statically typed languages in general Iâ€™m inclined to point out that the type system is very helpful for avoiding bugs and for performance. Fancy metaprogramming can also make it more difficult to understand how code works. HoweverÙ« this comparison surprised me in that I hadnâ€™t expected the difference in the amount of code to be quite so large. If the difference in general is really close to needing to write twice the amount of codeÙ« I still think Rust is worth the tradeoffÙ« but 2x is nothing to sneeze at and in the future Iâ€™ll be more inclined to hack something together in Ruby/Python if I just need to get it done quickly without a team and then throw it away after.</p>

<h2 id="rust-other-group">Rust (other group)</h2>

<p>The last comparison I did and also the most interesting to me was with my friend who did the project in Rust with one teammate (who I didnâ€™t know). My friend had a good amount of Rust experience having contributed to the Rust compiler and done lots of readingÙ« I donâ€™t know about his teammate.</p>

<p>Their project was 17Ù«211 raw linesÙ« 15k source linesÙ« and 637kb not including test code and generated code. It had no extra features and passed only 4/10 secret tests and 90% of the public code generation testsÙ« because they didnâ€™t find the time before the final deadline to implement fancier pieces of the spec. This is 3 times the size of our compiler written in the same languageÙ« but with strictly less functionality!</p>

<p>This result was really surprising to me and dwarfed all the between-language differences I had investigated thus far. So we compared <code class="language-plaintext highlighter-rouge">wc -l</code> file size listingsÙ« as well as spot checking how we each implemented some specific things that had very different code sizes.</p>

<p>It seems to come down to consistently making different design decisions. For exampleÙ« their front end (lexingÙ« parsingÙ« AST building) is 7597 raw lines to our 2164. They used a DFA-based lexer and LALR(1) parserÙ« but the other groups did similar things without as much code. Looking at their weeder fileÙ« I noticed a number of different design decisions:</p>

<ul>
  <li>They chose to use a fully typed parse tree instead of the standard string-based homogeneous parse tree. This presumably required a lot more type definitions and additional transformation code in the parsing stage or a more complex parser generator.</li>
  <li>They used <code class="language-plaintext highlighter-rouge">TryFrom</code> trait implementations for converting between the parse tree types and the AST types while validating their correctness. This lead to tons of 10-20 line <code class="language-plaintext highlighter-rouge">impl</code> blocks. We used functions that returned <code class="language-plaintext highlighter-rouge">Result</code> types to accomplish the same thingÙ« which had less line overhead and also freed us from the type structure a bit moreÙ« making parameters and re-use easier. Some things that for us were single line <code class="language-plaintext highlighter-rouge">match</code> branches were 10 line impl statements for them.</li>
  <li>Our types were structured in a way that required less copy-pasting. For example they used separate <code class="language-plaintext highlighter-rouge">is_abstract</code>Ù« <code class="language-plaintext highlighter-rouge">is_native</code> and <code class="language-plaintext highlighter-rouge">is_static</code> fields whose constraint checking code needed to be copy-pasted twiceÙ« once for their void-typed methods and once for their methods with a return typeÙ« with slight modifications. Whereas for us <code class="language-plaintext highlighter-rouge">void</code> was just a special typeÙ« and we came up with a taxonomy of modifiers into <code class="language-plaintext highlighter-rouge">mode</code> and <code class="language-plaintext highlighter-rouge">visibility</code> enums that enforced the constraints at the type level and constraint errors were generated in the default case of the match statement that translated the modifier sets to the mode and visibility.</li>
</ul>

<p>I didnâ€™t look at the code of the analysis passes of their compilerÙ« but they are similarly large. I talked to my friend and it seems they didnâ€™t implement anything like the visitor infrastructure that we did. Iâ€™m guessing this along with some other smaller design differences account for the size difference of this part. The visitor allowed our analysis passes to only pay attention to the parts of the AST they needed instead of having to pattern match down through the entire AST structureÙ« saving a lot of code.</p>

<p>Their code generation is 3594 lines where ours is 1560. I looked at their code for this and it seems that nearly all of the difference is that they chose to have an intermediate data structure for assembly instructionsÙ« where we just used string formatting to directly output assembly. This required defining types and output functions for all the instructions and operand types they used. It also meant that constructing assembly instructions took way more codeÙ« where we might have a formatting statement that used terse instructions like <code class="language-plaintext highlighter-rouge">mov ecxÙ« [edx]</code>Ù« they needed a giant statement <code class="language-plaintext highlighter-rouge">rustfmt</code> split over 6 lines which constructed the instruction with a bunch of intermediate nested types for the operands involving 6 levels of nested parentheses at its deepest. We could also output blocks of related instructions like a function preamble in one formatting statementÙ« where they had to do the full construction for each instruction.</p>

<p>Our team considered using such an abstraction. It would make it easier to have the option of either outputting textual assembly or directly emitting machine codeÙ« however that wasnâ€™t a requirement of the course. The same thing could also be accomplished with less code and better performance using an <code class="language-plaintext highlighter-rouge">X86Writer</code> trait with methods like <code class="language-plaintext highlighter-rouge">push(reg: Register)</code>. Another angle we considered was that it might make debugging and testing easierÙ« but we realized that looking at the generated textual assembly would actually be easier to read and test with <a href="https://docs.rs/insta/0.8.1/insta/">snapshot testing</a> as long as we inserted comments liberally. But we (apparently correctly) predicted that it would take a lot of extra codeÙ« and there wasnâ€™t any real benefit given what we knew we were going to needÙ« so we didnâ€™t bother.</p>

<p>A good comparison is with the intermediate representation the C++ group used as an extra featureÙ« which only took them closer to 500 extra lines. They used a very simple structure (making for simple type definitions and construction code) that used operations close to what Java required. This meant that their IR was much smaller (and thus required less construction code) than the resulting assemblyÙ« since many language operations like calls and casts expanded into many assembly instructions. They also say it really helped debugging since it cut out a lot of the cruft and was easy to read. The higher level representation also allowed them to do some simple optimizations on their IR. The C++ team came up with a really nice design which got them much more benefit with much less code.</p>

<p>Overall it seems like the overall 3x size multiplier is due to consistently making different design decisions both large and small in the direction of larger code. They implemented a number of abstractions that we didnâ€™t which added more codeÙ« and missed out on some of the abstractions we implemented which lead to less code.</p>

<p>This result really surprised meÙ« I knew design decisions mattered but I wouldnâ€™t have guessed beforehand that they would lead to any differences this largeÙ« given that I was only surveying people that I consider strong competent programmers. Of all the results from this comparisonÙ« this is the one I learned the most from. Something that I think helped was that I had read a lot about how to write compilers before I took the courseÙ« so I could take advantage of clever designs other people had come up with and found worked well like AST visitors and recursive descent parsing even when they werenâ€™t taught in the course.</p>

<p>One thing this really made me think about is the cost of abstraction. Abstractions may make things easier to extend in the futureÙ« or guard against certain types of errorsÙ« but they need to be considered against the fact that you may end up with 3 times the amount of code to understand and refactorÙ« 3 times the amount of possible locations for bugs and less time left to spend on testing and further development. Our course was unlike the real world in that we knew exactly what we needed to implement and that weâ€™d never touch the code afterwardsÙ« which eliminates the benefits of pre-emptive abstraction. However if you were going to challenge me to extend a compiler with an arbitrary feature youâ€™d tell me laterÙ« and I had to pick which compiler Iâ€™d start fromÙ« Iâ€™d choose ours even setting aside familiarity. Because thereâ€™d simply be much less code that Iâ€™d need to understand how to changeÙ« and I could potentially choose a better abstraction for the requirements (like the C++ teamâ€™s IR) once I knew how I needed to extend things.</p>

<p>It also solidified the taxonomy in my head of abstractions that you expect to remove code given only your current requirementsÙ« like our visitor patternÙ« and abstractions you expect to add code given only your immediate requirementsÙ« but that may provide extensibilityÙ« debuggability or correctness benefits.</p>

<h2 id="scala">Scala</h2>

<p>I also talked to a friend of mine who did the project in a previous term using ScalaÙ« but the project and tests were the exact same ones. Their compiler was 4141 raw lines and ~160kb of code not counting tests. They passed 8/10 secret tests and 100% of public tests and didnâ€™t implement any extra features. So comparing with our 5906 lines without extra features and testsÙ« their compiler is 0.7x the size.</p>

<p>One design factor in their low line count was that they used a different approach to parsing. The course allowed you to use a command line LR table generator tool that the course providedÙ« which this team used but no other team I mention did. This saved them having to implement an LR table generator. They also managed to avoid writing the LR grammar using a 150 line Python script which scraped a Java grammar web page they found online and translated it into the input format of the generator tool. They still needed to do some tree building in Scala but overall their parsing stage came in at 1073 lines to our 1443Ù« where most other teams use of LR parsing lead to larger parsers than our recursive descent one.</p>

<p>The rest of their compiler was similarly smaller than ours though without any obvious large design differencesÙ« although I didnâ€™t dig into the code. I suspect this is probably due to differences in expressiveness between Scala and Rust. Scala and Rust have similar functional programming features helpful for compilersÙ« like pattern matchingÙ« but Scalaâ€™s managed memory saves on code required to make the Rust borrow checker happy. Scala also has more miscellaneous syntactic sugar than Rust.</p>

<h2 id="ocaml">OCaml</h2>

<p>Since my team had all interned at <a href="https://www.janestreet.com/">Jane Street</a> the other language we considered using was OCamlÙ« we decided on Rust but I was curious about how OCaml might have turned out so I talked to someone else I knew had interned at Jane Street and they indeed did their compiler in OCaml with two other former Jane Street interns.</p>

<p>Their compiler was 10914 raw lines and 377kb including a small amount of test code and no extra features. They passed 9/10 secret tests and all public tests.</p>

<p>Like other groups it looks like a lot of the size difference is due to them using an LR parser generator and tree rewriting for parsingÙ« as well as a regex-&gt;NFA-&gt;DFA conversion pipeline for lexing. Their front-end (lexing+parsing+AST construction) is 5548 lines where ours is 2164Ù« with similar ratios for bytes. They also used <a href="https://blog.janestreet.com/testing-with-expectations/">expect tests</a> for their parser where we used similar snapshot tests that put the expected output outside the codeÙ« so their parser tests were ~600 lines of that total where ours were ~200.</p>

<p>That leaves 5366 lines (461 lines of which is interface files with just type declarations) for the rest of their compiler and 4642 for oursÙ« only 1.15x larger if you count interface files and basically the same size if you donâ€™t count them. So it looks like setting aside our parsing design decisionsÙ« Rust and OCaml seem similarly expressive except that OCaml needs interface files and Rust doesnâ€™t.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Overall Iâ€™m very glad I did this comparisonÙ« I learned a lot from it and was surprised many times. I think my overall takeaway is that design decisions make a much larger difference than the languageÙ« but the language matters insofar as it gives you the tools to implement different designs.</p>
'),('http://thume.ca/2019/04/18/writing-a-compiler-in-rust/', 'Writing a Compiler in Rust', '1555545600000',  13, '
<p>During my final term at UWaterloo I took <a href="https://www.student.cs.uwaterloo.ca/~cs444/">the CS444 compilers class</a> with a project to write a compiler from a substantial subset of Java to x86Ù« with a language and two teammates of your choice. My group of three chose to write our compiler in Rust and it was a fun experience. We spent time coming to design decisions that worked out really well and used Rustâ€™s strengths. Our compiler ended up being around 6800 lines of Rust and I personally put in around 60 hours of solid coding and more on code review and design. In this post Iâ€™ll go over some of the design decisions we made and some thoughts on what it was like using Rust.</p>

<h2 id="lexing-and-parsing">Lexing and Parsing</h2>

<p>The lectures for the course recommended writing an NFA to DFA compiler to implement the lexerÙ« and writing an <a href="https://en.wikipedia.org/wiki/Canonical_LR_parser">LR(1)</a> parser generator for the parserÙ« then having a separate â€œweedingâ€ pass to construct a final AST (<a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract Syntax Tree</a>) and validate it in various ways.</p>

<p>I suggested that we should try using a hand-written lexer and recursive descent parser insteadÙ« and my teammates agreed. A recursive descent parser allowed us to put all the code to parseÙ« validateÙ« and create the AST node in one place. We figured writing a pass to rewrite and validate the raw parse tree into a strongly typed AST would be about as much code as a recursive descent parserÙ« except with the additional work of having to implement an LR(1) parser generator.</p>

<p>The AST we produced made good use of Rustâ€™s type systemÙ« including extensive use of <code class="language-plaintext highlighter-rouge">enum</code> sum types to handle variants of typesÙ« expressions and statements. We also used <code class="language-plaintext highlighter-rouge">Option</code> and <code class="language-plaintext highlighter-rouge">Vec</code> extensivelyÙ« as well as <code class="language-plaintext highlighter-rouge">Box</code> to allow type recursion. Our AST types looked like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// We preserve source span information using a `Spanned` struct</span>
<span class="k">pub</span> <span class="k">type</span> <span class="n">Type</span> <span class="o">=</span> <span class="n">Spanned</span><span class="o">&lt;</span><span class="n">TypeKind</span><span class="o">&gt;</span><span class="p">;</span>

<span class="nd">#[derive(CloneÙ«</span> <span class="nd">DebugÙ«</span> <span class="nd">PartialEqÙ«</span> <span class="nd">EqÙ«</span> <span class="nd">Hash)]</span>
<span class="k">pub</span> <span class="k">enum</span> <span class="n">TypeKind</span> <span class="p">{</span>
    <span class="nf">Array</span><span class="p">(</span><span class="nb">Box</span><span class="o">&lt;</span><span class="n">Type</span><span class="o">&gt;</span><span class="p">)Ù«</span>
    <span class="nf">Ref</span><span class="p">(</span><span class="n">TypeRef</span><span class="p">)Ù«</span>
    <span class="n">Int</span><span class="p">Ù«</span>
    <span class="n">Byte</span><span class="p">Ù«</span>
    <span class="c">// ...</span>
<span class="p">}</span>

<span class="c">// ...</span>

<span class="nd">#[derive(CloneÙ«</span> <span class="nd">Debug)]</span>
<span class="k">pub</span> <span class="k">struct</span> <span class="n">InterfaceDecl</span> <span class="p">{</span>
    <span class="k">pub</span> <span class="n">name</span><span class="p">:</span> <span class="nb">String</span><span class="p">Ù«</span>
    <span class="k">pub</span> <span class="n">extends</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="n">TypeRef</span><span class="o">&gt;</span><span class="p">Ù«</span>
    <span class="k">pub</span> <span class="n">methods</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="n">Signature</span><span class="o">&gt;</span><span class="p">Ù«</span>
<span class="p">}</span>
</code></pre></div></div>

<p>We produced this using a <code class="language-plaintext highlighter-rouge">Parser</code> struct with functions for parsing different constructs that could also return parse errors. The <code class="language-plaintext highlighter-rouge">Parser</code> struct had a number of helper functions to easily consume and inspect tokensÙ« using the power of abstraction present in a full programming language to get closer to the brevity of a parser generator grammar DSL. Hereâ€™s an example of what our parser looked like:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[derive(CloneÙ«</span> <span class="nd">Debug)]</span>
<span class="k">pub</span> <span class="k">enum</span> <span class="n">ParseError</span> <span class="p">{</span>
    <span class="nf">Unexpected</span><span class="p">(</span><span class="n">SpannedToken</span><span class="p">)Ù«</span>
    <span class="nf">DuplicateModifier</span><span class="p">(</span><span class="n">SpannedToken</span><span class="p">)Ù«</span>
    <span class="n">MultipleVisibilities</span><span class="p">Ù«</span>
    <span class="c">// ...</span>
<span class="p">}</span>

<span class="k">pub</span> <span class="k">struct</span> <span class="n">Parser</span><span class="o">&lt;</span><span class="nv">"a</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="n">tokens</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">"a</span> <span class="p">[</span><span class="n">SpannedToken</span><span class="p">]Ù«</span>
    <span class="n">pos</span><span class="p">:</span> <span class="nb">usize</span><span class="p">Ù«</span>
<span class="p">}</span>

<span class="c">// ...</span>

<span class="k">fn</span> <span class="nf">parse_for_statement</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">PResult</span><span class="o">&lt;</span><span class="n">ForStatement</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">self</span><span class="nf">.eat</span><span class="p">(</span><span class="o">&amp;</span><span class="nn">Token</span><span class="p">::</span><span class="n">For</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
    <span class="k">self</span><span class="nf">.eat</span><span class="p">(</span><span class="o">&amp;</span><span class="nn">Token</span><span class="p">::</span><span class="n">LParen</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">init</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.parse_unless_and_eat</span><span class="p">(</span><span class="nn">Token</span><span class="p">::</span><span class="n">Semicolon</span><span class="p">Ù«</span> <span class="nn">Self</span><span class="p">::</span><span class="n">parse_for_init</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">condition</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.parse_unless_and_eat</span><span class="p">(</span><span class="nn">Token</span><span class="p">::</span><span class="n">Semicolon</span><span class="p">Ù«</span> <span class="nn">Self</span><span class="p">::</span><span class="n">parse_expr</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">update</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.parse_unless_and_eat</span><span class="p">(</span><span class="nn">Token</span><span class="p">::</span><span class="n">RParen</span><span class="p">Ù«</span> <span class="nn">Self</span><span class="p">::</span><span class="n">parse_statement_expr</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">body</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.parse_statement</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>
    <span class="nf">Ok</span><span class="p">(</span><span class="n">ForStatement</span> <span class="p">{</span> <span class="n">init</span><span class="p">Ù«</span> <span class="n">condition</span><span class="p">Ù«</span> <span class="n">update</span><span class="p">Ù«</span> <span class="n">body</span> <span class="p">})</span>
<span class="p">}</span>

<span class="c">// ...</span>

</code></pre></div></div>

<h3 id="backtracking">Backtracking</h3>

<p>Mostly our parser takes the form of an <a href="https://en.wikipedia.org/wiki/LL_parser">LL(1) parser</a>Ù« which looks ahead one token to decide how it should parse. But some constructs require unlimited lookahead to parse. For example <code class="language-plaintext highlighter-rouge">(java.lang.String)a</code> should parse as a parenthesized field access chain on the â€˜javaâ€™ variable except for the <code class="language-plaintext highlighter-rouge">a</code> at the endÙ« which makes it a cast expression. In fact even <code class="language-plaintext highlighter-rouge">LR(1)</code> parsers canâ€™t parse this specific case properlyÙ« and the recommended hack is to parse the inside of the parens as an â€œexpressionâ€ and then just validate in the weeder that the expression is actually a type.</p>

<p>We solve this problem using backtrackingÙ« which is where we can save a position in the token streamÙ« speculatively parse the following input as one constructÙ« and then roll back to that saved position if that parsing fails. This can cause non-linear parse times on pathological inputÙ« but pathological cases donâ€™t occur non-maliciously in practiceÙ« especially if backtracking is only used in some situations rather than for the whole parser.</p>

<p>An alternative strategy to backtracking that works in some situations is to parse the common elements of both nonterminals that could followÙ« then once the parser reaches the point where it can decideÙ« it calls the specific non-terminal function passing what has been parsed so far as arguments. We use this strategy for deciding between parsing classes and interfaces and between parsing methods and constructorsÙ« by parsing the modifiers firstÙ« then looking aheadÙ« then parsing the rest passing the parsed modifiers as arguments.</p>

<p>We have Rust helper functions that make backtracking really easy by trying one parse and then trying another if the first parse returns an <code class="language-plaintext highlighter-rouge">Err</code>:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// Unlike the Java specÙ« we can have arguments like `allow_minus` to avoid</span>
<span class="c">// massive duplication in the case of minor special cases.</span>
<span class="c">// `allow_minus` makes sure `(a)-b` parses as `int-int` rather than `(Type)(-int)`</span>
<span class="k">fn</span> <span class="nf">parse_prim_expr</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">Ù«</span> <span class="n">allow_minus</span><span class="p">:</span> <span class="n">AllowMinus</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">PResult</span><span class="o">&lt;</span><span class="nb">Box</span><span class="o">&lt;</span><span class="n">Expr</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">cur</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">self</span><span class="py">.tokens</span><span class="p">[</span><span class="k">self</span><span class="py">.pos</span><span class="p">];</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">lhs</span> <span class="o">=</span> <span class="k">match</span> <span class="o">&amp;</span><span class="n">cur</span><span class="py">.tok</span> <span class="p">{</span>
        <span class="nn">Token</span><span class="p">::</span><span class="n">LParen</span> <span class="k">=&gt;</span> <span class="k">self</span><span class="nf">.one_of</span><span class="p">(</span><span class="nn">Self</span><span class="p">::</span><span class="n">parse_cast_expr</span><span class="p">Ù«</span> <span class="nn">Self</span><span class="p">::</span><span class="n">parse_paren_expr</span><span class="p">)Ù«</span>
        <span class="c">// ...</span>
    <span class="p">};</span>
    <span class="c">// ...</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="pratt-expression-parsing">Pratt expression parsing</h3>

<p>Instead of parsing expressions with precedence using many grammar levelsÙ« we use a <a href="https://www.oilshell.org/blog/2017/03/31.html">Pratt parsing / precedence climbing</a> system. This algorithm allows specifying the operators as a table with a â€œbinding powerâ€ integerÙ« with higher binding power for operators with higher precedence. This is both easier and more efficient for parsing expressions with many levels of precedence.</p>

<p>Instead of using data tables like in the canonical Pratt parser implementationÙ« we used Rust functions with match statementsÙ« which fill the same purpose but with more power and no need to keep a data structure around:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">binding_power</span><span class="p">(</span><span class="n">cur</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">SpannedToken</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Option</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">match</span> <span class="o">&amp;</span><span class="n">cur</span><span class="py">.tok</span> <span class="p">{</span>
        <span class="nn">Token</span><span class="p">::</span><span class="nf">Operator</span><span class="p">(</span><span class="n">op</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="k">match</span> <span class="n">op</span> <span class="p">{</span>
            <span class="nn">Op</span><span class="p">::</span><span class="n">Times</span> <span class="p">|</span> <span class="nn">Op</span><span class="p">::</span><span class="n">Divide</span> <span class="p">|</span> <span class="nn">Op</span><span class="p">::</span><span class="nb">Modulo</span> <span class="k">=&gt;</span> <span class="nf">Some</span><span class="p">(</span><span class="mi">12</span><span class="p">)Ù«</span>
            <span class="nn">Op</span><span class="p">::</span><span class="n">Plus</span> <span class="p">|</span> <span class="nn">Op</span><span class="p">::</span><span class="n">Minus</span> <span class="k">=&gt;</span> <span class="nf">Some</span><span class="p">(</span><span class="mi">11</span><span class="p">)Ù«</span>
            <span class="nn">Op</span><span class="p">::</span><span class="n">Greater</span> <span class="p">|</span> <span class="nn">Op</span><span class="p">::</span><span class="n">GreaterEqual</span> <span class="p">|</span> <span class="nn">Op</span><span class="p">::</span><span class="n">Less</span> <span class="p">|</span> <span class="nn">Op</span><span class="p">::</span><span class="n">LessEqual</span> <span class="k">=&gt;</span> <span class="nf">Some</span><span class="p">(</span><span class="mi">9</span><span class="p">)Ù«</span>
            <span class="nn">Op</span><span class="p">::</span><span class="n">Equal</span> <span class="p">|</span> <span class="nn">Op</span><span class="p">::</span><span class="n">NotEqual</span> <span class="k">=&gt;</span> <span class="nf">Some</span><span class="p">(</span><span class="mi">8</span><span class="p">)Ù«</span>
            <span class="nn">Op</span><span class="p">::</span><span class="n">And</span> <span class="k">=&gt;</span> <span class="nf">Some</span><span class="p">(</span><span class="mi">7</span><span class="p">)Ù«</span>
            <span class="c">// ...</span>
        <span class="p">}Ù«</span>
        <span class="nn">Token</span><span class="p">::</span><span class="n">Instanceof</span> <span class="k">=&gt;</span> <span class="nf">Some</span><span class="p">(</span><span class="mi">9</span><span class="p">)Ù«</span>
        <span class="mi">_</span> <span class="k">=&gt;</span> <span class="nb">None</span><span class="p">Ù«</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="snapshot-testing">Snapshot testing</h2>

<p>Starting when we did our parser and continuing for the rest of our compilerÙ« we made extensive use of snapshot testing with the <a href="https://github.com/mitsuhiko/insta">insta crate</a>. Snapshot testing (similar to <a href="https://blog.janestreet.com/testing-with-expectations/">expect tests</a>) allows you to write tests which just provide the resulting data structure of some process and the testing system will create a â€œsnapshotâ€ of the result of that test in a fileÙ« and if the result ever changes it will cause a test failure and show you the diff between the snapshot file and the result it got. If the change was expectedÙ« you can then run a command to update the snapshot files that changed.</p>

<p>This was super useful for writing our parserÙ« before we could parse full files and do anything with themÙ« we could parse short snippets into AST types implementing the Rust <code class="language-plaintext highlighter-rouge">Debug</code> traitÙ« and <code class="language-plaintext highlighter-rouge">insta</code> would create pretty-printed snapshots that we could inspect for correctnessÙ« and then commit to check for future regressions.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[test]</span>
<span class="k">fn</span> <span class="nf">test_statement</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">lexer</span> <span class="o">=</span> <span class="nf">file_lexer</span><span class="p">(</span><span class="s">"testdata/statements.java"</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">tokens</span> <span class="o">=</span> <span class="n">lexer</span><span class="nf">.lex_all</span><span class="p">()</span><span class="nf">.unwrap</span><span class="p">();</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">parser</span> <span class="o">=</span> <span class="nn">Parser</span><span class="p">::</span><span class="nf">create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tokens</span><span class="p">);</span>

    <span class="k">let</span> <span class="n">statement</span> <span class="o">=</span> <span class="n">parser</span><span class="nf">.parse_statement</span><span class="p">();</span>
    <span class="nd">assert_debug_snapshot_matches!</span><span class="p">(</span><span class="s">"statements"</span><span class="p">Ù«</span> <span class="n">statement</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Later during the code generation phase we used this extensively to check our assembly output on test programs.</p>

<h2 id="semantic-analysis">Semantic analysis</h2>

<p>About half of our compiler is in the middle-end passes which compute information necessary for code generation and verify various correctness properties. This includes:</p>

<ul>
  <li>Resolving variable and type names.</li>
  <li>Folding constant expressions like <code class="language-plaintext highlighter-rouge">5*3+2</code> into numbers.</li>
  <li>Checking many different constraints of the Java class/interface hierarchy.</li>
  <li>Checking that all statements are reachable and all non-<code class="language-plaintext highlighter-rouge">void</code> functions return.</li>
  <li>Resolving types of all expressions and checking their correctness.</li>
</ul>

<h3 id="visitor-infrastructure">Visitor infrastructure</h3>

<p>Most of the passes in the middle of our compiler only care about certain AST nodesÙ« but need to act on those nodes anywhere they might occur in the AST. One way to do this would be to pattern match through the whole AST in every patchÙ« but thereâ€™s a lot of nodes so that would involve a lot of duplication.</p>

<p>Instead we have a <code class="language-plaintext highlighter-rouge">Visitor</code> trait (like an interface in other languages) which can be implemented by a compiler pass. It has callbacks only for the events we actually needÙ« which can run code at various points in the traversal of the ASTÙ« as well as modify the AST in place. All the callbacks have default implementations that do nothing so that passes only need to implement the methods they need.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// We use a dynamic error type here so we don"t have to make the visitor generic and</span>
<span class="c">// instantiate it a bunch for every error type</span>
<span class="k">pub</span> <span class="k">type</span> <span class="n">VResult</span> <span class="o">=</span> <span class="n">Result</span><span class="o">&lt;</span><span class="p">()Ù«</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="nn">std</span><span class="p">::</span><span class="nn">error</span><span class="p">::</span><span class="n">Error</span><span class="o">&gt;&gt;</span><span class="p">;</span>

<span class="k">pub</span> <span class="k">trait</span> <span class="n">Visitor</span> <span class="p">{</span>
    <span class="c">// used for resolving variable references</span>
    <span class="k">fn</span> <span class="nf">visit_var_ref</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">Ù«</span> <span class="mi">_</span><span class="n">t</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">VarRef</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span> <span class="p">{</span>
        <span class="nf">Ok</span><span class="p">(())</span>
    <span class="p">}</span>

    <span class="k">fn</span> <span class="nf">start_method</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">Ù«</span> <span class="mi">_</span><span class="n">t</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">Method</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span> <span class="p">{</span>
        <span class="nf">Ok</span><span class="p">(())</span>
    <span class="p">}</span>

    <span class="c">// `finish_` methods get passed the result of traversing their body so that they</span>
    <span class="c">// can wrap errors to provide better location information</span>
    <span class="k">fn</span> <span class="nf">finish_method</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">Ù«</span> <span class="mi">_</span><span class="n">t</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">Method</span><span class="p">Ù«</span> <span class="n">res</span><span class="p">:</span> <span class="n">VResult</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span> <span class="p">{</span>
        <span class="n">res</span>
    <span class="p">}</span>

    <span class="c">// like a `finish_` method except it doesn"t need the result</span>
    <span class="k">fn</span> <span class="nf">post_expr</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">Ù«</span> <span class="mi">_</span><span class="n">t</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">Expr</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span> <span class="p">{</span>
        <span class="nf">Ok</span><span class="p">(())</span>
    <span class="p">}</span>

    <span class="c">// ... a bunch of other methods</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Passes that implement <code class="language-plaintext highlighter-rouge">Visitor</code> are driven by dynamically dispatched calls from the <code class="language-plaintext highlighter-rouge">Visitable</code> traitÙ« which is implemented by every AST node and traverses the whole tree in evaluation order. A cool Rust feature we make good use of is â€œblanket implsâ€ which make the logic for handling AST children that are in containers clean and uniform.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">trait</span> <span class="n">Visitable</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">visit</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">Ù«</span> <span class="n">v</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">dyn</span> <span class="n">Visitor</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="p">:</span> <span class="n">Visitable</span><span class="o">&gt;</span> <span class="n">Visitable</span> <span class="k">for</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">visit</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">Ù«</span> <span class="n">v</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">dyn</span> <span class="n">Visitor</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span> <span class="p">{</span>
        <span class="k">for</span> <span class="n">t</span> <span class="n">in</span> <span class="k">self</span> <span class="p">{</span>
            <span class="n">t</span><span class="nf">.visit</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="nf">Ok</span><span class="p">(())</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c">// ... other blanket impls for Option&lt;T&gt; and Box&lt;T&gt;</span>

<span class="k">impl</span> <span class="n">Visitable</span> <span class="k">for</span> <span class="n">TypeKind</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">visit</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">Ù«</span> <span class="n">v</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">dyn</span> <span class="n">Visitor</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span> <span class="p">{</span>
        <span class="k">match</span> <span class="k">self</span> <span class="p">{</span>
            <span class="nn">TypeKind</span><span class="p">::</span><span class="nf">Array</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="nf">.visit</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">?</span><span class="p">Ù«</span>
            <span class="nn">TypeKind</span><span class="p">::</span><span class="nf">Ref</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="nf">.visit</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">?</span><span class="p">Ù«</span>
            <span class="mi">_</span> <span class="k">=&gt;</span> <span class="p">()Ù«</span>
        <span class="p">}</span>
        <span class="nf">Ok</span><span class="p">(())</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">impl</span> <span class="n">Visitable</span> <span class="k">for</span> <span class="n">ForStatement</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">visit</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">Ù«</span> <span class="n">v</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">dyn</span> <span class="n">Visitor</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span> <span class="p">{</span>
        <span class="n">v</span><span class="nf">.start_for_statement</span><span class="p">(</span><span class="k">self</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
        <span class="c">// closure allows us to use ? to combine results</span>
        <span class="k">let</span> <span class="n">res</span> <span class="o">=</span> <span class="p">(||</span> <span class="p">{</span>
            <span class="k">self</span><span class="py">.init</span><span class="nf">.visit</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
            <span class="k">self</span><span class="py">.condition</span><span class="nf">.visit</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
            <span class="k">self</span><span class="py">.update</span><span class="nf">.visit</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
            <span class="k">self</span><span class="py">.body</span><span class="nf">.visit</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="p">})();</span>
        <span class="n">v</span><span class="nf">.finish_for_statement</span><span class="p">(</span><span class="k">self</span><span class="p">Ù«</span> <span class="n">res</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c">// ... many other Visitable implementations</span>
</code></pre></div></div>

<p>This made a lot of our passes much easier. For example constant folding just overrides the <code class="language-plaintext highlighter-rouge">post_expr</code> methodÙ« checks if the children of an expression are constants and if so uses <code class="language-plaintext highlighter-rouge">mem::replace</code> to replace the node with a constant.</p>

<h3 id="resolving-names">Resolving names</h3>

<p>One discussion we had is how to handle resolving type and variable names. The most obvious way was doing so by mutating the AST using an <code class="language-plaintext highlighter-rouge">Option</code> field thatâ€™s initially <code class="language-plaintext highlighter-rouge">None</code>. However our functional programmer instincts felt icky about this so we tried to think of a better way. Using an optional field also had the problem that we knew by the code generation phase that all variables would be resolved but the type system would still think they could be <code class="language-plaintext highlighter-rouge">None</code> so weâ€™d need to <code class="language-plaintext highlighter-rouge">unwrap()</code> them every time we wanted to access them.</p>

<p>We first considered using a side table where weâ€™d give every named reference an ID or hash itÙ« then have a map from ID to resolved location that we created during the resolution stage. But we didnâ€™t like how this would make debugging harder since we could no longer just print out our AST types with <code class="language-plaintext highlighter-rouge">Debug</code> to see all their information including resolutions. It also would require passing around quite a few side tables and doing lots of lookups in them by the later stages. It didnâ€™t even solve the need for <code class="language-plaintext highlighter-rouge">unwrap</code> since the table access could theoretically not find the corresponding element.</p>

<p>Next we considered making all of our AST types generic with an annotation type parameter that started out as <code class="language-plaintext highlighter-rouge">()</code> but changed as the AST progressed through stages where it gained more info. The main problem with this is that each pass would need to re-build the entire ASTÙ« which would make easy visitor infrastructure much harder. Maybe if Rust had something like <a href="https://gitlab.haskell.org/ghc/ghc/wikis/commentary/compiler/derive-functor">an automatically derivable <code class="language-plaintext highlighter-rouge">Functor</code> implementation</a> it wouldnâ€™t have been badÙ« but barring that it would need a lot of boilerplate. There were also multiple things we needed to annotate at various stages necessitating many parametersÙ« and a lot of AST typesÙ« which would require a lot of refactoring our AST and parser to add a multitude of parameters.</p>

<p>So instead we just bit the bullet and used <code class="language-plaintext highlighter-rouge">Option</code> type fieldsÙ« and I think it worked out well. We implemented a nice <code class="language-plaintext highlighter-rouge">Reference&lt;TÙ« R&gt;</code> generic that had a <code class="language-plaintext highlighter-rouge">raw</code> and <code class="language-plaintext highlighter-rouge">resolved</code> field. We used it for both variable and type references. It had <code class="language-plaintext highlighter-rouge">Hash</code> and <code class="language-plaintext highlighter-rouge">PartialEq</code> implementations that only looked at the resolved value because thatâ€™s what mattered for data structures in later passes. It also had a special <code class="language-plaintext highlighter-rouge">Debug</code> implementation that made the output in snapshot tests nicer:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="p">:</span> <span class="nn">fmt</span><span class="p">::</span><span class="n">Debug</span><span class="p">Ù«</span> <span class="n">R</span><span class="p">:</span> <span class="nn">fmt</span><span class="p">::</span><span class="n">Debug</span><span class="o">&gt;</span> <span class="nn">fmt</span><span class="p">::</span><span class="n">Debug</span> <span class="k">for</span> <span class="n">Reference</span><span class="o">&lt;</span><span class="n">T</span><span class="p">Ù«</span> <span class="n">R</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">fmt</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">Ù«</span> <span class="n">f</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="nn">fmt</span><span class="p">::</span><span class="n">Formatter</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nn">fmt</span><span class="p">::</span><span class="n">Result</span> <span class="p">{</span>
        <span class="k">if</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">self</span><span class="py">.resolved</span> <span class="p">{</span>
            <span class="nd">write!</span><span class="p">(</span><span class="n">f</span><span class="p">Ù«</span> <span class="s">"{:#?} =&gt; {:#?}"</span><span class="p">Ù«</span> <span class="k">self</span><span class="py">.raw</span><span class="p">Ù«</span> <span class="n">r</span><span class="p">)</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="nd">write!</span><span class="p">(</span><span class="n">f</span><span class="p">Ù«</span> <span class="s">"{:?}"</span><span class="p">Ù«</span> <span class="k">self</span><span class="py">.raw</span><span class="p">)</span> <span class="c">// only print the raw if not resolved yet</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="reference-counting">Reference counting</h3>

<p>In a number of different placesÙ« especially the class hierarchy checking and type checking phasesÙ« a lot of things needed to have the same pieces of information propagated to them. For example types bubbling up an expression or inherited methods bubbling down a tree. In a language like Java weâ€™d just have multiple references to the same objectÙ« but in Rust for ownership reasons we couldnâ€™t do that straightforwardly. We started out in some places by <code class="language-plaintext highlighter-rouge">clone</code>ing things which worked fineÙ« but I realized I could just switch everything to use <code class="language-plaintext highlighter-rouge">Rc</code> to allow sharing.</p>

<p>I had an interesting moment where I thought â€œman it sucks that this code has to do all this reference count manipulationÙ« thatâ€™s unnecessarily slowÙ« maybe I should refactor this to use an arena or somethingâ€. Then I realized that if I had been writing in Swift I wouldnâ€™t have given this a second thought because <em>everything</em> would be ref-countedÙ« and even worse than the Rust versionÙ« <em>atomically</em> ref-counted. Writing code in Rust makes me feel like I have an obligation to make code as fast as possible in a way other languages donâ€™tÙ« just by surfacing the costs better. Sometimes I need to remind myself that actually itâ€™s fast enough already.</p>

<h2 id="code-generation">Code Generation</h2>

<p>The course requires that we generate textual NASM x86 assembly files. Given that we only need to output to thoseÙ« we decided we didnâ€™t need an intermediate abstraction for generating assemblyÙ« and our code generation stage could just use Rust string formatting. This would make our code simplerÙ« easier and also allow us to more easily include comments in the generated assembly.</p>

<p>The fact that we preserved source span information through our whole compiler and could generate comments came in handy because we could output comments containing the source expression/statement location for every single generated piece of code. This made it much easier to track down exactly which piece of code was causing a bug.</p>

<p>A somewhat annoying Rust thing we ran into is that we could find two easy ways of formatting to a stringÙ« both of which had an issue:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="k">mut</span> <span class="n">s</span> <span class="o">=</span> <span class="nn">String</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>
<span class="c">// Requires a Result return type or unwrapÙ« even though it won"t ever fail.</span>
<span class="c">// Generates a bunch of garbage error handling LLVM needs to optimize out.</span>
<span class="nd">writeln!</span><span class="p">(</span><span class="n">s</span><span class="p">Ù«</span> <span class="s">"mov eaxÙ« {}"</span><span class="p">Ù«</span> <span class="n">val</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
<span class="c">// Allocates an intermediate String which it then immediately frees</span>
<span class="n">s</span><span class="nf">.push_str</span><span class="p">(</span><span class="nd">format!</span><span class="p">(</span><span class="s">"mov eaxÙ« {}"</span><span class="p">Ù«</span> <span class="n">val</span><span class="p">));</span>
</code></pre></div></div>

<p>My two teammates worked on the initial stages of code generation in parallel and each of them chose a different fork of this tradeoffÙ« and by that close to the end of the course our consistency standards had relaxedÙ« so our code generation has both.</p>

<h3 id="usercorn">Usercorn</h3>

<p>Our compiler was supposed to output Linux ELF binaries and link to a runtime that made Linux syscalls. HoweverÙ« our entire team used macOS. Rewriting the runtime for macOS would have been somewhat annoying since syscalls arenâ€™t always as easy and well documented on macOS as Linux. It also would have added an annoying delay to running our tests and made the harness more complex if we had to <code class="language-plaintext highlighter-rouge">scp</code> the binaries to a Linux server or VM.</p>

<p>I remembered that my internet friend had written a cool tool called <a href="https://github.com/lunixbochs/usercorn">usercorn</a> that used the <a href="https://www.unicorn-engine.org/">Unicorn CPU emulator</a> plus some fanciness to run Linux binaries on macOS as if they were normal macOS binaries (or vice versa and a bunch of other things). It was straightforward to build a self-contained version that I could check into our repository and use in our tests to run our binaries. My teammate then got together a macOS build of <code class="language-plaintext highlighter-rouge">ld</code> that could link Linux ELF binaries and included it.</p>

<p>We could also use <code class="language-plaintext highlighter-rouge">usercorn</code> to output a trace of all the instructions executed and registers modified by our programsÙ« and this came in handy quite a few times for debugging our code generation.</p>

<p>I ran into one problem where a test program that did a lot of allocation was 1000x slower under usercorn than on a real Linux server. Luckily I knew the author and I just sent him the offending binary and he quickly figured it was due to an inefficient implementation of the <code class="language-plaintext highlighter-rouge">brk</code> syscall which reasonable programs donâ€™t use for every single memory allocation like the runtime the course provided did. He quickly figured out how to make it more efficient and pushed a fix later that evening which solved my problem. Heâ€™s pretty awesomeÙ« <a href="https://www.patreon.com/lunixbochs/overview">subscribe to his Patreon!</a></p>

<p>I then shared our pre-compiled bundle of <code class="language-plaintext highlighter-rouge">usercorn</code> and <code class="language-plaintext highlighter-rouge">ld</code> (with the bug fix for the assignment tests) with a few other teams I knew who used macOS so they could have an easier time testing as well.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Overall Iâ€™m proud of how our compiler turned out. It was a fun project and my teammates were excellent. I also think Rust ended up being a good choice of implementation languageÙ« especially the powerful <code class="language-plaintext highlighter-rouge">enum</code>s and pattern matching. The main downsides of Rust were the long compile times (although apparently comparable to a group that did their compiler in C++)Ù« and the fact that sometimes we had to do somewhat more work to satisfy the borrow checker.</p>

<p>One of the most interesting learning experiences from the project was when afterwards I talked to some other teams and got to compare what it was like to do the same project in different languages and with different design decisions. Iâ€™ll talk about that in an upcoming post!</p>
'),('http://thume.ca/2019/03/03/my-tungsten-cube/', 'My Tungsten Cube', '1551571200000',  13, '
<p>A few months ago I bought a featureless cube of tungsten. Itâ€™s 1.5 inches across and cost $130Ù« but I argue it was one of the best purchases Iâ€™ve made recently.</p>

<p>Why would I spend so much money on a cube? Well itâ€™s really dense. Tungsten is one of the densest elementsÙ« over twice the density of steel. My cube weighs one kilogram despite being pretty small. The first time I held a friendâ€™s tungsten cube I was blown awayÙ« it felt like some otherworldy force was pulling the cube down into my hand (spoiler: it was gravity). Whenever I show people my cube they consistently find it really cool and itâ€™s fun to be able to so easily share a unique experience like that.</p>

<p>Even after the initial surprise wore offÙ« I still find it just really satisfying to hold. Ever hold something with satisfying heft? Well itâ€™s like the platonically purest amplified form of that satisfaction. I keep it on my desk and turn it around in my hands while Iâ€™m thinking.</p>

<p>The cool thing about it being a featureless hunk of extremely hardÙ« durable metal that doesnâ€™t really oxidize awayÙ« is that it will last for a long time. I expect Iâ€™ll continue getting value out of having this cube on my desk for at least 5 years and probably more. Given how much I fidget with the cube and enjoy owning itÙ« I figure I definitely get more than $2/month worth of value out of it.</p>

<p>I struggled a lot with deciding to buy a cube. It felt <em>wrong</em> to spend so much money on a featureless hunk of metal. Money is for buying fancy doo-dadsÙ« or large thingsÙ« or hotel nightsÙ« or any number of other things that cost about as much while delivering arguably less value. On the other hand there was something appealing to me about buying an object that was so <em>platonically good</em>. It was just a really dense cube that I could derive a pure and weird form of satisfaction from holding.</p>

<p>AnyhowÙ« tungsten cubesÙ« 10/10 would recommend. Thereâ€™s a reason they have <a href="https://www.amazon.com/Tungsten-Cube-1-5-One-Kilo/dp/B00XZBIJLS/">so many 5 star Amazon reviews</a>. Maybe some day Iâ€™ll work up the courage to buy a <a href="https://www.amazon.com/dp/B01N23DISF/">$500 one thatâ€™s over 10 pounds</a> like my housemate last term did.</p>
'),('http://thume.ca/2018/08/16/def-con-26-ctf-writeups/', 'DEF CON 26 CTF Writeups: reverseÙ« doublethinkÙ« bewÙ« reeducation', '1534377600000',  13, '
<p>Recently I flew to Vegas to attend the DEF CON 26 CTF with (<a href="https://ctftime.org/team/1937">Samurai</a>)Ù« the team I <a href="/2018/05/13/winning-def-con-quals-writeups/">played with when we won the qualifiers</a>. I had a lot of fun and got very little sleepÙ« working two consecutive 20 hour days and finishing off with another 4 hours of contest at the end.</p>

<p>As a programmer entering CTF with only a little bit of reverse engineering experience and no exploit development skillsÙ« I was happy that the organizers included new King of the Hill format challenges this yearÙ« which I found I could contribute nicely to since they tended to mix in more programming with the hacking. I also made sure to spend some time poking around other challenge binaries in Binary Ninja to hone my reverse engineering skillsÙ« although I only managed to make a meaningful contribution doing this with <code class="language-plaintext highlighter-rouge">reeducation</code>.</p>

<h1 id="reverse">reverse</h1>

<p>The first challenge released and the first I worked on was <code class="language-plaintext highlighter-rouge">reverse</code>. It was a service with a client binary and a remote server that presented a curses interface for completing disassembly and assembly puzzles like filling in the line of assembly that matched some bytes of machine code. There were multiple â€œlevelâ€s consisting of a bunch of puzzlesÙ« solving them got you points and let you move to the next levelÙ« and each level was a new type of puzzle.</p>

<p>While a few of us in the hotel suite got started on figuring out how we wanted to automate itÙ« people on the floor started solving puzzles manuallyÙ« then <a href="https://twitter.com/lunixbochs"><code class="language-plaintext highlighter-rouge">aegis</code></a> gradually built up a UI automation script that copied data from his terminalÙ« parsed itÙ« ran it through command line (dis)assembler tools and typed the answers.</p>

<p>Back in the hotelÙ« a couple of us started on parsing the client output out of the VT100 but a teammate figured out the network protocol the client used so we started using that directly. The first level could actually be solved using an info leak that was present in the protocol but didnâ€™t show up in the clientÙ« but this didnâ€™t work for level 2 and up.</p>

<p>We then integrated the solvers for levels 1-4 from <code class="language-plaintext highlighter-rouge">aegis</code>â€™s automation into our script so <code class="language-plaintext highlighter-rouge">aegis</code> could stop having his computer taken over by UI automation every round.</p>

<p>We ran into a problem thoughÙ« we couldnâ€™t get through level 5 since the problems seemed nonsensical and impossible. There just wasnâ€™t enough information in the question to choose the right answer. We realized that there must be some way to cheat to solve it.</p>

<p>Luckily someone else on our team had been reversing the client and fuzzing the network protocol and had discovered a number of helpful tricks like the ability to not spend the limited â€œcoinsâ€ we had to attempt challengesÙ« and to restart a level as much as we wanted. After <code class="language-plaintext highlighter-rouge">aegis</code> noted that he saw duplicate assembly lines in his logs and that we should try dumpingÙ« I started on a script. I modified our solver Python code to use the protocol tricks to quickly request level 1 problems in a pipelined way to not have to wait for round trips and dump them to a file. Then <code class="language-plaintext highlighter-rouge">aegis</code> tuned up the script and ran it on the CTF floor dumping thousands of lines of assembly per secondÙ« eventually converging around 280k unique lines.</p>

<p>I then started on using these dumps to write better versions of our solvers (which previously often failed to determine the correct answer) by cheating with the known lines. This allowed us to resolve the difference between say <code class="language-plaintext highlighter-rouge">call sub_1432</code> and <code class="language-plaintext highlighter-rouge">call sub_2532</code> without knowing where the procedures were and made our solving simpler and more robust. We also incorporated an underflow bug a teammate discovered from poking at the server that gave us an extra 255 points per question. Unfortunately the dump didnâ€™t give us any clues as to how to solve level 5Ù« and unfortunately the dumped binary didnâ€™t appear to be the server like weâ€™d hoped. At this point the challenge was close to closing so we gave up and started on other problems.</p>

<p>After the contest we learned from the organizers there was a broken protocol instruction discoverable by fuzzing that allowed you to leak the server binary. You could then find an exploit allowing you to give yourself arbitrarily many points.</p>

<h1 id="doublethink">doublethink</h1>

<p>This was another King of the Hill challengeÙ« released just before the contest shut down on the first dayÙ« it was a fun problem that motivated me to stay up nearly all night.</p>

<p>The gist of the challenge was that you submitted a single 4KB chunk of binary that you could then execute against a number of different architectures using various emulatorsÙ« the more architectures you got to print the flag the higher your score. So the goal was to write a polyglot piece of shellcode that opened a flag file and wrote it out on modern architecturesÙ« or printed it from a known memory address on older architectures.</p>

<p>We realized we needed to write flag-printing shellcode for a bunch of architectures separately and then put them together in one blob with a sequence of jump instructions at the front for each architecture jumping to that architectureâ€™s payloadÙ« and where all the other architectureâ€™s jumps before it didnâ€™t stop the emulator or jump somewhere unintended. Another interesting twist is that a lot of the old architectures bytes/words with varying numbers of bitsÙ« which were just chopped off the file you gave by concatenating all the bytes in binary and chunking.</p>

<p>We decided to start by developing a bunch of payloads in parallel that we would assemble later. I started with PDP-8Ù« where after reading the instruction reference I found a <a href="https://bigdanzblog.wordpress.com/2014/05/31/hello-world-program-for-pdp-8-using-pal-assembly-language/">Hello World program</a> and <a href="https://github.com/radekh/palbart">a matching assembler</a>. The first challenge was that the output format of the assembler didnâ€™t match the format the challenge wantedÙ« so I had to write a 50 line python script to parse the assembled output and put it together at the bit level (because of the 12 bit bytes). After that I checked it printed Hello World against the provided testing Docker imageÙ« then modified the program to print the flagÙ« and made it much shorter.</p>

<p>I followed a similar process to construct a payload for PDP-10. After a bunch of architecture research and miscellaneous searching I found <a href="https://github.com/aap/tenth">an assembler as part of someoneâ€™s FORTH project</a>. I translated a Hello World program I found into that assemblerâ€™s syntax and modified the assembler code to print the info I neededÙ« and again wrote a Python script to parse the output and munge the bits into the format we neededÙ« then again modified the program to print the flag.</p>

<p>By this point other members of my team had written payloads for <code class="language-plaintext highlighter-rouge">clemency</code>Ù« <code class="language-plaintext highlighter-rouge">mix</code>Ù« <code class="language-plaintext highlighter-rouge">amd64</code> and <code class="language-plaintext highlighter-rouge">riscv</code> which we considered sufficient to start pulling them together. I started by writing a script to print a file as the bytes of varying bit widths including values in octal (which PDP system ISAs matched well with) so we could debug the jump train. Then I wrote a script to assemble jump sequences and payloads for different architectures at bit-level offsets. Then <code class="language-plaintext highlighter-rouge">aegis</code> and I worked together for a while and found a sequence of jumpsÙ« nops and padding that worked for <code class="language-plaintext highlighter-rouge">amd64</code>Ù« <code class="language-plaintext highlighter-rouge">pdp-8</code> and <code class="language-plaintext highlighter-rouge">pdp-10</code> together. After I went to bed a teammate managed to patch in a very short <code class="language-plaintext highlighter-rouge">mix</code> shellcode into oursÙ« leaving us with a 4-polyglot for the start the next day.</p>

<p>The next day I spent a bunch of hours with <code class="language-plaintext highlighter-rouge">aegis</code> trying to get a working sequence including <code class="language-plaintext highlighter-rouge">riscv</code> and failingÙ« and improving tooling and commenting it so others could try integrating more jumps. We mostly failed because things had too many constraints to fit in our head so by the time we thought we were approaching a solution we forgot an earlier constraint and went down a dead end. Eventually a teammate wrote a <code class="language-plaintext highlighter-rouge">pdp-1</code> payload and that ISA had few constraints and slotted pretty easily into our existing jump trainÙ« getting us to a 5-polyglot. I then tried and failed to integrate <code class="language-plaintext highlighter-rouge">hexagon</code> and <code class="language-plaintext highlighter-rouge">ibm-1401</code>. By that time the challenge was close to ending and we decided to move onÙ« with <code class="language-plaintext highlighter-rouge">clemency</code>Ù« <code class="language-plaintext highlighter-rouge">hexagon</code>Ù« <code class="language-plaintext highlighter-rouge">ibm-1401</code>Ù« and <code class="language-plaintext highlighter-rouge">riscv</code> payloads unusedÙ« which was sad.</p>

<p>It later turned out that this challenge too was possible to exploit to get an artificially high scoreÙ« according to the organizers and our later investigation. It was possible to use the <code class="language-plaintext highlighter-rouge">amd64</code> shellcode which was run directly (as <code class="language-plaintext highlighter-rouge">nobody</code>) concurrently from multiple submissions to fake a correct flag printing. This allowed two teams to get â€œfakeâ€ scores of 9 and 11Ù« although PPP (the 2nd place team) did actually create an 8-polyglot.</p>

<h1 id="bew">bew</h1>

<p>Released just before the end of the second dayÙ« this was the next challenge I worked on. It was a web app with a text field you could submit to to add text to a file that was printed on another page.</p>

<p>While the contest servers were still upÙ« we looked into the source and realized that the <code class="language-plaintext highlighter-rouge">express-validator</code> dependency had been replaced by an entirely different library using a WebAssembly module compiled with <a href="https://github.com/kripken/emscripten">Emscripten</a>. All inputs to the text file were passed through the validator library before being added to the text file.</p>

<p>After some theorizing about possible exploits involving using the Emscripten standard library emulation to use the Node <code class="language-plaintext highlighter-rouge">fs</code> module to get the flagÙ« we noticed on the submissions page that people were submitting exploits involving plain JS code and it seemed to work. We were confused but <code class="language-plaintext highlighter-rouge">aegis</code> started putting together our own flag retrieval payload that could get past the pre-filters while other members of our team started scraping flags other teams had retrieved with a script.</p>

<p>Eventually we found that the way the service worked was dumber than we thought. The WebAssembly did some preliminary filtering looking for use of <code class="language-plaintext highlighter-rouge">require</code> or the <code class="language-plaintext highlighter-rouge">fs</code> moduleÙ« then it passed the input to an external handler (below) which just took the input and <code class="language-plaintext highlighter-rouge">eval</code>â€˜d it in the Node server processÙ« and put the input in the text file if it threw an exception. This looked initially like it was rejecting JS and accepting text because most text triggers JS errors. The basic exploits people were using just obscured the <code class="language-plaintext highlighter-rouge">require</code> and <code class="language-plaintext highlighter-rouge">fs</code> use and used that to get the flag and put it in a public placeÙ« which we were also scraping without even deploying our own exploit!</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// The handler that the WebAssembly called into</span>
<span class="kd">var</span> <span class="nx">ASM_CONSTS</span> <span class="o">=</span> <span class="p">[</span><span class="kd">function</span><span class="p">(</span><span class="nx">$0</span><span class="p">)</span> <span class="p">{</span> <span class="nx">str</span> <span class="o">=</span> <span class="nx">Pointer_stringify</span><span class="p">(</span><span class="nx">$0</span><span class="p">);</span> <span class="k">try</span> <span class="p">{</span> <span class="nb">eval</span><span class="p">(</span><span class="nx">str</span><span class="p">);</span> <span class="k">return</span> <span class="mi">1</span><span class="p">;}</span> <span class="k">catch</span><span class="p">(</span><span class="nx">err</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="mi">0</span><span class="p">;</span> <span class="p">}</span> <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nb">eval</span><span class="p">(</span><span class="dl">"</span><span class="s1">const fs = require("fs");fs.writeFile("/tmp/test.txt"Ù« "testwrites")</span><span class="dl">"</span><span class="p">)</span> <span class="o">+</span> <span class="dl">"</span><span class="s1">WEBASS got </span><span class="dl">"</span> <span class="o">+</span> <span class="nx">$0</span><span class="p">);</span> <span class="p">}];</span>
</code></pre></div></div>

<p>After the contest servers closed for the nightÙ« we did some thinking about the challenge. Based on the large number of bytes you were allowed to patch only in the WebAssembly fileÙ« it seemed the intended patching solution was to write an actual JS validatorÙ« compile it to WASM and patch it inÙ« with functional tests likely verifying that the web app still accepted text and rejected JS. This sounded like a lot of workÙ« so we thought weâ€™d poke around with our full remote code execution some more.</p>

<p>I realized that I could patch the server dynamically by just reassigning the <code class="language-plaintext highlighter-rouge">ASM_CONSTS</code> variable (in scope!) to not <code class="language-plaintext highlighter-rouge">eval</code> the string and either reject or accept all submissionsÙ« fully closing the <code class="language-plaintext highlighter-rouge">eval</code> hole. This would persist until the server was restartedÙ« and based on the persistent text file we knew that the server was kept alive between requests. I eventually refined this into a version that left a back door so that we could still exploit the server if we messed upÙ« and also made sure our exploits (containing <code class="language-plaintext highlighter-rouge">/</code> and <code class="language-plaintext highlighter-rouge">_</code>) couldnâ€™t accidentally end up in the public text file:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">ASM_CONSTS</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="kd">function</span><span class="p">(</span><span class="nx">ptr</span><span class="p">)</span> <span class="p">{</span> <span class="nx">str</span> <span class="o">=</span> <span class="nx">Pointer_stringify</span><span class="p">(</span><span class="nx">ptr</span><span class="p">);</span> <span class="k">if</span><span class="p">(</span><span class="nx">str</span><span class="p">.</span><span class="nx">includes</span><span class="p">(</span><span class="dl">"</span><span class="s2">DAT_BEST_BACK_DOOR_SECRET</span><span class="dl">"</span><span class="p">))</span> <span class="nb">eval</span><span class="p">(</span><span class="nx">str</span><span class="p">);</span> <span class="k">return</span> <span class="p">(</span><span class="nx">str</span><span class="p">.</span><span class="nx">includes</span><span class="p">(</span><span class="dl">"</span><span class="s2">_</span><span class="dl">"</span><span class="p">)</span> <span class="o">||</span> <span class="nx">str</span><span class="p">.</span><span class="nx">includes</span><span class="p">(</span><span class="dl">"</span><span class="s2">/</span><span class="dl">"</span><span class="p">))</span> <span class="p">?</span> <span class="mi">1</span> <span class="p">:</span> <span class="mi">0</span><span class="p">;</span> <span class="p">}</span>
</code></pre></div></div>

<p>Meanwhile <code class="language-plaintext highlighter-rouge">aegis</code> figured out that he could modify the <code class="language-plaintext highlighter-rouge">express</code> web server handler chain to do all sorts of fun things. First he figured out how to take down all the pagesÙ« then how to add a backdoor flag page by mounting root as a public directory.</p>

<p>I talked this with <code class="language-plaintext highlighter-rouge">aegis</code> and we realized this was so absurdly easy and powerful that the organizers couldnâ€™t have thought of it. We realized we could insert a backdoor that let us get the flag and then close the door to all the other teamsÙ« with the only weakness being if another team realized this and closed the door first. If no other teams figured this out and beat us then we would get all the flags and no other team would get anyÙ« we could also close our own door without inserting the backdoor.</p>

<p>We realized that if we were lucky and were the only team to figure this outÙ« we needed to not leak our exploit publicly so other teams could immediately figure it out themselves. So I started by developing a thrower script for our exploits that could be run automatically and would ensure a team was backdoored and the door was closed without leaking our exploit in case of a patched team that accepted all submissions:</p>

<ol>
  <li>Check our flag backdoorÙ« if itâ€™s there weâ€™re done.</li>
  <li>Submit a canary piece of bogus JS code that used all the syntactic constructs our exploits usedÙ« if it went through then submitting our exploits would leak themÙ« so abandon.</li>
  <li>Install the backdoor express chain rewriting code.</li>
  <li>Check that we can retrieve the flagÙ« if not bail and log an error.</li>
  <li>Close the door and check that the door was successfully closed and log if not.</li>
</ol>

<p>Next I worked on improving <code class="language-plaintext highlighter-rouge">aegis</code>â€™s payload to place the flag backdoor at a less obvious place than <code class="language-plaintext highlighter-rouge">/flag</code> which required some URL rewriting. This is the payload I ended up with:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Part 1: exposes the flag at /flagaaa</span>
<span class="nx">s</span> <span class="o">=</span> <span class="nx">process</span><span class="p">.</span><span class="nx">mainModule</span><span class="p">.</span><span class="nx">children</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">children</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nx">exports</span><span class="p">.</span><span class="kd">static</span><span class="p">(</span><span class="dl">"</span><span class="s1">/</span><span class="dl">"</span><span class="p">);</span>
<span class="nx">process</span><span class="p">.</span><span class="nx">mainModule</span><span class="p">.</span><span class="nx">children</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">exports</span><span class="p">.</span><span class="nx">_router</span><span class="p">.</span><span class="nx">stack</span><span class="p">[</span><span class="mi">5</span><span class="p">].</span><span class="nx">handle</span> <span class="o">=</span> <span class="kd">function</span><span class="p">(</span><span class="nx">req</span><span class="p">Ù«</span> <span class="nx">res</span><span class="p">Ù«</span> <span class="nx">next</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">if</span><span class="p">(</span><span class="nx">req</span><span class="p">.</span><span class="nx">url</span> <span class="o">&amp;&amp;</span> <span class="nx">req</span><span class="p">.</span><span class="nx">url</span><span class="p">.</span><span class="nx">includes</span><span class="p">(</span><span class="dl">"</span><span class="s1">flag</span><span class="dl">"</span><span class="p">))</span> <span class="p">{</span>
    <span class="nx">req</span><span class="p">.</span><span class="nx">url</span> <span class="o">=</span> <span class="nx">req</span><span class="p">.</span><span class="nx">url</span><span class="p">.</span><span class="nx">substring</span><span class="p">(</span><span class="mi">0</span><span class="p">Ù«</span> <span class="nx">req</span><span class="p">.</span><span class="nx">url</span><span class="p">.</span><span class="nx">length</span><span class="o">-</span><span class="mi">3</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="k">return</span> <span class="nx">s</span><span class="p">(</span><span class="nx">req</span><span class="p">Ù«</span> <span class="nx">res</span><span class="p">Ù«</span> <span class="nx">next</span><span class="p">);</span>
<span class="p">};</span>
</code></pre></div></div>

<p>By this point it was 4am and we were tired after our 2nd consecutive 20 hour day so we went to sleep. We woke up just before the contest opened againÙ« and I got ready to throw our door closer at our own server manually since we had only automated the throwing at other teams.</p>

<p>But our worst fears came true and total victory was snatched from our grasp by a faster team! I threw the door closer at our own server shortly after opening and found that our canary went through when it shouldnâ€™t. I checked with some other test payloads and sure enoughÙ« it seemed that some other team had closed our door on usÙ« presumably after backdooring our server and all the others for themselves. It also turns out the exploit payload had errored in our automated thrower at minute 0 so we hadnâ€™t slipped in to any teams first.</p>

<p>Shortly later the contest organizers realized or were informed of their oversight about persistent exploits and they put in a workaround of restarting the servers every couple minutes to give all teams a chance to slip in. After streamlining my thrower to not be cautious and be faster since clearly lots of other teams knew about the problem and were already leaking their exploitsÙ« we managed to regularly slip into a few teams servers each restart.</p>

<p>It wasnâ€™t the glorious victory of monopolizing the flags that weâ€™d dreamed ofÙ« but we still got some people and were really proud of our clever plan and exploits.</p>

<h1 id="reeducation">reeducation</h1>

<p>In the last two hours of the contestÙ« I took a look at the new <code class="language-plaintext highlighter-rouge">reeducation</code> challenge. This was an attack/defend binary challenge that appeared to have been written in Rust.</p>

<p>My teammates had already run a Rust demangler on the symbols and had identified some interesting functions including one including <code class="language-plaintext highlighter-rouge">interpret</code> and determined that we could submit a payload to the service and it would run it through the interpreter.</p>

<p>While they worked on reverse engineering the stages leading to the interpreter I looked at the interpreter in Binary Ninja and used <code class="language-plaintext highlighter-rouge">gdb</code> to test the binary and figure out which registers contained the payload and length. I figured out that each â€œinstructionâ€ was two 64 bit words where if the instruction was <code class="language-plaintext highlighter-rouge">(aÙ«b)</code> it seemed to execute <code class="language-plaintext highlighter-rouge">mem[a] -= mem[b]</code> on the same memory array containing the code (allowing self modification).</p>

<p>I also discovered with <code class="language-plaintext highlighter-rouge">gdb</code> that the flag was placed in memory immediately after the submitted code. I also learned from <code class="language-plaintext highlighter-rouge">gdb</code> that the length register contained 1024 which was the length of the payload in bytesÙ« but in Binary Ninja I saw the bounds checking code was treating that length as the length in 64 bit words. This allowed the payload to access 8 times the memory it should have been able to without triggering an out of bounds errorÙ« including the flag! This looked to be the intended vulnerabilityÙ« Iâ€™m guessing caused by incorrect use of Rustâ€™s <code class="language-plaintext highlighter-rouge">unsafe</code> <code class="language-plaintext highlighter-rouge">Vec::from_raw_parts</code> or <code class="language-plaintext highlighter-rouge">slice::from_raw_parts_mut</code> passing in the byte length instead of the <code class="language-plaintext highlighter-rouge">u64</code> lengthÙ« an example of how if you use <code class="language-plaintext highlighter-rouge">unsafe</code> functions wrong in RustÙ« it can lead to vulnerabilities!</p>

<p>At this point I went and found some teammates in the hotel also working on the problem and shared all the knowledge I hadnâ€™t already posted on Slack. They had figured out that the payload we submitted had to contain only bytes of below a certain value. We figured out we had all the knowledge we needed to write an exploitÙ« but we only had 40 minutes of contest leftÙ« which was likely not enough.</p>

<p>My teammates started on an exploit script and I helped out occasionallyÙ« figuring out that we could use self-modifying code to access offsets that wouldnâ€™t otherwise make it through the byte value filter. Unfortunately we didnâ€™t have enough time to get a working exploit together.</p>

<p>HoweverÙ« while they were working on that I worked on developing a patch. In Binary Ninja I figured out that just underneath the code that initially retrieved the length there was a right shift that divided by 8 for use by some other part of the code. I used Binary Ninjaâ€™s patching functionality to fix that code to replace the <code class="language-plaintext highlighter-rouge">movÙ« shr</code> with a <code class="language-plaintext highlighter-rouge">shrÙ« mov</code> sequence of the same length that shifted the main length register and then copied it into the other register. The idea was this would fix the length to be the correct length to not allow out of bounds indexing to reach the flag. I posted my 7 byte patch in the Slack channel and one of the people on the floor submitted a patched binary using their better networking 15 minutes before the end of the contest. UnfortunatelyÙ« the scoreboard was hidden for the final day of the contest so although my patch passed the testsÙ« I donâ€™t know if it actually succeeded in getting us a few extra defense points in the final couple ticks.</p>

<h1 id="conclusion">Conclusion</h1>

<p>I had a ton of funÙ« and my team (Samurai) ended up coming 11thÙ« which although it isnâ€™t as good as our first place finish in the qualifiersÙ« is pretty good considering how high level the competition at the event was. I also learned a bunch more about competing in CTFs from my awesome teammates!</p>
'),('http://thume.ca/2018/05/13/winning-def-con-quals-writeups/', 'Winning the DEF CON Quals CTF! Writeups: Easy PisyÙ« FlagsifierÙ« Geckome', '1526169600000',  13, '
<p>A friend invited me to join his CTF team (<a href="https://ctftime.org/team/1937">Samurai</a>) this year for the Plaid CTF and the DEF CON qualifiers and I thought that sounded fun and wanted to learn more security and reverse engineeringÙ« so I did. For Plaid I just spent a couple hours tinkering with a few problems with my main accomplishment being reverse engineering a complicated APL program. For DEF CON I decided to go all out and dedicate my entire weekend to it. I had a really great timeÙ« and <a href="https://scoreboard.oooverflow.io/#/scoreboard">we won</a>!</p>

<p>I solved three problems mostly by myself: Easy PisyÙ« Flagsifier and Geckome. The last two were the 6th and 1st least-solved challenges in the gameÙ« and the less people solved a challenge the more points it was worth. This corresponds a little to how much work was requiredÙ« but also to how many lucky/clever/random insights are requiredÙ« and how much effort other teams decided to put in. Iâ€™d say Flagsifier was genuinely tricky but GeckomeÙ« the least-solved challengeÙ« was mostly luck and good tactics and wasnâ€™t much work compared to many other challenges.</p>

<p>I spent the last 4 hours of the CTF working on a solution to â€œadamtuneâ€Ù« and I finished a whole bunch of work that did what I intendedÙ« it just turned out the results werenâ€™t very good. The way the problem worked it was impossible to tell ahead of time whether my approach would be good enoughÙ« so I just had to spend the time and it didnâ€™t pan out. Now that <a href="https://github.com/o-o-overflow/chall-adamtune/blob/master/src/adamtune.py">the source</a> has been postedÙ« it seems like my basic approach was correctÙ« and that if I had used the Watson speech to text API instead of the Google one it may have given me the extra info I needed to make a good solution.</p>

<p>I also contributed a bit to discussion and reverse engineering on a few other problemsÙ« including â€œItâ€™s-a me!â€Ù« â€œTech Supportâ€ and â€œexzendtential-crisisâ€.</p>

<p>Without further adoÙ« hereâ€™s my writeups for the problems that I solved:</p>

<h2 id="easy-pisy">Easy Pisy</h2>

<p>A web app gave us the ability to sign a PDF and then submit a signed PDF. There was accessible source for the PHP scripts and sample PDFS. The source and examples showed that the PDFâ€™s could contain two possible commands: <code class="language-plaintext highlighter-rouge">ECHO</code> and <code class="language-plaintext highlighter-rouge">EXECUTE</code> (which runs a shell command). The signing script would only sign <code class="language-plaintext highlighter-rouge">ECHO</code> PDFs so you couldnâ€™t trivially execute any command.</p>

<p>Running one of the sample PDFs through showed the commands being run included converting the PDF to a PPM file and then running <code class="language-plaintext highlighter-rouge">ocrad</code> (an OCR tool) to extract the text out of them.</p>

<p>One of the example PDFs ran <code class="language-plaintext highlighter-rouge">EXECUTE ls</code> and came with a signatureÙ« it showed there was a <code class="language-plaintext highlighter-rouge">flag</code> file in the working directory.</p>

<p>So the problem was how to get a signed PDF that shows the text <code class="language-plaintext highlighter-rouge">EXECUTE cat flag</code>Ù« when we could only sign a PDF that had an <code class="language-plaintext highlighter-rouge">ECHO</code> command. This sounded a lot like it could involve the recent-ish PDF SHA1 collision. A quick check of the PHP docs showed that the <code class="language-plaintext highlighter-rouge">openssl_verify</code> function they used defaults to using SHA1 signatures!</p>

<p>My teammate <code class="language-plaintext highlighter-rouge">fstenv</code> found the <a href="https://alf.nu/SHA1">https://alf.nu/SHA1</a> website for generating colliding PDFsÙ« and I quickly opened Pixelmator and drew up one JPEG that said <code class="language-plaintext highlighter-rouge">ECHO hi</code> in big Arial font and another that said <code class="language-plaintext highlighter-rouge">EXECUTE cat flag</code>. I ran it through the service and it spit out two PDFs with identical hashes. I then went through signing the echo one and executing the cat one and got the flag!</p>

<h2 id="its-a-me">Itâ€™s-a Me</h2>

<p>This challenge involved a binary that presented text-based menus for a pizza restaurant. A bunch of us opened up the binary in Binary Ninja and IDA and used <a href="https://github.com/lunixbochs/revsync">revsync</a> to collaborate on naming symbols.</p>

<p>We found that it looked for emojis like tomatoÙ« pineapple and chicken as the pizza ingredients. If you ordered the Pineapple emoji as an ingredientÙ« it yelled and banned you. We found other pineapple-related code at the cooking stageÙ« so we needed to figure out how to get there without getting banned. Soon <code class="language-plaintext highlighter-rouge">aegis</code> figured out the cooking stage concatted the ingredientsÙ« so we could split the emojiâ€™s UTF-8 over 2 ingredients to get it through.</p>

<p>Then <code class="language-plaintext highlighter-rouge">aegis</code> found a code path that could write to a buffer before and after it being <code class="language-plaintext highlighter-rouge">free</code>â€˜dÙ« which could be the start of a heap corruption exploit. To get to that path we needed to make it think our pineapple pizzas were all an <code class="language-plaintext highlighter-rouge">ApprovedPizza</code> instead of a <code class="language-plaintext highlighter-rouge">CriminalPizza</code>.</p>

<p>So we found some bit field logic and <code class="language-plaintext highlighter-rouge">aegis</code> figured out that you could overflow the 4 bit fields and make it think all the pizzas were approved by cooking 16 pineapple pizzas and 1 tomato pizza. That let us corrupt the heap and get a segfault. Then <code class="language-plaintext highlighter-rouge">kileak</code> developed an exploit which he wrote up <a href="https://kileak.github.io/ctf/2018/defconquals18-itsame/">here</a>.</p>

<h2 id="flagsifier">Flagsifier</h2>

<p>This one was trickyÙ« it took me 4 hours of fiddling around in a <a href="https://gist.github.com/trishume/99a161c5c3653c08edfbf9e1cd6d27a5">Juypter Notebook</a>.</p>

<p>We were given a Keras convnet image classifer modelÙ« some sample images showing 38 MNIST-like letters spelling random words glommed togetherÙ« and the name â€œFlagsifierâ€. This suggested that the challenge was to extract an image of the flag from the model trained to recognize the flag.</p>

<p><img src="/assets/postassets/dcquals18/flagsifier_sample.png" alt="Flagsifier Sample Inpuw" /></p>

<p>First I Googled â€œMNIST lettersâ€ and found the EMNIST datasetÙ« which I suspected is what the samples and training data was made with. NextÙ« I had two possible avenues of extraction:</p>

<ol>
  <li>Use something like Deep Dream to optimize an image for flag-ness: this would take a reasonable amount of effort to implement and might work straightforwardlyÙ« but ran the risk of outputting blurry or otherwise unreadable images.</li>
  <li>Use the letters in the EMNIST dataset to optimize a flag string for flag-ness character by character. This would definitely give a readable resultÙ« but I wasnâ€™t sure if just hill-climbing a character at a time would reach the flag properlyÙ« since the final dense layer could theoretically learn not to activate basically at all until all the characters are right.</li>
</ol>

<p>I figured that the second approach had a better effort to expected reward tradeoff and started work. First I set up the data loading code for the EMNIST dataset and extracted only the capital letters (the samples were all uppercase). Then I extracted the first letter from a sample and searched the dataset for itÙ« confirming that the letters were from EMNIST. Later I figured out based on the â€œLâ€s in the samples that I needed to use the <code class="language-plaintext highlighter-rouge">ByMerge</code> version rather than the <code class="language-plaintext highlighter-rouge">ByClass</code> version and switched it.</p>

<p>Next I wrote a function that took a 38-character string and generated an image with random instances of each letter so that I could run things through the network. I needed to figure out which of the 40 class outputs was flag-nessÙ« without having the flag.</p>

<p>The examples I had run through so far had all output <code class="language-plaintext highlighter-rouge">1.0</code> for one class and <code class="language-plaintext highlighter-rouge">0.0</code> for othersÙ« I figured first I needed more resolution to pick up on hints of flag-ness. To get this I needed to remove the final softmax layer. Unfortunately Keras compiled the model using settings only available inside the load commandÙ« so it wasnâ€™t easy to modify it after loading. I took the easy/clever/hacky/fastest way out and opened the model in a hex editorÙ« found the JSON model description inside and changed <code class="language-plaintext highlighter-rouge">"softmax"Ù«</code> to <code class="language-plaintext highlighter-rouge">"linear" Ù«</code> with the space to maintain the length. This gave me a much higher resolution signal to look at and optimize.</p>

<p>I knew that all flags started with <code class="language-plaintext highlighter-rouge">OOO</code> so I composed an image with <code class="language-plaintext highlighter-rouge">OOO</code> and then blank spaceÙ« and saw that channel 2 (zero-indexed) had the highest activation.</p>

<p>I started by looping through each character for each position starting from the beginning and filling it with the character that had the highest activationÙ« using my same generator that picked random instances. This gave garbage resultsÙ« so I made it average the activations of 20 samples for each character and it correctly picked up the <code class="language-plaintext highlighter-rouge">OOO</code> and then a bunch of random-seeming characters.</p>

<p>I rewrote my generator and optimizer to pick 30 random versions of each letter for each position and choose the best letter instance for each slot. Then I rewrote it again so it could start from a given string instead of an empty blank canvas. Then I re-ran the optimizer again starting with my last result and it tuned in each character with context.</p>

<p>This gave me <code class="language-plaintext highlighter-rouge">OOOSOMGAUTHKNTICIWTTILIGCWCCISRTQUIVCT</code>. That looked like the first part might be <code class="language-plaintext highlighter-rouge">OOOSOMEAUTHENTIC</code>Ù« it was getting somewhere! So I posted it to the Samurai Slack channel. I was somewhat tapped out of ideas and my teammate wanted to try Deep DreamÙ« so I tried a bit harder to get the best guess of a starting point for Deep Dream to optimize. I noted that the <code class="language-plaintext highlighter-rouge">ByMerge</code> dataset meant <code class="language-plaintext highlighter-rouge">L</code> and <code class="language-plaintext highlighter-rouge">I</code> were nearly indistinguishableÙ« and given that and the context of an AI challenge it probably continued <code class="language-plaintext highlighter-rouge">OOOSOMEAUTHENTICINTELLIGENCEIS</code>. I couldnâ€™t decipher the last bit though so I prepared to wait for the deep dream results.</p>

<p>Then I got a Slack ping that the challenge had been solvedÙ« my teammate <code class="language-plaintext highlighter-rouge">shane</code> figured out that the last bit <code class="language-plaintext highlighter-rouge">RTQUIVCT</code> must be <code class="language-plaintext highlighter-rouge">REQUIRED</code>! We had managed to turn the garbled mess into the full flag.</p>

<h2 id="geckome">Geckome</h2>

<p>In this challenge there was a page with Javascript that collected a bunch of info from the browserÙ« put it all in a stringÙ« hashed itÙ« and if it had the correct hashÙ« passed it off to a PHP file that would give you the flag given the string.</p>

<p>We started by looking at the various JavascriptÙ« CSS and HTML features used on the page and tabulating which versions of which browsers could possibly have that combination of featuresÙ« and came up with this table:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Thing           Firefox Chrome  Opera   Safari
onbeforeprint   &lt;6      &lt;63     &lt;50     any
DataView        &gt;=15    &gt;=9     &gt;=12.1  &gt;=5.1
webkit anim     X       &gt;=4     &gt;=15    &gt;=4
SubtleCrypto    &gt;=34    &gt;=37    &gt;=24    &gt;=11
link prerender  X       &gt;=13    &gt;=15    X
video tag       &gt;=20    &gt;=4     &gt;=11.5  &gt;=4
ping attr       X       &gt;=15    &gt;=15    &gt;=6

The version expressions for onbeforeprint are
the browsers that don"t support itÙ« as suggested.
</code></pre></div></div>

<p>This didnâ€™t do much except rule out Firefox and Safari. We could also probably rule out Opera because itâ€™s rareÙ« and the challenge was named â€œGeckomeâ€ which had â€œomeâ€ from ChromeÙ« but nothing from Opera. But there were still too many Chrome versions.</p>

<p>I modified the script to put all the important values to hash on the screen so that we could easily look at the results in different browsers:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;pre</span> <span class="na">id=</span><span class="s">"log"</span><span class="nt">&gt;&lt;/pre&gt;</span>
<span class="nt">&lt;script&gt;</span>
    <span class="kd">var</span> <span class="nx">logText</span> <span class="o">=</span> <span class="dl">""</span><span class="p">;</span>
    <span class="kd">function</span> <span class="nx">logme</span><span class="p">(</span><span class="nx">thing</span><span class="p">Ù«</span><span class="nx">s</span><span class="p">)</span> <span class="p">{</span> <span class="nx">logText</span> <span class="o">+=</span> <span class="nx">thing</span><span class="p">;</span> <span class="nx">logText</span> <span class="o">+=</span> <span class="dl">"</span><span class="s2">: </span><span class="dl">"</span><span class="p">;</span> <span class="nx">logText</span> <span class="o">+=</span> <span class="nb">String</span><span class="p">(</span><span class="nx">s</span><span class="p">);</span> <span class="nx">logText</span> <span class="o">+=</span> <span class="dl">"</span><span class="s2">;</span><span class="se">\n</span><span class="dl">"</span><span class="p">;}</span>

    <span class="kd">var</span> <span class="nx">f</span> <span class="o">=</span> <span class="dl">""</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">navigator</span><span class="p">.</span><span class="nx">onLine</span><span class="p">)</span>
        <span class="nx">f</span> <span class="o">+=</span> <span class="dl">"</span><span class="s2">o</span><span class="dl">"</span><span class="p">;</span>
    <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">online</span><span class="dl">"</span><span class="p">Ù«</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">onLine</span><span class="p">);</span>
    <span class="nx">f</span> <span class="o">+=</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">vendor</span><span class="p">;</span>
    <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">vendor</span><span class="dl">"</span><span class="p">Ù«</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">vendor</span><span class="p">);</span>
    <span class="kd">function</span> <span class="nx">p</span><span class="p">()</span> <span class="p">{</span>
        <span class="nb">window</span><span class="p">.</span><span class="nx">print</span><span class="p">();</span>
    <span class="p">}</span>

    <span class="nx">f</span> <span class="o">+=</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">mimeTypes</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span>
    <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">mimes</span><span class="dl">"</span><span class="p">Ù«</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">mimeTypes</span><span class="p">.</span><span class="nx">length</span><span class="p">);</span>
    <span class="nx">x</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="k">for</span> <span class="p">(</span> <span class="nx">i</span> <span class="k">in</span> <span class="nb">navigator</span> <span class="p">)</span> <span class="p">{</span> <span class="nx">x</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span> <span class="p">}</span> <span class="nx">f</span> <span class="o">+=</span> <span class="nx">x</span><span class="p">;</span>
    <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">navlen</span><span class="dl">"</span><span class="p">Ù«</span> <span class="nx">x</span><span class="p">);</span>
    <span class="nx">x</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="k">for</span> <span class="p">(</span> <span class="nx">i</span> <span class="k">in</span> <span class="nb">window</span> <span class="p">)</span> <span class="p">{</span> <span class="nx">x</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span> <span class="p">}</span> <span class="nx">f</span> <span class="o">+=</span> <span class="nx">x</span><span class="p">;</span>
    <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">winlen</span><span class="dl">"</span><span class="p">Ù«</span> <span class="nx">x</span><span class="p">);</span>
    <span class="c1">// hash</span>
    <span class="kd">function</span> <span class="nx">str2ab</span><span class="p">(</span><span class="nx">str</span><span class="p">)</span> <span class="p">{</span>
        <span class="kd">var</span> <span class="nx">buf</span> <span class="o">=</span> <span class="k">new</span> <span class="nb">ArrayBuffer</span><span class="p">(</span><span class="nx">str</span><span class="p">.</span><span class="nx">length</span><span class="o">*</span><span class="mi">2</span><span class="p">);</span> <span class="c1">// 2 bytes for each char</span>
        <span class="kd">var</span> <span class="nx">bufView</span> <span class="o">=</span> <span class="k">new</span> <span class="nb">Uint16Array</span><span class="p">(</span><span class="nx">buf</span><span class="p">);</span>
        <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span><span class="o">=</span><span class="mi">0</span><span class="p">Ù«</span> <span class="nx">strLen</span><span class="o">=</span><span class="nx">str</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span> <span class="nx">i</span><span class="o">&lt;</span><span class="nx">strLen</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
            <span class="nx">bufView</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span> <span class="o">=</span> <span class="nx">str</span><span class="p">.</span><span class="nx">charCodeAt</span><span class="p">(</span><span class="nx">i</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="nx">buf</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="kd">function</span> <span class="nx">sha256</span><span class="p">(</span><span class="nx">str</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// We transform the string into an arraybuffer.</span>
        <span class="kd">var</span> <span class="nx">buffer</span> <span class="o">=</span> <span class="nx">str2ab</span><span class="p">(</span><span class="nx">str</span><span class="p">);</span>
        <span class="k">return</span> <span class="nx">crypto</span><span class="p">.</span><span class="nx">subtle</span><span class="p">.</span><span class="nx">digest</span><span class="p">({</span><span class="na">name</span><span class="p">:</span><span class="dl">"</span><span class="s2">SHA-256</span><span class="dl">"</span><span class="p">}Ù«</span> <span class="nx">buffer</span><span class="p">).</span><span class="nx">then</span><span class="p">(</span><span class="kd">function</span> <span class="p">(</span><span class="nx">hash</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">return</span> <span class="nx">hex</span><span class="p">(</span><span class="nx">hash</span><span class="p">);</span>
        <span class="p">});</span>
    <span class="p">}</span>

    <span class="kd">function</span> <span class="nx">hex</span><span class="p">(</span><span class="nx">buffer</span><span class="p">)</span> <span class="p">{</span>
        <span class="kd">var</span> <span class="nx">hexCodes</span> <span class="o">=</span> <span class="p">[];</span>
        <span class="kd">var</span> <span class="nx">view</span> <span class="o">=</span> <span class="k">new</span> <span class="nb">DataView</span><span class="p">(</span><span class="nx">buffer</span><span class="p">);</span>
        <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">view</span><span class="p">.</span><span class="nx">byteLength</span><span class="p">;</span> <span class="nx">i</span> <span class="o">+=</span> <span class="mi">4</span><span class="p">)</span> <span class="p">{</span>
            <span class="c1">// Using getUint32 reduces the number of iterations needed (we process 4 bytes each time)</span>
            <span class="kd">var</span> <span class="nx">value</span> <span class="o">=</span> <span class="nx">view</span><span class="p">.</span><span class="nx">getUint32</span><span class="p">(</span><span class="nx">i</span><span class="p">)</span>
            <span class="c1">// toString(16) will give the hex representation of the number without padding</span>
            <span class="kd">var</span> <span class="nx">stringValue</span> <span class="o">=</span> <span class="nx">value</span><span class="p">.</span><span class="nx">toString</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
            <span class="c1">// We use concatenation and slice for padding</span>
            <span class="kd">var</span> <span class="nx">padding</span> <span class="o">=</span> <span class="dl">"</span><span class="s1">00000000</span><span class="dl">"</span>
            <span class="kd">var</span> <span class="nx">paddedValue</span> <span class="o">=</span> <span class="p">(</span><span class="nx">padding</span> <span class="o">+</span> <span class="nx">stringValue</span><span class="p">).</span><span class="nx">slice</span><span class="p">(</span><span class="o">-</span><span class="nx">padding</span><span class="p">.</span><span class="nx">length</span><span class="p">)</span>
            <span class="nx">hexCodes</span><span class="p">.</span><span class="nx">push</span><span class="p">(</span><span class="nx">paddedValue</span><span class="p">);</span>
        <span class="p">}</span>

        <span class="c1">// Join all the hex strings into one</span>
        <span class="k">return</span> <span class="nx">hexCodes</span><span class="p">.</span><span class="nx">join</span><span class="p">(</span><span class="dl">""</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">if</span><span class="p">(</span><span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">.</span><span class="nx">length</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">plugin0name</span><span class="dl">"</span><span class="p">Ù«</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">filename</span><span class="p">);</span>
        <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">plugin0desc</span><span class="dl">"</span><span class="p">Ù«</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">description</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">if</span><span class="p">(</span><span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">.</span><span class="nx">length</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">plugin1name</span><span class="dl">"</span><span class="p">Ù«</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nx">filename</span><span class="p">);</span>
        <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">plugin1desc</span><span class="dl">"</span><span class="p">Ù«</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nx">description</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="nx">f</span> <span class="o">+=</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">filename</span><span class="p">;</span>
    <span class="nx">f</span> <span class="o">+=</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nx">description</span><span class="p">;</span>

    <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">f</span><span class="dl">"</span><span class="p">Ù«</span> <span class="nx">f</span><span class="p">);</span>

    <span class="nx">sha256</span><span class="p">(</span><span class="nx">f</span><span class="p">).</span><span class="nx">then</span><span class="p">(</span><span class="kd">function</span><span class="p">(</span><span class="nx">digest</span><span class="p">)</span> <span class="p">{</span>
        <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">digest</span><span class="dl">"</span><span class="p">Ù«</span> <span class="nx">digest</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="nx">digest</span> <span class="o">==</span> <span class="dl">"</span><span class="s2">31c6b7c46ff55afc8c5e64f42cc9b48dde6a04b5ca434038cd2af8bd3fd1483a</span><span class="dl">"</span><span class="p">)</span> <span class="p">{</span>
            <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">flag</span><span class="dl">"</span><span class="p">Ù«</span> <span class="dl">"</span><span class="s2">gotit!</span><span class="dl">"</span><span class="p">);</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">flag</span><span class="dl">"</span><span class="p">Ù«</span> <span class="dl">"</span><span class="s2">fail!</span><span class="dl">"</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="nb">document</span><span class="p">.</span><span class="nx">getElementById</span><span class="p">(</span><span class="dl">"</span><span class="s1">log</span><span class="dl">"</span><span class="p">).</span><span class="nx">innerHTML</span> <span class="o">=</span> <span class="nx">logText</span><span class="p">;</span>
    <span class="p">});</span>
<span class="nt">&lt;/script&gt;</span>
</code></pre></div></div>

<p>I then hosted a version of this and used <a href="http://browsershots.org/">BrowserShots</a> to take screenshots of it in many versions. Most crashed for lack of various APIs/values and none were correct.</p>

<p>My next idea was to brute force the hash by trying all the reasonable combinations of numbers and plugin strings.</p>

<p>I spent an hour writing a Rust program to brute force it that computed the strings and digests in the same wayÙ« including UTF-16 conversion and converting to hex. Then I checked that it could find the values for my browserâ€™s digest. I entered a lot of possible plugin values and reasonable ranges for numbers based on the browser screenshotsÙ« but couldnâ€™t find the correct one despite searching millions of combinations.</p>

<p><strong>SoÙ« I gave up.</strong> Then later got a Slack ping that my teammate <code class="language-plaintext highlighter-rouge">nopple</code> had solved it. He had taken my Rust program and added some extra plugin strings I had missed from the browser screenshots (<code class="language-plaintext highlighter-rouge">libpepflashplayer.so</code> turned out to be the key).</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">extern</span> <span class="n">crate</span> <span class="n">byteorder</span><span class="p">;</span>
<span class="k">extern</span> <span class="n">crate</span> <span class="n">sha2</span><span class="p">;</span>

<span class="k">use</span> <span class="nn">sha2</span><span class="p">::{</span><span class="n">Sha256</span><span class="p">Ù«</span> <span class="n">Digest</span><span class="p">};</span>
<span class="k">use</span> <span class="nn">byteorder</span><span class="p">::{</span><span class="n">LittleEndian</span><span class="p">Ù«</span> <span class="n">WriteBytesExt</span><span class="p">};</span>
<span class="k">use</span> <span class="nn">std</span><span class="p">::</span><span class="nn">fmt</span><span class="p">::</span><span class="n">Write</span><span class="p">;</span>

<span class="k">fn</span> <span class="nf">to_utf16</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="o">&amp;</span><span class="nb">str</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">out</span> <span class="o">=</span> <span class="nn">Vec</span><span class="p">::</span><span class="nf">with_capacity</span><span class="p">(</span><span class="n">s</span><span class="nf">.len</span><span class="p">()</span><span class="o">*</span><span class="mi">2</span><span class="p">);</span>
    <span class="k">for</span> <span class="n">point</span> <span class="n">in</span> <span class="n">s</span><span class="nf">.encode_utf16</span><span class="p">()</span> <span class="p">{</span>
        <span class="n">out</span><span class="py">.write_u16</span><span class="p">::</span><span class="o">&lt;</span><span class="n">LittleEndian</span><span class="o">&gt;</span><span class="p">(</span><span class="n">point</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="n">out</span>
<span class="p">}</span>

<span class="k">fn</span> <span class="nf">to_hex</span><span class="p">(</span><span class="n">bytes</span><span class="p">:</span> <span class="o">&amp;</span><span class="p">[</span><span class="nb">u8</span><span class="p">])</span> <span class="k">-&gt;</span> <span class="nb">String</span> <span class="p">{</span>
    <span class="nd">assert_eq!</span><span class="p">(</span><span class="n">bytes</span><span class="nf">.len</span><span class="p">()Ù«</span> <span class="mi">32</span><span class="p">);</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">s</span> <span class="o">=</span> <span class="nn">String</span><span class="p">::</span><span class="nf">with_capacity</span><span class="p">(</span><span class="mi">64</span><span class="p">);</span>
    <span class="k">for</span> <span class="n">byte</span> <span class="n">in</span> <span class="n">bytes</span> <span class="p">{</span>
        <span class="nd">write!</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">s</span><span class="p">Ù«</span> <span class="s">"{:02x}"</span><span class="p">Ù«</span> <span class="n">byte</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="n">s</span>
<span class="p">}</span>

<span class="k">fn</span> <span class="nf">hash</span><span class="p">(</span><span class="n">bytes</span><span class="p">:</span> <span class="o">&amp;</span><span class="p">[</span><span class="nb">u8</span><span class="p">])</span> <span class="k">-&gt;</span> <span class="nb">String</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">hasher</span> <span class="o">=</span> <span class="nn">Sha256</span><span class="p">::</span><span class="nf">default</span><span class="p">();</span>
    <span class="n">hasher</span><span class="nf">.input</span><span class="p">(</span><span class="n">bytes</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">output</span> <span class="o">=</span> <span class="n">hasher</span><span class="nf">.result</span><span class="p">();</span>
    <span class="nf">to_hex</span><span class="p">(</span><span class="n">output</span><span class="nf">.as_slice</span><span class="p">())</span>
<span class="p">}</span>

<span class="nd">#[derive(Debug)]</span>
<span class="k">struct</span> <span class="n">Browser</span> <span class="p">{</span>
    <span class="n">online</span><span class="p">:</span> <span class="nb">bool</span><span class="p">Ù«</span>
    <span class="n">vendor</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">"static</span> <span class="nb">str</span><span class="p">Ù«</span>
    <span class="n">mimes</span><span class="p">:</span> <span class="nb">u16</span><span class="p">Ù«</span>
    <span class="n">navs</span><span class="p">:</span> <span class="nb">u16</span><span class="p">Ù«</span>
    <span class="n">wins</span><span class="p">:</span> <span class="nb">u16</span><span class="p">Ù«</span>
    <span class="n">plug_name</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">"static</span> <span class="nb">str</span><span class="p">Ù«</span>
    <span class="n">plug_desc</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">"static</span> <span class="nb">str</span><span class="p">Ù«</span>
<span class="p">}</span>

<span class="k">fn</span> <span class="nf">construct_f</span><span class="p">(</span><span class="n">b</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">Browser</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">String</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">s</span> <span class="o">=</span> <span class="nn">String</span><span class="p">::</span><span class="nf">with_capacity</span><span class="p">(</span><span class="mi">64</span><span class="p">);</span>
    <span class="k">if</span> <span class="n">b</span><span class="py">.online</span> <span class="p">{</span> <span class="n">s</span><span class="nf">.push</span><span class="p">(</span><span class="sc">"o"</span><span class="p">);</span> <span class="p">}</span>
    <span class="n">s</span><span class="nf">.push_str</span><span class="p">(</span><span class="n">b</span><span class="py">.vendor</span><span class="p">);</span>
    <span class="nd">write!</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">s</span><span class="p">Ù«</span> <span class="s">"{}"</span><span class="p">Ù«</span> <span class="n">b</span><span class="py">.mimes</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
    <span class="nd">write!</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">s</span><span class="p">Ù«</span> <span class="s">"{}"</span><span class="p">Ù«</span> <span class="n">b</span><span class="py">.navs</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
    <span class="nd">write!</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">s</span><span class="p">Ù«</span> <span class="s">"{}"</span><span class="p">Ù«</span> <span class="n">b</span><span class="py">.wins</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
    <span class="n">s</span><span class="nf">.push_str</span><span class="p">(</span><span class="n">b</span><span class="py">.plug_name</span><span class="p">);</span>
    <span class="n">s</span><span class="nf">.push_str</span><span class="p">(</span><span class="n">b</span><span class="py">.plug_desc</span><span class="p">);</span>
    <span class="n">s</span>
<span class="p">}</span>

<span class="c">// Test target that"s my browser</span>
<span class="c">// const TARGET: &amp;"static str = "31504a9568837f94e9f0afe8387cf945fb4929b81e53caf16bdf65c417e294e0";</span>
<span class="c">// Real target</span>
<span class="k">const</span> <span class="n">TARGET</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">"static</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">"31c6b7c46ff55afc8c5e64f42cc9b48dde6a04b5ca434038cd2af8bd3fd1483a"</span><span class="p">;</span>

<span class="k">fn</span> <span class="nf">test</span><span class="p">(</span><span class="n">f</span><span class="p">:</span> <span class="o">&amp;</span><span class="nb">str</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">bool</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">utf16</span> <span class="o">=</span> <span class="nf">to_utf16</span><span class="p">(</span><span class="n">f</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">hex_hash</span> <span class="o">=</span> <span class="nf">hash</span><span class="p">(</span><span class="o">&amp;</span><span class="n">utf16</span><span class="p">[</span><span class="o">..</span><span class="p">]);</span>
    <span class="nd">assert_eq!</span><span class="p">(</span><span class="n">hex_hash</span><span class="nf">.len</span><span class="p">()Ù«</span> <span class="mi">64</span><span class="p">);</span>
    <span class="n">hex_hash</span> <span class="o">==</span> <span class="n">TARGET</span>
<span class="p">}</span>

<span class="k">struct</span> <span class="n">ForceConfig</span> <span class="p">{</span>
    <span class="n">navs_start</span><span class="p">:</span> <span class="nb">u16</span><span class="p">Ù«</span>
    <span class="n">navs_end</span><span class="p">:</span> <span class="nb">u16</span><span class="p">Ù«</span>
    <span class="n">wins_start</span><span class="p">:</span> <span class="nb">u16</span><span class="p">Ù«</span>
    <span class="n">wins_end</span><span class="p">:</span> <span class="nb">u16</span><span class="p">Ù«</span>
<span class="p">}</span>

<span class="k">const</span> <span class="n">PLUGNAMES</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">"static</span> <span class="p">[</span><span class="o">&amp;</span><span class="nv">"static</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="o">&amp;</span><span class="p">[</span>
    <span class="s">"internal-remoting-viewer"</span><span class="p">Ù«</span>
    <span class="s">"internal-pdf-viewer"</span><span class="p">Ù«</span>
    <span class="s">"widevinecdmadapter.plugin"</span><span class="p">Ù«</span>
    <span class="s">"PepperFlashPlayer.plugin"</span><span class="p">Ù«</span>
    <span class="s">"internal-nacl-plugin"</span><span class="p">Ù«</span>
    <span class="s">"libpdf.so"</span><span class="p">Ù«</span>
    <span class="s">"pepflashplayer.dll"</span><span class="p">Ù«</span>
    <span class="s">"Flash Player.plugin"</span><span class="p">Ù«</span>
    <span class="s">"WebEx64.plugin"</span><span class="p">Ù«</span>
    <span class="s">"CitrixOnlineWebDeploymentPlugin.plugin"</span><span class="p">Ù«</span>
    <span class="s">"googletalkbrowserplugin.plugin"</span><span class="p">Ù«</span>
    <span class="s">"AdobePDFViewerNPAPI.plugin"</span><span class="p">Ù«</span>
    <span class="s">"libpepflashplayer.so"</span><span class="p">Ù«</span>
<span class="p">];</span>

<span class="k">const</span> <span class="n">PLUGDESCS</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">"static</span> <span class="p">[</span><span class="o">&amp;</span><span class="nv">"static</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="o">&amp;</span><span class="p">[</span>
    <span class="s">""</span><span class="p">Ù«</span>
    <span class="s">"This plugin allows you to securely access other computers that have been shared with you. To use this plugin you must first install the &lt;a href=</span><span class="se">\"</span><span class="s">https://chrome.google.com/remotedesktop</span><span class="se">\"</span><span class="s">&gt;Chrome Remote Desktop&lt;/a&gt; webapp."</span><span class="p">Ù«</span>
    <span class="s">"Portable Document Format"</span><span class="p">Ù«</span>
    <span class="s">"Enables Widevine licenses for playback of HTML audio/video content. (version: 1.4.9.1070)"</span><span class="p">Ù«</span>
    <span class="s">"Plugin that detects installed Citrix Online products (visit www.citrixonline.com)."</span><span class="p">Ù«</span>
    <span class="s">"Shockwave Flash 9.0 r0"</span><span class="p">Ù«</span>
    <span class="c">// SNIPPED: versions 10 through 28. These didn"t end up being necessary.</span>
    <span class="s">"Shockwave Flash 29.0 r0"</span><span class="p">Ù«</span>
<span class="p">];</span>

<span class="k">fn</span> <span class="nf">force</span><span class="p">(</span><span class="n">c</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">ForceConfig</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">num_navs</span> <span class="o">=</span> <span class="p">(</span><span class="n">c</span><span class="py">.navs_end</span><span class="o">-</span><span class="n">c</span><span class="py">.navs_start</span><span class="p">)</span> <span class="k">as</span> <span class="nb">usize</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">num_wins</span> <span class="o">=</span> <span class="p">(</span><span class="n">c</span><span class="py">.wins_end</span><span class="o">-</span><span class="n">c</span><span class="py">.wins_start</span><span class="p">)</span> <span class="k">as</span> <span class="nb">usize</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">max_mime</span><span class="p">:</span> <span class="nb">u16</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span>

    <span class="k">let</span> <span class="n">total</span> <span class="o">=</span> <span class="n">num_navs</span><span class="o">*</span><span class="n">num_wins</span><span class="o">*</span><span class="p">(</span><span class="n">max_mime</span> <span class="k">as</span> <span class="nb">usize</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">PLUGNAMES</span><span class="nf">.len</span><span class="p">()</span><span class="o">*</span><span class="n">PLUGDESCS</span><span class="nf">.len</span><span class="p">();</span>
    <span class="nd">println!</span><span class="p">(</span><span class="s">"Brute forcing {} combinations"</span><span class="p">Ù«</span> <span class="n">total</span><span class="p">);</span>

    <span class="k">let</span> <span class="n">one_segment</span> <span class="o">=</span> <span class="n">total</span> <span class="o">/</span> <span class="mi">100</span><span class="p">;</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">tick</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

    <span class="k">for</span> <span class="n">navs</span> <span class="n">in</span> <span class="n">c</span><span class="py">.navs_start</span><span class="o">..</span><span class="n">c</span><span class="py">.navs_end</span> <span class="p">{</span>
        <span class="k">for</span> <span class="n">wins</span> <span class="n">in</span> <span class="n">c</span><span class="py">.wins_start</span><span class="o">..</span><span class="n">c</span><span class="py">.wins_end</span> <span class="p">{</span>
            <span class="k">for</span> <span class="n">mimes</span> <span class="n">in</span> <span class="mi">1</span><span class="o">..</span><span class="n">max_mime</span> <span class="p">{</span>
                <span class="k">for</span> <span class="n">plug_name</span> <span class="n">in</span> <span class="n">PLUGNAMES</span> <span class="p">{</span>
                    <span class="k">for</span> <span class="n">plug_desc</span> <span class="n">in</span> <span class="n">PLUGDESCS</span> <span class="p">{</span>
                        <span class="k">let</span> <span class="n">b</span> <span class="o">=</span> <span class="n">Browser</span> <span class="p">{</span>
                            <span class="n">online</span><span class="p">:</span> <span class="k">true</span><span class="p">Ù«</span>
                            <span class="c">// vendor: ""Ù«</span>
                            <span class="n">vendor</span><span class="p">:</span> <span class="s">"Google Inc."</span><span class="p">Ù«</span>
                            <span class="c">// vendor: "Opera Software ASA"Ù«</span>
                            <span class="n">mimes</span><span class="p">Ù«</span> <span class="n">navs</span><span class="p">Ù«</span> <span class="n">wins</span><span class="p">Ù«</span> <span class="n">plug_name</span><span class="p">Ù«</span> <span class="n">plug_desc</span><span class="p">Ù«</span>
                        <span class="p">};</span>
                        <span class="k">let</span> <span class="n">f</span> <span class="o">=</span> <span class="nf">construct_f</span><span class="p">(</span><span class="o">&amp;</span><span class="n">b</span><span class="p">);</span>
                        <span class="k">let</span> <span class="n">good</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="o">&amp;</span><span class="n">f</span><span class="p">);</span>
                        <span class="k">assert</span><span class="o">!</span><span class="p">(</span><span class="o">!</span><span class="n">good</span><span class="p">Ù«</span> <span class="s">"{:?}"</span><span class="p">Ù«</span> <span class="n">b</span><span class="p">);</span>

                        <span class="n">tick</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
                        <span class="k">if</span> <span class="n">tick</span> <span class="o">%</span> <span class="n">one_segment</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
                            <span class="nd">println!</span><span class="p">(</span><span class="s">"Done {}/{}"</span><span class="p">Ù«</span> <span class="n">tick</span><span class="p">Ù«</span> <span class="n">total</span><span class="p">);</span>
                        <span class="p">}</span>
                    <span class="p">}</span>
                <span class="p">}</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">conf</span> <span class="o">=</span> <span class="n">ForceConfig</span> <span class="p">{</span>
        <span class="n">navs_start</span><span class="p">:</span> <span class="mi">8</span><span class="p">Ù«</span>
        <span class="n">navs_end</span><span class="p">:</span> <span class="mi">58</span><span class="p">Ù«</span>
        <span class="n">wins_start</span><span class="p">:</span> <span class="mi">80</span><span class="p">Ù«</span>
        <span class="n">wins_end</span><span class="p">:</span> <span class="mi">270</span><span class="p">Ù«</span>
    <span class="p">};</span>
    <span class="nf">force</span><span class="p">(</span><span class="o">&amp;</span><span class="n">conf</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="adamtune">AdamTune</h2>

<p>This challenge involved passing a â€œvoice printâ€ test where you submitted an MP3 file that was allegedly <a href="https://adamdoupe.com/">Adam DoupÃ©</a> reading a sentence.</p>

<p>My teammates spent some time playing with training a text to speech model on a small hand-labeled dataset but that didnâ€™t produce good enough results and at 4 hours till the end of the contest we agreed thereâ€™s no way it could work in time.</p>

<p>By recording challenges from the demo serverÙ« I discovered that a vocabulary of about 209 words completely covered most challenges. So we decided to try a concatenative approach. My teammates downloaded the audio for a bunch of Adamâ€™s talks and gave me cut up mono wav files. I fed these through the Google Speech To Text API and got word level timing information. I wrote a script that cut out wav files of individual words in the vocabulary from the transcriptÙ« a script that picked out the best instances of these words based on length and volumeÙ« and a script that strung together the best instances into sentences.</p>

<p>HoweverÙ« the results sounded really bad. A lot of the words were said quickly or muttered or included bits of other wordsÙ« the results ended up being really difficult to understand.</p>

<p>I submitted it anyway and it actually passed the check that it said the right wordsÙ« but failed the classifier that it was Adam. This was the opposite of what I expectedÙ« since it was Adam but didnâ€™t sound like it was saying the sentence cleanly.</p>

<p>Looking at the source after the contestÙ« it seems the approach used in it is very similar except with the Watson speech APIÙ« which gives word-level confidences Google doesnâ€™tÙ« allowing better filteringÙ« and also might give better timestamps for less choppy cutouts.</p>

<p>My other guess for why we failed the classifier is that we used clips from Adamâ€™s livestreams doing pwnables instead of from his CS lecturesÙ« these sound very different because of different microphones and styles of speaking. We chose the pwnables because the audio was higher qualityÙ« but if the classifier used only lectures then that could easily explain why we failed the classifier.</p>

'),('http://thume.ca/2017/12/29/fixing-my-keyboards-latency/', 'Fixing My Keyboard"s Latency', '1514505600000',  13, '
<p>While discussing <a href="https://danluu.com/keyboard-latency/">Dan Luuâ€™s keyboard latency experiments</a> I realized that I had never tested my keyboardâ€™s latency. I use <a href="http://thume.ca/2014/09/08/creating-a-keyboard-1-hardware/">a custom keyboard I designed and built</a>Ù« but when I wrote the firmware I was focused on getting it working and didnâ€™t pay any attention to latency. When I took a look at the source code and immediately saw a 10ms delay that was there for no other reason than paranoiaÙ« I knew I was in for some fun.</p>

<p>After a bunch of measuringÙ« finding and squashing sources of latencyÙ« I managed to improve the latency of the main loop from 30 <em>milliseconds</em> to 700 <em>microseconds</em>. I then added a feature that changed the colour of the keyboardâ€™s RGB LEDs on every key press so that I could use the <a href="http://isitsnappy.com/">Is It Snappy</a> app with my iPhoneâ€™s high speed camera mode to do some latency testing.</p>

<p>The first thing I found was that with my improved firmware the end to end latency of typing a character in Sublime Text and XCode 9 near the top of my Macbook display is around 42ms<sup id="fnref:fps" role="doc-noteref"><a href="#fn:fps" class="footnote">1</a></sup>. This is pretty goodÙ« but the astonishing thing is that it means that before I fixed the firmware <strong>my keyboard used to account for almost <em>half</em> of my end-to-end typing latency</strong>. This is measuring from the LED colour change so it doesnâ€™t count the around 15ms<sup id="fnref:fps:1" role="doc-noteref"><a href="#fn:fps" class="footnote">1</a></sup> according to my testing from starting to press one of my keys the switch activating.</p>

<center>
  <video width="360" height="640" muted="" loop="" autoplay="">
    <source src="/assets/postassets/keyboardlatency/latency.mov" type="video/mp4" />
  </video>
</center>

<p>I also tested my Macbook keyboardÙ« as well as a few older low speed USB Apple keyboardsÙ« and found that they had around 67ms<sup id="fnref:fps:2" role="doc-noteref"><a href="#fn:fps" class="footnote">1</a></sup> of end-to-end latencyÙ« measuring from when the switch was fully depressed while hitting the key as fast as I could. I suspect part of the reason for this is that these keyboards only poll at 8ms and 10ms intervals according to USB Prober (an old Apple dev tool)Ù« whereas the <a href="https://www.pjrc.com/store/teensy32.html">Teensy</a> in my custom keyboard polls every millisecond. According to Danâ€™s post newer Apple external keyboards also poll at 1000hz.</p>

<p>Note that the 700us main loop doesnâ€™t translate into 700us switch-to-USB latencyÙ« since the USB transfer is done asynchronously via DMA by the <a href="https://www.pjrc.com/store/teensy32.html">Teensy</a>â€™s USB controller when it is polledÙ« which happens at 1000hz.</p>

<p>Itâ€™s interesting that I used my keyboard for 3 years without noticing that it added 30ms of latency. I have a few guesses why:</p>

<ul>
  <li>Although I can perceive 30ms of latency in a comparison testÙ« I have to pay attentionÙ« my keyboard having 30ms of extra latency just made it feel differentÙ« but thatâ€™s unsurprising since it was different in a bunch of ways.</li>
  <li>My only comparison was other high-latency keyboardsÙ« like my Macbookâ€™s. 30ms of latency difference is more perceptiple than 5-10ms.</li>
</ul>

<p>Anyhow hereâ€™s how I managed to bring the latency down from 30ms to 700us:</p>

<ol>
  <li>I added some measurement code that printed the time spent in the main loop to the Serial console after every key press. This gave me the 30ms figure.</li>
  <li>I removed the 10ms delay in the main loopÙ« and everything still worked.</li>
  <li>I searched for other delays and found one 2ms one between enabling a row for scanning and reading itÙ« which I removed with no apparent consequences. I added back in a 2 microsecond delay just in case.</li>
  <li>I had tried to make the display on my keyboard only update when it changedÙ« but I messed this up somewhere else and it was taking 5ms to update on every key press.</li>
  <li>The right half of my keyboard is scanned using an I/O expander over i2c since I didnâ€™t have enough pins on the Teensy. This is the same way the two halves of the <a href="https://www.ergodox.io/">Ergodox</a> work. Based on some Ergodox firmware I sawÙ« I reinitialized the direction registers of the I/O expander before every scanÙ« just in case. Unfortunately this added 2ms and wasnâ€™t really necessary since unlike the Ergodox you canâ€™t disconnect the second half of my keyboard with a cable.</li>
  <li>Now my loop was taking 3.8ms which was almost entirely the i2c communication with the I/O expander. A friend recommended I check out <a href="https://github.com/nox771/i2c_t3">nox771â€™s fast i2c library</a>. UnfortunatelyÙ« it wouldnâ€™t compile on the super old version of the Arduino/Teensyduino software I was using. I decided to upgradeÙ« and after several hours in C++ compilation hell and accounting for a few changesÙ« it worked. I bumped the i2c frequency up to 1.8 megahertz and now my loops took 700us!</li>
  <li>Now I started running into bouncing problems that lead to the occasionally doubled letterÙ« so I needed to implement debouncing. Some ways of implementing debouncing add latency but thatâ€™s totally unnecessary. <a href="https://github.com/trishume/PolyType/commit/372c2056d705211fb5554a6975eeca34b59f0bc8">I implemented</a> a simple technique that sends transitions immediately and then doesnâ€™t update a key for 5ms after.</li>
</ol>

<p>The specifics are only relevant to other people building keyboard firmwareÙ« especially the fast i2c one which I donâ€™t think most ErgoDox firmwares use. But I think itâ€™s interesting to see how easy it was to improve the latency of software that wasnâ€™t designed for it with only a few hours work.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:fps" role="doc-endnote">
      <p>I use an iPhone 5SÙ« which can only record at 120fpsÙ« so while these numbers are consistent over multiple measurementsÙ« they may be off by as much as 8ms.Â <a href="#fnref:fps" class="reversefootnote" role="doc-backlink">&#8617;</a>Â <a href="#fnref:fps:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a>Â <a href="#fnref:fps:2" class="reversefootnote" role="doc-backlink">&#8617;<sup>3</sup></a></p>
    </li>
  </ol>
</div>
'),('http://thume.ca/2017/12/09/cvdisplaylink-doesnt-link-to-your-display/', 'CVDisplayLink Doesn"t Link To Your Display', '1512777600000',  13, '
<p><strong>Edit 2017/12/10:</strong> So I screwed upÙ« I thought I was safe confirming it in two different ways but I was using an external monitor and all of the below is accurate only for the multi-monitor case. Skip to the bottom to read about my new results.</p>

<p><code class="language-plaintext highlighter-rouge">CVDisplayLink</code> is the recommended way to synchronize your drawing/animation with the refresh of the display on macOS. Many people assume it calls your app just after each display vsync eventÙ« unfortunately this isnâ€™t the case at all. <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> just fetches the refresh rate of your displayÙ« and sets a high resolution timer to call you every 16.6ms (for a 60hz display).</p>

<p>The major reason this is important is if your app has inconsistent rendering times and you get unlucky with the phase of your eventsÙ« youâ€™ll end up painting twice in some frames and zero times in othersÙ« leading to visible dropped frames in your animations. <a href="https://twitter.com/jordwalke/status/939064408986103808">As illustrated by @jordwalke on Twitter</a>:</p>

<p><a href="https://twitter.com/jordwalke/status/939064408986103808"><img src="/assets/postassets/displaylink/timing.jpeg" alt="Timing" /></a></p>

<p>This is particularly insidious because depending on how variable your draw times areÙ« a lot of the time youâ€™ll end up with consistent drawingÙ« but every N runs it will be really bad. Even worseÙ« your FPS measurements will still show 60fps because youâ€™re still drawing every 16.6ms.</p>

<p>AlsoÙ« if youâ€™re using this for a game loop where you only process input at the start of every frameÙ« you could have close to an entire extra frame of latency if youâ€™re unlucky at startup.</p>

<p>â€œBut itâ€™s a special thing that has â€˜displayâ€™ and â€˜linkâ€™ right in the nameÙ« surely it must link up to the display vsync events!â€ you might say. Thatâ€™s what I thought too until I talked to <a href="https://twitter.com/pcwalton">@pcwalton</a> at a Rust meetup and he said heâ€™d disassembled <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> and found it was just a timer. This was astonishing to me and I sat on this information somewhat skeptical for a while. ButÙ« today I finally got around to doing a bunch of investigation and found that heâ€™s right and <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> does not link to the vsync.</p>

<p>FirstÙ« I disassembled the <code class="language-plaintext highlighter-rouge">CoreVideo</code> framework where <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> resides and found a bunch of code that fetches the display rateÙ« calculates how often the timer should be triggered and waits on a timer. I didnâ€™t find any code that looked for vsync events.</p>

<p>NextÙ« I did some experimentsÙ« because I might have missed some hidden synchronization. I used <a href="https://github.com/KrisYu/Water">Kris Yuâ€™s Water</a> Metal sample app since thatâ€™s sadly the only macOS Metal sample code I could find that built for me. I then disassembled <code class="language-plaintext highlighter-rouge">MTKView</code> and confirmed that as I suspected it just uses <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> to call your <code class="language-plaintext highlighter-rouge">draw</code> method. Then I added <code class="language-plaintext highlighter-rouge">kdebug_signpost</code> calls in the <code class="language-plaintext highlighter-rouge">draw</code> method so that I could use Instrumentâ€™s â€œPoints of Interestâ€ trace combined with the new display vsync information to see how they line up.</p>

<p>What I found is that as one would expect with a timerÙ« within each run the <code class="language-plaintext highlighter-rouge">draw</code> call happens at a consistent time within the frameÙ« but between different runs the <code class="language-plaintext highlighter-rouge">draw</code> call happens at completely different times depending on the phase the <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> starts up in relation to the display vsync.</p>

<p>Hereâ€™s some screenshots of different runs in Instruments. The red boxes on the bottom are the <code class="language-plaintext highlighter-rouge">draw</code> callÙ« and the vsync display intervals are clearly visible as lining up very differently each run:</p>

<p><a href="/assets/postassets/displaylink/traces.png"><img src="/assets/postassets/displaylink/traces.png" alt="Display Traces" /></a></p>

<p>NowÙ« the real question isÙ« what do you do if you want actual vsync alignment? I actually donâ€™t knowÙ« I havenâ€™t done enough research yetÙ« but I have some ideas that may or may not work:</p>

<ul>
  <li>I think Cocoa animation or Core Animation draw callbacks may actually be linked to display vsyncÙ« in which case you can use those. Iâ€™m not sure though.</li>
  <li>OpenGL vsync might synchronize with the real vsync.</li>
  <li>Somehow Instruments gets at the real vsync timesÙ« they might come from a private APIÙ« but it also might be something public.</li>
  <li>There may be some other API I donâ€™t know about.</li>
</ul>

<p>Note that I havenâ€™t tested <code class="language-plaintext highlighter-rouge">CADisplayLink</code> on IOSÙ« but Iâ€™ve heard it works properly. AnywayÙ« if you know anything about this issue or how to do things properlyÙ« email me at <a href="mailto:tristan@thume.ca">tristan@thume.ca</a>! I may update this post if I learn anything new.</p>

<h3 id="edit-20171210-i-was-wrong-sorry">Edit 2017/12/10: I was wrongÙ« sorry</h3>

<p><a href="https://twitter.com/ametis_/status/939739328397295617">@ametis_</a> on Twitter noted that the internal <code class="language-plaintext highlighter-rouge">CVCGDisplayLink::getDisplayTimes</code> method actually accesses a pointer to a <a href="https://opensource.apple.com/source/IOGraphics/IOGraphics-517.17/IOGraphicsFamily/IOKit/graphics/IOFramebufferShared.h.auto.html">StdFBShmem_t</a>. I poked around some more and confirmed that the shared memory for this is indeed mapped in in the initializer. I figured I might miss something like thisÙ« hence why I did the experiments. This shared memory contains real vsync timesÙ« and is apparently a way to get real vsync information from the Kernel. See <a href="https://stackoverflow.com/questions/2433207/different-cursor-formats-in-ioframebuffershared">this StackOverflow post</a> for an example of code that maps it in. The question isÙ« why do my experiments show that it still doesnâ€™t line up with vsync?</p>

<p>The <code class="language-plaintext highlighter-rouge">MTKView</code> I was testing with uses <code class="language-plaintext highlighter-rouge">CVDisplayLinkCreateWithActiveCGDisplays</code> which if you have multiple displays creates a <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> â€œcapable of being used with all active displaysâ€Ù« i.e it doesnâ€™t use vsync. I was using an external monitor for my testsÙ« thereâ€™s nothing on my laptop display but I leave it open because thereâ€™s a hardware issue where it messes with my trackpad if I close it. In this case a smarter <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> could handle this case fine by realizing that only one of my displays was updating at the timeÙ« but it turns out it falls back to a timer.</p>

<p>I re-did my experiments in Instruments on my laptop display and found that it consistently fired the <code class="language-plaintext highlighter-rouge">draw</code> call half-way into the frameÙ« about 7ms from the next vsync. I donâ€™t know why it does it in the middle rather than the startÙ« but at least it was consistent across 6 runs.</p>

<p>SoÙ« basically this article is mostly wrongÙ« provided you only have one display. You still have to worry about jank due to inconsistent frame times on a single monitor if you donâ€™t have GL/Metal vsync enabled and your frames jitter around 7ms though. And if you want events near the start of vsync you may still have a difficult task ahead of you.</p>

<p>Itâ€™s probably even possible to get the correct events in a multi-monitor caseÙ« but you need some fancy code that watches which screen your monitor is onÙ« and constructs a new <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> with just that <code class="language-plaintext highlighter-rouge">CGDisplay</code> when the window moves.</p>

<p>InterestinglyÙ« <a href="https://twitter.com/ametis_/status/939739328397295617">@ametis_</a>â€™s account was created just for that tweetÙ« and figuring out that it uses <code class="language-plaintext highlighter-rouge">StdFBShmem_t</code> without a hint would have required way way better reversing skills than mine to trace the instance variable back to the init method through a bunch of offsets to a memory mapping of an opaque codeÙ« which they would have had to figure out is <code class="language-plaintext highlighter-rouge">kIOFBSharedConnectType</code> and look at that struct to find it contains the <code class="language-plaintext highlighter-rouge">vblTime</code> field. Either theyâ€™re really good at reverse engineeringÙ« or theyâ€™re an Apple engineer with access to the source code who looked into it after seeing my article. Regardless Iâ€™m happy they set me straight!</p>

<p>Thanks to other commenters on Hacker News and Twitter have pointed out a few things that I should add here:</p>

<ul>
  <li>Someone on HN notes that the Apple docs donâ€™t promise that <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> gives you refresh times. I had noticed this but didnâ€™t include it in my articleÙ« but I treated it as further evidence for my results though. OoopsÙ« turns out it does sometimesÙ« just not always.</li>
  <li><a href="https://twitter.com/jordwalke">@jordwalke</a> linked me to <a href="http://www.ananseproductions.com/game-loops-on-ios/">this article</a> that explains how <code class="language-plaintext highlighter-rouge">CADisplayLink</code> works on IOS.</li>
</ul>
'),('http://thume.ca/2017/11/10/eye-tracking-mouse-control-ideas/', 'Eye Tracking Mouse Control Ideas', '1510272000000',  13, '
<p>This is a list of ideas for using eye tracking as a mouse replacementÙ« specifically solving the problem that eye tracking often isnâ€™t quite accurate enough to use raw. Thereâ€™s lots of targets on a normal computer that are just too small for even the best fingertip-size eyetracker accuraciesÙ« like selecting individual charactersÙ« or small buttons. For some peopleÙ« like meÙ« eye trackers tend just not to work too well and only are accurate within maybe a 4 cm diameterÙ« much too large to specify most targets.</p>

<p>Thereâ€™s also reason to suspect that this situation wonâ€™t improve. People have been working on eye tracking for years and accuracy is still bad. A few papers Iâ€™ve read have said that in fact the muscles that point the eyes may even not be accurate enough to point as precisely as a mouseÙ« and even if they can that fixating gaze precisely leads to eye fatigue quite quickly.</p>

<p>Why would you want to replace the mouse with an eye-tracking based solution?</p>

<ul>
  <li>Disabilities</li>
  <li>Repetitive Stress Injuries: Thereâ€™s lots of approaches to addressing RSIsÙ« but itâ€™s also a much larger market.</li>
  <li>People who donâ€™t want to take their hands off the keyboard: Programmers go to crazy lengths to learn shortcuts to avoid reaching for the mouseÙ« if there was a fast system of hands-free mousingÙ« some may like it.</li>
</ul>

<p>Iâ€™m writing this list for two reasons:</p>

<ol>
  <li>So that I can get the WaybackMachine to archive it to have evidence of prior art in case anybody tries to patent these. I try to explore as much of the space of possible ideas people could try patenting as possible. Of courseÙ« itâ€™s possible one or more of these already falls under some patentÙ« because thereâ€™s patents on a lot of obvious ideasÙ« but I donâ€™t know of any.</li>
  <li>As a survey of the possibilitiesÙ« to look at whatâ€™s possible and possibly inspire someone to try something out. Eye tracking has such potentialÙ« but is sadly rarely used outside of research.</li>
</ol>

<p>Before proceeding Iâ€™d like to emphasize that <strong>not all these ideas are good</strong>Ù« many wouldnâ€™t be that nice to use or would have other issuesÙ« I aimed much more for breadth in creating this list than depth.</p>

<p>Thereâ€™s three broad categories to these ideas:</p>

<h2 id="combining-with-another-input-method">Combining with another input method</h2>

<p>Thereâ€™s a lot of alternative mousing methods that work but are quite slow. ButÙ« if you use eye tracking for coarse but fast narrowing of positionÙ« and then another technique for refinementÙ« they can be quite efficient.</p>

<dl>
  <dt><a href="https://github.com/trishume/PolyMouse">Polymouse</a></dt>
  <dd>Using head tracking for refinement and eye tracking for large movementsÙ« you can achieve speeds equal to a good trackpad and approaching a normal mouse. This is the main technique Iâ€™ve put effort into and was the focus of my research at the Waterloo HCI lab. I use a version of the â€œAnimated MAGICâ€ technique to quickly move the mouse cursor along the path to the target based on eye tracking. Iâ€™m currently working towards making this technique available in a low-cost and convenient system for daily use.</dd>
  <dt>Combining with a mouse</dt>
  <dd>This just allows you to use less mouse movement. This is built into Tobiiâ€™s consumer software.</dd>
  <dt>Combining with voice</dt>
  <dd>Thereâ€™s a lot of things on a screen to clickÙ« and itâ€™s hard to describe themÙ« but given a small region from eye trackingÙ« you can use OCR or accessibility APIs to find interactible things near the gaze and disambiguate what to do via voice. For example â€œclick findâ€ when looking near the â€œFind fileâ€ button on Github.</dd>
  <dt>Combining with a keyboard</dt>
  <dd>Within a region around the eyeÙ« you could offer a number of options for things to interact withÙ« presented as letters or colours overlayed on the screenÙ« and then use different keyboard keys to select which one was the true target. The places to put the markers could be done via a patternÙ« machine learningÙ« text recognition or an accessibility API. Similar to <a href="https://github.com/trishume/mjolnir.th.hints">this</a>.</dd>
  <dt>Combining with button timing</dt>
  <dd>When the click button is pressedÙ« instead of emitting a click event it could start move the cursor in for example a grid or spiral pattern around the gaze locationÙ« and when the user releases it clicks in that location. This could also be combined with likely target dataÙ« see the next section. This would be slow but doesnâ€™t require extra hardwareÙ« it uses timing information as the additional source.</dd>
  <dt>Face Gestures</dt>
  <dd>Camera data could be fed into a face tracking algorithm and face gestures could be used to refine the cursor position. For example moving the lips around like a joystickÙ« or twitching cheeks to nudge left and right. Most eye trackers are actually just IR cameras so this may not even require a separate camera.</dd>
</dl>

<h2 id="predicting-the-target">Predicting the target</h2>

<p>When you have eye tracking data that is fairly good but not perfectÙ« the effective accuracy can be improved by guessing good targets within the gaze region.</p>

<p>Good targets can be things like buttonsÙ« words to selectÙ« and other UI controls. Even when some place is interactibleÙ« it may make sense to choose a better target anywayÙ« for example preferring selecting entire words rather than characters within a wordÙ« and the right side of a tab targetting the close button and the left side targetting clicking the tab.</p>

<p>Given a source of information about likely targetsÙ« thereâ€™s various things you can do with the information:</p>

<dl>
  <dt>Snapping</dt>
  <dd>The gaze cursor or clicks snap to the nearest likely target. Possibly with snappiness determined by a measure of likelihood of clicking the target.</dd>
  <dt>Draw the cursor towards it</dt>
  <dd>This is basically a softer form of snapping. It could be like gravityÙ« or fancier. For example modelling the gaze data as a probability distribution over true targetsÙ« and target information as a prior distributionÙ« and then using Bayesian calculations to find the maximum likelihood target. I think I prefer the simpler and more consistent idea of snapping though.</dd>
</dl>

<p>Thereâ€™s a few ways I can think of getting the target informationÙ« a system could use either one or many of these:</p>

<dl>
  <dt>Use accessibility APIs</dt>
  <dd>Accessibility APIs can tell you the pixel location of buttonsÙ« text and other likely targets.</dd>
  <dt>Likelihood Neural Net</dt>
  <dd>Use machine learning (probably a CNN) to train a model that given a screenshotÙ« predicts a likelihood distribution (think heatmap) of click targets. It could be trained on data from recording a screenshot and the mouse position on every click during normal computer use.</dd>
  <dt>Prediction Neural Net</dt>
  <dd>Similar to the aboveÙ« but using Gaze data. A model would be trained on the gaze location and screen contents to predict the true mouse click target. One way to do this would be to feed the net patches of the screen centered on the gaze target. Training data would be gathered by saving data from every click and training on the true click position.</dd>
  <dt>Classical Computer Vision</dt>
  <dd>Thereâ€™s a number of possible computer vision techniques that could be used to identify targets without machine learning. For text anything from full OCR to algorithms that detect where text is without recognizing it (like in my <a href="https://github.com/trishume/KeySelect">KeySelect</a> demo). Buttons also often have textÙ« but controls could also be recognized using image patches recognized from previous clicks. You could even use heuristics like â€œcoloured thingsâ€ or â€œvisually complex thingsâ€.</dd>
</dl>

<h2 id="disambiguate-with-just-gaze">Disambiguate with just gaze</h2>

<p>Itâ€™s also possible to disambiguate targets with gaze aloneÙ« but this generally requires modifying or overlaying on the screen targets to manipulate the gaze.</p>

<dl>
  <dt>Magnifying</dt>
  <dd>The simplest one is just magnifying the error around the gazeÙ« either continuously or on dwell. This allows the user to refine their gaze on larger targets. The magnification can be either a rectangle or something fancier like a fisheye.</dd>
  <dt>Moving Markers</dt>
  <dd>Similar to keyboard disambiguationÙ« overlay likely targets with a marker that moves around in some pattern. Check if the gaze data is following one of the patterns. This works because eye trackers are better at detecting direction and timing of motion than absolute position. See the <a href="https://www.youtube.com/watch?v=x6hbicxEFbg">Orbits paper</a> for an example of this kind of system.</dd>
  <dt>Moving Distortion</dt>
  <dd>Similar to the previous except instead of markersÙ« distort the screen are around the gaze in a moving pattern where different parts move in different patterns. Then the user just follows what they want to click with their gaze.</dd>
  <dt>Eye Gestures</dt>
  <dd>Extra eye movements could be used to refine the position. For example darting the eyes in a position could nudge the cursor in that direction relative to where it was before the dart. Or winking an eye could move it left or right a small amount.</dd>
</dl>

<h2 id="how-to-click">How to click</h2>

<p>Clicking is a separate issueÙ« but thereâ€™s also lots of possibilities here:</p>

<ul>
  <li>Using a button: This could be a normal mouse or any other button.</li>
  <li>A foot pedal</li>
  <li>Dwell clicking</li>
  <li>Mouth noises: This is what I tried in my researchÙ« see <a href="https://github.com/trishume/PopClick">PopClick</a></li>
  <li>FaceÙ« head or eye gestures</li>
  <li>Voice recognition</li>
  <li>A keyboard</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Like I saidÙ« this was originally written primarily as prior art for patents. But I hope it was at least somewhat interesting to think about the numerous possibilities for eye tracking as a mouse replacementÙ« even if a lot of the ideas have issues.</p>
'),('http://thume.ca/2017/06/17/tree-diffing/', 'Designing a Tree Diff Algorithm Using Dynamic Programming and A*', '1497657600000',  13, '
<p>During my internship at <a href="https://www.janestreet.com/">Jane Street</a><sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>Ù« one of my projects was a config editing tool that at first sounded straightforward but culminated in me designing a custom tree diffing algorithm using dynamic programmingÙ« relentlessly optimizing it and then transforming it into an A* accelerated path finding algorithm. This post is the story of the design and optimization of the algorithmÙ« of interest to anyone who needs an algorithm for diffing treesÙ« or who just wants an in-depth example of the process of solving a real-world problem with a custom non-trivial dynamic programming algorithmÙ« and some tips on optimizing one while maintaining understandabilityÙ« or anyone who just wants to read a cool programming story and maybe learn something.</p>

<!-- Inspired by https://twitter.com/patio11/status/864770640796016641 -->

<h3 id="table-of-contents">Table of Contents</h3>

<ul>
  <li><a href="#background">Background</a>: Description of the problem I was solving.</li>
  <li><a href="#the-heuristic-approach">The Heuristic Approach</a>: My initial attempt at a simple algorithmÙ« and why it was insufficient.</li>
  <li><a href="#a-tree-diff-optimizer">A Tree Diff Optimizer</a>: Rethinking the problem as finding the optimal resulting tree diff.</li>
  <li><a href="#dynamic-programming">Dynamic Programming</a>: Background on using the correspondence between memoizing recursion and path finding on a grid to find solutions to problems like Levenshtein distance.</li>
  <li><a href="#the-algorithm">The Algorithm</a>: Extending Levenshtein distance with two grids and recursion.</li>
  <li><a href="#profiling-and-optimization">Profiling and Optimizing</a>: Relentless profiling and optimizations to reduce run time.</li>
  <li><a href="#path-finding">Path Finding</a>: Using A* to make the run time proportional to the difference rather than tree size.</li>
  <li><a href="#example-implementation">Example Implementation</a>: Analysis of the effectiveness and costs of A* on Levenshtein distanceÙ« sequence alignment and diffing problemsÙ« with open source example code.</li>
</ul>

<h2 id="background">Background</h2>

<p>Jane Street has a lot of config files for their trade handling systems which use <a href="https://en.wikipedia.org/wiki/S-expression">S-expressions</a> (basically a tree with strings as leaves). They often want to make changes that will only apply on certain daysÙ« for example days when markets will act differently than normal like elections and option expiry dates. To do this their config processor knows a special construct that is like a switch statement for datesÙ« it looks something like this:</p>

<figure class="highlight"><pre><code class="language-scheme" data-lang="scheme"><span class="p">(</span><span class="nf">thing-processor-config</span>
  <span class="p">(</span><span class="nf">:date-switch</span>
   <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span>
    <span class="p">(</span><span class="nf">speed</span> <span class="mi">5</span><span class="p">)</span>
    <span class="p">(</span><span class="nf">power</span> <span class="mi">7</span><span class="p">))</span>
   <span class="p">(</span><span class="k">else</span>
    <span class="p">(</span><span class="nf">speed</span> <span class="mi">3</span><span class="p">)</span>
    <span class="p">(</span><span class="nf">power</span> <span class="mi">9</span><span class="p">))))</span></code></pre></figure>

<p>The semantics are that any <code class="language-plaintext highlighter-rouge">:date-switch</code> block has its branches checked against the current date and the children of the correct branch are used in place of the <code class="language-plaintext highlighter-rouge">:date-switch</code> in the config structure. Note that each branch can contain multiple sub-trees.</p>

<p>NowÙ« just that small example took a while for me to type and get the indentation correct. People at Jane Street are frequently making edits where they just want to quickly change some numbers but have to make sure they get the syntax and indentation right and have everything still look nice. This is begging for automation!</p>

<p>So they asked me to write a tool that would allow people to just edit the file and run a commandÙ« and it would automatically scope their changes to the current dayÙ« or a date they specifyÙ« by detecting the differences between the current contents on disk and the committed contents in version control.</p>

<p>When I first heard the problemÙ« it sounded pretty easy and I thought Iâ€™d be done within a few daysÙ« but I discovered a number of catches after starting and it ended up taking 5 weeks. This sounds like we maybe should have abandoned it when we discovered how complex it wasÙ« but given how much time expensive people were spending doing these editsÙ« sometimes under time pressure when every extra minute had a high costÙ« it was worth it to get it right.</p>

<p>The first thing I discovered is that they had a library for parsing and serializing s-expressions while preserving indentation and commentsÙ« but it didnâ€™t cleanly handle making structural modifications to the parse tree. Before even starting the rest of the project I had to write a library that provided a better data model for doing this and having the result be nicely indented.</p>

<p>NextÙ« the real syntax for these date switch blocks is more complicated than my description and has a static constraint where the branches must cover every date in the current context and no moreÙ« including when nested inside other switches. I also didnâ€™t want edits to <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks to themselves be scoped to a dateÙ« since that would create invalid syntax. This required I parse my earlier style-preserving representation into one that computed date context and represented <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks specially in an <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract Syntax Tree (AST)</a> as well as transform back from my representation to the one I could output.</p>

<p>Now finally I was ready to start on the actual algorithm. The basic task my script had to do was take two trees and wrap differing sub-trees in a <code class="language-plaintext highlighter-rouge">:date-switch</code> block with the old contents in one branch and the new contents in the other branch. The thing isÙ« there are many ways to do this. The switch can be placed at many different levels and there may be multiple edits and itâ€™s not specified how to group them. Technically it could just add a <code class="language-plaintext highlighter-rouge">:date-switch</code> at the top level with the old file in one branch and the new file in anotherÙ« but that wouldnâ€™t be very satisfyingÙ« just like how technically the <code class="language-plaintext highlighter-rouge">diff</code> command could just output the entire old file prefixed with <code class="language-plaintext highlighter-rouge">-</code> and then the new file prefixed with <code class="language-plaintext highlighter-rouge">+</code>Ù« but then nobody would use it. I needed an algorithm that gave reasonable-looking and compact changes for real-world edits. It shouldnâ€™t double the file size in an enormous <code class="language-plaintext highlighter-rouge">:date-switch</code> when only a single number changed.</p>

<h2 id="the-heuristic-approach">The Heuristic Approach</h2>

<p>If you just want to read about the optimal algorithm and not why one was necessary you can <a href="#a-tree-diff-optimizer">skip this section</a>.</p>

<p>FirstÙ« I came up with a simple algorithm that I thought would work in almost all real-world cases. I simply recursively walked down the tree until I got to either a leaf that was different or a node that had a different number of childrenÙ« and then it would put a <code class="language-plaintext highlighter-rouge">:date-switch</code> at that level.</p>

<p>This didnâ€™t produce the most satisfying resultsÙ« it was okay for changes to leavesÙ« but as soon as you added or removed a child from a listÙ« it would duplicate most of the list when it could have taken advantage of the ability to have a different number of children in each branch.</p>

<p>It produced this:</p>

<figure class="highlight"><pre><code class="language-scheme" data-lang="scheme"><span class="p">(</span><span class="nf">:date-switch</span>
 <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span>
  <span class="p">(</span><span class="nf">foo</span>
   <span class="nv">qux</span>
   <span class="c1">; ... 1000 more lines ...</span>
   <span class="nv">baz</span><span class="p">))</span>
 <span class="p">(</span><span class="k">else</span>
  <span class="p">(</span><span class="nf">foo</span>
   <span class="c1">; ... 1000 more lines ...</span>
   <span class="nv">baz</span><span class="p">)))</span></code></pre></figure>

<p>When we really would have preferred:</p>

<figure class="highlight"><pre><code class="language-scheme" data-lang="scheme"><span class="p">(</span><span class="nf">foo</span>
 <span class="p">(</span><span class="nf">:date-switch</span>
  <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span> <span class="nv">qux</span><span class="p">)</span>
  <span class="p">(</span><span class="k">else</span><span class="p">))</span>
 <span class="c1">; ... 1000 more lines ...</span>
 <span class="nv">baz</span><span class="p">)</span></code></pre></figure>

<p>LuckilyÙ« this was easy enough to solve since Jane Street already had an <a href="https://github.com/janestreet/patience_diff">OCaml library implementing the Patience Diff algorithm</a> for arbitrary lists of comparable OCaml types. When I had two lists of differing lengthÙ« I simply applied the Patience Diff algorithm and placed <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks based on the diff.</p>

<p>This algorithm worked okay for cases of a single editÙ« but we wanted the tool to work with multiple editsÙ« and for those it still often produced terrible results.</p>

<p>For exampleÙ« because it stopped recursing and applied a diff as soon as it reached a list of changing lengthÙ« it would do this:</p>

<figure class="highlight"><pre><code class="language-scheme" data-lang="scheme"><span class="p">(</span><span class="nf">this</span>
 <span class="p">(</span><span class="nf">:date-switch</span>
  <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span>
   <span class="p">(</span><span class="nf">bar</span>
    <span class="c1">; ... 1000 more lines ...</span>
    <span class="nv">baz</span><span class="p">))</span>
  <span class="p">(</span><span class="k">else</span>
   <span class="p">(</span><span class="nf">foo</span>
    <span class="c1">; ... 1000 more lines ...</span>
    <span class="nv">baz</span><span class="p">)))</span>
 <span class="nv">tests</span>
 <span class="p">(</span><span class="nf">:date-switch</span>
  <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span> <span class="nv">adding</span> <span class="nv">to</span> <span class="nv">a</span> <span class="nv">list</span> <span class="nv">and</span> <span class="nv">modifying</span> <span class="nv">a</span> <span class="nv">sub-tree</span><span class="p">)</span>
  <span class="p">(</span><span class="k">else</span><span class="p">)))</span></code></pre></figure>

<p>It duplicates the long sub-tree instead of placing the <code class="language-plaintext highlighter-rouge">:date-switch</code> lower down in itÙ« just because we made another edit at a higher level of the tree.</p>

<p>There were a number of other cases where it didnâ€™t produce output as nice as a human wouldÙ« but earlier on my mentor and I had sighed and accepted it. This though was the last strawÙ« we needed a new approachâ€¦</p>

<h2 id="a-tree-diff-optimizer">A Tree Diff Optimizer</h2>

<p>At this point I was fed up with constantly discovering failure modes of algorithms I thought should work on real-world casesÙ« so I decided to design an algorithm that found the <em>optimal</em>
solution.</p>

<p>I started by searching the Internet for tree diff algorithmsÙ« but every algorithm I found was either a different kind of diff than what I neededÙ« or was complex enough that I wasnâ€™t willing to spend the time understanding it (probably only to later find out it computed a different kind of diff than I needed).</p>

<p>SpecificallyÙ« what I needed was mostly like a tree diff but I wasnâ€™t optimizing for the same thing as other algorithmsÙ« what I wanted to optimize for was resulting file sizeÙ« including indentation. This I thought represented what I wanted fairly wellÙ« and captured why previous results which duplicated large parts of the file were bad. As well as the character cost of the branchesÙ« each additional <code class="language-plaintext highlighter-rouge">:date-switch</code> block added more characters. AdditionallyÙ« each switch construct could also contain multiple sub-trees in each branchÙ« which I needed to model to account for overhead correctly.</p>

<p>Consider the case of <code class="language-plaintext highlighter-rouge">(a b c)</code> becoming <code class="language-plaintext highlighter-rouge">(A b C)</code>. A human would write:</p>

<figure class="highlight"><pre><code class="language-scheme" data-lang="scheme"><span class="p">(</span><span class="nf">:date-switch</span>
 <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span> <span class="p">(</span><span class="nf">A</span> <span class="nv">b</span> <span class="nv">C</span><span class="p">))</span>
 <span class="p">(</span><span class="k">else</span> <span class="p">(</span><span class="nf">a</span> <span class="nv">b</span> <span class="nv">c</span><span class="p">)))</span></code></pre></figure>

<p>Despite the fact that the <code class="language-plaintext highlighter-rouge">b</code> is duplicatedÙ« this is the smallest number of characters. However if we had something longer weâ€™d want something differentÙ« so the optimal result even depends on the length of leaf nodes:</p>

<figure class="highlight"><pre><code class="language-scheme" data-lang="scheme"><span class="p">((</span><span class="nf">:date-switch</span> <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span> <span class="nv">A</span><span class="p">)</span> <span class="p">(</span><span class="k">else</span> <span class="nv">a</span><span class="p">))</span>
 <span class="nv">this_is_a_super_long_identifier_we_do_not_want_duplicated_because_it_is_looong</span>
 <span class="p">(</span><span class="nf">:date-switch</span> <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span> <span class="nv">C</span><span class="p">)</span> <span class="p">(</span><span class="k">else</span> <span class="nv">c</span><span class="p">)))</span></code></pre></figure>

<p>A very common real-world example of why it is important for it to be able to batch together differences is when changing multiple values of a data structure. The config files often have lots of key-value pairs and edits often touch many nearby values:</p>

<figure class="highlight"><pre><code class="language-scheme" data-lang="scheme"><span class="p">(</span><span class="nf">thing-processor-config</span>
  <span class="p">(</span><span class="nf">:date-switch</span>
   <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span>
    <span class="p">(</span><span class="nf">speed</span> <span class="mi">5</span><span class="p">)</span>
    <span class="p">(</span><span class="nf">size</span> <span class="mi">80</span><span class="p">)</span>
    <span class="p">(</span><span class="nf">power</span> <span class="mi">9001</span><span class="p">))</span>
   <span class="p">(</span><span class="k">else</span>
    <span class="p">(</span><span class="nf">speed</span> <span class="mi">3</span><span class="p">)</span>
    <span class="p">(</span><span class="nf">size</span> <span class="mi">80</span><span class="p">)</span>
    <span class="p">(</span><span class="nf">power</span> <span class="mi">7</span><span class="p">))))</span></code></pre></figure>

<p>Even though <code class="language-plaintext highlighter-rouge">size</code> didnâ€™t changeÙ« we duplicate it because itâ€™s cleaner than having two <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks.</p>

<!-- This kind of case is also where counting indentation comes in handyÙ« if we only change one value we want to put the `:date-switch` around the whole pair because the indentation for putting it around the value is ugly:

    (thing-processor-config
      (speed (:date-switch
              (2017-04-07 5)
              (else 3)))
      ; better to do this
      (:date-switch
       (2017-04-07 (power 7))
       (else (power 9)))) -->

<!-- We can model the problem as a recursive decision-making problem where we want to find the optimal set of decisions. At each level we"ll have two listsÙ« a "new" list and an "old" listÙ« there"s a number of cases:

- If both lists are emptyÙ« there"s nothing to do
- If the first element of both lists is the sameÙ« we put it in the output and then make decisions on the remainder of the list.
- If both lists start with a different child listÙ« we have two choices:
  - We can start a new `:date-switch` block
  - Or we can recurse and decide how to place `:date-switch` blocks within the child list.
- OtherwiseÙ« we can only enter a `:date-switch` block.

And then we have a separate set of decisions we can make on lists
 -->

<h2 id="dynamic-programming">Dynamic Programming</h2>

<p>After 2+ days of researchÙ« discussing ideas with my mentorÙ« and sitting down in a chair staring out at the nice view of London while thinking and sketching out cases of the algorithm in a notebookÙ« I had something. It was a recursive dynamic programming algorithm that checked every possible way of placing the <code class="language-plaintext highlighter-rouge">:by-date</code> blocks and chose the bestÙ« but used memoization (thatâ€™s the dynamic programming part) so that it re-used sub-problems and had polynomial instead of exponential complexity.</p>

<p>The core of the tree diffing problem is similar to the <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein Distance</a> problemÙ« you have two lists that have some number of insertions and deletions between themÙ« and you want to find the best way to match them up. You can do this with a number of different cases based on the first elements of the lists with different costsÙ« calculating those costs involves some constant plus recursively computing the cost for the rest of the lists. Then you compute the cost for each possible decision and take the minimum one.</p>

<p>For example if you have a function <code class="language-plaintext highlighter-rouge">best_cost(oldÙ«new)</code> to solve the Levenshtein distance problemÙ« thereâ€™s three cases for the start of the lists: insertÙ« delete and same. The simplest case is if the first two elements are the sameÙ« and characters that are the same cost <code class="language-plaintext highlighter-rouge">0</code>Ù« then the cost is just <code class="language-plaintext highlighter-rouge">best_cost(old[1..]Ù« new[1..])</code>. If a delete costs <code class="language-plaintext highlighter-rouge">1</code>Ù« then if the start of the list is a delete that means the character is in <code class="language-plaintext highlighter-rouge">old</code> but not <code class="language-plaintext highlighter-rouge">new</code> so the total cost is <code class="language-plaintext highlighter-rouge">1 + best_cost(old[1..]Ù« new)</code>. Insert is similar but the opposite direction. This recursion terminates with the base case of <code class="language-plaintext highlighter-rouge">best_cost([]Ù«[]) = 0</code>. The problem is that this leads to an exponential number of recursive calls.</p>

<p>But we can fix this by noticing that a lot of things are being computed redundantly and sharing the results by â€œmemoizingâ€ the function so that it stores the results for arguments it has been called with before. As seen in the diagram belowÙ« where the numbers on the nodes represent calls to <code class="language-plaintext highlighter-rouge">best_cost(old[i..]Ù« new[j..])</code> as <code class="language-plaintext highlighter-rouge">iÙ«j</code>:</p>

<p><img src="/assets/postassets/treediff/tree.png" alt="Decision tree diagram" /></p>

<p>But in some cases it can be difficult to think about the problem as a recursive memoized decision tree. Luckily thereâ€™s a different way of thinking about it that lends itself very well to sketching out algorithms in a notebook or on a whiteboard. We can rotate the tree 45 degrees and notice that we can think about it as a grid:</p>

<p><img src="/assets/postassets/treediff/treegrid.png" alt="Decision tree diagram rotated to be a grid" /></p>

<p>This is useful for memoization since it means we can store our results in an efficient-to-access 2D arrayÙ« but also because we can now think of our problem as finding a path from the top left of a grid to the bottom right using a certain set of moves. Whenever our decisions are constrained we can annotate the grid where the input lists have a propertyÙ« like two items being the same. In the example belowÙ« we have a diagram of trying to find the Levenshtein distance from â€œabcdâ€ to â€œbcadâ€Ù« with the best path boldedÙ« and an alternative more costly path our algorithm might explore shown dashed.</p>

<p><img src="/assets/postassets/treediff/simplepaths.png" alt="Levenshtein distance paths" /></p>

<p>We can find the best path by testing all the paths and returning the best one. There are exponentially many pathsÙ« but we can notice that the best path from a point in the middle of the grid to the bottom right is always the same no matter what moves might have gotten us to that point.</p>

<p>One way to exploit this is to recursively search all paths from the top leftÙ« memoizing the best path at each point so we donâ€™t compute it again. This corresponds to the memoizing of recursive functions mentioned earlier and is called the â€œtop-down approachâ€ to dynamic programming.</p>

<p>Thereâ€™s also the â€œbottom upâ€ approach where you start from the bottom right and fill in each intersection with the best path based on previously computed results or base cases by using an order where everything you need is always available. In this case it would be right to leftÙ« top to bottomÙ« like reading a book from end to start.</p>

<p>Now we know that if we can restate our tree diffing problem as a problem of path-finding on a graphÙ« we can turn that into an implementation using dynamic programming.</p>

<h2 id="the-algorithm">The Algorithm</h2>

<p>The key differences between my problem and Levenshtein distances were the fact that it was a tree and not a listÙ« and the fact that consecutive sequences of inserts/deletes were cheaper than separate ones (because consecutive edits could be combined in one <code class="language-plaintext highlighter-rouge">:date-switch</code> block). My cost function is also different in that Iâ€™m measuring the size of the resulting tree including <code class="language-plaintext highlighter-rouge">:date-switch</code> blocksÙ« so my moves will need costs based on that.</p>

<p>I can extend the list algorithm to trees by adding a move Iâ€™ll call â€œrecurseâ€ that goes down and right and can be done on any square where both items are sub-trees (not leaves). The cost of the move is the cost of the resulting diff from running the entire tree-diff algorithm recursively on those two sub-trees. I donâ€™t bother recursing if the two sub-trees are the sameÙ« since the â€œsameâ€ move has identical cost in that caseÙ« and is faster to compute.</p>

<p>We can handle the cheaper consecutive inserts and deletes by modeling entering and leaving a <code class="language-plaintext highlighter-rouge">:date-switch</code> block as moves. However now we have different move sets based on if we are in or out of a <code class="language-plaintext highlighter-rouge">:date-switch</code> block and different costs to get to the end from a given point. We can rectify this by splitting our problem into path-finding over <em>two</em> grids of the same size. One is our â€œoutsideâ€ gridÙ« where we can do the â€œsameâ€Ù« â€œrecurseâ€ and now also a â€œinâ€ move which moves us to the same position on the other grid.</p>

<p>On the â€œinsideâ€ grid we can do â€œinsertâ€Ù« â€œdeleteâ€ and â€œoutâ€ moves. But that wonâ€™t quite work because if â€œinâ€ and â€œoutâ€ both donâ€™t make forward progressÙ« the graph has a cycle and our search algorithm will endlessly recurse over paths going â€œinâ€ and â€œoutâ€ at the same point. We can solve this by splitting â€œoutâ€ into â€œinsert outâ€ and â€œdelete outâ€. The first two are the same as insert and delete except they also move to the â€œoutsideâ€ gridÙ« we also have to make sure that we donâ€™t use the â€œinsertâ€ and â€œdeleteâ€ moves to go to the bottom right of the â€œinsideâ€ gridÙ« because then weâ€™d be stuck.</p>

<p>This gives us a set of moves that always make forward progress and share as much as possibleÙ« with this we can find the best path and that gives us an optimal diff. See the diagram below which also includes the cost of each move and an example pathÙ« although not necessarily the optimal one:</p>

<p><a href="/assets/postassets/treediff/treediffgrid.pdf" target="_blank">
<img src="/assets/postassets/treediff/treediffgrid.png" alt="Tree diff diagram" />
</a></p>

<p>Even this model is simplifiedÙ« because in reality I had to handle input lists that both might have <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks already in themÙ« so there were a bunch more cases and contingencies for handling existing <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks properly. But those arenâ€™t very interesting and the core of the algorithm is the same.</p>

<p>So I implemented this algorithm on top of the AST manipulation framework Iâ€™d built by translating it to a memoized recursive algorithm operating on linked lists. Since the outer algorithm also involved recursionÙ« this meant I had two kinds of recursionÙ« which I structured using OCamlâ€™s ability to define functions inside of other functions. I had an outer <code class="language-plaintext highlighter-rouge">scope_diffs</code> function that took two lists of s-expressions and produced a list of s-expressions with differences scoped by <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks. Inside itÙ« I allocated two tables to memoize the results inÙ« and defined <code class="language-plaintext highlighter-rouge">scope_suffix_diffs_inside</code> and <code class="language-plaintext highlighter-rouge">scope_suffix_diffs_outside</code> functions that took indices of the start of the suffixes and mutually recursed and memoized into the tables based on the moves above.</p>

<p>Unlike the Levenshtein difference algorithm I wanted more than just the costÙ« so I stored the actual scoped s-expressions up to each point in the table directlyÙ« because I was using immutable linked lists in OCaml this was memory-efficient since each entry would share structure with the entries it was built from. This way I avoided the back-tracing path reconstruction step that is frequently used with dynamic programming. In order to make the lists share structure I did have to add to the front instead of the backÙ« but I just reversed the best resulting list before I returned it.</p>

<p>Once I finished programming it and got it to compileÙ« I think I only had to fix one place where Iâ€™d copy-pasted a <code class="language-plaintext highlighter-rouge">+1</code> where I shouldnâ€™t have and then it worked beautifully. FinallyÙ« unlike all my heuristic attemptsÙ« I couldnâ€™t find a case where this produced a result significantly worse than what a human would do.</p>

<p><em>Side note:</em> I used to expect lots of debugging time whenever I finished a bunch of complex algorithmic codeÙ« but to my surprise Iâ€™ve found thatâ€™s rarely the case when using languages with good type systems. The compiler catches almost all small implementation errorsÙ« and since Iâ€™ve usually spent a long time thinking about all the edge cases carefully while designing the algorithmÙ« thereâ€™s usually no serious bugs left by the time it compiles. My tests usually fail a few timesÙ« but thatâ€™s normally because I wrote the tests wrong.</p>

<p>UnfortunatelyÙ« while my new algorithm worked quite well for small filesÙ« it was very slow on large files. My mentor timed it on a few example files and fit a polynomial and discovered that it was empirically <code class="language-plaintext highlighter-rouge">O(n^3)</code> (or it might have been <code class="language-plaintext highlighter-rouge">O(n^4)</code> I forget) in the file size. This was unfortunate since some of the files were tens of thousands of lines long. I had to make it fasterÙ« luckily while Iâ€™d been thinking about and implementing the algorithm Iâ€™d accumulated quite a list of optimization ideas to try. But firstÙ« I decided to profile to see what the biggest costs were.</p>

<h2 id="profiling-and-optimizing">Profiling and Optimizing</h2>

<h3 id="incremental-cost-computation">Incremental cost computation</h3>

<p>The first order of business was to discover why the empirical complexity was higher than we thought it should be. My mentor and I tried to come up with a proper analysis of what it should beÙ« but given all the cases and the nested nature of trees there were just too many parameters and we couldnâ€™t come up with anything precise. ButÙ« as far as we could tell the complexity of the underlying algorithm should have been about <code class="language-plaintext highlighter-rouge">O(n^2*log(n))</code> in the length of real files.</p>

<p>I could have looked over the implementation carefully to find all the extra unnecessary workÙ« but an easier method was just to use the <a href="https://perf.wiki.kernel.org/index.php/Main_Page">Linux <code class="language-plaintext highlighter-rouge">perf</code> tool</a> to profile it. I knew the work that caused it to be <code class="language-plaintext highlighter-rouge">O(n^3)</code> wasnâ€™t at the outer levels of the algorithmÙ« or I would have noticed easilyÙ« so it had to be an operation within that would show up in the profiles.</p>

<p>Sure enoughÙ« most of the programâ€™s time was spent in the code that computed the length/cost of an s-expression. I had a function that walked a tree and computed its total lengthÙ« and in the part of the algorithm where I had to choose the lowest-cost move I computed the cost of the entire path from that pointÙ« which added an extra <code class="language-plaintext highlighter-rouge">O(n)</code> inside the <code class="language-plaintext highlighter-rouge">O(n^2)</code> algorithm yielding <code class="language-plaintext highlighter-rouge">O(n^3)</code>.</p>

<p>In order to fix thisÙ« I made sure every cost computation was constant timeÙ« which meant I had to construct the cost of a path incrementally as it was constructedÙ« and also not repeatedly walk trees to determine their cost.</p>

<p>I solved this in three steps:</p>

<ol>
  <li>Create a â€œcosted listâ€ type which was a linked list except each item included the cost of the suffix from that point. This had a constant-time prepend operation that just added the cost of the item being prepended to the cost field of the rest of the list.</li>
  <li>Modify the Abstract Syntax Tree (AST) data structure to include a cost field on every nodeÙ« and to use a costed list for children. I also made all the AST builder functions compute the cost of their components by just adding the cost of their overhead with the costs of their child nodes or costed lists. Now both getting the cost of an AST subtree and constructing a node were constant time.</li>
  <li>When building the path/diff/result of my algorithm I used a costed list and constructed new <code class="language-plaintext highlighter-rouge">:date-switch</code> nodes using the constant-time builder API.</li>
</ol>

<p>After I did thisÙ« our measurements of growth were consistent with the <code class="language-plaintext highlighter-rouge">O(n^2*log(n))</code> we were expecting.</p>

<h3 id="skipping-identical-prefixes-and-suffixes">Skipping identical prefixes and suffixes</h3>

<p>This was an easy but high-impact optimization I had written down earlier. By the properties of the cost of each moveÙ« if a prefix and/or suffix of the two lists was identicalÙ« the â€œsameâ€ move would always be the best for those parts of the path. This meant that I could find the longest prefix and suffix of the two lists that was the same and only run the dynamic programming algorithm on the middle part that wasnâ€™t. This made the common case of edits being concentrated at a single point in the file very fast because now the running time was more like <code class="language-plaintext highlighter-rouge">O(d^2*log(d)+n)</code> with <code class="language-plaintext highlighter-rouge">n</code>being file size (large) and <code class="language-plaintext highlighter-rouge">d</code> being the size of the edited region (small).</p>

<p>Now almost all common uses of the tool would return instantly except edits in multiple places spread out through a large file. It was now a pretty useful toolÙ« but users having to know which cases to avoid to make the tool not take forever wasnâ€™t great. It would sometimes be used in high-pressure situations and often people did want to make edits in different placesÙ« manually batching the edits up and running the tool multiple times wasnâ€™t ideal.</p>

<p>There was also only one or two weeks left in my internshipÙ« not much time to do another projectÙ« and I think my mentor was having fun challenging me to make the tool perfect and brainstorming how to do so with me. I was also enjoying the processÙ« so the optimization would continue until performance improved!</p>

<h3 id="tree-creation-optimization">Tree creation optimization</h3>

<p>Profiling indicated a lot of time was spent creating <code class="language-plaintext highlighter-rouge">:date-switch</code> AST nodes.</p>

<p>First I wrote a fast-path method of creating and computing cost for <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks the algorithm creates since they use a simpler format and a known indentation style than the more general AST construction builder uses.</p>

<p>AdditionallyÙ« when exploring paths in the â€œinside :date-switchâ€ tableÙ« I used to create a <code class="language-plaintext highlighter-rouge">:date-switch</code> node whenever I needed to know the cost so far to decide between moves. InsteadÙ« I switched to just adding the costs of the <code class="language-plaintext highlighter-rouge">insert</code> and <code class="language-plaintext highlighter-rouge">delete</code> branches (which were costed lists)Ù« to a known overhead of the <code class="language-plaintext highlighter-rouge">:date-switch</code> block. I only created the full node upon exiting to the â€œoutside :date-switchâ€ table.</p>

<p>But my mentor realized this could extend even further: The search for the best path only ever needs to know the cost of a resulting path/treeÙ« we only need the full tree for the best path at the end of the search. So I added a â€œlazy <code class="language-plaintext highlighter-rouge">:date-switch</code>â€ AST node that has a stored cost computed by fast addition of the cost of the components plus a known overheadÙ« but doesnâ€™t actually create the node immediately and just stores an OCaml <code class="language-plaintext highlighter-rouge">lazy</code> thunk that creates it if we try to serialize the result.</p>

<!-- ### Adaptive memoization tables

My tool was now instant in most common cases and difficult cases were over 100x faster. ButÙ« on the very largest 10Ù«000+ line config files it would still take up to 5 minutes in the worst case if you made edits in multiple places. There were no longer any obvious hot spots in the profilesÙ« I needed algorithmic improvements that let me search less possible paths.

But before I did thatÙ« in order for them to be effective I had to enable sparse storage of the memoization tables. I was using 2D arraysÙ« but if I wanted to search less than `O(n^2)` states at each level I also wanted to not allocate `O(n^2)` memory.

A common approach when memoizing a recursive function is to store things in a hash tableÙ« that way you only pay for the storage of the states you actually explore. So I switched my implementation to use a hash table. UnfortunatelyÙ« it was now significantly slower and profiling showed hash table lookups were the cause of the slowdown.

I thought about it and realized that I only needed the memory savings on levels of the tree with large listsÙ« if I had two lists of 10Ù«000 elementsÙ« a 2d array would have 100 million slots. But if the lists only had
 -->
<!-- ^ It turns out it"s no longer in the implementationÙ« I must have done it but realized later it didn"t really help. -->

<h3 id="more">More?</h3>

<p>My tool was now instant in most common cases and difficult cases were over 100x faster. ButÙ« on the very largest 10Ù«000+ line config files it would still take up to 5 minutes in the worst case if you made edits in multiple places. There were no longer any obvious hot spots in the profilesÙ« I needed algorithmic improvements that let me search less possible paths.</p>

<p>I looked at my list of optimization ideas and there was only one leftÙ« which I had written down early on in the process when thinking about the correspondence between dynamic programming and path finding on a grid. It was just a few characters in a Markdown note that I had saved for if I was feeling ambitious and really needed it: â€œA*â€.</p>

<h2 id="path-finding">Path Finding</h2>

<p>Back when I was designing the algorithm by thinking about it as a path finding problemÙ« I thought â€œhey waitÙ« if this is a path finding problemÙ« why not use an actual path finding algorithm?â€ The first thing I realized is that the memoized recursion approach I was planning on taking was just a <a href="https://en.wikipedia.org/wiki/Depth-first_search">depth first search</a>Ù« which can be a path finding algorithmÙ« but not a particularly good one.</p>

<!-- As far as I can tell the bottom-up table-filling approach to dynamic programming corresponds most closely to [Dijkstra"s Algorithm](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm)Ù« except the acyclic graph and known structure mean you don"t have to manually track the visited and unvi -->

<p>Could I use a better path finding algorithm? Breadth first search wouldnâ€™t help much since the goal was near the maximum distance in bounds. HoweverÙ« <a href="https://en.wikipedia.org/wiki/A*_search_algorithm">A*</a>Ù« perhaps the most famous path finding algorithmÙ« seemed like it might helpÙ« if only I could come up with a good heuristic. So I wrote it down without thinking too much and came back to it later after I had done all my other optimizations.</p>

<p>The last time I learned A* was when I read <a href="http://shop.oreilly.com/product/9780596516246.do">Algorithms in a Nutshell</a> (good book) years ago and all I remembered was that it needed a priority queue and a good heuristic. I had a <a href="https://github.com/janestreet/core_kernel/blob/2e2bb4caedf0ca49d89735911578709434a780e2/src/heap_intf.ml">Heap</a> for the priority queueÙ« but I didnâ€™t remember how to actually implement it or what a good heuristic wasÙ« so <a href="https://en.wikipedia.org/wiki/A*_search_algorithm">to Wikipedia I went!</a>.</p>

<p>I learned that I needed a heuristic that never overestimated the remaining costÙ« and that ideally never decreased more than the cost of any move taken. One thing that satisfies those properties is the maximum of the costs of the two list suffixes from a location. This corresponds to the notion that a scoped config file that includes the contents of both config files canâ€™t be smaller than either of the input files. This heuristic was easy to compute using the costed list representation I already hadÙ« which already has the cost of each suffix of the input lists.</p>

<p>With a heuristic and an understanding of A* in handÙ« I refactored the implementation of my algorithm to work by putting successor states in a priority queue based on their cost plus the heuristic remaining cost. This required changing each instance of recursion on my table into the creation of a <code class="language-plaintext highlighter-rouge">State</code> structure that encompassed if I was inside or outside of a <code class="language-plaintext highlighter-rouge">:date-switch</code>Ù« and the current position.</p>

<p>I also had to make two changes to my data structures. FirstÙ« since I was no longer using recursion to destructure my linked lists but was now indexing themÙ« which is <code class="language-plaintext highlighter-rouge">O(n)</code>Ù« I created arrays of the tails of my input costed lists so that random access was fast. NextÙ« my solution still used <code class="language-plaintext highlighter-rouge">O(n^2)</code> memory in all cases due to the 2D array memoization tableÙ« so I switched that to a hash table from position tuples.</p>

<p>Profiling now showed a lot of time was then spent in hash table lookupsÙ« so I experimented with dynamically using a 2D array for small input lists (like were often found on the lower levels of the tree) and a hash table for larger input listsÙ« but further profiling showed it didnâ€™t increase performance muchÙ« probably because most of the lookups were in the larger listsÙ« so I stuck with plain hash tables.</p>

<p>After a little debugging of off-by-one errorsÙ« I ran the program on my largest test case and it finished instantly. It was so fast I was suspicious it was broken and just skipping all the workÙ« but sure enough it worked perfectly in every case I threw at it. The cost was something like <code class="language-plaintext highlighter-rouge">O(n * log(n) * e^2)</code> where <code class="language-plaintext highlighter-rouge">n</code> is the file size and <code class="language-plaintext highlighter-rouge">e</code> is the number of edits. Me and my mentor managed to think of some edge case trees where it might revert to <code class="language-plaintext highlighter-rouge">O(n^2)</code> behaviorÙ« and it still only scaled to config files of tens of thousands of lines rather than hundreds of thousandsÙ« but it was nearly instant for all cases that might actually occurÙ« so it was good enoughâ„¢.</p>

<p>I spent the remaining 3 days of my internship polishing up the user interface of the toolÙ« cleaning up the code and writing lots of doc comments explaining my algorithm. I also gave a presentation to a bunch of the other engineers telling a shorter version of the story Iâ€™ve written here. That marked the end of my internship with Jane Street and one of the most interesting algorithmic problems Iâ€™ve ever worked onÙ« despite it being part of a tool for editing configuration files.</p>

<h2 id="example-implementation">Example Implementation</h2>

<p>I was curious about how the approach of turning a dynamic programming problem into an A* path finding problem scaled and how applicable it was to other problems. SoÙ« I developed <a href="https://github.com/trishume/seqalign_pathing">an example implementation</a> of this approach in Rust for the <a href="https://en.wikipedia.org/wiki/Sequence_alignment">sequence alignment problem</a>Ù« which <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein distance</a> is a specific instance of. Itâ€™s structured for simplicity and I havenâ€™t optimized it at allÙ« but itâ€™s good enough to demonstrate the asymptotic improvements.</p>

<p>The <a href="https://github.com/trishume/seqalign_pathing/blob/master/src/lib.rs">core code of the algorithm</a> is fairly simple and is a good demonstration of the logic required to turn a dynamic programming algorithm into an A* path finding instance. It allows you to tune the weights of insertions/deletionsÙ« mismatches and matches of characters in the two stringsÙ« so that you can change it to be Levenshtein distance or some other instance of sequence alignment.</p>

<p>The heuristic it uses is based on splitting the remaining distance to the bottom right corner into two components: the minimum number of insertion/deletion moves necessary to get on the diagonal from the goalÙ« and the minimum number of match moves necessary to get from that place on the diagonal to the goal. This represents the minimum possible cost required to reach the goal from any position without knowing what the actual best path is.</p>

<figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">fn</span> <span class="nf">diag</span><span class="p">(</span><span class="n">pos</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">Pos</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">i32</span> <span class="p">{</span>
    <span class="p">(</span><span class="n">pos</span><span class="err">.</span><span class="mi">1</span> <span class="k">as</span> <span class="nb">i32</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">pos</span><span class="err">.</span><span class="mi">0</span> <span class="k">as</span> <span class="nb">i32</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">fn</span> <span class="nf">heuristic</span><span class="p">(</span><span class="n">pos</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">Pos</span><span class="p">Ù«</span> <span class="n">goal</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">Pos</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Score</span> <span class="p">{</span>
    <span class="c">// find the distance to the diagonal the goal is on</span>
    <span class="k">let</span> <span class="n">goal_diag</span> <span class="o">=</span> <span class="nf">diag</span><span class="p">(</span><span class="n">goal</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">our_diag</span> <span class="o">=</span> <span class="nf">diag</span><span class="p">(</span><span class="n">pos</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">indel_dist</span> <span class="o">=</span> <span class="p">(</span><span class="n">our_diag</span> <span class="o">-</span> <span class="n">goal_diag</span><span class="p">)</span><span class="nf">.abs</span><span class="p">();</span>
    <span class="c">// find the distance left after moving to the diagonal</span>
    <span class="k">let</span> <span class="n">total_dist</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">goal</span><span class="err">.</span><span class="mi">0</span> <span class="o">-</span> <span class="n">pos</span><span class="err">.</span><span class="mi">0</span><span class="p">Ù«</span> <span class="n">goal</span><span class="err">.</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pos</span><span class="err">.</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="nb">i32</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">match_dist</span> <span class="o">=</span> <span class="n">total_dist</span> <span class="o">-</span> <span class="n">indel_dist</span><span class="p">;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">indel_dist</span> <span class="o">*</span> <span class="n">INDEL</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">match_dist</span> <span class="o">*</span> <span class="n">MATCH</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p><img src="/assets/postassets/treediff/heuristic.png" alt="Heuristic diagram" /></p>

<h3 id="discoveries">Discoveries</h3>

<p>Hereâ€™s some things I learned by fiddling with the program and timing it:</p>

<ul>
  <li>As expectedÙ« the algorithm only tends to explore states along the diagonal of the gridÙ« with the width of the area explored proportional to the edit distance. This suggests the running time is something like <code class="language-plaintext highlighter-rouge">O((a+b) * e^2)</code> where <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code> are the input lengths and <code class="language-plaintext highlighter-rouge">e</code> is the edit distance.</li>
  <li>Running it on a 10Ù«000 base pair gene sequence with an edit distance of 107 takes 0.26 seconds.</li>
  <li>Running it on a 10 megabyte random text file with 1 edit near the beginning and 2 near the end takes 20 seconds and evaluates 40 million states. This is a case where with the <code class="language-plaintext highlighter-rouge">O(n^2)</code> algorithm just allocating and zeroing <code class="language-plaintext highlighter-rouge">4*10^14</code> bytes of memory for a table with the naive algorithm would take forever. Demonstrating that this optimization does in fact provide an asymptotic speed up.</li>
  <li>Itâ€™s still way slower than specialized sequence alignment implementations like <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5408825/">Edlib</a>Ù« probably asymptotically so. These implementations use all sorts of fancy tricks including fancy algorithmic tricksÙ« SIMD and bit vectors to eke out maximum performance for bioinformatics applications. My implementation is at least way way simpler.</li>
  <li>Plain <a href="https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm">Dijkstraâ€™s algorithm</a> (A* with a heuristic always returning 0) actually performs almost as well for Levenshtein distance because only edits have cost so it explores along the diagonal towards the goal along the path with less edits just because those have lower cost. HoweverÙ« if the problem has a cost for matching portions as well (like my original tree diffing problem) Dijkstraâ€™s algorithm will explore in a blob expanding from the top left and be almost as slow as the naive algorithm.</li>
  <li>With a heuristicÙ« Levenshtein-distance like instances where only edits have cost take about the same time to run as instances like my tree-diffing problem where matching segments also have cost.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>A* is an interesting technique thatâ€™s an easy way to accelerate a class of dynamic programming problems. It definitely works on any vaguely diff or edit-distance like problemÙ« but it might extend to even more. If you want absolute peak performance on a simple algorithm thereâ€™s probably better techniques to useÙ« Iâ€™d start by looking at what bioinformatics people doÙ« but if you just want something easy and flexible this seems like a good techniqueÙ« and itâ€™s not one Iâ€™ve seen done beforeÙ« and Google doesnâ€™t turn up any results. It might even be novelÙ« or it might just be that A* is a hard term to Google forÙ« Iâ€™m interested to hear from anybody whoâ€™s seen something like this before.</p>

<hr />

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>A great place to workÙ« highly recommend. I did get Jane Streetâ€™s permission before divulging the algorithm I wrote for them in this post.Â <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
'),('http://thume.ca/2017/04/06/learning-through-job-diversity/', 'Things I"ve Learned Doing Internships', '1491436800000',  13, '
<p>Iâ€™m a student at the University of WaterlooÙ« famous for its co-op program where students do 6 4-month work terms throughout their degree. Iâ€™ve now done <a href="http://thume.ca/resume/">7 internships</a> both within the program and outside it. Doing internships before one graduates is a great way of experiencing lots of different teamsÙ« work environments and even cities. This has allowed me to gain a much better idea of what kind of place I want to work after I graduate. Every job has taught me something genuinely new: my model of what factors are important to my enjoyment of a job has totally changed.</p>

<p>In this post Iâ€™ll share some of what I learned at each different companyÙ« especially the things that surprised me and went against conventional wisdom or practice.</p>

<h2 id="halogen-software">Halogen Software</h2>

<p>This was my first jobÙ« at a company that makes enterprise Java software for HR departments. Back then I was super enthused to have found a jobÙ« but nowadays this is the kind of place many of my friends would avoid just on the sound of it. Thereâ€™s a meme in Waterloo of â€œCali or bustâ€ where students try desperately hard to get jobs in California and are very sad if they have to settle for enterprisey boring-sounding jobs.</p>

<p>The thing isÙ« I enjoyed this job and had fun! My coworkers were great and despite working on software many would judge to be boring I found the work engaging.</p>

<p>At Halogen I learned that even companies that exemplify all the stereotypes of a boring company (JavaÙ« B2BÙ« CRUDÙ« cubicalsÙ« not in California) can be good enjoyable places to work. Just because your job isnâ€™t at the hottest company in California doesnâ€™t mean it will be miserable.</p>

<h2 id="the-eclipse-foundation">The Eclipse Foundation</h2>

<p>My second job was an unpaid co-op job for credit in high-school where I would spend the second half of every school day working. I worked on fixing bugs in the Eclipse IDE off of the bug tracker.</p>

<!-- I found this place by noticing it within 500m of my house on Google Maps and cold-calling them. I needed a job that was easy to get to for a half-day and it so happened that the organization behind the Eclipse Java IDE was close by. It turned out that they don"t employ anyone working on the IDEÙ« but the person I phoned was a former programmer and agreed to supervise me. -->

<p>What I learned is that <em>tooling matters a lot</em>. Itâ€™s not that the Java tooling I was using allowed me to figure things out fasterÙ« itâ€™s what allowed me to do things <em>at all</em>. I could wade in with no experience to a multi-million line code base and fix <a href="https://bugs.eclipse.org/bugs/show_bug.cgi?id=2369">11-year old bugs</a> because the Java and Eclipse tooling was <em>so good</em>. The ability to view references and definitions with total accuracy and to follow things in an excellent debugger was key. An interesting Eclipse-specific feature was that every part of Eclipse was a pluginÙ« so instead of spending hours compiling all of EclipseÙ« you could download the source for the relevant pluginÙ« load itÙ« then immediately press â€œRunâ€ and it would start a new instance of Eclipse almost immediately that cloned your copy of Eclipse except for that one plugin. To this day it is the largest project Iâ€™ve worked on but it had a very fast feedback loop and short setup timeÙ« it was quite impressive.</p>

<p>Almost all of Javaâ€™s faults as a language were made up for by tooling that was leagues better than any other popular language (excepting maybe C#). This job tempered my enthusiasm for how much more productive <code class="language-plaintext highlighter-rouge">$AWESOME_LANGUAGE</code> is than languages like Java and C# despite better design and handy features.</p>

<h2 id="shopify">Shopify</h2>

<p>I worked at Shopify three times: twice during high school summers and once as my first Waterloo co-op job. As suchÙ« I learned a fair amount thereÙ« but the lessons were sometimes spread outÙ« so Iâ€™ve grouped them together.</p>

<h3 id="transparent-and-involved-executives-are-fantastic">Transparent and involved executives are fantastic</h3>

<p>The CEO of ShopifyÙ« <a href="http://www.theglobeandmail.com/report-on-business/rob-magazine/meet-our-ceo-of-the-year/article21734931/">Tobi LÃ¼tke</a>Ù« is incredibly awesome. He started as the first developerÙ« and he makes sure to stay afloat with the latest developments and will even weigh in on technical strategy if you tag him on Github. As an intern it was pretty awesome to sit down on a couch with the CEO and hack on <a href="https://github.com/Shopify/liquid">Liquid</a> together. Heâ€™s also very transparent and makes sure everything about the company is too. For exampleÙ« every couple weeks he does a frank AMA where he addresses questions submitted and voted on by employees and does a good job of giving detailed answers and not dodging.</p>

<p>On other fridaysÙ« employees give lightning talks about what they are working on. This is where one story that really exemplifies the difference between a great CEO and a stereotypical one happened: I was giving a short talk about flaws in the <a href="https://github.com/Shopify/liquid">Liquid</a> template parser and how it would accept almost anything without a syntax errorÙ« and <a href="https://github.com/Shopify/liquid/pull/235">my work in replacing it</a>. My next term I learned that while watching my talk heâ€™d joked to the person next to him  â€œthat kidâ€™s got courageâ€Ù« which clued me in that at most other companiesÙ« trash talking code the CEO wrote that powered an important part of the productÙ« in front of the entire companyÙ« wouldâ€™ve been a â€œcareer limiting moveâ€ to put it lightly. I had talked to Tobi about the parser rewrite before the talk and he was in fact the first one to admit that the parser had issuesÙ« he had even bought a book on parsers hoping to fix it himself somedayÙ« so I knew I was safe giving the talk. RegardlessÙ« it still shows the benefits of having a great transparent CEO who does his best to rid the company of stifling corporate politics.</p>

<h3 id="good-managers-make-a-big-difference">Good managers make a big difference</h3>

<p>Up until my last internship at Shopify Iâ€™d had good team leadsÙ« supervisors and managers. I recognized that they were important but they didnâ€™t really affect me or my work that much. This sounds like the lead up to a bad manager storyÙ« but actually the thing that changed my mind was having a <em>fantastic</em> team lead/manager.</p>

<p>He was dedicatedÙ« competentÙ« funnyÙ« relentlessly positiveÙ« an excellent advocate for me and the rest of the team. He was also a developer but he spent most of his time being team leadÙ« keeping everything on targetÙ« prioritizingÙ« problem solving and making sure we were on target to ship on time.</p>

<p>He had a moderate impact on my productivity: prioritizingÙ« distributing tasksÙ« answering questions and pair programming on difficult tasks. HoweverÙ« he had a tremendous impact on environment of being on the team and thus my enjoyment of the job. I learned that having a good manager helps things run smoothlyÙ« but having an excellent manager can make a good job <em>great</em>. I hear that having a bad manager can make a good job terribleÙ« but luckily I have yet to experience that (<em>crosses fingers</em>).</p>

<h3 id="if-everything-else-is-done-right-the-task-doesnt-matter">If everything else is done rightÙ« the task doesnâ€™t matter</h3>

<p>The importance of a good manager ties into my next pointÙ« which is that on that same team I was working on a CRUD web appÙ« a stereotypically boring task. HoweverÙ« I really enjoyed that jobÙ« and through that I learned that when a company gets <em>everything else right</em> it doesnâ€™t matter very much what the actual task is.</p>

<p>When I was working at Shopify the third timeÙ« my team was greatÙ« my manager was greatÙ« the culture was greatÙ« the office was greatÙ« the tools were greatÙ« the language was greatÙ« the food was greatÙ« the focus on quality was greatÙ« the technical decision-making was great. It didnâ€™t matter that I was working on redesigning a web form.</p>

<p>This isnâ€™t to say the task doesnâ€™t matter at all. If the task was actually an unpleasant one and not just a less exciting form of programmingÙ« I wouldnâ€™t have enjoyed it nearly as much.</p>

<h2 id="the-university-of-waterloo-hci-lab">The University of Waterloo HCI Lab</h2>

<p>My next termÙ« following my general strategy of trying out as many different jobs as possibleÙ« despite enjoying my previous job so much I tried out research. I worked on a system that fused eye trackingÙ« head tracking and sound recognition to provide <a href="https://github.com/trishume/PolyMouse">a hands-free mouse alternative that I could use as quickly as I can a trackpad</a>. I also worked on custom computer vision systems for eye tracking and marker trackingÙ« as well as developing custom audio recognition algorithms. I basically got free reign to work on a side project I had as a job and do exactly the work I wanted and found interesting.</p>

<h3 id="further-learning-on-project-coolness">Further learning on project coolness</h3>

<p>This switch from working on CRUD web apps to a cool project that I had chose myself furthered my learning from the previous term. Despite working on my choice of the most interesting topicÙ« although I definitely enjoyed the jobÙ« I didnâ€™t enjoy it as much as my previous internship at Shopify.</p>

<p>There were two components to this:</p>

<p>FirstÙ« the magnitude in difference of how interesting a project sounds doesnâ€™t correspond to the magnitude of difference in how interesting working on a project is. Working on cool computer vision systems involves a lot of architectureÙ« plumbingÙ« refactoring and debugging. Most of these tasks are the same kind of tasks one does when working on a CRUD web app. Even when I was working on redesigning a web form there were times when I had to go sit away from the computer and think really hard with a notepad about architectural issues and how to design the system in a clean and robust way. Despite massive differences in how interesting they soundedÙ« the computer vision system only involved moderately more interesting difficult problems and slightly less boring plumbing than the CRUD web app.</p>

<p>SecondlyÙ« I found that even when I was working on the interesting challenging partsÙ« I enjoyed and valued the challenge and learningÙ« but not as much as I expected to value them before I started the job. The difference in fun was tangible but not as extreme as I had imagined.</p>

<p>Previous to this term I had systematically overvalued the importance of the challenge and interestingness of the task. I also see this a lot when people I know choose jobsÙ« theyâ€™ll sacrifice payÙ« company qualityÙ« location choiceÙ« teamÙ« cultureÙ« perks and pretty much everything else if it means they can work on something cool like compilers for machine learning on big data. I did exactly this as well for my research term.</p>

<p>Interestingness of the work is still a significant positive factor when Iâ€™m choosing a jobÙ« it just no longer overrides all other considerationsÙ« itâ€™s more of a factor I use to decide between two good options.</p>

<h3 id="teams">Teams</h3>

<p>One part of the difference between working in the lab and working at Shopify was that in the lab I was working alone on my own project. There were other people in the lab that I talked to occasionally but we didnâ€™t really work together or even eat lunch together.</p>

<p>I realized that great coworkers are an important part of why I enjoyed my previous jobs.</p>

<h2 id="jane-street">Jane Street</h2>

<p>For my next internship I worked at <a href="https://www.janestreet.com">Jane Street</a> in London UK. I worked on developer toolsÙ« low-latency networking codeÙ« rendering huge tables and tree-diffing algorithmsÙ« all in OCaml. I had a great timeÙ« both with the interesting work and all the other parts of working there.</p>

<h3 id="interviewing">Interviewing</h3>

<p>The first thing that impressed me about Jane StreetÙ« because it was before I even startedÙ« was how good their interviewing system is. The questions seemed rather good at testing programming ability rather than algorithm knowledge or flashes of inspiration. They were about thinking hardÙ« puzzling out all the cases and extracting a clean design. I was allowed to use a whiteboardÙ« their laptopÙ« or my own laptopÙ« with any language I wanted. Each interview had two interviewers in the roomÙ« I assume for higher judgement reliability for the time spent. There were a reasonable number of interviews packed in to one dayÙ« and I got an offer a fairly short amount of time after I interviewed.</p>

<p>Later I learned that they have a set of people who specialize in interviewing and do substantially more interviews because they like to and for greater consistency and skill specialization. Each question is well-specified and alpha and beta tested before being used for decision-making. Becoming the lead of the two interviewers for a specific question requires having shadowed someone else who knows it well.</p>

<p>This interview process seems substantially better than any other process that I have heard of (with the possible exception of the Matasano process <a href="https://news.ycombinator.com/user?id=tptacek">tptacek on HN</a> talks aboutÙ« but I havenâ€™t looked into that much). It addresses many of the common criticisms of tech company interviews like algorithm bingoÙ« requiring flashes of inspirationÙ« requiring coding on a whiteboardÙ« poor question designÙ« inexperienced interviewers and lack of inter-rater reliability. It seems like it would have a very low false positive rateÙ« and a lower (though still significant) false negative rate than other interview processes Iâ€™ve seen.</p>

<h3 id="agency">Agency</h3>

<p>Another thing that impressed me is the level of agency afforded to employees. The management structure was extremely flatÙ« and everyoneâ€™s job was basically either â€œDo whatâ€™s best for the companyÙ« probably codingâ€ or â€œDo whatâ€™s best for the companyÙ« probably tradingâ€ with some people in between and a few â€œâ€¦ with some managingâ€ thrown in.</p>

<p>For certain type of companyÙ« this seems to work excellently. Competent people know that for decisions with sufficiently high stakes it is a good idea to seek input from othersÙ« and expend effort to make the right decision proportional to the stakes. This means thereâ€™s little need for explicit policiesÙ« procedures and approval chains. That doesnâ€™t mean the value they provide is absentÙ« they just happen whenever they make sense for the task at handÙ« like ops checklists and working with other people to make big decisions correctly. I was surprised by the extent to which â€œDo whatâ€™s bestâ€ gets the benefits of standard corporate practices when helpfulÙ« but avoids the pitfalls. I still donâ€™t believe this is broadly applicable thoughÙ« it needs a certain type of company to work well.</p>

<h2 id="conclusion">Conclusion</h2>

<p>My model of what a good job and an effective company looks like have changed significantly since before I started working. Since starting at Waterloo Iâ€™ve even precommitted to not doing repeat internshipsÙ« so as to maximize the variety of jobsÙ« locationsÙ« and companies I experience. Itâ€™s tempting to return when I have a great time and a job is the best one Iâ€™ve ever hadÙ« but I remember that the only reason I took <em>that</em> job was that I didnâ€™t return to the <em>previous</em> best job I ever had.</p>

<p>Iâ€™m looking forward to further learning at 3 more internships before I graduateÙ« including one in San Francisco at Google this summer. After I graduateÙ« Iâ€™ll look hard at all the different jobs Iâ€™ve had and will have a good model with which to decide what I want to do next. This will likely be returning to my favourite past companyÙ« but I might also use this information to choose a brand new path Iâ€™m confident is better.</p>
'),('http://thume.ca/2017/03/04/my-text-editor-journey-vim-spacemacs-atom-and-sublime-text/', 'My Text Editor Journey: VimÙ« SpacemacsÙ« Atom and Sublime Text', '1488585600000',  13, '
<p>I currently use a highly customized Sublime Text 3 as my text editor for
almost all programming. HoweverÙ« people are often surprised to learn that Iâ€™ve
used Vim for 6 monthsÙ« Emacs/Spacemacs for 10 months (including much elisp
hacking) and Atom for a monthÙ« yet I still prefer Sublime.</p>

<p>This post explains my journey between text editorsÙ« what I learnedÙ« what I
like and dislike about each of themÙ« and why in the end Iâ€™ve chosen Sublime
(for now). Most detailed is <a href="#spacemacs">my reasoning for abandoning Spacemacs</a>Ù« despite
being a top contributor and power userÙ« although many of
my criticisms of Vim also apply to Spacemacs (and vice versa).</p>

<h2 id="the-early-days-textmate--sublime-text-2">The Early Days: Textmate &amp; Sublime Text 2</h2>

<p>My text editor when I first learned programming was TextmateÙ« and I stuck with
it for a few years (I forget how many) before I at some point switched to
Sublime Text 2â€™s trialÙ« and then paid for a license.</p>

<p>Back then I only used the basics: syntax highlightingÙ« find/replaceÙ«
autocompleteÙ« file treeâ€¦ I didnâ€™t know any keyboard shortcuts besides
standard OS ones like copy-paste and undo. I used the mouse for all selection
and eventually learned the Sublime command pallete and â€œopen file in projectâ€
pallete.</p>

<p>This setup didnâ€™t cause me any troubleÙ« I was productive and nothing was
painful. ButÙ« I heard tell of the true power one gained upon learning to use a
<em>real</em> editor like Vim or Emacs. I watched screencasts where Vim masters would
perform impressive editing operations in a couple keystrokes.</p>

<h2 id="vim-a-taste-of-power">Vim: A Taste of Power</h2>

<p>In late 2012 I switched to Vim. I learned the keyboard shortcuts with <code class="language-plaintext highlighter-rouge">vimtutor</code>
and printed cheat sheets. I read tons of blog articles (often conflicting) on
learning and using Vim the right way.</p>

<p>I tried using a blank <code class="language-plaintext highlighter-rouge">.vimrc</code> and building pieces from scratch making sure I
understood what each piece did each time. HoweverÙ« this was taking far too
longÙ« my editor was missing key functionality from Sublime and Textmate like a
file treeÙ« good autocompleteÙ« open in projectÙ« and support for languages I
used. It was also ugly.</p>

<p>So I started using the <a href="https://github.com/spf13/spf13-vim">spf13</a> Vim
distribution. It was niceÙ« and had most of the features I wanted. You can
still find my modified spf13-based vimrc <a href="https://github.com/trishume/dotfiles/tree/master/vim%2B">here</a>.</p>

<p><img src="/assets/postassets/editors/vim.png" alt="Vim" /></p>

<p>I was reasonably happy with this setup and continued using it for over 6 months.</p>

<p>HoweverÙ« there were many pain points. One of these was that things often
didnâ€™t work. For exampleÙ« my tab key was bound to tons of different things
like autocompleteÙ« snippet expansionÙ« indentationÙ« moving between snippet
fields and inserting the literal tab character. Many of those overrode each
other in different contextsÙ« but very often it chose the wrong one. I ended up
fixing this somewhat but not completelyÙ« but I didnâ€™t have this issue in
Sublime because everything was designed to work together so the tab key just
always did what I wanted. Even after I fixed itÙ« the hours I spent
diagnosing the issueÙ« figuring out how to resolve the conflictsÙ« implementing
itÙ« then re-learning my muscle memory probably erased weeks of sub-
second Vim speed gains.</p>

<p>Another issue I had was that Vim was mouse-hostile. I was fully aware that the
Vim philosophy is to just never use the mouse. HoweverÙ« even with plugins like
<a href="https://github.com/easymotion/vim-easymotion">EasyMotion</a> and ideal vim
shortcut use the keyboard is slower for some selection tasks like selecting a
range of text far from the cursor than the mouse is. Often using Vim shortcuts
felt faster because my brain was engaged figuring out the optimal combination
of motions and looking for EasyMotion hintsÙ« but whenever I timed myself I was
consistently much slower than I was with the mouse. Iâ€™m only talking about
long range selection and cursor movement hereÙ« I totally concede that keyboard
shortcuts are better for short range movement and selection. Vim wasnâ€™t that
bad for the mouseÙ« but lots of plugins didnâ€™t really work well with it and
mouse selection often worked weirdly in some states.</p>

<h2 id="back-to-sublime-with-a-stint-in-atom">Back to Sublime (with a stint in Atom)</h2>

<p>I realized that I didnâ€™t like fighting my editor and loved the ease of use and
mouse support of Sublime. HoweverÙ« I also loved the power of Vimâ€™s keyboard
model. LuckilyÙ« I could use <a href="https://github.com/guillermooo/Vintageous">Vintageous</a>.</p>

<p>This way I could get all the power I liked about Vim with all the niceties of
Sublime.</p>

<p>In factÙ« Vintageous is arguably more powerful than Vim itself because it works
with multiple cursors. Using multiple cursors with Vim bindings is incredibleÙ«
itâ€™s basically the same power as Vim macros give youÙ« except you can compose
them on the fly with instant feedback about what commands did at each place
you wanted to use them (see gif below). I found I rarely used macros with Vim because I had to
think hard about which commands I could use that would work on every instance
and make sure I didnâ€™t screw anything upÙ« then figure out how I wanted to run
the macro for each locationÙ« but with Sublime it was so easy I did it all the
time. YesÙ« I know both Vim and Emacs have multiple cursor pluginsÙ« but they are
hacks and donâ€™t seamlessly work with all commands and together with the mouse.</p>

<p><img src="/assets/postassets/editors/sublime_vim.gif" alt="Sublime Vim" /></p>

<p>I started using Sublime as a power userâ€™s text editor just like I had used Vim.
I learned the keyboard shortcutsÙ« read about the functionality and installed plugins.</p>

<p>For a month I also tried out Atom. I pretty much replicated my Sublime Text
setup with the equivalent Atom pluginsÙ« plus some extras that only Atom offered.
HoweverÙ« I preferred Sublimeâ€™s speed. It wasnâ€™t just that some editing operations
had a bit of latencyÙ« but that Sublime could offer features that Atom couldnâ€™t
because of its speed. For example Sublimeâ€™s â€œopen in projectâ€ panel instantly
previews the files as you type because it can load files in millisecondsÙ« and search
is incremental by default.</p>

<p>I used this setup quite happily from mid-2013 to late-2014. HoweverÙ« I started
thinking about the possibility of using Emacs with <code class="language-plaintext highlighter-rouge">evil-mode</code>. Iâ€™d heard its
Vim emulation was fantastic and the possibility of using Emacs lisp to craft
the perfect text editing experience given time was enticing.</p>

<p>I started looking around at various Emacs starter kits like <a href="https://github.com/bbatsov/prelude">Prelude</a>
and tried out a few. I read Emacs articlesÙ« documentation and blog posts
about peopleâ€™s Emacs configs. HoweverÙ« everything had really horrible convoluted
hard to remember keyboard shortcuts that didnâ€™t fit well with Vimâ€™s.</p>

<h2 id="spacemacs">Spacemacs</h2>

<p><a name="spacemacs"></a></p>

<p>ThenÙ« I found Spacemacs. It was exactly what I was looking for. It was prettyÙ«
integrated Vim and Emacs functionality in an interesting and discoverable wayÙ«
and promised to have everything set up to work out of the box. Somehow this
project only had around 12 stars on Github and no other contributors. It
seemed the creator had poured tons of effort into making a fantastic projectÙ«
but unlike most peopleâ€™s dotfilesÙ« he put effort and thought into making it
adaptable to individual needs and documenting how to do so. I was stunned that
this project only had ~20 stars and no other contributors.</p>

<p>So I downloaded itÙ« started working on my own <code class="language-plaintext highlighter-rouge">.spacemacs</code> file and joined the
Gitter chat the creator had set up. A little while later I submitted the <a href="https://github.com/syl20bnr/spacemacs/pull/19">first
contribution</a> to the project.</p>

<p>Little did I know at that point that the reason it only had 20 stars was that
by chance and lots of Googling I had just stumbled upon it earlier than
everyone else. Over the coming weeks I continued tweaking and sending PRs and
other early adopters like <a href="https://github.com/cestdiego">Diego</a> trickled in to
the chat and started contributing.</p>

<p>As I used Spacemacs I often noticed things that worked poorly or not at all.
I kept steadily fixing most problems I found and adding new contribution layers
for the things I wanted. When I was using Spacemacs for something where I had
already fixed most of the bugsÙ« it was quite nice and felt efficient.</p>

<p>I continued using Spacemacs for around 6 months and maintained my position
as top contributor for most of that time. I helped newbies out in the Gitter
chatÙ« triaged PRs and contributed and maintained a few different layers.</p>

<p>I thouroughly enjoyed contributing to SpacemacsÙ« but nearly everything I
contributed was fixing a bug or annoyance I encountered while trying to get
something doneÙ« often writing the elisp to fix an earlier problem.</p>

<h3 id="brokenness">Brokenness</h3>

<p>These yak-shaving tasks ranged from <a href="https://github.com/syl20bnr/spacemacs/pull/174">fixing annoying keybinding conflicts</a> that Sublime Text had built-in logic forÙ«
to <a href="https://github.com/syl20bnr/spacemacs/pull/58/files">getting LaTeX support to work</a>. I even <a href="https://github.com/Hammerspoon/hammerspoon/pull/300">wrote a general mechanism for tabbing OSX windows</a> to get around how bad all the Emacs tab/workspace plugins were.
I definitely <a href="https://github.com/syl20bnr/spacemacs/pull/76">noticed my annoyance</a>
but I ignored it since I was having fun and I had hope that things would get better after more work.</p>

<p><img src="/assets/postassets/editors/spacemacs.png" alt="Spacemacs Tabs" /></p>

<p>HoweverÙ« after six months of making almost no progress on other projects while
discovering and fixing bugs and implementing things I missed from other
editorsÙ« I realized that there might not be an end. Part of the problem is
that I love learning new languages and doing different kinds of projects. Other
Spacemacs users might make a few fixes here and there for their primary use caseÙ«
whereas I was stuck adding support for <a href="https://github.com/syl20bnr/spacemacs/pull/1415">D</a>Ù«
<a href="https://github.com/syl20bnr/spacemacs/pull/937">RacketÙ« Nim and Rust</a> and then
fixing the bugs I exposed when changing my workflow.</p>

<p>I think the underlying reason is that everything in EmacsÙ« and especially
SpacemacsÙ« is a hack. Core Emacs offers almost nothing and everything is
layered on top as ad-hoc Emacs Lisp additions. Different third-party plugins
and to some extent base functionality step on each others toes and make
conflicting assumptions all the time. One particularly bad example I ran into
is my Emacs hanging mysteriously when autocompleting on some two character
suffixes. After much searching it turned out to be a <a href="https://github.com/syl20bnr/spacemacs/issues/2654">known issue</a> where if what I was
completing looked like a domain name Emacs would try to ping it because of an
interaction between autocompletionÙ« file findingÙ« and remote server support.</p>

<h3 id="lack-of-consistency-and-discoverability">Lack of Consistency and Discoverability</h3>

<p>Another problem with this pile-of-hacks design is that nothing was consistent
or discoverable. Every moment I saved on common operations due to efficient
keyboard shortcuts was cancelled out by a minute spent searching for how to do
a less common operation that I didnâ€™t do often enough to memorize.</p>

<p>An example of an occasional workflow I can do in Sublime is:</p>

<ul>
  <li>Paste my clipboard into the search box.</li>
  <li>Search all files in a project for without regex support (useful when searching for a string with special
characters that you donâ€™t want to escape)Ù« case insensitively.</li>
  <li>Narrow it down to a glob of certain files without re-typing my query.</li>
  <li>Edit my query slightly to refine the resultsÙ« again without re-typing it.</li>
  <li>Replace the content of all those occurences once satisfied.</li>
</ul>

<p>I tried to do this in Emacs onceÙ« and had to spend a ton of Googling and investigating <code class="language-plaintext highlighter-rouge">M-x</code> listings:</p>

<ul>
  <li>Look up how to search in project without regex (Iâ€™ve never figured out a way to do this)</li>
  <li>Look up the shortcut for pasting into the minibuffer (I use Evil so I canâ€™t use <code class="language-plaintext highlighter-rouge">p</code> like usual).</li>
  <li>Hope that the command is Helm-based so I can edit my queryÙ« otherwise re-type everything to narrow it down.</li>
  <li>Look up how to replace in project without regexÙ« oops itâ€™s an entirely different command from searching.</li>
  <li>Re-enter everything into the new command and run it.</li>
</ul>

<p><img src="/assets/postassets/editors/sublime_find.png" alt="Sublime"s fancy find dialog" /></p>

<h3 id="navigating-multiple-files">Navigating Multiple Files</h3>

<p>The last major problem I had was how difficult it was to work with code spread
across multiple files compared to Sublime Text.</p>

<p>Thereâ€™s three main ways for working with files in Emacs: buffersÙ« files and windows.</p>

<p>I tried using buffers but the problem is that buffer switching is slow and
difficult. It only takes one keystroke to switch to the most recently opened
other bufferÙ« if you remember which that isÙ« but switching to other buffers
requires waiting for a list to showÙ« reading itÙ« then multiple additional keys to select the right one.
Buffers also tend to proliferate like mad and these lists end up enormous taking many keys to filter to the right one.
They are also nearly impossible to navigate with the mouse if Iâ€™m reading code and thatâ€™s where my hand is.</p>

<p>Navigating using normal <code class="language-plaintext highlighter-rouge">find-file</code> and <code class="language-plaintext highlighter-rouge">helm</code> mechanics has a similar problem:
switching is just slow. It takes a lot of key strokesÙ« and those strokes sometimes
involve waiting for a list to appear that you can read.</p>

<p>Having your frame/screen split into a bunch of windows (Emacs reverses the
meaning of window and frame from every other editor) in Spacemacs has the
advantage that each window has a number on it and you can hit <code class="language-plaintext highlighter-rouge">SPC+1</code> to
<code class="language-plaintext highlighter-rouge">SPC+9</code> to switch directly to them. This is great in that it is very fast and
easy to rememberÙ« find and see where you want to go and how to get there. The
problem is that you sacrifice screen real estate for every new file you work
with. I normally ameliorate this with <a href="https://github.com/roman/golden-ratio.el">golden-ratio</a>
modeÙ« which shrinks unfocused windowsÙ« but they still take up space.</p>

<p>With Sublime Text I use tabsÙ« which are amazing. I can switch quickly and directly
between files with <code class="language-plaintext highlighter-rouge">cmd+1</code> to <code class="language-plaintext highlighter-rouge">cmd+9</code>Ù« see all the files Iâ€™m working with at a glanceÙ«
and navigate with the mouse if I want to. I can also easily rearrange tabs so that the
most frequently used and important files are on lower consistent numbers that I can <a href="https://en.wikipedia.org/wiki/Subitizing">subitize</a>.
I can even use <a href="https://packagecontrol.io/packages/Zen%20Tabs">ZenTabs</a> to ensure that I only
ever have my 9 most recently used files open in tabsÙ« eliminating buffer proliferation.
Infrequent but useful actions like moving a file between windows and panesÙ« and copying the file
path are all obvious discoverable mouse actions. The file Iâ€™m working on always fills the full screenÙ«
unless I want to reference other code in another pane. When the file I want isnâ€™t a tab
I can open it with â€œGoto Anythingâ€Ù« which is similar in speed to narrowing to a buffer by name.
When I want to navigate based on a projectâ€™s directory structure I have access to a fantastic
file tree.</p>

<p>YesÙ« Emacs has plugins to add tabs but they are hacks. Theyâ€™re uglyÙ« slowÙ« break when used
with other pluginsÙ« donâ€™t have good keyboard shortcutsÙ« and display tons of useless buffers I donâ€™t care about.</p>

<p>When I watch friends and coworkers use Vim and Emacs this is the thing I
notice most. They look super efficient since theyâ€™re furiously typing things
or navigating directoriesÙ« but often the file they are opening is one that
they looked at just a minute ago and would have taken me a single keystroke to
switch to. They however have to type a bunch of characters to narrow to the
buffer name. I even frequently see Vim/Emacs users opening files by
navigating directories when I would have just typed a few characters into
â€œGoto Anythingâ€. Emacs and Vim also have ways to fuzzy search for a file in a
projectÙ« but the heuristics and tools are often so bad and slow that they give
up and fall back on manually finding the file. Iâ€™ve never seen a Vim or Emacs
users who navigates between files as fast as I do in Sublime.</p>

<h3 id="realization">Realization</h3>

<p>I realized that despite all my work and the work of other contributors using
Emacs was still a pain and I longed for the just-works nature of Sublime Text.
It didnâ€™t help that many operations in Spacemacs had surprisingly high latency
(similar to Atom) and many things were ugly (like the file tree). I said my goodbyes
to the Spacemacs community and headed back to Sublime Text.</p>

<p>I still think Spacemacs is overall quite good though. If youâ€™re someone who
mainly codes in one languageÙ« especially a popular oneÙ« then you can get
Spacemacs set up to do exactly what you wantÙ« and the huge community nowadays
means that either the bugs will have been fixed or you can easily get help
with the ones you encounter. Iâ€™ve listed a bunch of disadvantagesÙ« but Emacs
has powerful features that Sublime doesnâ€™tÙ« I just didnâ€™t like what I had to
give up to get them.</p>

<h2 id="sublime-text-3-back-with-vengeance">Sublime Text 3: Back With Vengeance</h2>

<p>So I switched back to Sublime Text 3Ù« but just like after VimÙ« I took some of the
things I enjoyed back with me. I updated my plugin and keybinding arsenal to include
many of the handy things I used in Spacemacs.</p>

<p><img src="/assets/postassets/editors/sublime.png" alt="Sublime Text 3" /></p>

<p>One thing I really enjoyed in Emacs was <a href="https://magit.vc">Magit</a>Ù« so I installed
<a href="https://github.com/divmain/GitSavvy">GitSavvy</a> in Sublime and found it had almost
everything I liked about Magit. I even like its workflow marginally better and the
Github integration is top notch.</p>

<p>I set up the <a href="https://github.com/deanishe/alfred-repos">Alfred Git Repos</a> workflow
to replicate opening projects with ProjectileÙ« and used my <a href="https://github.com/Hammerspoon/hammerspoon/pull/300">OSX window tabbing plugin</a>
to manage my Sublime Windows as well.</p>

<p>The fanciest thing I did was create <a href="https://github.com/trishume/SublimeTect">my own set of keybindings</a>
that work like Vim except with the palm keys of <a href="/2014/09/08/creating-a-keyboard-1-hardware/">my custom keyboard</a>
as the mode. That way it is faster to quickly do movement and editing actions in
the middle of writing. It also synergizes way better with the mouse because
I never am in an unexpected mode when I use it and then move back to the keyboard
since they physical state of my hands is the state of the editor. I still drop into
Vintageous mode for fancier editing though.</p>

<p>And all this took me only a few evenings to get to a point where I was happier
with it than the Spacemacs setup that had taken me six months. Iâ€™ve been using
this setup happily since mid-2015 with only a couple bugs which were quickly
fixedÙ« despite using the dev builds of ST3 and many plugins itâ€™s been orders
of magnitude more reliable than Emacs.</p>

<h2 id="jane-street">Jane Street</h2>

<p>Then I went to work at <a href="https://www.janestreet.com">Jane Street</a> for an internship
and ended up migrating back to Spacemacs for a little while. Jane Street has a bunch
of internal Emacs toolingÙ« and even a bunch of custom integration with SpacemacsÙ«
along with much more mature tooling for OCaml than Sublime Text.</p>

<p>It was mostly pretty goodÙ« but far from smooth sailing. Various internal
and external Emacs plugins I used conflicted on their idea of where windows
should go and took over other windowsÙ« almost actively replacing whichever
window I cared about most. I encountered tons of bugsÙ« both large and small.
Many of these I ended up patching myselfÙ« either with dotfile snippets or <a href="https://github.com/ocaml/tuareg/pull/99">pull</a> <a href="https://github.com/ocaml/tuareg/pull/103">requests</a>.</p>

<p>Not only did I encounter over 20 different EmacsÙ« Spacemacs and plugin bugs
(some annoying me quite regularly) during my four monthsÙ« but there were other
problems. Jane Streetâ€™s massive code base made many plugins slow to a crawl.
Synchronous autocompletion with Merlin occasionally hung Emacs. Using <code class="language-plaintext highlighter-rouge">helm-projectile</code>
was unbearable without caching and slow even with it. Until I disabled a bunch
of hooks saving files took seconds due to <code class="language-plaintext highlighter-rouge">hg</code> commands running slowly on the large repo.</p>

<p>Eventually I talked to the one guy using Sublime Text at Jane Street and got
his set of plugins and settings for working on Jane Streetâ€™s OCaml with Sublime.
I modied the <a href="https://github.com/cynddl/sublime-text-merlin">Sublime Merlin</a> plugin
to support <a href="https://github.com/jbrooksuk/Intellitip">tooltips</a> that showed the inferred
type of an expression and clickable links to the file of definition and declaration.</p>

<p>I then started using Sublime Text for sprees of reading codeÙ« but not for writing it.
Sublime still had far worse support for building and indenting Jane Street code.
ButÙ« this way I could understand things faster by using quick fuzzy search of filesÙ«
excellent tabsÙ« smooth scrolling with the mouseÙ« and tooltip links to navigate the codebase.</p>

<p>Eventually I started using Sublime for editing as wellÙ« after I improved indentingÙ«
highlighting and autocompletion slightly. I still kept Emacs open to run the source
controlÙ« <a href="https://github.com/janestreet/iron">code review</a> and <a href="https://github.com/janestreet/jenga">Jenga build</a> pluginsÙ«
but I set up elisp so that it navigated to compile errors in both Sublime Text and Emacs.
This offered an excellent compromise between nice plugins and a good editor that I was happy with.</p>

<p>Despite all the additional functionality and improvements I made to SublimeÙ« I actually
think I spent less time on getting Sublime to work than on fixingÙ« debugging and setting
up Spacemacs while I was there.</p>

<h2 id="closing-thoughts">Closing Thoughts</h2>

<p>OverallÙ« Iâ€™m still very satisfied with Sublime Text. I think text editors could
go a lot further than they are nowÙ« but so could most software. I feel very
productiveÙ« I never fight my editorÙ« and it works for any language I throw at it.</p>

<p>I would love it if Sublime was open sourceÙ« or if there was an open source editor
that was as good. HoweverÙ« I realize that many of the reasons I love Sublime
wouldnâ€™t be possible without it making money. The reason the creator(s) can pour
so much effort and care into every detail is that Jon (and now also Will) can work
on it full time for years. No other text editor has a custom cross-platform UI toolkitÙ«
a custom parallel regex engineÙ« and incredibly fast indexingÙ« search and editing engines.</p>

<p>I also realize that in some respects Sublimeâ€™s rather limited plugin API is an advantage.
Unlike Emacs/Vim/Atom I rarely have to worry about plugins slowing down my experience
by accidentally doing something synchronously on the entire fileÙ« since the API almost enforces
asynchronous design. No plugin can break core functionality or slow startup times.
Plugins are forced to work only in ways where it is difficult to conflict with each other
since two plugins canâ€™t implement hacks in the internals that interfere with each other.
When Emacs plugins implement â€œhelpfulâ€ hacks to basic functionality that conflict and break
thingsÙ« my approach is often to disable them since I rarely want these hacks anyway.</p>

<p>Sublime can also get faster and better every release because they donâ€™t have to worry as much
about piles of hacks restricting how they can change their internals. Like how Atom constantly
has to <a href="http://blog.atom.io/2014/07/02/moving-atom-to-react.html">deprecate old APIs</a> whenever they restructure to improve performance.</p>

<p>AlsoÙ« the recent dev builds have patched what I think was the number one
hole in Sublimeâ€™s plugin API: tooltips and inline annotations. Now plugins can
implement <a href="https://github.com/facelessuser/ColorHelper">fancy custom tooltips</a>
with links and colours and formatting using a subset of HTML. This same HTML
subset can also be used to inject â€œphantomsâ€: rich text annotations of code
for things like previewing LaTeX formulaeÙ« coloursÙ« typesÙ« lints and errors.
This should allow most of the useful plugins that previously were only
possible in Atom/Emacs to be ported to SublimeÙ« but since it is implemented
centrally instead of a bunch of different ways it will work seamlessly and
consistently.</p>

<p>Iâ€™m optimistic for the future of Sublime Text. Iâ€™d love to see a new editor thatâ€™s open source
and as fastÙ« nice and powerful as SublimeÙ« but I donâ€™t expect to since it would be a ton of work.
Visual Studio Code looks pretty awesome thoughÙ« if I was writing Javascript Iâ€™d consider it for the
excellent tooling integrationÙ« but for less common languages it doesnâ€™t look any better than Sublime.</p>

<p>I wrote this post because I often find myself justifying my use of Sublime Text to
Vim and Emacs users. They often look at Sublime users as people who just havenâ€™t put
in the effort to learn a <em>real power userâ€™s text editor</em>. Theyâ€™re confused when they learn
that I have tried Vim and Emacs extensively and still choose to use what they see as
a basic newbie editor. I hope this post explains why Sublime is an excellent choice
for a highly customizable power userâ€™s text editor.</p>

<h2 id="edit-faq">Edit: FAQ</h2>

<p>Some responses to questions Iâ€™ve seen raised after posting this:</p>

<h3 id="you-just-havent-learned-vim-a-real-vim-user-could-do-long-distance-text-selection-faster">You just havenâ€™t learned Vim. A real Vim user could do long distance text selection faster.</h3>

<p>I think I know vim quite wellÙ« Iâ€™ve been using vim bindings for 5 years now across varying editors. I know almost all Vim bindings.</p>

<p>How about a test? Suppose my cursor is on line 198 of <a href="https://github.com/trishume/syntect/blob/ef3b99b06b72e89b7a0036969897751034422f5a/src/parsing/parser.rs">this file</a> I want to copy <code class="language-plaintext highlighter-rouge">match_pat.has_captures &amp;&amp; cur_level.captures.is_some()</code> on line 172. If you give me an efficient sequence of vim bindings for that movement I can tell you if I know what everything does without looking it up.</p>

<p>I think a more apt criticism would be that I think too slowly to use Vim. I can figure out that â€œ26j4wy10eâ€ does what I wantÙ« and at my normal english characters/second typing speed that is faster than doing the selection with my mouse. HoweverÙ« when I actually try and do that without figuring it out ahead of time I take longer to readÙ« count and figure out the right numbers and actionsÙ« then type the individual characters (which due to muscle memory for english Iâ€™m slower at than typing english). I end up being slower than the mouseÙ« and with a higher mental load.</p>

<p>You could say I just need to â€œgit gudâ€ and practiceÙ« but if practicing for hours a day for 5 years doesnâ€™t get me to the point that Iâ€™m better than the mouseÙ« I think itâ€™s time to say that maybe it isnâ€™t a lack of practice. More likely itâ€™s an innate skill differenceÙ« processing speedÙ« countingÙ« typing coordinationÙ« or a combination of the above. I do actually use Vim bindings a lot of the timeÙ« I know them wellÙ« and I know when it is faster for me to use the mouse.</p>

<p>That all presumes that there exists a substantial number of people who are faster in practice at long distance text selection with vim shortcuts than I am with the mouse. I have yet to see someone where I can confidently say that is the caseÙ« and Iâ€™ve watched a reasonable number of vim users. Some are within the margin of error where I would have to do a timed race with a stopwatchÙ« but I havenâ€™t seen any that are clearly meaningfully faster. I guess everyone Iâ€™ve seen using vim (including many 5+ year users) could be a â€œvim n00bâ€Ù« but that sounds a bit â€œno true scotsmanâ€-like.</p>

<h3 id="if-you-used-stock-emacs-without-all-the-bloat-it-would-be-faster-and-stable">If you used stock Emacs without all the bloat it would be faster and stable.</h3>

<p>Yes it would have been faster and more stableÙ« however then I would just complain about the lack of a bunch of features from Sublime that I likeÙ« and the terrible keybindings.</p>

<p>I also have minor RSI issuesÙ« Iâ€™m not keen to turn them into major RSI issues by using Emacs bindings.</p>

<h3 id="you-can-only-switch-directly-to-a-few-tabs-buffer-switching-is-logarithmic-time-for-many-buffers">You can only switch directly to a few tabsÙ« buffer switching is logarithmic time for many buffers.</h3>

<p>YesÙ« but tabs are more like a cache. Like I mentionÙ« when it isnâ€™t easy to hit the numbered shortcut to
jump directly to a tab I use â€œGoto Anythingâ€ to narrow directly to the fileÙ« which takes the same amount
of time buffer switching would.</p>

<p>Tabs are just an additional speedup in the case that Iâ€™m switching to one of my ~6 most recently/frequently
used files. Iâ€™d say itâ€™s the case that over 95% of my switches are to one of my tabsÙ« but only at most 50%
of my switches are to my most recently used other fileÙ« thereâ€™s gains to be had over Emacs in that extra 45%
of switches that become fast.</p>
'),('http://thume.ca/2016/12/03/disassembling-sublime-text/', 'Disassembling Sublime Text', '1480723200000',  13, '
<p>This afternoon I spent some time with the free trial of the
<a href="https://www.hopperapp.com/">Hopper Disassembler</a> looking through the binary of
Sublime Text 3. I found some interesting things and some undocumented settings.</p>

<h2 id="undocumented-settings">Undocumented Settings</h2>

<p>The most potentially useful and interesting thing I found were some undocumented
settings for Sublime Text. A couple of them could even be useful to some people:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">draw_shadows</code>: A boolean that can disable the shadow effect when any line is longer
that the window. I personally like effect but if you want a cleaner look or your window
is only slightly wider than your text and the shadow effect kicks in earlyÙ« you can use
this setting.</li>
  <li><code class="language-plaintext highlighter-rouge">indent_guide_options</code>:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">solid</code>: This as an undocumented option that makes indent guides solid instead of dashed.
Add this in addition to a <code class="language-plaintext highlighter-rouge">draw_*</code> option.</li>
      <li><code class="language-plaintext highlighter-rouge">draw_active_single</code>: Like <code class="language-plaintext highlighter-rouge">draw_active</code> but only draws the innermost indent guide your
cursor is in instead of guides for every indent level down to it.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">draw_debug</code>: A boolean that if true enables a special debugging text renderer. It seems to
turn sections of the document either blue or redÙ« and within the sections it turns tokens
alternating light and dark shades of those colours. Note you have to set the setting to false
to turn it offÙ« not just delete it. These change sometimes when scrolling and editing but I
canâ€™t figure out when and why.</li>
  <li><code class="language-plaintext highlighter-rouge">wide_caret</code>: This just acts like adding to <code class="language-plaintext highlighter-rouge">caret_extra_width</code>Ù« probably an old settingÙ« not useful.</li>
</ul>

<p>Thereâ€™s also the undocumented command line flags:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">--multiinstance</code>: Starts a new instance of Sublime even if one is already running.</li>
  <li><code class="language-plaintext highlighter-rouge">--debug</code>: Prints debug output to stdoutÙ« I think this is just the output that goes in the built-in console.</li>
</ul>

<p>I discovered these settings by running <code class="language-plaintext highlighter-rouge">strings</code> on my <code class="language-plaintext highlighter-rouge">Sublime Text.app/Contents/MacOS/Sublime Text</code>
binary and looking near the things I knew where config options for things that looked like config
optionsÙ« then trying them out.</p>

<p><img src="/assets/postassets/sublimesecrets/debug_render.png" alt="Debug rendering mode" />
<img src="/assets/postassets/sublimesecrets/configs.png" alt="Debug rendering mode" /></p>

<h2 id="libraries-used">Libraries Used</h2>

<p>The Sublime Text release binaries donâ€™t have symbol names stripped outÙ« probably for debugging
reasonsÙ« and for that Iâ€™m very grateful because itâ€™s really cool. The assembly is still largely
indecipherable to meÙ« but there are some cool things I can find out.</p>

<p>From the function names I can also see some of the libraries used in the making of Sublime Text.
Hereâ€™s a partial list:</p>

<ul>
  <li>Skia: Itâ€™s been mentioned online this is used for rendering everything</li>
  <li>Google densehash: Faster hash mapÙ« used everywhere</li>
  <li>Oniguruma: Fallback for fancy regexes the custom engine canâ€™t handle</li>
  <li>Boost</li>
  <li>Google breakpad</li>
  <li>CryptoPP/Crypto++ (in old versionsÙ« now replaced with libtomcrypt)</li>
  <li>leveldb: Used to store symbol indexes I think</li>
  <li>snappy: Fast compressionÙ« not sure what it is used for</li>
  <li>Hunspell</li>
  <li>YAML (apparently actually yaml-cpp)</li>
  <li>lzma</li>
  <li>Hunzip: Probably what is used to unzip the zipped up package format</li>
  <li>libtomcrypt</li>
</ul>

<h2 id="internal-names">Internal names</h2>

<p>I can also see some general architecture and what things are named. This is just cool trivia.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sregex</code>: The custom super fast regex engine. I think the special feature is that it can search for many different regexes on one piece of text at the same time. Because <a href="http://github.com/trishume/syntect">when I wrote a sublime-syntax highighter</a> thatâ€™s what I would have wanted.</li>
  <li><code class="language-plaintext highlighter-rouge">skyline</code>: The name for Sublimeâ€™s widgets framework. The centerpiece is <code class="language-plaintext highlighter-rouge">skyline_text_control</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">px</code>: The windowing and platform integration framework used for event handlingÙ« file management and other OS integration across WindowsÙ« Linux and OSX.</li>
  <li><code class="language-plaintext highlighter-rouge">TokenStorage</code>: The class that stores and renders highlighted tokens.</li>
</ul>

<p>God how I wish any of these were open source. Each of these would be useful in
many things other than text editors. Thereâ€™s no app I know of that has its own
custom-rendered UI framework that manages to be as fast and smoothly
integrated with the OS as <code class="language-plaintext highlighter-rouge">skyline</code> and <code class="language-plaintext highlighter-rouge">px</code> are. The custom regex engine
would be a handy library as well. I do understand that these goodies might not
have existed in the first place if Jon couldnâ€™t make money off of Sublime Text
thoughÙ« so Iâ€™m grateful that I at least have one beautiful and fast cross-
platform app.</p>

<h2 id="more">More</h2>

<p>I also tried to figure out how some parts of the editor work and why they are so fastÙ«
but I couldnâ€™t figure out much from the assembly. All the key functions have hundreds of
basic blocks and are enormous with everything inlined. If I spent an entire day I might be
able to reverse engineer one functionÙ« but that wouldnâ€™t get me very far.</p>

<p>If thereâ€™s anything youâ€™re interested in about Sublime Textâ€™s internalsÙ« leave a
comment and I might take a look. Especially if itâ€™s a tiny behaviour improvement that
isnâ€™t accessible to the plugin API but might be possible to patch in the binaryÙ«
with a debuggerÙ« or with something like <a href="http://www.frida.re/">Frida</a>.</p>

<h2 id="edit-updates">Edit: Updates</h2>

<p>After this article was posted on <a href="https://news.ycombinator.com/item?id=13100560">Hacker News</a>
and cross-posted to <a href="https://forum.sublimetext.com/t/disassembling-sublime-text/24824">the Sublime forum</a>Ù«
@wbondÙ« the Package Control maintainer and new Sublime developer replied with some corrections and new info.
Iâ€™ve updated the library listing above with the new info.</p>
'),('http://thume.ca/2016/07/16/advanced-hackery-with-the-hammerspoon-window-manager/', 'Advanced Hackery With The Hammerspoon Window Manager', '1468627200000',  13, '
<p>Along with <a href="https://kapeli.com/dash">Dash</a>Ù« <a href="https://www.sketchapp.com/">Sketch</a> and <a href="http://papersapp.com/">Papers</a>Ù« one of the main reasons I havenâ€™t yet switched to Linux is <a href="http://www.hammerspoon.org/">Hammerspoon</a>. Hammerspoon gives me most of the power that a fancy Linux tiling window manager and configurable desktop would give meÙ« without having to switch operating systems. Itâ€™s fully configurable with LuaÙ« has <a href="http://www.hammerspoon.org/docs/index.html">tons of built in modules</a> and it is simple to write your own modules. I think of it more as a general-purpose tool for modifying OSXâ€™s user interface than just a window manager. This post explores some of the ways Iâ€™ve used Hammerspoon to greatly enhance my general OSX-using experience.</p>

<p><img src="/assets/postassets/hammerspoon/hammerspoon.png" alt="Hints Screenshot" /></p>

<h2 id="window-hints">Window Hints</h2>

<p>The first Hammerspoon module I wrote was a port of <a href="/howto/2012/11/19/using-slate/#switching-windows">Slateâ€™s window hints</a>Ù« which if youâ€™ve ever used Vimium or VimperatorÙ« are like link hints for windows. They allow you to switch to any window with only two keystrokes: One shortcut to bring up icons and letters for every windowÙ« and then simply hitting the key corresponding to the window you want.</p>

<p><a href="https://github.com/trishume/mjolnir.th.hints">The module</a> was written mostly in a single evening as a native Lua module (originally for MjolnirÙ« the precursor to Hammerspoon).
It didnâ€™t take much timeÙ« and is very enjoyable to useÙ« and because the module was added to the core Hammerspoon distributionÙ« lots of other people can also benefit from it.</p>

<h2 id="window-tabs">Window Tabs</h2>

<p>The second Hammerspoon module I wrote was one that allows you to add tabs to any OSX Application. The tabs sit in the top right of the title bar and allow you to easily switch between windows of an app with keyboard shortcuts (e.g <code class="language-plaintext highlighter-rouge">ctrl+tab number</code>) and later by clicking. This was originally motivated by my switching to <a href="http://spacemacs.org/">Spacemacs</a> and it not having a good solution for working on many different projects like Vim tabs. This module allowed me to wrangle Emacs windows to more easily switch between different projects. I later repurposed it to switch between Sublime Windows for the same reason when I switched back to Sublime Text.</p>

<p>This module was very different to write since it was pure Lua. It uses Hammerspoonâ€™s various powerful built-in modules including the drawing moduleÙ« the app watcher moduleÙ« and the window listener module.</p>

<p><img src="/assets/postassets/hammerspoon/tabs.png" alt="Tabs Screenshot" /></p>

<h2 id="mouth-noises">Mouth Noises</h2>

<p>Most recently I <a href="https://github.com/Hammerspoon/hammerspoon/pull/936">contributed</a> a <a href="http://github.com/trishume/thume.popclick">module for recognizing mouth noises</a>. It is based off some low-latency high-accuracy mouth noise recognizers I wrote during my research term at the UWaterloo HCI lab. Personally I use this module to scroll pages hands-free while lying down on the couch with my laptop. Previously I had to contort my hand into a cramped position on my chest to scroll with the trackpad while lying on my back. Itâ€™s one of my zanier uses of Hammerspoon but it is nice to use nonetheless. Just goes to show the variety of user interface scripting tasks Hammerspoon can do.</p>

<h2 id="custom-window-management-hotkeys">Custom Window Management Hotkeys</h2>

<p>I love being able to customize my window management shortcuts perfectly for the kind of things I normally do. I have a custom modifier key on <a href="/2014/09/08/creating-a-keyboard-1-hardware/">my keyboard</a> that is dedicated to window management I call <code class="language-plaintext highlighter-rouge">hyper</code>. Pressing <code class="language-plaintext highlighter-rouge">hyper</code> in combination with the left home row jumps directly between my most frequently used apps (ChromeÙ« SublimeÙ« iTerm2Ù« MailÙ« Path Finder) and a pair of keys that mark a certain window and focus itÙ« for all the other apps I use occasionally like PDF readers when writing LaTeX. Pressing <code class="language-plaintext highlighter-rouge">hyper</code> with the right home row moves a window between full screenÙ« halves of the monitorÙ« and between screens. Various other hyper shortcuts do things like toggling mouth noise recognition. I also have a hotkey I can hit when I plug in my external monitor that arranges all my apps between monitors in the way I like them instantly.</p>

<h2 id="miscellaneous-hackery">Miscellaneous Hackery</h2>

<p>Iâ€™ve used Hammerspoon for some one-off tasksÙ« especially when I want to bind things to global keyboard shortcuts. An example of this is a weekend project I did to make a mouse controlled by head movements detected by an accelerometer on a microphone headset. I used Hammerspoon to send serial commands to the microcontroller when I pressed a shortcut to toggle the mousing on and off.</p>

<p><img src="/assets/postassets/hammerspoon/lookmouse.jpg" alt="Lookmouse" /></p>

<h2 id="conclusion">Conclusion</h2>

<p>I hope this has given you some ideas about how you can use Hammerspoon to make your computing experience more pleasant. Check out <a href="https://github.com/trishume/dotfiles/blob/master/hammerspoon/hammerspoon.symlink/init.lua">my Hammerspoon config</a> to see how I configure everything and tie it all together. For more inspiration check out the amazing things <a href="https://github.com/asmagill/hammerspoon-config">asmagill does in his config</a>. He has experimental modules for all sorts of things like drawing calendarsÙ« custom app menusÙ« fonts and speech control.</p>

'),('http://thume.ca/2016/04/03/simple-binary-formats-and-terrible-hacks/', 'Simple Binary Formats and Terrible Hacks', '1459641600000',  13, '
<p>Last weekend me and my friend <a href="http://mlht.ca/">Marc</a> went to <a href="https://medium.com/@tau/terriblehack3-1164c2541c3f">TerribleHack III</a> and made <a href="http://dayder.thume.ca/">Dayder</a>Ù« a neat little website for finding <a href="http://tylervigen.com/spurious-correlations">spurious correlations</a> in lots of time series data sets. I did the ingestion of our initial data set of causes of death over timeÙ« as well as the JS/HTML front end. Marc made the correlation finding web server in Rust and also did the final prettying up of the CSS. Iâ€™m quite proud of how well it turned out given that it was made in 12 hours.</p>

<p><img src="/assets/postassets/binary/dayder.png" alt="Dayder" /></p>

<p>The coolest part of Dayder is how fast it is. All the DOM and JS Canvas rendering code is custom built for rendering hundreds of graphs in milliseconds. Marc and I also designed a custom simple binary format for storing time series data in a compact way. We called the format <a href="https://github.com/trishume/dayder/blob/master/format.md">btsf</a> and it is a key reason why our app can quickly send tons of time series data sets to the client as well as store them on the server in a compact way. All 6591 time series fit in less than 1 megabyte of dataÙ« allowing them all to be sent to the client for instantaneous filtering.</p>

<p>The following week I gave a short talk at a UWaterloo CS Club event about simple binary formats and how they can make your project fasterÙ« easier and cooler:</p>

<script async="" class="speakerdeck-embed" data-id="56dcaeddea6f466bb08d8ee28694f952" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>

<p>Now that Iâ€™ve used simple binary formats for both <a href="http://ratewith.science/">Rate With Science</a> and DayderÙ« Iâ€™m a big fan. Although outside a hackathon context where I have time to learn libraries and where I donâ€™t have the incentive to design new formats for funÙ« I think I would probably go with something established like <a href="https://capnproto.org/">Capâ€™n Proto</a> or <a href="https://thrift.apache.org/">Thrift</a> instead of a custom format.</p>
'),('http://thume.ca/2016/03/24/eye-tracker-reviews-pupil-labs-tobii-eyex-eye-tribe-tobii-x2-30/', 'Eye Tracker Reviews: Pupil LabsÙ« TobiiÙ« Eye TribeÙ« XLabs', '1458777600000',  13, '
<p>During my time at the <a href="http://hci.cs.uwaterloo.ca/">UWaterloo HCI Lab</a> Iâ€™ve had the opportunity to try out 5 different eye trackers and compare them.
These eye trackers span the price range from free to $10Ù«000+ and use a variety of different tracking methods. These trackers are also not always direct
alternativesÙ« they are often meant for very different scenarios.</p>

<p>Disclaimer: These are the results that I got for myself using these eye trackers. Eye tracking performance varies wildly between people so it is likely that
for some of these trackers I got atypically bad or good performance. When my results donâ€™t square with claimed performance or performance Iâ€™ve seen in videos
Iâ€™ll try and note that.</p>

<p>AlsoÙ« I have not done exact degrees accuracy tests on any of these trackers. I may however give figures in degreesÙ« hereâ€™s what I mean when I mean by these:
Whenever I test these outÙ« the tracked point or the filtered point (if there is jitter) is with high probability within a given distance of my real gaze point.
I then use trigenometry to work out the degree angle corresponding to that distanceÙ« a handy rule of thumb is that each degree corresponds to about a centimeter of
distance at a typical screen-head distance ( <code class="language-plaintext highlighter-rouge">tan(1.0*(pi/180))*60 = 1.04</code> ).</p>

<p>With that out of the way lets move on to the trackers:</p>

<h1 id="pupil-labs-headset-my-favourite-research-eye-tracker">Pupil Labs Headset: My favourite research eye tracker</h1>

<p>My lab has a <a href="https://pupil-labs.com/store/">Pupil Labs</a> eye tracking headset with a high speed world camera and 120hz binocular eye cameras.
Itâ€™s well suited for a variety of researchÙ« and is the only eye tracker with amazing open source software.</p>

<h4 id="pros">Pros:</h4>
<ul>
  <li>Good tracking: very high precision (i.e low jitter) and fairly high accuracy immediately after calibration (~1.5 degrees)</li>
  <li>Allows free head motion because the eye tracker is fixed to your head.</li>
  <li>Robustly tracks markers in order to map gaze onto surfaces like screens.</li>
  <li>The open source software is amazing. Really good interfaceÙ« easy to useÙ« tons of featuresÙ« and unlike <em>every other eye tracker</em> you can add any features you need yourself.</li>
  <li>You donâ€™t need a computer screen and you can do eye tracking experiments in other environments.</li>
  <li>Good price for a research eye tracker (on the order of $1000)Ù« especially with academic discount.</li>
  <li>Tolerates other IR devices. Since the tracking doesnâ€™t use glints you can use other IR lights like an IR head tracker at the same time. It is the only eye tracker like this.</li>
  <li>Fully cross platform: WindowsÙ« OSX and Linux.</li>
</ul>

<h4 id="cons">Cons:</h4>
<ul>
  <li>The headset can easily be jostled if you move your head too much or crinkle your faceÙ« and when that happens accuracy drops proportional to the change in position.
The technique Iâ€™m researching requires head motion and I typically see accuracy of ~3 degrees after some head movements slightly move the headset.</li>
  <li>Doesnâ€™t fit with other glasses very wellÙ« and if it does fit the reflections make it worthless.</li>
  <li>You have to wear something on your head. It is fine at first but after an hour or two can start to feel quite uncomfortable.</li>
  <li>You have to recalibrate every single time you put it onÙ« unlike some remote eye trackers.</li>
</ul>

<h4 id="watch-out-for">Watch out for:</h4>
<ul>
  <li>Eye cameras canâ€™t adjust to get a good view of eyes very near the center of the faceÙ« I had a participant like this and it still worked but lost tracking at larger gaze angles.</li>
  <li>If your ears move when your face movesÙ« it will move the eye tracker out of calibration almost immediately. I had a participant like this.</li>
</ul>

<h1 id="tobii-eyex--steelseries-sentry-best-consumer-eye-tracker">Tobii EyeX / Steelseries Sentry: Best consumer eye tracker</h1>

<p>The <a href="http://www.tobii.com/xperience/">Tobii EyeX</a> (or the identical Steelseries Sentry) is an incredible consumer eye tracker. One downside is it only works on WindowsÙ« but Iâ€™ve gotten around this by running
the EyeX software in a VMWare Fusion VM and <a href="https://gist.github.com/trishume/b25492f25fc8ebe01dd9">piping the data to my mac over UDP</a>. Two caveats are that in order to switch to the mac and have tracking continue you have to <a href="http://dannyman.toldme.com/2014/05/15/vmware-retina-thunderbolt-constant-resolution/">lock the
VMâ€™s screen resolution</a>. Also if the load gets too high on the VM sometimes the tracker will stop
and take a couple seconds before it automatically restartsÙ« this is only an issue in VMs and can be mostly avoided by running no other programs on the Windows VM.</p>

<h4 id="pros-1">Pros:</h4>
<ul>
  <li>Extremely robust to head motion: your calibration will last practically forever. You can move your head around as much as you want and still maintain decent (2-3 degrees accuracy) tracking.
This means you donâ€™t have to calibrate every time you sit downÙ« just keep your one calibration for an arbitrarily long time. The magnetic mount is extremely repeatable so it doesnâ€™t need to be recalibrated.</li>
  <li>Good accuracy even on large screens: Although the accuracy degrades near cornersÙ« in general the tracker gives me ~2-3 degrees of accuracyÙ« which is quite decent.</li>
  <li>Comes with very nice software. The SDK is nice and the software gives you a nice calibration test screenÙ« a very pretty gaze traceÙ« and some handy eye tracking desktop enhancements like warping your mouse cursor.</li>
</ul>

<h4 id="cons-1">Cons:</h4>
<ul>
  <li>Low precision. There is quite a bit of jitterÙ« but it is bounded (it is almost never more than 2cm from the center of the jitter)Ù« so can be mostly eliminated by filtering.</li>
  <li>Windows only.</li>
  <li>You may not record gaze data. This is a developer SDK term meant to make you buy Tobiiâ€™s more expensive trackersÙ« it is not an issue if youâ€™re developing interaction techniques or just using the tracker.</li>
  <li>Your head needs to be relatively low with respect to the monitor. I prefer my head to be near the top of my monitor but this is outside the non-adjustable view of the tracker from the monitorâ€™s bottom edge.
You can fix this by tilting your monitor upwardsÙ« I was lucky that my monitor had an adjustable stand.</li>
</ul>

<h1 id="edit-tobii-4c-new-best-consumer-eye-tracker">[Edit] Tobii 4C: New best consumer eye tracker</h1>

<p>Iâ€™ve now had a chance to use the <a href="https://tobiigaming.com/eye-tracker-4c/">Tobii 4C</a> for a while and itâ€™s fantastic. Everything I said about the EyeX above appliesÙ« with the following new notes:</p>

<ul>
  <li>All the processing is now done on the deviceÙ« this means very low CPU and USB loads. It now works flawlessly in VMWare Fusion.</li>
  <li>Accuracy is similar or maybe somewhat better. Itâ€™s the most accurate eye tracker Iâ€™ve used personally.</li>
  <li>Tobii is now working on a macOS implementation of the Stream Engine SDK (the low level C API). Iâ€™ve tried out an alpha and it works quite well. I used it to implement <a href="https://github.com/trishume/FusionMouse">FusionMouse</a>.</li>
  <li>I tried it out in combination with a TrackIR 5 and it didnâ€™t interfere with the tracking muchÙ« which let me combine eye tracking and head tracking that is higher accuracy than the tracking Tobii provides on Windows. I remember having problems when I tried the TrackIR with the EyeXÙ« so either they fixed something or my setup changed enough that it works now.</li>
</ul>

<p>The restrictions on recording data still apply thoughÙ« so itâ€™s still difficult to legally use for researchÙ« other than research on interactive eye tracking systems.</p>

<p>Another tip I picked up: The adhesive on the magnetic strips for attaching the 4C/EyeX to a monitor have very strong permanent adhesive thatâ€™s difficult to remove without breaking or bending anything. If you use double-sided foam tape you can attach the strip to a monitor in a way thatâ€™s much easier to remove. The extra distance also enables it to be mounted on some laptops.</p>

<h1 id="the-eye-tribe-tracker-good-but-doesnt-work-well-for-me">The Eye Tribe Tracker: Good but doesnâ€™t work well for me</h1>

<p>The <a href="http://theeyetribe.com/">Eye Tribe tracker</a> (I have the older $100 model) is a great piece of hardware at a great priceÙ« unfortunately it barely works for me.
Iâ€™ve seen it work well for other people in videos so Iâ€™m not claiming this is a common problemÙ« just one that I invariably experience. Iâ€™ve tried it in tons of environments
with different computersÙ« positions and eyewear. After <a href="http://thume.ca/2016/02/02/a-reverse-engineering-adventure-eye-tribes-usb-protocol/">reverse engineering</a> it I think I have identified
the problem as due to extra glints on the side of my eyes when looking away from the center of my screen. I can calibrate in the center and get ~4 degrees of accuracy within a 1000 x 1000px areaÙ« but that isnâ€™t great.</p>

<p>As suchÙ« Iâ€™ve restricted my Pros and cons to discussing other issues than accuracy:</p>

<h4 id="pros-2">Pros:</h4>
<ul>
  <li>Great priceÙ« only $100.</li>
  <li>Works on OSX. This is better than the Tobii EyeX so if youâ€™re looking for a consumer tracker on OSX try the Eye Tribe.</li>
  <li>A great high speed high resolution infrared camera: I <a href="http://thume.ca/2016/02/02/a-reverse-engineering-adventure-eye-tribes-usb-protocol/">reverse engineered</a> the control codes so you can use it for other purposes like motion tracking or writing your own eye tracking algorithms. This canâ€™t be done easily with the EyeX since it uses a much more locked down custom USB protocol.</li>
</ul>

<h4 id="cons-2">Cons:</h4>
<ul>
  <li>Tripod mount means that if you bump itÙ« pull the cableÙ« or bump your monitorÙ« youâ€™ll have to recalibrate. This is in contrast to the sentryÙ« which mounts directly to your monitor.
If youâ€™re ambitious you could improve your own clamping mount for the eye tribe tracker or fix the tripod and monitor in place.</li>
  <li>Limited software: The software does very little compared to Tobiiâ€™s and Pupilâ€™s software. It is basically just a calibration and API server.</li>
</ul>

<h1 id="tobii-x2-30-great-but-overpriced">Tobii X2-30: Great but overpriced</h1>

<p>My lab has a <a href="http://www.tobiipro.com/product-listing/tobii-pro-x2-30/">Tobii Pro X2-30</a> which in many ways is similar to the Tobii EyeX. The main hardware difference is that it uses two cameras instead of oneÙ« but I assume they are
lower resolution since it only needs USB 2.0 bandwidths instead of USB 3.0. The main legal difference is that you are allowed to record the gaze data with the pro models. The main practical difference is that the X2-30 costs over <strong>50 TIMES</strong> as much. The price is not public and I imagine they quote different prices to different people. Iâ€™m not sure if my lab signed any agreements with regards to giving away the price so Iâ€™ll just say we paid somewhere over 50x the price of an EyeX.</p>

<p>The pros/cons and tracking performance are very similar to the Tobii EyeX. Unless you are doing a study where you need to record gaze dataÙ« the 50x increase in price is not worth it in my opinion.</p>

<h4 id="pros-3">Pros:</h4>
<ul>
  <li>Extremely robust to head motion: your calibration will last practically forever. You can move your head around as much as you want and still maintain decent (2-3 degrees accuracy) tracking.
This means you donâ€™t have to calibrate every time you sit downÙ« just keep your one calibration for an arbitrarily long time. The magnetic mount is extremely repeatable so it doesnâ€™t need to be recalibrated.</li>
  <li>Good accuracy: Although the accuracy degrades near cornersÙ« in general the tracker gives ~2.0 degrees of accuracy when not using a chin restÙ« which is quite good and slightly better than the EyeX.</li>
  <li>Comes with very nice software. The SDK is nice and the software gives you a nice calibration test screenÙ« a very pretty gaze traceÙ« and some handy eye tracking desktop enhancements like warping your mouse cursor.</li>
  <li>The new Analytics SDK 3.0 allows use with OSX and Linux.</li>
</ul>

<h4 id="cons-3">Cons:</h4>
<ul>
  <li>The nice EyeX software it works with is Windows-only.</li>
  <li>Only specified to work on relatively small monitors by modern standards (22â€ diagonal).</li>
  <li>I found that sometimes the tracked gaze would jump for half a second or so to a wildly inaccurate position ~15cm away from where I was looking. This is bad because it is harder to filter out and distinguish from a saccade.</li>
  <li>Crazy expensive. This is not unique to Tobii. Basically every eye tracker intended for research (except the Pupil) is absurdly overpriced. Many research eye trackers cost in the range of $50Ù«000.</li>
  <li>Your head needs to be relatively low with respect to the monitor. I prefer my head to be near the top of my monitor but this is outside the non-adjustable view of the tracker from the monitorâ€™s bottom edge.
You can fix this by tilting your monitor upwardsÙ« I was lucky that my monitor had an adjustable stand.</li>
</ul>

<h1 id="xlabs-gaze-chrome-plugin-best-webcam-only-eye-tracker">XLabs Gaze Chrome Plugin: Best webcam only eye tracker</h1>

<p>The <a href="https://xlabsgaze.com/">XLabs</a> chrome plugin allows you to do eye tracking on a web page using only a webcam and no special hardware.
Iâ€™ve only ever had good results when trying out their <a href="https://eyesdecide.com/">EyesDecide</a> softwareÙ« although I was also in a different environment when I tried it that way.</p>

<h4 id="pros-4">Pros:</h4>
<ul>
  <li>Basically your only option for eye tracking without special hardware. Allows you to do things like web usability eye tracking studies with only a laptop.</li>
  <li>Free! The SDK is currently free to useÙ« although that may changeÙ« and you donâ€™t have to buy hardware.</li>
  <li>Rather decent tracking. Quite impressive for a webcam trackerÙ« can achive 2-4 degree accuracies varying extensively by personÙ« environment and calibration.</li>
  <li>Fully cross platformÙ« because it is just a Chrome plugin.</li>
</ul>

<h4 id="cons-4">Cons:</h4>
<ul>
  <li>Very long calibration process: If you want good results you need to go through a very long sequence of calibration dotsÙ« on the order of 30.</li>
  <li>Very short lived calibration. It is not as robust to head motion as other trackers and becomes miscalibrated within a few minutes unless you are constantly calibrating with their dynamic calibration.</li>
  <li>Very sensitive to lighting. You need bright light on your faceÙ« sitting near a window is best. If the lighting isnâ€™t right it can sometimes barely work at all.</li>
  <li>You can only use it within Chrome. No desktop apps.</li>
</ul>

<h1 id="others">Others</h1>

<p>There are tons of crazy expensive research eye tracking systems that I havenâ€™t tried for exactly that reason: they cost way too much. Iâ€™m sure some of them are quite excellentÙ« but they cost as much of a car for hardware that certainly
isnâ€™t 1/10th that expensive to manufacture.</p>

<p>Thereâ€™s two other sub-$1000 eye trackers I have not tried but I have read a bit about:</p>

<h4 id="gazepoint-gp3">Gazepoint GP3</h4>

<p>The <a href="http://www.gazept.com/product/gazepoint-gp3-eye-tracker/">Gazepoint GP3</a> is $500 and internally uses a <a href="https://www.ptgrey.com/case-study/id/10423">Point Grey camera</a> which probably has a 752x480 resolutionÙ« which is much lower than the Eye Tribe tracker.
The only advantage it might have over the Eye Tribe is that it uses bright pupil tracking (so perhaps more robust) and their software might be betterÙ« but likely is not. Gazepointâ€™s software is also Windows only.
I see no reason to consider this tracker over the cheaper and seemingly much better Tobii EyeX.</p>

<h4 id="mygaze">MyGaze</h4>

<p>The <a href="http://www.mygaze.com/">MyGaze</a> seems to be the deluxe consumer eye tracker. I havenâ€™t bought it since it is outside my â€œjust trying it outâ€ budget when I already personally own 2 consumer eye trackers.
HoweverÙ« there seems to be some glowing recommendations online from people who have tried other consumer eye trakers calling it the best of everything low cost. It is also made by engineers from SMI which is a
super fancy expensive high quality research eye tracker company. Thereâ€™s some recommendations and a video (that shows incredible &lt;1 degree accuracy) <a href="http://www.apparelyzed.com/forums/topic/37302-questions-about-smis-500-mygaze-vs-200-eye-tribe-tracker-pro/">on this forum thread</a>. If you have the budget for it I recommend you try this tracker out (and then let me know how you like it).</p>

<p>One downside is that although the hardware only costs $500Ù« you have to pay $900 to also get the developer SDKÙ« unlike every other consumer eye tracker which gives away the SDK for free with the tracker.</p>

<h4 id="the-eye-tribe-pro">The Eye Tribe Pro</h4>

<p>The Eye Tribe is soon going to release a new tracker with new algorithms and supposedly better tracking on many dimensions for $200. I have no idea how good it will be or how it will compare to other low cost eye trackers.</p>
'),('http://thume.ca/2016/02/02/a-reverse-engineering-adventure-eye-tribes-usb-protocol/', 'A Reverse Engineering Adventure: Eye Tribe"s USB Protocol', '1454371200000',  13, '
<p><strong>Update:</strong> See bottom of the article for recent progress. Iâ€™ve managed to get a full 10-bit high def video feed and have released example code.</p>

<p>In 2014 I bought an <a href="http://theeyetribe.com/">Eye Tribe eye tracker</a> hoping to work on some neat eye tracking projects.
Unfortunately Iâ€™ve never been able to reach the fingertip level accuracy they claim and that I have seen in videos.
I always get around +/- 5cm (2 inches) or more of jitter. Recently Iâ€™ve been working on eye tracking research again
and I thought I would take a crack at debugging my accuracy issues.</p>

<p>Thereâ€™s just one problem: The Eye Tribeâ€™s tracking software is closed source and doesnâ€™t have a debug view or a raw camera
feed API. Iâ€™ve been wanting to try my hand at reverse engineering lately so I set myself the goal of reverse engineering
the trackerâ€™s USB protocol so that I could turn the trackerâ€™s IR lights on and capture the IR video feed.</p>

<p>The Eye Tribe tracker is really just a USB 3.0 <a href="https://en.wikipedia.org/wiki/USB_video_device_class">UVC</a> camera (the standard webcam protocol) that shoots
in monochrome IR. It also has bright IR LEDs that light up the userâ€™s face since there isnâ€™t much ambient IR indoors.
Capturing the video is easyÙ« the hard part is that the LEDs are controlled through a proprietary extension to the USB video camera protocol.</p>

<p>Thus I started on my quest to discover the special commands that would turn on those LEDs. In the end I figured out some cool techniquesÙ«
and helped diagnose out my issue (havenâ€™t solved it yet though). What could be useful to others is that the Eye Tribe is effectively
a low cost (<a href="https://www.ptgrey.com/">alternatives</a> are &gt;$500)Ù« high resolutionÙ« high frame rate IR camera with built in illuminators.
This could be used for all sorts of computer vision projects like a cheap <a href="http://www.vicon.com/">Vicon</a> style motion capture system or an
open source eye tracker.</p>

<h2 id="exploration">Exploration</h2>

<p>I started by <a href="http://superuser.com/questions/781982/how-can-i-install-usb-prober-from-the-developer-sdk-on-mac-os-x">installing USB Prober</a>Ù« a dev tool that lets you inspect the metadata of devices connected by USB. You can get practically the same
information in the USB section of the built in â€œSystem Informationâ€ app but I installed USB Prober in case it gave more info.</p>

<p>I started looking through the <a href="https://github.com/trishume/EyeTribeReversing/blob/master/USBProber.txt">USB info dump for the Eye Tribe tracker</a> and
discovered some good clues. First of all that it was a UVC cameraÙ« and that it was only a UVC cameraÙ« no other fancy USB control endpoints.
I also noticed that there was a <code class="language-plaintext highlighter-rouge">VDC (Control) Extension Unit</code> interface: this was probably where the custom lights control messages could be sent.</p>

<p>I also figured out some other interesting things like the camera module being manufactured by <a href="https://www.leopardimaging.com/">Leopard Imaging</a>
and that it could capture high resolution 2304x1536 video at 27fps (thatâ€™s more than 1080p) and 768x1024 at 60fps. There are also a bunch of intermediate
resolutions it can do at intermediate frame rates.</p>

<h2 id="attempting-to-log">Attempting to Log</h2>

<p>My next step was to try and log the USB traffic between the tracker and the eye tracking data server program The Eye Tribe provides.
UnfortunatelyÙ« Apple hasnâ€™t updated the kernel extensions for USB logging for the latest OSs. Last time I tried installing them I nearly
bricked my laptop because it couldnâ€™t read any USB HID inputÙ« including the internal USB hub for the laptopâ€™s keyboard and trackpad.
I only rescued it by copying the Kext files from the recovery partition onto my main driveÙ« I started backing up my entire disk instead of just
my important files after that incident.</p>

<p>So instead I took the advice in <a href="http://lists.apple.com/archives/usb/2015/Jan/msg00004.html">this mail thread</a> and tried <code class="language-plaintext highlighter-rouge">usbtrace</code> and <code class="language-plaintext highlighter-rouge">dtrace</code>
instead. Unfortunately <code class="language-plaintext highlighter-rouge">usbtrace</code> showed megabytes per minute of all my systemâ€™s USB traffic in a not very useful format.
<code class="language-plaintext highlighter-rouge">dtrace</code> showed me that control messages were being sent by the tracking serverÙ« and from what call stackÙ« but not which messages and what they contained.</p>

<h2 id="disassembly">Disassembly</h2>

<p>After logging failedÙ« I tried a different approach. I downloaded the trial of <a href="http://www.hopperapp.com/">Hopper 3</a> and loaded up the Eye Tribe server executable.
Most of the method names were just numbered symbols but I managed to find an Objective C method called <code class="language-plaintext highlighter-rouge">setUvcControl:withValue:</code> that belonged to a class called
<code class="language-plaintext highlighter-rouge">UVCCameraControl</code>. I tried tracing the callers to see if I could find any obvious light control codeÙ« but with no function symbol namesÙ« no source codeÙ« and
only vaguely knowing x86_64 assemblyÙ« I wasnâ€™t able to do it.</p>

<p>Instead I used <a href="http://stevenygard.com/projects/class-dump/">class-dump</a> on the server executable to look at the other methods. I Googled some of the method names
and found <a href="http://phoboslab.org/log/2009/07/uvc-camera-control-for-mac-os-x">it was open source</a> (code on <a href="https://github.com/HBehrens/CamHolderApp/blob/master/CamHolderApp%2FUVCCameraControl.m">Github here</a>). Now I had the source code for the mechanism used to send the messagesÙ« but I didnâ€™t know what they were called with.</p>

<p>I read through the source of that class and started looking at the <a href="http://www.cajunbot.com/wiki/images/8/85/USB_Video_Class_1.1.pdf">UVC protocol spec</a> to make sense of what I found.
I learned that auxiliary parameters of a camera are controlled and inspected by UVC control requests like <code class="language-plaintext highlighter-rouge">SET_CUR</code> and <code class="language-plaintext highlighter-rouge">GET_CUR</code> on different interfaces and with different control selectors.
I figured out through reading the source code that the bit fields described in the protocol corresponded with the fields of OSXâ€™s <a href="https://developer.apple.com/library/mac/documentation/Kernel/Reference/USB_kernel_header_reference/index.html#//apple_ref/c/tdef/IOUSBDevRequest">IOUSBDevRequest</a>.</p>

<h2 id="debugging">Debugging</h2>

<p>I started on a new approach to try and log the control requests sent by the server through intercepting the method calls made by it.
If I could print out the contents of the <code class="language-plaintext highlighter-rouge">IOUSBDevRequest</code> structs being sentÙ« I could probably figure out which ones turned on the lights. So I fired up <a href="http://lldb.llvm.org/">LLDB</a>
and set a breakpoint at the hex address of <a href="https://github.com/HBehrens/CamHolderApp/blob/master/CamHolderApp%2FUVCCameraControl.m#L255">sendControlRequest:</a> from the disassembly.</p>

<p>I started the server with the tracker connected and LLDB hit the breakpointÙ« but since there were no debug symbolsÙ« all I could look at was registers and assembly.
I had no idea what the calling conventions were for Objective-C code and looking them up and peeking at some memory didnâ€™t seem to find the right things.
So I kept stepping and reached down into <code class="language-plaintext highlighter-rouge">IOUSBInterfaceClass::interfaceControlRequest(void*Ù« unsigned charÙ« IOUSBDevRequest*)</code> which although it didnâ€™t have debug infoÙ«
at least had an unobfustucated function name. I Googled this and found that Apple <a href="http://www.opensource.apple.com/source/IOUSBFamily/IOUSBFamily-203.4.7/IOUSBLib/Classes/IOUSBInterfaceClass.cpp">published the source code</a>!</p>

<p>The registers and assembly werenâ€™t helping me very much until after an hour or two I figured out how to find where the struct I wanted was located.
The source code for <code class="language-plaintext highlighter-rouge">IOUSBInterfaceClass::interfaceControlRequest(void*Ù« unsigned charÙ« IOUSBDevRequest*)</code> showed it copying a <code class="language-plaintext highlighter-rouge">IOUSBDevRequest</code> into an <code class="language-plaintext highlighter-rouge">IOUSBDevRequestTO</code> and not much else.
So I looked at the dissassembly for that method in the debugger and saw a bunch of mov instructions copying the fields of the struct. They all looked something like:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0x100ae2fb0 &lt;+14&gt;: movb   %alÙ« -0x28(%rbp)
0x100ae2fb3 &lt;+17&gt;: movb   0x1(%rbx)Ù« %al
</code></pre></div></div>

<p>Aha! At that point the struct I want must be pointed to by register <code class="language-plaintext highlighter-rouge">%rbp</code>. I stepped to that pointÙ« and after a figuring out the right casting and pointer indirection I printed out the second byte:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(lldb) e (int)((char*)$rbx)[1]
(int) $22 = 129
</code></pre></div></div>

<p>The second byte of the struct I wanted should be the <code class="language-plaintext highlighter-rouge">UInt8 bRequest</code> field which should correspond to one of the <a href="https://github.com/HBehrens/CamHolderApp/blob/master/CamHolderApp%2FUVCCameraControl.h#L16">constants in the UVCCameraControl</a>. Sure enough after using <code class="language-plaintext highlighter-rouge">irb</code> to convert <code class="language-plaintext highlighter-rouge">129</code> to hex I got <code class="language-plaintext highlighter-rouge">0x81</code> which is the request code for <code class="language-plaintext highlighter-rouge">UVC_GET_CUR</code>Ù« I had found it!</p>

<h2 id="logging-for-real-this-time">Logging (for real this time)</h2>

<p>Now I needed to figure out how to print out the other fields and the data pointed to by the <code class="language-plaintext highlighter-rouge">void *pData</code> field. All fast enough so that the tracking server wouldnâ€™t get messed up.
My strategy for this was to try and script LLDB to break at the exact right instructionÙ« print out all of the fieldsÙ« and then continue automatically.</p>

<p>I read about LLDBâ€™s Python scripting capabilitiesÙ« but the Python interface was poorly documented and could only really do anything with debug infoÙ« which I didnâ€™t have.</p>

<p>So instead I figured out all the right casting invocations to print out the fields of the structÙ« which took a while.
Then I figured out the exact offset from the start of the dynamic library I wanted to break at (the absolute address changed every time I started up the tracking server)Ù« set a breakpoint there
and added a breakpoint command which printed the fields and then continued:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>breakpoint set -a &lt;address of IOUSBLib I found&gt;+0x7fae
breakpoint command add 1
e ((uint64_t*)$rbx)[0]
e ((uint64_t*)$rbx)[1]
p *(uint32_t(*)[15])(((uint32_t**)$rbx)[1])
e ((uint32_t*)$rbx)[4]
c
DONE
</code></pre></div></div>

<p>Then I ran the codeÙ« connected the eye trackerÙ« started the tracking UI (which turns on the lights)Ù« waited a bitÙ« and shut down the tracking UI (turning off the lights).
It output a bunch of data which I copy pasted into some <a href="https://github.com/trishume/EyeTribeReversing/blob/master/log2.txt">text</a> <a href="https://github.com/trishume/EyeTribeReversing/blob/master/log3.txt">files</a>.</p>

<h2 id="analysis">Analysis</h2>

<p>Now I had a log of the control requestsÙ« but as a couple 64 bit decimal integers in a copy-pasted LLDB log. So I had to write a script to parse out the various fields of the <code class="language-plaintext highlighter-rouge">IOUSBDevRequest</code> struct.
I did this in RubyÙ« eventually producing <a href="https://github.com/trishume/EyeTribeReversing/blob/master/parsedump.rb">this script</a>.</p>

<p>First I had to parse the formatÙ« then I used bitwise operators to extract the various fields of the struct out of the integers and into fields of a Ruby hash.
Now I had the raw data from the structÙ« but all the fields were still opaque numbers: next I had to interpret them.</p>

<p>I started by going back to the <a href="http://www.cajunbot.com/wiki/images/8/85/USB_Video_Class_1.1.pdf">UVC protocol spec</a> and copy-pasted some of the name tables in the appendix into hash literals in my script. I tried using these to map the numbers to namesÙ« but ended up with weird results. Then came a couple hours of fiddlingÙ« confusion and readingÙ« as well as looking at <a href="https://github.com/HBehrens/CamHolderApp/blob/master/CamHolderApp%2FUVCCameraControl.m#L286">how the records were constructed</a> and correlating that with the spec. After the 5th try at mapping I figured out which fields came from where: I had to use the <code class="language-plaintext highlighter-rouge">Terminal ID</code> from USB Prober to decide which table to look up the control selector (high byte of the <code class="language-plaintext highlighter-rouge">wValue</code> field) in based on the <code class="language-plaintext highlighter-rouge">unitID</code> field (high byte of <code class="language-plaintext highlighter-rouge">wIndex</code>).</p>

<p>Finally I got results that made sense: before the lights turned on the server sent a couple <code class="language-plaintext highlighter-rouge">UVC_SET_CUR</code> requests to the extension unit. It looked like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{:bmRequestType=&gt;33Ù« :bRequest=&gt;1Ù« :wValue=&gt;768Ù« :wIndex=&gt;768Ù« :wLength=&gt;2Ù« :selector=&gt;3Ù« :unitId=&gt;3Ù« :req=&gt;"UVC_SET_CUR"Ù« :unit=&gt;"VC_EXTENSION_UNIT"}
[15Ù« 0]
{:bmRequestType=&gt;33Ù« :bRequest=&gt;1Ù« :wValue=&gt;1024Ù« :wIndex=&gt;512Ù« :wLength=&gt;2Ù« :selector=&gt;4Ù« :unitId=&gt;2Ù« :req=&gt;"UVC_SET_CUR"Ù« :unit=&gt;"VC_PROCESSING_UNIT"Ù« :msg=&gt;"PU_GAIN_CONTROL"}
[63Ù« 0]
{:bmRequestType=&gt;33Ù« :bRequest=&gt;1Ù« :wValue=&gt;1024Ù« :wIndex=&gt;768Ù« :wLength=&gt;8Ù« :selector=&gt;4Ù« :unitId=&gt;3Ù« :req=&gt;"UVC_SET_CUR"Ù« :unit=&gt;"VC_EXTENSION_UNIT"}
[250Ù« 0Ù« 240Ù« 0Ù« 250Ù« 0Ù« 240Ù« 0]
{:bmRequestType=&gt;33Ù« :bRequest=&gt;1Ù« :wValue=&gt;1536Ù« :wIndex=&gt;768Ù« :wLength=&gt;2Ù« :selector=&gt;6Ù« :unitId=&gt;3Ù« :req=&gt;"UVC_SET_CUR"Ù« :unit=&gt;"VC_EXTENSION_UNIT"}
[44Ù« 1]
{:bmRequestType=&gt;33Ù« :bRequest=&gt;1Ù« :wValue=&gt;512Ù« :wIndex=&gt;768Ù« :wLength=&gt;4Ù« :selector=&gt;2Ù« :unitId=&gt;3Ù« :req=&gt;"UVC_SET_CUR"Ù« :unit=&gt;"VC_EXTENSION_UNIT"}
[0Ù« 0Ù« 0Ù« 0]
{:bmRequestType=&gt;33Ù« :bRequest=&gt;1Ù« :wValue=&gt;1024Ù« :wIndex=&gt;512Ù« :wLength=&gt;2Ù« :selector=&gt;4Ù« :unitId=&gt;2Ù« :req=&gt;"UVC_SET_CUR"Ù« :unit=&gt;"VC_PROCESSING_UNIT"Ù« :msg=&gt;"PU_GAIN_CONTROL"}
[51Ù« 0]
... more of the same message with small adjustments to the gain around level 51 ...
{:bmRequestType=&gt;33Ù« :bRequest=&gt;1Ù« :wValue=&gt;1024Ù« :wIndex=&gt;512Ù« :wLength=&gt;2Ù« :selector=&gt;4Ù« :unitId=&gt;2Ù« :req=&gt;"UVC_SET_CUR"Ù« :unit=&gt;"VC_PROCESSING_UNIT"Ù« :msg=&gt;"PU_GAIN_CONTROL"}
[51Ù« 0]
{:bmRequestType=&gt;33Ù« :bRequest=&gt;1Ù« :wValue=&gt;768Ù« :wIndex=&gt;768Ù« :wLength=&gt;2Ù« :selector=&gt;3Ù« :unitId=&gt;3Ù« :req=&gt;"UVC_SET_CUR"Ù« :unit=&gt;"VC_EXTENSION_UNIT"}
[0Ù« 0]
{:bmRequestType=&gt;33Ù« :bRequest=&gt;1Ù« :wValue=&gt;1024Ù« :wIndex=&gt;512Ù« :wLength=&gt;2Ù« :selector=&gt;4Ù« :unitId=&gt;2Ù« :req=&gt;"UVC_SET_CUR"Ù« :unit=&gt;"VC_PROCESSING_UNIT"Ù« :msg=&gt;"PU_GAIN_CONTROL"}
</code></pre></div></div>

<p>So it looks like there are a couple requests sent to the extension unitÙ« but only selector <code class="language-plaintext highlighter-rouge">3</code> is sent with a positive value when the lights are turned on and later a zero when the lights are turned off.</p>

<h2 id="capture">Capture</h2>

<p>Now I just had to test my theory by writing an app that sent the right UVC control requests. I used <a href="http://openframeworks.cc/">OpenFrameworks</a> since it comes with a camera capture example that uses
QtKit (which is deprecated but allegedly <code class="language-plaintext highlighter-rouge">UVCCameraControl</code> doesnâ€™t work with <code class="language-plaintext highlighter-rouge">AVFoundation</code>). I linked in the <a href="https://github.com/atduskgreg/ofxUVC">ofxUVC</a> addon but ended up just calling the Obj-C
class directly. I started by fiddling with the gain setting and managed to even see myself a little bit without the IR illuminators turned on.</p>

<p>Then I tried sending selector <code class="language-plaintext highlighter-rouge">3</code> with a value of <code class="language-plaintext highlighter-rouge">15</code> to turn the lights onÙ« and <strong>it worked first try</strong>! The lights didnâ€™t turn off when I shut down my test appÙ« but that was an easy fix of adding another control message setting it to <code class="language-plaintext highlighter-rouge">0</code>.</p>

<h2 id="victory">Victory!</h2>

<p><img src="https://camo.githubusercontent.com/3927cebd93eaf9e4c75858a4fad0b10d38cb6ad2/687474703a2f2f692e696d6775722e636f6d2f6733495855646f2e6a7067" alt="Captured frame" /></p>

<p>That picture is captured with a gain level of around <code class="language-plaintext highlighter-rouge">0</code> but I noticed in the logs that the tracking server was setting the gain level around <code class="language-plaintext highlighter-rouge">51</code>. But when I adjusted the gain that highÙ«
the 8 bit green values used to hold the image started wrapping around leading to a messed up image. This might be the cause of the tracking quality issues Iâ€™ve been havingÙ« but the real server
might do something to mitigate this. <strong>Edit:</strong> Iâ€™ve since discovered that lowering the exposure to compensate negates this issueÙ« so I assume the real server uses a higher frame rate and lower exposure so they need the high gain setting. Another neat thing about the exposure is if you set it really long it can effectively take still pictures without the LEDs on.</p>

<p>Next I used the feature of the demo app to save a video to my driveÙ« which interestingly started replacing some frames with pure greenÙ« which didnâ€™t happen at all in the live preview.
I later discovered that the 1 minute movie it saved was <em>10 gigabytes</em> because it wasnâ€™t using any compression. It is possible the dropped frames were my SSD bottlenecking the video capture.
Anyhow I compressed it down with Handbrake and uploaded it to YoutubeÙ« sorry for the annoying green frames.</p>

<p>In the video below you can see me looking at the four corners of my screenÙ« and then some things on the screen. I then slowly adjust the gain setting upwards until it reaches <code class="language-plaintext highlighter-rouge">51</code> at which
point I wave my arms around to mark the time. Then I continue adjusting the gain up to maximum.</p>

<iframe width="660" height="495" src="https://www.youtube.com/embed/8CguH2EJqUo" frameborder="0" allowfullscreen=""></iframe>

<h2 id="update">Update</h2>

<p>After I first published this post I emailed The Eye Tribe with my info and storyÙ« and I got some help and info from them.
It turns out that the eye tracker isnâ€™t working in as large of an area as it should (not sure why) so I can only use a 12â€ diagonal area of my screen instead of the full 24â€.
If I use the small area I get much better accuracyÙ« closer to +/- 1cm of jitter and a 0-4cm offset from my true gaze location. This is still not as good accuracy as advertized
and it works on a much smaller area than advertizedÙ« but it is better than before. It is still entirely useless to me thoughÙ« the accuracy is good enough for my projectÙ« but the area is too small.
Note that I have seen videos of other people achieving the claimed accuracyÙ« it is likely that there is still some special complicating factor with my unit or setupÙ« most customers probably have no issues.</p>

<p>This is post is also not ment to bash The Eye Tribe. Theyâ€™re my second favourite eye tracking company after <a href="https://pupil-labs.com/pupil/">Pupil Labs</a>. Despite their closed source software they are
still significantly more open than most other eye tracking companies with orders of magnitude lower cost.</p>

<h2 id="update-2">Update 2</h2>

<p>Iâ€™ve now figured out how to properly retrieve high resolution 60fps video at the full 10 bit depth.
The tracker has a variety of resolutions availableÙ« higher resolutions only work with lower frame rates.
The highest resolution is 2304x1536 which is available at 27FPS. Some of the resolutions offered are scaled down versions of the full imageÙ« whereas others are cropped areas of it.
In order to get the full 60FPS you have to lower the exposure timeÙ« which significantly increases the noiseness of the image.</p>

<p>The pixels are encoded in YUY2 format where the lowest 8 bits of brightness are in the Y component and the highest 2 are in the UV component.</p>

<p>Iâ€™ve created a <a href="https://github.com/trishume/SmartGaze">project on Github called SmartGaze</a> where Iâ€™ve done a little bit of work on implementing eye tracking algorithms for the Eye Tribe.
So far Iâ€™ve retrieved the raw feed using <a href="https://github.com/ktossell/libuvc">libuvc</a>Ù« found the eye regions using glintsÙ« and then used an implementation of the <a href="http://thirtysixthspan.com/openEyes/software.html">Starburst algorithm</a>
to locate the iris ellipse. The repo is released under the GPLv2 but <a href="https://github.com/trishume/SmartGaze/tree/d8cc7a767f6a451d69905a9d67a95e16d14f401a">an earlier commit</a> containing just the code to read the raw 10 bit feed is released under the MIT license. I may or may not decide to finish this given that I recently got a <a href="https://steelseries.com/gaming-controllers/sentry-gaming-eye-tracker">Steelseries Sentry</a> that works well for me when I run it in a Windows VM and <a href="https://gist.github.com/trishume/b25492f25fc8ebe01dd9">pipe the data over UDP</a> to my mac.</p>

<p>Hereâ€™s a video of the raw feed. The fact that you can hardly see the pupils in this video is a product of how I reduced the 10 bit image down to 8 bitsÙ« as well as not setting the PU_GAIN UVC control.
More recent commits of SmartGaze use a much brighter videoÙ« but one that washes out details of the face.</p>

<iframe width="660" height="495" src="https://www.youtube.com/embed/nfCrLg9DnGc" frameborder="0" allowfullscreen=""></iframe>
'),('http://thume.ca/2015/11/19/amazing-profs-of-waterloo-2015/', 'Amazing Profs of Waterloo 2015', '1447891200000',  13, '
<p>During my three terms at The University of Waterloo so far every single professor Iâ€™ve had has been quite good. Some howeverÙ« are amazing. Each of these amazing profs is amazing in very different ways. Some are great lecturersÙ« some great teachers and some great people.</p>

<p>In this post Iâ€™ll highlight some of the great professors Iâ€™ve had so far and what makes them amazing.</p>

<h2 id="prabhakar-ragde-cs-146---the-educator">Prabhakar Ragde (CS 146) - The Educator</h2>

<p>Prabhakar is the most dedicated <em>teacher</em> I have ever had. He spends an incredible amount of time and effort refining his lecture material and designing his courses to be the best they can be. He goes above and beyond to make sure that students learn in the best way possible. He had some trouble finding a good way to teach self-balancing binary treesÙ« so he went and did original research and formulated a purely functional self-balancing binary tree data structure thatâ€™s main advantage is to being easier to learn. It seems to almost physically pain him to see something not taught well. Every teacher should aspire to be as good at teaching as Prabhakar is.</p>

<h3 id="protip">Protipâ„¢</h3>

<p>He teaches the advanced CS courses in first yearÙ« but he teaches them so well that for many people they are easier than the normal courses. The material is indeed more advancedÙ« but the assignments are less work and the tests have bonus marks so it is easier to get high marks. I highly recommend taking CS 145 and 146.</p>

<p>He is also addicted to TwitterÙ« follow him if you want to know about all the fancy food he eats.</p>

<h2 id="jan-kycia-mns-101---the-renaissance-man">Jan Kycia (MNS 101) - The Renaissance Man</h2>

<p>Janâ€™s lectures are goodÙ« heâ€™s an effective speaker and does very neat physics demos in class. What is really incredible about him is his breadth and depth of knowledge. Never in my life have I met anybody so knowledgeable in so many different fields. Heâ€™s a physicist by trainingÙ« but also knows a ton about electronicsÙ« engineeringÙ« machiningÙ« measurementÙ« plumbingÙ« materials and really cold things. He leads a <a href="http://science.uwaterloo.ca/~jkycia/">low temperature lab</a> (he says â€œmillikelvinâ€ a lot) where he uses all these skills to build some highly impressive things. Have I mentioned heâ€™s also really nice and friendly?</p>

<p>I would say that â€œAny sufficiently advanced technologist is indistinguishable from a wizardâ€ except that Jan will gladly show you all of his tricks if you ask. I have an incredible amount of respect for Jan and look up to him as a model of a truly formidable human being.</p>

<h3 id="protip-1">Protipâ„¢</h3>

<p>After every class for around 40 minutes he answers student questionsÙ« goes on interesting tangentsÙ« and sometimes gives lab tours and descriptions of his research. It is very much worth your time to stick around for theseÙ« I have never once regretted staying after class to learn new and interesting things from himÙ« even if they arenâ€™t part of the course. Especially follow him whenever he brings students down to the lab to pick up assignmentsÙ« that place is a technological wonderland and he gives amazing tours and research overviews if you ask.</p>

<p>AlsoÙ« MNS 101 (an introduction to material science) is a great course to take. It is very interesting and is a science that most people havenâ€™t had any exposure to in high school.</p>

<h3 id="things-i-have-seen-in-his-lab">Things I have seen in his lab</h3>

<ul>
  <li>Custom-designed electronic measurement equipment.</li>
  <li>High-precision custom-machined heat pumps.</li>
  <li>Custom-made vibration isolating vacuum pipe flextures.</li>
  <li>Superconducting silicon wafer integrated circuits custom-fabricated in house.</li>
  <li>Decades-old equipment that he has scavenged for pennies on the dollar and then painstakingly fixed up to working condition.</li>
</ul>

<h3 id="examples-of-things-he-has-talked-about-after-class">Examples of things he has talked about after class</h3>

<ul>
  <li>The little-known secrets to creating incredibly pure samples of a material using a plasma arc melterÙ« electrical discharge machiningÙ« acid bathsÙ« and many other steps.</li>
  <li>How to procure an x-ray crystallography set-up on the cheap by buying used DNA flourescence scanners from hospitals.</li>
  <li>The different types of superconducting and non-superconducting wire to use at temperatures approaching 0 kelvin.</li>
  <li>The design factors to take into account when reducing vibrational heating through pipe flextures that must handle vacuum forces.</li>
  <li>How to create strong non-heat-conductive supports by cutting up carbon fiber hunting arrows.</li>
</ul>

<h2 id="eric-helleiner-psci-150---the-lecturer">Eric Helleiner (PSCI 150) - The Lecturer</h2>

<p>Helleinerâ€™s lectures just make you want to listen. Heâ€™s enthusiastic about what he teaches in a very friendly way. I just really like listening to him talk about interesting political science things. Heâ€™s also knowledgeable and teaches interesting PSCI classesÙ« but the reason heâ€™s on this list is that his lectures are just really enjoyable.</p>

<h3 id="protip-2">Protipâ„¢</h3>

<p>Go to his office hours some timeÙ« maybe bring a friendÙ« and just talk to him about interesting politics things. I skipped class to do this once and me and my friend chatted with him for over an hour.</p>
'),('http://thume.ca/2015/03/30/wikipedia-link-graphs-and-terrible-hacks/', 'Wikipedia Link Graphs and Terrible Hacks', '1427673600000',  13, '
<p>A couple months ago <a href="http://davepagurek.com/">Dave Pagurek</a> and I decided on making an <a href="http://ratewithscience.thume.net">arbitrary scale finder</a> for the upcoming UWaterloo <a href="http://terriblehack.website">â€œstupid shit no one needsâ€ hackathon</a>. I decided that I would do this by finding paths in the links between Wikipedia pages. The thing is to do this I needed a good data set in the right format.</p>

<p>I did some research and found <a href="http://mu.netsoc.ie/wiki/">Six Degrees of Wikipedia</a> which had some information but no data or source files. I then found <a href="https://github.com/mirkonasato/graphipedia">Graphipedia</a> but discovered that Neo4j was not fast enough to do what I wanted. Thus I embarked on the adventure of creating my own Wikipedia link graph data set designed for efficient execution of common graph algorithms. The premise was compressing the whole graph into a small(ish) file that would fit entirely in memoryÙ« so I called it <a href="https://github.com/trishume/wikicrush">Wikicrush</a>.</p>

<p>I spent the next few weeks occasionally working on a set of Ruby scripts that in multiple stages processed the 10GB compressed <code class="language-plaintext highlighter-rouge">enwiki-20150205-pages-articles.xml.bz2</code> file into two 500mb files: <code class="language-plaintext highlighter-rouge">xindex.db</code> and <code class="language-plaintext highlighter-rouge">indexbi.bin</code>. For each stage in the process I ensured that it worked in O(n) time and reasonable memory. This way I could use crunch through the entire thing over a day on a cheap VPS. During development I would use the smaller Simple English wiki which I could process in a few minutes on my laptop. The advantage of the multi-stage design is that if I needed to tweak something I could just re-run the stages after that point rather than the whole thing. The intermediate files it created were also very useful for debugging and could be useful data sets in their own right.</p>

<p><img src="/assets/postassets/wikicrush/ssh-screenshot.png" alt="VPS Working Away" /></p>

<p>I ended up with two files Iâ€™m rather proud ofÙ« one is a binary link graph in a custom format I designed myself designed to fit in memory and allow very efficient searching and processing. The other is simply an Sqlite index designed to translate article titles into offsets into the binary file and back again. The formats are fairly easy to work with in any imperative language and have many handy features. I documented the formats in detail in the <a href="https://github.com/trishume/wikicrush#primary-data">Wikicrush readme</a>. They work so well that my $10/month VPS can easily breadth first search through millions of articles in less than a second.</p>

<p>I had the initial version working fairly quickly but had to spend a bunch of time fixing small bugs to get it to accurately represent the actual link graph of Wikipedia. I had to fix things like following redirectsÙ« cutting out broken linksÙ« ignoring links in comments and proper handling of case in links (I ended up lowercasing everything). Although making your own Wikipedia data set may seem easy at firstÙ« thereâ€™s plenty of ways things can go wrong. Many times I thought I had a good complete data set and only later would I realize something was wrong. One time I thought I had finally worked out the kinks and then discovered weeks later that it thought 70% of links on Wikipedia were invalidÙ« which obviously isnâ€™t true. Even just yesterday I found and fixed a little bug that only affected 300 articlesÙ« but the perfectionist in me sent my VPS to slave away for another 40 hours of rebuilding.</p>

<p><strong>Edit:</strong> I recently found another glitch and overhauled the entire process to be more robust. I now think Iâ€™ve shaken out all the bugs so I have put up a download of the final product.
You can find the link on the <a href="https://github.com/trishume/wikicrush">Wikicrush readme</a>. I also no longer need to lowercase everything. This is AFAIK the only Wikipedia link graph dataset available for public download.</p>

<h2 id="the-terrible-hacks-hackathon">The Terrible Hacks Hackathon</h2>

<p>During the hackathon some parts went very smoothly while others did not. Working with the files I had created was very easyÙ« working with the Rust language for my first time was not. At some point I could not link my graph search algorithm to the <a href="https://github.com/iron/iron">Iron</a> web framework because my algorithm and Sqlite connection were not thread safe and one can not disable type system based thread safety checks in Iron with Rust. I ended up with a suitably terrible hack which was having the Rust code communicate over stdin/stdout and having a Ruby Sinatra server interface with that. Along with thatÙ« all the paths were hard codedÙ« it required a specific <code class="language-plaintext highlighter-rouge">rustc</code> commit and one had to manually fiddle with the <code class="language-plaintext highlighter-rouge">Cargo.toml</code> and <code class="language-plaintext highlighter-rouge">Cargo.lock</code> files to work around a bug in Cargo just to get it to compile. This made it practically impossible to install and run on anything but my laptop.</p>

<p>I eventually got things hacked together and by that time Dave had put together a fantastic front end with fancy CSSÙ« autocomplete and REST loading. All I had to do was serve his static files and expose a JSON API.</p>

<p>Once we did that we had a productÙ« and it ended up working great. The paths it generated were amusing and it was fun to use. Not to mention it looked pretty good for something put together in one afternoon:
<img src="/assets/postassets/wikicrush/rws-screenshot.png" alt="The Product" /></p>

<h2 id="the-rewrite">The Rewrite</h2>

<p>A week later I decided to kill two birds with one experimental statically-typed stone and learned the <a href="http://nim-lang.org/">Nim</a> language by rewriting the project in it. I ran into a couple similar problems with the Jester web framework and loading the file into an int32 array but unlike the similar problems in Rust these had easy workarounds. In the end everything worked reasonably well with Nim especially after I got some help on IRC from its creator.</p>

<p>You can now visit and try out <a href="http://ratewithscience.thume.net/">Rate With Science</a> powered purely by Nim and backed by Wikicrush.</p>
'),('http://thume.ca/2015/03/14/idea-a-viral-industrial-charity/', 'Idea: A Viral Industrial Charity', '1426291200000',  13, '
<p>Deviating from the usual programming content of this blog Iâ€™d like to talk about an idea Iâ€™ve been thinking about recently. This week I went to a talk by <a href="http://lewisdartnell.com/en-gb/">Lewis Dartnell</a> author of the most interesting non-fiction book Iâ€™ve ever read called <a href="http://the-knowledge.org/en-gb/the-book/">The Knowledge</a>. Itâ€™s a book that explores the essential science and technology necessary to build a modern society from the perspective of bootstrapping civilization after the apocalypse. The apocalypse is merely a convenient thought experiment thoughÙ« its a fantastic read just to learn about all the hidden industrial processes and science that keeps the world working today.</p>

<p>Personally the book got me thinking about how this idea of bootstrapping might help in the modern world. I also learned about the fundamental behind the scenes industrial processes that keep the world runningÙ« like the Haber-Bosch Process and the production of fundamental chemicals like lime. It gave me huge respect for how incredible difficult it is to create an industrial civilization.</p>

<p>The most interesting idea Iâ€™ve thought ofÙ« and Iâ€™m sure this idea isnâ€™t uniqueÙ« is the possibility of a viral industrial charity. Suppose there exists a set of machineryÙ« tools and knowledge which a group of people can use to produce a second set of machines in a reasonable time span like one year. The other criterion for these machines are that they can be used to productively ensure a decent standard of living for those working on reproducing them.</p>

<p>If funding could be found to build one set of these machinesÙ« they could be set up in a third-world country as a kind of employer. A group of 100 or so people would be trained to use the machines and they would work to produce a new set and be compensated with the right to use the machines to provide themselves with good housingÙ« food and other useful things. The magic comes once they finish the second set of machines and can use it to establish another village. Now there are two villages producing new sets and exponential growth takes holdÙ« with luck the charity could grow to create thousands of new industrialized villages per year. With the only infusion of charity capital being the initial setÙ« some management and perhaps a small kit for each new village of very difficult to produce items like machine control computers.</p>

<p>This is by no means a perfect planÙ« there are many potential issues. Chief among them is that this set of machinery does not yet exist. Technology is awesome but it is also hard and highly interdependent. It is difficult to satisfy both of the dual criteria of having no external dependencies and being useful for sustaining an independent village. There is a project called the <a href="http://opensourceecology.org/wiki/Global_Village_Construction_Set">Global Village Construction Set</a> that is trying to do just this but it is slow and difficult. They have some great ideas but designing all these machines is a lot of work and they have not solved the closed dependency problem despite trying very hard. Many of their machines require some external parts such as ball bearings and microcontrollersÙ« which need very precise dedicated machinery to produce. It is likely that any set of reproducing machines might need a box of small precision parts like ball bearings and integrated circuits to close the cycle. HoweverÙ« if this box is cheap enough a charity could support the exponential growth without too much fund raising.</p>

<p>The other technological challenge is resources. For the village to be self-sufficient it would have to produce its own materials and food. Farming can be done in many locations especially with good toolsÙ« but natural resources are often very spread out. The solution to this is probably to make everything out of a minimal set of different materials that are produced from very common natural resources. One idea from the Global Village Construction Set is the possibility of electrolyzing aluminum from clay. Clay is very commonÙ« easy to extract and can be used to make bricksÙ« ceramic objects and aluminum metal (with some difficulty). A village built near a clay depositÙ« a river and some fertile land for farming with some natural or planted woodland nearby might be able to produce all the resources it needs. The village may still need to do some trading perhaps of aluminum for scrap steel to produce high stress specialized parts thoughÙ« steel mining and refining is likely beyond the capability of a small village yet steel is necessary for many useful machines.</p>

<p>The other thing to think about is the charity structure itself. It has the virtue of not being very dependent on the external economy and enabling self-sufficiency. HoweverÙ« it does require at least some managerial and government structure to ensure that the people living in the village continue producing new sets of machinery instead of just using them to satisfy their own needs. This should be possible in any country with a decent governmentÙ« it could probably be set up legally as an employerÙ« albeit an unconventional one. Villagers who stopped producing machinery would be breaking the law in the same way as factory employees would be if they started stealing the output of the factory and taking it home. And Iâ€™m sure the occupants/employees would at least feel content with the idea that the purpose of their hard work is to help lift others out of poverty. They would of course also be compensated with a standard of living higher than they were used to.</p>

<p>As long as no one has designed this theoretical village this plan remains just an idea. HoweverÙ« the <a href="http://opensourceecology.org/wiki/Global_Village_Construction_Set">Global Village Construction Set</a> is doing a great job and it is possible that years in the future it will be polished enough that with some start up capital and planning this could be a real endeavour. For my part I might even try to help design some of the machines on their to-do list as a fun hobby and way of learning about machinery.</p>

<p>For anyone who found the content of this post interestingÙ« I highly recommend you read <a href="http://the-knowledge.org/en-gb/the-book/">The Knowledge</a> and take a look at the wiki for the <a href="http://opensourceecology.org/wiki/Global_Village_Construction_Set">Global Village Construction Set</a>. I just thought Iâ€™d put this idea out there to see if anyone else has comments on itÙ« I by no means think this is a perfect plan and it likely would have many practical tripping points. HoweverÙ« if these problems could be solved its potential impact per dollar invested is amazing.</p>
'),('http://thume.ca/howto/2015/03/07/configuring-spacemacs-a-tutorial/', 'Configuring Spacemacs: A Tutorial', '1425686400000',  13, '
<p><strong>Edit:</strong> Some things in this post are now outdated. Iâ€™m currently using Sublime Text with Vim keybindings instead of Spacemacs so I havenâ€™t been keeping up. Iâ€™ve fixed some things (Thanks Fabien!) but others may remain. If you want to fix something outdated <a href="https://github.com/trishume/trishume.github.com/blob/master/_posts%2F2015-03-07-configuring-spacemacs-a-tutorial.md">submit a PR to my website</a>.</p>

<p>A few months ago I switched to using <a href="https://github.com/syl20bnr/spacemacs">Spacemacs</a> as my text editor of choice. It has great vim keybindings and extensive default configs for a variety of packages. Iâ€™ve become one of the top contributors to Spacemacs and Iâ€™ve learned a few things about configuring it in the process. This post will function as a tutorial to get you started with configuring Spacemacs to your liking.</p>

<p>You can get started using Spacemacs by following the installation instructions in the <a href="https://github.com/syl20bnr/spacemacs">readme</a> and perusing the in-depth <a href="https://github.com/syl20bnr/spacemacs/blob/master/doc/DOCUMENTATION.org">documentation</a>.</p>

<h1 id="the-spacemacs-file">The .spacemacs File</h1>

<p>The <code class="language-plaintext highlighter-rouge">~/.spacemacs</code> file is your main starting point for configuring Spacemacs. If you donâ€™t have this file you can install a template pressing <code class="language-plaintext highlighter-rouge">SPC : dotspacemacs/install RET</code> in SpacemacsÙ« where <code class="language-plaintext highlighter-rouge">SPC</code> is space and <code class="language-plaintext highlighter-rouge">RET</code> is the enter key. At any time you can press <code class="language-plaintext highlighter-rouge">SPC f e d</code> to edit this file.</p>

<p>The template comes with many variables that you can customize and use to set things like font sizes and window preferences. Once you are done editingÙ« save the file and either press <code class="language-plaintext highlighter-rouge">SPC f e R</code> in the file to reload it or just restart Spacemacs.</p>

<p>Some parts of this file are more important than others:</p>

<h2 id="dotspacemacsuser-config">dotspacemacs/user-config</h2>

<p>This function is run after Spacemacs sets itself upÙ« in here you can customize variables and activate extra functionality you want. Perhaps the most important thing to know is that this is generally where you can paste random snippets of Emacs Lisp you find on the internet. If a page says to put a snippet into your <code class="language-plaintext highlighter-rouge">init.el</code> file <strong>donâ€™t do that</strong>Ù« put it in <code class="language-plaintext highlighter-rouge">dotspacemacs/user-config</code> instead.</p>

<p>Another thing this function is useful for is setting the default state of some toggleable editor preferences. If you press <code class="language-plaintext highlighter-rouge">SPC t</code> you will see some of the things you can toggleÙ« these include line numbersÙ« line wrappingÙ« current line highlightÙ« etcâ€¦</p>

<p>Most of these toggles actually enable and disable â€œminor modesâ€Ù« if you want some of these on or off by default you can put things like these in your <code class="language-plaintext highlighter-rouge">dotspacemacs/user-config</code> function:</p>

<figure class="highlight"><pre><code class="language-lisp" data-lang="lisp"><span class="p">(</span><span class="nb">defun</span> <span class="nv">dotspacemacs/user-config</span> <span class="p">()</span>
  <span class="p">(</span><span class="nv">global-hl-line-mode</span> <span class="mi">-1</span><span class="p">)</span> <span class="c1">; Disable current line highlight</span>
  <span class="p">(</span><span class="nv">global-linum-mode</span><span class="p">))</span> <span class="c1">; Show line numbers by default</span></code></pre></figure>

<h2 id="dotspacemacs-configuration-layers">dotspacemacs-configuration-layers</h2>

<p>This brings us to <strong>configuration layers</strong> the most core concept of Spacemacs. Not all parts of Spacemacs are enabled by defaultÙ« there are a large number of user contributed â€œlayersâ€ that add packages and configs for things like programming languagesÙ« external tools and extra functionality. Layers specify which packages they want Spacemacs to install for themÙ« how to load the package and often include some default configs to make the package integrate well with the rest of Spacemacs.</p>

<p>The <code class="language-plaintext highlighter-rouge">dotspacemacs-configuration-layers</code> variableÙ« set in the <code class="language-plaintext highlighter-rouge">dotspacemacs/layers</code> function near the top of the template is where you specify which layers you want to include. When you find yourself wondering â€œdoes Spacemacs come with support for X?â€ you can simply type <code class="language-plaintext highlighter-rouge">SPC f e h</code> and search through the built in layers. Once you find one you want to include simply include it in the list in the variable set statement. This is what mine looks like:</p>

<figure class="highlight"><pre><code class="language-lisp" data-lang="lisp"><span class="nv">dotspacemacs-configuration-layers</span> <span class="o">"</span><span class="p">(</span><span class="nv">extra-langs</span> <span class="nv">auctex</span>
  <span class="nv">company-mode</span> <span class="nv">git</span> <span class="nv">c-c++</span> <span class="nv">haskell</span> <span class="nv">html</span> <span class="nv">javascript</span> <span class="nv">ruby</span> <span class="nv">ycmd</span>
  <span class="nv">smex</span> <span class="nv">dash</span> <span class="nv">colors</span> <span class="nv">lua</span> <span class="nv">trishume</span> <span class="nv">markdown</span> <span class="nv">finance</span><span class="p">)</span></code></pre></figure>

<p>YahÙ« I use a lot of layers; you should tooÙ« theyâ€™re pretty important! You can see staples like â€œhtmlâ€ and â€œrubyâ€ as well as fancier functionality ones like â€œcompany-modeâ€. Try looking through <a href="https://github.com/syl20bnr/spacemacs/tree/master/layers">the â€œlayersâ€ directory</a> to see all the available contributed layers and their Readmeâ€™s and source code.</p>

<h1 id="your-own-layers">Your Own Layers!</h1>

<p>You too could be the author of your very own layer! In factÙ« youâ€™ll likely find you want to after you have used Spacemacs for a while. The most important purpose of layers is adding <a href="http://melpa.org/">MELPA</a> packages and the configuration and keybindings for them. <strong>Donâ€™t</strong> try and just install packages with the default Emacs package manager like the internet might tell you to do!</p>

<p>If you want to install a package you found onlineÙ« like <a href="http://melpa.org/#/2048-game">2048-game</a>Ù« youâ€™ll want to create a layer that includes the package and sets it up. Another option for small things is to add the package to the <code class="language-plaintext highlighter-rouge">dotspacemacs-additional-packages</code> list. There are a couple of places you can put this layerÙ« which is really just a folder with some emacs lisp files:</p>

<h2 id="the-private-directory">The â€œprivateâ€ Directory</h2>

<p>This is a folder in the main Spacemacs directory where you can put configuration layers for your own personal use.
You can create a template layer in this directory using <code class="language-plaintext highlighter-rouge">&lt;SPC&gt; : configuration-layer/create-layer RET</code>.</p>

<p>The descriptive comments in the template <code class="language-plaintext highlighter-rouge">packages.el</code> do a pretty good job of explaining what to do. Basically you add the package you want to include to the <code class="language-plaintext highlighter-rouge">yourlayernamehere-packages</code> list and then create <code class="language-plaintext highlighter-rouge">yourlayernamehere-init-yourpackagenamehere</code> functions where you use <a href="https://github.com/jwiegley/use-package">use-package</a> to load the package and set it up. Take a look at <a href="https://github.com/syl20bnr/spacemacs/tree/master/layers/%2Btools/finance">existing layers</a> for examples of how to set up packages and keybindings.</p>

<p>Once you have written a layer <strong>you have to load it in .spacemacs</strong> just like any other layer. Add your layerâ€™s name to <code class="language-plaintext highlighter-rouge">dotspacemacs-configuration-layers</code>.</p>

<h2 id="dotspacemacs-configuration-layer-path">dotspacemacs-configuration-layer-path</h2>

<p>If you want to keep your layers in a git repository or Dropbox sync or some other folderÙ« you can use the <code class="language-plaintext highlighter-rouge">dotspacemacs-configuration-layer-path</code> variable in <code class="language-plaintext highlighter-rouge">.spacemacs</code> to set another folder where you can load layers from. Then you can just copy the layer directory that Spacemacs puts in the private directory into this directory and Spacemacs will be able to load it from there.</p>

<h2 id="the-contrib-directory">The â€œcontribâ€ Directory</h2>

<p>If you are adding some awesome new functionality to SpacemacsÙ« which you probably areÙ« you should seriously consider contributing it back. This is how Spacemacs has grown into the awesome distribution that it is. Donâ€™t worry about people finding it hacky or not usefulÙ« we wonâ€™t mind and might even help you make it better.</p>

<p>This is what I doÙ« Iâ€™m proud to say that I only have 1 private layerÙ« <a href="https://github.com/syl20bnr/spacemacs/tree/064a598bff56f7cef1ac2ddf1c43684357dde56a/contrib/company-mode">every</a> <a href="https://github.com/syl20bnr/spacemacs/tree/064a598bff56f7cef1ac2ddf1c43684357dde56a/contrib/lang/extra-langs">other</a> <a href="https://github.com/syl20bnr/spacemacs/tree/064a598bff56f7cef1ac2ddf1c43684357dde56a/contrib/ycmd">layer</a> <a href="https://github.com/syl20bnr/spacemacs/tree/064a598bff56f7cef1ac2ddf1c43684357dde56a/contrib/auctex">Iâ€™ve</a> <a href="https://github.com/syl20bnr/spacemacs/tree/064a598bff56f7cef1ac2ddf1c43684357dde56a/contrib/ranger-control">written</a> has been contributed back to Spacemacs. Itâ€™s as simple as forking SpacemacsÙ« adding your layer to <code class="language-plaintext highlighter-rouge">contrib</code> and submitting a Github pull request.</p>

<h2 id="tips-for-writing-layers">Tips For Writing Layers</h2>

<p>Thereâ€™s a couple things that are nice to know when writing layers. The most important thing to know is some of the features of <a href="https://github.com/jwiegley/use-package">use-package</a>. You use this in the init functions in <code class="language-plaintext highlighter-rouge">packages.el</code> to load the package and set it up. The function takes a package name and some attributes containing things like functions to run on load. You use use-package <strong>instead of</strong> doing whatever loading step the package readme tells you to doÙ« generally you donâ€™t include things like <code class="language-plaintext highlighter-rouge">(require "blah)</code>.</p>

<h3 id="basic-format">Basic Format</h3>

<figure class="highlight"><pre><code class="language-lisp" data-lang="lisp"><span class="p">(</span><span class="nb">defun</span> <span class="nv">finance/init-ledger-mode</span> <span class="p">()</span>
  <span class="p">(</span><span class="nb">use-package</span> <span class="nv">ledger-mode</span>
    <span class="c1">; Use :mode to set language modes to automatically activate on certain extensions</span>
    <span class="ss">:mode</span> <span class="p">(</span><span class="s">"\\.\\(ledger\\|ldg\\)\\""</span> <span class="o">.</span> <span class="nv">ledger-mode</span><span class="p">)</span>
    <span class="c1">; :defer t activates lazy loading which makes startup faster</span>
    <span class="ss">:defer</span> <span class="no">t</span>
    <span class="c1">; The code in :init is always runÙ« use it to set up config vars and key bindings</span>
    <span class="ss">:init</span>
    <span class="p">(</span><span class="k">progn</span> <span class="c1">; :init only takes one expression so use "progn" to combine multiple things</span>
      <span class="c1">; You can configure package variables here</span>
      <span class="p">(</span><span class="k">setq</span> <span class="nv">ledger-post-amount-alignment-column</span> <span class="mi">62</span><span class="p">)</span>
      <span class="c1">; Using evil-leader/set-key-for-mode adds bindings under SPC for a certain mode</span>
      <span class="c1">; Use evil-leader/set-key to create global SPC bindings</span>
      <span class="p">(</span><span class="nv">evil-leader/set-key-for-mode</span> <span class="ss">"ledger-mode</span>
        <span class="s">"mhd"</span>   <span class="ss">"ledger-delete-current-transaction</span>
        <span class="s">"m RET"</span> <span class="ss">"ledger-set-month</span><span class="p">))</span>
    <span class="ss">:config</span> <span class="c1">; :config is called after the package is actually loaded with defer</span>
      <span class="c1">; You can put stuff that relies on the package like function calls here</span>
      <span class="p">(</span><span class="nv">message</span> <span class="s">"Ledger mode was actually loaded!"</span><span class="p">)))</span></code></pre></figure>

<h3 id="things-that-arent-packages">Things that arenâ€™t packages</h3>

<p>If you want to bundle up some snippet or config that isnâ€™t related to a package you can use the <code class="language-plaintext highlighter-rouge">config.el</code>
file in the layer. In here you can just put Emacs Lisp code and functions that will be evaluated when a layer is loaded.</p>

<h3 id="dependencies">Dependencies</h3>

<p>Sometimes you want to hook something in your layer into another package. This is most common for making sure your alayer works well with default packages like smartparens. To do this youâ€™ll want to use <code class="language-plaintext highlighter-rouge">eval-after-load</code>. <a href="https://github.com/syl20bnr/spacemacs/blob/064a598bff56f7cef1ac2ddf1c43684357dde56a/contrib/ansible/packages.el#L24">Hereâ€™s an example</a> of a package adding extra functionality to <code class="language-plaintext highlighter-rouge">yaml-mode</code>.</p>

<h1 id="other-information">Other Information</h1>

<p>This guide hopefully gave you enough info to get startedÙ« but thereâ€™s so much more to Spacemacs that isnâ€™t here. Thereâ€™s a bunch of other sources of information that you should look at if you canâ€™t find what you want:</p>

<h2 id="the-gitter-chat">The Gitter Chat</h2>

<p>Please visit the <a href="https://gitter.im/syl20bnr/spacemacs">Gitter chat room</a> if you have any questions about configuring or using Spacemacs that you canâ€™t figure outÙ« or just come to chat with other Spacemacs users. Thereâ€™s always tons of knowledgeable people thereÙ« including the awesome maintainer @syl20bnrÙ« who will help you out.</p>

<h2 id="the-documentation">The Documentation</h2>

<p>Most of these layer concepts and mechanics are explained in depth in the massive <a href="https://github.com/syl20bnr/spacemacs/blob/master/doc/DOCUMENTATION.org">Documentation</a>. It also has information on lots of the functionality available in Spacemacs.</p>

<h2 id="the-source-code">The Source Code!</h2>

<p>If you want deep insight into the workings of Spacemacs you should really take a look at the <a href="https://github.com/syl20bnr/spacemacs">source code</a> on Github. The main difference between me and the average Spacemacs user is that I have read lots of the source and thus I know a lot about how Spacemacs works. I swear itâ€™s really not that complicatedÙ« youâ€™ll discover that most of Spacemacs is actually just the <code class="language-plaintext highlighter-rouge">spacemacs</code> layer which is just like any other configuration layer except it is included by default. You can also read the code for the contrib layers for ideasÙ« although the techniques these use might be less consistent since they were written by lots of differnt peopleÙ« many of them newbies. For a good start I recommend skimming through this <a href="https://github.com/syl20bnr/spacemacs/blob/master/layers/%2Bdistributions/spacemacs-base/packages.el">packages.el</a> file. You can also use <code class="language-plaintext highlighter-rouge">SPC h SPC</code> to search for layers and hit enter to visit their source.</p>

<h1 id="conclusion">Conclusion</h1>

<p>I hope this helped you on your way to become a Spacemacs power-user. This guide was rather specific to configuration but I plan on maybe writing other tutorials on basic use and other tips. Donâ€™t forget to say hi to me and all the other awesome Spacemacs people in the <a href="https://gitter.im/syl20bnr/spacemacs">Gitter chat</a>Ù« we always love hearing from other Spacemacs users!</p>
'),('http://thume.ca/howto/2014/12/02/using-mjolnir-an-extensible-osx-window-manager/', 'Using Mjolnir: An Extensible OSX Window Manager', '1417478400000',  13, '
<p><strong>Edit: I am now using <a href="http://www.hammerspoon.org/">Hammerspoon</a> which is a fork of Mjolnir that is basically the same except it comes with the modules (no luarocks)Ù« itâ€™s under active development and the naming is slightly different and more consistent. Most of this article still applies.</strong></p>

<p>Recently I started using the amazing and highly configurable window manager called <a href="http://mjolnir.io/">Mjolnir</a>.
But really it isnâ€™t a window managerÙ« itâ€™s an OSX wrapper around a Lua configuration file and event loop that
has a constellation of modules that allow you to configure all sorts of computer control tasks. The most common use
for Mjolnir is managing Windows but there are all sorts of modules that allow you to use it for doing things like
<a href="https://github.com/asmagill/mjolnir-config/blob/master/utils/_actions/battery_usbdrives.lua">unmounting your USB drives when you switch to battery power</a>.</p>

<p>Two years ago I wrote a blog post about <a href="/howto/2012/11/19/using-slate/">configuring Slate</a>Ù« the configurable window manager
that I had been using until this month. HoweverÙ« the maintainer hasnâ€™t worked on Slate in years and there are dozens of pull requests sitting around without merge and comment. There have been <a href="https://github.com/mattr-/slate">attempts</a> to revive itÙ«
but there were still some rough edges and I decided to try something new.</p>

<p>Here Iâ€™ll describe how I use Mjolnir and my experience with it so far.</p>

<h2 id="getting-started">Getting Started</h2>

<p>The instructions on <a href="http://mjolnir.io/">Mjolnirâ€™s homepage</a> are pretty good as far as getting Mjolnir installed goes.
Youâ€™ll need to get luarocks working and then create an <code class="language-plaintext highlighter-rouge">init.lua</code> fileÙ« which isnâ€™t very hard.
The basic install you get canâ€™t do much so youâ€™ll have to use some of the many <a href="https://rocks.moonscript.org/search?q=mjolnir">Mjolnir modules</a>.
Before you use a module you have to install it firstÙ« to install <code class="language-plaintext highlighter-rouge">mjolnir.hotkey</code> you would run</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>luarocks install mjolnir.hotkey
</code></pre></div></div>

<h2 id="window-management">Window Management</h2>

<p>Mjolnir makes managing windows really easy with great modules to help you with this most of which are built upon the basic
functionality found in <a href="https://rocks.moonscript.org/modules/sdegutis/mjolnir.application">mjolnir.application</a>.
That module provides basic access to running applications and their windowsÙ« which modules like
<a href="https://github.com/BrianGilbert/mjolnir.bg.grid">mjolnir.bg.grid</a> use to provide things like the ability
to move windows around and resize on a grid. There are even fancier modules like
<a href="https://github.com/nathankot/mjolnir.tiling">mjolnir.tiling</a> which automatically organize your windows
like a fancy Linux tiling window manager would do.</p>

<h3 id="basic-key-bindings">Basic Key Bindings</h3>

<p>Generally the way you want to start is by binding actions (really just Lua functions) to keys using the <code class="language-plaintext highlighter-rouge">mjolnir.hotkey</code>.
Hereâ€™s an example from the Mjolnir homepage of binding a key that just nudges a window right:</p>

<figure class="highlight"><pre><code class="language-lua" data-lang="lua"><span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">({</span><span class="s2">"cmd"</span><span class="p">Ù«</span> <span class="s2">"alt"</span><span class="p">Ù«</span> <span class="s2">"ctrl"</span><span class="p">}Ù«</span> <span class="s2">"D"</span><span class="p">Ù«</span> <span class="k">function</span><span class="p">()</span>
  <span class="kd">local</span> <span class="n">win</span> <span class="o">=</span> <span class="n">window</span><span class="p">.</span><span class="n">focusedwindow</span><span class="p">()</span>
  <span class="kd">local</span> <span class="n">f</span> <span class="o">=</span> <span class="n">win</span><span class="p">:</span><span class="n">frame</span><span class="p">()</span>
  <span class="n">f</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="mi">10</span>
  <span class="n">win</span><span class="p">:</span><span class="n">setframe</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="k">end</span><span class="p">)</span></code></pre></figure>

<p>Since itâ€™s just Lua code you can also just directly pass function names and use variables to refer to common chords:</p>

<figure class="highlight"><pre><code class="language-lua" data-lang="lua"><span class="kd">local</span> <span class="n">mash</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"ctrl"</span><span class="p">Ù«</span> <span class="s2">"shift"</span><span class="p">}</span>
<span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">mash</span><span class="p">Ù«</span> <span class="s2">"c"</span><span class="p">Ù«</span> <span class="n">mjolnir</span><span class="p">.</span><span class="n">openconsole</span><span class="p">)</span></code></pre></figure>

<h3 id="using-a-grid">Using a Grid</h3>

<p>Personally I found the easiest way of doing window management was to use the <a href="https://github.com/BrianGilbert/mjolnir.bg.grid">mjolnir.bg.grid</a> module. It provides functions that allow you to shuffle windows around a grid of a configurable number of rows and
columns (3x3 by default). Hereâ€™s an example of some basic bindings inspired by <a href="https://github.com/vpetro/dotfiles/blob/master/.mjolnir/init.lua">this config</a>:</p>

<figure class="highlight"><pre><code class="language-lua" data-lang="lua"><span class="kd">local</span> <span class="n">grid</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.sd.grid"</span>
<span class="kd">local</span> <span class="n">hotkey</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.hotkey"</span>

<span class="n">grid</span><span class="p">.</span><span class="n">MARGINX</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">grid</span><span class="p">.</span><span class="n">MARGINY</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">grid</span><span class="p">.</span><span class="n">GRIDWIDTH</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">grid</span><span class="p">.</span><span class="n">GRIDHEIGHT</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1">-- a helper function that returns another function that resizes the current window</span>
<span class="c1">-- to a certain grid size.</span>
<span class="kd">local</span> <span class="n">gridset</span> <span class="o">=</span> <span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">Ù«</span> <span class="n">y</span><span class="p">Ù«</span> <span class="n">w</span><span class="p">Ù«</span> <span class="n">h</span><span class="p">)</span>
    <span class="k">return</span> <span class="k">function</span><span class="p">()</span>
        <span class="n">cur_window</span> <span class="o">=</span> <span class="n">window</span><span class="p">.</span><span class="n">focusedwindow</span><span class="p">()</span>
        <span class="n">grid</span><span class="p">.</span><span class="n">set</span><span class="p">(</span>
            <span class="n">cur_window</span><span class="p">Ù«</span>
            <span class="p">{</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">Ù«</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">Ù«</span> <span class="n">w</span><span class="o">=</span><span class="n">w</span><span class="p">Ù«</span> <span class="n">h</span><span class="o">=</span><span class="n">h</span><span class="p">}Ù«</span>
            <span class="n">cur_window</span><span class="p">:</span><span class="n">screen</span><span class="p">()</span>
        <span class="p">)</span>
    <span class="k">end</span>
<span class="k">end</span>

<span class="kd">local</span> <span class="n">mash</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"ctrl"</span><span class="p">Ù«</span> <span class="s2">"shift"</span><span class="p">}</span>
<span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">mash</span><span class="p">Ù«</span> <span class="s1">"n"</span><span class="p">Ù«</span> <span class="n">grid</span><span class="p">.</span><span class="n">pushwindow_nextscreen</span><span class="p">)</span>
<span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">mash</span><span class="p">Ù«</span> <span class="s1">"a"</span><span class="p">Ù«</span> <span class="n">gridset</span><span class="p">(</span><span class="mi">0</span><span class="p">Ù«</span> <span class="mi">0</span><span class="p">Ù«</span> <span class="mi">1</span><span class="p">Ù«</span> <span class="mi">2</span><span class="p">))</span> <span class="c1">-- left half</span>
<span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">mash</span><span class="p">Ù«</span> <span class="s1">"s"</span><span class="p">Ù«</span> <span class="n">grid</span><span class="p">.</span><span class="n">maximize_window</span><span class="p">)</span>
<span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">mash</span><span class="p">Ù«</span> <span class="s1">"d"</span><span class="p">Ù«</span> <span class="n">gridset</span><span class="p">(</span><span class="mi">1</span><span class="p">Ù«</span> <span class="mi">0</span><span class="p">Ù«</span> <span class="mi">1</span><span class="p">Ù«</span> <span class="mi">2</span><span class="p">))</span> <span class="c1">-- right half</span></code></pre></figure>

<h2 id="window-hints">Window Hints</h2>

<p>One of my favourite parts of Mjolnir is that you can write your own modules in Lua and Objective C to hook into OSX
functionality that Mjolnir doesnâ€™t support by default. The great thing is other people have already written all sorts
of modules to do things like <a href="https://github.com/Linell/mjolnir.lb.spotify">controlling Spotify</a>
and <a href="https://github.com/asmagill/mjolnir_asm.ui/tree/master/sound">playing sounds</a>.</p>

<p>Recently I wrote my own module in 4 hours or so that adds the window hints feature that I missed from Slate:
<a href="https://github.com/trishume/mjolnir.th.hints">mjolnir.th.hints</a>. Except I think I did it even better than Slate did.
It allows you to quickly switch apps and windows using â€œhintsâ€ that pop up when you hit a key that have a letter on themÙ«
when you press the letter it switches to that app.</p>

<p><img src="https://camo.githubusercontent.com/384052b64aa56146c1efb579b6fbdb60901987ea/687474703a2f2f692e696d6775722e636f6d2f6b744c6742574f2e706e67" alt="Hints Screenshot" /></p>

<p>All you have to do is bind it to a key:</p>

<figure class="highlight"><pre><code class="language-lua" data-lang="lua"><span class="kd">local</span> <span class="n">hints</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.th.hints"</span>
<span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">({</span><span class="s2">"cmd"</span><span class="p">}Ù«</span><span class="s2">"e"</span><span class="p">Ù«</span><span class="n">hints</span><span class="p">.</span><span class="n">windowHints</span><span class="p">)</span>
<span class="c1">-- You can also use this with appfinder to switch to windows of a specific app</span>
<span class="kd">local</span> <span class="n">appfinder</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.cmsj.appfinder"</span>
<span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">({</span><span class="s2">"ctrl"</span><span class="p">Ù«</span><span class="s2">"cmd"</span><span class="p">}Ù«</span><span class="s2">"k"</span><span class="p">Ù«</span><span class="k">function</span><span class="p">()</span> <span class="n">hints</span><span class="p">.</span><span class="n">appHints</span><span class="p">(</span><span class="n">appfinder</span><span class="p">.</span><span class="n">app_from_name</span><span class="p">(</span><span class="s2">"Emacs"</span><span class="p">))</span> <span class="k">end</span><span class="p">)</span></code></pre></figure>

<h1 id="my-config">My Config</h1>

<p>My personal config is a bit fancier and more specific to me than you might want to start off withÙ« but you might want to get
some ideas from it. You can find the latest version <a href="https://github.com/trishume/dotfiles/blob/master/hammerspoon/hammerspoon.symlink/init.lua">in my dotfiles repo</a>Ù«
but Iâ€™ve included my config at the time of writing later on the page because it will probably be simpler than my
config at the time you read this.</p>

<p>It has fancy features like rebinding the keys on keyboard layout change (which doesnâ€™t always work).
Probably the best feature is a crappy implementation of something that mimics Slateâ€™s support for layouts.</p>

<p><strong>Edit: see <a href="https://github.com/trishume/dotfiles/blob/master/hammerspoon/hammerspoon.symlink/init.lua">my dotfiles repo</a> for the Hammerspoon version.</strong></p>

<figure class="highlight"><pre><code class="language-lua" data-lang="lua"><span class="c1">-- Load Extensions</span>
<span class="kd">local</span> <span class="n">application</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.application"</span>
<span class="kd">local</span> <span class="n">window</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.window"</span>
<span class="kd">local</span> <span class="n">hotkey</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.hotkey"</span>
<span class="kd">local</span> <span class="n">keycodes</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.keycodes"</span>
<span class="kd">local</span> <span class="n">fnutils</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.fnutils"</span>
<span class="kd">local</span> <span class="n">alert</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.alert"</span>
<span class="kd">local</span> <span class="n">screen</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.screen"</span>
<span class="c1">-- User packages</span>
<span class="kd">local</span> <span class="n">grid</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.bg.grid"</span>
<span class="kd">local</span> <span class="n">hints</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.th.hints"</span>
<span class="kd">local</span> <span class="n">appfinder</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.cmsj.appfinder"</span>

<span class="kd">local</span> <span class="n">definitions</span> <span class="o">=</span> <span class="kc">nil</span>
<span class="kd">local</span> <span class="n">hyper</span> <span class="o">=</span> <span class="kc">nil</span>

<span class="kd">local</span> <span class="n">gridset</span> <span class="o">=</span> <span class="k">function</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
	<span class="k">return</span> <span class="k">function</span><span class="p">()</span>
		<span class="kd">local</span> <span class="n">win</span> <span class="o">=</span> <span class="n">window</span><span class="p">.</span><span class="n">focusedwindow</span><span class="p">()</span>
		<span class="k">if</span> <span class="n">win</span> <span class="k">then</span>
			<span class="n">grid</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="n">win</span><span class="p">Ù«</span> <span class="n">frame</span><span class="p">Ù«</span> <span class="n">win</span><span class="p">:</span><span class="n">screen</span><span class="p">())</span>
		<span class="k">else</span>
			<span class="n">alert</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="s2">"No focused window."</span><span class="p">)</span>
		<span class="k">end</span>
	<span class="k">end</span>
<span class="k">end</span>

<span class="n">auxWin</span> <span class="o">=</span> <span class="kc">nil</span>
<span class="k">function</span> <span class="nf">saveFocus</span><span class="p">()</span>
  <span class="n">auxWin</span> <span class="o">=</span> <span class="n">window</span><span class="p">.</span><span class="n">focusedwindow</span><span class="p">()</span>
  <span class="n">alert</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="s2">"Window ""</span> <span class="o">..</span> <span class="n">auxWin</span><span class="p">:</span><span class="n">title</span><span class="p">()</span> <span class="o">..</span> <span class="s2">"" saved."</span><span class="p">)</span>
<span class="k">end</span>
<span class="k">function</span> <span class="nf">focusSaved</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">auxWin</span> <span class="k">then</span>
    <span class="n">auxWin</span><span class="p">:</span><span class="n">focus</span><span class="p">()</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="kd">local</span> <span class="n">hotkeys</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">function</span> <span class="nf">createHotkeys</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">key</span><span class="p">Ù«</span> <span class="n">fun</span> <span class="k">in</span> <span class="nb">pairs</span><span class="p">(</span><span class="n">definitions</span><span class="p">)</span> <span class="k">do</span>
    <span class="kd">local</span> <span class="n">mod</span> <span class="o">=</span> <span class="n">hyper</span>
    <span class="k">if</span> <span class="nb">string.len</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="nb">string.sub</span><span class="p">(</span><span class="n">key</span><span class="p">Ù«</span><span class="mi">2</span><span class="p">Ù«</span><span class="mi">2</span><span class="p">)</span> <span class="o">==</span> <span class="s2">"c"</span> <span class="k">then</span>
      <span class="n">mod</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"cmd"</span><span class="p">}</span>
    <span class="k">end</span>

    <span class="kd">local</span> <span class="n">hk</span> <span class="o">=</span> <span class="n">hotkey</span><span class="p">.</span><span class="n">new</span><span class="p">(</span><span class="n">mod</span><span class="p">Ù«</span> <span class="nb">string.sub</span><span class="p">(</span><span class="n">key</span><span class="p">Ù«</span><span class="mi">1</span><span class="p">Ù«</span><span class="mi">1</span><span class="p">)Ù«</span> <span class="n">fun</span><span class="p">)</span>
    <span class="nb">table.insert</span><span class="p">(</span><span class="n">hotkeys</span><span class="p">Ù«</span> <span class="n">hk</span><span class="p">)</span>
    <span class="n">hk</span><span class="p">:</span><span class="n">enable</span><span class="p">()</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="k">function</span> <span class="nf">rebindHotkeys</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">Ù«</span> <span class="n">hk</span> <span class="k">in</span> <span class="nb">ipairs</span><span class="p">(</span><span class="n">hotkeys</span><span class="p">)</span> <span class="k">do</span>
    <span class="n">hk</span><span class="p">:</span><span class="n">disable</span><span class="p">()</span>
  <span class="k">end</span>
  <span class="n">hotkeys</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="n">createHotkeys</span><span class="p">()</span>
  <span class="n">alert</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="s2">"Rebound Hotkeys"</span><span class="p">)</span>
<span class="k">end</span>

<span class="k">function</span> <span class="nf">applyPlace</span><span class="p">(</span><span class="n">win</span><span class="p">Ù«</span> <span class="n">place</span><span class="p">)</span>
  <span class="kd">local</span> <span class="n">scrs</span> <span class="o">=</span> <span class="n">screen</span><span class="p">:</span><span class="n">allscreens</span><span class="p">()</span>
  <span class="kd">local</span> <span class="n">scr</span> <span class="o">=</span> <span class="n">scrs</span><span class="p">[</span><span class="n">place</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
  <span class="n">grid</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="n">win</span><span class="p">Ù«</span> <span class="n">place</span><span class="p">[</span><span class="mi">2</span><span class="p">]Ù«</span> <span class="n">scr</span><span class="p">)</span>
<span class="k">end</span>

<span class="k">function</span> <span class="nf">applyLayout</span><span class="p">(</span><span class="n">layout</span><span class="p">)</span>
  <span class="k">return</span> <span class="k">function</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">appName</span><span class="p">Ù«</span> <span class="n">place</span> <span class="k">in</span> <span class="nb">pairs</span><span class="p">(</span><span class="n">layout</span><span class="p">)</span> <span class="k">do</span>
      <span class="kd">local</span> <span class="n">app</span> <span class="o">=</span> <span class="n">appfinder</span><span class="p">.</span><span class="n">app_from_name</span><span class="p">(</span><span class="n">appName</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">app</span> <span class="k">then</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">Ù«</span> <span class="n">win</span> <span class="k">in</span> <span class="nb">ipairs</span><span class="p">(</span><span class="n">app</span><span class="p">:</span><span class="n">allwindows</span><span class="p">())</span> <span class="k">do</span>
          <span class="n">applyPlace</span><span class="p">(</span><span class="n">win</span><span class="p">Ù«</span> <span class="n">place</span><span class="p">)</span>
        <span class="k">end</span>
      <span class="k">end</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="k">function</span> <span class="nf">init</span><span class="p">()</span>
  <span class="n">createHotkeys</span><span class="p">()</span>
  <span class="n">keycodes</span><span class="p">.</span><span class="n">inputsourcechanged</span><span class="p">(</span><span class="n">rebindHotkeys</span><span class="p">)</span>
  <span class="n">alert</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="s2">"MjolnirÙ« at your service."</span><span class="p">)</span>
<span class="k">end</span>

<span class="c1">-- Actual config =================================</span>

<span class="n">hyper</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"cmd"</span><span class="p">Ù«</span> <span class="s2">"alt"</span><span class="p">Ù«</span> <span class="s2">"ctrl"</span><span class="p">Ù«</span><span class="s2">"shift"</span><span class="p">}</span>
<span class="c1">-- Set grid size.</span>
<span class="n">grid</span><span class="p">.</span><span class="n">GRIDWIDTH</span>  <span class="o">=</span> <span class="mi">6</span>
<span class="n">grid</span><span class="p">.</span><span class="n">GRIDHEIGHT</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">grid</span><span class="p">.</span><span class="n">MARGINX</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">grid</span><span class="p">.</span><span class="n">MARGINY</span> <span class="o">=</span> <span class="mi">0</span>
<span class="kd">local</span> <span class="n">gw</span> <span class="o">=</span> <span class="n">grid</span><span class="p">.</span><span class="n">GRIDWIDTH</span>
<span class="kd">local</span> <span class="n">gh</span> <span class="o">=</span> <span class="n">grid</span><span class="p">.</span><span class="n">GRIDHEIGHT</span>

<span class="kd">local</span> <span class="n">gomiddle</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span> <span class="o">=</span> <span class="mi">1</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span><span class="p">Ù«</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">4</span><span class="p">Ù«</span> <span class="n">h</span> <span class="o">=</span> <span class="mi">6</span><span class="p">}</span>
<span class="kd">local</span> <span class="n">goleft</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span> <span class="o">=</span> <span class="mi">0</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">0</span><span class="p">Ù«</span> <span class="n">w</span> <span class="o">=</span> <span class="n">gw</span><span class="o">/</span><span class="mi">2</span><span class="p">Ù«</span> <span class="n">h</span> <span class="o">=</span> <span class="n">gh</span><span class="p">}</span>
<span class="kd">local</span> <span class="n">goright</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span> <span class="o">=</span> <span class="n">gw</span><span class="o">/</span><span class="mi">2</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">0</span><span class="p">Ù«</span> <span class="n">w</span> <span class="o">=</span> <span class="n">gw</span><span class="o">/</span><span class="mi">2</span><span class="p">Ù«</span> <span class="n">h</span> <span class="o">=</span> <span class="n">gh</span><span class="p">}</span>
<span class="kd">local</span> <span class="n">gobig</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span> <span class="o">=</span> <span class="mi">0</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">0</span><span class="p">Ù«</span> <span class="n">w</span> <span class="o">=</span> <span class="n">gw</span><span class="p">Ù«</span> <span class="n">h</span> <span class="o">=</span> <span class="n">gh</span><span class="p">}</span>

<span class="kd">local</span> <span class="n">fullApps</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s2">"Safari"</span><span class="p">Ù«</span><span class="s2">"Aurora"</span><span class="p">Ù«</span><span class="s2">"Nightly"</span><span class="p">Ù«</span><span class="s2">"Xcode"</span><span class="p">Ù«</span><span class="s2">"Qt Creator"</span><span class="p">Ù«</span><span class="s2">"Google Chrome"</span><span class="p">Ù«</span>
  <span class="s2">"Google Chrome Canary"</span><span class="p">Ù«</span> <span class="s2">"Eclipse"</span><span class="p">Ù«</span> <span class="s2">"Coda 2"</span><span class="p">Ù«</span> <span class="s2">"iTunes"</span><span class="p">Ù«</span> <span class="s2">"Emacs"</span><span class="p">Ù«</span> <span class="s2">"Firefox"</span>
<span class="p">}</span>
<span class="kd">local</span> <span class="n">layout2</span> <span class="o">=</span> <span class="p">{</span>
  <span class="n">Airmail</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">Ù«</span> <span class="n">gomiddle</span><span class="p">}Ù«</span>
  <span class="n">Spotify</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">Ù«</span> <span class="n">gomiddle</span><span class="p">}Ù«</span>
  <span class="n">Calendar</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">Ù«</span> <span class="n">gomiddle</span><span class="p">}Ù«</span>
  <span class="n">Dash</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">Ù«</span> <span class="n">gomiddle</span><span class="p">}Ù«</span>
  <span class="n">iTerm</span> <span class="o">=</span> <span class="p">{</span><span class="mi">2</span><span class="p">Ù«</span> <span class="n">goright</span><span class="p">}Ù«</span>
  <span class="n">MacRanger</span> <span class="o">=</span> <span class="p">{</span><span class="mi">2</span><span class="p">Ù«</span> <span class="n">goleft</span><span class="p">}Ù«</span>
<span class="p">}</span>
<span class="n">fnutils</span><span class="p">.</span><span class="n">each</span><span class="p">(</span><span class="n">fullApps</span><span class="p">Ù«</span> <span class="k">function</span><span class="p">(</span><span class="n">app</span><span class="p">)</span> <span class="n">layout2</span><span class="p">[</span><span class="n">app</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">Ù«</span> <span class="n">gobig</span><span class="p">}</span> <span class="k">end</span><span class="p">)</span>

<span class="n">definitions</span> <span class="o">=</span> <span class="p">{</span>
  <span class="p">[</span><span class="s2">";"</span><span class="p">]</span> <span class="o">=</span> <span class="n">saveFocus</span><span class="p">Ù«</span>
  <span class="n">a</span> <span class="o">=</span> <span class="n">focusSaved</span><span class="p">Ù«</span>

  <span class="n">h</span> <span class="o">=</span> <span class="n">gridset</span><span class="p">(</span><span class="n">gomiddle</span><span class="p">)Ù«</span>
  <span class="n">t</span> <span class="o">=</span> <span class="n">gridset</span><span class="p">(</span><span class="n">goleft</span><span class="p">)Ù«</span>
  <span class="n">n</span> <span class="o">=</span> <span class="n">grid</span><span class="p">.</span><span class="n">maximize_window</span><span class="p">Ù«</span>
  <span class="n">s</span> <span class="o">=</span> <span class="n">gridset</span><span class="p">(</span><span class="n">goright</span><span class="p">)Ù«</span>

  <span class="n">g</span> <span class="o">=</span> <span class="n">applyLayout</span><span class="p">(</span><span class="n">layout2</span><span class="p">)Ù«</span>

  <span class="n">d</span> <span class="o">=</span> <span class="n">grid</span><span class="p">.</span><span class="n">pushwindow_nextscreen</span><span class="p">Ù«</span>
  <span class="n">r</span> <span class="o">=</span> <span class="n">mjolnir</span><span class="p">.</span><span class="n">reload</span><span class="p">Ù«</span>
  <span class="n">q</span> <span class="o">=</span> <span class="k">function</span><span class="p">()</span> <span class="n">appfinder</span><span class="p">.</span><span class="n">app_from_name</span><span class="p">(</span><span class="s2">"Mjolnir"</span><span class="p">):</span><span class="n">kill</span><span class="p">()</span> <span class="k">end</span><span class="p">Ù«</span>

  <span class="n">k</span> <span class="o">=</span> <span class="k">function</span><span class="p">()</span> <span class="n">hints</span><span class="p">.</span><span class="n">appHints</span><span class="p">(</span><span class="n">appfinder</span><span class="p">.</span><span class="n">app_from_name</span><span class="p">(</span><span class="s2">"Emacs"</span><span class="p">))</span> <span class="k">end</span><span class="p">Ù«</span>
  <span class="n">j</span> <span class="o">=</span> <span class="k">function</span><span class="p">()</span> <span class="n">hints</span><span class="p">.</span><span class="n">appHints</span><span class="p">(</span><span class="n">window</span><span class="p">.</span><span class="n">focusedwindow</span><span class="p">():</span><span class="n">application</span><span class="p">())</span> <span class="k">end</span><span class="p">Ù«</span>
  <span class="n">ec</span> <span class="o">=</span> <span class="n">hints</span><span class="p">.</span><span class="n">windowHints</span>
<span class="p">}</span>

<span class="c1">-- launch and focus applications</span>
<span class="n">fnutils</span><span class="p">.</span><span class="n">each</span><span class="p">({</span>
  <span class="p">{</span> <span class="n">key</span> <span class="o">=</span> <span class="s2">"o"</span><span class="p">Ù«</span> <span class="n">app</span> <span class="o">=</span> <span class="s2">"MacRanger"</span> <span class="p">}Ù«</span>
  <span class="p">{</span> <span class="n">key</span> <span class="o">=</span> <span class="s2">"e"</span><span class="p">Ù«</span> <span class="n">app</span> <span class="o">=</span> <span class="s2">"Google Chrome"</span> <span class="p">}Ù«</span>
  <span class="p">{</span> <span class="n">key</span> <span class="o">=</span> <span class="s2">"u"</span><span class="p">Ù«</span> <span class="n">app</span> <span class="o">=</span> <span class="s2">"Emacs"</span> <span class="p">}Ù«</span>
  <span class="p">{</span> <span class="n">key</span> <span class="o">=</span> <span class="s2">"i"</span><span class="p">Ù«</span> <span class="n">app</span> <span class="o">=</span> <span class="s2">"iTerm"</span> <span class="p">}Ù«</span>
  <span class="p">{</span> <span class="n">key</span> <span class="o">=</span> <span class="s2">"m"</span><span class="p">Ù«</span> <span class="n">app</span> <span class="o">=</span> <span class="s2">"Airmail"</span> <span class="p">}</span>
<span class="p">}Ù«</span> <span class="k">function</span><span class="p">(</span><span class="n">object</span><span class="p">)</span>
    <span class="n">definitions</span><span class="p">[</span><span class="n">object</span><span class="p">.</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="k">function</span><span class="p">()</span> <span class="n">application</span><span class="p">.</span><span class="n">launchorfocus</span><span class="p">(</span><span class="n">object</span><span class="p">.</span><span class="n">app</span><span class="p">)</span> <span class="k">end</span>
<span class="k">end</span><span class="p">)</span>

<span class="n">init</span><span class="p">()</span></code></pre></figure>

'),('http://thume.ca/2014/09/08/creating-a-keyboard-1-hardware/', 'Designing and Building a Keyboard: The Body', '1410134400000',  13, '
<p>This summer I set myself the task of designing and building a chording keyboard from scratch. Chording keyboards use a different system of typing where you type entire syllables or words in a single stroke by pressing multiple keys at a time. My keyboard is designed to use a system similar to <a href="http://velotype.com/en/">Velotype</a>. This should theoretically let me type at up to 200WPM.</p>

<p>To spoil the ending I managed to build a pretty sweet keyboard that I am using to type this very article. HoweverÙ« I havenâ€™t written the chording software yet so Iâ€™m currently using it as a Dvorak keyboard.</p>

<p><strong>Update 10/10/2016:</strong> Iâ€™ve been using the keyboard for 2 years now. I wrote the <a href="https://github.com/trishume/PolyType">chording firmware</a> and tried learning it but after a month I was still typing at 3wpm. But I did end up really liking the keyboard layout used normally so itâ€™s still my primary keyboard. Iâ€™ve also upgraded the hardware with <a href="https://twitter.com/trishume/status/774977727342444544">cool RGB LEDs</a>. I use the palm keys with a <a href="https://github.com/trishume/SublimeTect">set of Sublime Text shortcuts</a> that is like VIM but the mode is set by the physical state of my palms. This integrates better with the mouseÙ« I never type in the wrong modeÙ« and itâ€™s better for quickly doing something in another mode.</p>

<p><img src="/assets/postassets/keyboardhw/finished-3.jpg" alt="Finished Keyboard" /></p>

<p>When I started the project I thought it might take 2 weeks to finish the hardware and then I would spend the rest of the summer on software. Boy was I wrong! It took me a month to finish the case and another month of evenings spent soldering after work. I managed to complete the hardware before heading off to Waterloo but only barely.</p>

<p>This post will be mostly about the case and key switchesÙ« next Iâ€™ll write about the electronicsÙ« then the layout (once I design it)Ù« and then the software (once I write it).</p>

<p><img src="/assets/postassets/keyboardhw/finished-4.jpg" alt="Case" /></p>

<h1 id="overview">Overview</h1>

<h2 id="the-keys">The Keys</h2>

<p>One thing about chording keyboards is that since you have to press many keys at the same timeÙ« it is nice to have very low activation force key switches so that your hands donâ€™t have to work as hard to press more switches.</p>

<p>The Velotype uses custom rubber dome switches with a 15g activation force but those require custom molded silicone sheets and a PCB. Instead I modified Cherry MX Red key switchesÙ« which are already some of the lowest force switches out thereÙ« and I cut the springs down from 1.5cm to 1.0cm. This gave them an activation force of around 20g instead of 45g.</p>

<p>For the key caps I pulled the black blank ones off my Das Keyboard since I figured that buying and shipping a new set of key caps would cost more than the resale value of my (now redundant) Das.</p>

<p><img src="/assets/postassets/keyboardhw/stripped_das.jpg" alt="Case" /></p>

<h2 id="the-case">The Case</h2>

<p>The case was made with layered acrylic sheets cut on <a href="http://biblioottawalibrary.ca/en/ImagineSpace">the laser cutter at my local library</a>. The layers are bolted together with machine screws with rubber feet at the bottom. The layout is my own design inspired by the Velotype Pro and the Erogdox. The top and bottom layers are thin black acrylic to give the keyboard a nice look and hide the internals. Features include a carrying handleÙ« palm keys and a space for a LCD screen.</p>

<p><img src="/assets/postassets/keyboardhw/case.jpg" alt="Case" /></p>

<h2 id="the-design">The Design</h2>

<p>I did all the design in the (free!) student edition of AutoCad. I used cherry switch hole specs posted on the <a href="http://geekhack.org/">GeekHack</a> forum that I fine tuned by laser cutting small test plates. Before doing the final cut in acrylic I cut one prototype in cheap MDF and also a one-button test keyboard in acrylic. This let me catch a couple design flaws and fine tune my CAD model before the final cut.</p>

<p><img src="/assets/postassets/keyboardhw/model-screen.png" alt="Case" /></p>

<p>My original plan was to draw up the CAD files in two days and then cut them the next dayÙ« then spend the next couple days soldering. Turns out I dramatically underestimated the difficulty of designing quality hardware. It took me a week to do the CAD models alone. I had to design the layoutÙ« print multiple tests on paper to test ergonomicsÙ« then draw up the key cutoutsÙ« layoutÙ« case and internal pockets in AutoCad. Then I spent days tweaking the kerfÙ« screw placement and PCB pocket size so that everything would fit together well.</p>

<h1 id="the-full-story---detailed-build-log">The Full Story - Detailed Build Log</h1>

<h2 id="the-original-plan-backstory-skip-if-you-want">The Original Plan (BackstoryÙ« skip if you want)</h2>

<p>This whole crazy quest started when I got the idea of trying to build a mag-lev hall effect keyboard. The switches would levitate on magnets inside shafts above a hall effect sensorÙ« this would allow very smooth low force switches that gave back analogue signals. This would allow cool things like variable-speed WASD gaming and detection of different typing styles.</p>

<p>I made some crappy prototypes with fridge magnets and paper and it seemed promising so I ordered some hall effect sensors off Digikey and used OpenSCAD to design some 3D models for key switches. I 3D printed them at my libraryÙ« the first time didnâ€™t turn out well but I tweaked the model and got a decent print. HoweverÙ« the switches didnâ€™t feel very good since smooth shaft sliding requires very tight tolerances that even the very nice SLA 3D printer I was using couldnâ€™t make switches that didnâ€™t wobble and scrape.</p>

<p>I ended up abandoning the project because after further testing I discovered that the magnets in adjacent switches would repel each other causing very weird responses and things like keys being twice as hard to press down when the adjacent one was down. This problem could only be solved by using springs to keep the key up and then switching to weaker magnetsÙ« or by shielding each key with something like mu-metal. This is a purely mechanical problemÙ« the hall effect sensors actually werenâ€™t interfered with much by adjacent magnets because they only measure the field strength in one axis.</p>

<p><img src="/assets/postassets/keyboardhw/maglevs.jpg" alt="Case" /></p>

<h2 id="the-real-quest-begins">The Real Quest Begins</h2>

<p>After giving up on mag-lev I tried cutting the springs on a cherry brown switch and ended up with a decent low force key switch. Thus started the quest to build a custom chording keyboard. Goals included low forceÙ« low costÙ« ergonomic designÙ« full programmabilityÙ« and the ability to use it as a normal keyboard.</p>

<p>I started out by doing a bunch of research on other peopleâ€™s custom keyboards and reading Geekhack threads and blog posts. I used some ideas from the <a href="https://www.ergodox.io/">Ergodox</a>Ù« <a href="https://github.com/technomancy/atreus">the Atreus</a>Ù« and of course the Velotype Pro.</p>

<h2 id="drawing-up-the-cad-file">Drawing up the CAD File</h2>

<h3 id="the-layout">The Layout</h3>

<p>I started my layout off by just setting up a massive rectangular grid of keys in AutoCadÙ« I then printed it off at actual size and used my own hand to stagger the columns to match my fingers. One major difference from normal keyboards is that the home row position of the pinky finger is actually on physical row down from the middleÙ« an idea I took from the Velotype. This position is much nicer ergonomically given how short the pinky fingers areÙ« it is just unconventional.</p>

<p><img src="/assets/postassets/keyboardhw/homerow.png" alt="Case" /></p>

<p>I then used the same printÙ« measureÙ« adjust modelÙ« repeat technique to place the thumb cluster and palm keys. The final step was tweaking the layout so that it could use a standard key cap setÙ« this meant doing things like using 1.25U keys for the thumbs instead of 1.5 because there are more of them. While doing this I also kept in mind that each row of key caps has a different profile.</p>

<p>The final step was to mirror the one sided layout to the other side and then measure the natural distance between my hands in order to determine the separation.</p>

<h3 id="the-rest-of-the-case">The Rest of The Case</h3>

<p>After drawing up the layout I had to design the rest of the case. I drew a box around the outside and then some interior pockets for the wiring. I measured the piece of perfboard and the LCD I had decided on and then put in pockets for those and added channels to the wiring pockets. Then I rounded all the corners to reduce the number of pointy edges as well as the risk of the acrylic cracking.</p>

<p><img src="/assets/postassets/keyboardhw/spacer.png" alt="Case" /></p>

<p>Finally I placed the bolt holes in locations that were structurally important and also were solid on all layers. I then measured where the screw holes were on the circuit boards and put those in on the bottom for mounting.</p>

<p>I had drawn the various pockets on different layers in AutoCad so I created a viewport for each physical layer of acrylic and then just set which layers I wanted drawn on each viewport. Bolt holes on all layersÙ« switch holes on the plate layerÙ« etcâ€¦</p>

<h2 id="acquiring-materials">Acquiring Materials</h2>

<p>Now that I had my CAD files it was time to acquire the acrylic I needed to cut them in. I called up the <a href="http://www.lairdplastics.ca/">Laird Plastics</a> in Ottawa and they had the acrylic I needed but only in $100 4 foot x 8 foot sheets. This was a great price per square foot but it was way more than I needed. So I checked out <a href="http://canusplastics.com/">Canus Plastics</a> and they had the exact acrylic thickness and colours I needed and they even cut me sheets of the size I wanted while I waited. I also went around the back to their dumpster and found some nice off-cuts for practice material.</p>

<p>I got 2 sheets of 43cmx24cm eighth inch black acrylic and 3 sheets of quarter inch 43cmx24cm clear acrylic for $50.</p>

<p><img src="/assets/postassets/keyboardhw/canus-loot.jpg" alt="Case" /></p>

<p>I also went to Home Depot and bought the right size of machine screws as well as some $3 sheets of MDF in the same thicknesses as my acrylic.</p>

<h2 id="stop-prototype">StopÙ« Prototype!</h2>

<h3 id="switch-cutout-kerf">Switch Cutout Kerf</h3>

<p>The first thing I wanted to tune was the tightness of my switch cutouts. My acrylic plate was quarter inch thick clear acrylic which is to thick for the switches to snap in so they are friction fit. This meant I had to get the fit very close because I had no PCB to hold the switches in and I didnâ€™t want them popping out if I tried to take off the key caps or turned the keyboard upside down.</p>

<p>I ended up printing 6 different small acrylic test sheets including various insets and resizings of different cherry switch cutout shapes. I measured the results that came off the laser cutter with calipers and found that the laser had 0.2mm kerf in the material I was using.</p>

<p>After adjusting for the kerf I had to figure out how tight I wanted the switch holes. Here are the results of my testingÙ« measured against the Cherry width spec of 19.05mm with calipers:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-0.15mm : Very loose fitÙ« some playÙ« can"t pull keycap without pulling out switch.
Keyboard made like this would fall apart easily if it didn"t have a PCB.
-0.10mm : Same as -0.15mm maybe imperceptibly tighter
0.00mm : Cherry Spec. Holds switches to be very robust without a PCB. Almost zero play.
Still not tight enough to pull a keycap without pulling out switch.
+0.05mm : Very nice solid fit. Can pull a keycap off without pulling switch.
+0.10mm : Quite tight without stressing switch.
Can easily pull keycap off without feeling switch move.
Takes effort to pop out.
I"m going to use this for my board since it won"t have a PCB.
</code></pre></div></div>

<p>For my final version I decided on the +0.1mm inset (0.3mm including accounting for the laser kerf.).</p>

<p>I also printed some plates to test friction mounting the stabilizers. Turns out you canâ€™t friction mount them and you have to make the slots wider and hot glue them. My CAD models include large stabilizer slots but I didnâ€™t end up installing the stabilizers since they turned out to be unnecessary.</p>

<p><img src="/assets/postassets/keyboardhw/test-plates.jpg" alt="Case" /></p>

<h3 id="cute-lil-mini-keyboard">Cute Lilâ€™ Mini Keyboard</h3>

<p>To test the acrylic layeringÙ« the bolt holes and the border widthÙ« and cutting the acrylic I drew up a one key test keyboard that I printed and bolted together. It helped me discover that my bolt holes were too close to the edges for my rubber feet to fit. It also looks super cute. I left a hole for cable so that I can eventually hook it up in case I come up with a good idea for it.</p>

<p><img src="/assets/postassets/keyboardhw/mini-board.jpg" alt="Case" /></p>

<h3 id="mdf-prototype">MDF Prototype</h3>

<p>So that I didnâ€™t mess up my $50 acrylic sheets I did a test cut in $4 dollars worth of crappy MDF/hardboard and Iâ€™m glad I did. This prototype helped me discover that the USB cable didnâ€™t really fit into the case cutout and that I had forgotten to turn some switch cutouts sideways. It also helped me be confident that the final cuts would turn out as I wanted them to.</p>

<h2 id="modifying-switches">Modifying Switches</h2>

<p>After I cut the MDF prototype I spent 2 one hour sessions in the basement modifying key switches. For each switch I opened it using toothpicksÙ« took out the spring and put it up against a rulerÙ« grabbed it with my wire snippers at the correct point and moved it over a dish and snipped it. Then I put the switch back together and tested the feel. If a switch felt too light I tested it with a multimeter to make sure it didnâ€™t stay down when I pressed itÙ« if it did I tossed it into a rejects pile.</p>

<p>I only modified 46 switchesÙ« which was enough for all the keys used in chordingÙ« the extra keys which are only used for normal typing and special characters are unmodified. I did all 46 at around 1.5 minutes per switch median time with only 5 rejects (it took significantly longer for some switches because of additional testing).</p>

<p>The source switches were <a href="http://mechanicalkeyboards.com/shop/index.php?l=product_detail&amp;p=806">a bag of 110 Cherry MX Reds</a> I bought for $50. I chose Cherry Reds because they work better for low force modification since they donâ€™t have a tactile bump. When I tried modifying Browns sometimes the switch would get stuck on the bump on the way up.</p>

<p>After modifying the switches I mounted them in my MDF prototype with the low force switches in the right places and normal switches everywhere else. Afterwards I put my Das Keyboard key caps on making sure to use the correct rows. I then had a feel-complete version of my keyboard that I could try typing onÙ« it was pretty nice!</p>

<p><img src="/assets/postassets/keyboardhw/mdf-proto.jpg" alt="Case" /></p>

<h2 id="final-cutting">Final Cutting</h2>

<p>With all my prototyping done I biked to the library with my CAD files and acrylic sheets and spent an hour sitting next to a laser cutter while reading Hacker News and occasionally switching plates and printing a new file and sometimes watching the laser cutter slowly turn a featureless sheet into the keyboard I had been working on for a month.</p>

<p>Everything went excellently and I took my sheets homeÙ« bolted them together and tested that things fit. I then started transferring switches and keycaps from their respective positions on the MDF prototype to the final acrylic plate.</p>

<p><img src="/assets/postassets/keyboardhw/transfer.jpg" alt="Case" /></p>

<p>One interesting thing I discovered was how susceptible to fingerprintsÙ«
hair and dust the layered acrylic design is. It doesnâ€™t affect the functionality but it sure looks ugly. When assembling the layers I had to wear rubber gloves and wipe each layer down with a microfiber cloth before bolting them together.</p>

<p>After a while I had a look and feel complete version of my keyboardÙ« now I just had the soldering to doÙ« but that could wait. At this point I was halfway through the summer and I went on vacation from working during my vacation. I took my keyboard shell with me and occasionally practiced typing on the low force switchesÙ« just with the keyboard on my lap sitting by a lake with nothing connected to it.</p>

<h2 id="electronics">Electronics</h2>

<p>For the second month of the summer I worked at Shopify and every day when I got home I worked on designing the electronics and soldering up the key matrix and controller. Thereâ€™s a lot more to tell about this process but this post is already 2Ù«500 words.</p>

<p><em><strong>Coming eventually</strong>Ù« Part 2 â€œDesigning and Building a Keyboard: The Mindâ€Ù« in which I will detail the wiringÙ« controller and basic firmware that make bring it to the functional state it is in now.</em></p>

<p><strong>Update 10/10/2016:</strong> Sorry I still havenâ€™t written the other parts. The firmware is <a href="https://github.com/trishume/PolyType">on Github</a> though. The electronics is a key matrix connected to a Teensy 3.1 and a MCP23017 multiplexer for more outputs.</p>

<p><img src="/assets/postassets/keyboardhw/electronics.jpg" alt="Case" /></p>

<h2 id="conclusion">Conclusion</h2>

<p>With everything includedÙ« including prototyping materialsÙ« extra backup parts and shipping costs the total price came to $233. This figure does not include the dozens of hours of my own labor I put in.</p>

<p>I posted all the CAD files on <a href="https://github.com/trishume/KeyboardCAD">Github</a> including the AutoCAD files for the caseÙ« the Fritzing file for the controller board and the ruby scripts that generate OpenSCAD scripts that generate mag-lev key models.</p>

<p>For funÙ« hereâ€™s the checked off items of my To-Do list including most of the building and debugging steps (after a certain point when I started th e list). Donâ€™t expect to understand itÙ« it was written for my own reference.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- Design small one switch test layers
- Design PolyType logo plate (didn"t turn out well)
- Go to Home Depot and buy 6-32 machine screws&amp;nuts and 2"x2" MDF
- Laser cut switch test layers and logo plate in offcut acrylic
- Design circuit (to size perfboards properly)
- Test stabilizers on small acrylic test plate
- Disassemble Das Keyboard
- Finish full plate designs
- Use correct switch holes on plate design
- Modify 46 red switch springs.
- Add PCB holes to CAD file
- Cut MDF into 3 keyboard plate
- Order diodesÙ« memoryÙ« IO expander on digikey
- Fix layout to not use stabilized velo keys
- Laser cut new plate for test cake
- Laser cut finished plate design in MDF
- Test sizing of PCB in MDF
- Mount cherry switches in MDF plate and put das caps on them
- Test feel of entire layoutÙ« is last chance to change it.
- USB slot on clear top layer
- turn long thumb key slots sideways
- make display screw holes bigger
- move ring finger column down
- shorter USB slot
- Laser cut finished plate in Acrylic
- Test fit of all plates together
- Test fit of components in pockets
- Mount all switches
- Wire up key matrix rows
- Install stabilizers
- Buy female headers and PCB screws
- Wire up matrix columns
- Solder controller board
- Wire matrix to controller board
</code></pre></div></div>

<p>Stay tuned for further parts of this saga!</p>
'),('http://thume.ca/2014/06/25/a-tour-of-the-ruby-standard-library/', 'A Tour of the Ruby Standard Library', '1403654400000',  13, '
<p>Recently I gave a full length talk at <a href="http://ottawaruby.ca/">Ottawa Ruby</a> on highlights of the Ruby standard library. It has elements suited to both beginner and advanced Rubyists.</p>

<p>The Ruby standard library is huge and awesome and this talk was designed to show off some of the cool parts of it that are helpful in everyday Ruby programmingÙ« and some that are mostly just useful for trivia.</p>

<iframe allowfullscreen="" mozallowfullscreen="" webkitallowfullscreen="" src="/rubytour/embedder.html#index.html" width="660" height="370" style="border:3px solid black;">
</iframe>

<p>I gave the talk on June 24Ù« 2014.</p>
'),('http://thume.ca/2013/12/09/math-summative-program/', 'Hacking Math Homework', '1386547200000',  13, '
<p>Many high school students complain about boring and repetitive homeworkÙ« but Iâ€™ve found a fun way of dealing with this that I find actually helps me understand concepts even better.
When faced with large rote assignments I write programs to complete the homework like no human can: instantlyÙ« perfectly and on a large scale.
In the past I have written written <a href="/2013/01/24/hacking-english-class/">Literary Analysis Visualizations</a>Ù« Punnet Square generators and <a href="http://github.com/trishume/handyGraph">Graphing Programs</a>.</p>

<p>Most of the time it takes way more time to write the program than it would take to do the homework but I end up learning a lot more and having more fun.
Recently I wrote my wrote my most outrageous program yetÙ« it took 10 times longer than it should have and blew away my teacher and class.</p>

<p>Part of my Advanced Functions class summative this year was to create a series of piecewise functions that when graphed produce
a picture. Some examples given were line drawings of a smiley face and the Batman symbol. But I had an idea that would go beyond the intended simple line drawings so I spent my weekend implementing it.</p>

<p>I wrote a program that takes an image and composes equations of varying densities into hundreds of massive piecewise functions
so that when you graph them on a very large canvas and zoom out they replicate the image in greyscale. The output looks like this:</p>

<p><img src="/assets/postassets/mathSummative/obama_small.png" alt="Obama" />
<a href="/assets/postassets/mathSummative/collage_small.png"><img src="/assets/postassets/mathSummative/collage_small.png" alt="Function Collage" /></a></p>

<h2 id="additional-resources">Additional Resources</h2>

<p>Another part of the program outputs a massive Latex document with all the large piecewise functions that produces a huge PDF.
You can <a href="/assets/postassets/mathSummative/summative.pdf">download a PDF</a> that explains all the parts and has some more examples.</p>

<h2 id="the-program">The Program</h2>

<p>The program is written in Python and uses matplotlibÙ« Numpy and Pillow.
Excuse the terrible code with the manual constantsÙ« global variables and terrible logic structure.
Not only was I learning Python while writing this but I had to finish the program by the next day and then
never use the program again.</p>

<script src="https://gist.github.com/7881306.js">
</script>

'),('http://thume.ca/2013/09/30/learning-dvorak/', 'Typing Faster', '1380499200000',  13, '
<p>What if you improved your typing speed from
<span class="TKAdjustableNumber" data-var="curWpm" data-min="5" data-max="100" data-step="5"> wpm</span>
to <span class="TKAdjustableNumber" data-var="newWpm" data-min="5" data-max="200" data-step="5"> wpm</span>?</p>

<p>Over <span class="TKAdjustableNumber" data-var="career" data-min="1" data-max="40"> years</span> typing <span class="TKAdjustableNumber" data-var="dailyTyping" data-min="5" data-max="500"> minutes</span> per work day you could:</p>

<ul>
  <li>Spend <b data-var="ratio2" data-format="%.2f"> times</b> as much time typing saving <b data-var="savedHours" data-format="%.0f"> hours</b>.</li>
  <li>Or type <b data-var="ratio1" data-format="%.1f"> times</b> as many words jumping from <b data-var="totalWords" data-format="%.2f"> million words</b> typing to <b data-var="newWords" data-format="%.2f"> million words</b>.</li>
</ul>

<p>If you earn <span class="TKAdjustableNumber" data-var="pay" data-min="1" data-max="400" data-format="$%.0f">â€‹</span> per hour the extra productivity is worth <b data-var="worth" data-format="$%.0f">â€‹</b>.</p>

<h2 id="learning-to-type-efficiently-in-3-weeks">Learning to Type Efficiently in 3 Weeks</h2>

<p>Are you satisfied with your current typing speed? Do you even know what speed you type at?
If you donâ€™t know go test yourself on <a href="http://www.keyhero.com/">KeyHero</a>Ù« Iâ€™ll wait.
Typing faster and in the correct way has many advantages including productivity gainsÙ«
ergonomics and ability to look at the screen while typing. HoweverÙ« not everyone can simply
practice typing and improve their speedÙ« sometimes more drastic action is required.
With the right method you can improve your speed from 25 wpm to 60 wpm in 3 weeks of casual effort like I did.
Two years later I now type properly at 80 wpm with no dedicated practice since those 3 weeks.</p>

<p>Most people improve their typing speed through practice on sites like <a href="http://www.keyhero.com/">KeyHero</a>.
This approach works in some cases but there are some cases where this approach is ineffective.
In order for your practice to be effective you have to continue typing faster and correctly afterwards during normal computer use.
For many years I typed at a dismal speed of 25 wpm with incorrect fingering and my eyes firmly focused on my keyboard.
I tried to practice typing correctly and would get up to 20 wpm without looking at the keyboard but as soon as I was done
and I wanted to program or chat with friends I would go back to my slightly faster but incorrect method of typing and lose my progress.
No matter how hard you practice if you immediately go back to looking at your keyboard or typing improperly afterwards you wonâ€™t get any faster.</p>

<p>Salvation came a couple years ago when I discovered a method of kicking out my typing crutches: learning <a href="http://en.wikipedia.org/wiki/Dvorak_Simplified_Keyboard">Dvorak</a>.
Dvorak is a keyboard layout with a much more efficient design with the most common letters on the home row.
It is supposedly more efficient but I couldnâ€™t care less about thatÙ« what mattered to me is that all the keys were in different positions and the labels on the keys were wrong.
I basically threw away everything I knew about typing and started afresh typing properly and efficientlyÙ« at 0 wpm.
After a weekend of studying I had learned the layout. In only a week I beat my previous speed. In 2 weeks I doubled it and in 3 weeks I was typing at 60 wpm.
InterestinglyÙ« I was only practicing about one hour per day. The important thing was that I never switched my computer off of Dvorak and did everything in the new layout.</p>

<p><img src="/assets/postassets/typing/Progress.png" alt="Progress Graph Sketch" /></p>

<p>By starting from the beginning on a keyboard layout where you canâ€™t cheat and look at keysÙ« you can eliminate
the bad habits that prevent you from becoming a fast typist.
If you look at your keyboard while you type you miss helpful auto-complete popups and typos you have madeÙ« leading to drastically lower effective wpm.
Not only this but if you truly need to look you are limiting your typing speed to how fast you can target the next letter.</p>

<p>Unlike ColemakÙ« the Dvorak layout is available by default on most versions of OSXÙ« Windows and Linux so even if you have to use someone elseâ€™s computer you can switch the layout.
You donâ€™t have to buy a special keyboard and you might even get ergonomic benefits from using a more efficient layout and not having to contort your fingers so much.
After a few years of using Dvorak I havenâ€™t had any problems with using other peopleâ€™s computers or keyboards.
You can always fall back on hunt and peck if you canâ€™t be bothered to change the layout setting.</p>

<p>If your typing speed is below 40wpm or you have to look at the keyboard I highly recommend you learn Dvorak to get rid of your bad habits and improve your speed.
This trick helped me immensely and if you have trouble typing quickly because of bad habitsÙ« it can help you too.</p>

<h2 id="specifics">Specifics</h2>

<p>To initially learn the basic layout so that I could type every letterÙ« albeit slowlyÙ« I used two methods.
I practiced with lessons on <a href="http://learn.dvorak.nl/">dvorak.nl</a> and printed off a sheet with the layout so that I could
memorize it away from the computer. I did this all in 2 days of focus so that I wouldnâ€™t have to switch back to QWERTY between
practices to get things done.</p>

<p>Once I could type everything I needed to I started using KeyHeroÙ« which is a nicer platform for both practicing and tracking your progress.
I also used Dvorak for everyday things like programming and writing. I was slow to begin with but very soon I could type faster than before.</p>

<script>
var tangle = new Tangle(documentÙ« {
    initialize: function () {
        this.curWpm = 30;
        this.newWpm = 80;
        this.career = 10;
        this.dailyTyping = 30;
        this.pay = 40;
    }Ù«
    update: function () {
        this.ratio1 = this.newWpm / this.curWpm;
        this.ratio2 = 1.0 / this.ratio1;

        this.totalMins = this.career * 220 * this.dailyTyping;
        this.totalHours = this.totalMins / 60;
        this.newHours = this.totalHours * this.ratio2;
        this.savedHours = this.totalHours - this.newHours;

        this.totalWords = this.totalMins * this.curWpm / 1000000;
        this.newWords = this.totalWords * this.ratio1;

        this.worth = this.savedHours * this.pay;
    }
});
</script>

'),('http://thume.ca/2013/05/17/best-search-engine/', 'The Best Search Engine For Programmers', '1368748800000',  13, '
<p>There are many different comparisons of
search engine results out there but I thought I would do one specifically geared
towards the audience I identify with: programmers.</p>

<p>Do note that these tests are not rigorous and are based on my
observations of which search engine delivers the best results from a
programmerâ€™s perspective for a number of programming related searches.</p>

<p>The tests were conducted using Google Chrome in Incognito mode while signed out
of any accounts I had with the site in question.</p>

<p>I will be comparing the following search engines:</p>

<ul>
  <li><a href="http://google.com/">Google</a></li>
  <li><a href="http://bing.com/">Bing</a></li>
  <li><a href="http://duckduckgo.com/">DuckDuckGo</a>: This will be particularly interesting since DDG has a number of
features geared towards geeks and programmers.</li>
  <li><a href="http://samuru.com/">Samuru</a>: A cool new search engine based on natural language processing.</li>
</ul>

<h2 id="1-slate">1. Slate</h2>

<p>Slate is a window management tool for OSX which I have <a href="/howto/2012/11/19/using-slate/">written about before</a>. The correct first result should probably be Slate magazine but the geeky result I am looking for is the window manager. Since Slate is not as popular as my other search terms I threw this one in as a tough start to the comparison.</p>

<h3 id="results">Results</h3>
<p>Google actually got it as the second result! I was so stunned by this that I
thought Google was tracking me even with incognito. But I got one of my non-geeky
friends to Google it and he got it as a result as well.
<img src="/assets/postassets/search/3-google.png" alt="Google" /></p>

<p>All the other search engines returned the magazine first and then the rock.</p>

<h3 id="winner">Winner</h3>
<p>Google by a long shot! I only tried this one because I thought none of them
would get it.</p>

<h2 id="2-chef">2. Chef</h2>

<p>If a programmer searches for â€œChefâ€ they are probably referring to the
automation platform by Opscode. What I am looking for is results that talk about
ChefÙ« preferably from OpsCode.</p>

<h3 id="results-1">Results</h3>
<p>All search engines had OpsCode Chef on the first page but only some had it in
the top 3.
<img src="/assets/postassets/search/1-google.png" alt="Google" />
<img src="/assets/postassets/search/1-bing.png" alt="Bing  " />
<img src="/assets/postassets/search/1-ddg.png" alt="DDG   " />
<img src="/assets/postassets/search/1-samuru.png" alt="Samuru" /></p>

<h3 id="winner-1">Winner</h3>
<p>Google was the only search engine that returned Chef in the top 3 results and it
put it as the first result.</p>

<h2 id="3-node">3. Node</h2>

<p>This is an interesting one since even as a programmer it is tough to figure out
if the correct result is a networking node or Node.js.</p>

<h3 id="results-2">Results</h3>
<p><img src="/assets/postassets/search/2-google.png" alt="Google" />
<img src="/assets/postassets/search/2-bing.png" alt="Bing  " />
<img src="/assets/postassets/search/2-ddg.png" alt="DDG   " />
<img src="/assets/postassets/search/2-samuru.png" alt="Samuru" /></p>

<h3 id="winner-2">Winner</h3>
<p>Depends on your personal preferences. Google and Samuru put nodejs.org first and
Bing and DDG put networking nodes first. Bing is the only one that does not
mention both.</p>

<h2 id="4-underscore">4. Underscore</h2>

<p>Should refer to underscore.js. No screenshots for this one because I have
already made you scroll too much.</p>

<p><strong>Google</strong>: 2/3 including top result are underscore.js
<strong>DuckDuckGo</strong>: 1/3
<strong>Bing</strong>: 0/3
<strong>Samuru</strong>: Samuru gave underscore.js as third result on first search but
because of the way the engine works it gave 3 articles about the character 30s
later after it had done more processing.</p>

<h2 id="5-ruby">5. Ruby</h2>

<p>InterestinglyÙ« every search engine got the Ruby language as the top result
except for BingÙ« which gave the gem as the top result.</p>

<h2 id="overall-winner">Overall Winner</h2>

<p>Google is the only search engine that returned the results that a programmer
would be looking for every time. It seems the worst of the 4 search engines was
BingÙ« which got many things and even something as simple as Ruby wrong.</p>

'),('http://thume.ca/2013/05/01/too-many-projects-not-enough-pro/', 'Too Many ProjectsÙ« Not Enough pro', '1367366400000',  13, '
<p>I have too many projectsÙ« so I started a new project to solve my problems.
This project is a <a href="http://github.com/trishume/pro">little tool called pro</a> which allows you to easily deal with all
your git repositories.</p>

<p>It has a handful of very useful featuresÙ« each of which solves a problem that I
have experienced. I imagine they will be useful to others as well. You can get
<code class="language-plaintext highlighter-rouge">pro</code> by running <code class="language-plaintext highlighter-rouge">gem install pro</code>.</p>

<p>Do note that a Unix system is required to use thisÙ« so it wonâ€™t work on Windows
without Cygwin.</p>

<h2 id="cding-to-a-projects-repository">CDâ€™ing to a projectâ€™s repository</h2>

<p>Cdâ€™ing to your projects is harder than it should be.
There are <a href="https://github.com/rupa/z">many tools</a> that try and solve this
problem using frequency and recency.
Pro solves the problem by fuzzy searching only git repositories.</p>

<p>The <code class="language-plaintext highlighter-rouge">pd</code> command allows you to instantly CD to any git repo by fuzzy matching
its name.
You can install the <code class="language-plaintext highlighter-rouge">pd</code> tool (name configurable) by running <code class="language-plaintext highlighter-rouge">pro install</code>.
Once you have it you can do some pretty intense cdâ€™ing:</p>

<p><img src="/assets/postassets/pro/pd_screen.png" alt="pd demo" /></p>

<h2 id="state-of-the-repos-address">State of the Repos Address</h2>

<p>Oftentimes I find myself wondering which git repositories of mine still have
uncommitted changes or unpushed commits. I could find them all and run git
status but it would be nice to get a quick overview. <code class="language-plaintext highlighter-rouge">pro status</code> does this.</p>

<p><img src="/assets/postassets/pro/pro_status.png" alt="pro status" /></p>

<p>You can also run <code class="language-plaintext highlighter-rouge">pro status &lt;repo&gt;</code> to show the output of <code class="language-plaintext highlighter-rouge">git status</code> for a
certain repo.</p>

<h2 id="run-all-the-commands">Run all the commands!</h2>

<p>Wouldnâ€™t it be cool if you could run a command on all your repos and see a
summary of the output? Now you can!</p>

<p>You can do this with <code class="language-plaintext highlighter-rouge">pro run &lt;command&gt;</code>. If you donâ€™t pass a command it will
prompt you for one.</p>

<p>For exampleÙ« searching all your repos for ruby files:</p>

<p><img src="/assets/postassets/pro/pro_run.png" alt="pro run" /></p>

<p>Notice that it double checks before running so you donâ€™t accidentally run <code class="language-plaintext highlighter-rouge">rm -rf *</code> on all
your projects.</p>

<h2 id="the-pro-base">The Pro Base</h2>

<p>Pro can use a base directory to speed up its search for git repos. By default it
uses your home folder.</p>

<p>To set the base directory either create a file at <code class="language-plaintext highlighter-rouge">~/.proBase</code> containing the
base path or set the environment variable <code class="language-plaintext highlighter-rouge">PRO_BASE</code> to the path.</p>

<h2 id="conclusion">Conclusion</h2>

<p><code class="language-plaintext highlighter-rouge">pro</code> is a handy tool that makes working with lots of git repos much easier. If
you want to get it run <code class="language-plaintext highlighter-rouge">gem install pro</code>. You can also <a href="http://github.com/trishume/pro">check it out on Github</a>.</p>
'),('http://thume.ca/2013/04/10/the-best-programming-videogame/', 'The Best Programming Game', '1365552000000',  13, '
<p>Ever since I was in grade 4 I have been playing the worldâ€™s best programming
game. The game is highly rewardingÙ« an excellent way to learn programming
and itâ€™s even free!</p>

<p>This game has many advantages over other programming video games:</p>

<ul>
  <li>Like MinecraftÙ« it is open-ended and allows players to set their own
goals.</li>
  <li>It allows players to use any library and programming language they want to.</li>
  <li>The game can lead to real world rewards and recognition. It has MLG
players and top gamers can earn hundreds of thousands of dollars per year.</li>
  <li>It can run on any computer regardless of how recently it was made or what OS
it runs.</li>
  <li><strong>It even has multiplayer support!</strong> You can play with friends and even post your
solutions to the puzzles online.</li>
</ul>

<p>Have you guessed what game it is yet? Does it sound interesting?</p>

<p>The game is called â€œJust Friggin Programâ€ and it works like this:</p>

<ol>
  <li>Think of a program you would like to write.</li>
  <li>Use the internet to learn things.</li>
  <li>Write the program!</li>
  <li><strong>You beat the level!</strong> Repeat for the next level.</li>
</ol>

<p>I am now 17 and I have gotten a lot of fun out of playing this game for the last
8 years. I have learned everything I know about programming through playing and Iâ€™m sure many other programmers have too.
The best part is I have ended up with a <a href="http://github.com/trishume">portfolio of cool projects</a> while players
of other games just have their â€œlevels completedâ€ screen to show for it.</p>

<p><em>Instead of introducing children to brand new 3D â€œlearn-to-programâ€ games I suggest
the oldest game of them all as the best way to teach kids to programming.</em></p>
'),('http://thume.ca/2013/03/29/contributing-to-eclipse/', 'Contributing to Eclipse', '1364515200000',  13, '
<h2 id="background">Background</h2>

<p>When most programmers think of Eclipse they think of the Java IDE but Eclipse is
actually a huge group of projects with very little relation to each other except
that they are all managed by The Eclipse Foundation.</p>

<p>I had the privilege of working for <a href="http://eclipse.org/org/foundation">The Eclipse
Foundation</a> this past semester at school as a
High School
co-op job. The Foundation does not actually employ developers but since I was
working for free I was able to actually work on the code base with expert
guidance from my supervisor Wayne Beaton at the Foundation.</p>

<p>This was an interesting experience. I worked on fixing bugs in various Eclipse
projects including one that had been around for 11 years and likely affected
thousands of developers. In this article I hope to share some of the knowledge I
gathered about contributing to Eclipse projects.</p>

<p><strong>Edit:</strong> To clarifyÙ« I am not ranting about how bad my job was. I thoroughly
enjoyed my time at The Eclipse Foundation. I also enjoy using Eclipse as an IDE.
Yes it is slow and RAM-intensive but itâ€™s amazing auto complete and content
assist make it invaluable for Java programming. I use VIM for every other language.</p>

<h2 id="one-does-not-simply-compile-eclipse">One Does Not Simply Compile Eclipse</h2>

<p>For my first week my supervisor had the idea of using me to figure out how difficult
it is to be a new contributor to Eclipse. I was given a bug to fix and no other
instruction.</p>

<p>I started off with the assumption that I would have to compile Eclipse. Which
seemed reasonable enough given my experience with other open source projects.</p>

<p>UnfortunatelyÙ« I was <strong>dead wrong</strong>. I spent many hours reading through outdated
wiki pages and filling up my hard drive with build files until my supervisor
eventually told me what I had only seen briefly mentioned in a paragraph full of
adjectives: <strong>you do not need to compile Eclipse to develop it</strong>.</p>

<h2 id="the-one-true-path">The One True Path</h2>

<p>Eclipse is actually developed within Eclipse using a plugin called the Plugin
Development Toolkit (PDT). This sounds like it is only useful for developing
pluginsÙ« and it is.</p>

<p>The thing is Eclipse is actually almost entirely made up of Eclipse plugins.
This is an excellent architecture once you start developing for it but it is not
necessarily easy for new contributors.</p>

<h2 id="working-on-an-eclipse-project">Working on an Eclipse Project</h2>

<p>Before following this procedure make sure you have the PDT plugin and the EGit
plugin installed.</p>

<p>This procedure only applies to plugins that are plugins to the Eclipse IDE.</p>

<ol>
  <li>Clone the right repository in EGit.
    <ul>
      <li>You can find all the repositories at <a href="http://git.eclipse.org/c/">http://git.eclipse.org/c/</a></li>
      <li>You only need the repository you will be working on directlyÙ« it will use
 the binary plugins in your Eclipse installation for dependencies.</li>
      <li>Make sure to select the import projects box in the clone dialog.</li>
    </ul>
  </li>
  <li>Create a new â€˜Eclipse Applicationâ€™ run configuration.</li>
  <li>Make changes to the code and run or debug your configuration.</li>
</ol>

<p>This will launch another copy of Eclipse with the changes that you have made.
You can even set breakpoints and run it in the debugger.</p>

<h2 id="bugzilla">Bugzilla</h2>

<p>All Eclipse bugs are tracked on <a href="http://bugs.eclipse.org/">http://bugs.eclipse.org/</a>. They use the loose
definition of the term â€˜bugâ€™ that includes feature requests and things that
should be made better.</p>

<p>Any code contribution you make as a non-commiter (which you probably are if you
are reading this article) must be made through Bugzilla. If you write a new feature
and want to contribute it you should create a new bug saying the feature should
be added and immediately submit a patch file.</p>

<p>You can either submit a patch by attaching a patch file to the bug or on some
projects by submitting a pull request with the bug id in the title to the Github
mirror of the project. Keep in mind that not all projects have active committers
on Github to see your pull request so you may want to link to it from the bug.</p>

<h3 id="next-steps">Next Steps</h3>

<p>With any luck a committer will see your patch and write a comment about it.
This could take anywhere from a day to many months depending on how active the
project is.</p>

<p>On some of my patches I got a helpful response within hoursÙ« on others I only
got a reply weeks later and some of my patches are still sitting there to this
dayâ€¦</p>

<p>The committer may recommend some changes to your patch to fix bugs or make it better.
Once your patch is good enough the developer will commit it. They may ask you
some questions about originality or have you fill out a form as part of the
intellectual property process. I think my supervisor said they should have had me fill out a form but they never did.</p>

<p>Congratulations! You may now enjoy the warm fuzzy feeling that comes from
contributing to an Eclipse project!</p>

<h2 id="my-own-journey">My Own Journey</h2>

<p>I submitted patches for many bugs during my time at The Foundation.
I fixed many small bugs like having the Javadoc for a function show up in the
Javadoc view when you select it with autoComplete.</p>

<p>Some of my larger achievements:</p>

<ul>
  <li>Helping fix bugs related to Retina displays so that Eclipse displays crisply
on new Retina MacBook Pros.</li>
  <li>Updating the Eclipse Ruby DLTK project to support debugging ruby 1.9+ using
the â€˜debuggerâ€™ gem instead of the outdated â€˜ruby-debugâ€™ gem on 1.8.</li>
</ul>

<p>My biggest achievement was fixing an 11 year old bug that affects any Eclipse
user who has ever had to forcefully stop Eclipse and then lost their place in
what they were working on. <a href="https://bugs.eclipse.org/bugs/show_bug.cgi?id=2369">Bug 2369</a>.</p>

<p>Eclipse is very good at auto-saving state when it is shut down properly but many
users like myself keep Eclipse open constantly and only ever start it up again
when it crashes or our computer crashes.</p>

<p>The reason nobody experienced had taken it on was probably because it was very
difficult. I toiled for weeks chasing through layer upon layer of abstraction trying to
untie the workbench save code from the shutdown code.</p>

<p>I eventually settled upon copying the entire workbench model and then cleaning
up the parts that were not supposed to be persisted in the copy. I gradually
found what parts had to be removed from the model by chasing the causes of
various duplicate menu items and toolbars.</p>

<p>I managed to fix the bug just one week before my coop term ended. And I got to
feel that warm fuzzy open source contribution feeling knowing that I made a
difference people would notice. And they did:</p>

<div>
<blockquote class="twitter-tweet"><p>@<a href="https://twitter.com/mmmandel">mmmandel</a> wowÙ« a 4 digit bug number. You can almost see the evolution of the platform UI team by reading through the comments.</p>&mdash; Ian Bull (@irbull) <a href="https://twitter.com/irbull/status/312241966857482240">March 14Ù« 2013</a></blockquote>
<script src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>

'),('http://thume.ca/2013/02/06/ottawa-ruby-lightning-talks/', 'Ottawa Ruby Lightning Talks', '1360108800000',  13, '
<p>I have attended the Ottawa Group of Ruby Enthusiasts (<a href="http://ottawaruby.ca/">http://ottawaruby.ca/</a>) for
about a year now. It has been a great place to meet other Ruby developers and
learn interesting things.</p>

<p>The group normally has a main speaker who gives a long talk and one or two 10 minute
lightning talks punctuated by breaks to eat pizza and talk. The main talk is
normally over Skype and the lightning talks are done by volunteers from the group.</p>

<p>I have given two lightning talks on topics which I believed I might know more
than other members. Both talks went well and Iâ€™ve decided to post the slides.
Be aware that I did do a significant amount of talking so you canâ€™t get the
whole message from just the slidesÙ« but they are better than nothing.</p>

<h2 id="edit-the-ruby-standard-library">Edit: The Ruby Standard Library</h2>

<p>I recently did a full length talk on the Ruby standard library.
You can find the slides at <a href="http://thume.ca/rubytour">http://thume.ca/rubytour</a>.</p>

<h2 id="ruby--programming-contests">Ruby + Programming Contests</h2>

<p>The first talk I did was on writing programming contests in Ruby. I write lots
of programming contests and have tried using a couple different languages for
them but keep coming back to Ruby.</p>

<script async="1" class="speakerdeck-embed" data-id="e41bf2e052d60130a4381231380e9e6b" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js">
</script>

<h2 id="ruby--shell-scripts">Ruby &gt; Shell Scripts</h2>

<p>My most recent talk which I gave last meeting was on using Ruby as a scripting
language to automate repetetive tasks.</p>

<script async="1" class="speakerdeck-embed" data-id="926bb4f052d60130870722000a1c41cd" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js">
</script>

<h2 id="developing-a-gem-in-20-minutes">Developing a Gem in 20 Minutes</h2>

<p>I live coded a simple Ruby gem using Bundler in 20 minutes and explained
some tricks and how easy it was to write Ruby Gems.</p>

<p><a href="https://gist.github.com/trishume/5d1ea89862e031a48434">Hereâ€™s a Transcript</a></p>

<h2 id="improv-lighting-talk">Improv lighting Talk</h2>

<p>I recently gave an improvised lightning talk prompted by the lack of other
lighting talks called â€œHow to do a lightning talk.â€ I talked about choosing a
topic that you feel you have unique knowledge of to give you more confidence and
how all that was really important was the confidence to go up there. Everything
else would work itself out.</p>
'),('http://thume.ca/2013/01/24/hacking-english-class/', 'Hacking English Class', '1358985600000',  13, '
<p>I was sitting in English class last year and thinking about how English was
about as far away from programming as you can get. We were discussing the
significance of characters in the novel <em>Lord of the Flies</em> and I thought â€œI
wonder if I could write a program to analyze this bookÙ« that would be ironic.â€</p>

<p>So that evening I wrote a Ruby script that analyzed the occurences of characters
names in <em>Lord of the Flies</em> and graphed it over time. It was a fun graphÙ«
especially the most noticable feature being references to â€œPiggyâ€ suddenly dropping.</p>

<p>I went on to write another script to analyze <em>Lord of the Flies</em> as well as
other scripts during English class this year. Here are some of the ones I have
come up withÙ« starting with the most recent.</p>

<p>Most recently I wrote a program that reads entire stories and generates passages that
capture the texture of the story using Markov Trees.</p>

<p><img src="/assets/postassets/hackEnglish/markov-poster.png" alt="Markov Stories" /></p>

<p>In grade 11 my project was analyzing the most common colours in <em>The Great Gatsby</em>.
My teacher thought that yellow would be the most common but it turns out to be
white.</p>

<p><img src="/assets/postassets/hackEnglish/Colours-of-Gatsby.png" alt="Gatsby Colours" /></p>

<p>My other work this year was highlighting important words in the poem <em>Beowulf</em>.</p>

<p><a href="/assets/postassets/hackEnglish/Beowulf.png"><img src="/assets/postassets/hackEnglish/Beowulf.png" alt="Charged Words in Beowulf" /></a></p>

<p>As well as my two <em>Lord of the Flies</em> graphs.</p>

<p><img src="/assets/postassets/hackEnglish/lotf-1.png" alt="Lotf timeline" /></p>

<p>The second one shows words that appear close togetherÙ« the saturation indicates
how often they occur close together.</p>

<p><a href="/assets/postassets/hackEnglish/lotf-2.png"><img src="/assets/postassets/hackEnglish/lotf-2.png" alt="Lotf co-occurence" /></a></p>
'),('http://thume.ca/howto/2012/11/19/using-slate/', 'Using Slate: A Hacker"s Window Manager for Macs', '1353283200000',  13, '
<p><strong>Edit: Iâ€™ve recently switched to using <a href="http://mjolnir.io">Mjolnir</a> and have posted <a href="/howto/2014/12/02/using-mjolnir-an-extensible-osx-window-manager/">a new tutorial</a> on that.</strong></p>

<p>Switching windows with the keyboard on Mac OSX is hilariously inefficient: it
involves repeatedly pressing command+tab through millions of programs until you
get to the right one when you could have just clicked the window and been done
with it. Moving windows is no better so people have resorted to paying for tools
like SizeUp and Divvy. I used to have these problems too until I <s>switched to
Linux</s> discovered a program called Slate.</p>

<p>Fancy window management is no longer just for Linux users and their XMonad.</p>

<h2 id="enter-slate">Enter Slate</h2>

<p><a href="https://github.com/jigish/slate">Slate</a> is a keyboard-driven window management
program for Mac OSX. It is highly configurable and has tons of features. It has
permanently changed the way I use my Mac. Not only is it better than other
popular programs like DivvyÙ« SizeUp and MoomÙ« it beats their prices at being
<strong>free</strong>. Slate is the VIM/Emacs of window managers: it is less of a window
manager than a workflow changing tool you will never give up.</p>

<p>Slate has so much functionality that I think of it more as a shortcut-based
productivity tool than a window manager. Here is a sample of what it can do:</p>

<ul>
  <li><strong>Move/Resize/Shift windows:</strong> this can be done based on different screen size
fractions and even mathematical formulae. There are commands for practically
every window operation you can think of. It also supports the Divvy style
sizing grid.</li>
  <li><strong>Switch Windows:</strong> Slate can act as a complete replacement for command+tab in
many ways. I will talk about this more in the â€œWindow Switchingâ€ section.</li>
  <li><strong>Manage multiple monitors:</strong> Slate can move windows between monitors as well as
detecting your monitor configuration and automatically moving windows around
when you plug in an external monitor.</li>
  <li><strong>Save window layouts:</strong> Slate has a feature called â€œsnapshotsâ€ that allows you to
save your current window layout and restore it at any time. This is handy for
having different layouts for different projects/tasks.</li>
</ul>

<p>In this article I will describe the kind of things you can do with Slate and how
to configure it to do these things.</p>

<h2 id="switching-windows">Switching Windows</h2>

<p>Slate allows me to switch to any window I want in one shortcut and a single key
press. I can do this using a feature called â€œWindow Hintsâ€. If you have ever
used easyMotion for Vim or Vimperator/Vimium you will be familiar with this
concept.</p>

<p>When you press a shortcut (I use <code class="language-plaintext highlighter-rouge">cmd+e</code>)Ù« every window is instantly overlain with
a letterÙ« starting with those on the home row of your keyboard. By pressing the
letter over a window your focus is transfered to that window. For windows that
are hidden behind others the application icon is displayed in the overlay.</p>

<h3 id="as-usual-a-picture-is-worth-a-thousand-words">As usualÙ« a picture is worth a thousand words:</h3>
<p><a href="/assets/postassets/slate/windowhints.jpg"><img src="/assets/postassets/slate/windowhints.jpg" alt="Window Hints" /></a>
Notes: There is an option to overlay the icons with a dark background so that it
is easier to read the letters. Also note the fancy Slate managed window layout.</p>

<h3 id="switching-windows-even-faster">Switching Windows Even Faster</h3>

<p>Even though window hints are super fast there are some applications I switch to
and from so often that I wanted to be able to do it in one shortcut. LuckilyÙ«
Slate had my back. Using Slateâ€™s focus command I was able to give my most commonly used programs
their own switching shortcuts.</p>

<p>Inspired by <a href="http://stevelosh.com/blog/2012/10/a-modern-space-cadet/">this article</a>Ù« I use a
program called â€œPCKeyboard Hackâ€ (ironically mac only) to bind my caps lock key
to <code class="language-plaintext highlighter-rouge">command+option+shift+control</code> which I call â€œhyperâ€.  I use this binding to
manage all my custom shortcuts. For exampleÙ« <code class="language-plaintext highlighter-rouge">hyper+e</code> focuses on my browserÙ«
<code class="language-plaintext highlighter-rouge">hyper+u</code> focuses on my editorÙ« <code class="language-plaintext highlighter-rouge">hyper+i</code> focuses on iTermÙ« <code class="language-plaintext highlighter-rouge">hyper+m</code> focuses MailÙ«
etcâ€¦</p>

<h2 id="moving-windows">Moving Windows</h2>

<p>Slate has numerous commands for moving and resizing windows. I personally only
use a small portion of them. The most common ones are the classic â€œresize to
left halfâ€Ù« â€œresize to right halfâ€ and â€œfill the screenâ€; howeverÙ« I also have
ones like â€œmove this to my other monitorâ€ and â€œlayout my applications across
both monitors just the way I like themâ€. All of these are bound to keyboard
shortcuts.</p>

<p>I started off with Slate by rebinding my numpad to window movement commands.
Whenever I need to type a number I use the ones along the top of the keyboard so
before Slate the numpad was just useless buttons. I bound the numpad keys like
to resize windows in the direction they pointed. For exampleÙ« 5 was fullscreenÙ«
4 was left half and 6 was right half. The other buttons were quartersÙ« top and
bottom. Special numpad keys like * and + did things like display a window
resizing grid or arrange my windows in a certain layout.</p>

<p>I soon grew tired of reaching for my numpad so I added bindings to the home row
of my keyboard using the hyper key. This is more convenient for when I donâ€™t
have a numpad and it makes it so I donâ€™t have to reach over.</p>

<p>I have just scratched the surface of what Slate can do in terms of window
movement and resizingÙ« Slate has commands for resizing windows incrementallyÙ«
nudging windows aroundÙ« resizing to any fraction of the screen you want and even
moving windows to specific pixel positions.</p>

<p><a name="configuration">
</a></p>
<h1 id="configuring-slate">Configuring Slate</h1>
<h3 id="aka-how-do-i-do-all-this-cool-stuff">A.K.A How do I do all this cool stuff?</h3>

<p>Like many amazing tools such as VIM and ZSHÙ« Slate is configured through a
dotfile in the home directory called <code class="language-plaintext highlighter-rouge">.slate</code>. The <a href="https://github.com/jigish/slate">Slate
Readme</a> file has very detailed information on
configuring Slate so I am just going to show some tricks that let you do
specific things.</p>

<p>The <code class="language-plaintext highlighter-rouge">~/.slate</code> file is made up of different commands. The top level commands are:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">config</code>: for global configurations.</li>
  <li><code class="language-plaintext highlighter-rouge">alias</code>: to create alias variables.</li>
  <li><code class="language-plaintext highlighter-rouge">layout</code>: to configure layouts.</li>
  <li><code class="language-plaintext highlighter-rouge">default</code> :to default certain screen configurations to layouts</li>
  <li><code class="language-plaintext highlighter-rouge">bind</code>: binds a key to an action.</li>
  <li><code class="language-plaintext highlighter-rouge">source</code>: to load configs from another file.</li>
</ul>

<p>The <code class="language-plaintext highlighter-rouge">#</code> character is used for comment lines and <code class="language-plaintext highlighter-rouge">"</code> is used to delimit
strings.</p>

<h3 id="general-configuration">General Configuration</h3>

<p>Using the <code class="language-plaintext highlighter-rouge">config</code> commandÙ« you can set a variety of options that change how
slate works. Here are some you options that I like to set:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>config defaultToCurrentScreen true
# Shows app icons and background appsÙ« spreads icons in the same place.
config windowHintsShowIcons true
config windowHintsIgnoreHiddenWindows false
config windowHintsSpread true
</code></pre></div></div>

<h3 id="window-hints">Window Hints</h3>

<p>Along with the general configuration from the previous sectionÙ« all you have to
do to use window hints is bind the hint operation to a key. I like to use
<code class="language-plaintext highlighter-rouge">command+e</code> as it is easy to type and not used in many mac applications.</p>

<p>To do this put the following in your <code class="language-plaintext highlighter-rouge">.slate</code> file:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bind e:cmd hint ASDFGHJKLQWERTYUIOPCVBN # use whatever keys you want
</code></pre></div></div>

<p>You can choose which letters you want window hints to use. The letters will be
assigned to windows in the order specified by the <code class="language-plaintext highlighter-rouge">windowHintsOrder</code> config
option. If you have more windows than there are letters specifiedÙ« some hints
will not be shown. I suggest you start with either the home row of your keyboard
or all the keys on one side of the keyboard so you only need one hand.</p>

<h3 id="window-grid">Window Grid</h3>

<p>If you are a fan of the Divvy style window positioning grid Slate can do
that too. To bind the window grid to a key use a command like:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bind g:cmd grid padding:5 0:6Ù«2 1:8Ù«3
</code></pre></div></div>

<p>This particular command binds <code class="language-plaintext highlighter-rouge">command+g</code> to show a 6x2 grid on the first
monitor (monitor <code class="language-plaintext highlighter-rouge">0</code>) and a 8x3 grid on the second monitor (monitor <code class="language-plaintext highlighter-rouge">1</code>).</p>

<p><a href="/assets/postassets/slate/grid.png"><img src="/assets/postassets/slate/grid.png" alt="Window Grid" /></a></p>

<h3 id="normal-window-management">Normal Window Management</h3>

<p>Slate is so configurable that it allows you to specify any fraction of the
screen you want to move windows; howeverÙ« this can be annoying if you just want
to use halves and fullscreen. To remedy thisÙ« Slate allows you to create aliases
that you can use for common commands.</p>

<p>Here are some aliases I use for common positions:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Abstract positions
alias full move screenOriginX;screenOriginY screenSizeX;screenSizeY
alias lefthalf move screenOriginX;screenOriginY screenSizeX/2;screenSizeY
alias righthalf move screenOriginX+screenSizeX/2;screenOriginY screenSizeX/2;screenSizeY
alias topleft corner top-left resize:screenSizeX/2;screenSizeY/2
alias topright corner top-right resize:screenSizeX/2;screenSizeY/2
alias bottomleft corner bottom-left resize:screenSizeX/2;screenSizeY/2
alias bottomright corner bottom-right resize:screenSizeX/2;screenSizeY/2
</code></pre></div></div>

<p>You can then bind these commands to any keys you want. For exampleÙ« you can use
the numpad to move windows around:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Numpad location Bindings
bind pad1 ${bottomleft}
bind pad2 push bottom bar-resize:screenSizeY/2
bind pad3 ${bottomright}
bind pad4 ${lefthalf}
bind pad5 ${full}
bind pad6 ${righthalf}
bind pad7 ${topleft}
bind pad8 push top bar-resize:screenSizeY/2
bind pad9 ${topright}
</code></pre></div></div>

<h3 id="layouts">Layouts</h3>

<p>Layouts allow you to tell Slate how you like your windows arranged so it can
arrange them for you. To create a layout you have to specify how you like your
applications arranged and then you bind the layout to a keyboard shortcut.</p>

<p>We can re-use the aliases from the last section in our layout definitions like
this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>layout 1monitor "iTerm":REPEAT ${bottomright}
layout 1monitor "Sublime Text 2":REPEAT ${lefthalf}
layout 1monitor "MacVim":REPEAT ${lefthalf}
layout 1monitor "Safari":REPEAT ${righthalf}
layout 1monitor "Mail":REPEAT ${righthalf}
layout 1monitor "Path Finder":REPEAT ${topright}
layout 1monitor "Xcode":REPEAT ${full}
layout 1monitor "Eclipse":REPEAT ${full}
layout 1monitor "iTunes":REPEAT ${full}
</code></pre></div></div>

<p>Then we can bind the layout to a key like this:</p>

<p>bind l:cmd layout 1monitor</p>

<p>Now whenever we press <code class="language-plaintext highlighter-rouge">command+l</code> our apps will arrange themselves the way we
like. In this example I named my layout <code class="language-plaintext highlighter-rouge">1monitor1</code> but you can give it a
meaningful name and even have multiple layouts with different names.</p>

<h3 id="ultra-fast-app-switching">Ultra-Fast App Switching</h3>

<p>To bind shortcuts directly to focusing an app you can use the focus command.
For exampleÙ« we can bind <code class="language-plaintext highlighter-rouge">command+option+b</code> to focus our browser:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bind b:cmd;alt focus "Google Chrome"
</code></pre></div></div>

<h3 id="my-slate">My .slate</h3>

<p>Here is my <code class="language-plaintext highlighter-rouge">.slate</code> file in its entiretyÙ« do note that it is optimized for the
Dvorak keyboard layoutÙ« so some of the shortcuts may seem weird and the hint
keys are the Dvorak home row rather than qwerty.</p>

<script src="https://gist.github.com/4121655.js?file=.slate">
</script>

'),('http://thume.ca/projects/2012/11/14/magic-png-files/', 'Magic PNG Thumbnails', '1352851200000',  13, '
<p>I was shown trick by a friend where an image was posted on a website
that displayed one thing in the thumbnail and another in the lightbox.
<a href="http://funnyjunk.com/channel/ponytime/rainbow+dash/llhuDyy/15#15">http://funnyjunk.com/channel/ponytime/rainbow+dash/llhuDyy/15#15</a></p>

<p>This post contains an explanation of how these images work and how I was able
to replicate their behaviour.</p>

<h2 id="the-behaviour">The Behaviour</h2>

<p>Certain renderers of the png files would display one image and other renderers
would display a completely different one. One image is always dark and one is
light.</p>

<h3 id="example">Example:</h3>
<p><img src="/assets/postassets/doubleVision/difference.png" alt="Difference example" /></p>

<h3 id="things-that-display-the-light-image">Things that display the light image:</h3>

<ul>
  <li>Thumbnail renderers (FacebookÙ« etcâ€¦)</li>
  <li>Apple png rendering</li>
  <li>Windows png rendering</li>
</ul>

<h3 id="things-that-display-the-dark-image">Things that display the dark image:</h3>

<ul>
  <li>Firefox (and by extension anything that uses libpng)</li>
  <li>Google Chrome</li>
</ul>

<h3 id="this-can-lead-to-interesting-combos">This can lead to interesting combos:</h3>

<ul>
  <li>linking the image on facebook can show one image as a thumbnail but a completely different one when the link is clicked.</li>
  <li>A picture that detects the userâ€™s browser. (Chrome/Firefox or Safari)</li>
  <li>A picture that displays one thing in the browser and a different thing when downloaded to the userâ€™s (victimâ€™s) computer.</li>
  <li>The classic image board thumbnail.</li>
</ul>

<h2 id="the-challenge-and-victory">The Challenge and Victory</h2>

<p>I started on a long journey to figure out how this effect works so that I
could replicate it. The path to enlightenment involved many wrong turns
including believing that the image was being interpreted as a GIF but I
eventually discovered the truth.</p>

<p>After I discovered the secret I wrote a command line tool in Ruby called
doubleVision so that anybody could generate magic thumbnail images.</p>

<p><a href="http://github.com/trishume/doubleVision">doubleVision is available on Github</a>
and as an executable Ruby gem.</p>

<p>The output images look like this:</p>

<p><img src="/assets/postassets/doubleVision/out.png" alt="Sample Image" /></p>

<p>Try downloading it to your computer and then viewing it. Cool eh?</p>

<h2 id="how-it-works">How it works</h2>

<p>The PNG specification contains a metadata attribute that allows you
to specify the gamma to render the image with. This attribute is intended to
be used to ensure that images look identical on all computers. This is a very
normal image processing process called <a href="http://en.wikipedia.org/wiki/Gamma_correction">Gamma Correction</a></p>

<p>The PNG specification defines the gAMA chunk (the chunk that stores the gamma
value) to change the image output like so:</p>

<p>light_out = image_sample^(1 / gamma)</p>

<p>This scales the image values exponentially based on the reciprocal of the
gamma value. If the gamma value is around 1 like it normally is this function
has little noticeable effect. During this processÙ« the lowest brightness value
for a pixel is 0 and the highest is 1.</p>

<p>If we set the PNG gamma attribute to a very low valueÙ« making the exponent
value very high (since it is the reciprocal)Ù« all darker pixels will be made
black and all lighter pixels will be mapped to the normal spectrum.</p>

<h3 id="exponential-gamma-mapping">Exponential Gamma Mapping</h3>
<p><img src="/assets/postassets/doubleVision/PNG_Gamma_mapping.png" alt="Gamma mapping" /></p>

<p>We can reverse this mapping for a very low value of the gamma attribute (I use 0.023)
to get a PNG image where all the pixels of the image are mapped to very light
colors. If we then set the gamma value of the PNG to 0.023 the image will look
somewhat normalÙ« except for the rounding errors introduced by crunching the
image into high values.</p>

<p>The thing isÙ« not all renderers support the gamma attribute. If we try and
view this image in a renderer that does not support the gamma attribute it
will show too bright to make out.</p>

<p>We can abuse this to create a magic thumbnail by taking two images of the same
size and creating a new image twice their dimensions. One image is run through
the previously mentioned reverse gamma filter that makes all pixels very bright and
the other is darkened so that it has no very bright pixels. The images are
then spaced out in grids around each other (see image). The resulting image is
saved as a PNG file with a gAMA of 0.023.</p>

<h3 id="pixel-grid-pattern">Pixel Grid Pattern</h3>
<p><img src="/assets/postassets/doubleVision/pixelgrid.png" alt="Grid Pattern" /></p>

<p>When the image is displayed in a renderer that supports gamma (Like Firefox/Chrome) the light pixels
become fairly dark but visible colors and the normal pixels become a grid of dark pixels.
When the image is displayed in a renderer that does not support gamma (like Apple/Microsoft rendering)
The untransformed image is shown surrounded by a grid of seemingly white pixels.</p>

<h2 id="installation-and-usage">Installation and Usage</h2>

<p>You can install the doubleVision gem and command using:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ gem install doubleVision
</code></pre></div></div>

<p>NextÙ« run the program like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>doubleVision withgamma.png withoutgamma.png out.png
</code></pre></div></div>

<p>obviously replacing the filenames with your own.</p>

<p>It will combine the images into one image (<code class="language-plaintext highlighter-rouge">out.png</code>) that will display
<code class="language-plaintext highlighter-rouge">withgamma.png</code> when viewed with gamma support (e.g. in Firefox)
and <code class="language-plaintext highlighter-rouge">withoutgamma.png</code> when displayed without gamma support (e.g. As a thumbnail)</p>

<h3 id="for-more-detailed-instructions-read-the-readme-on-github">For more detailed instructions read the <a href="http://github.com/trishume/doubleVision">README on Github</a></h3>

<h2 id="other-example">Other Example</h2>

<p><img src="/assets/postassets/doubleVision/DayNight.png" alt="Day and Night" /></p>

<p>Was generated from:
<img src="/assets/postassets/doubleVision/Night.png" alt="Night" />
and
<img src="/assets/postassets/doubleVision/Day.png" alt="Day" /></p>

'),('http://thume.ca/projects/2012/11/04/simple-accurate-eye-center-tracking-in-opencv/', 'SimpleÙ« accurate eye center tracking in OpenCV', '1351987200000',  13, '
<p>I am currently working on writing <a href="http://github.com/trishume/eyeLike">an open source gaze tracker</a> in OpenCV that requires only a webcam.
One of the things necessary for any gaze tracker<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> is accurate tracking of the eye center.</p>

<p>For my gaze tracker I had the following constraints:</p>
<ul>
  <li>Must work on low resolution images.</li>
  <li>Must be able to run in real time.</li>
  <li>I must be able to implement it with only high school level math knowledge.</li>
  <li>Must be accurate enough to be used for gaze tracking.</li>
</ul>

<p>I came across a paper<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup> by Fabian Timm that details an algorithm that fit all of my criteria.
It uses image gradients and dot products to create a function that theoretically is at a maximum at the center of the imageâ€™s most prominent circle.</p>

<p>Here is a video he made of his algorithm in action:</p>

<iframe width="560" height="315" src="http://www.youtube.com/embed/aGmGyFLQAFM" frameborder="0" allowfullscreen="">
</iframe>

<p><strong>Before continuing I recommend that you read <a href="https://www.inb.uni-luebeck.de/fileadmin/files/PUBPDFS/TiBa11b.pdf">his paper</a>.</strong></p>

<h1 id="implementing-the-algorithm">Implementing the algorithm</h1>

<p>After implementing the algorithm detailed in the paper using OpenCV functions my implementation had horrendous accuracy and many problems. These were partially caused by the paper not specifying some important numbers.</p>

<p>These numbers include:</p>
<ul>
  <li>The eye region fractions.</li>
  <li>The gradient magnitude threshold.</li>
  <li>The size of the eye regions used.</li>
</ul>

<p>I contacted Dr. Timm and he helped me with some of my problems.
Below are some problems that I resolved with Dr. Timmâ€™s help.</p>

<h2 id="things-that-are-not-in-the-paper">Things That Are Not in the Paper</h2>

<p>The first thing I fixed was the eye region fractions as portions of the face. From Dr. Timm:</p>

<blockquote>
  <p>Let (xÙ« y) be the upper left corner and WÙ« H the width and height of the detected face.
ThenÙ« the mean of the right eye centre is located at (x + 0.3Ù« y + 0) and the mean of the left centre is at position (x + 0.7Ù« y + 0.4).</p>
</blockquote>

<p>On his recommendation I also applied a gaussian blur to the face before processing it to smooth noise. I use the sigma of <code class="language-plaintext highlighter-rouge">0.005 * sideLengthOfFace</code>.</p>

<h3 id="the-gradient-algorithm">The Gradient Algorithm</h3>

<p>One important thing that is not explained very clearly in the paper is the gradient algorithm. In his implementation he uses the MatLab <code class="language-plaintext highlighter-rouge">gradient</code> function. In my original implementation I used a Sobel operator but by imitating MatLabâ€™s gradient function I achieved much better results.</p>

<p>The way MatLabâ€™s gradient algorithm works (in Matlab code) is <code class="language-plaintext highlighter-rouge">[x(2)-x(1) (x(3:end)-x(1:end-2))/2 x(end)-x(end-1)]</code> with x being the input. Translated into C++ and OpenCV this comes out as:</p>

<figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="nf">computeMatXGradient</span><span class="p">(</span><span class="k">const</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="o">&amp;</span><span class="n">mat</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">out</span><span class="p">(</span><span class="n">mat</span><span class="p">.</span><span class="n">rows</span><span class="p">Ù«</span><span class="n">mat</span><span class="p">.</span><span class="n">cols</span><span class="p">Ù«</span><span class="n">CV_64F</span><span class="p">);</span>

  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="n">mat</span><span class="p">.</span><span class="n">rows</span><span class="p">;</span> <span class="o">++</span><span class="n">y</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">const</span> <span class="n">uchar</span> <span class="o">*</span><span class="n">Mr</span> <span class="o">=</span> <span class="n">mat</span><span class="p">.</span><span class="n">ptr</span><span class="o">&lt;</span><span class="n">uchar</span><span class="o">&gt;</span><span class="p">(</span><span class="n">y</span><span class="p">);</span>
    <span class="kt">double</span> <span class="o">*</span><span class="n">Or</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="n">ptr</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="n">y</span><span class="p">);</span>

    <span class="n">Or</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">Mr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Mr</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">mat</span><span class="p">.</span><span class="n">cols</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span> <span class="o">++</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">Or</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">Mr</span><span class="p">[</span><span class="n">x</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Mr</span><span class="p">[</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mf">2.0</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">Or</span><span class="p">[</span><span class="n">mat</span><span class="p">.</span><span class="n">cols</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">Mr</span><span class="p">[</span><span class="n">mat</span><span class="p">.</span><span class="n">cols</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Mr</span><span class="p">[</span><span class="n">mat</span><span class="p">.</span><span class="n">cols</span><span class="o">-</span><span class="mi">2</span><span class="p">];</span>
  <span class="p">}</span>

  <span class="k">return</span> <span class="n">out</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure>

<p>to get the Y gradient I simply take the X gradient of the transpose matrix and transpose it again(<code class="language-plaintext highlighter-rouge">computeMatXGradient(eyeROI.t()).t()</code>)</p>

<p>By replicating his gradient algorithm I was also able to use the same gradient threshold as him. From Dr. Timm:</p>

<blockquote>
  <p>I remove all gradients that are below this threshold:</p>

  <p><code class="language-plaintext highlighter-rouge">0.3 * stdMagnGrad + meanMagnGrad</code></p>

  <p>where â€œstdMagnGradâ€ and â€œmeanMagnGradâ€ are the standard deviation and the mean of all gradient magnitudesÙ« i.e. the length of the gradients.;</p>
</blockquote>

<h3 id="the-little-thing-that-he-didnt-mention">The â€œLittle Thingâ€ that he didnâ€™t mention</h3>

<p>Because his algorithm in the form he gives in the paper is generalized to all circles he left out one tiny important thing. For me this one line of code made the difference between it working and being terribly innacurate.</p>

<p>In the equation he gives the dot product of the <code class="language-plaintext highlighter-rouge">d</code> vector and the gradient is taken and then squared. The thing is this makes negative dot products positive.</p>

<p>Dot products are negative if the vectors are pointing in opposite directions. The gradient function used creates vectors that always point towards the lighter region. Since the iris is darker than the sclera (white part) the vectors of the iris edge always point out. This means that at the center they will be facing in the same direction as the <code class="language-plaintext highlighter-rouge">d</code> vector. <strong>Anything pointing in the opposite direction is irrelevant</strong></p>

<p>To fix this I added a line of code that turns negative values into zero so they have no effect on the result:
<code class="language-plaintext highlighter-rouge">dotProduct = std::max(0.0Ù«dotProduct);</code></p>

<p>After adding this line of code my implementation tracked my eyes excellently and worked exactly as it should.</p>

<p>#Conclusion</p>

<p>Dr. Timmâ€™s eye center location algorithm is an excellent simple way to track the pupilÙ« but only if you add a few extra things that he does not talk about in his paper.</p>

<p>In terms of my eye tracker at the moment this is all I have implemented. I am
still looking into methods of tracking a reference point like eye corner to
accurately judge where the user is looking.</p>

<p>I am also looking into using deformation of the eye into an oval to
determine the orientation of the iris.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>An eye tracker gives the pixel position of the center of the pupil in an image whereas a gaze tracker determines where the person is looking on the screen.Â <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Timm and Barth. Accurate eye centre localisation by means of gradients. In Proceedings of the Int. Conference on Computer Theory and Applications (VISAPP)Ù« volume 1Ù« pages 125-130Ù« AlgarveÙ« PortugalÙ« 2011. INSTICC.Â <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/web/HandlingExtraQueryParameters', 'What you should do about extra query parameters on your URLs', '1599622919000',  14, '<div class="wikitext"><p>My entry on <a href="https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters">how web server laxness created a de facto requirement
to accept arbitrary query parameters on your URLs</a>
got a number of good commentsÙ« so I want to agree with and magnify
the suggestion about what to do about these parameters. First offÙ«
<a href="https://utcc.utoronto.ca/~cks/space/blog/web/CautionIsAMistakeToday">you shouldn"t reject web page requests with extra query parameters</a>. I also believe that you shouldn"t just
ignore them and serve the regular version of your web page. InsteadÙ«
as said by several commentatorsÙ« <strong>you should answer with a HTTP
redirect to the canonical URL of the web page</strong>Ù« which will be
stripped of at least the extra query parameters.</p>

<p>(I think that this should be a permanent HTTP redirect instead of
a temporary one for reasons that don"t fit within the margins of
this entry. AlsoÙ« this assumes that you"re dealing with a <code>GET</code> or
a <code>HEAD</code> request.)</p>

<p>Answering with a HTTP redirect instead of the page has two useful
or important effectsÙ« as pointed out by commentators on <a href="https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters">that entry</a>. FirstÙ« any web search engines that are
following those altered links won"t index duplicate versions of
your pages and get confused about which is the canonical one (or
downrate you in results for having duplicate content). SecondÙ«
people who copy and reshare the URL from their browser will be
sharing the canonical URLÙ« not the messed up version with tracking
identifiers and other gunk. This assumes that you don"t care about
those tracking identifiersÙ« but I think this is true for most of my
readers.</p>

<p>(In additionÙ« you can"t count on other people"s tracking identifiers
to be preserved by third parties when your URLs get re-shared. If
you want to track that sort of stuffÙ« you probably need to add your
own tracking identifier. You might care about this ifÙ« for exampleÙ«
you wanted to see how widely a link posted on Facebook spread.)</p>

<p>HoweverÙ« this only applies to web pagesÙ« not to API endpoints. Your
API endpoints (even <code>GET</code> ones) should probably error out on extra
query parameters unless there is some plausible reason they would
ever be usefully shared through social media. If your API endpoints
never respond with useful HTML to bare <code>GET</code>sÙ« this probably doesn"t
apply. If you see a lot of this happening with your endpointsÙ« you
might make them answer with HTTP redirects to your API documentation
or something like that instead of some 4xx error status.</p>

<p>(But you probably should also try to figure out why people are
sharing the URLs of your API endpoints on social mediaÙ« and other
people are copying them. You may have a documentation issue.)</p>

<p>PS: As you might suspectÙ« this is what <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a> doesÙ« at least for the
extra query parameters that it specifically recognizes.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpgradeDrag', 'Why Fedora version upgrades are complicated and painful for me', '1599537037000',  14, '<div class="wikitext"><p>It"s September and I still haven"t upgraded any of my machines to
Fedora 32 (which came out at the end of April). If I delay too much
longerÙ« I might run into Fedora 33 coming out and Fedora 31 dropping
out of my upgrade pathÙ« so I really need to start getting moving
on this. ButÙ« <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/MyKernelUpdateSteps">much like why updating my Fedora kernels is complicated</a>Ù« my Fedora version updates are a drag; complexÙ«
time consumingÙ« and periodically painful. So I keep not getting
around to it.</p>

<p>(In a normal yearÙ« I would have spent a slow afternoon at work to
upgrade the work machineÙ« in an environment where having it not
work is not completely disruptiveÙ« then upgraded the home machine.
That"s not <a href="https://en.wikipedia.org/wiki/COVID-19_pandemic">today"s environment</a>; now I"m at homeÙ«
and my home desktop is also my DSL gateway.)</p>

<p>Normal people have sensible straightforward Fedora upgrade processes.
They start the upgrade in one of the official methodsÙ« go away for
a an hour or threeÙ« and it all works. Because my machines run such
an unusual and custom set of environmentsÙ« I don"t trust this process
and I also don"t want to be without either my home desktop or my
work desktop for several hours. So the first complication of my
upgrades is that I do <a href="https://fedoraproject.org/wiki/Upgrading_Fedora_using_package_manager">live upgrades using <code>dnf</code></a> and
during themÙ« I watch <code>dnf</code>"s output to see if there are signs of
problems with package updates. I can do other things during thisÙ«
but that"s more than an hour where I am basically babysitting the
machine while distracting myself every so often. This is a time
sink and not a terribly pleasant way to spend my timeÙ« but it"s
probably the least of the upgrade"s pain.  Doing upgrades in an
unofficial way on an unusual system configuration also raises the
risks that something will break during themÙ« and I can never
completely test this in advance (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/Fedora30GrubBLSGotcha">for example</a>).</p>

<p>(I capture all the <code>dnf</code> output by using <code>script</code> so that I can
also look at it laterÙ« but there"s no good way that I know of to
scan through the result the way I could with a more straightforward
log file.  Something like <code>less</code> will show me the raw outputÙ«
complete with progress bars being rendered and so on. And my terminal
windows only have so much backscroll.)</p>

<p>The next big complication is that I use <a href="https://zfsonlinux.org/">ZFS on Linux</a> for my home directory and other critical
thingsÙ« and it"s of course not integrated with Fedora. This means
there"s always a risk of something going wrong with my ZFS setup
during a Fedora version upgrade. To deal with thisÙ« I "preflight"
my Fedora version upgrades extensively on virtual machines (which
helps deal with the "will they work in general" issue). This takes
its own set of time and preparation workÙ« and is its own kind of
little slog.</p>

<p>FinallyÙ« upgrading Fedora sometimes creates problems in my custom
desktop environment (or <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/MyDesktopTour">non-environment</a>)
that I"ll have to then sort out (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/Fedora29XIssues">for example</a>).
These range from somewhat modestÙ« such as font rendering issuesÙ«
to significantÙ« such as sound not working any more. In extreme
casesÙ« my desktop environment won"t start at all and I get to spend
some time sorting things out. This means that I can only start the
upgrade on a day when I feel that I have that kind of time left in
the dayÙ« and I have to be up to dealing with various kinds of
irritation about my environment exploding.</p>

<p>There really isn"t anything that can be done about all of thisÙ« and
it"s really all a pain that I"ve set myself up for through my own
machine setup choices. So some timeÙ« I just have to say that I"m
spending this afternoon (or this day) on the workÙ« and get it done
(and I"m hoping that writing this entry will help push me forward
on it).</p>

<p>(Sometimes I wonder if tracking Fedora Rawhide would make my life
easier by spreading this time and effort out over a longer timeÙ«
instead of concentrating it all in a few days. But Rawhide"s potential
for serious bugs discourages me. What I really want is a rolling
release of "stable" FedoraÙ« with no big bangs of major releasesÙ«
but this will probably never exist. There are sensible reasons for
distributions to like the idea of major releasesÙ« but that"s for
another entry.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpgradeDrag?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters', 'URL query parameters and how laxness creates de facto requirements on the web', '1599452238000',  14, '<div class="wikitext"><p>One of the ways that <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a> (the code behind <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>) is unusual is that it strictly validates the query parameters
it receives on URLsÙ« including on HTTP <code>GET</code> requests for ordinary
pages. If a HTTP request has unexpected and unsupported query
parametersÙ« such a <code>GET</code> request will normally fail. When I made
this decision it seemed the cautious and conservative approachÙ« but
<a href="https://utcc.utoronto.ca/~cks/space/blog/web/CautionIsAMistakeToday">this caution has turned out to be a mistake on the modern web</a>. In practiceÙ« all sorts of sites will
generate versions of your URLs with all sorts of extra query
parameters tacked onÙ« give them to peopleÙ« and expect them to work.
If your website refuses to play alongÙ« (some) people won"t get to
see your content. <strong>On today"s webÙ« you need to accept (and then
ignore) arbitrary query parameters on your URLs</strong>.</p>

<p>(Today"s new query parameter is "s=NN"Ù« for various values of NN
like "04" and "09". I"m not sure what"s generating these URLsÙ« but
it may be Slack.)</p>

<p>You might wonder how we got hereÙ« and that is a story of lax behavior
(orÙ« if you preferÙ« being liberal in what you accept). In the
beginningÙ« both Apache (for static web pages) and early web
applications often ignored extra query parameters on URLsÙ« at least
on <code>GET</code> requests. I suspect that other early web servers also
imitated Apache hereÙ« but I have less exposure to their behavior
than Apache"s. My guess is that this behavior wasn"t deliberateÙ«
it was just the simplest way to implement both Apache and early
web applications; you paid attention to what you cared about and
didn"t bother to explicitly check that nothing else was supplied.</p>

<p>When people noticed that this behavior was commonplace and widespreadÙ«
they began using it. I believe that one of the early uses was for
embedding "where this link was shared" information for your own web
analytics (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/AnalyticsVsSecurity">cf</a>)Ù« either based on your logs
or using JavaScript embedded in the page. In the way of thingsÙ«
once this was common enough other people began helpfully tagging
the links that were shared through them for youÙ« which is why I
began to see various "utm_*" query parameters on inbound
requests to <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a> even though I never
published such URLs.
Web developers don"t leave attractive nuisances alone for longÙ« so
soon enough people were sticking on extra query parameters to your
URLs that were mostly for them and not so much for you. Facebook
may have been one of the early pioneers here with their "fbclid"
parameterÙ« but other websites have hopped on this particular train
since then (as I saw recently with these "s=NN" parameters).</p>

<p>At this pointÙ« the practice of other websites and services adding
random query parameters to your URLs that pass through them is so
wide spread and common that accepting random query parameters is
pretty much a practical requirement for any web content serving
software that wants to see wide use and not be irritating to the
people operating it. IfÙ« like <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a>Ù« you stick to your guns and
refuse to accept some or all of themÙ« you will drop some amount of
your incoming requests from real peopleÙ« disappointing would be
readers.</p>

<p>This practical requirement for URL handling is not documented in
any specificationÙ« and it"s probably not in most "best practices"
documentation. People writing new web serving systems that are
tempted to be strict and safe and cautious get to learn about it
the hard way.</p>

<p>In generalÙ« any laxness in actual implementations of a system can
create a similar spiral of de facto requirements. Something that
is permitted and is useful to people will be usedÙ« and then supporting
that becomes a requirement. This is especially the case in a
distributed system like the webÙ« where any attempt to tighten the
rules would only be initially supported by a minority of websites.
These websites would be "outvoted" by the vast majority of websites
that allow the lax behavior and support itÙ« because that"s what
happens when the vast majority work and the minority don"t.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters?showcomments#comments">7 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/tech/IM2000NotGoodIdea', 'Daniel J. Bernstein"s IM2000 email proposal is not a good idea', '1599367141000',  14, '<div class="wikitext"><p>A long time agoÙ« Daniel J. Bernstein wrote a proposal for a new
generation of Internet email he called <a href="https://cr.yp.to/im2000.html">IM2000</a>Ù« although it never went anywhere.
Ever since thenÙ« a significant number of people have idealized it
as the great white "if only" hope of email (especially as the
solution to spam)Ù« in much the same way that people idealized Sun"s
<a href="https://en.wikipedia.org/wiki/NeWS">NeWS</a> as the great "if only"
alternative to X11. UnfortunatelyÙ« IM2000 is not actually a good
idea.</p>

<p>The core of <a href="https://cr.yp.to/im2000.html">IM2000</a> is summarized by Bernstein as follows:</p>

<blockquote><p>IM2000 is a project to design a new Internet mail infrastructure
around the following concept: Mail storage is the sender"s
responsibility.</p>
</blockquote>

<p>The first problem with this is that it doesn"t remove the fundamental
problem of emailÙ« which is (depending on how you phrase it) that
email is an <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/EmailVsModernProtocols"><em>anonymous push</em> protocol</a>
or that it lacks <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SignedEmailWrongProblem"><em>revocable authorization</em> to send you things</a>. In IM2000Ù« random strangers on the
Internet are still allowed to push to youÙ« they just push less data
than they currently do with (E)SMTP mail.</p>

<p>The idea that IM2000 will deal with spam rests on the idea that
forcing senders to store mail is difficult for spammers. Even a
decade ago this was a questionable assumptionÙ« but today it is
clearly false. A great deal of serving capacity is yours for the
asking (and someone"s credit card) in AWSÙ« <a href="https://en.wikipedia.org/wiki/Google_Cloud_Platform">GCP</a>Ù« AzureÙ« OVHÙ«
and any number of other VPS and serverless computing places.  In
addition many spammers will have a relatively easy time with
"storing" their emailÙ« because their spam is already generated from
templates and so in IM2000 could be generated on the fly whenever
you asked for it from them. We now have a great deal of experience
with web servers that generate dynamic content on demand and it"s
clear that they can run very efficiently and scale very wellÙ«
provided that they"re designed competently.</p>

<p>(I wrote about this a long time ago <a href="https://utcc.utoronto.ca/~cks/space/blog/spam/SenderStorageHelpsSpammers">here</a>Ù« and things have gotten much
easier for spammers since then.)</p>

<p>At the same timeÙ« IM2000 is catastrophic for your email privacy.
People complain vociferously about "tracking pixels" in HTML email
that betray when you open and read the email from someone; wellÙ«
IM2000 is one giant tracking pixel that reliably reports when and
where you read that email message. IM2000 would also be a terrible
email reading experienceÙ« because it"s like a version of IMAP where
message retrieval has random delays and sometimes fails entirely.</p>

<p>(As far as spam filtering your incoming IM2000 messages goesÙ« IM2000
gives you far less up front information than you currently get with
SMTP email. I wrote up this and other issues a long time ago in an
entry about <a href="https://utcc.utoronto.ca/~cks/space/blog/spam/SenderStorageProblems">the technical problems of such schemes</a>. Some of those problems are no longer
really an issue more than a decade laterÙ« but some continue to be.)</p>

<p>At a broader "technical choices have social impacts" levelÙ« IM2000
would create a very different experience than today"s email systems
if implemented faithfullyÙ« one where "your" email was actually not
yours but was mostly other people"s because other people are storing
it. Those other people can mostly retract individual messages by
deleting them from their servers (you would still have the basic
headers that are pushed to you)Ù« and they can wipe out large sections
of your email by deleting entire accounts (and the sent messages
associated with them)Ù« or even by going out of business or having
a data loss incident. Imagine a world where an ISP getting out of
the mail business means that all email that its customers have sent
from their ISP email accounts over the years just goes awayÙ« from
everyone"s mailbox.</p>

<p>(If "ISP" sounds abstract hereÙ« substitute "Yahoo". Or "GMail".)</p>

<p>In additionÙ« in some potential realizations of IM2000Ù« email would
become mutable in practice (even if you weren"t supposed to in
theory)Ù« because once again the sender is storing the message and
is in a position to alter that stored copy. Expect that capability
to be used sooner or laterÙ« just as people silently revise things
posted on the web (including official statementsÙ« perhaps especially
including them).</p>

<p>Some of these social effects can be partially avoided by storing
your own local copies of IM2000 messages when you read themÙ« but
there are two issues. The first is pragmatic; the more you store
your own copies and the earlier you make themÙ« the more IM2000 is
SMTP in a bad disguise. The second is social; in the IM2000 world
the server holds the authoritative copy of the messageÙ« not youÙ«
so if you say the message says one thing (based on your local copy)
and the server operator says it says something else (or doesn"t
exist)Ù« the server operator likely wins unless you have very strong
evidence.</p>

<p>In generalÙ« I think that IM2000 or anything like it would create
an "email" experience that was far more like the webÙ« complete with
the experience of <a href="https://en.wikipedia.org/wiki/Link_rot">link rot</a>
and <a href="https://utcc.utoronto.ca/~cks/space/blog/web/CoolUrlsChange">cool messages changing</a>Ù« than today"s
email (where for better or worse you keep your own full record of
what you receivedÙ« read and reread it at your leisureÙ« and know
that it"s as immutable as you want it to be). And it would still
have the problem that people can push stuff in front of youÙ« unlike
the web where you usually at least have to go looking for things.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/CyberPowerPowerpanelNotes', 'Some notes on what the CyberPower UPS "Powerpanel" software reports to you', '1599282594000',  14, '<div class="wikitext"><p>For reasons beyond the scope of this entryÙ« I recently bought a
reasonably nice UPS for home usage. Me being meÙ« I then found a
Prometheus metrics exporter for itÙ« <a href="https://gitlab.com/shouptech/cyberpower_exporter">cyberpower_exporter</a> (and see also
<a href="https://shoup.io/posts/2020-03-19-cyberpower-p8s/">Mike Shoup"s blog post about it</a>)Ù« and then
tinkered with it. This exporter works by talking to the daemon
provided by <a href="https://www.cyberpowersystems.com/product/software/power-panel-personal/powerpanel-for-linux/">CyberPower"s Powerpanel software</a>Ù«
instead of talking directly to the UPSÙ« so my first port of call
was to dump the raw information the daemon was providing for my
UPS.</p>

<p>(The Powerpanel software is available as a Fedora RPM that"s not
too obnoxious. Per <a href="https://wiki.archlinux.org/index.php/CyberPower_UPS">the Arch Wiki page on CyberPower UPS</a>Ù« you can also
use <a href="http://networkupstools.org/">Network UPS Tools (NUT)</a>. I opted
to take the simpler path that theoretically should just work.)</p>

<p>You get status information from Powerpanel by connecting to the
Unix socket <code>/var/pwrstatd.ipc</code> (yes I knowÙ« it should be in <code>/run</code>)
and sending ASCII "STATUS" followed by two newlines. You can do this
by hand with <code>nc</code> if you feel like it:</p>

<blockquote><pre style="white-space: pre-wrap;">
printf "STATUS\n\n" | nc -U /var/pwrstatd.ipc
</pre>
</blockquote>

<p>What you get back is something like this (this is my particular UPS
modelÙ« yours may vary):</p>

<blockquote><pre style="white-space: pre-wrap;">
STATUS
state=0
model_name=CP1500PFCLCD
firmware_num=000000000000
battery_volt=24000
input_rating_volt=120000
output_rating_watt=900000
avr_supported=yes
online_type=no
diagnostic_result=1
diagnostic_date=2020/07/31 12:34:53
power_event_result=1
power_event_date=2020/07/31 12:33:59
power_event_during=21 sec.
battery_remainingtime=5160
battery_charging=no
battery_discharging=no
ac_present=yes
boost=no
utility_volt=121000
output_volt=121000
load=8000
battery_capacity=100
</pre>
</blockquote>

<p>The "volt" and "watt" numbers need to be divided by 1000 to get the
units you expect from their name. The "load" is divided by 1000 to
get a percentage (or by 100000 to get it in 0.0 to 1.0 form)Ù« and
is as a percentage of the output rating watts. The daemon doesn"t
report the current load in watts; instead you have to compute it
for yourself. The battery remaining time is in seconds. The battery
capacity is a percentageÙ« but unlike <code>load</code>Ù« it"s expressed as a
straight 0-100 number. The times are in your local timezoneÙ« not
UTCÙ« and I don"t know how the UPS reports longer durations of power
events (in the minutes or even more than an hour).</p>

<p>I suspect that the <code>state</code>Ù« <code>power_event_result</code>Ù« and
<code>diagnostic_result</code> fields can take on multiple values.  Based
on what the CyberPower <code>pwrstat</code> command reports for my UPS right
nowÙ« these mean a normal stateÙ« that the last power event was a
blackout (a total power loss)Ù« and that the last self-test passed.</p>

<p>(The blackout was because I unplugged the UPS from the wall
socket to make sure everything workedÙ« which is why it was
so short.)</p>

<p>The reported <code>load</code> number is somewhat untrustworthy and definitely
seems to be quantized by the UPS. It"s possible to observe reported
loads of "0" if my home machine environment is idle enough (with
the display blanked). This isn"t just an artifact of the Powerpanel
softwareÙ« either; when I looked at the UPS"s actual front panelÙ«
it reported 0 load and 0 watts being used. The front panel also
reports "VA" figuresÙ« and they didn"t go to zero at these "0 load"
times. HoweverÙ« as far as I can tell VA figures aren"t reported by
the Powerpanel softwareÙ« and may or may not be provided to the
outside world by the UPS itself.</p>

<p>(The NUT page for <a href="https://networkupstools.org/ddl/Cyber_Power_Systems/CP1000PFCLCD.html">a very similar model</a>
doesn"t list any VA data.)</p>

<p>As a consequenceÙ« you can"t really use the reported <code>load</code> value
to see how much power your overall UPS-based setup is using over
time; the UPS <code>load</code> will under-report at times of low usage and
perhaps at other times. This was a bit disappointingÙ« but then I
didn"t buy the UPS to (also) be a watt-meter with a USB readout
that I could grab from the computer.</p>

<p>(The UPS connects to my desktop via USB and is visible as a USB
deviceÙ« but I haven"t tried to dump its USB traffic to see the truly
raw data. That"s a little bit too much work for my current level of
curiosity.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/web/CoolUrlsChange', 'In practiceÙ« cool URLs change (eventually)', '1599194516000',  14, '<div class="wikitext"><p>The idea that "cool URLs don"t change" has been an article of faith
for <a href="https://www.w3.org/Provider/Style/URI">a very long time</a>.
HoweverÙ« at this point we have more than 20 years of experience
with the webÙ« and anyone who"s been around for a significant length
of time can tell you that <strong>in practiceÙ« cool URLs change all of
the time</strong> (and I don"t mean just minor changes like preferring
HTTPS over HTTP). Over a sufficient length of timeÙ« internal site
page layouts change (sometimes because <a href="https://utcc.utoronto.ca/~cks/space/blog/web/CoolUrlProblem">URL design is hard</a>)Ù« people move domains or hosts within a domainÙ«
and sometimes cool URLs even go away and must be resurrectedÙ«
sometimes by hand (through people re-publishing and re-hosting
things) and sometimes through the <a href="https://web.archive.org/">Wayback Machine</a>. This decay in cool URLs is so pervasive
and well recognized that we have a term for itÙ« <a href="https://en.wikipedia.org/wiki/Link_rot">link rot</a>.</p>

<p>(Of courseÙ« you"re a good personÙ« and your cool URLs don"t change.
But this is the web and we all link to each otherÙ« so it"s inevitable
that some other people"s cool URLs that you link to will suffer
from link rot.)</p>

<p>Despite link rot being widely recognized as very realÙ« I think that
in many way"s we"re in denial about it. We keep pretending (both
culturally and technically) that if we wish hard enough and try
hard enough (and yell at people hard enough)Ù« all important URLs
will be cool URLs that are unchanging forever. But this is not the
case and is never going to be the caseÙ« and it"s long past time
that we admitted it and started dealing with it. Whether we like
it or notÙ« it is better to deal with the world of the web as it is.</p>

<p>CulturallyÙ« we recite "cool URLs don"t change" a lotÙ« which makes
it hard to talk about how best to evolve URLs over timeÙ« how to
preserve content that you no longer want to hostÙ« and other issues
like that. I don"t think anyone"s written a best practices document
for "so you want to stop having a web site (but people have linked
to it)"Ù« never mind what a company can do to be friendly for archiving
when it goes out of business or shuts down a service. And that"s
just scratching the surface; there"s a huge conversation to be had
about the web over the long term once we admit out loud that nothing
is forever around here.</p>

<p>(The <a href="https://archiveteam.org/">Archive Team</a> has opinions. But
there are some hard issues here; there are people who have published
words on the InternetÙ« not under CC licensesÙ« and then decided for
their own reasons that they no longer want those words on the
Internet despite the fact that other people like themÙ« linked to
them a lotÙ« and so on.)</p>

<p>TechnicallyÙ« how we design our web systems and web environments
often mostly ignores the possibility of future changes in either
our own cool URLs or other people"s. What this means in more tangible
terms is really a matter for other entriesÙ« but if you look around
you can probably come up with some ideas of your own. Just look for
the pain points in your own web publishing environment if either
your URLs or other people"s URLs changed.</p>

<p>(One pain point and sign of problems is that it"s a thing to spider
your own site to find all of the external URLs so you can check if
they"re still alive. Another pain point is that it can be so hard
to automatically tell if a link is still thereÙ« since not all dead
links either fail entirely or result in HTTP error codes. Just ask
people who have links pointing to what are now parked domains.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/WhyMailFilteringLanguage', 'Why I want something like Procmail with a dedicated mail filtering language', '1599104784000',  14, '<div class="wikitext"><p>A couple of years ago I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ProcmailWhatNext">discovering that procmail
development is basically dead</a> and wondering
out loud what I might switch to. In some comments on that entryÙ«
<a href="http://plasmasturm.org/">Aristotle Pagaltzis</a> suggested that
in an environment (such as MH) with one message per fileÙ« wellÙ«
let me quote:</p>

<blockquote><p>[...]Ù« then you can write yourself one or more programs in your
favourite language that kick the mail from there to wherever you want
it to end up. The entirety of the job of such code is opening and
reading files and then moving themÙ« for which any language whatsoever
will doÙ« so the only concern is how far you want to library up your
mail parsing.</p>
</blockquote>

<p>My reply (in another comment on that entry) was that I wanted a
system where I directly wrote mail filtering rulesÙ« as is the case
in procmailÙ« not a system where I wrote filtering rules in some
general purpose programming language. But I never explained why I
wanted a special purpose language for this.</p>

<p>My reason for this is that writing mail filtering in a special
purpose language removes (or rather hides) all of the plumbing that
is otherwise necessary. The result may have obscure syntax (procmail
certainly does)Ù« but almost everything it says is about what mail
filtering is happeningÙ« not the structure of getting it to happen
(both at the large scale level of opening filesÙ« parsing themÙ«
moving them aroundÙ« and at the small scale level of executing or
otherwise matching rules). This makes it much easier to come back
later to pull out "what is this filtering" from the system; the
configuration file you read is all about that. With a general purpose
programming languageÙ« coming back in six months or a year requires
essentially reverse engineering your entire programÙ« because you
have to find the filtering rules in the rest of the code (and
understand how they"re executed).</p>

<p>(In theory you can avoid some of this if you write good enough
documentation for your personal filtering setup. In practice it"s
pretty unlikely that you willÙ« or that this documentation will be
well tested enough (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DocumentationNeedsTesting">because you need to test documentation</a>). An open source mail filtering system
with a dedicated filtering language is much more likely to have
good documentation that lets you drop right into understanding your
filtering rules again.)</p>

<p>This is a subtle advantage of DSLs (Domain Specific Languages) in
general. In a good DSLÙ« <a href="https://utcc.utoronto.ca/~cks/space/blog/web/WhySimpleMarkup">much like with wikitext</a>Ù«
almost everything you write is real "content" (hereÙ« real filtering
rules)Ù« and very little of it is scaffolding. A general purpose
language necessarily isn"t that focused on your specific problem
areaÙ« and so making it focus that way requires a bunch of scaffolding.
At the extremeÙ« you wind up building your own language that"s
implemented in the general purpose language.</p>

<p>(This may be literalÙ« with a parser and everythingÙ« or it may be
in the form of a set of stylized and standard function calls or
method calls you make to embody your real work.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/WhyMailFilteringLanguage?showcomments#comments">5 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoConcurrencyStillNotEasy', 'Even in GoÙ« concurrency is still not easy (with an example)', '1599019066000',  14, '<div class="wikitext"><p>Go is famous for making concurrency easyÙ« through good language
support for <a href="https://golangbot.com/goroutines/">goroutines</a>. Except
what Go makes easy is only one level of concurrencyÙ« the nuts and
bolts level of making your code do things concurrently and communicating
back and forth through channels. Making it do the right things
concurrently is still up to youÙ« and unfortunately Go doesn"t
currently provide a lot of standard library support for correctly
implemented standard concurrency patterns.</p>

<p>For exampleÙ« one common need is for a limited amount of concurrency;
you want to do several things at onceÙ« but only so many of them.
At the moment this is up to you to implement on top of goroutinesÙ«
channelsÙ« and things like the <a href="https://golang.org/pkg/sync/"><code>sync</code></a>
package. This is not as easy as it looksÙ« and quite competent people
can make mistakes here. As it happensÙ« I have an example ready to
hand today.</p>

<p><a href="https://github.com/google/gops">Gops</a> is a convenient command to
list (and diagnose) Go processes that are currently running on your
system. Among other thingsÙ« it"ll tell you which version of Go they
were compiled withÙ« which is handy if you want to see if you have out
of date binaries that should be rebuilt and redeployed. One of the
things <code>gops</code> needs to do is look at all of the Go processes on your
systemÙ« which it does concurrently. HoweverÙ« it doesn"t want to look
at too many processes at onceÙ« because <a href="https://github.com/google/gops/pull/118">that can cause problems with
file descriptor limits</a>. This
is a classic case of <em>limited concurrency</em>.</p>

<p>Gops implements this at the moment with code in <a href="https://github.com/google/gops/blob/6fb0d860e5fa50629405d9e77e255cd32795967e/goprocess/gp.go#L29">goprocess.FindAll()</a>
that looks like thisÙ« in somewhat sketched and reduced form:</p>

<blockquote><pre style="white-space: pre-wrap;">
func FindAll() []P {
   pssÙ« err := ps.Processes()
   [...]
   found := make(chan P)
   limitCh := make(chan struct{}Ù« concurrencyProcesses)

   for _Ù« pr := range pss {
      limitCh &lt;- struct{}{}
      pr := pr
      go func() {
         defer func() { &lt;-limitCh }()
         [... get a P with some error checking ...]
         found &lt;- P
      }()
   }
   [...]

   var results []P
   for p := range found {
      results = append(resultsÙ« p)
   }
   return results
}
</pre>
</blockquote>

<p>(In the real code there"s a WaitGroup for coordinationÙ« and the
<code>found</code> channel gets closed appropriately.)</p>

<p>How this works is clearÙ« and is a standard pattern (covered in eg
Go 101"s <a href="https://go101.org/article/channel-use-cases.html">Channel Use Cases</a>). We use a
buffered channel to provide a limited number of tokens; sending a
value into the channel implicitly takes a token (and blocks if the
token supply is exhausted)Ù« while receiving a value from it puts a
token back in. We take a token before we start a new goroutineÙ« and
the goroutine releases the token when it"s done.</p>

<p>Except that <a href="https://github.com/google/gops/issues/123">this code has a bug if there are too many processes
to examine</a>. Even knowing
that there is a bug in this codeÙ« it may not be obvious.</p>

<p>The bug is that the goroutines only receive from <code>limitCh</code> to release
their token after sending their result to the unbuffered <code>found</code>
channelÙ« while the main code only starts receiving from <code>found</code>
after running through the entire loopÙ« and <strong>the main code takes
the token in the loop and blocks if no tokens are available</strong>. So
if you have too many processes to go throughÙ« you start N goroutinesÙ«
they all block trying to write to <code>found</code> and don"t receive from
<code>limitCh</code>Ù« and the main <code>for</code> loop blocks trying to send to <code>limitCh</code>
and never reaches the point where it starts receiving from <code>found</code>.</p>

<p>At one levelÙ« this bug is a very fragile bug; it only exists because
of multiple circumstances. If the goroutines took the token by
sending to <code>limitCh</code> instead of the main <code>for</code> loop doing itÙ« the
bug would not exist; the main <code>for</code> loop would start them allÙ« many
would stopÙ« and then it would go on to receive from <code>found</code> so that
they could receive from <code>limitCh</code> and release their token so other
goroutines would run. If the goroutines received from <code>limitCh</code> to
release their token before sending to <code>found</code>Ù« it wouldn"t exist
(but because of error handlingÙ« it"s simpler and more reliable to
do the receive in a <code>defer</code>). And if the entire <code>for</code> loop was in
an additional goroutineÙ« the main code would go on to receive from
<code>found</code> and unblock completed goroutines to release their tokensÙ«
so the fact that the <code>for</code> loop was blocked waiting to send to
<code>limitCh</code> wouldn"t matter.</p>

<p>At another levelÙ« this shows how concurrency is not easy as easy
as it looks in Go. All you need is one mistake and things skid to
a haltÙ« and all of the code involved can look good to a casual
examination. Getting concurrency correct is simply hard for people
(we can debate about whyÙ« but I think that it is is very clear).</p>

<p>(I"m sure that the people who wrote and approved the change that
added this concurrency limiting code to gops were good programmers.
A tricky case still tripped them upÙ« passing all of their scrutiny.
Even when I knew that there was a concurrency problem in the code
and where it was (because my <code>gops</code> was hanging all of a suddenÙ«
and <a href="https://github.com/go-delve/delve">Delve</a> told me where
everything was stuck)Ù« it still took me some time to see what the
exact problem was.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/SignedEmailSolutionImpact', 'Why we won"t like it if signing email is the solution to various email problems', '1598926733000',  14, '<div class="wikitext"><p>Yesterday I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SignedEmailWrongProblem">my thesis that all forms of signing email
are generally solving the wrong problem</a>
and said in passing that if signing email was actually a solutionÙ«
we wouldn"t like it in the long run. TodayÙ« let"s talk about that.</p>

<p>As I sort of discussed yesterdayÙ« the issue with signing email as
a solution is that on the InternetÙ« identities normally can"t be
used to exclude people because people can always get a new one (egÙ«
a new domain and new DKIM keys for it and so on). If signed email
is going to solve problemsÙ« the requirement is that such new
identities stop being useful. In other wordsÙ« email providers would
stop accepting email from new identities (or at least do something
akin to that). If new identities don"t get your email acceptedÙ«
existing identities are suddenly important and can be used to revoke
access.</p>

<p>(This revocation might be general or specificÙ« where a user could
say "I don"t want to see this place"s email any more" and then the
system uses the identity information to make that reliable.)</p>

<p>Let"s be blunt: big email providers would love this. Google would
be quite happy in a world where almost everyone used one of a few
sources of email and Google could make deals or strongarm most or
all of them. Such a world would significantly strengthen the current
large incumbents and drive more business to their paid offerings.
Even the current world where it"s rather easier in practice to get
your email delivered reliably if you"re a Google Mail or Microsoft
Office365 customer does that; a world where only a few identities
had their email reliably accepted would make that far worse.</p>

<p>For the rest of usÙ« that would be a pretty disastrous change. I
won"t say that the cure would be worse than the disease (people"s
opinions here vary)Ù« but it would likely create two relatively
separate email worldsÙ« with the remaining decentralized email network
not really connected to the centralized one of "only known identities
accepted here" email. If running your own mail server infrastructure
meant not talking to GMailÙ« a lot of people and organizations would
drop out of doing it and the remaining ones would likely have
ideological reasons for continuing to do so.</p>

<p>(A far out version of this would be for it to lead to multiple
federated email networksÙ« as clusters of email systems that interact
with each other but don"t accept much email from the outside world
effectively close their borders much as the big providers did. If
this sounds strangeÙ« wellÙ« there are multiple IRC networks and even
the <a href="https://en.wikipedia.org/wiki/Fediverse">Fediverse</a> is
splintering in practice as not everyone talks to everyone else. And
there are plenty of messaging systems that don"t interconnect with
each other at all.)</p>

<p>PS: There are lesser versions of thisÙ« where large email providers
don"t outright stop showing "outside" email to people but they do
downgrade and segregate it. And of course that happens to some
degree today through opaque anti-spam and anti-junk systems; if
Hotmail dislikes your email but not enough to reject it outrightÙ«
probably a lot of people there aren"t going to see it.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/SignedEmailWrongProblem', 'All forms of signing email are generally solving the wrong problem (a thesis)', '1598842533000',  14, '<div class="wikitext"><p>Modern email is full of forms of signed email. Personally signed
email is the old fashioned approach (and wrong)Ù« but modern email
on the Internet is laced with things like <a href="https://en.wikipedia.org/wiki/DomainKeys_Identified_Mail">DKIM</a>Ù« which
have the sending system sign it to identify at least who sent it.
UnfortunatelyÙ« the more I think about itÙ« the more I feel that
signed email is generally solving the wrong problem (and if it"s
solving the right oneÙ« we won"t like that solution in the long run).</p>

<p>A while ago I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/EmailVsModernProtocols">why email often isn"t as good as modern
protocols</a>Ù« which is because it"s what I
described as an <em>anonymous push</em> protocol. An anonymous push protocol
necessarily enables spam since it allows anyone to send you things.
Describing email as "anonymous push" makes it sound like the anonymity
is the problemÙ« which would make various forms of signing the
solution (including DKIM). But this isn"t really what you care about
with email and requiring email to carry some strong identification
doesn"t solve the problemÙ« as we"ve found out with all of the spam
email that has perfectly good DKIM signatures for some random new
domain.</p>

<p>(This is a version of <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TwoSidesOfIdentity">the two sides of identity</a>.
On the Internet people can trivially have multiple identitiesÙ« so
while an identity is useful to only let selected people inÙ« it"s
not useful to keep someone out.)</p>

<p>I think that what you really care about with modern communication
protocols is <em>revocable authorization</em>. With a pull protocolÙ« you
have this directly; you tacitly revoke authorization by stopping
pulling from the place you no longer like. With a push protocolÙ«
you can still require authorization that you grantÙ« which lets you
revoke that granted authorization if you wish. The closest email
comes to this is having lots of customized email addresses and
carefully using a different one for each service (which Apple has
recently automated for iOS people).</p>

<p>ObviouslyÙ« requiring authorization to push things to you has a
fundamental conflict with any system that"s designed to let arbitrary
strangers contact you without prearrangement (which is <a href="https://utcc.utoronto.ca/~cks/space/blog/spam/FundamentalSpamProblem">the
fundamental problem of spam</a>).
Modern protocols seem to deal with this in two ways (even with
revocable authorization); they have some form of gatekeeping (in
the form of accounts or access)Ù« and then they evolve to provide
settings that let you stop or minimize the ability of arbitrary
strangers to contact you (for exampleÙ« Twitter"s settings around
who can send you Direct Messages).</p>

<p>(The modern user experience of things like Twitter has also evolved
to somewhat minimize the impact of strangers trying to contact you;
for exampleÙ« the Twitter website separates new DMs from strangers
from DMs from people you"ve already interacted with. It"s possible
that email clients could learn some lessons from thisÙ« for example
by splitting your inbox into "people and places you"ve interacted
with before" and "new contacts from strange people". This would
make DKIM signatures and other email source identification usefulÙ«
apart from the bit where senders today feel free to keep changing
where they"re sending from.)</p>

<p>PS: In this viewÙ« actions like blocking or muting people on Twitter
(or the social network of your choice) is a form of revoking their
tacit authorization to push things to you.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SignedEmailWrongProblem?showcomments#comments">9 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoContextValueMistake', 'An interesting mistake with Go"s <code>context</code> package that I (sort of) made', '1598757854000',  14, '<div class="wikitext"><p>TodayÙ« <a href="https://dave.cheney.net/">Dave Cheney</a> did another Go pop quiz
<a href="https://twitter.com/davecheney/status/1299846267850223616">on Twitter</a>Ù«
where he asked whether the following code printed -6Ù« 0Ù« "&lt;nil>"Ù« or
paniced:</p>

<blockquote><pre style="white-space: pre-wrap;">
package main
</pre>

<pre style="white-space: pre-wrap;">
import (
    "context"
    "fmt"
)

func f(ctx context.Context) {
    context.WithValue(ctxÙ« "foo"Ù« -6)
}

func main() {
    ctx := context.TODO()
    f(ctx)
    fmt.Println(ctx.Value("foo"))
}
</pre>
</blockquote>

<p>I didn"t answer this correctly because I focused my attention on the
wrong thing.</p>

<p>What I focused on was the use of the <code>"foo"</code> string as the context
keyÙ« partly because of my experience with languages like Python.
To start withÙ« the <a href="https://golang.org/pkg/context/"><code>context</code></a>
package"s documentation says:</p>

<blockquote><p>The provided key must be comparable and should not be of type string
or any other built-in type to avoid collisions between packages using
context. Users of WithValue should define their own types for keys.
[...]</p>
</blockquote>

<p>A traditional problem in languages like Python is that two strings
may compare the same without actually being the same thingÙ« and
some code really wants you to present it with the exact same thing.
HoweverÙ« the <code>context</code> package doesn"t require that you present it
with the exact same keyÙ« just a key where the <em>interface value</em> of
the key will compare the same.</p>

<p>(Because <code>context</code> compares interface valuesÙ« both the value and
the type must match; it"s not enough for both values to have the
same underlying concrete typeÙ« say stringÙ« and to compare identical.
This is why defining your own string type is a reliable away around
collisions between packages.)</p>

<p>So after I worked through all of thisÙ« I confidently answered that
this code printed -6. The <code>"foo"</code> string that the value is set
with is not necessarily the same <code>"foo"</code> string that it"s retrieved
withÙ« but that doesn"t matter. HoweverÙ« this is not the problem
with the code. The actual problem is that <strong>context.WithValue()
returns a new context with the value setÙ« it doesn"t change the
context it"s called on</strong>. Dave Cheney"s code is written as if
<code>.WithValue()</code> mutates the current contextÙ« as <code>f()</code> ignores that
new context that <code>.WithValue()</code> provides and returns nothing to
<code>main()</code>. Since the original <code>context</code> in <code>main()</code> is what <code>.Value()</code>
is called onÙ« it has no <code>"foo"</code> key and the result is actually
"&lt;nil>".</p>

<p>This problem with the code is actually a quite interesting mistakeÙ«
because as far as I can tell right now none of the usual Go style
checkers detect it. This code passes "<code>go vet</code>"Ù« it produces no
complaints from <a href="https://github.com/kisielk/errcheck"><code>errcheck</code></a>
because we"re not ignoring an error return valueÙ« and tools like
<a href="https://github.com/golangci/golangci-lint">golangci-lint</a> only
complain about the use of the built-in type string as the key in
<code>.WithValue()</code>. Nothing seems to notice that we"re ignoring the
critical return value from <code>.WithValue()</code>Ù« which turns it into more
or less a no-op.</p>

<p>(Now that Dave Cheney has brought this to the surfaceÙ« I suspect
that someone will contribute a check for it to <a href="https://staticcheck.io/">staticcheck</a>Ù« which already detects the "using a
built-in type as a key" issue.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoContextValueMistake?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/unix/VimNotUsingFeatures', 'My divergence from "proper" Vim by not using and exploring features', '1598673577000',  14, '<div class="wikitext"><p>I"ve read a reasonable number of Vim tutorials and introductions
by nowÙ« and one of the things that stands out is how some of what
I do differs from what seems to be considered "proper" Vim. The
simple way to put it is that I use less of Vim"s features than the
tutorials often introduce. One of the best examples is something
that I do all of the timeÙ« which is reflowing paragraphs.</p>

<p>The official proper Vim way to reflow paragraphs (based on tutorials
I"ve read) is <code>gq{motion}</code>. Often the most flexible version is
<code>gqip</code> or <code>gqap</code> (where "ip" or "ap" select the paragraph you"re
in). Assuming that various things are set correctlyÙ« this will
magically reflow your paragraphÙ« much as M-q does in Emacs (a command
I"m accustomed to using there).</p>

<p>HoweverÙ« for various reasons I don"t use this; instead I rely on
the general purpose hammer of "<code>!</code>" and the (relatively) standard
Unix <code>fmt</code> command. My conditioned reflex sequence of commands for
formatting the paragraph I"m writing is "ESC { !}fmt }"Ù« and in
general I"ll use "!}fmt" more or less reflexively.</p>

<p>At one level this is somewhere between a curiosity and a deliberate
choice not to learn all of Vim and try to Vim golf everything in
sight (a choice that <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/ViInefficientMovement">I"ve written about before</a>).
At another level this is kind of a weakness. As an exampleÙ« in
writing this entry I discovered not just that the <code>gq</code> command could
be made to use <code>fmt</code>Ù« but also discovered or re-discovered the <code>ip</code>
and <code>ap</code> motion modifiersÙ« which might be useful periodicallyÙ«
including in my usual paragraph reflowing.</p>

<p>Or perhaps notÙ« because now that I experiment with itÙ« using <code>ip</code>
instead of moving to the start of the paragraph causes the cursor
to jump up to the start after the paragraph is reflowed. Using an
explicit { command means that I"m (relatively) conscious that I"m
actively moving before I reflowÙ« instead of having the cursor jump.
If Vim was EmacsÙ« I probably wouldn"t mindÙ« but since Vim is Vim I
think I may prefer the explicitness of my current approach.</p>

<p>(And on character golfingÙ« using <code>ip</code> or <code>ap</code> saves no characters
in this situation. To really golfÙ« I would need to switch to <code>gq</code>.)</p>

<p><a href="https://utcc.utoronto.ca/~cks/space/blog/unix/ViInefficientMovement">As before</a>Ù« I probably shouldn"t be
surprised. Vim"s sets of commands and motions are now really quite
largeÙ« and people generally pick and choose what they use out of
large sets like that. I suspect that plenty of Vim users use only
various subsets of themÙ« subsets that would strike other Vim users
as annoyingly inefficient or old-fashioned.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/VimNotUsingFeatures?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/web/Firefox80VideoAccelConfusion', 'Firefox 80 and my confusion over its hardware accelerated video on Linux', '1598591821000',  14, '<div class="wikitext"><p>The news of the time interval is that Firefox 80 is out and in
theory it can support hardware video acceleration on X11Ù« not just
Wayland (<a href="https://www.omgubuntu.co.uk/2020/08/firefox-80-release-linux-gpu-acceleration">source</a>Ù«
<a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=Firefox-80-Released">also</a>).
The master Mozilla tracking bug for hardware accelerated video on
X11 is <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1619523">bug #1619523</a>Ù« with all
sorts of information. So I downloaded the official release (one of
my Firefox setups uses the official builds these days for reasons
beyond the scope of this entry) and tried to get it to do accelerated
video playback. The short version is that I think I"ve failedÙ« but I"m
not sure why.</p>

<p>Even in Firefox 80Ù« getting VA-API accelerated video playback
requires a whole series of magic incantations in <code>about:config</code>
preferences and perhaps environment variables when you start Firefox
(this may change in the next release). Assuming that all of those
are set rightÙ« Firefox can apparently still decide that it doesn"t
like your Linux video driver (or its version)Ù« your specific hardwareÙ«
or perhaps either or both of the resolution of the source video and
the resolution of your display. Some or many of these can be forced
with Firefox settingsÙ« but at the same time the bug reports I"ve
read say that sometimes Firefox ignores hardware acceleration because
it"s slower for the specific circumstancesÙ« or because it has known
bugs. If Firefox is making a sensible decision for <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2018">my specific
hardware</a>Ù« that"s one thing and I want
it to do what will work best. But if I"ve missed a setting or if
Firefox is just being twitchy about somethingÙ« I also want to
override it. In general I know my hardware is capable of hardware
accelerated playback of videos at far lower CPU usage than Firefox
manages (on the same videos).</p>

<p>UnfortunatelyÙ« Firefox won"t tell me what it"s doing or whyÙ« at
least not in a way that I can understand. I"ve peered into the
depths of <code>about:support</code>Ù« which tells me some of the "what" but
not the "why"Ù« and I"ve tried some of the things from <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1619523">bug #1619523</a>
without success. If Firefox is or isn"t going to do hardware
accelerated video playbackÙ« I wish it would tell me both what it was
doing and why. Otherwise I"m probably going to go on being confused
and annoyed with it.</p>

<p>(I care about hardware acceleration not just because of CPU load
but because my perception is that hardware acceleration is necessary
to play back a full sized video smoothly without dropping frames
every so often. This may be wrong on modern hardwareÙ« even on my 4k
display.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/Firefox80VideoAccelConfusion?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSSSDActivitySlowsScrubs', 'Even on SSDsÙ« ongoing activity can slow down ZFS scrubs drastically', '1598496494000',  14, '<div class="wikitext"><p>Back in the days of <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetupII">our OmniOS fileservers</a>Ù«
which used HDs (spinning rust) across iSCSIÙ« we wound up <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSScrubsOurSpeedup">changing
kernel tunables to speed up ZFS scrubs</a> and
saw a significant improvement. When we migrated to <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">our current
Linux fileservers with SSDs</a>Ù« I
didn"t bother including these tunables (or the Linux equivalent)Ù«
because I expected that SSDs were fast enough that it didn"t matter.
IndeedÙ« our SSD pools generally scrub like lightning.</p>

<p>(Our Linux fileservers use a ZFS version before <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSSequentialScrubIsComing">sequential scrubs</a> (<a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSScrubScannedVsIssued">also</a>).
It"s possible that sequential scrub support would change this story.)</p>

<p>ThenÙ« this weekendÙ« a ZFS pool with 1.68 TB of space used took two
days to scrub (48:15Ù« to be precise). This is not something that
happens normally; this size of pool usually scrubs much fasterÙ« on
the order of a few hours. When I poked at it a bit none of the disks
seemed unusually slow and there were no signs of other problemsÙ«
it was just that the scrub was running slowly. HoweverÙ« looking at
NFS client metrics in <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">our metrics system</a> suggested that there was
continuous ongoing NFS activity to some of the filesystems in that
pool.</p>

<p>Although I don"t know for sureÙ« this looks like a classical case
of even a modest level of regular ZFS activity causing the ZFS scrub
code to back off significantly on IO. Since this is on SSDsÙ« this
isn"t really necessary (at least for us); we could almost certainly
sustain both a more or less full speed scrub and our regular read
IO (significant write IO might be another storyÙ« but that"s because
it has some potential performance effects on SSDs in general). HoweverÙ«
with no tuning our current version of ZFS is sticking to conservative
defaults.</p>

<p>In one senseÙ« this isn"t surprisingÙ« since it"s how ZFS has
traditionally reacted to IO during scrubs. In another senseÙ« it isÙ«
because it"s not something I expected to see affect us on SSDs; if
I had expected to see itÙ« I"d have carried forward our ZFS tunables
to speed up scrubs.</p>

<p>(Now that I look at our logged dataÙ« it appears that ZFS scrubs on
this pool have been slow for some timeÙ« although not "two days" slow.
They used to complete in a couple of hoursÙ« then suddenly jumped to
over 24 hours. More investigation may be needed.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/ColdLockupMachineMysteryII', 'My home desktop is still locking up when it gets too cold (and what next)', '1598413897000',  14, '<div class="wikitext"><p>In early 2019 I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/ColdLockupMachineMystery">the mystery of my home desktop that
was locking up when it got too cold</a>.  At
that point the machine was about a year old (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2018">I built it in March
or so of 2018</a>) and the winter of 2018-2019
was its first winter and thus my first chance to see this. I regret
to report that I haven"t really done anything since thenÙ« and the
machine will still lock up when it gets too cold. For last winter
(the 2019-2020 winter)Ù« my workaround was to raise the heat here;
in combination with a generally mild winter that was enough to have
only a couple of lockups during especially cold overnight times.</p>

<p><a href="https://en.wikipedia.org/wiki/COVID-19_pandemic">Current world and local events</a> suggest strongly
that daytime interior temperatures will not be an issue this coming
winterÙ« because I will almost certainly be working from home almost
all of the time and so will want it warm enough to be comfortable
(which is well above the temperature the machine locks up at).
However that still leaves me with the direct issue of overnight
temperatures and the indirect issue that I have a machine with some
sort of flaw that"s now my primary machine for doing work.</p>

<p>The path of least resistance is to do nothing and assume that nothing
really bad will happen. My machine will probably lock up a few times
overnight when I"m not using it over the winterÙ« but that"s no big
deal. The path of more effort and some risk is to reseat at least
the memoryÙ« loosen and re-tighten the motherboard screwsÙ« and perhaps
experiment with canned air to selectively cool spots on the motherboard
to see if I can identify something that triggers the problem. This
risks a slightly flaky component into a very flaky or even a dead
componentÙ« which would leave me with a dead machineÙ« and also has
no guarantee of fixing or even identifying the problem.</p>

<p>(But re-seating things should be very low risk so I should really
try itÙ« however much I don"t like working with hardware.)</p>

<p>The sure but more expensive path would be to replace at least the
motherboard and (probably) the power supply. Buying a new motherboard
or PSU would be necessary in practice even if I identify a fault
in my current one and get it replaced under warrantyÙ« because I"m
not going to be without a home desktop for so much as a day if I
can help it. This feels wasteful (the current hardware is only about
two and a half years old) and expensiveÙ« but if I put a reasonable
value on my time and annoyance it"s probably the second cheapest
option after doing nothing. It also means I would have to figure
out at least a new motherboardÙ« which is where I started thinking
about <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/MissingPCType">how I want a type of PC and motherboard that"s generally
skipped</a>. HoweverÙ« it would give me an emergency
spare motherboard and PSU that would be comparable to my current
machineÙ« which is something I might decide I care about in the
current conditions.</p>

<p>(Having a reliable motherboard with two M.2 slots and a backup
emergency spare would also make it less scary to upgrade to M.2
NVMe drives. Right now I"ve been holding back on that partly because
my emergency machine is <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2011">my old home PC</a>Ù«
which has no M.2 slots and <a href="https://twitter.com/thatcks/status/975884414021496832">I lost full trust in</a>.)</p>

<p>(This entry is one of the ones that I write in part to convince myself
to do something sensible. Whether I actually will is an open question;
knowing myselfÙ« the most likely option is to do nothing until the
weather starts getting cold enough that the issue"s more imminent.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/ColdLockupMachineMysteryII?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/tech/MissingPCType', 'I want a type of desktop PC (and motherboard) that"s generally skipped', '1598326141000',  14, '<div class="wikitext"><p>By nowÙ« the desktop x86 PC market has segmented itself into a number
of categories. There are machinesÙ« CPUsÙ« and motherboards that are
basic machines with limited features and made to be quite inexpensiveÙ«
"business" machines that don"t need very much but are more than the
very basicsÙ« machines for gaming enthusiastsÙ« and HEDT ("High End
Desktop") workstations that are aimed at people building high powered
machines. Typical examples of what are in these categories are in
Anandtech"s <a href="https://www.anandtech.com/show/11891/best-cpus-for-workstations">Best CPUs for Workstations</a>
and <a href="https://www.anandtech.com/show/9793/best-cpus">Best CPUs for Gaming</a>;
in Intel motherboard chipsets there is the H seriesÙ« the B seriesÙ«
and the Z series (sometimes among others). Unfortunately for meÙ«
my interests in machines fall into an intermediate category that
doesn"t generally existÙ« which I will call a <em>sysadmin workstation</em>.</p>

<p>Every system administrator probably has a somewhat different view
of what they want in their desktop. My image of a sysadmin workstation
is exemplified by <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2018">my current home machine</a>;
it has a fast (Intel) CPUÙ« it takes a fair amount of RAM that can
run at faster than completely stock speedsÙ« it has at least M.2
slots (both of which run at x4) and four SATA portsÙ« and it can
drive at least one 4K display through onboard graphics. Unlike a
gaming machineÙ« I want to use integrated graphics (they"re quieterÙ«
less clutterÙ« cheaperÙ« and generally better supported on Linux)
instead of a GPU. Unlike a HEDT workstationÙ« I don"t want a
fire-breathing CPU with its increased cost and cooling requirements
(and I also don"t want one or more GPUs for GPU computation). And
I want more storage (especially M.2) than basic home or business
desktops usually provide.</p>

<p>(I might change my views on GPUs if Intel starts making discreet
GPUs that are well supported under LinuxÙ« drive two 4K displays
at 60 Hz or betterÙ« and don"t require lots of cooling.)</p>

<p>It"s possible to put together a sysadmin workstationÙ« of course; I
did it for <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2018">my current home machine</a> and
<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/WorkMachine2017">my current (AMD based) work machine</a>Ù«
although the latter has to use a GPU. But it generally involves
buying more than you need and picking through specifications to
narrow in on the bits you care aboutÙ« and the motherboard support
for integrated graphics is often somewhat limited. People who buy
motherboards with lots of features and high specification generally
use GPUsÙ« so there are a fair number of otherwise suitable motherboards
that just don"t support onboard graphics. I"m also lucky in that
Intel still provides versions of their higher end desktop CPUs with
onboard graphics. AMD has historically restricted onboard graphics
to lower end models; if you wanted a reasonably powerful RyzenÙ« you
were stuck getting a GPU.</p>

<p>(As far as Intel versus Ryzen goesÙ« <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/MyIntelVsAMDView-2018">I still don"t trust AMD</a>. My Intel home machine still has its problem
of <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/ColdLockupMachineMystery">hanging when the temperature drops too low</a>Ù«
but that"s a narrow issue that"s probably a motherboard fault. The
coming of winter with another go-around of this issue is one reason
I"m thinking about motherboards and desktops and so on again.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/MissingPCType?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/spam/BugzillasGetSpam', 'The Linux kernel bugzilla (and others) get spammed (of course)', '1598238947000',  14, '<div class="wikitext"><p>The general rule of the Internet is that everything gets spammedÙ«
so at one level it should be no surprise to me that bug reporting
systems for open source projects do. As it happensÙ« I sort of have
personal experience with thisÙ« especially through <a href="https://bugzilla.kernel.org/show_bug.cgi?id=196683">this old bug
for AMD Ryzens hanging on Linux</a>Ù« which I"m
subscribed to because <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/RyzenApparentlyStable">it sort of affects me</a>. Actually reading the bug will
generally not show you any spamÙ« but that"s because people go through
and remove it quite promptly when it"s submitted. I know about the
spam because I get the standard Bugzilla email when someone submits
an update to itÙ« including a new spam comment.</p>

<p>(I"m pretty sure the Fedora Bugzilla instance gets spammed tooÙ«
although perhaps less than the kernel"s.)</p>

<p>Since you have to register to leave new comments in the Linux kernel
bugzilla and the spam persistsÙ« the spammers are either doing this
at least partially by hand or have automated the process of registering
for Bugzillas. This isn"t just the usual automated form stuffing
that goes on everywhere.</p>

<p>(When I say "the spammers"Ù« it could be people that they"ve hired
to do it in low-wage areas.)</p>

<p>That this happens doesn"t so much make me sad as make me angry
(again) at the spammersÙ« not just because of the spam but because
of the way they progressively ruin everything on the Internet.
Behind the clean looking Linux kernel bugzilla bug entry is some
number of people who have to shovel out the stables and worry about
how to try to stop the inflowÙ« and the same is true for lots of
other things. Everything on the Internet today that allows people
to send in content has to deal with spamÙ« which means that spam
is a tax on all of those things (and one that wears away at people).
I"m sure that there are things that aren"t being built because of
spamÙ« or that are being built differently.</p>

<p>PS: I believe that the Linux kernel bugzilla spam I"ve seen has
generally been attempts to plant links to various sites. Sometimes
it"s just a big spew of URLsÙ« but sometimes it has some text (even
sometimes text that"s plugging its links instead of just filling up
space).</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/python/ArgparseSomeUnixNotes', 'Some bits on making Python"s argparse module work like Unix usually does', '1598155179000',  14, '<div class="wikitext"><p>I recently discovered that <a href="https://utcc.utoronto.ca/~cks/space/blog/python/ArgparseAbbreviatedOptions">argparse allows you to abbreviate long
options</a>Ù« and then Chris Wellons wrote
about <a href="https://nullprogram.com/blog/2020/08/01/">Conventions for (Unix) Command Line Options</a>Ù« which included a criticism
of <a href="https://docs.python.org/3/library/argparse.html"><code>argparse</code></a>. I"m
not going to write about how to make argparse behave todayÙ« because I
haven"t explored that in full; insteadÙ« this is some quick notes from
the documentation and my past experiences.</p>

<p>FirstÙ« both Wellons and I had a bad reaction to argparse accepting
abbreviated options. HoweverÙ« based on <a href="https://docs.python.org/3/library/argparse.html#argumentparser-objects">the documentation</a>
you probably have to accept itÙ« because of an important postscript
note:</p>

<blockquote><p><em>Changed in version 3.8</em>: In previous versionsÙ« <code>allow_abbrev</code>
[being <code>False</code>] also disabled grouping of short flags such as <code>-vv</code>
to mean <code>-v -v</code>.</p>
</blockquote>

<p>Almost no one has Python 3.8Ù« which means that the cure here is
worse than the disease. Not accepting grouped short flags is much
worse than accepting abbreviated long flagsÙ« so until Python 3.8+
is pervasive we"re stuck with the latter.</p>

<p>As it implicitly documents (in the form of its example)Ù« argparse
allows the non-traditional style of options being intermixed with
non-option arguments on the command lineÙ« instead of requiring all
options to be before non-options. There is no way to control this.
Argparse does accept "<code>--</code>" to terminate the option list (with some
caveats)Ù« after which things that look like options are non-option
arguments.</p>

<p>In generalÙ« using the <a href="https://docs.python.org/3/library/argparse.html#nargs"><code>nargs</code></a> argument
for <a href="https://docs.python.org/3/library/argparse.html#the-add-argument-method"><code>add_argument()</code></a>
is neither necessary nor useful for options (and <a href="https://utcc.utoronto.ca/~cks/space/blog/python/ArgparseNargsChoicesLimitation">has issues when
used with non-options</a>). Setting
things like "<code>type=str</code>" or "<code>action="append"</code> causes the argument
parser to do the right thing; similarlyÙ« it does the right thing
when the action doesn"t consume any argument value (this behavior
is documented in a postscript of the <code>nargs</code> section). As Wellons
notedÙ« argparse can fall down badly if you attempt to create an
option that takes an optional value. FortunatelyÙ« <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/MyOptionsConventions">I don"t think
you should do that</a> and should stick
to options either always taking a value or never doing so. Argparse"s
own examples use "<code>nargs="?"</code>" for non-options arguments that are
in fact optional.</p>

<p>Argparse makes a weird attempt to handle command line arguments that
are negative numbersÙ« as documented in <a href="https://docs.python.org/3/library/argparse.html#arguments-containing">Arguments containing -</a>.
This isn"t how traditional Unix commands behave with such argumentsÙ«
where a leading "-" is a leading "-" no matter whatÙ« with no attempts to
guess at what should happen. This behavior is not currently optional
and I don"t think there"s a really good way to trick argparse into not
doing it.</p>

<p>(Actually reading much of the <a href="https://docs.python.org/3/library/argparse.html"><code>argparse</code></a> documentation has
already taught me useful things I didn"t knowÙ« such as how the
<a href="https://docs.python.org/3/library/argparse.html#dest"><code>dest</code></a>
argument is optional. I"m not sure I"d want to ever leave it outÙ«
though; explicit is better than implicitÙ« and using "<code>dest</code>" leaves
a visible reminder in the code of what attribute holds the result.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/links/MozillaWhyNoXULAddons', 'Link: Why Did Mozilla Remove XUL Add-ons?', '1598063581000',  14, '<div class="wikitext"><p>David Teller"s <a href="https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/">Why Did Mozilla Remove XUL Add-ons?</a>
is the answer to this questionÙ« from someone who works on Firefox.
Firefox XUL Add-ons are the old and more powerful form of addonsÙ«
which have now been replaced by WebExtensions as of Firefox Quantum.</p>

<p>I knew a certain amount about this area (and it"s an interest of
mineÙ« since Firefox WebExtensions still aren"t quite as good for
<a href="https://utcc.utoronto.ca/~cks/space/blog/web/Firefox74Addons">my addons</a>)Ù« but I didn"t know all of the
details and the article taught me things. I had never quite wondered
what happened to Firefox"s Electrolysis stuffÙ« for example; the
article answers the question.</p>

<p>(<a href="https://hackers.town/@lmorchard/104723322435253992">Via</a>Ù«
itself via <a href="https://mastodon.social/@mhoye">@mhoye</a>.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/GoogleWhenEvilRealized', 'When I stopped believing in Google"s fundamental good nature', '1598062069000',  14, '<div class="wikitext"><p>Once upon a time I might have believed in Google"s fundamental
goodness and well intentioned nature (probably with qualifications).
Google themselves eventually taught me betterÙ« perhaps later than
it took for other people to realize that they were an amoral
corporation. For meÙ« the moment of realizationÙ« the point where I
knew for sure that Google"s "don"t be evil" slogan was inoperativeÙ«
was the great <a href="https://en.wikipedia.org/wiki/Google%2B">Google+</a>
"nymwars"Ù« where Google (for Google+) declared that everyone on
Google+ must use their real name and then attempted to enforce that
(<a href="https://en.wikipedia.org/wiki/Nymwars#Google">it went wrong pretty fast</a>).</p>

<p>There were a large number of problems with Google+"s "real name"
policies. It didn"t match how actual users referred to each other
and were known onlineÙ« including for people who actually worked at
Google. Forcing people to reveal their real name does real harm and
has real risks (something appreciated even back then in 2011Ù« but
which is more pointed today). And in practiceÙ« a "real name" policy
is actually a "it looks like a real name to underpaid support people
or some automated system" policyÙ« where "John Smith" is far more
likely to be accepted than a non-Western name or an unusual oneÙ«
even if one is not your real name and the other is.</p>

<p>Google knew all of this. PeopleÙ« including internal peopleÙ« pointed
this out to them at great length. A decent number of technical people
who worked at Google protested. There were demonstrated problems with
the actual enforcement and actions involved. And GoogleÙ« in both their
senior leadership and their ongoing policiesÙ« simply didn"t care. All
of the harms and the wrongs did not matter to them. They were going to
do evil because they couldÙ« and because they thought it served their
corporate goals for Google+.</p>

<p>(We all know how that one went; Google+ diedÙ« for all that it had
some good ideas.)</p>

<p>Watching all of this happenÙ« watching all of the protesting and
good arguments and everything go exactly nowhereÙ« is when I knew
that my image of Google was wrong (and gone). Now I extend no more
trust to Google than I think supported by their corporate and
commercial interests. Google employees may care about "don"t be
evil" and doing the right thing and so onÙ« but Google as a whole
does notÙ« and the employees do what Google tells them to.</p>

<p>(This elaborates something I said in an aside long agoÙ« in an entry
about <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SmartphoneWhyIPhone">why my smartphone is an iPhone</a>.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/GoogleWhenEvilRealized?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DashboardsWhatForAndSettings', 'What you"re looking for with a Grafana dashboard affects its settings', '1597982248000',  14, '<div class="wikitext"><p>Recently I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/GrafanaOurIntervalSettings">how we chose our time intervals in dashboards</a>Ù« where the answer is that we mostly
use <a href="http://docs.grafana.org/reference/templating/#the-interval-variable"><code>$__interval</code></a>
because for our purposes this is the best option. But this raises
the question of what is our purpose with our dashboards. Put another
wayÙ« why do we not care about seeing brief spikes in our dashboards?</p>

<p>Broadly speakingÙ« I think that dashboards can be there to look for
signs of obvious issuesÙ« to look for signs of subtle issuesÙ« or to
diagnose problems in detail (when you already know there"s an issue
and you"re trying to understand what"s going on). Pretty much all
of our dashboards are for some combination of the first or the lastÙ«
and we don"t normally go looking for subtle issues.</p>

<p>(The flipside of looking for signs of obvious issues is reassuring
you that there are no obvious issues right now. From a cynical
perspectiveÙ« this may be the purpose of a lot of overview dashboards.)</p>

<p>When you"re looking for obvious issuesÙ« broad overviews are generally
fine. If you have periodic very short usage spikes but nothing else
notices on a larger scaleÙ« you almost certainly don"t have an
<em>obvious</em> issue. SimilarlyÙ« showing very short usage spikes on a
broad overview graph isn"t necessarily useful unless you believe
that these spikes are the sign of a larger issue. As a resultÙ« you
might as well use <code>$__interval</code> even though it makes short term
spikes disappear when you"re looking at longer time periods.</p>

<p>When you"re trying to diagnose problems in detail you already know
something is going on and you"re probably looking at fine time
scales around specific times of interest. At fine time scalesÙ« a
properly set up Grafana dashboard will show you all of the information
availableÙ« including fine grained spikesÙ« because it"s using a very
short <code>$__interval</code> since it covers only a small time range. This
is certainly my experience with our dashboardsÙ« where I often wind
up looking at only five or ten minute time windows in order to try
to really understand what was going on at some point.</p>

<p>Looking for subtle issues is an interesting challenge in dashboard
design. I suspect it"s hard to do without knowing a fair bit about
how your environment is supposed to behave (or at least believing
that you do). At this point it"s not something that I"m doing very
much of in our dashboard design (although I"ve sort of done some
of it).</p>

<p>(See also <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DashboardAttentionProblem">the problem of paying too much attention to our
dashboards</a>.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/web/LinuxBrowserSupportPains', 'Potential problem points for Chrome (or any browser) to support Linux', '1597890426000',  14, '<div class="wikitext"><p>SupposeÙ« not entirely hypotheticallyÙ« that you"re worried about the
possibility of browsers no longer supporting Linux (and Unix in
general). Since Chrome and Firefox are already cross-platformÙ« a
sensible question is what might make supporting Linux (or Unix in
general) difficult in a cross-platform browserÙ« especially one that
already supports Android. From my somewhat ignorant perspectiveÙ« I
see two general issues.</p>

<p>One big thing that a browser needs to do is interact with the
platform"s "graphics" system for drawingÙ« videoÙ« audioÙ« input eventsÙ«
and other similar things (extending to eg clipboard support). Unix
currently has two graphics systems (X11 and Wayland) that are used
by no one elseÙ« and they"re at least somewhat different from other
platforms (especially X11Ù« which is very old fashioned). If the X11
and Wayland APIs diverge too far away from what Android and Windows
support (and possibly Mac OS)Ù« then continuing to support the lowest
common denominator between all of these platforms might be considered
too limiting (or too much work to basically emulate what other
platforms can do).</p>

<p>(We"ve already seen some degree of this in videoÙ« where both Chrome
and Firefox have been very slow to support hardware accelerated
video playback on Unix systems.)</p>

<p>The other large areaÙ« especially for ChromeÙ« is platform security
features for process isolation and process security. To the best
of my understandingÙ« Chrome is much more secure on Windows than it
is on Unix because Windows allows it to do much more to lock down
various processes. Unix (Linux especially) is trying to move forward
on thisÙ« but it"s generally been happening slowly and it may not
match the APIs that Chrome is organized around on Windows. On
AndroidÙ« Google has a lot of freedom to advance the platform security
features in any way that they wantÙ« so they could move towards
features and APIs that are more convenient for them (ieÙ« probably
more Windows like). This would leave Unix as the odd one outÙ«
requiring an increasing amount of code (and effort) just for itÙ«
for less security.</p>

<p>(Firefox is not as far along toward separated and securely confined
processesÙ« so I expect that this affects it less.)</p>

<p>PS: With all of that saidÙ« <a href="https://old.reddit.com/r/linux/comments/ic1afz/firefox_and_web_browsers_for_linux/">the Reddit comments</a>
for <a href="https://utcc.utoronto.ca/~cks/space/blog/web/FirefoxAndLinuxBrowsers">my entry worrying about Firefox"s future on Linux</a> raised a good point (<a href="https://old.reddit.com/r/linux/comments/ic1afz/firefox_and_web_browsers_for_linux/g21onzz/">here</a>)
for Chrome continuing to support LinuxÙ« which is that a lot of
Google developers use Linux internally and they need a browserÙ« and
probably ideally a Chrome that at least renders the same as Chrome
on Windows and Android.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/LinuxBrowserSupportPains?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/PrometheusVsCPUFrequency', 'The Prometheus host agent can disturb Linux CPU frequency measurements', '1597807604000',  14, '<div class="wikitext"><p>Recently I read <a href="https://www.robustperception.io/cpu-frequency-scaling-metrics-from-the-node-exporter">CPU frequency scaling metrics from the node
exporter</a>Ù«
which talks about how to look at the <a href="https://prometheus.io/">Prometheus</a>
metrics that the <a href="https://github.com/prometheus/node_exporter">Prometheus host agent</a> gathers and exposes
to Prometheus. Naturally this got me to to look at the frequencies
that my own little Prometheus setup on <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2018">my home machine</a>
had gatheredÙ« which gave me a surprise.</p>

<p>Like a lot of desktopsÙ« my home machine is idle almost all of the
timeÙ« and I can see that reflected in a lot of the statistics that
the Prometheus host agent gathers. But Prometheus reported that my
my CPU frequency was hovering up at very high valuesÙ« often around
4 GHz (and checking confirmed that these were what the host agent
was reporting). Since this didn"t match my expectationsÙ« I looked
at the direct information in <code>/sys</code>:</p>


<pre style="white-space: pre-wrap;">
: hawklords.cs ; cd /sys/devices/system/cpu/cpufreq
: hawklords.cs ; cat policy?/scaling_cur_freq policy??/scaling_cur_freq
800079
800210
800106
800045
800091
800032
800162
800644
801214
800175
800060
800026
</pre>

<p>That isÙ« my CPUs are sitting at around 800 MhzÙ« which is actually
the minimum frequency (scaling_min_freq is 800000). That"s what
I see almost all of the time when my desktop is idleÙ« with brief
exceptions.</p>

<p>My only theory for what"s going on with the Prometheus host agent
is that this is happening because the host agent is a <a href="https://golang.org/">Go</a> program and is quite parallelized and concurrent.
When Prometheus or you ask the host agent for metricsÙ« it immediately
goes out to gather them from all of its <a href="https://github.com/prometheus/node_exporter#collectors"><em>collectors</em></a> in parallelÙ«
which is likely to make many or all of your CPUs busy and thus push
up their frequencies. Apparently my overall system (LinuxÙ« the CPUÙ«
and whatever BIOS magic is going on) is so good at this that the
speed rises fast enough for the host agent to observe itÙ« and then
drops again almost immediately once the host agent is done. I suspect
that the Prometheus daemon itself also contributes to the CPU usage
(since it"s receiving the data from the host agent)Ù« but I expect
that the host agent"s multi-CPU usage is the big factor.</p>

<p>(The choice of CPU frequency governor likely affects this; my home
machine is currently on "powersave"Ù« which is what my Fedora 31
environment defaults to. The CPU frequency driver is intel_pstate.)</p>

<p>This unfortunately rather reduces the usefulness of the host agent"s
CPU frequency information on Linux. You can probably use it to look
at big exceptions (such as CPUsÙ« coresÙ« or sockets that are
persistently out of step with what they should be)Ù« but it"s clearly
not a reliable guide to the normal state of your systems.</p>

<p>PS: I see similar but less drastic effects on <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/WorkMachine2017">my office machine</a>Ù« which has an AMD Ryzen instead of an Intel CPU.
Direct examination in <code>/sys</code> suggests that it idles around 1.8 GhzÙ«
but the host agent sees it around 2.7 to 2.9 Ghz when idleÙ« with
spikes to higher.</p>

<p>PPS: The host agent does sometimes observe low frequencies; it"s
reported 800 Mhz frequencies on each core on my home machine at
some point over the past week. It even appears to have seen 800 Mhz
on all cores at some point.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/web/FirefoxAndLinuxBrowsers', 'Firefox and web browsers for Linux', '1597718045000',  14, '<div class="wikitext"><p>The (web) news of the time interval is that <a href="https://arstechnica.com/information-technology/2020/08/firefox-maker-mozilla-lays-off-250-workers-says-covid-19-lowered-revenue/">Mozilla is laying off
a significant number of people</a>Ù«
including people working on <a href="https://developer.mozilla.org/en-US/docs/Tools#:~:text=You%20can%20open%20the%20FirefoxÙ«%2B%20Opt%20%2B%20I%20on%20macOS.">Firefox"s web developer tools</a>
and <a href="https://developer.mozilla.org/en-US/">MDN</a>. Naturally this
has led to people worrying about the future of Firefox (wellÙ« more
than usualÙ« since it"s had declining web browser share for some
time). As a user of Firefox on Linux I have some extra worriesÙ«
because Firefox is kind of special on Linux.</p>

<p>People on WindowsÙ« Mac OSÙ« iOSÙ« and Android can be confident that
there will pretty much always be a competent browser on their
platform. Each of these platforms is backed by a big company and
having a competent browser is too important to their success for
the company to neglect it. Linux (or Unix in general) is the odd
platform outÙ« since there"s no large company behind it to fund
browser development. Competent Unix web browsers are kind of a side
effect of browser development for other platforms.</p>

<p>Out of the main browsers remainingÙ« only Mozilla has felt genuinely
committed to keeping their browser going on Unix. Apple and Microsoft
are obviously indifferentÙ« and Google"s corporate goals for Chrome
only require it to work on major platforms such as Windows and
Android (Android is not Unix hereÙ« because Android doesn"t use X11
or Wayland and has increasingly divergent APIs and capabilities).
It"s fairly easy to imagine a future where Firefox fading out leaves
Unix people with essentially no modern browsers and a growing set
of sites that we couldn"t really use.</p>

<p>(I believe that the Chrome developers generally care about Chrome
working on UnixÙ« but they"re at the mercy of what Google is willing
to spend money on. If the spur of competition from Firefox goes
awayÙ« Google might decide that Unix no longer qualifies. They might
even decide that supporting Chromium on Unix is getting in the way
of internal changes that make it better on Android and Windows.)</p>

<p>This might sound theoreticalÙ« but in a way Unix users have been
here before. Back in the days before Netscape open-sourced its
browser to create MozillaÙ« Netscape"s browser was pretty much the
only good option for Unix usersÙ« and Netscape had a solid period
of relative stagnation in the late 90s and early 00s. I used Netscape
back then and it was not really a great experience. I"m not looking
forward to the possibility of a rerun of that.</p>

<p>(In the pre-Mozilla daysÙ« Unix users were also at the mercy of what
Unixes Netscape bothered to provide browser binaries for. I"m pretty
sure that there were some Unix workstation users who lost out due
to thatÙ« which didn"t help the fortunes of their Unix vendors in
an era where the web was becoming more and more important.)</p>

<p>PS: It"s possible that CanonicalÙ« Red HatÙ« and perhaps SuSE would
get together to fund enough ongoing Firefox development to keep
things viable on Linux (and hopefully other Unixes). Perhaps there
are even people in these organizations considering this issue right
now.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/FirefoxAndLinuxBrowsers?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/unix/TimeBeforeReadline', 'Important parts of Unix"s history happened before readline support was common', '1597637326000',  14, '<div class="wikitext"><p>Unix and things that run on Unix have been around for a long time
now. In particularÙ« <a href="https://en.wikipedia.org/wiki/GNU_Readline">GNU Readline</a> was first released in
1989 (as was <a href="https://en.wikipedia.org/wiki/Bash_(Unix_shell)">Bash</a>)Ù«
which is long enough ago for it (or lookalikes) to become pretty
much pervasiveÙ« especially in Unix shells. Today it"s easy to think
of readline support as something that"s always been there.  But of
course this isn"t the case. Unix in its modern form dates from <a href="https://en.wikipedia.org/wiki/Version_7_Unix">V7</a> in 1979 and <a href="https://en.wikipedia.org/wiki/History_of_the_Berkeley_Software_Distribution#4.2BSD">4.2
BSD</a>
in 1983Ù« so a lot of Unix was developed before readline and was
to some degree shaped by the lack of it.</p>

<p>(This isn"t to say that GNU Readline and Bash were the first sources
of readline style editingÙ« command completionÙ« and so on; on Unix
they go back at least as far as 1983Ù« with <a href="https://en.wikipedia.org/wiki/Tcsh">tcsh</a>. But tcsh wasn"t pervasive for
various reasons.)</p>

<p>One obvious thing that was shaped by the lack of readline was csh.
Csh has a sophisticated set of operations on your command history
that are involved through special strings embedded in your command
line. To quote <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=4.2BSD/usr/man/man1/csh.1">the 4.2 BSD csh manpage</a>:</p>

<blockquote><p>History substitutions place words from previous command input as
portions of new commandsÙ« making it easy to repeat commandsÙ« repeat
arguments of a previous command in the current commandÙ« or fix
spelling mistakes in the previous command with little typing and a
high degree of confidence.  History substitutions begin with the
character `!" and may begin anywhere in the input stream (with the
proviso that they do not nest).</p>
</blockquote>

<p>The most well known history substitution for tcsh users is probably
"<code>!!</code>"Ù« which repeats the previous command. Bash has a similar
facilityÙ« <a href="https://www.gnu.org/software/bash/manual/html_node/History-Interaction.html">cf</a>Ù«
and even today the Bash manual calls out its similarity to csh"s
version. These days I suspect most people using Bash don"t use Bash"s
history substitutions and just stick to readline stuff; it"s generally
more fluid and easy to deal with.</p>

<p>(This is an obvious observationÙ« but at times it"s easy to blur the
old days of Unix together and lose track of how comparatively old
some parts of it are. Or at least it is for me.)</p>

<p>PS: My impression is that the widespread availability of command
and filename completion subtly shapes the kind of command names and
file names that people use. When you don"t have completionÙ« it makes
a lot of sense for names to be short and it doesn"t matter if they"re
all jumbled together so that completion can"t tell them apart.
FamouslyÙ« Unix loves short command names because they"re short to
typeÙ« which makes a lot of sense in a V7 environment.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/TimeBeforeReadline?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/BlameAndWorksOnMyLaptop', '"It works on my laptop" is a blame game', '1597550442000',  14, '<div class="wikitext"><p>There is an infamous dialog between developers and operations teams
(<a href="https://markosrendell.wordpress.com/2014/02/20/it-works-on-my-laptop-win/">eg</a>)
where the core of the exchange is the developer saying "it works
on my laptop" and then the operations team saying "wellÙ« pack up
your laptopÙ« it"s going into production". Sometimes this is reframed
as the developer saying "it works on my laptopÙ« deploy it to
production". One of many ways to understand this exchange is as a
game of who is to blame for production issues.</p>

<p>When the developer says "well it works on my laptop"Ù« they"re
implicitly saying "you operations people screwed up when deploying
it". When the operations people say "well pack up your laptop"Ù«
they"re implicitly saying in return "no we didn"tÙ« you screwed it
up one way or another; either it didn"t work or you didn"t prepare
it for deployment". The developer is trying to push blame to
operations and operations is trying to push blame back.</p>

<p>(This exchange is perpetually darkly funny to system administrators
because we often feel that we"re taking the fall for what are
actually other people"s problemsÙ« and in this exchange the operations
people get to push back.)</p>

<p>But the important thing here is that this is a social problemÙ« just like
any blame game. Sometimes this is because higher up people will punish
someone (implicitly or explicitly) for the issueÙ« and sometimes this is
because incentives aren"t aligned (which can lead to <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DevopsBlameProblem">DevOps as a way
to deal with the blame problem</a>).</p>

<p>(<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DevopsProblemLevels">This isn"t the only thing that DevOps can be for</a>.)</p>

<p>Playing the blame game in real life instead of in funny Internet
jokes isn"t productiveÙ« it"s a problem. If your organization is
having this dialog for realÙ« it has multiple issues and you"re
probably going to get caught in the fallout.</p>

<p>(I almost wrote "you have multiple issues"Ù« but it"s not your
problemÙ« it"s the organization"s. Unless you"re very highly placedÙ«
you can"t fix these organizational problemsÙ« because they point to
deep cultural issues on how developers and system administrators
view each otherÙ« interact with each otherÙ« and probably are rewarded.)</p>

<p>Realizing this makes the "it works on my laptop" thing a little
less funny and amusing to meÙ« and a bit sadder and darker than it
was before.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/BlameAndWorksOnMyLaptop?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoInlinesAcrossPackages', 'Go will inline functions across packages (under the right circumstances)', '1597467487000',  14, '<div class="wikitext"><p>Like many languagesÙ« or more exactly many compilers for many
languagesÙ« Go will <a href="https://en.wikipedia.org/wiki/Inline_expansion"><em>inline</em></a> one function into
another under the right circumstances.  For more on this in general
(and examples)Ù« see Dave Cheney"s <a href="https://dave.cheney.net/2020/04/25/inlining-optimisations-in-go">Inlining optimisations in Go</a>.</p>

<p>In many languagesÙ« only functions within the same source code file
or compilation unit are candidates for inlining. Functions that are
further away than that (and compiled separately)Ù« especially in
completely separate packages or librariesÙ« are not available for
inlining for various reasons. As I found out recentlyÙ« modern
versions of Go don"t work this wayÙ« especially with <a href="https://dave.cheney.net/2020/05/02/mid-stack-inlining-in-go">mid-stack
inlining</a>.
If a function in a different package that you use is simple enoughÙ«
the Go compiler will quietly inline it into your function.</p>

<p>With Go"s <a href="https://dave.cheney.net/2020/05/02/mid-stack-inlining-in-go">mid-stack inlining</a>Ù« there are some very common functions
from standard packages that are inlined (probably) in many people"s
code. One prominent example is <a href="https://golang.org/pkg/fmt/#Printf"><code>fmt.Printf</code></a>. The actual implementation of
<code>fmt.Printf</code> is:</p>


<blockquote><pre style="white-space: pre-wrap;">
func Printf(format stringÙ« a ...interface{}) (n intÙ« err error) {
   return Fprintf(os.StdoutÙ« formatÙ« a...)
}
</pre>
</blockquote>

<p>(You can see it in <a href="https://github.com/golang/go/blob/master/src/fmt/print.go#L210">fmt/print.go</a>.)</p>

<p>This is simple enough to be inlinedÙ« and so it generally is. If you
write a little test program and build it with the necessary compiler
flags (from Dave Cheney"s <a href="https://dave.cheney.net/2020/05/02/mid-stack-inlining-in-go">Mid-stack inlining in Go</a>)Ù« you
can get a report on this:</p>

<blockquote><pre style="white-space: pre-wrap;">
$ go build -gcflags=-m=2 fred.go
[...]
./fred.go:4:14: inlining call to fmt.Printf [...]
</pre>
</blockquote>

<p>(And if you check on <a href="https://godbolt.org/">Compiler Explorer</a>
(aka "godbolt")Ù« you can verify that the generated assembly matches
this.)</p>

<p>PS: I don"t know if this inlining extends to internal runtime
functions that the compiler generates call to for youÙ« such as
<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts">converting small integer values to interfaces</a>Ù«
or if it only happens for calls that are in your source as you wrote
it.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallIntsII', 'Go 1.15"s interface optimization for small integers is invisible to Go programs', '1597382145000',  14, '<div class="wikitext"><p>When I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts">how Go 1.15 improved converting small integer
values to interfaces</a>Ù« I said that Go
pointing small integer interface values to its special static array
of the first 256 integers was similar to what some dynamic languages
do. For exampleÙ« Python effectively <a href="https://en.wikipedia.org/wiki/String_interning"><em>interns</em></a> a bunch of small
integers. HoweverÙ« in one important respect what Go is doing is
different from what Python and other languages are doing. In GoÙ«
this optimization is invisible to normalÙ« proper Go programsÙ« while
the equivalent in other languages <a href="https://utcc.utoronto.ca/~cks/space/blog/python/ObjectIdentityGotcha">often is visible in some
situations</a>.</p>

<p>The reason this optimization is visible to programs in Python is
that Python exposes the actual unique interned objects for small
numbers to you. Since you get access to these objectsÙ« you can tell
when two numbers from two completely different sources are actually
the same objectÙ« and sometimes this matters. (And since the unique
objects are directly exposed to youÙ« they have to be made immutable.)</p>

<p>Go doesn"t do this. Go works in values and values are always copiedÙ«
including when you create interface values from concrete values
(even if the concrete value is a pointer). <strong>How an interface value
holds its copy of the concrete value is invisible to Go programs</strong>.
When you create an interface value from a concrete valueÙ« the
interface value takes a copy of the concrete value and stores it
somehow. When you get the concrete value back using a <a href="https://tour.golang.org/methods/15">type assertion</a> or call a method on the concrete
type through the interface valueÙ« Go makes a copy of the concrete
value held by the interface value and gives it to you (or the
method). You never get a reference to the interface value"s copy
of the concrete value.</p>

<p>MechanicallyÙ« Go implements interface values using a pair of pointers
(<a href="https://research.swtch.com/interfaces">cf</a>)Ù« which means that
an interface value normally needs to allocate a place to put its
copy of the concrete value (which it will then have a pointer to).
But you never get access to the "pointer to the concrete value"
part of the interface value in normal Go and so you can never observe
that for a small integerÙ« it"s pointing into a static array instead
of into the heap.  Since you can"t see these pointersÙ« you also
can"t see that two different interface values have pointers to the
same entry in the static array.</p>

<p>(You can use <a href="https://golang.org/pkg/unsafe/">the <code>unsafe</code> package</a>
to crack open the otherwise opaque interface value and pull out the
pair of pointers. But then you"re not using normal Go.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/ManyRealLifeIdentities', 'People often have multiple social identities even in the physical realm', '1597285468000',  14, '<div class="wikitext"><p>Somewhat recentlyÙ« I read <a href="https://yarmo.eu/post/future-online-identity-decentralized">The Future of Online Identity is
Decentralized</a>
(<a href="https://lobste.rs/s/ckalve/future_online_identity_is_decentralized">via</a>)Ù«
and it said one thing in passing that made me twitch. I"ll quote rather
than paraphrase:</p>

<blockquote><p>Authenticity and anonymity aren"t mutually exclusive and that is
the beauty of the internet. In the physical realmÙ« you are (mostly)
limited to a single social identity. In the digital spaceÙ« there are
no such restrictions. While you can"t embody multiple persons in the
offline worldÙ« you can have several identities online. [...]</p>
</blockquote>

<p>This isÙ« in practiceÙ« not the case. Many people have what are in effect
multiple social identities in the real worldÙ« and you can even argue
that the lack of support for this in common platforms on the Internet
has created some real problems (especially for how people interact with
them).</p>

<p>The way you naturally create multiple social identities in the real
world is simple; you don"t tell everyone you interact with about
everything you doÙ« especially in detail. You are in practice one
person at workÙ« another person at homeÙ« a third person at <a href="https://tbn.ca/">your
bike club</a>Ù« a fourth person on the photowalks you
do (<a href="https://en.wikipedia.org/wiki/COVID-19_pandemic">or did</a>)
with the group of regularsÙ« and so on and so forth. These disjoint
groups of people may have some idea that you have other identities
(you may mention to your co-workers that you"re a keen bicyclist
and are in a bike club)Ù« but they probably don"t know the details
(and often they don"t want to). In practice these are different
social identities and you"re a different person to all of these
groups; each one may well know some things about you that would
surprise others who know you.</p>

<p>(My impression is that this separation is especially strong between work
and everything else. People like to draw a line here and not share back
and forth.)</p>

<p>By nowÙ« we"ve all heard stories of these separate social identities
breaking down (or being exposed) on the Internet in social mediaÙ«
in the familiar story of "I had no idea they were &lt;X>" (or "believed
in &lt;X>")Ù« where &lt;X> is often something uncomfortable to you. Before
FacebookÙ« TwitterÙ« and the likeÙ« this sort of thing required different
groups of people to talk to each other or have an unexpected
connection (sayÙ« one of your co-workers takes up bicycling and joins
your bicycle club). NowÙ« social media often slams all of that
together; if you see anything of someoneÙ« you may see everything.
Social media generally tacitly encourages this by making it easiest
to share everything with everyoneÙ« instead of providing good support
for multiple social identities on a single platform (leading to the
perennial "I followed you to read about &lt;X>Ù« not &lt;Y>" complaints
on Twitter and elsewhere).</p>

<p>(You can also argue that the Internet makes it easier for people
who want to cross connect your (online) identities to do soÙ« because
it made broad searches much easier. On the InternetÙ« you have to
be deliberately anonymous or simple web searches may well turn up
multiple social identities.)</p>

<p>Relatively strong Internet anonymity is probably easier than strong
physical anonymityÙ« at least today (where you can take someone"s
name you learned from one connection to them and start trying to
find other signs of them on the Internet). Physical social identities
necessarily leak what you look like and often your nameÙ« and you
can readily skip both on most of the Internet.</p>

<p>(Some portions of the Internet are very intent on knowing your real
nameÙ« but there"s still a broad norm that people can be anonymous
and pseudonymous. And if you have a relatively common nameÙ« even
your name is relatively pseudonymous by itselfÙ« because there
will be many people on the Internet with that name.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts', 'How Go 1.15 improved converting small integer values to interfaces', '1597207160000',  14, '<div class="wikitext"><p>In GoÙ« <a href="https://golang.org/ref/spec#Interface_types">interface values</a>
are famously implemented as a pair of pointers (see Russ Cox"s <a href="https://research.swtch.com/interfaces">Go
Data Structures: Interfaces</a>);
a pointer to information about the type and a pointer to the value
itself. This generally means that the value must be dynamically
allocated in the <em>heap</em>Ù« which means that it will contribute to the
work that Go"s garbage collection does.</p>

<p>The <a href="https://golang.org/doc/go1.15">Go 1.15 release notes</a> mention
an intriguing improvement in <a href="https://golang.org/doc/go1.15#runtime">the runtime section</a>:</p>

<blockquote><p>Converting a small integer value into an interface value no longer
causes allocation.</p>
</blockquote>

<p>When I saw thatÙ« I immediately wondered how it worksÙ« and especially
if Go"s runtime was now sometimes using the value pointer field in
interface values to directly store the value.
(There are a number of languages that do thisÙ« using various approaches
like <a href="https://wiki.c2.com/?TagBit">tag bits</a> to tell values from real
pointers.)</p>

<p>The answer turns out to be pretty straightforwardÙ« and is in <a href="https://go-review.googlesource.com/c/go/+/216401">Go
CL 216401</a> (merged
in <a href="https://github.com/golang/go/commit/9828c43288a53d3df75b1f73edad0d037a91dff8">this commit</a>Ù«
which may be easier to read). The Go runtime has a special static
array of the first 256 integers (0 to 255)Ù« and when it would
normally have to allocate memory to store an integer on the heap
as part of converting it to an interfaceÙ« it first checks to see
if it can just return a pointer to the appropriate element in the
array instead. This kind of static allocation of frequently used
values is common in languages with lots of dynamic allocation;
Python does something similar for small integersÙ« for example
(<a href="https://utcc.utoronto.ca/~cks/space/blog/python/ObjectIdentityGotcha">which can sometimes surprise you</a>).</p>

<p>(It turns out that Go previously had an optimization where if you were
converting 0 to an interface valueÙ« it would return a pointer to a
special static zero value. This new optimization for 0-255 replaces
that.)</p>

<p>There is one special trick that Go plays here. The actual array is
an array of <code>uint64</code>Ù« but it reuses the same array for smaller sized
values as well. On <a href="https://en.wikipedia.org/wiki/Endianness">little endian</a> systems like x86Ù« this
is fine as it stands because a pointer to a 64-bit value is also a
valid pointer to that value interpreted as 32 or 16 bits (or 8
bits). But on big endian systems this isn"t the caseÙ« so if Go is
running on a big endian machine it bumps up the pointer so that it
works properly (making it point to either the last two bytes or the
last four bytes of the 8-byte value).</p>

<p>(On a little endian machineÙ« the pointer is to the low byte of the
value and the remaining bytes are all zero so it doesn"t matter how
many more of them you look at. On a big endian machineÙ« the pointer
is to the high byteÙ« but the low byte is the thing that matters.)</p>

<p>As bonus trivia for this changeÙ« this new array of 0-255 <code>uint64</code>
values was then reused for avoiding allocating anything for one-byte
strings in another change (<a href="https://github.com/golang/go/commit/bda42a7a782dbcf4b123d617c5b60f3c848cbb82">this commit</a>Ù«
<a href="https://go-review.googlesource.com/c/go/+/221979">CL 221979</a>).
Go previously had an array of bytes for this purposeÙ« but why have
two arrays. Big endian machines need the same sort of pointer bumping
they did for small integers being converted to interface valuesÙ«
but little endian machines can once again use the pointers as is.</p>

<p>PS: There are runtime functions for converting 16Ù« 32Ù« and 64 bit
values to interface valuesÙ« in <a href="https://github.com/golang/go/blob/master/src/runtime/iface.go">runtime/iface.go</a>
(they can be inlined in actual code)Ù« but I was puzzled because
there is no runtime function for converting 8 bit values. It turns
out that 8-bit values are directly handled by the compiler in
<a href="https://github.com/golang/go/blob/master/src/cmd/compile/internal/gc/walk.go#L837">walk.go</a>Ù«
where it generates inline code that uses the <code>staticuint64s</code> array.
This may be done directly in the compiler partly because it needs
no fallback path for larger valuesÙ« unlike the 16Ù« 32Ù« and 64 bit
casesÙ« since an 8 bit value will always be in <code>staticuint64s</code>.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraAvoidingModules', 'Disabling DNF modules on Fedora 31 so they don"t mess up package updates', '1597113409000',  14, '<div class="wikitext"><p>Fedora 31 DNF modules (and probably Fedora 32 ones as well) are
currently brokenÙ« as covered <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailure">here</a>
and <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailureII">here</a>. Fedora is not insuring
that DNF modules that claim to be the "latest" (for example ripgrep)
have versions of their packages that are as recent as the non-modular
packages (the ripgrep module has 11.0.2; Fedora 31 has 12.0.1)Ù« and
the mere existence of a DNF module for something will block updatesÙ«
even if you have not enabled the module. The only way out is to
disable (or ignore) DNF modules.</p>

<p>If you want to temporarily ignore DNF modules to update your system
to the latest versions of packages available in the main Fedora 31
repositoryÙ« the following (from <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailure">my first entry</a>) appears to work:</p>

<blockquote><pre style="white-space: pre-wrap;">
dnf --setopt=updates.module_hotfixes=true --setopt=fedora.module_hotfixes=true update
</pre>
</blockquote>

<p>In <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailureII">my second entry</a> I thought that
removing everything from <code>/etc/dnf/modules.d</code> would prevent problems.
This turns out to not be the case. If you want to completely disable
DNF modulesÙ« you need to either edit /etc/yum.repos.d/fedora-modular.repo
to change "enabled=1" to "enabled=0"Ù« or remove the file entirely.
I would edit the fileÙ« as that probably has a higher chance to
survive package updates of the fedora-repos package. I believe
that you can also do this with "<code>dnf config-manager --set-disabled
fedora-modular</code>"Ù« but I"m the kind of person who uses an editor
here.</p>

<p>(Fedora has repo files in <code>/etc/yum.repos.d</code> for reasons of historical
compatibility and avoiding flag days where all repo files have to
moveÙ« one way or another.  It amuses me sometimes.)</p>

<p>I don"t yet know if upgrading Fedora with DNF keeps modules disabled.
I suspect not and that I"ll have to go back in to clean things out
after I upgrade to Fedora 32 one of these days. After my experiences
with modules to dateÙ« I have no intentions of ever having them doing
anything on any of my Fedora machines until and unless Fedora gives
me no choice in the matter.</p>

<p>I hope that this is the last entry I have to write about DNF modules.
There"s more that I could say about this mess but I"d rather not spend
more time on it.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraAvoidingModules?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/unix/UnixOptionsConventions', 'Unix options conventions are just thatÙ« which makes them products of culture', '1597027795000',  14, '<div class="wikitext"><p>Recently I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/MyOptionsConventions">my views on some conventions for Unix
command line options</a>Ù« where I disagreed in
part with what Chris Wellons considered <a href="https://nullprogram.com/blog/2020/08/01/">Conventions for Command
Line Options</a>. Both Wellons
and I have a lot of Unix experienceÙ« and that we disagreed on parts
of what rightfully should be a well established core of Unix in
practice shows some things about them.</p>

<p>The first thing to note about Unix"s conventions on options is that
they"ve always been ad hoc and imperfectly adhered toÙ« to the extent
that they even existed in the first place. To start withÙ« V7 Unix
did not have <code>getopt(3)</code>Ù« so every V7 program did its own parsing
of options and I"m certain that some of them had somewhat different
behavior. Several V7 programs completely broke these conventions;
famously <code>dd</code> doesn"t even use conventional options that start with
a "-"Ù« and while <code>find</code> has options that start with "-" they"re
actually more like GNU style long options.</p>

<p>(<a href="https://en.wikipedia.org/wiki/Getopt">Wikipedia</a> implies that
<code>getopt(3)</code> first appeared in System IIIÙ« and indeed <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=SysIII/usr/src/man/man3/getopt.3c">here"s the
System III <code>getopt(3)</code> manpage</a>Ù«
dating from 1980 (<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=SysIII/usr/src/man/man3">cf</a>Ù«
<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=SysIII">also</a>).)</p>

<p>The second thing is that both Wellons and I can go on about conventions
all we want (and what they should be)Ù« but the reality is that the
"conventions" that exist are defined by what programs actually do.
If a lot of programs (or a popular option parsing library) behave
in a particular wayÙ« in practice that is the convention regardless
what I think of it (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/MyOptionsConventions">or write</a>). The corollary
of this is that what people consider convention is in large part
defined by how the programs they use behave. By its mere existence
and popularityÙ« GNU Getopt has defined a lot of the modern conventions
for options handling; if you deviate from itÙ« you will surprise
people who expect your programs to behave like the other programs
they use every day.  Before GNU Getopt was what most programs usedÙ«
<code>getopt(3)</code> did the same thing and had the same effect for the
conventions it enforced.</p>

<p>(New options parsing libraries tend not to break too much with the
current convention when they were initially writtenÙ« but they can
selectively change some of themÙ« especially what are considered more
obscure ones.)</p>

<p>FinallyÙ« I suspect that part of the difference between Wellons" view
of these conventions and mine is because of when we came into Unix. I
started using Unix long enough ago that it was in the era of classic
<code>getopt(3)</code> instead of GNU Getopt (and long options)Ù« so the rules that
<code>getopt(3)</code> enforced were the ones that I wound up internalizing as the
correct conventions. Someone who came into Unix later would have been
primarily exposed to GNU Getopt"s somewhat different behaviorÙ« with it
supporting intermixed options and non option argumentsÙ« long options
being routineÙ« and so on.</p>

<p>The corollary of this is that people who come into Unix today
are learning the conventions as they stand nowÙ« including any
inconsistencies between Unix programs that are increasingly written in
different languagesÙ« with different argument parsing librariesÙ« and so
on.  Some languages are sufficiently divergent that no one is going to
mistake them for "how Unix commands should behave" (I"m looking at youÙ«
Go)Ù« but others are close enough that people are likely to internalize
parts of their behaviorÙ« even if only as expected divergences and
differencesÙ« just as people remember <code>find</code> and its unusual behavior.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/UnixOptionsConventions?showcomments#comments">9 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailureII', 'More problems with Fedora 31 DNF modules and package updates', '1596944499000',  14, '<div class="wikitext"><p>A while back I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailure">how Fedora 31 had fumbled DNF modules
and package updates</a>Ù« which ended with
me believing that I had fixed the problem so that I would get updates
to packages I cared about despite the DNF module versions not being
updated. Then recently <a href="https://twitter.com/thatcks/status/1291373423655084034">I tweeted</a>:</p>

<blockquote><p>It turns out that Fedora 31 DNF modulesÙ« even reset ones that aren"t
activeÙ« are apparently still both out of date and blocking package
updates. Modular ripgrep is 11.xÙ« current main repo ripgrep is 12.1.0Ù«
but good luck getting that.</p>

<p>Dear Fedora: If I have to resort to bodhi to get the latest
stable main repository version of packagesÙ« DNF has failed
*spectacularly*. If these packages had security updatesÙ« there
would be real issues here.</p>
</blockquote>

<p><a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailure">As before</a>Ù« for a while "<code>dnf updateinfo
info</code>" has been telling me that there was an update to ripgrep
availableÙ« to 12.1.0 (I had 12.0.0). However I couldn"t get <code>dnf</code>
to actually apply the updateÙ« and the latest version that the
"ripgrep" module has is 11.0.2. Similar problems were reported for
meson and a couple of other packages. This is despite the fact that
I had no DNF modules enabled; I had reset all of them in <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailure">my first
go around</a>.</p>

<p>To actually get the current packagesÙ« I resorted to the brute force
approach of <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraBodhiGetPackages">downloading them through <code>bodhi</code></a>.
This is not an approach that most people can do (most people aren"t even
aware of <a href="https://fedoraproject.org/wiki/Bodhi">Bodhi</a>).  Looking backÙ«
it"s possible that I could have succeeded by using the set of command
line options from <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailure">my first entry</a>. I
didn"t think of trying it at the timeÙ« and anyway I knew that Bodhi
would work for sure and I had already wasted enough time (and
accumulated enough frustration on Fedora DNF"s broken modularity).</p>

<p>Allow me to emphasize that: <strong>as it currently standsÙ« Fedora DNF modules
are broken</strong>. Module packages are not being kept up to date (even when
the module claims to be the "latest" version of a program) and the mere
existence of modules blocks you from getting up to date packages from
the main repository. If I could completely remove or turn off DNF
modulesÙ« I wouldÙ« but as far as I know they"re deeply integrated into
DNF and aren"t optional in that way.</p>

<p>After I went through the Bodhi approach I hunted around and found
an assortment of files in <code>/etc/dnf/modules.d</code>Ù« which appears to
be where DNF records modules you"ve done anything at all with. There
were files lingering here for every DNF module I"d ever had enabledÙ«
even if I"d done "<code>dnf module reset ..</code>" on them. I removed all of
these filesÙ« so maybe the next time there"s a new ripgrep update
I"ll get it without any hassles.</p>

<p>(I knowÙ« I have to update to Fedora 32 sometimeÙ« which is going to
re-enable various modules that I"ll have to clean out again. I
haven"t gotten around to it the way I usually do because all of my
usual processes for this have been thrown off by working from home
all of the time due to <a href="https://en.wikipedia.org/wiki/COVID-19_pandemic">ongoing world and local events</a>.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailureII?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/GrafanaOurIntervalSettings', 'How we choose our time intervals in our Grafana dashboards', '1596852370000',  14, '<div class="wikitext"><p>In a comment on <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">my entry on our Prometheus and Grafana setup</a>Ù« trallnag asked a good question:</p>

<blockquote><p>Would you mind sharing your concrete approach to setting the time
intervals for functions like rate() and increase()?</p>
</blockquote>

<p>This is a good questionÙ« because trallnag goes on to cover why this
is an issue you may want to think about:</p>

<blockquote><p>I tend to switch between using $__intervalÙ« completely fixed
values like 5m or a Grafana interval variable with multiple
interval to choose from. None are perfect and all fail in certain
circumstancesÙ« ranging from missing spikes with $__interval to
under or oversampling with custom intervals.</p>
</blockquote>

<p>The very simple answer is that so far I"ve universally used
$__intervalÙ« which is <a href="http://docs.grafana.org/reference/templating/#the-interval-variable">Grafana"s templating variable for
"whatever the step is on this graph given the time scale you"re
currently covering"</a>.
Using $__interval means that your graph is (theoretically)
continuous but without oversampling; every moment in time is used
for one and only one graph point.</p>

<p>The more complete answer is that we use $__interval but often
tell Grafana that there is a minimum interval for the query that
is usually slightly larger than how often we generate the metric.
When you use <code>rate()</code>Ù« <code>increase()</code>Ù« and their kinÙ« you need to
make sure that your interval always has at least two metric pointsÙ«
otherwise they give you no value and your graphs look funny. Since
we"re using variable intervalsÙ« we have to set the minimum interval.</p>

<p>In a few graphs I"ve experimented with combining <code>rate()</code> and <code>irate()</code>
with an <code>or</code> clause:</p>


<blockquote><pre style="white-space: pre-wrap;">
rate( ...[$__interval] ) or
   irate( ...[4m] )
</pre>
</blockquote>

<p>The idea here is that if the interval is too short to get two metric
pointsÙ« the <code>rate()</code> will generate nothing and we fall through to
<code>irate()</code>Ù« which will give us the rate across the two most recent
metric points (see <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusRateVsIrate"><code>rate()</code> versus <code>irate()</code></a>).
UnfortunatelyÙ« this is both annoying to write (since you have to
repeat your metric condition) and inefficient (since Prometheus
will always evaluate both the <code>rate()</code> and the <code>irate()</code>)Ù« so I"ve
mostly abandoned it.</p>

<p>The high level answer is that we use $__interval because I don"t
have a reason to make things more complicated. Our Grafana dashboards
are for overviews (even detailed overviews)Ù« not narrow troubleshootingÙ«
and I feel that for this a continuous graph is generally the most
useful. It"s certainly the easiest to make work at both small and large
timescales (including ones like "the last week"). We"re also in the
position where we don"t care specifically about the rate of anything
over a fixed interval (egÙ« "error rate in the last 5 minute should be
under ...")Ù« and probably don"t care about momentary spikesÙ« especially
when we"re using a large time range with a dashboard.</p>

<p>(Over a small time rangeÙ« a continuous graph of <code>rate()</code> will show you
all of the spikes and dips. Or you can go into Grafana"s "Explore" and
switch to <code>irate()</code> over a fixedÙ« large enough interval.)</p>

<p>If we wanted to always see short spikes (or dips) even on dashboards
covering larger time rangesÙ« we"d have to use the more complicated
approach I covered in <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusSubqueriesForSpikes">using Prometheus subqueries to look for spikes
in rates</a>. There"s no clever choice of
interval in Grafana that will get you out of this for all time ranges
and situationsÙ« and Prometheus currently has no way to find these spikes
or dips short of writing out the subquery. Going down this road also
requires figuring out if you care about spikesÙ« dipsÙ« or bothÙ« and if
it"s both how to represent them on a dashboard graph without overloading
it (and yourself).</p>

<p>(AlsoÙ« the metrics we generally graph with <code>rate()</code> are things that we
expect to periodically have short term spikes (often to saturationÙ« for
things like CPU usage and network bandwidth). A dashboard calling out
that these spikes happened would likely be too noisy to be useful.)</p>

<p>PS: This issue starts exposing a broader issue of what your Grafana
dashboards are forÙ« but that"s another entry.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/UbuntuOldPackageProblem', 'Our problem installing an old Ubuntu kernel set of packages', '1596772803000',  14, '<div class="wikitext"><p>On TwitterÙ« <a href="https://twitter.com/thatcks/status/1291453564527824897">I said</a>:</p>

<blockquote><p>It has been "0" days since I"ve wound up hating Debian"s choice to
sign package metadata instead of packages (or perhaps "in addition to"
these days). Why? Because it makes it much more difficult to support
"install a packageÙ« satisfying dependencies from this directory of
debs".</p>
</blockquote>

<p>Naturally there is a story here.</p>

<p>We have some <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">Linux fileservers</a> running
UbuntuÙ« and we are very controlled about upgrading their kernel
versions (partly because of <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu1804OddKernelPanic">mysterious crashes</a>). We have a new kernel version that"s
proven on our test fileserver and our most recently build fileserver
(which is itself a story)Ù« and we"re looking at upgrading the other
fileservers to that kernel. HoweverÙ« this kernel is not the most
recent Ubuntu kernel; it"s sufficiently old that it"s no longer in
the official Ubuntu package repositories.</p>

<p>We have our own local Ubuntu mirrorÙ« where we never delete packagesÙ«
and it has all of the many linux-* packages and meta-packages
required. HoweverÙ« we can"t just do "<code>apt-get install
linux-generic=...</code>" and get all of those packages. Because these
older Linux kernels aren"t in the Ubuntu official package repositoriesÙ«
they"re not in the official repository index files. Because these
index files are signedÙ« our mirror can"t just rebuild them to reflect
the full set of packages we have available. Although we have these
files available on our mirrorÙ« we can"t use themÙ« at least not
easily.</p>

<p>SimilarlyÙ« I suspect this fundamental assumption of signed index files
(or at least the existence of index files) is part of why I don"t think
any <code>dpkg</code> frontend has an option to just get packages and dependencies
from a directory you supply. You can "<code>dpkg -i *.deb</code>" for everything in
a directoryÙ« but that requires you to carefully curate the directory to
have absolutely everything requiredÙ« and Ubuntu kernels come in a rather
large number of packages.</p>

<p>(If there is a command line frontend that supports thisÙ« I would like to
know about it. I don"t count dropping .debs into /var/cache/apt/archives
for aptÙ« although I"ve read that it actually works.)</p>

<p>You don"t really have this problem on RPM based systems like
CentOS. Since all RPM packages themselves are signedÙ« signed metadata
isn"t as important and tools like <code>yum</code> and <code>dnf</code> are generally happy to
work with a pool of RPMs in a directory.</p>

<p>(Note that <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/UnsignedMetadataExploits">unsigned repository metadata opens you up to some attacks</a>Ù« so you definitely want to sign it if
possible. It"s also safe to generate your own local unsigned repository
metadataÙ« since you generally trust yourself.)</p>

<p>(See also <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/UbuntuISOPackageUpdate">my wish to be able to easily update the packages on an
Ubuntu ISO image</a>Ù« which also runs into
this issue.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/UbuntuOldPackageProblem?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/unix/MyOptionsConventions', 'My views on some conventions for Unix command line options', '1596684851000',  14, '<div class="wikitext"><p>Recently I read Chris Wellons" <a href="https://nullprogram.com/blog/2020/08/01/">Conventions for Command Line Options</a>Ù« which reviews these
conventions. As it happensÙ« I learned and have internalized a
somewhat different version of how these conventions should be and
how I expect programs to behave. I"m not going to mention things
where my expectations agree with Wellons" presentation of the
conventionsÙ« just where I differ.</p>

<p>On short options that accept an argumentÙ« Wellons says:</p>

<blockquote><p>This technique is used to create another categoryÙ« <em>optional option
arguments</em>. The optionâ€™s argument can be optional [...]</p>
</blockquote>

<p>There are no optional option arguments; an option either always
takes an argument or it never does. This is how the traditional
<code>getopt(3)</code> behavesÙ« at least as far as I rememberÙ« and appears to
be how <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=4.3BSD/usr/man/man3/getopt.3">the 4.3 BSD <code>getopt(3)</code> manpage</a>
documents it.</p>

<p>(It"s also how <a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/getopt.html">POSIX <code>getopt()</code></a>
is required to behave; see the discussion of how <code>optarg</code> is set.)</p>

<blockquote><p>Options can typically appear in any order â€” something parsers
often achieve via <em>permutation</em> â€” but non-options typically follow
options.</p>
</blockquote>

<p>Non-options always follow options. By extensionÙ« the first non-option
argument terminates scanning for options; any remaining "-..."
things become arguments. Again this is how the 4.3 BSD <code>getopt(3)</code>
is documentedÙ« and in fact that options and non-options can"t be
intermixed is mostly required by the <code>getopt(3)</code> API.</p>

<p>(How <code>getopt(3)</code> returns non-option arguments to you is that it
gives you the index of the first argument in <code>argv</code>. To support
intermixed options and non-optionsÙ« it would have to permute the
order of entries in <code>argv</code> to move all options up to before all
non-options. In modern C definitions of <code>getopt(3)</code>Ù« including <a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/getopt.html">the
POSIX one</a>Ù« I
believe this is forbidden because <code>argv</code> is declared <code>const</code>.)</p>

<p>My strong cultural expectations for option handling only cover short
options; while I have opinions about how long options should actÙ«
they"re not as visceral as for short options. Just as with short options
and for much the same pragmatic reasonsÙ« I don"t believe in long options
with optional option arguments; long options should either always take
an argument or never do so. Behaving otherwise breaks my expectation
that long options are just the same as short options except longer
(and they can"t be groupedÙ« and there"s that optional "=" thing for
arguments).</p>

<p>(This difference between my views and Chris Wellons" views points out
some general issues hereÙ« but that"s for another entry.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/MyOptionsConventions?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu2004MaybeMostlySkipping', 'We may wind up significantly delaying or mostly skipping Ubuntu 20.04', '1596603243000',  14, '<div class="wikitext"><p>Back at the start of AprilÙ« I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu2004TimingIssues">how we might face some
issues with the timing of Ubuntu 20.04</a>Ù« given
<a href="https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic">ongoing world and local events</a>Ù«
because we generally need to be in the office to deploy 20.04
machines and upgrade machines to 20.04. Back thenÙ« I optimistically
hoped for a return to normality and the office perhaps by JulyÙ« and
in any case not lots and lots later. That is not the situation we"ve
wound up in. InsteadÙ« it seems most likely that we won"t be in the
office on regular basis until next spring at the earliest.</p>

<p>The highest priority machines to upgrade are our remaining Ubuntu
16.04 machinesÙ« which will be going out of support in April of next
year. Fortunately we don"t have very many of them compared to our
18.04 machinesÙ« so there is not a huge amount of work to do.
UnfortunatelyÙ« most of our Exim based mail machines are 16.04 and
<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/EximTaintingPain">the 20.04 version of Exim is a significantly disruptive upgrade</a>Ù« plus a number of the remaining machines
are delicate to upgrade (our Samba serverÙ« for example).</p>

<p>This opens up the issue of what Ubuntu version to upgrade these
16.04 machines to. Normally we"d upgrade them to Ubuntu 20.04Ù« but
normally we"d already be running less critical machines on 20.04
and getting experience with it; this time they"d be among our first
20.04 machines. On the other sideÙ« we"re already running Ubuntu
18.04 in general and in some cases running the same services on
18.04 as we currently do on 16.04 (we have a couple of 18.04 Exim
machinesÙ« for example). This makes upgrading most or all of our
16.04 machines to 18.04 instead of 20.04 a reasonably attractive
propositionÙ« especially for Exim based machines. We"d have to upgrade
them again in two years when 22.04 comes out and 18.04 starts going
out of supportÙ« but hopefully in two years the situation will be a
lot different.</p>

<p>(If we"re not back in the office in two yearsÙ« it seems likely that
a fair number of things will have changed in our operations. And
in any case we"ll have a lot more experience with remote operationÙ«
and possibly hardware that better supports it.)</p>

<p>If we only have limited time in the office to work on machinesÙ«
going out of our way to upgrade 18.04 machines to 20.04 seems like
a bad use of timeÙ« even if they"re machines that we normally try
to keep on the latest version of Ubuntu (such as our user login
servers). There will be new machines and there are some machines
where we want to rework them anyway for various reasonsÙ« and both
of these may sensibly wind up on 20.04Ù« but otherwise I suspect
we"re going to leave more machines than usual at 18.04 until
we"re back in the office.</p>

<p>(New services can go on Ubuntu 20.04 without causing any extra problemsÙ«
because we"d have to develop and explore them no matter what Ubuntu
version we used for them.)</p>

<p>If we get back in the office on an ongoing basis next summerÙ« we could
start upgrading machines to Ubuntu 20.04 thenÙ« but Ubuntu 22.04 will
be only a year away. We may well decide to stick with 18.04 for most
machines and move them to 22.04 when it comes out.</p>

<p>Overall this seems likely to leave us with relatively modest use
of Ubuntu 20.04Ù« although we"re definitely planning to use it for
some things. To the extent that we do use Ubuntu 20.04Ù« our use is
going to be slow and delayed (and has already been delayed from our
usual timeline).</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu2004MaybeMostlySkipping?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/EximTaintingPain', 'Exim"s change to "taint" some Exim variables is going to cause us pain', '1596511189000',  14, '<div class="wikitext"><p><a href="https://www.exim.org/">Exim</a> is a very flexible mail system (aka
a MTAÙ« Mail Transfer agent)Ù« to the extent that in its raw state
<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/EximMailerKit">Exim is a mailer construction kit</a> more than a
mailer (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PostfixVsExim">if you want a simple mailerÙ« consider Postfix</a>).
You can use this power for a lot of thingsÙ« like <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/SimpleEximMailingLists">building simple
mailing lists</a>Ù« where a mailing list is
created by putting a file of addresses in a specific directory (the
name of the file being the name of the mailing list).</p>

<p>This flexibility and power can create security issuesÙ« for example
when you directly use information from the incoming mail message
(information that"s under the control of the sender) to open a file
in a directory. If not carefully controlledÙ« an attacker who knows
enough about your Exim configuration could possibly make you open
files you don"t intend toÙ« like "../../../etc/passwd".</p>

<p>(This is a standard risk when using information that"s ultimately
provided by an attacker.)</p>

<p>For a long timeÙ« Exim left it up to whoever wrote your Exim
configuration file to worry about this. It was on them to do input
validation to make sure that /cs/lists/<a href="https://www.exim.org/exim-html-current/doc/html/spec_html/ch-string_expansions.html#SECTexpvar">$local_part</a>
would never have anything dangerous in it. Recently the Exim developers
decided that this was not sufficient and introduced the idea of
"tainted data"Ù« which isn"t allowed to be used in various places
(especiallyÙ« as part of a filename that will be opened or accessed).
Things that are under the control of a potential attackerÙ« such as
the local part or the domain of an addressÙ« are tainted.</p>

<p>UnfortunatelyÙ« there are a lot of places where it"s traditionally
been natural to use the Exim <code>$local_part</code> string variable as
part of file accessÙ« which is now tainted and forbidden. SpecificallyÙ«
we have various places in the Exim configurations for several mail
machines that use it. These uses are safe in our environment because
we only make use of <code>$local_part</code> after it"s been verified to
exist in our generated list of valid local addressesÙ« but Exim isn"t
smart enough to know that they"re safe. Instead there are a collection
of ways to de-taint strings (<a href="https://www.mail-archive.com/exim-users@exim.org/msg54831.html">eg</a>Ù«
<a href="https://www.mail-archive.com/exim-users@exim.org/msg54904.html">also</a>Ù«
<a href="https://www.mail-archive.com/exim-users@exim.org/msg54739.html">also</a>Ù«
<a href="https://mox.sh/sysadmin/tainted-filename-errors-in-exim-4.94/">also</a>)Ù«
which from one perspective are a set of artificial hoops you now
have to jump through to pacify Exim. Some of these options for
de-tainting are backward compatible to versions of Exim before
tainting was introducedÙ« but generally the compatible ways are more
awkward than the modern best ways.</p>

<p>PeopleÙ« us includedÙ« who upgrade to a version of Exim that includes
tainting will have to go through their Exim configuration files and
revise them to de-taint various things the configuration needs to
use. For usÙ« this has to happen for any upgrade of our mail machines
to Ubuntu 20.04; 20.04 has a version of Exim with taintingÙ« while the
Exim versions in 18.04 and 16.04 are pre-tainting ones. This means that
upgrading any of our mail machines to Ubuntu 20.04 needs configuration
changesÙ« and some of these configuration changes may not be backward
compatible.  I think I can find all of the places where our Exim
configurations might use tainted dataÙ« but I"m not completely confident
of that; if I miss oneÙ« we"re going to experience Exim errors and
failures to properly process some email in production.</p>

<p>This is going to be a little bit painful. I"m not looking forward to
itÙ« especially as it is yet another case of "do more work to wind up
in exactly the same place".</p>

<p>(There"s an obvious better way for the Exim people to have done this
transition to tainted dataÙ« but it would have been slower and meant that
Exim remained insecure by default for longer.)</p>

<p>PS: We"re at least better off than the people on CentOS using EPELÙ«
who apparently got a "tainted data" version of Exim just dropped
on them as a regular package update (<a href="https://bugzilla.redhat.com/show_bug.cgi?id=1848283">cf</a>).</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/python/DjangoErrorPropagationIssue', 'The issue of how to propagate some errors in our Django web app', '1596428190000',  14, '<div class="wikitext"><p>Much of what <a href="https://utcc.utoronto.ca/~cks/space/blog/python/DjangoORMDesignPuzzleII">our Django application to handle (Unix) account
requests</a> does is only available to special
people such as professorsÙ« who can actually approve account requests
instead of just making them. Following our usualÙ« we protect the
management section of the web app with <a href="https://utcc.utoronto.ca/~cks/space/blog/web/ApacheBasicAuthWhy">Apache HTTP Basic
Authentication</a>Ù« where only people in
designated Unix groups (such as the "sponsors" group) have access.
HoweverÙ« the Django application also has a "users" tableÙ« and in
order to have access to the application you have to be in it (as
well as be in a Unix group that"s allowed access). Normally we
maintain these two things in sync; when we add someone to the
relevant Unix groupÙ« we also add them as a user (and set the type
of user they areÙ« and set up other necessary data for people who
can sponsor accounts). But sometimes we overlook this extra step
so people wind up permitted by Apache but not in the "users" table.
If they actually try to use our web applicationÙ« this causes it to
stop with an error.</p>

<p>(This "users" table is part of the application"s own set of tables
and modelsÙ« not <a href="https://docs.djangoproject.com/en/3.0/topics/auth/default/">the normal Django authentication system"s User
table</a>.
Possibly I should have handled this differently so that it"s more
integrated with normal Django stuffÙ« but when I started this web
application I was new to Django and keeping things completely
separate was much easier.)</p>

<p>Right nowÙ« a bunch of our views look like this at the start:</p>


<blockquote><pre style="white-space: pre-wrap;">
def approve(request):
  urec = get_user(request)
  if urec.is_staff():
    ...
  ...
</pre>
</blockquote>

<p>You"ll note that there"s no error handling. This is because
<code>get_user()</code> does the brute force simple thing (with some error
checks removed):</p>

<blockquote><pre style="white-space: pre-wrap;">
def get_user(request):
  user = request.META["REMOTE_USER"]
  try:
    return models.User.objects.get(login=user)
  except models.User.DoesNotExist:
    ... log a message ...
    raise django.http.Http404
</pre>
</blockquote>

<p>This is simple and reliableÙ« but it has a downsideÙ« which is that
people who run into this mistake of ours get the same HTTP 404 error
page that they"d get if they were trying to go to a URL that genuinely
didn"t exist in our application. This is at best uninformative and
at worst confusingÙ« and I"d like to do better. Unfortunately I"m
not sure what the best way to do it is.</p>

<p>My first attempt was to raise Django"s Http404 error with a specific
message string and then try to make our template for the application"s
404 error page check for that string and generate a different set of
messages. That failedÙ« because as far as I can see either Django drops
the message string at some point in its processing or doesn"t pass it to
your custom template as a template variable.</p>

<p>I can see three alternate approachesÙ« none of which I"m persuaded
by. The simple but unappealing option is to change <code>get_user()</code>
to return an error in this situation. This would require a boilerplate
change at every place it"s called to check the error and handle it
by generating a standard "we screwed up" response pageÙ« which makes
the code feel like Go instead of Python. But at least how things
worked would be obvious (and if I returned <code>None</code>Ù« I could make
failures to handle this case relatively obvious).</p>

<p>The more complicated but less code approach is to raise a custom
error and wrap every function that calls <code>get_user()</code> with a
decorator that catches the error to generate and return the standard
explanation page. I would have to decorate every view function that
directly or indirectly calls <code>get_user()</code> (and remember to add
this if I added new functions)Ù« and decorators are sort of advanced
Python magic that aren"t necessarily either clear or straightforward
for people to follow.</p>

<p>I suspect that the way I"m supposed to do this in Django is with
some form of middleware. If I kept to much of the current approachÙ«
I could do this with a middleware that just used
<a href="https://docs.djangoproject.com/en/3.0/topics/http/middleware/#process-exception"><code>process_exception()</code></a>Ù«
but that doesn"t seem the most idiomatic way. Since this is a common
processing step for anything protected behind HTTP Basic AuthenticationÙ«
it feels like the middleware should do the user lookup itself and
attach it to the request somehowÙ« with the actual views not even
calling <code>get_user()</code>. But I don"t know how to attach arbitrary
data to Django"s request objectsÙ« and anyway that involves even
more Django magic than middleware that catches a custom exception
(and the magic is less clearÙ« since the view functions would just
access data without any obvious reason for it to be there).</p>

<p>(I care about the amount of magic involved in any solution because
my co-workers aren"t particularly familiar with Django and even I
only touch the code every once in a while. Possibly this means I
should just use the explicit error checking versionÙ« even if it
makes me twitch.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/python/DjangoErrorPropagationIssue?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/TickersVersusSleeping', 'Getting my head around the choice between sleeping and "tickers"', '1596338681000',  14, '<div class="wikitext"><p>If you have a program that wants to do something periodicallyÙ« say
once every ten secondsÙ« the obvious and simplest way is to just
sleep for ten seconds after each time you do the thing. For example:</p>


<blockquote><pre style="white-space: pre-wrap;">
while True:
  collect_device_stats()
  publish_device_stats()
  time.sleep(10)
</pre>
</blockquote>

<p>Some languages and libraries also offer an API that I"ve seen called
a "ticker"; GoÙ« for exampleÙ« has <a href="https://golang.org/pkg/time/#Ticker"><code>time.Ticker</code></a>. A ticker signals or invokes
you somehow every time intervalÙ« such as every ten seconds. With
a tickerÙ« you could write the above (in Go) as something like:</p>

<blockquote><pre style="white-space: pre-wrap;">
ticker := time.NewTicker(10*time.Second)
for {
  t := &lt;- ticker.C
  collect_device_stats(t)
  publish_device_stats(t)
}
</pre>
</blockquote>

<p>The big difference between the two is that <strong>a ticker is indifferent
to how long it took you to do your work</strong>. If collecting and
publishing device stats takes two secondsÙ« the sleep approach means
that you will do this once every twelve seconds (two seconds for
the work followed by ten seconds of sleeping). The ticker approach
will collect and publish once every ten secondsÙ« because it signals
you every ten seconds even if it took you two seconds to collect
and publish device stats.</p>

<p>While this may make tickers sound greatÙ« this behavior has potential
downsides. Which one you want depends partly on what your reasons are
for sleeping or delaying. In particularÙ« if you"re sleeping to limit
the load your actions createÙ« then a ticker may not be what you wantÙ«
precisely because it"s indifferent to how long your work took. If your
work takes nine seconds and you sleep afterward for tenÙ« you"re keeping
things less than 50% busy. If your work takes nine seconds and you have
a ten second tickerÙ« you"re keeping things 90% busy; one second after
you finish your work the ticker will go off again and start it all over.</p>

<p>Tickers are great for things you want to happen every N secondsÙ«
even if they take a bunch of time (or a variable amount of time).
Sleeping is great for things you want to happen no more often than
once every N seconds. HoweverÙ« the difference between the two only
matters if what you"re doing does (or may) take an appreciable
amount of time compared to the tick (or sleep) interval; if it isn"t
going toÙ« you might as well use whichever API is more idiomatic and
convenientÙ« although tickers will probably make things more regular
and precise.</p>

<p>(This set of thoughts was sparked by poking around in <a href="https://gitlab.com/shouptech/cyberpower_exporter">some Python
code</a> that used
the <code>sleep()</code> idiom and then thinking about how it would probably
use a ticker in Go. (WellÙ« in Go it would have a better API for what
it"s doingÙ« but apart from that.))</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/TickersVersusSleeping?showcomments#comments">5 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/AlertsIncludeObvious', 'Putting some extra "obvious" information into our temperature alerts', '1596252195000',  14, '<div class="wikitext"><p>As part of <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">our Prometheus system</a>Ù«
we monitor the temperature in our machine rooms and wiring areas
and send out alerts if the temperature gets what we consider to be
"too high". The alert email generated for high temperatures is a
slight variation of our general alert message; it has some generic
framingÙ« a specific message generated in Prometheus to describe the
situationÙ« and a convenient link to the Grafana dashboard for that
temperature sensor.</p>

<p>We don"t fix the AC systems in our machine rooms ourselves; for the
most partÙ« they"re considered part of the building"s infrastructure
and are managed by <a href="https://www.fs.utoronto.ca/">the university people who look after the
buildings</a>. When there"s an AC problemÙ«
part of what we do is to call those people to notify them of the
problemÙ« and there"s a standard set of contacts. Probably this is
all pretty normal for handling machine room AC.</p>

<p>Last weekÙ« we got a temperature alert (fortunately for a transient
condition). As I started to deal with the issueÙ« I once again had
to remind myself of who we called and what their phone number was.
We"ve had to deal with machine room AC issues often enough recently
that I could trace through the logic of who it wasÙ« but not so much
that I had the phone numbers memorizedÙ« so there was a certain
amount of going through <a href="https://www.fs.utoronto.ca/">university websites</a>
and scanning some old email from past incidents and so on. As I was
doing thisÙ« I slapped myself on the foreheadÙ« because <em>the AC contact
information should have been in the alert email</em>.</p>

<p>This contact information is obvious in one senseÙ« and it doesn"t
vary from sensor to sensor and alert to alert in the way that the
specifics of the situation and even the link to the temperature
sensor"s dashboard do. But it"s completely predictable that we"re
going to want the information when we get a temperature alertÙ« and
for all that it"s obvious and standardÙ« I don"t generally deal with
AC issues often enough to actually remember all of it (my co-workers
may have better memories). This makes it a good thing to put in
temperature alertsÙ« so once I"d looked up everything (and the
temperature had gone down again on its own)Ù« I updated the alerts
to have a short footer that tells us who to call.</p>

<p>I"ve read various things on alerting that said alerts should ideally
include links to <a href="https://en.wikipedia.org/wiki/Runbook">runbooks</a>.
However I always interpreted it as "runbooks for specific alerts"
and the runbooks being for big thingsÙ« not a little snippet of
general information for a whole class of alerts. Of course in
retrospect this is a bit silly.</p>

<p>My moral from this is that I should always try to think through
what people getting the alert will immediately wantÙ« then consider
putting it into the alert (either directly or perhaps on a web
page). This is worth thinking about even if it feels like standard
and obvious informationÙ« because what"s obvious now may not be
obvious when the alert goes off for the first time in six months.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/AlertsIncludeObvious?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/IPMIPortIsolatedNetwork', 'Putting IPMIs on a port isolated network to deal with shared network interfaces', '1596167069000',  14, '<div class="wikitext"><p>Yesterday I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/IPMISharedInterfaceProblem">the problem of "shared" IPMI network
interfaces</a>Ù« which is that when the
host and the IPMI both have access to the same physical network
portÙ« you"re exposed to a compromised host putting itself on your
<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/KVMOverIPSecurity">secure IPMI network</a> and compromising other
IPMIs (and then hosts) over it. There was a discussion about this
<a href="https://lobste.rs/s/5dknzm/problem_shared_ipmi_network_interfaces">on lobste.rs</a>Ù«
where <a href="https://lobste.rs/s/5dknzm/problem_shared_ipmi_network_interfaces#c_jaarka">lobste.rs user sn made an excellent suggestion</a>:</p>

<blockquote><p>The L2 feature you are looking for is called a protected port. This
should be available on any managed switchÙ« but Iâ€™ll link to the
cisco documentation: <a href="https://www.cisco.com/en/US/docs/switches/lan/catalyst3850/software/release/3.2_0_se/multibook/configuration_guide/b_consolidated_config_guide_3850_chapter_011101.html">[link]</a></p>
</blockquote>

<p>("Protected ports" are what I know as <a href="https://en.wikipedia.org/wiki/Private_VLAN">port isolation</a>Ù« where hosts connected
to these isolated ports can only talk to designated "uplink" portsÙ«
not with each other.)</p>

<p>This is a great suggestion and a great idea. Generally your IPMIs don"t
need to communicate with each otherÙ« they only need to communicate with
upstream machines that monitor themÙ« collect syslog messagesÙ« connect
to them to manage serversÙ« and so on. If you put all of the ports used
for IPMIs on a port isolated network (or on a port isolated subset of
switches)Ù« a compromised server can"t bring up the host side of a shared
IPMI network interface to talk to the other IPMIs; it can only talk to
the upstream serversÙ« which are hopefully a lot more secure than the
IPMIs (which often aren"t).</p>

<p>If we were to design a new IPMI network from scratchÙ« I would at
least suggest this and see if my co-workers could spot a reason
it"s a bad idea in our setup. Our current IPMI network drifted into
that role (which is a story all in its own right)Ù« so it"s <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/CSLabNetworkLayout">an
ordinary "sandbox" private network</a> without
port isolation; we probably don"t want to go back to revise it to
be port isolatedÙ« especially <a href="https://en.wikipedia.org/wiki/COVID-19_pandemic">these days</a>.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/IPMISharedInterfaceProblem', 'The problem of "shared" IPMI network interfaces', '1596077289000',  14, '<div class="wikitext"><p>These daysÙ« most of our servers have some form of <a href="https://en.wikipedia.org/wiki/Intelligent_Platform_Management_Interface">IPMI</a>
supportÙ« including a network connection for their IPMI and any
associated services (like KVM over IP). HoweverÙ« there is a significant
variation in how this network connection is provided in hardwareÙ« and
that causes some problems for actually using IPMI with less expensive
servers in environments where you care about security.</p>

<p>The best servers have a separate physical network port that"s only
accessible to and used by the IPMI. The physical machine may have
three network ports on the backÙ« but the host machine (the server)
is only connected to two; the third is connected only to the IPMI.
This is typical for our Supermicro servers as used inÙ« for exampleÙ«
<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">our Linux ZFS fileservers</a>.</p>

<p>On other servers of oursÙ« there is no network port that"s connected only
to the IPMI; insteadÙ« at some levelÙ« the available network ports are
shared between the IPMI and the host system. OftenÙ« the BIOS and the
IPMI can operate these ports in two modesÙ« "dedicated" and "shared". In
dedicated modeÙ« the host server is entirely locked out of one port and
NICÙ« and only has one network interface available. In shared modeÙ« the
host and the IPMI magically share a network port; traffic for the IPMI
goes to it (and is theoretically invisible to the host)Ù« while traffic
for the host goes to it so that the port looks like a normal network
port.</p>

<p>(There are variations on this depending on the server.)</p>

<p>I don"t like this "shared" mode. The problem with it is simple;
<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/KVMOverIPSecurity">any IPMI system needs to be on a secure network</a>
and with a shared network portÙ« the host has potential access to
your theoretically secure IPMI networkÙ« with all of the other crunchy
and probably dangerously insecure IPMIs on it. SureÙ« traffic to the
server"s own IPMI will be fenced away from the hostÙ« but other
traffic probably won"t be (partly because there are some people who
put their IPMIs on the same network as their hosts).</p>

<p>Even the existence of a shared mode is probably dangerous to the
security of your IPMI networkÙ« because on some systems this setting
can be changed through IPMI itself from the host (for exampleÙ« see
the various "set-nic-mode" commands in FreeIPMI"s <a href="https://www.gnu.org/software/freeipmi/manpages/man8/ipmi-oem.8.html"><code>ipmi-oem</code></a>).
An attacker who"s compromised one such server can probably switch its
IPMI mode from dedicated to sharedÙ« then put the host on the IPMI
network and get to work.</p>

<p>Only a completely dedicated IPMI network port is safe from thisÙ«
because only then does the host have no access to it no matter
what the BIOS and IPMI are set to or can be changed to. So I
wish everything had dedicated IPMI network portsÙ« not ones that
are potentially accessible by the host. SadlyÙ« extra network
ports and NICs cost moreÙ« so they don"t appear on most of the
inexpensive servers we tend to buy.</p>

<p>(Since the host can talk to the IPMI and IPMIs can have security
bugsÙ« a fully dedicated IPMI network port doesn"t make you completely
safe. In theory the host can compromise the IPMI and get the IPMI
to proxy network traffic for it. In practice this is not something
that"s likely to be a risk for most people; it rises to the level
of <a href="https://www.usenix.org/system/files/1401_08-12_mickens.pdf">"the intelligence agency is going to intelligence agency"</a> [PDFÙ«
but it"s James MickensÙ« you should read it].)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSOurSparesSystemV', 'Our ZFS spares handling system for ZFS on Linux', '1595992624000',  14, '<div class="wikitext"><p>When we ran <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetup">Solaris fileservers</a>
and then <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetupII">OmniOS fileservers</a> we
ended up building our own system for handling replacing failed disks
with sparesÙ« which I wrote about years ago in <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemI">part 1</a>Ù« <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemII">2</a>Ù«
<a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemIII">3</a>Ù« and <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/OurSparesSystemIV">4</a>. When we migrated to our current
generation of <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">Linux based ZFS fileservers</a>Ù«
many of our local software for OmniOS migrated over almost completely
unchanged. This included (and includes) our ZFS spares systemÙ« which
remains mostly unchanged from the Solaris and OmniOS era (both in how
it operates and in the actual code involved).</p>

<p>The first important aspect of our spares system is that it is still
state drivenÙ« not event driven. Rather than trying to hook into
<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise">ZED</a> to catch and handle eventsÙ« our spares driver
program operates by inspecting the state of all of our pools and
attempting to start any disk replacement that"s necessary (and
possible). We do use ZED to immediately run the spares driver in
response to both ZED vdev state change events (which can be a disk
failing) and pool resilvers finishing (because a resilver finishing
can let us start more disk replacements). We also run the spares
driver periodically from cron as a backup to ZED; even if ZED isn"t
running or misses events for some reasonÙ« we will eventually notice
problems.</p>

<p>Our Solaris and OmniOS fileservers used iSCSIÙ« so we had to carefully
maintain a list of what iSCSI disks were potential spares for each
fileserver (a fileserver couldn"t necessarily use any iSCSI disk
visible to it). Since our Linux fileservers only have local disksÙ«
we could get rid of these lists; the spares driver can now use any
free disks it sees and its knowledge of available spares is always
up to date.</p>

<p>(As beforeÙ« these "disks" are actually fixed size partitions on our
SSDsÙ« with four partitions per SSD. We are so immersed in our world
that we habitually call these "disks" even though they aren"t.)</p>

<p>As in the iSCSI worldÙ« we don"t pick replacement disks randomly;
instead there is a preference system. Our fileservers have half
their disks on SATA and half on SASÙ« and our regular mirrored pairs
use the same partition from matching disks (so the first partition
on the first SATA disk is in a mirror vdev with the first partition
on the first SAS disk). Spare replacement tries to pick a replacement
disk partition on the same type of disk (SATA or SAS) as the dead
disk; if it can"t find oneÙ« it falls back to "any free partition"
(which can happen if we use up almost all of the available space
on a fileserverÙ« which has already happened on one).</p>

<p>In the pastÙ« with HDs over iSCSIÙ« we had to carefully limit the
number of resilvers that we did at once in order to not overwhelm
the system; our normal limit was replacing only one "disk" (a
partition) at a time. Our experience with local SSDs is that this
is no longer really a problemÙ« so now we will replace up to four
failed partitions at onceÙ« which normally means that if a SSD fails
we immediately start resilvers for everything that was on it. This
has made a certain amount of old load limiting code in the spares
driver basically pointlessÙ« but we haven"t bothered to remove it.</p>

<p>For inspecting the state of ZFS poolsÙ« we continue to rely on <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemII">our
local C program to read out ZFS pool state</a>. It ported from OmniOS to ZFS on
Linux with almost no changesÙ« although getting it to compile on
Ubuntu 18.04 was a bit of a pain because of how Ubuntu packages ZFS
there. It"s possible that ZFS on Linux now has official APIs that
would provide this informationÙ« but our existing code works now so
I haven"t had any interest in investigating the current state of
any official API for ZFS pool information.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/MicrowaveGoodUIBehavior', 'Digital microwaves show an example of good UI doing what you wanted', '1595908922000',  14, '<div class="wikitext"><p>Every so oftenÙ« you encounter a bit of UI that does what you mean
to do so transparently that you don"t even notice that the UI is
breaking its own "how it works" rules to do so. You could say that
this is the complete reverse of <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/UnixAnnoyance">robot logic</a>Ù«
as seen yesterday in <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/PamPasswdErrorFail">trying to change your password on Linux</a>. Recently I realized that I"d run
into such a "do what I mean even though it doesn"t fit" UI in plain
ordinary microwavesÙ« of all places.</p>

<p>Your typical microwave has a 0-9 digital pad for entering the cooking
time and its cook time is set in MM:SS. If you want one minute and
twenty secondsÙ« you punch in "1 2 0" and the microwave displays "1:20"
and counts down from there. This is all perfectly logical and sensibleÙ«
and forms a clear model of how the microwave behaves.</p>

<p>So what happens if you enter "9 0"? The microwave doesn"t reject
this as an error because you can"t have 90 seconds in the seconds
portion of a minutes and seconds time (you can have at most 59).
Instead it breaks the model and gives you 90 seconds of cook time.
This creates some inconsistenciesÙ« of course; if you enter "9 9"
you get 99 secondsÙ« but if you enter "1 0 0"Ù« you get 60 seconds
(because now it"s 1:00 cook time). On at least some microwaves
this still works even if you enter more than two digits; "1 9 9"
is 199 secondsÙ« not an error (or one minute plus 99 seconds).</p>

<p>This behavior was so natural and so obviously correct and what I meant
that I spent years not realizing there was anything unusual about
it. Only one day as I was keying in "9 0" yet again and congratulating
myself on pressing one less digit than "1 3 0" did I stop to ask myself
why it even worked. And the answer is that the microwave makers went out
of their way to figure out what this input should mean so that it should
match user expectationsÙ« and make it so.</p>

<p>(I suspect or at least hope that there were user studies by some early
microwave company on what people expected to happen when they keyed in
various number sequences that weren"t proper MM:SS setups.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/MicrowaveGoodUIBehavior?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/PamPasswdErrorFail', 'Linux PAM leads to terrible error messages from things like <code>passwd</code>', '1595817652000',  14, '<div class="wikitext"><p>Here is a puzzle for you. Suppose that you"re trying to change your
password on a typical Linux systemÙ« as happens periodically (and as
we make new logins on our systems do immediately)Ù« and you get the
following:</p>

<pre style="white-space: pre-wrap;">
; passwd
Changing password for user cks.
Current password: 
passwd: Authentication token manipulation error
</pre>

<p>What has gone wrong here? What should you do to fix it? Should you
try againÙ« or instead send email to your system administrators to
get them to fix it?</p>

<p>WellÙ« you don"t knowÙ« because <code>passwd</code> and <a href="https://en.wikipedia.org/wiki/Linux_PAM">Linux"s implementation
of PAM</a> have combined to
create a terrible error message through <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/UnixAnnoyance">robot logic</a>Ù« where the error message is completely technically
logical and correct but useless in practice. <strong>The most likely cause
of this message is that you"ve mis-typed your current password</strong>Ù«
but there are other possible causes if things have gone wrong in
the depths of PAM. The only people who can start to disentangle
this is your system administratorsÙ« or in general anyone who can
look at PAM"s logs (normally in syslog)Ù« because only there will
you find extremely valuable and much more precise messages like:</p>

<blockquote><pre style="white-space: pre-wrap;">
passwd[487312]: pam_unix(passwd:chauthtok): authentication failure; logname= uid=19 euid=0 tty=pts/6 ruser= rhost=  user=cks
</pre>
</blockquote>

<p>Even this isn"t really clearÙ« but with sufficient painful experience
you can decode this to that the passwd command was verifying your
password through traditional Unix <code>/etc/shadow</code> encrypted passwordsÙ«
and the password you typed didn"t "authenticate"Ù« ie didn"t match
the encrypted password.</p>

<p>One of the reasons this is a terrible error message is because normal
people have essentially no chance at all of understanding it (as I can
assure you from our experience of supporting the people who use <a href="https://support.cs.toronto.edu/">our</a> systems). The best you can do is use
a wrapper script that puts a big explanatory message around the whole
thingÙ« and even then people get confused.</p>

<p>(And if other things go wrong and the same message gets printed
outÙ« you"re really confusing people; you"ve claimed that the problem
is that they"re using the wrong passwordÙ« except they know that
they"re not. At least they"ll probably email the system administrators
at that point.)</p>

<p>I"m not sure if the PAM API provides any way for PAM modules such
as pam_unix to provide a more specific error message. This
particular error message is the generic PAM error string for
<code>PAM_AUTHTOK_ERR</code>Ù« which is the equally generic PAM error code
that pam_unix is forced to return in this situation. You can
see the full list in the <a href="https://man7.org/linux/man-pages/man3/pam.3.html">pam(3)</a> manpage.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSOnLinuxModuleBackups', 'Keeping backup ZFS on Linux kernel modules around', '1595737330000',  14, '<div class="wikitext"><p>I"m a long term user of <a href="https://zfsonlinux.org/">ZFS on Linux</a>
and over pretty much all of the time I"ve used itÙ« I"ve built it
from the latest development version. Generally this means I update
my ZoL build at the same time as <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/MyKernelUpdateSteps">I update my Fedora kernel</a>Ù« since a ZoL update requires a kernel reboot
anyway. This is a little bit daringÙ« of courseÙ« although the ZoL
development version has generally been quite solid (and this way I
get the latest features and improvements long before I otherwise
would).</p>

<p>One of the things I do to make it less alarming is that <strong>I always
keep backup copies of previous versions of ZFS on Linux</strong>Ù« in the
form of copies of the RPMs I install and update. Naturally I keep
these backup copies in a non-ZFS filesystemÙ« because I need to be
able to get at them even if the new version of ZFS isn"t working
(possibly just with the new kernelÙ« possibly in general). I haven"t
needed these backup copies very oftenÙ« but on the rare occasions
when I"ve had to revertÙ« I was very glad that they were there.</p>

<p>(You don"t always run into immediate failures to bring ZFS up;
sometimes there are merely stability or other issues in a new
development changeÙ« and you want to roll back to a previous one.
In those cases it"s okay to have the previous versions on a ZFS
filesystemÙ« because you can probably use ZFS enough to grab them.)</p>

<p>Not everyone uses development versions of ZFS on LinuxÙ« but I suggest
that you keep backup copies of older versions even if you only use
released ZoL versions. You never know when you may run into an issue
and be glad that you have options.</p>

<p>(That I keep backup copies of previous versions and want to have them
accessible outside of ZFS is one reason that I doubt I"ll ever use ZFS
on Linux on my root filesystem. System recovery is much easier in many
scenarios if ZFS isn"t required to at least boot the systemÙ« get it on
the networkÙ« or access the root filesystem from a live CD.)</p>

<p>One obvious requirement here is that you should never update ZFS
pool or filesystem features until you"re absolutely sure that you"ll
never want to revert to a ZoL version that"s too old to support those
features. This generally makes me quite conservative about updating pool
features; I want them to be in a ZoL release that"s been out long enough
to be considered fully stable.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSOnLinuxModuleBackups?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/web/FirefoxMyVariedWindows', 'My varied types of Firefox windows', '1595646281000',  14, '<div class="wikitext"><p>When I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/WindowManagerWants">what I want out of my window manager</a>Ù« I mentioned that I have a plethora
of Firefox windowsÙ« generally iconified to <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/MyDesktopTour">my desktop</a>. This may sound like things are out of
control (and in a way they are)Ù« but there is some method to my
madness. I actually have a number of different sorts of Firefox
windows.</p>

<p>In no particular orderÙ« I have Firefox windows for:</p>

<ul><li>things that I"m actively working on or using. These are the
windows that are most likely to be openÙ« instead of iconified; I
tend to iconify them only if I"m running out of space.<p>
</li>
<li>things that I"m relatively actively reading. I"m one of those
people who gets distracted or just doesn"t want to read one thing
for too long (and sometimes I get interrupted)Ù« so I tend to have
several things that I"m reading through at any given time.<p>
</li>
<li>things that I refresh and look at on a regular basisÙ« either
temporarily or on a regular basis. Now that I"m writing thisÙ«
I"ve realized that I should shift some of these to <a href="https://utcc.utoronto.ca/~cks/space/blog/web/BookmarksAlternative">my browser
start page</a>Ù« because that"s part of what
it"s there for.<p>
</li>
<li>things that I"m holding around as references for other things I"m
doing. In theory these aren"t permanent; in practiceÙ« sometimes
the other thing falls down my priority list and its reference
windows wind up sitting around for a long time.<p>
A related category is web pages I"m going to mention in emailÙ« a
<a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a> entryÙ« or something like that; here
I have the web page still around as a way of both keeping its URL
and reminding me of it.<p>
</li>
<li>things that I have aspirations of reading (or getting to) but
in practice I"m not going to get to any time soonÙ« or perhaps
ever. This includes things that I"ve stopped being that interested
in (but I can"t admit it to myself and close the window)Ù« and
things that I feel I should be interested in butÙ« wellÙ« I"ll read
them laterÙ« someday.</li>
</ul>

<p>Sometimes these windows have multiple tabs; this is especially
common for references and things I"m actively working on.</p>

<p>I can"t pile all of these different types of windows together in
one clump (such as a bunch of tabs in a single window)Ù« even sorted
by titleÙ« because I need to keep what type of window they are
straight. Right now I keep track of that primarily based on where each
window is iconified on my screen; some areas and some arrangements are
for one purposeÙ« other arrangements and areas are for others.</p>

<p>Some of these (the "aspirations of reading" windows) could be dealt with
better if I had a good way to archive a window and list and track my
archived windows. This would probably take a Firefox addon; the ideal
one would archive the entire window state (what Firefox currently saves
in its session storeÙ« that"s used to restore all your windows when
restarting Firefox) and be able to completely return it to lifeÙ« as if
I"d never closed that window and all its tabs.</p>

<p>(Right now I have a little local HTML file where I sort of do this by
hand. You can guess how often this happensÙ« and it just has URLs and
titles (and the date when I put them there)Ù« so it"s less convenient
than "just give me the window back".)</p>

<p>Some method to group and then de-group specific Firefox windows on
demand would also helpÙ« because then I could have a group for each
sort of thing and put windows into it that I"m not actively looking
at right now. I"m not sure if I"d want this to be the same "archive"
mechanism as for things I don"t expect to look at for some timeÙ«
because that would probably put these other web pages a bit too far
out of my mind. That probably means it"s not something that should
be done by Firefox but instead by my window manager somehow.</p>

<p>(It"s quite possible that there are some good Firefox addons for dealing
with this sort of thing. I haven"t looked into the area very muchÙ« or
even really thought about what might be possible to do inside Firefox.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/FirefoxMyVariedWindows?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/solaris/OverlookingSyseventadm', 'Some thoughts on us overlooking Illumos"s <code>syseventadm</code>', '1595564462000',  14, '<div class="wikitext"><p>In a comment on <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise">my praise of ZFS on Linux"s ZFS event daemon</a>Ù« <a href="https://sysmgr.org/blog">Joshua M. Clulow</a>
noted that Illumos (and thus OmniOS) has an equivalent in <a href="https://illumos.org/man/1M/syseventadm"><code>syseventadm</code></a>Ù« which dates back to
Solaris. I hadn"t previously known about <code>syseventadm</code>Ù« despite
having run <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetup">Solaris fileservers</a> and <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetupII">OmniOS
fileservers</a> for the better part of a decadeÙ«
and that gives me some tangled feelings.</p>

<p>I definitely wish I"d known about <code>syseventadm</code> while we were still
using OmniOS (and even Solaris)Ù« because it would probably have
simplified our life. SpecificallyÙ« it probably would have simplified
the life of <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemI">our spares handling system</a> (<a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemII">2</a>Ù« <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemIII">3</a>). At the leastÙ«
running immediately when some sort of pool state change happened
would have sped up its reaction to devices failing (insteadÙ« it ran
every fifteen minutes or so from cronÙ« creating a bit of time lag).</p>

<p>(On the whole it was probably good to be forced to make our spares
system be state based instead of event based. State based systems are
easier to make robust in the face of various sorts of issuesÙ« like
dropped events.)</p>

<p>At the same timeÙ« that we didn"t realize <code>syseventadm</code> existed isÙ«
in my mindÙ« a sign of problems in how Illumos is organized and
documented (which is something it largely inherited from Solaris).
For instanceÙ« <code>syseventadm</code> is not cross referenced in any of the
Fault Manager related manpages ( <a href="https://illumos.org/man/1M/fmd"><code>fmd</code></a>Ù«
<a href="https://illumos.org/man/1M/fmdump"><code>fmdump</code></a>Ù« <a href="https://illumos.org/man/1M/fmadm"><code>fmadm</code></a>Ù« and so on). The fault management
system is the obvious entry point for a sysadmin exploring this
area on Illumos (<a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/FaultManagerIrritation">partly because it dumps out messages on you</a>)Ù« so some sort of cross reference would
have led me to <code>syseventadm</code>. Nor does it come up much in discussions
on the InternetÙ« although if I"d asked specifically back in the
days I might have had someone mention it to me.</p>

<p>(It got mentioned in <a href="https://serverfault.com/questions/538978/how-to-run-a-command-once-a-zfs-scrub-completes">this Serverfault question</a>Ù«
for example.)</p>

<p>A related issue is that in order to understand what you can do with
<code>syseventadm</code>Ù« you have to read Illumos header files (<a href="https://serverfault.com/a/752050">cf</a>). This isn"t even mentioned in
the <a href="https://illumos.org/man/1M/syseventadm"><code>syseventadm</code></a> manpageÙ« and the examples in the manpage are
all for custom events generated by things from a hypothetical third
party vendor <code>MYCO</code> instead of actual system events. Without a lot
of contextÙ« there are not many clues that ZFS events show up in
<code>syseventadm</code> in the first place for you to write a handler for
them. It also seems clear that writing handlers is going to involve
a lot of experimentation or reading the source to determine what
data you get and how it"s passed to you and so on.</p>

<p>(In general and speaking as a sysadminÙ« the documentation for
syseventadm doesn"t present itself as something that"s for end
sysadmins to use. If you have to read kernel headers to understand
even part of what you can doÙ« this is aimed at <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/OperatorsAndSystemProgrammers">system programmers</a>.)</p>

<p>On the whole I"m not terribly surprised that we and apparently other
people missed the existence and usefulness of syseventadmÙ« even if
clearly there was some knowledge of it in the Illumos community. That we
did miss it while ZFS on Linux"s equivalent practically shoved itself in
our face is an example of practical field usability (or lack thereof) in
action.</p>

<p>At this point interested parties are probably best off writing
articles about how to do things with syseventadm (especially ZFS
things)Ù« and perhaps putting it in Illumos ZFS FAQs. Changing the
structure of the Illumos documentation or rewriting the manpages
probably has too little chance of good returns for the time invested;
for the most partÙ« the system documentation for Illumos is what it
is.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/unix/MainKernelAndUserAPI', 'C"s <code>main()</code> is one of the places where Unix"s user and kernel APIs differ', '1595477926000',  14, '<div class="wikitext"><p>Modern Unixes often like to draw a legalistic distinction between
the API provided to user space by the kernel and the Unix API
provided to programs by the "standard library"Ù« by which they mean
the standard C library. Some peopleÙ« me includedÙ« don"t entirely
like this (I"ve written about <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/UnixAPIAndCRuntime">whether the C runtime and library
is a legitimate part of the Unix API</a>). HoweverÙ«
regardless of what I might think about itÙ« Unix has long had at
least one place where there was a real difference between the normal
API that everyone used and the API that the kernel actually
implemented. I"m talking about the traditional C style <code>main()</code>
entry point that starts your program.</p>

<p>Everyone knows the basic form of <code>main()</code>Ù« with <code>argc</code> and <code>argv</code>;
you"re called with a count of the arguments and an array of strings.
In slightly more advanced usage there is a third argumentÙ« <code>envp</code>Ù«
an array of environment variables. This format is very old in Unix.
The two argument version of <code>main()</code> goes back to at least Research
Unix <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V4/man/man2/exec.2">V4"s <code>exec(2)</code></a>Ù« while
the three argument form with environment variables seems to appear
in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/man/man2/exec.2">V7"s <code>exec(2)</code></a>.</p>

<p>HoweverÙ« this is not the actual <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/ProgramStartTwoApproaches">program entry point</a> that the V7 Unix kernel used when
starting your programÙ« and the actual entry point had a somewhat
different API than <code>main()</code>. ConventionallyÙ« V7 C programs actually
started at an assembly symbol called <code>start</code>; the simplest version
of the assembly code involved is in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/src/libc/csu/crt0.s"><code>crt0.s</code></a>
and it clearly does a certain amount of setup work. There are other
versions of this startup in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/src/libc/csu">/usr/src/libc/csu</a> that
do various amounts of more workÙ« such as arranging to profile your
program.</p>

<p>(Research Unix V6 also had a <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V6/usr/source/s4/crt0.s"><code>crt0.s</code></a>Ù«
but it"s rather different; I think there are no loopsÙ« for example.
If I understood PDP-11 assembly language I might have a better idea of
what it was actually doing.)</p>

<p>In V7Ù« the differences between the user API for <code>main()</code> and the
kernel API are not huge. In current UnixesÙ« there"s often rather
more going onÙ« especially once you include dynamic loaders and
things like the <a href="https://lwn.net/Articles/519085/">"auxiliary vector"</a>
present in some Unixes. I suspect that the simplest version of a
modern one to look at is <a href="https://musl.libc.org/">musl libc</a> for
LinuxÙ« where <a href="https://git.musl-libc.org/cgit/musl/tree/crt/crt1.c">crt1.c</a>
and <a href="https://git.musl-libc.org/cgit/musl/tree/src/env/__libc_start_main.c">the main libc bootstrap functions</a> are
relatively straightforward.</p>

<p>(Some of the code is because the C runtime environment needs to be
set up (and yesÙ« modern C has a runtime)Ù« but a certain amount of
it is converting between how the kernel involves programs and how
<code>main()</code> wants to be invoked.  For exampleÙ« notice how musl libc"s
main start function isn"t called with <code>argc</code> as an explicit argument;
instead it retrieves <code>argc</code> from memory.)</p>

<h3>Sidebar: The interesting V7 trick with data address 0</h3>

<p>At the end of every version of V7"s crt0.s is a little bit that
initially puzzled me:</p>


<blockquote><pre style="white-space: pre-wrap;">
.data
   .=.+2   / loc 0 for I/D; null ptr points here.
</pre>
</blockquote>

<p>What this is doing is that it"s reserving two bytes of space at the
start of the data section. V7 Unix ran on PDP-11"s that supported
<a href="https://gunkies.org/wiki/PDP-11_Memory_Management">split instruction and data address space</a>Ù« so the data
section starts at (data) address 0. Reserving two bytes at the start
insures that no variable or other thing in the data section can be
located at address 0 and so C NULL is always distinct from valid
pointers.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/MainKernelAndUserAPI?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/tech/ProgramStartTwoApproaches', 'Contrasting the two common approaches to where programs start running', '1595389001000',  14, '<div class="wikitext"><p>When a program (in a broad sense) is executedÙ« it must start running
somewhere. There are two common approaches for choosing what code is
the first code executedÙ« each with different tradeoffs that make some
languages and system environments pick one over the other.</p>

<p>The simplest approach is to say that the first code in the program
starts running. This is what PythonÙ« PerlÙ« many versions of BASICÙ«
and shell scripts all do; execution starts from the top of your
file and marches down. This is also something that"s done at the
machine code level; a simple execution environment might load your
code into memory (often at a fixed address) and then simply transfer
control to the start of that block of memory. This isÙ« for exampleÙ«
how PC BIOSes load and execute the Master Boot Record (MBR) from
hard drives; the first 512 byte sectors is loaded into memory and
they jump to it.</p>

<p>The other common approach is to say that execution starts at a user
defined entry pointÙ« at some address or identifier that is set by
the program. Sometimes this entry point is specified by you as you
build or execute the program; sometimes it is set by conventionÙ«
such as C"s <code>main()</code>. Your <code>main()</code> function doesn"t have to be at
the start of your program"s code or at any specific address in
memory; the system will arrange to find it and begin execution
there (at least at a conceptual levelÙ« with some handwaving). This
approach is common in compiled languagesÙ« especially ones that
support building a single entity from multiple source files.</p>

<p>The tradeoff of the "start at the start" approach is that you have
to care about the order of your codeÙ« both for code within a file
and also the order of files (if your program is made up of multiple
files). For "start at the start"Ù« layout matters. Many "start at
the start" languages are most naturally used with programs that
live in a single file; among other thingsÙ« this means that you don"t
need to worry about the order of multiple files. This is commonly
the case for interpreted languagesÙ« so "start at the start" is
common for them.</p>

<p>(It"s not universal in interpreted languagesÙ« even on Unix. For
exampleÙ« awk is only sometimes ordered; you can put a "<code>BEGIN</code>"
rule anywhereÙ« but code order matters if multiple rules act on a
single line.)</p>

<p>The tradeoff of the entry point approach is that you have to define
the entry pointÙ« either by hand or through convention. If defined
by hand (at build or run time)Ù« you have to do some extra work and
you have an extra thing to keep track of; if defined by conventionÙ«
it"s a bit harder to add some code to run at the start of your
program (you have to add it to the front of the code at the defined
entry pointÙ« respecting any ordering requirementsÙ« and can"t just
add a block at the very start of the file). The advantage of the
entry point approach is that the order of code and files no longer
matters.</p>

<p>(AlsoÙ« conventions are arbitrary choices and are essentially magic.
The reason your C programs start at <code>main()</code> is "because"Ù« which
is unsatisfying to some people and something you just have to
memorize.)</p>

<p>It"s common for compiled languages to support building programs
from multiple source files that have no specific order among
themselvesÙ« because this is the easiest approach for humans to deal
with; we can name our source files whatever makes sense and don"t
have to maintain them in some careful order. This pretty much forces
the entry point model. Supporting the "start at the start" model
would require people to maintain an order that the source files
were specified in during compilationÙ« and not just use "cc -o barney
*.o" or the equivalent.</p>

<p>(This entry was sparked by <a href="https://news.ycombinator.com/item?id=23904313">the Hacker News discussion</a> of <a href="https://utcc.utoronto.ca/~cks/space/blog/python/WhyNoMainFunction">my exploration
of why Python doesn"t require a "main" function</a>. As mentionedÙ« Python is a "start
at the start" language and it has an execution model to support
that.)</p>

<p>PS: On modern Unixes that use ELF format executablesÙ« you can see
the entry address of executables with "<code>readelf -h &lt;program></code>" and
then looking at the "Entry point address". Programs generally have
a wide variety of entry point addresses.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/ProgramStartTwoApproaches?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/python/WhyNoMainFunction', 'An exploration of why Python doesn"t require a "main" function', '1595302075000',  14, '<div class="wikitext"><p>Many languages start running your program by calling a function of
yours that must have a specific name. In C (and many C derived
languages)Ù« this is just called <code>main()</code>; in GoÙ« it"s <code>main.main()</code>
(the <code>main()</code> function in the <code>main</code> package). Python famously
doesn"t require any such functionÙ« and won"t automatically call a
function called <code>main()</code> even if you create it. Recently I read
<a href="https://towardsdatascience.com/why-doesnt-python-have-a-main-function-3afe6a8d093">Why doesnâ€™t Python have a main function?</a>
(<a href="https://lobste.rs/s/fumh1r/why_doesn_t_python_have_main_function">via</a>)Ù«
which puts forward one discussion for why this is so. HoweverÙ« I have
a somewhat different way of explaining this situation.</p>

<p>The core reason that Python doesn"t require a <code>main()</code> function is a
combination of its execution model (specifically for what happens when
you import something) and that under normal circumstances you start
Python programs by (implicitly) importing a single file of Python code.
So let"s look at each of these parts.</p>

<p>In many languages things like functionsÙ« classesÙ« and so on are
created (defined) by the interpreter or compiler as it parses the
source file. In PythonÙ« this is not quite the case; insteadÙ« <a href="https://utcc.utoronto.ca/~cks/space/blog/python/FunctionDefinitionOrder"><code>def</code>
and <code>class</code> are executable statements</a>Ù«
and they define classes and functions when they execute (among other
thingsÙ« this is part of <a href="https://utcc.utoronto.ca/~cks/space/blog/python/WhyMetaclassesWork">why metaclasses work</a>).
When Python imports somethingÙ« it simply executes everything in the
file (or the import more generally). When what"s executed is <code>def</code>
and <code>class</code> statementsÙ« you get functions and classes. When what"s
executed is regular codeÙ« you get more complicated things happeningÙ«
including conditional imports or calling functions on the fly under
the right conditions. Or you can write an entire program that just
runs inlineÙ« as the file is imported.</p>

<p>(This has some interesting consequencesÙ« including <a href="https://utcc.utoronto.ca/~cks/space/blog/python/ReloadRealBehavior">what reloading
a Python module really does</a>.)</p>

<p>HoweverÙ« Python is not quite as unique here as it might look. Many
languages have some facility to run arbitrary code early on as the
program is "loading"Ù« before the program starts normal execution
(Go has <code>init()</code> functionsÙ« for example). Where Python is different
from these languages is that Python normally starts a program by
loading and executing a specific single file. Because Python is
only executing a single fileÙ« it"s unambiguous what code is run in
what order and it"s straightforward for the code in that file to
control what happens. In a senseÙ« rather than picking an arbitrarily
named function for where execution (nominally) startsÙ« Python is
able to sneakily pick an arbitrarily named file by having you provide
it.</p>

<p>(Compiled languages traditionally have a model where code from a bunch
of separate files is all sort of piled up together. In PythonÙ« you can"t
really aggregate multiple files together into a shared namespace this
way; one way or anotherÙ« you have to <code>import</code> them and everything starts
from some initial file.)</p>

<p>Where this nice model breaks down and needs a workaround is if you
run a package with "<code>python -m ...</code>"Ù« where Python doesn"t really
have a single file that you"re executing (or it"d have to make
<code>__init__.py</code> serve double duty). As covered in the official
documentation"s <a href="https://docs.python.org/3/library/__main__.html"><code>__main__</code> â€” Top-level script environment</a> (<a href="https://lobste.rs/s/fumh1r/why_doesn_t_python_have_main_function#c_jmer2v">via</a>)Ù«
Python adopts the arbitrary convention of loading a <code>__main__.py</code>
file from your package and declaring it more or less the point where
execution starts.</p>

<p>(Under at least some situationsÙ« your package"s <code>__init__.py</code> may
also be executed.)</p>

<p>PS: contrary to <a href="https://towardsdatascience.com/why-doesnt-python-have-a-main-function-3afe6a8d093">the original article"s views</a>Ù«
<strong>I strongly suggest that you have a <code>main()</code> function</strong>Ù« because
<a href="https://utcc.utoronto.ca/~cks/space/blog/python/ImportableMain">there are significant benefits to keeping your program importable</a>.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/python/WhyNoMainFunction?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise', 'In praise of ZFS On Linux"s ZED "ZFS Event Daemon"', '1595210334000',  14, '<div class="wikitext"><p>I"ve written before (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSameness">here</a>) about how <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">our
current Linux ZFS fileservers</a> work much
like <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetupII">our old OmniOS fileservers</a>.
HoweverÙ« not everything is quite the same between ZFS on Linux and
traditional Solaris/OmniOS ZFS. One of the most welcome differences
for us is <a href="https://zfsonlinux.org/manpages/0.8.4/man8/zed.8.html">ZED</a>Ù«
the ZFS Event Daemon. What ZED does that is so great is that it provides
a very simple way to take action when <a href="https://zfsonlinux.org/manpages/0.8.4/man5/zfs-events.5.html">ZFS events</a> happen.</p>

<p>When a ZFS event happensÙ« ZED looks through a directory (generally
<code>/etc/zfs/zed.d</code>) to find scripts (or programs) that should be run
in response to the event. Each script is run with a bunch of
environment variables set to describe what"s going onÙ« and it can
use those environment variables to figure out what the event is.
ZED decides what things to run based on their names; generally you
wind up with script names like <code>all-cslab.sh</code> (which is run on
all events) and <code>resilver_finish-cslab.sh</code> (which is run when a
resilver finishes).</p>

<p>Because these are just a collection of individual filesÙ« you"re
free to add your own without colliding with or having to alter the
standard "ZEDLETs" provided by ZFS on Linux. Your additions can do
anything you want them toÙ« ranging from the simple to the complex.
For instanceÙ« our simplest ZEDLET simply syslogs all of the ZED
environment variables:</p>


<blockquote><pre style="white-space: pre-wrap;">
PATH=/usr/bin:/usr/sbin:/bin:/sbin:$PATH
export PATH
if [ "$ZEVENT_SUBCLASS" = "history_event" ]; then
        exit 0
fi
unset ZEVENT_TIME
unset ZEVENT_TIME_STRING
printenv | fgrep "ZEVENT_" | sort | fmt -999 |
    logger -p daemon.info -t "cslab-zevents"
exit 0
</pre>
</blockquote>

<p>(There"s a standard "all-syslog.sh" ZEDLETÙ« but it doesn"t syslog
all of the information in the zevents. Capturing all of the information
is especially useful if you want to write additional ZEDLETs and
aren"t quite sure what they should look for or what environment
variables have useful information.)</p>

<p>It can take a bit of time and experimentation to sort out what ZFS
events are generated (and with what information available) in
response to various things happening to adn in your ZFS pools. But
once you have figured it outÙ« ZED gives you a way to trigger and
drive all sorts of system management activities. These can be active
(like taking action if devices fail) or passive (like adding markers
in your metrics system or performance dashboards for when ZFS scrubs
or resilvers start and endÙ« so you can correlate this with other
things happening).</p>

<p>Coming from Solaris and OmniOSÙ« where there was no such simple
system for reacting to things happening in your ZFS poolsÙ« ZED was
a breath of fresh air for us. More than anything elseÙ« it feels
like how ZFS events should have been handled from the startÙ« so
that system administrators could flexibly meet their own local needs
rather than having to accept whatever the Solaris Fault Management
system wanted to give them.</p>

<p>PS: Because ZFS on Linux is now OpenZFSÙ« I believe that ZED will
probably eventually show up in FreeBSD (if it isn"t already there).
Perhaps it will even some day be ported back to Illumos.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoBuildUsingNewAPIs', 'Using Go build directives to optionally use new APIs in the standard library', '1595130013000',  14, '<div class="wikitext"><p>I mentioned recently that new APIs in the Go standard library were
relatively easy to optionally supportÙ« because such new APIs only
appear in new Go releases and you can conditionally build files
based on the Go release that"s building your program. But that"s a
pretty abstract descriptionÙ« so let"s make it concrete.</p>

<p>One of the long time limitations of the <a href="https://golang.org/pkg/crypto/tls/"><code>crypto/tls</code></a> package was that it only gave
you numbers for <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SSLCipherNames">TLS cipher suites</a>Ù« not
any sort of namesÙ« and for logging and reporting things to users
you often wanted a name. Go"s lack of names for its cipher suite
numbers left you to roll your own conversionÙ« generally with <a href="https://github.com/siebenmann/call/blob/master/tlsnames.go">a
big table of mappings</a>Ù« as I
do (or did) in my <a href="https://github.com/siebenmann/call"><code>call</code></a>
program.  In Go 1.14Ù« the Go authors fixed this by adding
<a href="https://golang.org/pkg/crypto/tls/#CipherSuiteName"><code>tls.CipherSuiteName()</code></a>. If I was
content to have the latest version of <a href="https://github.com/siebenmann/call"><code>call</code></a> only build on Go
1.14 or laterÙ« I could simply convert it to directly using
<a href="https://golang.org/pkg/crypto/tls/#CipherSuiteName"><code>tls.CipherSuiteName()</code></a> in place of my current hand done solution.
HoweverÙ« for various reasons I would like to keep <a href="https://github.com/siebenmann/call"><code>call</code></a> building
on previous Go versions as wellÙ« which means that I need to use my old
solution if the new API isn"t available.</p>

<p>The first step is to pull out the small function that needs to
access the API into a separate fileÙ« or create a function to do
this if you don"t have one already. In my case I might as well call
my (new) function <code>cipherSuiteName()</code>. Then we create two versions
of this function in two filesÙ« let"s call them <code>ciphername.go</code> and
<code>ciphername_old.go</code>. The second file has the current implementationÙ«
for older versions of GoÙ« while the first version has the new
implementation that calls <code>tls.CipherSuiteName()</code>.</p>

<p>The first file can very simple if all you want to do is directly
call the new API and accept its result. It needs a Go build directive
to only build on Go 1.14 and laterÙ« and can look like this:</p>

<blockquote><pre>
// There must be a blank line between the
// build directive and "package main".
//
// +build go1.14

package main

import "crypto/tls"

func cipherSuiteName(id uint16) string {
    return tls.CipherSuiteName(id)
}
</pre>
</blockquote>

<p>The second file will have a more complicated implementationÙ« which
I"m leaving out hereÙ« and a Go build directive to not build on Go
1.14 (and later):</p>

<blockquote><pre>
// For pre 1.14 Go versions without
// tls.CipherSuiteName().
//
// +build !go1.14

package main

import "fmt"

func cipherSuiteName(id uint16) string {
   ....
}
</pre>
</blockquote>

<p>My view is that you should use the longer file name for the old
implementationÙ« because in the long run you"re probably going to
delete it (when you stop supporting old Go versions). Depending
on what your function in <code>ciphername.go</code> doesÙ« you might want to
keep it or simply switch over to a direct call to
<a href="https://golang.org/pkg/crypto/tls/#CipherSuiteName"><code>tls.CipherSuiteName()</code></a>.</p>

<p>Useful references for Go build directives are <a href="https://golang.org/pkg/go/build/">the go/build package
documentation</a> and Dave Cheney"s
<a href="https://dave.cheney.net/2013/10/12/how-to-use-conditional-compilation-with-the-go-build-tool">How to use conditional compilation with the go build tool</a>.</p>

<p>(This is the kind of entry that I write partly for my later useÙ«
because I"m sure I"m going to want to do this for other APIs in the
future.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ToolsNotAlwaysSilent', 'Not all sysadmin tools should be silent by default', '1595037614000',  14, '<div class="wikitext"><p>As a long term Unix personÙ« I have wound up with a reflexive
assumption that all of the programs and tools I write should be
silent by default. This is the traditional Unix approach; Unix
programs are supposed to be silent if all goes well and only print
things if asked to or if something goes wrongÙ« for good reasons.
HoweverÙ« lately I"ve began thinking that this is not necessarily
always correct and that under some circumstances my programs and
tools should be somewhat verbose by default (with an option to
make them Unix style silent).</p>

<p>A certain amount of the tools I write are normally run through
automation (such as crontabs and scripts)Ù« where they can be supplied
with whatever command line options we wantÙ« and they may or may not do
something when run depending on the state of the system (or what they
perceive that to be). If I"m running such a program interactivelyÙ«
it"s generally an exceptional situation and I want and expect it to do
something. If the program follows the Unix philosophy and is silent both
when there is no work to be done and when there"s work to do but it goes
wellÙ« I"m at a loss for which one actually happened.</p>

<p>For this sort of programÙ« I"ve come to believe that some verbosity
by default is more helpful in practice. When I run the program
interactively with no command line optionsÙ« it will actually tell me
what it did (or didn"t do) and I won"t be left wondering. When we run it
through automationÙ« we can give it the command line option that makes
it more silentÙ« so we don"t get a barrage of emails from crontab or the
like.</p>

<p>All of that sounds abstractÙ« so let me make it concrete. One part
of <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemI">our ZFS spares system</a> is a
program called "<code>sanspares</code>". The primary job of <code>sanspares</code> is to
either actually perform sparing or report on what sparing it would
like to doÙ« but it can run into various reasons it might not actually
do any sparing despite wanting to. Right nowÙ« sanspares is a silent
by default programÙ« so if I run it interactively and it produces
no output it could be for one of several reasons. If I"m checking
what sanspares thinks about the health of a fileserverÙ« the different
reasons for not doing anything matter and I would like to know which
one it was. I actually recently had to run <code>sanspares</code> interactivelyÙ«
and I had to do a bunch of fiddling with "<code>-vv</code>" flags until I was
confident that I understood why it was doing what it was doing.</p>

<p>(Silence is especially not golden if there"s a possibility that your
program is actually broken. This was part of why I was running sanspares
interactivelyÙ« as I needed to fix an issue we"d found with it recently as
well as understand the health of the fileserver.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ToolsNotAlwaysSilent?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/spam/ExesInEverything', 'Malware spammers put .exe Windows executables in everything', '1594950703000',  14, '<div class="wikitext"><p>RecentlyÙ« for <a href="https://twitter.com/thatcks/status/1276163223960551427">reasons beyond the scope of this entry</a>Ù« I"ve been
expanding <a href="https://github.com/siebenmann/exim-attachment-logger">our system for recording email attachment type information</a> to be able
to look inside more archive formats to get the file extensions of
files inside them. The most significant format I wanted to be able
to peer inside was <a href="https://en.wikipedia.org/wiki/7z">7zip archives</a>Ù«
because 7zip archives are one of the big areas where <a href="https://utcc.utoronto.ca/~cks/space/blog/spam/MalwareMatchingDifference">ClamAV differs
from our current commercial solution</a>
by recognizing fewer thingsÙ« but I added support for ISO 9660 images
and CAB files while I was there.</p>

<p>In completely unsurprising newsÙ« once I had this interior file extension
logging workingÙ« it started lighting up with 7zip archivesÙ« ISO 9660
imagesÙ« and even a CAB archive here and there that all contained <code>.exe</code>
filesÙ« generally with nothing else. This matches malware behavior I"ve
seen before for <a href="https://utcc.utoronto.ca/~cks/space/blog/spam/MalwareBeingClear">7zip attachments</a> and <a href="https://utcc.utoronto.ca/~cks/space/blog/spam/SpamCapturingCanBeUseful">ISO images</a>Ù« but it"s always useful to have this stuff
confirmed (especially since malware behavior changes over time).</p>

<p>(We"re already rejecting email that contains .cab files or ISO
images as attachmentsÙ« but now I can have more confidence that these
truly are bad and we can make more fine grained filtering decisions
if we need to. Since we now canÙ« we"re rejecting email with 7zip
archives that have .exes in them.)</p>

<p>My assumption is that malware spammers are putting .exes in all
sorts of archive formats in an attempt to shield them from content
scanners. Some of this will be for content scanners that can"t look
inside the archive format at allÙ« and probably some is for things
where a different archive format messes up simple signature recognition
or executable scanning. I can"t say that this is a silly ideaÙ«
because until recently this content smuggling mostly worked against
us.</p>

<p>It is somewhat amusing to get confirmation that all of those very
bad looking things really are badÙ« such as the people who put several
extensions on their filenames:</p>

<blockquote><p>attachment application/x-7z-compressed; MIME file ext: .pdf.z; 7zip exts: .exe</p>
</blockquote>

<p>Of courseÙ« in the grand traditional of malwareÙ« sometimes the extension
is sort of a lie:</p>

<blockquote><p>attachment application/octet-stream; MIME file ext: .pdf.z; file magic: application/x-rar; rar exts: .exe</p>
</blockquote>

<p>Perhaps it"s simpler in the software to just use a fixed set of extensions
regardless of what archive type you"re packing it up as. (We have a number
of these .pdf.z RAR archives logged recently.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/spam/CleverURLObfuscation', 'A piece of phish spam with some clever URL obfuscation', '1594867187000',  14, '<div class="wikitext"><p>We were the target of a phish spam run today. In many respects it
was a standard modern phish; it was specifically targeted to usÙ«
with a message and claimed sender tuned to hereÙ« it was in HTMLÙ«
and the inducement to click was a claim of "go here to retrieve a
voicemail message". HoweverÙ« it had one interesting trick that I
haven"t seen beforeÙ« and that was how it obfuscated its target URL.</p>

<p>The first level of obfuscation was that the target in the &lt;a
href="..."> was entirely encoded in HTML hex entitiesÙ« which probably
only stops very basic spam recognizer engines (and serves as a big
warning sign for others). HoweverÙ« even when decoded the direct
URL came out to be "/blah/?of=&lt;email address>"Ù« with no host in
evidence. At first I stared at this in puzzlementÙ« and then the
penny dropped and I looked at the full HTML. Up at the top was
a little thing:</p>

<blockquote><p>&lt;html> &lt;base href="&amp;#x68;&amp;#x74; &amp;#x74;&amp;#x70; &amp;#x73;&amp;#x3A; &amp;#x5C;&amp;#x2F;[...]</p>
</blockquote>

<p>(For a bit of extra obfuscationÙ« that decodes to "https:\/". I"ve
removed the hostnameÙ« and added strategic spaces between some hex
entities so that this entry doesn"t get an extra-wide line.)</p>

<p>The phish spammers had split their URL in two by using <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/base">a base URL
element</a>.
The base URL element had the hostname (and the https://Ù« sort of);
the &lt;a href> had the path on the host. Given thisÙ« it seems likely
that a decent number of anti-spam engines that parse HTML don"t
handle it to the extent of base URL elements (and anything that
just does basic text matching is out in the cold).</p>

<p>(I have a personal little program that extracts URLs from email
messages for my own uses. It didn"t understand the base URL elementÙ«
but I"m not sure I should bother fixing that.)</p>

<p>I expect that IMAP mail clients properly reconstruct the full URL
as part of properly rendering modern HTMLÙ« although I haven"t tested
that. I don"t know if web based things like GMail doÙ« although it"s
possible that document base URLs are used frequently enough in real
HTML email that they have to.</p>

<p>(The phish spammer targeting us may have assumed that anyone using
GMail or the like was a lost cause anywayÙ« and have aimed at people
using desktop or mobile IMAP clients.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/python/ArgparseAbbreviatedOptions', 'Today I learned that Python"s argparse module allows you to abbreviate long command line options', '1594782494000',  14, '<div class="wikitext"><p><a href="https://docs.python.org/3/library/argparse.html">Argparse</a> is the
standard Python library for Unix style command line argument handling;
I use it in all of my Python programs these days.  As part of this
it supports the now standard long optionsÙ« so you can have options
like "<code>--dead-disks</code>" instead of just "<code>-D</code>" (there are only so
many single characters to go aroundÙ« and they can be hard to
remember). Today I learned that <a href="https://docs.python.org/3/library/argparse.html">argparse</a> accepts abbreviations
for these long optionsÙ« provided that they"re unambiguous. If you
have a long option "<code>--dead-disks</code>" and no other long option that
starts with "d"Ù« argparse will accept all of "--dead-disk"Ù« "--dead"Ù«
and even "--d" as meaning "--dead-disks".</p>

<p>This is clearly documented in the argparse documentation if you
bother to read it all (I never did)Ù« in <a href="https://docs.python.org/3/library/argparse.html#prefix-matching">Argument abbreviations
(prefix matching)</a>. You
can turn it off when constructing your <a href="https://docs.python.org/3/library/argparse.html#argparse.ArgumentParser">ArgumentParser</a>
by setting the <a href="https://docs.python.org/3/library/argparse.html#allow-abbrev"><code>allow_abbrev</code></a>
keyword argument to "<code>false</code>". Unfortunately I don"t think there"s
anything visible in a program"s --help that will tell you whether
or not it accepts abbreviated options; you have to either read
the Python code or just try it with something harmless.</p>

<p>(It appears that <a href="https://docs.python.org/3/library/optparse.html">optparse</a>Ù« argparse"s
predecessorÙ« always allowed abbreviationsÙ« with no way to turn it
off I"m basing this on a little mention of abbreviated long options
in <a href="https://docs.python.org/3/library/optparse.html#how-callbacks-are-called">this section</a>.
This makes argparse a clear improvement hereÙ« since at least you can turn
abbreviated options off if you want to.)</p>

<p>With my user hat onÙ« I think this is a fine little feature. Long
options are oftenÙ« wellÙ« longÙ« and if you can abbreviate them you
might as well so people don"t have to type as much (at least the
people who don"t have command line completion for options for your
programs).</p>

<p>With my sysadmin hat onÙ« I"m worried about the implications of
abbreviated options accidentally getting embedded into other scriptsÙ«
crontab entriesÙ« and so on. For instanceÙ« if the real option is
"--dead-disks" but it"s usually used with a single disk nameÙ« it
would be easy to accidentally forget that it wasn"t "--dead-disk"
and embed that mistake in a script. Although this works todayÙ« it
risks confusion in people who later read the script (including your
future self). With heavily abbreviated optionsÙ« evolving the program
to add more options risks now making a previously unambiguous and
working abbreviation now ambiguous and not working. If you add a
new "--deadline" argument and scripts were using "--dead" as an
abbreviation for "--dead-disks"Ù« suddenly they"re going to start
getting errors.</p>

<p>(You can think of this as a version of <a href="https://en.wikipedia.org/wiki/Robustness_principle">Postel"s law</a>Ù« in which
case <a href="https://tools.ietf.org/id/draft-thomson-postel-was-wrong-03.html">The Harmful Consequences of the Robustness Principle</a>
sort of applies.)</p>

<p>Given this concernÙ« it"s tempting to update at least some of our
sysadmin tools to disable abbreviated command line options and
perhaps to make it my default argparse setting in future tools.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/python/ArgparseAbbreviatedOptions?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/links/PrometheusQueryAnatomy', 'Link: The Anatomy of a PromQL Query', '1594777403000',  14, '<div class="wikitext"><p><a href="https://promlabs.com/blog/2020/06/18/the-anatomy-of-a-promql-query/">The Anatomy of a PromQL Query</a>
(<a href="https://old.reddit.com/r/PrometheusMonitoring/comments/hjuele/the_anatomy_of_a_promql_query_promlabs_blog/">via</a>)
is a very clear and nice explanation of what goes into a <a href="https://promlabs.com/blog/2020/06/18/the-anatomy-of-a-promql-query/">PromQL</a>
query. It covers both the elements (metricsÙ« functionsÙ« and so on)
and the Prometheus data types you use (such instant vectors and
range vectors). This is a very useful article because while PromQL
is solidly documentedÙ« it doesn"t have a concept overview that"s
as clear and straightforward as this.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow', 'How major and minor device numbers worked in V7 Unix', '1594695193000',  14, '<div class="wikitext"><p>Unix people who"ve been around for a while know that Unix devices
have <em>device numbers</em>Ù« and that device numbers are divided into
<em>major</em> and <em>minor</em> device numbers. When you do "<code>ls -l /dev/null</code>"
and one of the fields that <code>ls</code> prints is two comma separated
numbersÙ« those are the major and minor numbers (on LinuxÙ« they are
"1Ù« 3"; this varies by Unix). Device numbers and their split into
major and minor parts go back a long wayÙ« to before Research Unix
V7Ù« but V7 makes a convenient point to look at what they meant and
how they worked in the original Unixes.</p>

<p>As various sources will tell youÙ« the major number tells you (and
the Unix kernel) what sort of device it is and thus what device
driver to use to talk to itÙ« while the minor number tells the device
driver what specific bit of hardware it"s responsible for that you
want to talk to.  Sometimes the minor number also determines some
bit of functionality. Because V7 was a deliberately simple and
brute force system and kernelÙ« major device numbers had a very
simple implementation. We can see it in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf/c.c">the generated V7 kernel
configuration file <code>c.c</code></a>:</p>


<pre style="white-space: pre-wrap;">
 struct bdevsw bdevsw[] =
 {
   nulldevÙ« nulldevÙ« rkstrategyÙ« &amp;rktabÙ« /* rk = 0 */
   nodevÙ« nodevÙ« nodevÙ« 0Ù« /* rp = 1 */
   [...]
   nodevÙ« nodevÙ« nodevÙ« 0Ù« /* hp = 6 */
   htopenÙ« htcloseÙ« htstrategyÙ« &amp;httabÙ« /* ht = 7 */
   nodevÙ« nodevÙ« nodevÙ« 0Ù« /* rl = 8 */
   0
 };
</pre>

<p>What we"re seeing here is that V7 literally had an array of <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/h/conf.h"><code>bdevsw</code>
structures</a> indexed
by the major (block) device numberÙ« with various function that were
called when you did things like open a device (in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/sys/fio.c"><code>fio.c</code></a>).
There was a similar array for character devicesÙ« the <code>cdevsw</code> array.
In both of themÙ« what driver functions were listed here instead of
stubbed out were determined by simple configuration files (<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf">here</a>)
that said what devices you had (among other things).</p>

<p>(The <code>c.c</code> file was generated by <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf/mkconf.c">a program</a>.
The particular <code>c.c</code> file in the TUHS V7 tree was built with only
two block devices configuredÙ« the <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/rk.c">RK disk driver</a> and
<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/ht.c">TJU16 tape driver "ht"</a>.)</p>

<p>In V7 the minor device number was only interpreted by the device
driverÙ« as far as I can see. Device drivers used this for a variety
of purposes. For instanceÙ« <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/mem.c">the <code>mem</code> character driver</a>
implemented <code>/dev/null</code> as minor device 2Ù« to go along with access
to physical memory and kernel memory. The <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/rl.c"><code>rl</code> disk driver</a> used
the minor device number to decide what physical disk it was talking
to (it supported up to four of them). Once V7 started getting out
in the worldÙ« other people wrote drivers for it (such as <a href="http://clara.comm.sfu.ca/pups/PDP-11/Trees/V7/usr/sys/dev/rx2.c">the RX02
floppy disk driver</a>) that
used minor device numbers both to select what to talk to and control
what features to use.</p>

<p>(There"s also <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/kl.c">the <code>kl</code> KL/DL-11 serial and console driver</a>Ù« which
seems to deal with three different sets of hardware control registers
based on the minor number.)</p>

<p>The <code>/dev/tty</code> character device was implemented in a clever and
very short way in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/sys.c"><code>sys.c</code></a>. In
V7Ù« there were no pseudo-ttys and no hot-plugged devicesÙ« so your
underlying physical terminal device always existed and was recorded
in your <code>u</code> area (see <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/h/user.h"><code>user.h</code></a>) The
general tty driver simply used this recorded device number of your
controlling tty to call its openÙ« readÙ« writeÙ« and ioctl functions
through the <code>cdevsw</code> array. As far as I can tellÙ« this driver paid
no attention at all to the minor device number; as long as <code>/dev/tty</code>
had major number 7Ù« the minor number was irrelevant.</p>

<p>PS: Note that V7 device drivers tended to be a little relaxed about
error checking for their minor device numbers (and other things).
For instanceÙ« as far as I can tell the <code>mem</code> driver actually only
distinguishes between minor number 2Ù« minor number 1Ù« and "everything
else"Ù« which is treated as minor number 0Ù« giving access to physical
memory.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/RunningServersFredBrooks', 'Running servers and Fred Brooks on transforming programs to products', '1594610131000',  14, '<div class="wikitext"><p>One of the seminal books on software engineering and project
management is Fred Brooks" justly famous <a href="https://en.wikipedia.org/wiki/The_Mythical_Man-Month">The Mythical Man-Month</a>. One of the
things that Brooks discusses in the book is the additional effort
it takes to transform a program (that has been written) into a
product (that can be sold). The modern open source world has its
own equivalent of this transformation that many people experience;
to make your program useful for other people it needs documentationÙ«
build instructionsÙ« and often generalization and more testing than
you gave it in your own personal use.</p>

<p>A while back I wrote an entry about how <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/RunningServersNotTrivial">running servers and
services well is not trivial</a>Ù« which is
about exactly that. It has recently occurred to me that one part
of this difficultyÙ« and also how setting up and running servers
often appears easy for non specialistsÙ« is another version of Fred
Brooks" transformation from programs to products and the extra
effort it takes. Just as it"s easy to write a one off program for
your own useÙ« it"s easy these days to set up a one off special
server. But that"s not the server equivalent of a <em>product</em>; it"s
the server equivalent of a program before it"s been transformed
into a product. To become a product (a production server)Ù« you need
a whole raft of additional things (many of which I outlined in <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/RunningServersNotTrivial">my
entry</a>).</p>

<p>Many programs can be transformed into products through incremental
improvements and developments (writing documentationÙ« for example).
Unfortunately servers are often less malleable this wayÙ« and it may
not be very easy (or even possible) to transform a casually set up
server into a production grade server. Often you"ll wind up rebuilding
the server from scratch. The good news is that it"s usually much
easier (and faster) to build new versions of servers than it is to
rewrite programs from scratch.</p>

<p>I think that this can also provide a guide and a caution for when
you should set up a casual server yourself. If all you need is the
server equivalent of a one-off programÙ« you can spin it up just as you
would write that program. But watch out; just as one off programs not
infrequently get drawn into (or pressed into) long term useÙ« your "one
off" server may not be so temporary or unimportant after all. If it
becomes a load bearing component of your environmentÙ« the initial quick
approach will likely have left you with lingering problems.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/DesktopAppAutostartSystemd', 'Linux desktop application autostarting is different from systemd user units', '1594527634000',  14, '<div class="wikitext"><p>When I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/DesktopAppAutostart">how applications autostart on modern Linux
desktops</a>Ù« there was <a href="https://old.reddit.com/r/linux/comments/hbek8n/how_applications_autostart_on_modern_linux/">a Reddit discussion</a>Ù«
and one of the people there noted that things could also be autostarted
through systemd user units. As covered in <a href="https://wiki.archlinux.org/index.php/Systemd/User">the Arch Wiki page on
this</a>Ù« Linuxes
that are systemd based generally automatically start a "<code>systemd
--user</code>" user systemd instance for youÙ« and one of the things this
will do is it will start things in <code>~/.local/share/systemd/user</code>
and <code>~/.config/systemd/user</code>Ù« which you can manipulate.</p>

<p>HoweverÙ« there are some significant differences between the two
that help explain why Linux desktops don"t use systemd user units.
The big one is that <strong>systemd user units are per-userÙ« not
per-session</strong>. By their natureÙ« desktop applications are a per
session thing and so not a great fit for a per-user system.  In
fact even getting systemd user units to be able to talk to your
desktop session takes what is basically a hackÙ« as covered in <a href="https://wiki.archlinux.org/index.php/Systemd/User#DISPLAY_and_XAUTHORITY">the
Arch wiki section on DISPLAY and XAUTHORITY</a>Ù«
and this hack must be carefully timed so that it works correctly
(it has to happen before units that need to talk to your desktop
are startedÙ« and that means they have to be terminated when you log
out).</p>

<p>Desktops also have a lot more fine control over what gets started
with <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/DesktopAppAutostart">their current mechanisms</a>. Obviously
these things only get started for desktop sessionsÙ« not things like
SSH loginsÙ« and they can be specific to certain desktops or not
start in some desktops. I don"t believe there is a native systemd
unit option for "run only if this environment variable is defined"Ù«
so you can"t readily make a systemd unit that only runs in desktop
sessionsÙ« never mind only a particular sort of desktop.</p>

<p>(Relying to any significant degree on user units would also more
strongly tie desktops to systemdÙ« although I don"t know if that"s
something they worry about these days or if it"s full steam ahead
on systemd in general.)</p>

<p>My general impression is that systemd user .service units are not
a good fit for what most users want and do with autostarting things
todayÙ« whether or not they"re using a desktop. Systemd user units
are probably a better fit for socket and dbus unitsÙ« because those
are more naturally activated on the fly as neededÙ« but I don"t know
if people are doing this very much (especially for desktop related
things).</p>

<p>(As a practical matterÙ« I"d consider it pretty obnoxious if a program
decided to set itself to autostart as a systemd user unit. I suspect
I"m not alone in this.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/DesktopAppAutostartSystemd?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoMiddlewareVsInterfaceSmuggling', 'The impact on middleware of expanding APIs with Go"s interface smuggling', '1594434134000',  14, '<div class="wikitext"><p>RecentlyÙ« the Go blog had <a href="https://blog.golang.org/module-compatibility">Keeping your Modules Compatible</a> which is about
doing exactly that as you add features and want to expand your
module"s API. When the module"s API involves interfacesÙ« one of
the approaches they suggested is what I"ve called <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoInterfaceSmuggling">interface
smuggling</a> and what other people have
called <em>interface upgrades</em>. Let me quote the article:</p>

<blockquote><p>When you run into a case where you want to add a method to an existing
interfaceÙ« you may be able to follow this strategy. Start by creating
a new interface with your new methodÙ« or identify an existing
interface with the new method. NextÙ« identify the relevant functions
that need to support itÙ« type check for the second interfaceÙ« and add
code that uses it.</p>
</blockquote>

<p>This is a quite popular approachÙ« one used by many packages in Go"s
standard library and third party packages. HoweverÙ« it has a dark
sideÙ« and that is its unfortunate effects on middleware.</p>

<p>The problem for middleware is best illustrated by the most common
sort of middlewareÙ« which is things that interpose in the chain of
HTTP handlers to modify the results. Much middleware wants to look
at or act on some aspect of the HTTP replyÙ« for example <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoPrometheusMetricLabels">to gather
metrics based on the result code</a>Ù« which
means that it must modify and proxy the <a href="https://golang.org/pkg/net/http/#ResponseWriter"><code>http.ResponseWriter</code></a> passed to child
<a href="https://golang.org/pkg/net/http/#Handler"><code>http.Handler</code></a>s. Over
time the <a href="https://golang.org/pkg/net/http/"><code>http</code> package</a> has
acquired a whole collection of smuggled interfaces on ResponseWritersÙ«
such as <a href="https://golang.org/pkg/net/http/#CloseNotifier"><code>http.CloseNotifier</code></a> (which is deprecated)Ù«
<a href="https://golang.org/pkg/net/http/#Flusher"><code>http.Flusher</code></a>Ù«
<a href="https://golang.org/pkg/net/http/#Hijacker"><code>http.Hijacker</code></a>Ù« and
<a href="https://golang.org/pkg/net/http/#Pusher"><code>http.Pusher</code></a>. In the
future there will probably be more.</p>

<p>(In additionÙ« the ResponseWriter may or may not support
<a href="https://golang.org/pkg/io/#ReaderFrom"><code>io.ReaderFrom</code></a>.)</p>

<p>If you"re a piece of middlewareÙ« the ResponseWriter you"re passed
may support someÙ« manyÙ« or all of these additional APIs. HoweverÙ«
Go provides you no good way to pass this support through your proxy
ResponseWriter that you"re going to pass to children Handlers. The
Prometheus people try hard to do it anywayÙ« and <a href="https://github.com/prometheus/client_golang/blob/master/prometheus/promhttp/delegator.go">the result is
rather messy</a>
and involves a combinatorial explosion of the possible combinations
of APIs. As the case of io.ReaderFrom showsÙ« these additional APIs
don"t even necessarily come from the <a href="https://golang.org/pkg/net/http/"><code>http</code> package</a>. A smuggled
interface from anywhere may need to be supported.</p>

<p>One answer to this is that you just don"t support these additional
APIs in your middlewareÙ« or you only support a few of them. The
problem with this is that the ResponseWriter and the client code
that people are trying to use your middleware with well have been
developedÙ« testedÙ« and normally used in an environment where these
expanded APIs are usedÙ« not cut off. As we all knowÙ« if you don"t
test it it doesn"t work. Your middleware may be the first code to
try to pass the next hop a ResponseWriter with a genuinely narrow
APIÙ« because such narrow APIs may mostly come from middleware. And
of course if there are any bugs in the resultÙ« people will blame
your middleware.</p>

<p>None of this is insurmountable. But beyond the problems and the
hasslesÙ« it means that expanding your API with interface smuggling
is decidedly not transparent if people use middleware with it. And
as a practical matterÙ« some amount of the time your new API will
not be usable until middleware is expanded to cope with it (if it
ever is).</p>

<p>Another problem is that this expansion of middleware to cope with
your new API can"t happen until your new API itself is pervasive.
Go currently provides no support for conditional building based on
the version of other packages or the state of their APIÙ« so middleware
can"t include any use of your new API interfaces until it doesn"t
have to build against versions of your package that predate them.</p>

<p>(People can work around this for HTTP middleware because they can
make files build only on specific minimum versions of Go. Your
package doesn"t have this magical power; it"s something available
only for new APIs in the Go standard library.)</p>

<p>Because nothing is new under the sunÙ« this problem was noticed back
in 2014"s <a href="https://avtok.com/2014/11/05/interface-upgrades.html">Interface Upgrades in Go</a>Ù« which is
one of the earliest places to call this pattern an "interface
upgrade". The article notes the proxy problem and ends with a call
to use interface upgrades sparingly. This is good advice in my
opinionÙ« but is very much at odds with the idea of routinely using
interface upgrades to expand your API.</p>

<p>(<a href="https://old.reddit.com/r/golang/comments/hoehhv/interface_smuggling_a_go_design_pattern_for/">Via</a>.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/UbuntuBuildingFirefox', 'UbuntuÙ« building current versions of FirefoxÙ« and snaps', '1594354085000',  14, '<div class="wikitext"><p>Today on TwitterÙ« <a href="https://twitter.com/thatcks/status/1281331375912767489">I said</a>:</p>

<blockquote><p>Given that Ubuntu"s ostensible logic for putting Chrome in a snap is
"it makes maintaining it easier"Ù« my cynical side expects Ubuntu to
also do this with Firefox before too long (due to Firefox"s need for
steadily increasing versions of Rust).</p>
</blockquote>

<p>(The context here is LWN"s <a href="https://lwn.net/Articles/825005/">Linux Mint drops Ubuntu Snap packages</a>Ù« <a href="https://lobste.rs/s/9q0kta/linux_mint_drops_ubuntu_snap_packages">via</a>.
For "Ubuntu"Ù« you can read "Canonical"Ù« since Canonical is driving
this.)</p>

<p>Ubuntu ships current versions of Firefox (at the moment Firefox 78)
in Ubuntu LTS releasesÙ« which means that they must build current
versions of Firefox on all supported Ubuntu LTS versions. Firefox
is built partly with Rust (among other things)Ù« and new releases
of Firefox often require relatively recent versions of Rust; for
instanceÙ« right now Firefox Nightly (which will become Firefox 80
or 81) requires Rust 1.43.0 or better. Nor is Rust the only thing
that Firefox has minimum version requirements for. Firefox 78Ù« the
current releaseÙ« requires nasm 2.14 or better if you want to build
the AV1 codecsÙ« and I"m sure there are others I just haven"t tripped
over yet.</p>

<p>This is a problem for Ubuntu because Ubuntu famously doesn"t like
updating packages on Ubuntu LTS (or probably any Ubuntu releaseÙ«
but I only have experience with LTS releases). TodayÙ« the need to
build current Firefox versions on old Ubuntu LTS releases means
that Ubuntu 16.04 has been dragged up to Rust 1.41.0 (the same Rust
version that"s on 18.04 and 20.04). If current versions of Rust
weren"t required to build FirefoxÙ« Rust on 16.04 would probably be
a lot like GoÙ« where the default is version 1.6 (that"s the <code>golang</code>
package version) and the most recent available one is Go 1.10 (which
actually dates from 2018Ù« which is modern for an LTS release from
2016). When Firefox 80 or so is released and requires Rust 1.43.0
or betterÙ« Ubuntu will have to update Rust again on all of the still
supported LTS versionsÙ« which will probably still include 16.04 at
that point.</p>

<p>Canonical can"t like this. At the same timeÙ« they have to ship
Firefox and they have to keep it currentÙ« for security reasons.
Shipping Firefox as a Snap would deal with both problemsÙ« because
Canonical would no longer need to be able to build the current
Firefox from source on every supported Ubuntu release (LTS and
otherwiseÙ« but the oldest ones are generally LTS releases). Given
that Canonical wants to shove everyone into Snaps in generalÙ« I
rather expect that they"re going to do this to Firefox sooner or
later.</p>

<p>PS: I"m not looking forward to thisÙ« because <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu2004SnapsHomeIssue">Snaps don"t work
with NFS mounted home directories or in our environment in general</a>. Ubuntu moving Firefox to a Snap would
probably cause us to use the official Mozilla precompiled binaries
in the short termÙ« and push us more toward another Linux release
in the longer term (probably Debian).</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/UbuntuBuildingFirefox?showcomments#comments">5 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/links/MimeTypeAssociations', 'Link: Mime type associations (on Linux)', '1594310077000',  14, '<div class="wikitext"><p>Enrico Zini"s <a href="https://www.enricozini.org/blog/2020/debian/mime-type-associations/">Mime type associations</a>
(via <a href="https://planet.debian.org/">Planet Debian</a>) is
about the practical side of fixing MIME type associations so that
various types of files open in the right program on your Debian
system.  This is an area of interest to meÙ« but I"ve never pulled
everything together into one spot (and compactly) the way this
article does.</p>

<p>(For my entriesÙ« there"s <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/XdgMimeTypeSearching">how <code>xdg-mime</code> searches for MIME type
handlers</a>Ù« <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/XdgOpenWhichBrowser">how <code>xdg-open</code> picks
which web browser to use</a>Ù« <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/UbuntuMailcapBasics">the
basics of <code>/etc/mailcap</code></a>Ù« and <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/MailcapDocx2txtTangle">a
cautionary story of mailcap handling</a>.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/links/MimeTypeAssociations?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoInterfaceSmuggling', '"Interface smuggling"Ù« a Go design pattern for expanding APIs', '1594265867000',  14, '<div class="wikitext"><p>Interfaces are one of the big ways of creating and defining APIs
in <a href="https://golang.org/">Go</a>. Go famously encourages these
interfaces to be very minimal; the widely used and implemented
<a href="https://golang.org/pkg/io/#Reader"><code>io.Reader</code></a> and <a href="https://golang.org/pkg/io/#Writer"><code>io.Writer</code></a> are each one method. Minimal APIs
such as this have the advantage that almost anything can implement themÙ«
which means that Go code that accepts an <code>io.Reader</code> or <code>io.Writer</code> can
work transparently with a huge range of data sources and destinations.</p>

<p>HoweverÙ« this very simplicity and generality means that these APIs
are not necessarily the most efficient way to perform operations.
For exampleÙ« if you want to copy from an io.Reader to an io.WriterÙ«
such as <a href="https://golang.org/pkg/io/#Copy"><code>io.Copy()</code></a> doesÙ« using
only the basic API means that you have to perform intermediate data
shuffling when in many cases either the source could directly write
to the destination or the destination could directly read from the
source. Go"s solution to this is what I will call <em>interface
smuggling</em>.</p>

<p>In interface smugglingÙ« the actual implementation is augmented with
additional well known APIsÙ« such as <a href="https://golang.org/pkg/io/#ReaderFrom"><code>io.ReaderFrom</code></a> and <a href="https://golang.org/pkg/io/#WriterTo"><code>io.WriterTo</code></a>. Functions that want to
work more efficiently when possibleÙ« such as <a href="https://golang.org/pkg/io/#Copy"><code>io.Copy()</code></a>Ù«
attempt to convert the io.Reader or io.Writer they obtained to
the relevant API and then use it if the conversion succeeded:</p>

<blockquote><pre style="white-space: pre-wrap;">
if wtÙ« ok := src.(WriterTo); ok {
   return wt.WriteTo(dst)
}
if rtÙ« ok := dst.(ReaderFrom); ok {
   return rt.ReadFrom(src)
}
[... do copy ourselves ...]
</pre>
</blockquote>

<p>I call this <em>interface smuggling</em> because we are effectively smuggling
a differentÙ« more powerfulÙ« and broader API through a limited one.
In the case of types supporting io.WriterTo and io.ReaderFromÙ«
io.Copy completely bypasses the nominal API; the .Read() and .Write()
methods are never actually usedÙ« at least directly by io.Copy (they may
be used by the specific implementations of .WriteTo() or .ReadFrom()Ù« or
more interface smuggling may take place).</p>

<p>(Go code also sometimes peeks at the concrete types of interface
API arguments. This is how under the right circumstancesÙ« io.Copy
will wind up using the Linux <a href="https://man7.org/linux/man-pages/man2/splice.2.html"><code>splice(2)</code></a> or <a href="https://man7.org/linux/man-pages/man2/sendfile.2.html"><code>sendfile(2)</code></a> system
calls.)</p>

<p>There is also interface smuggling that expands the APIÙ« as seen in
things like <a href="https://golang.org/pkg/io/#ReadCloser"><code>io.ReadCloser</code></a>
and <a href="https://golang.org/pkg/io/#ReadWriteSeeker"><code>io.ReadWriteSeeker</code></a>.
If you have a basic <code>io.Reader</code>Ù« you can try to convert it to see if it
actually supports these expanded APIsÙ« and then use them if it does.</p>

<p>PS: There"s probably a canonical Go term for doing this as part
of your API designÙ« either to begin with or <a href="https://blog.golang.org/module-compatibility">as part of expanding
it while retaining backward compatibility</a>. If soÙ« feel free
to let me know in the comments.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoInterfaceSmuggling?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraBtrfsDefaultView', 'Some thoughts on Fedora moving to btrfs as the default desktop file system', '1594180024000',  14, '<div class="wikitext"><p>The news of the time interval for me is that there is a Fedora
change proposal to <a href="https://fedoraproject.org/wiki/Changes/BtrfsByDefault">make btrfs the default file system for Fedora
desktop</a>
(<a href="https://communityblog.fedoraproject.org/fedora-33-btrfs-by-default-test-day-2020-07-08/">via</a>Ù«
itself <a href="https://lobste.rs/s/skkr5x/fedora_33_btrfs_by_default_test_day_2020_07">via</a>;
see also <a href="https://lists.fedoraproject.org/archives/list/devel@lists.fedoraproject.org/thread/IOPR2R3SCKOFUCKPLMS4MDD5664SGQFR/">the mailing list post</a>).
Given that in the past I"ve been a btrfs sceptic (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSOnLinuxvsBtrfsToday">eg</a>Ù« from 2015)Ù« long time readers might expect
me to have some views here. HoweverÙ« this time around my views are
cautiously optimistic for btrfs (and Fedora)Ù« although I will only
be watching from a safe distance.</p>

<p>The first two things to note are that 2015 is a long time ago (in
computer time) and I"m too out of touch with btrfs to have an
informed opinion on its current state. I"m confident that people
in Fedora wouldn"t have proposed this change if there weren"t good
reasons to believe that btrfs is up to the task. The <a href="https://btrfs.wiki.kernel.org/index.php/Status">current btrfs
status</a> looks pretty
good on a skimÙ« although the section on <a href="https://btrfs.wiki.kernel.org/index.php/Status#Device_replace">device replacement</a>
makes me a little alarmed. The Fedora proposal also covers who else
is using btrfs and has been for some timeÙ« and it"s a solid list
that suggest btrfs is not going to explode for Fedora users.</p>

<p>I"m a big proponent of <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/NextGenerationFilesystem">modern filesystems with data and metadata
checksums</a>Ù« so I like that aspect
of btrfs. As far as performance goesÙ« most people on desktops are
unlikely to notice the differenceÙ« and as a long term user of <a href="https://zfsonlinux.org/">ZFS
on Linux</a> I can testify how nice it is to
not have to preallocate space to specific filesystems (even if with
LVM you can grow them later).</p>

<p>HoweverÙ« I do feel that this is Fedora being a bit adventurous.
This is in line with Fedora"s goals and general stance of being a
relatively fearless leading edge distributionÙ« but at the same time
sometimes the leading edge is also the bleeding edge. I would not
personally install a new Fedora machine with btrfs in the first few
releases of Fedora that defaulted to itÙ« because I expect that there
will be teething problems. Some of these may be in btrfsÙ« but others
will be in system management programs and practices that don"t cope
with btrfs or conflict with it.</p>

<p>In the long run I think that this change to btrfs will be good for
Fedora and for Linux as a whole. Ext4 is a perfectly decent filesystem
(and software RAID works fine)Ù« but it"s possible to do much betterÙ«
as ZFS has demonstrated for a long time.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraBtrfsDefaultView?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/web/BlogDroppingPerDayPages', 'I now think that blog "per day" pages with articles are a mistake', '1594094965000',  14, '<div class="wikitext"><p>Back in 2005 when I wrote <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a>Ù« the engine that is used for
<a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>Ù« there was an accepted standard structure
for blogs that people followedÙ« me included. For instanceÙ« it was
accepted convention that the front page of your blog showed a number
of the most recent articlesÙ« and you could page backward to older
ones. Part of this structure was the idea that you would have a
page for each day and that page would show the article or articles
written that day (if any). When I put together <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a>"s URL structure
for blog-like areasÙ« I followed thisÙ« and to this day <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering
Thoughts</a> has these per-day pages.</p>

<p>I now think that these per day pages are not the right thing to do
on the modern web (for most blogs)Ù« for three reasons. The first
reason is that they don"t particularly help <a href="https://utcc.utoronto.ca/~cks/space/blog/web/RealBlogUsability">real blog usability</a>Ù« especially getting people to explore your blog
after they land on a page. Most people make at most one post a dayÙ«
so exploring day by day doesn"t really get you anything more than
links in a blog entry to the next entry and the previous entry will
(and if the links have the destination"s titleÙ« they will probably
be giving you more information than a day).</p>

<p>The second reason is that because they duplicate content from your
actual articlesÙ« they confuse search engine based navigation. Perhaps
the search engine will know that the actual entry is the canonical
version and present that in preference to the per-day page where
the entry is also presentÙ« but perhaps not. And if you do have two
entries in one dayÙ« putting both of their texts on one page risks
disappointment in someone who is searching for a combination of
terms where one term is only in one entry and the other term is in
a second.</p>

<p>The third and weakest reason is a consequence of how <a href="https://utcc.utoronto.ca/~cks/space/blog/web/EverythingGetsVisited">on the modern
webÙ« everything gets visited</a>. Per-day pages
are additional pages in your blog and web crawlers will visit themÙ«
driving up your blog"s resource consumption in the process. These
days my feelings are that you generally want to minimize the number
of pages in your blogÙ« not maximize themÙ« something I"ve written
about more in <a href="https://utcc.utoronto.ca/~cks/space/blog/web/ManyURLsModernDrawback">The drawback of having a dynamic site with lots of
URLs on today"s web</a>. But this is not a
very strong reasonÙ« if you have a reasonably efficient blog and
you serve per-day pages that don"t have the full article text.</p>

<p>I can"t drop per-day pages here on <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>Ù« because
I know that people have links to them and I want those links to
keep working as much as possible. The simple thing to do is to stop
putting full entries on per-day pagesÙ« and instead just put in their
title and a link to them (just as I already do on per-month and
per-year pages); this at least gets rid of the duplication of entry
text and makes it far more likely that search engine based navigation
will deliver people to the actual entry.  The more elaborate thing
would be to automatically serve a HTTP redirect to the entry for
any per-day page that had only a single entry.</p>

<p>(For relatively obvious reasons you"d want to make this a temporary
redirect.)</p>

<p>There"s a bit of me that"s sad about this shift in blog design and
web usage; the per-dayÙ« per-monthÙ« and per-year organization had a
pleasant regularity and intuitive appeal. But I think its time has
passed. More and moreÙ« we"re all tending toward <a href="https://utcc.utoronto.ca/~cks/space/blog/web/StaticVsDynamicSiteLayout">the kind of minimal
URL structure typical of static sites</a>Ù«
even when we have dynamic sites and so could have all the different
URL structures and ways of accessing our pages that we could ask for.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/BlogDroppingPerDayPages?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoWhenNotManyGoroutines', 'A Go lesson learned: sometimes I don"t want to use goroutines if possible', '1594007545000',  14, '<div class="wikitext"><p>We have a heavily NFS based server environment <a href="https://support.cs.toronto.edu/">here</a>Ù« with <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">multiple NFS servers</a> and an IMAP server that accesses
all mailboxes over NFS. That IMAP server has had <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/LoadAverageIMAPImpactQuestion">ongoing issues
with elevated load averages</a>Ù«
and what at least seems to be IMAP slowness. HoweverÙ« our current
metrics leave a lot of uncertainties about the effects of all of
thisÙ« because we basically only have a little bit of performance
data for a few IMAP operations. One thing I"d like to do is gather
some very basic Unix level NFS performance data from our IMAP server
and from some other machinesÙ« to see if I can see anything.</p>

<p>One very simple metric is how long it takes to read a little file
from every NFS filesystem we have mounted on a machine. As it
happensÙ« we already have the little files (they"re used for another
system management purpose)Ù« so all I need is a program to open and
read each one while timing how long it takes. There"s an obvious
issue with doing this sequentiallyÙ« which is that if there"s a
single slow filesystemÙ« it could delay everything else.</p>

<p>The obvious answer here was GoÙ« goroutinesÙ« and some form of goroutine
pool. Because the goroutines just do IO (and they"re only being
used to avoid one bit of IO delaying another separate bit)Ù« the
natural size of the goroutine pool is fairly largeÙ« say 50 to 100
goroutines (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ManyNFSFilesystemsWhy">we have a lot of NFS filesystems</a>).  This is quite easy and obvious
to implement in GoÙ« so I put together a little Go program for it
and watched the numbers it generated as they jumped around.</p>

<p>ThenÙ« out of reflexive cautionÙ« I tried running the same program
with a goroutine pool size of 1Ù« which more or less forced serial
execution (the pool goroutine infrastructure was still active but
there was only one worker goroutine doing all the reading). To my
surprise the "time to read a file" number for all filesystems was
visibly and decidedly lower. I could run the program side by side
with the two different goroutine pool sizes and see this clearly.</p>

<p>Some thinking gave me a possible reason why this is so. My core
code does essentially the following (minus error checking):</p>

<blockquote><pre style="white-space: pre-wrap;">
start := time.Now()
fileÙ« err := os.Open(target)
nÙ« err := file.Read(buffer)
duration := time.Now().Sub(start)
</pre>
</blockquote>

<p>This sequence makes two system calls and <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoSchedulerAndSyscalls">each system call is a
potential goroutine preemption point</a>. If
a goroutine gets preempted during either system callÙ« it can only
record the finishing time once it"s scheduled again (and finishes
the readÙ« if it was preempted in the open). If there are 50 or more
goroutines all doing thisÙ« some of them could well be preempted and
then not scheduled for some timeÙ« and that scheduling delay will
show up in the final duration. When there aren"t multiple goroutines
activeÙ« there should be very little scheduling delay and the recorded
durations (especially the longest durations) will be lower. And the
ideal situation for essentially no goroutine contention is of course
one goroutine.</p>

<p>(Technically this makes two more system calls to get the time at
the start and the end of the sequenceÙ« but on modern systemsÙ«
especially LinuxÙ« these don"t take long enough to trigger <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoSchedulerAndSyscalls">Go"s
system call preemption</a> and probably don"t
even enter the kernel itself.)</p>

<p>Because I still worry about individual slow filesystems slowing
everything down (or stalls on some filesystems)Ù« my solution was a
more complicated work pool approach that starts additional worker
goroutines only when all of the current ones seem to have stalled
for too long.  If all goes well (and it generally does in my testing)Ù«
this runs with only one goroutine.</p>

<p>(My current code has the drawback that once the goroutine worker
pool expandsÙ« all of them stay activeÙ« which means that enough
slow filesystems early on in the checks could get me back to the
thundering herd problem. I"m still thinking about that issue.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoWhenNotManyGoroutines?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/tech/TLSHowMultipleChains', 'How you get multiple TLS certificate chains from a server certificate', '1593892980000',  14, '<div class="wikitext"><p>I"ve known and read for some time that a single server certificate
can have more than one chain to a root certificate that you trustÙ«
but I never really thought about the details of how this worked.
Then <a href="https://www.agwa.name/blog/post/fixing_the_addtrust_root_expiration">the AddTrust thing</a>
happenedÙ« I started writing about <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusBlackboxVsAddTrust">how Prometheus"s TLS checks
would have reacted to it</a>Ù«
and Guus left a comment on <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusBlackboxVsAddTrust">that entry</a> that got me thinking
about what else Prometheus could sensibly look at here. So now
I want to walk through the mechanics of multiple TLS chains to
get this straight in my head.</p>

<p>Your server certificate and the other TLS certificates in a chain
are each signed by an <em>issuer</em>; in a verified chainÙ« this chain of
issuers eventually reaches a Certificate Authority root certificate
that people have some inherent trust in. HoweverÙ« a signed certificate
doesn"t specifically name and identify the issuer"s certificate byÙ«
sayÙ« its serial number or hash; instead <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateIdentity">issuers are identified
by their X.509 Subject Name</a> and also at
least implicitly by their keypair (and sometimes explicitly).  By
extensionÙ« your signed certificate also identifies the key type of
the issuer"s certificate; if your server certificate is signed by
RSAÙ« an intermediate certificate with an ECDSA keypair is clearly
not the correct parent certificate.</p>

<p>(Your server certificate implicitly identifies the issuer by keypair
because they signed your certificate with it; an intermediate
certificate with a different keypair can never validate the signature
on your certificate.)</p>

<p>HoweverÙ« several certificates can have the same keypair and <a href="https://en.wikipedia.org/wiki/X.509">X.509
Subject Name</a>Ù« provided that
other attributes differ. One such attribute is the issuer that
signed them (including whether this is <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSWhatIsSelfSignedCert">a self-signed CA root
certificate</a>). So the first thing is that
<strong>having more than one certificate for an issuer is generally
required to get multiple chains</strong>. If you only have one certificate
for each issuerÙ« you can pretty much only build a single chain.</p>

<p>There are three places that these additional certificates for an
issuer can come from; they can be sent by the serverÙ« they can be
built into your certificate store in advanceÙ« or they can be cached
because you saw them in some other context. The last is especially
common with browsersÙ« which often cache intermediate certificates
that they see and may use them in preference to the intermediate
certificate that a TLS server sends. Other software is generally
more static about what it will use. My guess is that we"re unlikely
to have multiple certificates for a single CA root issuerÙ« at least
for modern CAs and modern root certificate sets as used by browsers
and so on.  This implies that the most likely place to get additional
issuer certificates is from intermediate certificates sent by a
server.</p>

<p>(In any caseÙ« it"s fairly difficult to know what root certificate
sets clients are using when they talk to your server. If your server
sends the CA root certificate you think should be used as part of
the certificate chainÙ« a monitoring client (such as Prometheus"s
checks) can at most detect when it"s got an additional certificate
for that CA root issuer in its own local trust store.)</p>

<p>One cause of additional issuer certificates is what"s called
<em>cross-signing</em> a CA"s intermediate certificateÙ« as is currently
the case with <a href="https://letsencrypt.org/certificates/">Let"s Encrypt"s certificates</a>. In cross-signingÙ« a CA
generate two versions of its intermediate certificateÙ« using the
same X.509 Subject Name and keypair; one is signed by its own CA
root certificate and one is signed by another CA root certificate.
A CA can also cross-sign its own new root certificate (wellÙ« the
keypair and issuer) directlyÙ« as is the case with <a href="https://ssl-tools.net/subjects/6ff4684d4312d24862819cc02b3d472c1d8a2fa6">the DST Root
CA X3 certificate that Let"s Encrypt is currently cross-signed with</a>;
one certificate for "DST Root CA X3" is self-signed and likely in
your root certificate setÙ« but two others existed that were
cross-signed by an older DST CA root certificate.</p>

<p>(As covered in the certificate chain illustrations in <a href="https://www.agwa.name/blog/post/fixing_the_addtrust_root_expiration">Fixing the
Breakage from the AddTrust External CA Root Expiration</a>Ù« this
was also the case with the expiring AddTrust root CA certificate.
The "<a href="https://ssl-tools.net/subjects/cd30d24c343a82ab1f0570158ad7a107762992e9">USERTrust RSA Certification Authority</a>"
issuer was also cross-signed to "<a href="https://ssl-tools.net/subjects/7cb166549cabdb44ee622616adf4657bf77ad594">AddTrust External CA Root</a>"Ù«
a CA root certificate that expired along with that cross-signed
intermediate certificate. And this USERTrust root issuer is still
cross signed to another valid root certificateÙ« "<a href="https://ssl-tools.net/subjects/53b54f6e16a815187849c176725823579954799e">AAA Certificate
Services</a>".)</p>

<p>This gives us some cases for additional issuer certificates:</p>

<ul><li>your server"s provided chain includes multiple intermediate certificates
for the same issuerÙ« for example both Let"s Encrypt intermediate
certificates.  A client can build one certificate chain through
each.<p>
</li>
<li>your server provides an additional cross-signed CA certificateÙ« such
as the USERTrust certificate signed by AddTrust. A client can build
one certificate chain that stops at the issuer certificate that"s in
its root CA setÙ« or it can build another chain that"s longerÙ« using
your extra cross-signed intermediate certificate.<p>
</li>
<li>the user"s browser knows about additional intermediate certificates
and will build additional chains using themÙ« even though your server
doesn"t provide them in its set of certificates. This definitely
happensÙ« but browsers are also good about handling multiple chains.</li>
</ul>

<p>In a good worldÙ« all intermediate certificates will have an expiration
time no later than the best certificate for the issuer that signed
them. This was the case with the AddTrust expiration; the cross-signed
USERTrust certificate expired at the same time as the AddTrust root
certificate. In this case you can detect the problem by noticing
that a server provided intermediate certificate is expiring soon.
If only a CA root certificate at the end of an older chain is
expiring soon and the intermediate certificate signed by it has a
later expiration dateÙ« you need to check the expiration time of the
entire chain.</p>

<p>As a practical matterÙ« monitoring the expiry time of all certificates
provided by a TLS server seems very likely to be enough to detect
multiple chain problems such as the AddTrust issue. Competent
Certificate Authorities shouldn"t issue server or intermediate
certificates with expiry times later than their root (or intermediate)
certificatesÙ« so we don"t need to try to find and explicitly check
those root certificates. This will also alert on expiring certificates
that were provided but that can"t be used to construct any chainÙ«
but you probably want to get rid of those anyway.</p>

<h3>Sidebar: Let"s Encrypt certificate chains in practice</h3>

<p>Because browsers do their own thingÙ« a browser may construct multiple
certificate chains for Let"s Encrypt certificates today even if
your server only provides the LE intermediate certificate that is
signed by DST Root CA X3 (the current Let"s Encrypt default for the
intermediate certificate). For exampleÙ« if you visit <a href="https://valid-isrgrootx1.letsencrypt.org/">Let"s Encrypt"s
test site for their own CA root</a>Ù« your browser will
probably cache the LE intermediate certificate that chains to the
LE CA root certificateÙ« and then visiting other sites using Let"s
Encrypt may cause your browser to ignore their intermediate certificate
and chain through the "better" one it already has cached. This is
what currently happens for me on Firefox.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/TLSWhatIsSelfSignedCert', 'What a TLS self signed certificate is at a mechanical level', '1593836710000',  14, '<div class="wikitext"><p>People routinely talk about self signed TLS certificates. You use
them in situations where you just need TLS but don"t want to set
up an internal Certificate Authority and can"t get an official TLS
certificateÙ« and many CA root certificates are self signed. But
until recently I hadn"t thought about what a self signed certificate
isÙ« mechanically. So here is my best answer.</p>

<p>To simplify a lotÙ« a TLS certificate is a bundle of attributes wrapped
around a public key. All TLS certificates are signed by someone; we
call this the <em>issuer</em>. <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateIdentity">The issuer for a certificate is identified
by their X.509 Subject Name</a>Ù« and also at least
implicitly by the keypair used to sign the certificate (since only
an issuer TLS certificate with the right public key can validate the
signature).</p>

<p>So this gives us the answer for what a self signed TLS certificate
is. It"s a certificate that lists its own Subject Name as the issuer
and is signed with its own keypair (using some appropriate key
signature algorithmÙ« such as SHA256-RSA for RSA keys). It still has
all of the usual TLS certificate attributesÙ« especially "not before"
and "not after" datesÙ« and in many cases they"ll be processed
normally.</p>

<p>Self signed certificates are not automatically CA certificates for a
little private CA. Among other thingsÙ« the self-signed certificate can
explicitly set an "I am not a CA" marker in itself. Whether software
respects this if someone explicitly tells it to trust the self-signed
certificate as a CA root certificate is another matterÙ« but at least you
tried.</p>

<p>Self-signed certificates do have a serial number (which should be
unique)Ù« and a unique cryptographic hash. Browsers that have been told
to trust a self-signed certificate are probably using either these or
a direct comparison of the entire certificate to determine if you"re
giving them the same self-signed certificateÙ« instead of following the
process used for identifying issuers (of checking the issuer Subject
Name and so on). This likely means that if you re-issue a self-signed
certificate using the same keypair and Subject NameÙ« browsers may not
automatically accept it in place of your first one.</p>

<p>(As far as other software goesÙ« who knows. There are dragons all
over those hillsÙ« and I suspect that there is at least some code
that accepts a matching Subject Name and keypair as good enough.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/WorkNotDoneFromHome', 'The work that"s not being done from home is slowly accumulating for us', '1593745597000',  14, '<div class="wikitext"><p>At the momentÙ« the most recent things I"ve seen have talked about
<a href="https://support.cs.toronto.edu/">us</a> not returning to the office
before SeptemberÙ« and then not all of us at one time. This gives
me complicated feelingsÙ« including about what work we are doing.
From the outsideÙ« our current work from home situation probably
looks like everything is going pretty well. We"ve kept the computing
lights onÙ« things are being doneÙ« and so far all of the ordinary
things that people ask of us get done as promptly as usual. A few
hardware issues have come up and have been dealt with by people
making brief trips into the office. So it all looks healthy; you
might even wonder why we need offices.</p>

<p>When I look at the situation from insideÙ« things are a bit different.
We may be keeping the normal lights onÙ« but at the same time there"s a
steadily growing amount of work that is not being done because of our
working from home. The most obvious thing is that ordering new servers
and other hardware has basically been shut down; not only are we not in
the office to work on any hardwareÙ« it mostly can"t even be delivered to
the university right now.</p>

<p>The next obvious thing is the timing of any roll out of Ubuntu 20.04
on our machines. Under normal circumstancesÙ« we"d have all of the
infrastructure for installing 20.04 machines ready and probably
some test machines out there for people to poke atÙ« and we"d be
hoping to migrate a number of user-visible machines in August before
the fall semester starts. That"s looking unlikelyÙ« since at this
point all we have is an ISO install image that"s been tested only
in temporary virtual machines. Since we haven"t been in the officeÙ«
we haven"t set up any real servers running 20.04 on an ongoing
basis. We"re in basically <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu2004TimingIssues">the bad case situation I imagined back
in early April</a>.</p>

<p>(And of course many of the people we"d like to have poke at 20.04
test machines are busy with their own work from home problemsÙ« so
even if we had test machinesÙ« they would probably get less testing
than usual.)</p>

<p>Another sign is that many of our Ubuntu servers have been up without
a reboot for what is now an awfully long time for us. Under normal
circumstances we might have scheduled a kernel update and reboot
by nowÙ« but under work from home conditions we only want to take
the risk of doing kernel updates and rebooting important servers
if there is something critical. If something goes wrongÙ« it"s not
a walk down to the machine roomÙ« it"s a trip into the office (and
a rather longer downtime).</p>

<p>There"s also a slowly accumulating amount of pending physical
networking workÙ« where we"re asked to change what networks particular
rooms or network ports are on because people are moving around.
This work traditionally grows as the fall semester approaches and
space starts getting sorted out for new graduate students and so
onÙ« although that could change drastically this year depending on
the university"s overall plans for what graduate students will do
and where they will work.</p>

<p>(To put it one wayÙ« a great deal of graduate student space is not
set up for appropriate physical distancing. Nor is a fair amount
of other office and lab space.)</p>

<p>One level up from this is that there"s a number of projects that
need to use some physical servers. We have a bunch of OpenBSD
machines on old OpenBSD versions that could do with updates (and
refreshes on to new hardware)Ù« for exampleÙ« but we need to build
them out in test setups first. Another example is that we have plans
to significantly change <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/SlurmHasCreatedCattle">how we currently use SLURM</a>Ù« but that needs a few machines to set up a
little new cluster (on our server networkÙ« as part of our full
environment).</p>

<p>(A number of these projects need custom network connectivityÙ« such
as new test firewalls needing little test networks. Traditionally
we build this in some of our "lab space"Ù« with servers just sitting
on a table wired together.)</p>

<p>Much of this is inherent in us having and using physical servers. Having
physical servers in a machine room means receiving new hardwareÙ« racking
itÙ« cabling it upÙ« and installing itÙ« all of which we have to do in
person (plus at least pulling the cables out of any old hardware that
it"s replacing). Some of it (such as our reluctance to reboot servers)
is because we don"t have full remote KVM over IP capabilities on our
servers.</p>

<p>PS: We"re also lucky that <a href="https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic">all of this</a> didn"t
happen in a year when we"d planned to get and deploy a major set
of hardwareÙ« such as the year when we got the hardware for <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">our
current generation of fileservers</a>.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/links/CodeOnlySaysWhatItDoes', 'Link: Code Only Says What it Does', '1593733785000',  14, '<div class="wikitext"><p>Marc Booker"s <a href="https://brooker.co.za/blog/2020/06/23/code.html">Code Only Says What it Does</a> (<a href="https://lobste.rs/s/efrg4x/code_only_says_what_it_does">via</a>) is about
what code doesn"t say and why all of those things matter. Because
I want you to read the articleÙ« I"m going to quote all of the first
paragraph:</p>

<blockquote><p>Code says what it does. That"s important for the computerÙ« because
code is the way that we ask the computer to do something. It"s OK for
humansÙ« as long as we never have to modify or debug the code. As soon
as we doÙ« we have a problem. FundamentallyÙ« debugging is an exercise
in changing what a program does to match what it should do. It
requires us to know what a program should doÙ« which isn"t captured in
the code. Sometimes that"s easy: What it does is crashÙ« what it should
do is <em>not crash</em>. Outside those trivial casesÙ« discovering intent is
harder.</p>
</blockquote>

<p>This is not an issue that"s exclusive to programmingÙ« as I"ve written
about in <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ConfigMgmtIsNotDocumentation">Configuration management is not documentationÙ« at least
not of intentions</a>
(<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ProceduresAreNotDocumentation">procedures and checklists and runbooks aren"t documentation
either</a>). In computing
we love to not write documentationÙ« but not writing down our
intentions in some form is just piling up future problems.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSAdminVsFilesystemLayout', 'In ZFSÙ« your filesystem layout needs to reflect some of your administrative structure', '1593658735000',  14, '<div class="wikitext"><p>One of the issues we sometimes run into with ZFS is that ZFS
essentially requires you to reflect your administrative structure
for allocating and reserving space in how you lay out ZFS filesystems
and filesystem hierarchies. This is because <strong>in ZFSÙ« all space
management is handled through the hierarchy of filesystems</strong> (and
perhaps in having multiple pools). If you want to make two separate
amounts of space available to two separate sets of filesystems (or
collectively reserved by them)Ù« either they must be in different
pools or they must be under different dataset hierarchies within
the pool.</p>

<p>(These hierarchies don"t have to be visible to usersÙ« because you can
mount ZFS filesystems under whatever names you wantÙ« but they exist in
the dataset hierarchy in the pool itself and you"ll periodically need to
know themÙ« because some commands require the full dataset name and don"t
work when given the mount point.)</p>

<p>That sounds abstractÙ« so let me make it concrete. Simplifying only
slightlyÙ« our filesystems <a href="https://support.cs.toronto.edu/">here</a>
are visible to people as <code>/h/NNN</code> (for home directories) and <code>/w/NNN</code>
(<em>workdirs</em>Ù« for everything else). They come from some NFS server
and live in some ZFS pool there (inside <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurContainerFilesystems">little container filesystems</a>)Ù« but the NFS server and to some extent
the pool is an implementation detail. Each research group has its
own ZFS pool (or for big onesÙ« more than one pool because one pool
can only be so big)Ù« as do some individual professors. HoweverÙ«
there are not infrequently cases where a professor in a group pool
would like to <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/HowWeSellStorage">buy extra space</a> that
is only for their studentsÙ« and also this professor has several
different filesystems in the pool (often a mixture of /h/NNN homedir
filesystems and /w/NNN workdir ones).</p>

<p>This is theoretically possible in ZFSÙ« but in order to implement
it ZFS would force us to put all of a professor"s filesystems under
a sub-hierarchy in the pool. Instead of the current tank/h/100 and
tank/w/200Ù« they would have to be something like tank/prof/h/100
and tank/prof/w/200. The ZFS dataset structure is required to reflect
the administrative structure of how people buy space. One of the
corollaries of this is that you can basically only have a single
administrative structure for how you allocate spaceÙ« because a
dataset can only be in one place in the ZFS hierarchy.</p>

<p>(So if two professors want to buy space separately for their filesystems
but there"s a filesystem shared between them (and they each want it to
share in their space increase)Ù« you have a problem.)</p>

<p>If there were sub-groups of people who wanted to buy space collectivelyÙ«
we"d need an even more complicated dataset structure. Such sub-groups
are not necessarily decided in advanceÙ« so we can"t set up such a
hierarchy when the filesystems are created; we"d likely wind up
having to periodically modify the dataset hierarchy.  Fortunately
the manpages suggest that "<code>zfs rename</code>" can be done without
disrupting service to the filesystemÙ« provided that the mountpoint
doesn"t change (which it wouldn"tÙ« since we force those to the
/h/NNN and /w/NNN forms).</p>

<p>While our situation is relatively specific to <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/HowWeSellStorage">how we sell space</a>Ù« people operating ZFS can run into
the same sort of situation any time they want to allocate or control
collective space usage among a group of filesystems. There are
plenty of places where you might have projects that get so much
space but want multiple filesystemsÙ« or groups (and subgroups) that
should be given specific allocations or reservations.</p>

<p>PS: One reason not to expose these administrative groupings to users
is that they can change. If you expose the administrative grouping in
the user visible filesystem name and where a filesystem belongs shiftsÙ«
everyone gets to change the name they use for it.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSHierarchyQuotaLack', 'The unfortunate limitation in ZFS filesystem quotas and refquota', '1593569847000',  14, '<div class="wikitext"><p>When ZFS was newÙ« the only option it had for filesystems quotas was
the <code>quota</code> propertyÙ« which <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSSnapshotQuota">I had an issue with</a>
and which caused us practical problems in <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetup">our first generation
of ZFS fileservers</a> because it covered the space
used by snapshots as well as the regular user accessible filesystem.
Later ZFS introduced the <code>refquota</code> propertyÙ« which did not have
that problem but in exchange doesn"t apply to any descendant datasets
(regardless of whether they"re snapshots or regular filesystems).
At one level this issue with <code>refquota</code> is fineÙ« because we put
quotas on filesystems to limit their maximum size to what our backup
system can comfortably handle. At another levelÙ« this issue impacts
how we operate.</p>

<p>All of this stems from a fundamental lack in ZFS quotasÙ« which is
ZFS"s general quota system doesn"t let you limit space used only
by unprivileged operations. Writing into a filesystem is a normal
everyday thing that doesn"t require any special administrative
privilegesÙ« while making ZFS snapshots (and clones) requires special
administrative privileges (either from being <code>root</code> or from having
had them specifically delegated to you). But you can"t tell them
apart in a hierarchyÙ« because ZFS only you offers the binary choice
of ignoring all space used by descendants (regardless of how it
occurs) or ignoring none of itÙ« sweeping up specially privileged
operations like creating snapshots with ordinary activities like
writing files.</p>

<p>This limitation affects our pool space limitsÙ« because we use them
for two different purposes; <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/HowWeSellStorage">restricting people to only the space
that they"ve purchased</a> and <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSGuaranteeFreeSpace">insuring
that pools always have a safety margin of space</a>.
Since pools contain <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ManyNFSFilesystemsWhy">many filesystems</a>Ù«
we must limit their total space usage using the <code>quota</code> property.
But that means that any snapshots we make for administrative purposes
consume space that"s been purchasedÙ« and if we make too many of
them we"ll run the pool out of space for completely artificial
reasons. It would be better to be able to have two quotasÙ« one for
the space that the group has purchased (which would limit only
regular filesystem activity) and one for our pool safety margin
(which would limit snapshots too).</p>

<p>(This wouldn"t completely solve the problemÙ« thoughÙ« since snapshots
still consume space and if we made too many of them we"d run a pool
that should have free space out of even its safety margin. But it would
sometimes make things easier.)</p>

<p>PS: I thought this had more of an impact on our operations and the
features we can reasonable offer to peopleÙ« but the more I think
about it the more it doesn"t. Partly this is because we don"t make
much use of snapshotsÙ« thoughÙ« for various reasons that sort of
boil down to "the natural state of disks is usually full". But
that"s for another entry.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSHierarchyQuotaLack?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusBlackboxVsAddTrust', 'How Prometheus Blackbox"s TLS certificate metrics would have reacted to AddTrust"s root expiry', '1593485594000',  14, '<div class="wikitext"><p>The last time around I talked about <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusBlackboxTLSExpiry">what Blackbox"s TLS certificate
expiry metrics are checking</a>Ù« but it
was all somewhat abstract. <a href="https://www.agwa.name/blog/post/fixing_the_addtrust_root_expiration">The recent AddTrust root expiry</a>
provides a great example to make it concrete. As a quick summaryÙ«
the <a href="https://github.com/prometheus/blackbox_exporter">Blackbox exporter</a>
provides two metricsÙ« probe_ssl_earliest_cert_expiry for the
earliest expiring certificate and
probe_ssl_last_chain_expiry_timestamp_seconds for the latest
expiring verified chain of certificates.</p>

<p>If your TLS server included the expiring AddTrust root certificate
as one of the chain certificates it was providing to clientsÙ« the
probe_ssl_earliest_cert_expiry metric would have counted down
and your alarms would have gone offÙ« despite the fact that your
server certificate itself wasn"t necessarily expiring. This would
have happened even if the AddTrust certificate wasn"t used any more
and its inclusion was just a vestige of past practices (for example
if you had a "standard certificate chain set" that everything
served). In this case this would have raised a useful alarmÙ« because
the mere presence of the AddTrust certificate in your server"s
provided chain caused problems in some (or many) TLS libraries
and clients.</p>

<p>(Browsers were fineÙ« though.)</p>

<p>Even if your TLS server included the AddTrust certificate in its
chain and your server certificate could use it for some verified
chainsÙ« the probe_ssl_last_chain_expiry_timestamp_seconds would
not normally have counted down. Most or perhaps all current server
certificates could normally be verified through another chain that
expired laterÙ« which is what matters here. If
probe_ssl_last_chain_expiry_timestamp_seconds had counted down
tooÙ« it would mean that your server certificate could only be
verified through the AddTrust certificate for some reason.</p>

<p>Neither metric would have told you if the AddTrust certificate was
actually being used by your server certificate through some verified
chain of certificatesÙ« or if it was now completely unnecessary.
Blackbox"s TLS metrics don"t currently provide any way of knowing
thatÙ« so if you need to monitor the state of your server certificate
chains you"ll need another tool.</p>

<p>(There"s a third party <a href="https://github.com/ribbybibby/ssl_exporter">SSL exporter</a>Ù« but I don"t think it
does much assessment of chain healthÙ« or give you enough metrics
to know if a server provided chain certificate is unnecessary.)</p>

<p>If you weren"t serving the AddTrust root certificate and had a
verified chain that didn"t use itÙ« but some clients required it to
verify your server certificateÙ« neither Blackbox metric would have
warned you about this. Because you weren"t serving the certificateÙ«
probe_ssl_earliest_cert_expiry would not have counted down; it
includes only TLS certificates you actually serveÙ« not all of the
TLS certificates required to verify all of your currently valid
certificate chains. And probe_ssl_last_chain_expiry_timestamp_seconds
wouldn"t have counted down because there was an additional verified
chain besides the one that used the AddTrust root certificate.</p>

<p>(In general it"s very difficult to know if some client is going to
have a problem with your certificate chainsÙ« because there are many
variables. Including outright programming bugsÙ« which were part of
the problem with AddTrust. If you want to be worriedÙ« read Ryan
Sleevi"s <a href="https://medium.com/@sleevi_/path-building-vs-path-verifying-implementation-showdown-39a9272b2820">Path Building vs Path Verifying: Implementation Showdown</a>.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusBlackboxVsAddTrust?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/python/DjangoAppAdaptations', 'Adapting our Django web app to changing requirements by not doing much', '1593407387000',  14, '<div class="wikitext"><p>We have <a href="https://utcc.utoronto.ca/~cks/space/blog/python/DjangoORMDesignPuzzleII">a Django web application to handle (Unix) account requests</a>Ù« which is now nine years old. I"ve called
this <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/ProductAndUtilityCode">utility code</a>Ù« but I
<a href="https://utcc.utoronto.ca/~cks/space/blog/python/DjangoIsProductCode">mentioned recently</a> that over that time there
have been some changes in how graduate students were handled that
needed some changes in the application. Except not very much change
was necessaryÙ« in some waysÙ« and in other ways the changes are
hacks. So here are some stories of those changes.</p>

<p>When we (I) initially wrote the web applicationÙ« our model of how
new graduate students got Unix accounts was straightforward. All
graduate students were doing a thesis (either a Masters or a PhD)
and so all of them have a supervising professor. As a long standing
matter of policyÙ« that supervisor was their <em>account sponsor</em>Ù« and
so approved their account request. Professors can also sponsor
accounts for other people associated with themÙ« such as postdocs.</p>

<p>(This model already has a little glitch; some students are co-supervised
by more than one professor. Our system requires one to be picked as the
account sponsorÙ« instead of somehow recording them as co-sponsoredÙ«
which has various consequences that no one has complained about so far.)</p>

<p>The first change that showed up was that <a href="https://www.cs.toronto.edu/">the department</a> developed a new graduate programÙ« the
<a href="https://mscac.utoronto.ca/">Master of Science in Applied Computing</a>.
Graduate students in the MScAC program don"t write a thesis and as
a result they don"t have a supervising professor. As it happenedÙ«
we already had a model for solving thisÙ« because Unix accounts for
administrative and technical staff are not sponsored by professors
either; they have special non-professor sponsors. So we added another
such special sponsor for MScAC students. This was not sufficient by
itselfÙ« because the account request system sometimes emails new
graduate students and the way those messages were written assumed
that the student"s sponsor was supervising them.</p>

<p>Rather than develop a general solution to thisÙ« we took the brute
force solution of an "{% if ...}" condition in the relevant Django
template. Because of how our data is set upÙ« this condition both
has to reach through several foreign keys and uses a fixed text
match against a magic nameÙ« instead of checking any sort of flag
or status marker (because no such status marker was in the original
data model). Fortunately the name it matches against is not exposed
to peopleÙ« because the official name for the program has actually
changed over time but our internal name has never been updated
(partly because it was burned into the text template). This is a
hackÙ« but it works.</p>

<p>The second change is that while all graduate students must eventually
get a specific supervisorÙ« not all of them have one initially when they
arrive. In particularÙ« there is one research group that accepts most
new graduate students collectively and then sorts out who they will be
supervised laterÙ« once the graduate students know more about the group
and their own interests. In the pastÙ« this had been solved artificially
by assigning nominal sponsors immediately even if they weren"t going to
be the student"s supervisorÙ« but eventually the group got tired of this
and asked us to do better. The solution here was similar to the
MScAC program (and staff accounts); we invented a synthetic "supervisor"
for themÙ« with a suitable generic name. Unlike with the MScAC programÙ«
we didn"t customize the Django templates for this new situationÙ« and
unfortunately the result does look a little ugly and awkward.</p>

<p>(This is where a general solution would have been useful. If we
were templating this from a database table or the likeÙ« we could
have just added a new entry for this general research group case.
Adding another Django "{% if ...}" to the template would have made
it too tangledÙ« so we didn"t.)</p>

<p>I don"t think we did anything clever in our Django application"s
code or its data model. A lot of the changes we were able to make
were inherent in having a system that was driven by database tables
and being able to add relatively arbitrary things to those tables
(with some hacks involved). Where our changes start breaking down
is exactly where the limitations of that start appearingÙ« such as
multiple cases in templates when we didn"t design that into the
database.</p>

<p>(Could we have added it later? Perhaps. But I"ve always been too
nervous about database migrations to modify our original database
tablesÙ« partly because I"ve never done one with Django. This is a
silly fear and in some ways it"s holding back the evolution of our
web application.)</p>

<p>PS: You might think that properly dealing with the co-supervision
situation would make the research group situation easy to deal withÙ«
by just having new graduate students "co-sponsored" by the entire
research group. It"s actually not clear if this is the right answerÙ«
because the situations are somewhat different on the Unix side.
When you actively work with a supervisorÙ« you normally get added
to their Unix group so you can access group-specific things (if
there are any)Ù« so for co-supervisors you should really get added
to the Unix groups for both supervisors. HoweverÙ« it"s not clear
if people collectively sponsored by a research group should be added
to every professor"s Unix group in the same way. This implies that
the Django application should know the difference between the two
cases so that it can signal our Unix account creation process to
treat them differently.</p>

<h3>Sidebar: Our name hack for account sponsors</h3>

<p>When someone goes to our web page to request an accountÙ« they have
to choose their sponsor from a big &lt;select> list of them. The list
is sorted on the sponsor"s last nameÙ« to make it easier to find.
The idea of "first name" and "last name" is somewhat tricky (as is
their order)Ù« and automatically picking them out from a text string
is even harder. So we deal with the problem the other way around.
Our Django data model has a "first name" and a "last name" fieldÙ«
but what they really mean is "optional first part of the name" and
"last part of the name (that will determine the sort order)".</p>

<p>As part of thisÙ« the synthetic account sponsors generally don"t
have a "first name"Ù« because we want them to sort in order based
on the full description (such as "MScAC Graduate Student"Ù« which
sorts in M not G or S).</p>

<p>(Sorting on "last name" is somewhat arbitraryÙ« but part of it is that we
expect people requesting accounts to be more familiar with the last name
of their sponsor than the first name.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/python/DjangoIsProductCode', 'Understanding why Django"s goals are not our goals for our web application', '1593317145000',  14, '<div class="wikitext"><p>A while back I wrote about how <a href="https://utcc.utoronto.ca/~cks/space/blog/python/DjangoGoalsNotOurGoals">Django"s goals are probably not
our goals for our web application</a>Ù« but at
the timeÙ« I didn"t have a succinct way of talking about why this was
the case.  Recently I wrote about a realization I"d come to about
<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/ProductAndUtilityCode">product code and utility code</a>Ù«
where product code is used as part of delivering your business but
utility code sits in the background doing other things. That
realization gives me a better way to talk about Django and us.</p>

<p>Right from its beginning as a newspaper"s publishing platformÙ«
<a href="https://www.djangoproject.com/">Django</a> has been product code and
been used for product code. Probably most large sized Python projects
(such as <a href="https://twistedmatrix.com/">Twisted</a>) see themselves
this way and are often used this wayÙ« with people building big
projects that support the business on top of them (after allÙ« you
rarely build big projects if you don"t need them). As direct and
indirect product codeÙ« Django is constantly evolving as the needs
of people"s businesses pull it in various directions. Django mostly
has good API stabilityÙ« but this stability is to enable people with
product code that use Django to move faster.</p>

<p><a href="https://utcc.utoronto.ca/~cks/space/blog/python/DjangoORMDesignPuzzleII">Our Django based Unix account request handling system</a> is not product codeÙ« it"s utility code.
The business rules and processes for authorizing new accounts are
set by policies that are extremely stableÙ« and <a href="https://www.cs.toronto.edu/">the department</a> doesn"t operate in a way where we
suddenly change the sort of accounts that we set up. How the
department teaches and what sort of programs it offers have changed
(although slowly)Ù« but that"s as far as it goes.</p>

<p>(Looking backÙ« there actually have been some modest policy changes
about some aspects of incoming graduate students. We"ve patched
around these in the account request system in some simple waysÙ«
which is actually an interesting story of flexibility and adaptation.
But the fundamental ideas of who can have an account here and who
decides that haven"t changed. University departments are like thatÙ«
and unlike businesses.)</p>

<p>As we"ve found outÙ« basing utility code on top of product code is
not a great path to happiness. This isn"t really surprising since
the two are pulling in different directions; utility code wants to
be staticÙ« while product code needs to evolve as business activities
do. Django has done a good job of being stable (in its API) despite
thatÙ« but there is still work to keep up with it (beyond the shift
to Python 3)Ù« and that work is not what utility code wants.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/NetworkManagerConnectionConflict', 'NetworkManager and (not) dealing with conflicting network connections', '1593225734000',  14, '<div class="wikitext"><p>I recently tweeted <a href="https://twitter.com/thatcks/status/1275799821199249409">a wish for NetworkManager</a>:</p>

<blockquote><p>I wish there was some straightforward way to tell NetworkManager to
not automatically connect to any wifi networks if my laptop has a
wired network connectionÙ« while still auto-connecting if there is no
wired Ethernet.</p>
</blockquote>

<p>In NetworkManager you can set a priority for network connectionsÙ«
but as far as I can tell you can"t tell it that two connections
conflict with each other and should never be brought up at the same
time. You can write scripts that run when connections change and
that take down connections (on Twitter <a href="https://twitter.com/zigford_org/status/1276070144930766848">@zigford</a> pointed
me to a script for this <a href="https://zigford.org/precision-5510---gentoo-gnulinux.html">here</a>)Ù« but I
don"t consider this straightforward. So let me give you the story of
how I have wound up wanting this.</p>

<p>I have <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/DellXPS13FedoraReview">a work laptop</a>Ù« which I"ve brought
home periodically for short periods of light use in the past (for
example over our Christmas vacations). At that point I set it up
for wireless networking and to automatically connect to my home
wireless for convenience. ThenÙ« thanks to <a href="https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic">current world and local
events</a>Ù« I
took my work laptop home for extended use over a longer periodÙ« and
soon discovered that my home wireless network has surprisingly high
and variable latency. Fortunately I"d also taken the laptop"s USB
Ethernet adapter and I have a little home switchÙ« so I could change
over to having my laptop use a wired connection (although <a href="https://twitter.com/thatcks/status/1247567034596147201">not
without fun discoveries</a>).</p>

<p>As it happensÙ« I don"t have two home subnetsÙ« one wired and one
wireless; I have one that everything is on (and the AP just extends
it out from wired to wireless). When I initially set up my laptop
at home on the wirelessÙ« I gave it a fixed IP address and name so
that I could easily SSH to it (and because I give everything here
a fixed IP address). When I "switched" my laptop to using a wired
connectionÙ« I gave that wired Ethernet address the same fixed IP
addressÙ« because I had no desire to have to SSH to "laptop-wired"
versus "laptop-wifi" (I just want to SSH to "laptop"). Unfortunately
this means that if both the wired and the wireless connections are
active at onceÙ« both get the same IP and then fun things happen.
EspeciallyÙ« some of my traffic to my laptop goes over the wirelessÙ«
with increased and variable latenciesÙ« which is what I set up a
wired connection to avoid.</p>

<p>(I"m honestly surprised that my DHCP server didn"t object to handing
out the same IP at once to two different thingsÙ« but then I did
tell it that both the wired and the wireless Ethernet addresses
could have the same IP. I"m also surprised at how long it took me
to notice this; I only did because I was running "ifconfig -a" for
another reason and noticed that my wifi adapter had an IP assigned.)</p>

<p>My current solution is to tell NetworkManager to not automatically
connect to my home wireless network. This is less convenient if I
want to use my work laptop from somewhere elseÙ« but in practice I
almost never do (my work laptop is mostly used for video conferencingÙ«
since it has a camera and a microphone; actual work happens from
my home desktop).</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/NetworkManagerConnectionConflict?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusBlackboxTLSExpiry', 'What Prometheus Blackbox"s TLS certificate expiry metrics are checking', '1593143536000',  14, '<div class="wikitext"><p>One of the things that the <a href="https://github.com/prometheus/blackbox_exporter">Prometheus Blackbox exporter</a> can do is connect
to services that use TLS and harvest enough certificate information
from them to let you monitor and alert on soon to expire TLS
certificates. TraditionallyÙ« this was a single metricÙ«
probe_ssl_earliest_cert_expiryÙ« but in <a href="https://github.com/prometheus/blackbox_exporter/releases/tag/v0.17.0">the 0.17.0 release</a> a
second one was addedÙ« probe_ssl_last_chain_expiry_timestamp_seconds.
TLS certificate expiry issues have been on my mind because of <a href="https://www.agwa.name/blog/post/fixing_the_addtrust_root_expiration">the
mess from the AddTrust root expiry</a>Ù« and
recently I read a pair of articles by Ryan Sleevi on <a href="https://medium.com/@sleevi_/path-building-vs-path-verifying-the-chain-of-pain-9fbab861d7d6">TLS certificate
path building and verifying</a>
(<a href="https://medium.com/@sleevi_/path-building-vs-path-verifying-the-chain-of-pain-9fbab861d7d6">part 2</a>)Ù«
which taught me that this issue isn"t at all simple. After all thisÙ«
I wound up wondering exactly what these two Blackbox exporter metrics
were checking.</p>

<p>When you connect to a TLS serverÙ« it sends one or more certificates
to youÙ« generally at least twoÙ« in what is commonly called a
<em>certificate chain</em>. These server sent certificates don"t include
the Certificate Authority"s root certificateÙ« because you need to
already have thatÙ« and they don"t actually have to form a single
chain or even be related to each other. Normally they should be a
chain (and <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SSLChainOrder">be in a specific order</a>)Ù« but
people make all sorts of configuration errors and decisions in the
certificates that they send. The Blackbox exporter"s
probe_ssl_earliest_cert_expiry metric is the earliest expiry
of any of these server sent certificates. I"m not certain if it"s
filtered of invalid certificatesÙ« but it definitely doesn"t exclude
self-signed certificates.</p>

<p>(SpecificallyÙ« it is the earliest expiry of a certificate in the
Go <a href="https://golang.org/pkg/crypto/tls/#ConnectionState">crypto.tls.ConnectionState</a>"s <code>PeerCertificates</code>.)</p>

<p>When you actually verify a TLS certificate (if you do it correctly) you
wind up with one or more valid paths between the server certificate and
some roots of trust; we can call these the <em>verified chains</em>. These
chains will use the server certificate that the server sent youÙ« but
they may not use all or even any of the other certificates. To work
out the probe_ssl_last_chain_expiry_timestamp_seconds metricÙ« the
Blackbox exporter first goes over every verified chain to find out the
earliest expiry time of any certificate in it and the picks the latest
such chain expiry time. These verified chains do include the CA root
certificatesÙ« which don"t necessarily expire regardless of their nominal
expiry time. If there are no verified chains at allÙ« such as if you"re
dealing with a self-signed certificateÙ« the Blackbox exporter currently
makes this metric be an extremely large and useless negative number.</p>

<p>(The verified chains come from the Go <a href="https://golang.org/pkg/crypto/tls/#ConnectionState">crypto.tls.ConnectionState</a>"s
<code>VerifiedChains</code>. If there are no verified chainsÙ« the metric is
the zero value of Go"s <a href="https://golang.org/pkg/time/#Time">time.Time</a>
turned into a time in the Unix epoch. Since this zero value is more
than a thousand years before January 1st 1970 UTCÙ« it winds up very
negative. This is potentially a bug and may change someday.)</p>

<p>Normally there will always be a verified chainÙ« because otherwise
the Blackbox TLS probe would fail entirely. You have to specifically
set insecure_skip_verify to true in the Blackbox configuration
in order to accept self-signed certificates or other chain problems.</p>

<p>So what do these metrics meanÙ« beyond their technical details? If the
earliest certificate expiry is soonÙ« it doesn"t necessarily mean that
your TLS server certificate itself is about to expireÙ« but it does mean
that some TLS certificate your server is providing to people is about
to. Either you"re serving an unnecessary intermediate TLS certificateÙ«
or some number of your users are about to have a problem. Either is
an issue that you should fixÙ« especially since an expired certificate
that"s not necessary may still make many TLS libraries fail to verify
your server certificate.</p>

<p>(This is part of <a href="https://www.agwa.name/blog/post/fixing_the_addtrust_root_expiration">what happened with the AddTrust expiry</a>.
A surprisingly large number of TLS libraries had to be patched
to just skip it.)</p>

<p>The last chain expiry is the point at which you definitely will
have problemsÙ« because no one at all will be able to build a verified
chain for your server certificate. A last chain expiry that"s well
into the future is not a guarantee that you"ll be free of problems
until thenÙ« unless you know that there"s only one valid chain that
can be formed from your server certificate. If there are multiple
chainsÙ« not all clients may able to use all chains so some of them
could be stuck on chains that might expire earlier. The Blackbox
exporter doesn"t currently have a metric for the earliest expiring
verified chainÙ« but perhaps it should.</p>

<p>(Normally all verified certificate chains will have the same expiry
timeÙ« because the shortest lifetime certificate on them should be
the server"s certificate itself. If there are multiple chains and
there"s a difference between the latest and the earliest chain
expiry timeÙ« you may be about to have an exciting time (although
it"s not your fault).)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/unix/FilesystemStatDeviceProblem', 'Unix"s design issue of device numbers being in stat() results for files', '1593050647000',  14, '<div class="wikitext"><p>SometimesÙ« you will hear the view that Unix"s design is without
significant issuesÙ« especially the "pure" design of Research Unix
(before people who didn"t really understand Unix like Berkeley and
corporate AT&amp;T got their hands on it). Unfortunately that is not
the caseÙ« and there are some areas where Research Unix made decisions
that still haunt us to this day. For reasons beyond the scope of
this entryÙ« today"s example is that part of the file attributes
that you get from <a href="https://man.openbsd.org/stat.2"><code>stat()</code></a> system
call and its friends is the "device number" of the filesystem the
file is on.</p>

<p>(To be specificÙ« this is the <code>st_dev</code> field of the <code>struct stat</code>
that <code>stat()</code> returnsÙ« which has been since <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/include/sys/stat.h">V7"s stat.h</a>.
The <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V6/usr/man/man2/stat.2">V6 stat()</a> was
even more explicit about what it was returning.)</p>

<p>In UnixÙ« the user level file attributes you get back need some kind
of locally unique identifier for the filesystem that the file is
onÙ« so the presence of some identifier is not a mistake. The
identifier being different between two files is how you detect
things like that you"re at a filesystem mount pointÙ« that you can"t
use <a href="https://man.openbsd.org/link.2"><code>link()</code></a>Ù« or that two otherwise
identical looking files are not actually hardlinked together because
they"re on different filesystems. It"s also useful to have an
identifier that can be matched up with things like a list of mounted
filesystems.</p>

<p>HoweverÙ« early Unixes didn"t make this merely some identifierÙ« they
made this specifically the device number of the underlying disk
device that the filesystem was mounted from (hence its name as
"<code>st_dev</code>"). This had the unfortunate consequence of permanently
joining two logically separate identifier namespacesÙ« the namespace
of (mounted) filesystems and the namespace of block devices.</p>

<p>NowÙ« 40 odd years laterÙ« we have plenty of Unix filesystems that
don"t have underlying block devices (especially singular ones).
Anything mounted using one of these filesystems needs to somehow
make up a "device number" for itselfÙ« and this device number can"t
be the same as any real block device. This generally requires Unixes
to carve out a section of their overall block device numbers that"s
reserved for filesystems to do this withÙ« in other words things
that aren"t actually block devices. Fortunately modern Unixes have
generally made the namespace of device numbers be much larger than
it used to be.</p>

<p>(Then because device numbers for block devices are generally stableÙ«
a certain amount of software expects the "device number" returned as
part of file attributes to also be stableÙ« for any arbitrary filesystem.
When the kernel and a filesystem has to make this number up on the flyÙ«
this is not always the case.)</p>

<p>At the same timeÙ« this is a good design for V7 itselfÙ« in the time and
the context. V7 and its kernel were intended to be a small systemÙ« and
in a small system you don"t want to go doing extra work unless you
absolutely have toÙ« especially in the kernel. V7 could reuse the device
number to be the filesystem identifier essentially for freeÙ« so that"s
what it did.</p>

<p>(V7"s kernel took any number of shortcuts in the interests of having
a simple implementation. For instanceÙ« a lot of things were stored
in small fixed-sized arraysÙ« because you would never have more than
a modest number of processesÙ« open filesÙ« or so on.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/web/PeopleShowYouSiteFlaws', 'Sometimes it takes other people to show you some of your site"s design flaws', '1592969714000',  14, '<div class="wikitext"><p>RecentlyÙ« I wrote an entry about <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/Go2GenericsExpectedEfficiency">people"s efficiency expectations
for generics in Go</a>Ù«
and also wound up having a little discussion in the comments of
that entry. The r/golang reddit <a href="https://old.reddit.com/r/golang/comments/hcce4e/peoples_efficiency_expectations_for_generics_in/">linked to my entry</a>Ù«
so I read itÙ« and one thing I noticed was that one of the people
commenting probably didn"t realize that the entry and my comment
on it had been written by the same person.</p>

<p>My first reaction was uncharitableÙ« but then I put myself in that
commentator"s shoes and had a rather more humbling reaction. Looking
at it from the outsideÙ« right now there"s no particularly obvious
sign in how I display comments here that the "cks" who left a comment
is in fact the author of the entry. There are contextual clues (for
example "cks" appears in several places around <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>Ù« including the URL and <a href="https://mastodon.social/@cks">my Fediverse link</a>)Ù« but there"s nothing that says it
clearly. Even my name is not directly visible on the comment; I
hide it behind an &lt;abbr> element with a titleÙ« which is not obvious
at the best of times and is <a href="https://utcc.utoronto.ca/~cks/space/blog/web/HTMLAbbrAndMobileBrowsers">probably completely invisible on
mobile browsers</a>Ù« something I didn"t
know until yesterday.</p>

<p>(Because I"m likely to change how comments are displayedÙ« right now
the comment authorship for me looks like "By <abbr title="Chris Siebenmann">cks</abbr> at ...". The "cks" is the &lt;abbr>Ù« if it doesn"t show
in your browser.)</p>

<p>Obviously I should do something about this specific flaw in how
<a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a> (the wiki engine underlying <a href="https://utcc.utoronto.ca/~cks/space/blog/">this blog</a>) displays
comments written by myselfÙ« although I haven"t decided exactly how
it should look. But this is also a useful general lesson in how
flaws in our own designs can linger until someone points them outÙ«
and also on how the flaws may not be pointed out in an obvious and
explicit way. Any time you wind up thinking "how could someone not
see that?" about some aspect of your websiteÙ« you should probably
step back and take a serious attempt at figuring out why. There
may be a good reason.</p>

<p>(This can be extended to more than websites. Over timeÙ« I"ve learned
that when people miss something or misunderstand what I"ve written
hereÙ« often I haven"t quite written what I thought I did. I"ve
assumed too much backgroundÙ« or I haven"t written out what was
obvious in my headÙ« or I"ve cut some corners.  It all looked good
to me in reading it over before postingÙ« because I knew what I was
talking aboutÙ« but other people don"t. I"ve seen similar issues
come up when I put together <a href="https://grafana.com/">Grafana</a>
dashboards for <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">our monitoring setup</a>; I knew what they were
saying and how to read themÙ« but my co-workers didn"t and so couldn"t
follow the morass.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/web/HTMLAbbrAndMobileBrowsers', 'Today I learned that HTML &lt;abbr> may not do much on mobile browsers', '1592882210000',  14, '<div class="wikitext"><p>For some timeÙ« I"ve been using HTML &lt;abbr> elements with <code>title</code>
attributes in my writing here on <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>.
Sometimes I use it purely to provide a friendly expansion of
abbreviationsÙ« like a TLS <abbr title="Certificate Authority">CA</abbr> or
<abbr title="Man In The Middle (attack)">MITM</abbr>; sometimes the expansion
acquires some additional commentaryÙ« such as the mention of &lt;abbr>
itself in <a href="https://utcc.utoronto.ca/~cks/space/blog/web/HTMLDetailsWikiProblem">this entry</a>Ù« and sometimes I
use it for little asides. In a couple of contexts I use it to provide
additional information; for exampleÙ« any of my comments here
(currently) say that they are "by <abbr title="Chris Siebenmann">cks</abbr>"Ù«
where the &lt;abbr> is used to add my name.</p>

<p>Today I had a reason to look at some of my pages that are using
&lt;abbr> in a mobile browserÙ« specifically the iOS mobile browser.
That was when I learned that iOS Safari doesn"t render &lt;abbr> in
any visible wayÙ« which is fairly reasonable because there"s no real
way to interact with it; on desktopsÙ« an &lt;abbr>"s title is shown
when you hover the mouse over itÙ« but on mobile there"s no hover.
This is a bit surprising because both <a href="https://developer.mozilla.org/en/docs/Web/HTML/Element/abbr">MDN"s &lt;abbr> page</a> and
<a href="https://caniuse.com/#feat=mdn-html_elements_abbr">CanIUse</a> currently
say that it"s fully supported on mobile browsers.</p>

<p>Once I started doing Internet searches it appears that this is a
long standing issue and unlikely to change (because of the hover
problem). There are various workarounds with both CSS and JavaScriptÙ«
but I"m not certain I like any of themÙ« especially with how I"ve
historically used &lt;abbr> here; some of my &lt;abbr> usage would look
very out of place if displayed inline in some way. Given that a
decent amount of browsing comes from mobile these daysÙ« this is
likely going to cause me to rethink how I use &lt;abbr> here on
<a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a> and likely use it a lot lessÙ« if at
all. Probably a lot more terms will wind up as actual links to
explanations of themÙ« which is not necessarily a bad change overall.</p>

<p>This is a useful lesson to me that the webÙ« and especially the
mobile webÙ« is an ongoing learning experience. Things that I think
I know should be tested every so oftenÙ« and I should look at my own
sites in a mobile browser more often.</p>

<p>(As part of thisÙ« I should find out if there"s a not too annoying
and difficult way to look at and interact with my sites from an
Android browserÙ« despite not having any Android devices myself.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/HTMLAbbrAndMobileBrowsers?showcomments#comments">5 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoValueCopyIsTyped', 'In GoÙ« the compiler needs to know the types of things when copying values', '1592791194000',  14, '<div class="wikitext"><p>If Go implements generics (which seems likely to happen someday)Ù«
there will be a lot of interesting generic functions that don"t
need to do much more with the specific types they"re instantiated
with other than copy values around (and often allocate slices and their
backing arrays). The classical mapÙ« filterÙ« and reduce trio all
don"t need to do anything more themselves than copy valuesÙ« and the
same is true for things like making a slice of the keys of a map.
If the compiler is interested in generating only a single set of
code for these generic functions (similar to <a href="https://dave.cheney.net/2018/05/29/how-the-go-runtime-implements-maps-efficiently-without-generics">how maps are implemented</a>)Ù«
one interesting question is how much it needs to know about the
values being copied around here. In particularÙ« does the Go runtime
need to know their typeÙ« or is it enough to know how big they are
and then just copy the relevant number of bytes with a memory move?</p>

<p>Unfortunately for usÙ« the answer is that <strong>the Go runtime needs to
know the types of the values it"s copying</strong>Ù« even if it"s only
copying them to already allocated memory. We can discover why by
looking at the source for <a href="https://go.googlesource.com/go/+/refs/heads/master/src/runtime/mbarrier.go#149"><code>runtime.typedmemmove</code></a>.
The short version of why is that if the runtime is currently doing
a garbage collectionÙ« all Go code needs to take special precautions
when updating pointers. This includes when copying values that are
either pointers or composite types that include pointers. When doing
a bulk memory moveÙ« the runtime needs to know where the pointers
are in the destinationÙ« and that requires knowing the type of the
destination.</p>

<p>(For moreÙ« see <a href="https://go.googlesource.com/go/+/refs/heads/master/src/runtime/mbitmap.go#581"><code>runtime.bulkBarrierPreWrite</code></a>.)</p>

<p>The Go runtime also needs to know the type of things when allocating
memory for them (such as when creating or expanding a slice). This
is because all newly allocated objects must have runtime information
set up so that the Go garbage collector knows where any pointers
in them are (among other thingsÙ« this is <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoUnsafeTypeConvGCSafety">why unsafe type conversions
are still garbage collection safe</a>).
Setting up this information requires knowing the type of what is
being allocatedÙ« because this information on pointers is in the
type information.</p>

<p>The exception for both copying values and allocating new memory for
them is that if the type contains no pointersÙ« I believe that all
the Go runtime needs to know is that and what alignment is required
for values. A generic function could thus potentially be compiled
into a general version for pointer containing types and a narrower
version that only worked for non-pointer types. In practice you
would probably just compile a version that was passed a pointer to
the type informationÙ« because the type information gives you sizeÙ«
alignmentÙ« and pointer information all in one place with only a
single argument.</p>

<p>(You"ll notice that <a href="https://go.googlesource.com/go/+/refs/heads/master/src/runtime/mbarrier.go#149"><code>runtime.typedmemmove</code></a> is just a <code>memmove()</code>
if the type doesn"t contain any pointersÙ« although some of this is
hidden in <a href="https://go.googlesource.com/go/+/refs/heads/master/src/runtime/cgocheck.go#59"><code>runtime.cgoCheckMemmove</code></a>.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DNSUpdatesAndSecondaries', 'The additional complications in DNS updates that secondary DNS servers add', '1592695145000',  14, '<div class="wikitext"><p>I was recently reading Julia Evans" <a href="https://jvns.ca/blog/how-updating-dns-works/">What happens when you update
your DNS? </a> (which
is a great clear explanation of what it says)Ù« and it brought back
some painful memories of the old days (which are still the current
days for some people)Ù« which I might as well share.</p>

<p>TodayÙ« most DNS services that people deal with are managed DNS
providers. When you enter a DNS update into your DNS provider"s API
or website for thisÙ« magical things happen behind the scenes in the
DNS provider"s infrastructure and your update normally goes live
more or less immediately on all of the authoritative DNS servers
involved in answering queries for your domain. In this environmentÙ«
where your changes appear on your authoritative DNS servers effectively
instantlyÙ« the only thing that matters for how fast your changes
are visible is how long the various recursive DNS servers on the
Internet have cached your existing informationÙ« as Julia Evans
covers.</p>

<p>HoweverÙ« authoritative DNS servers didn"t originally work that way
and even today things don"t necessarily quite work out that way if
you run your own DNS service using straightforward DNS servers like
<a href="https://nlnetlabs.nl/projects/nsd/about/">NSD</a> or the venerable
Bind. The original DNS server environment had the idea of <em>primary</em>
and <em>secondary</em> authoritative DNS servers. The primary DNS servers
got all of the data for your zone from files on their disk (or more
recently perhaps from a database or some network data source)Ù« and
the secondary DNS servers got the data for your zone by copying it
from a primary DNS server (possibly one that wasn"t advertised
publiclyÙ« which is often called a "stealth master")Ù« generally with
an <a href="https://en.wikipedia.org/wiki/DNS_zone_transfer">AXFR</a>.
Effectively your secondary authoritative DNS servers were (and are)
a cache.</p>

<p>(You could have multiple primary serversÙ« at which point it was up
to you to make sure they were all using the same DNS zone data. The
very simple way to do this was to <code>rsync</code> the data files around to
everyone before having the DNS servers reload zones.)</p>

<p>Any time that you have what is effectively a cacheÙ« you should be
asking about cache invalidation and refreshing; DNS servers are no
exception. The original answer to this is in the specifications of
<a href="https://en.wikipedia.org/wiki/SOA_record">the DNS SOA record</a>Ù«
which has (zone) <em>refresh</em>Ù« <em>retry</em> (of a failed refresh)Ù« and
<em>expire</em> timesÙ« and a zone serial number so that secondaries could
tell when their copy of the zone was out of date compared to the
DNS primary.  Every refresh intervalÙ« a secondary would check the
SOA serial number on its primary and fetch an update if necessary.
If it couldn"t talk to the primary for long enoughÙ« it would declare
the zone stale and stop answering queries from its cached data.</p>

<p>This meant that DNS updates had two timers on their propagation
aroundÙ« once you made them. First they had to propagate from the
primary to all of the secondariesÙ« which was based on the SOA refresh
time.  Once all secondaries were answering queries using the new
DNS dataÙ« recursive DNS servers could still have old queries cached
for up to the query TTL. In the worst caseÙ« where you make a change
just after a refresh and a recursive DNS server queried your last
secondary just before its refresh timer went offÙ« your update might
not reach everyone until the sum of the entry"s TTL and the zone"s
SOA refresh.</p>

<p>(Adding a new DNS record could have a similar delay but here the
first time was the SOA <em>minimum</em> valueÙ« which in theory set the TTL
for negative replies. More or less.)</p>

<p>Having to wait for secondary DNS servers to hit their refresh timers
to update has various issues. Obviously it slows down DNS updatesÙ«
but it also means that there"s a potentially significant amount of
time when your various authoritative DNS servers are giving different
answers to queries. All of this was recognized relatively early on
and led to <a href="https://tools.ietf.org/html/rfc1996">RFC 1996</a>Ù« which
created the DNS NOTIFY mechanismÙ« which lets primary servers send
a special DNS NOTIFY message to secondaries.</p>

<p>When you update your primary serversÙ« they signal the secondary
servers that a zone change has (probably) happened. Generally the
secondaries will then immediately try to transfer the updated zone
over so they can use it to answer queries. A DNS NOTIFY doesn"t
guarantee that the secondaries are promptly up to dateÙ« but it makes
it much more likelyÙ« and there is some protection against the NOTIFY
being dropped in transit between the primary and the secondaries.
In practice this seems to work fairly wellÙ« especially in network
environments where the primaries and secondaries are close to each
other (in network terms).  However it"s still not guaranteedÙ« so
if you have <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">a monitoring system</a>Ù«
it"s worth having a check for the SOAs on your zones not being out
of sync for too long between your primaries and secondaries.</p>

<p>(DNS providers hopefully have similar internal monitoring.)</p>

<p>Normally your primary DNS server software will automatically send
out DNS NOTIFY messages to appropriate secondary servers if you
tell it to reload things. You can generally manually trigger sending
them even without a zone change or reload; one use of this is making
sure that a particular secondary (or all of them) gets a little
prod to try doing an update.</p>

<p>PS: Since we run our DNS ourselves <a href="https://support.cs.toronto.edu/">here</a>Ù« this whole area remains an
issue that we have to think about and remember some aspects of.
But that"s another entry.</p>

<p>PPS: Usually secondary servers have restrictions on who they"ll accept
DNS NOTIFY messages fromÙ« and I believe the messages can optionally be
authenticated in some way these days.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DNSUpdatesAndSecondaries?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraRemovingMustBeOptIn', 'Removing unmaintained packages from your Fedora machine should require explicitly opting in', '1592621064000',  14, '<div class="wikitext"><p>Ben Cotton recently wrote an entry on <a href="https://funnelfiasco.com/blog/2020/06/18/removing-unmaintained-packages-from-an-installed-system/">Fedora potentially removing
unmaintained packages from your system under some circumstances</a>Ù«
because there is <a href="https://fedoraproject.org/wiki/Changes/Fedora-Retired-Packages">a Fedora change proposing to remove "retired"
packages</a>.
The change proposal contains the following remarks:</p>

<blockquote><h4>Upgrade/compatibility impact</h4>
<p>During an upgradeÙ« all retired packages will be automatically removed.</p>

<p>[...]</p>

<h4>How To Test</h4>
<p>1. Upgrade to next version of Fedora. 2. Check all retired packages
are removed.</p>
</blockquote>

<p>In the ending of Ben Cotton"s articleÙ« he says in passing "[B]ut
we have to make sure weâ€™re clearly communicating what is happening
to the user" if package removal happens. I will go further than that.</p>

<blockquote><p><strong>Removing packages from your system on Fedora upgrades should require
an explicit opt-in</strong>Ù« and this opt-in should be able to show you the
list of packages being removed.</p>
</blockquote>

<p>Going beyond thatÙ« Fedora should never remove unmaintained packages
from your system without this opt inÙ« for example they should never
push out an updated <code>fedora-retired-packages</code> RPM in Fedora updates.</p>

<p>Removing unmaintained packages from people"s systems is removing
functionality with no replacement or equivalent. This can break what
people are doing with their Fedora machinesÙ« and doing so is both
morally wrong and dangerous in practice. It doesn"t take too many cases
of Fedora upgrades or Fedora package updates breaking things without
warning for people to stop doing either of them.</p>

<p>Because this requires explicit user opt-in and a UI and so onÙ« and
additional unmaintained packages should not be removed during the
lifetime of a Fedora releaseÙ« I think that removing retired packages
during upgrades should live in the upgraderÙ« not be implemented as
an RPM package (or at least not as an RPM package that"s installed
by default). The upgrade system is the only place that is in a
position to actively prompt the user in a meaningful way to obtain
explicitÙ« informed opt-in consent to this.</p>

<p>(The lightweight version of this would be to require people to opt in in
advance by installing the special <code>fedora-retired-packages</code> RPM. People
who know enough to manually select and install the package can be
presumed to know what they"re doing and be making an informed choice to
accept whatever package retirements Fedora wants to push.)</p>

<p>PS: I was going to consider this different from the existing situation
with fedora-obsolete-packages for various hand-waving reasonsÙ« but
the more I look at what packages Fedora has removed through the
fedora-obsolete-packages RPMÙ« the more I think that the two should be
mostly merged together and treated very similarly (ieÙ« require explicit
opt-in). The current fedora-obsolete-packages goes well beyond merely
removing packages that cause upgrade problems (unless you take a rather
expansive view of "upgrade problems").</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraRemovingMustBeOptIn?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/Go2GenericsExpectedEfficiency', 'People"s efficiency expectations for generics in "Go 2" and patterns of use', '1592540727000',  14, '<div class="wikitext"><p>The Go authors have recently come out with <a href="https://blog.golang.org/generics-next-step">a blog entry on the
next steps for generics</a>
and a new <a href="https://go.googlesource.com/proposal/+/refs/heads/master/design/go2draft-type-parameters.md">draft design based on interfaces instead of contracts</a>.
As it always isÙ« one of the concerns raised in the draft is about
<a href="https://go.googlesource.com/proposal/+/refs/heads/master/design/go2draft-type-parameters.md#efficiency">the efficiency tradeoffs of any implementation</a>.</p>

<p>Roughly speakingÙ« there are two ways to implement generics. One is
to generate fully specialized implementations every time a generic
function or type is specialized to a concrete set of types; another
is to compile only a single implementation and quietly pass hidden
parameters to the implementation so that it can do its workÙ« similar
to how interfaces are implemented in Go (and also maps; most of the
code of Go maps is genericÙ« not specialized for each type of map).
Fully specialized implementations are as fast as the compiler can
make them with full knowledge of the types and functions involvedÙ«
but they take longer to compile and result in more code in the final
binary.</p>

<p>In thinking about thisÙ« it strikes me that there are two usage
patterns (or at least extremes of usage patterns) for genericsÙ«
based on what code people often write in Go today. I will call these
<em>type safe interfaces</em> and <em>single implementations</em> respectively.
The type safe interfaces usage pattern would use generics to implement
a type safe version of what code is already doing with <code>interface{}</code>
or somewhat more restrictive interfaces today. The proposal itself
talks about Go using generics to implement type safe versions of
things like <a href="https://golang.org/pkg/container/list/">container/list</a>
and <a href="https://golang.org/pkg/sync/#Map">sync.Map</a> (<a href="https://go.googlesource.com/proposal/+/refs/heads/master/design/go2draft-type-parameters.md#pervasiveness">here</a>).</p>

<p>The single implementations usage pattern would use generics to condense
what today is multiple copies of essentially the same codeÙ« specialized
to various typesÙ« into a single block of code using generic types. These
are the people who are tired of writing yet another copy of the function
to generate a slice of all of the keys of a map of some new type. Their
existing code could in theory be written once using <code>interface{}</code> and a
lot of typecastsÙ« but in practice repetition is better than all of the
typecasts required (and the resulting possibility of runtime panics)Ù«
especially since the underlying code is often reasonably simple and
short.</p>

<p>People in the type safe interfaces usage pattern probably don"t
mind the potential speed overheads of a single unspecialized
implementationÙ« because they are already paying that penalty today.
This does imply that such a generics implementation shouldn"t perform
worse than the interface based equivalent. People in the single
implementations usage pattern are replacing hand specialized Go
code with a generics implementation so they can write it only once.
Some of them won"t be willing to do this if there"s a significant
performance penalty as a result of such a conversionÙ« and in general
these people are willing to pay the compile time and space penalty
for specialized implementations because they"re already doing so
today with their hand specialized code.</p>

<p>(Hopefully the Go compiler can find clever ways to often make the
extra cost of unspecialized code very lowÙ« similar to <a href="https://dave.cheney.net/2018/05/29/how-the-go-runtime-implements-maps-efficiently-without-generics">how it
implements maps efficiently</a>.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/Go2GenericsExpectedEfficiency?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/DesktopAppAutostart', 'How applications autostart on modern Linux desktops', '1592446308000',  14, '<div class="wikitext"><p>A while back I mentioned that <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/MicrosoftTeamsBadArrogance">part of Microsoft Teams" misbehavior
was autostarting when you logged in</a>;
recentlyÙ« because I was testing <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/XInputGtkScrollPuzzle">some things</a>
on my laptop with alternate desktopsÙ« <a href="https://twitter.com/thatcks/status/1273261622933557249">that behavior led to me
uninstalling Teams</a>. So all
in allÙ« it seemed like a good time to read up on how applications
get automatically started when you log in (if they do) on modern
Linux desktops like Gnome and Cinnamon.</p>

<p>(This is not normally an issue for me in <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/MyDesktopTour">my desktop environment</a>Ù« because everything in it is explicitly
started by hand in a shell script.)</p>

<p>UnsurprisinglyÙ« there"s a <a href="https://freedesktop.org/">freedesktop.org</a>
standard on thisÙ« the <a href="https://specifications.freedesktop.org/autostart-spec/latest/">Desktop Application Autostart Specification</a>Ù«
which builds on the <a href="https://specifications.freedesktop.org/desktop-entry-spec/latest/"><code>.desktop</code> file specification</a>.
The simple version is that you set applications to autostart by
installing an appropriate .desktop file for them into either
<code>/etc/xdg/autostart</code> (for a system-wide autostart on login) or
<code>~/.config/autostart</code> (for an autostart for an individual user).</p>

<p>There are a number of special settings keys that can be in these
.desktop files. FirstÙ« you can have a <code>OnlyShowIn</code> or <code>NotShowIn</code>
key that controls which desktops should autostart this or not
autostart it (the specification misspells these keys in some mentions
of them). SecondÙ« you can have a <code>Hidden=true</code> keyÙ« in which case
the application should not autostart (in any desktop). For obvious
reasonsÙ« the latter key is most useful in your personal autostart
directory.</p>

<p>Some desktops have custom keys of their ownÙ« and even custom locations
for additional .desktop files to autostart; for example KDE before
KDE 5 apparently also used ~/.kde/Autostart (see <a href="https://docs.kde.org/trunk5/en/kde-workspace/kcontrol/autostart/index.html">here</a>).
An important and common property is X-GNOME-Autostart-enabledÙ« which
is (still) in wide use despite <a href="https://gist.github.com/najamelan/b44e943145b03e018229">apparently being deprecated</a>.  In
particularÙ« Cinnamon appears to implement disabling of standard
autostart things by copying their .desktop file to your ~/.config/autostart
directory and adding a line to the end with
"X-GNOME-Autostart-enabled=false".</p>

<p>(GNOME .desktop files can also have a phase of GNOME"s startup that
they happen in; see <a href="https://gist.github.com/najamelan/b44e943145b03e018229">here</a> and <a href="https://github.com/GNOME/gnome-session/blob/master/gnome-session/README">here</a>.
KDE .desktop files apparently have somewhat similar properties too.)</p>

<p>Some desktops have their own custom locations for various special
thingsÙ« or have had in the past (<a href="https://askubuntu.com/questions/971105/what-is-the-difference-between-config-autostart-and-config-autostart-scrip">eg</a>Ù«
<a href="https://wiki.archlinux.org/index.php/KDE#Autostart">also</a>Ù« and
for <a href="https://wiki.lxde.org/en/Autostart">LXDE</a>). HoweverÙ« desktops
don"t necessarily use custom locations and settings. I know that
with CinnamonÙ« if you add a new thing to be done on startupÙ« Cinnamon
puts a new .desktop file in your ~/.config/autostart.</p>

<p>More minimal "desktops" may or may not automatically support .desktop
autostarts. HoweverÙ« according to the Arch wiki"s page on <a href="https://wiki.archlinux.org/index.php/XDG_Autostart">XDG
Autostart</a>Ù«
there are standalone programs that will do this for you if you want
them to. On my normal machinesÙ« my own window manager environment
is so divergent that I don"t think autostarting .desktop files is
of any use to meÙ« so I"m not planning to try any of them.</p>

<p>(<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/DellXPS13FedoraReview">My work laptop</a> runs a more or less
standard Cinnamon environmentÙ« which automatically handles autostarting
things. I believe that Cinnamon considers itself a form of GNOME
for <code>OnlyShowIn</code> and <code>NotShowIn</code> and so on .desktop keys. Cinnamon
certainly disables autostarted things using a GNOME specific key.)</p>

<p>Applications can arrange to autostart in at least two waysÙ« the
honest way and the sneaky way. The honest way is to put a copy of
their .desktop file into <code>/etc/xdg/autostart</code>. The sneaky way is
to wait until you run them onceÙ« then copy their .desktop file into
your ~/.config/autostart directory (re-copying this file every time
they"re run is optional). Based on poking through the RPM package
for Microsoft Teams (and also <a href="https://twitter.com/jrcresawn/status/1273293329774505984">how they apparently have a preferences
setting about this</a>)Ù« Teams
appears to do this the sneaky way.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/XInputGtkScrollPuzzle', 'A scrolling puzzle involving GTK+Ù« XInputÙ« and alternate desktops (on Fedora)', '1592368628000',  14, '<div class="wikitext"><p>Recently I discovered that <a href="https://github.com/IBBoard/cawbird">cawbird</a>
wasn"t recognizing certain "scroll up" events in parts of its
interface. This wasn"t a new issueÙ« although I originally thought
it was; instead for years I"d been missing some of cawbird"s
functionality without noticing (and before itÙ« corebird). I don"t
know exactly what the core problem isÙ« but part of it appears to
be some sort of interaction between desktop environments (or the
lack of them) and <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/XInputOldAndNew">the new approach to handling input devices using
the X Input Extension</a>.</p>

<p><a href="https://github.com/IBBoard/cawbird/issues/164">The actual Cawbird issue</a>
is somewhat complicated and tangledÙ« but fortunately it can be
boiled down to a simpler situation through <a href="https://bugzilla.gnome.org/show_bug.cgi?id=675959">a test program that
prints GTK mouse scroll event information</a> (a copy of my
version is <a href="https://utcc.utoronto.ca/~cks/programs/gtk-events/gtk-scroll-events.c">here</a>).
For backgroundÙ« when vertical scrolling happens in GDKÙ« you can see
either or both of specific smooth scrolling eventsÙ« with a Y delta
of some valueÙ« and "scroll up" and "scroll down" eventsÙ« which
appear to always have a Y delta of 0.</p>

<p>On <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/MyDesktopTour">my desktop</a> running <a href="http://www.fvwm.org/">fvwm</a> outside of a desktop environment like GnomeÙ«
what I see from the test program when I use my mouse scroll wheel
is just a stream of scroll up and scroll down events from a source
device of "Core Pointer". On <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/DellXPS13FedoraReview">my work laptop</a>
running CinnamonÙ« scrolling on the touchpad generates smooth scrolling
events with various Y deltas depending on how fast I"m moving my
fingersÙ« while using the scroll wheel on an external mouse generates
both a smooth scrolling event (with a Y delta of -1 or +1 depending
on the direction) and a "scroll up" (or "scroll down") event; these
events have a source device of either the touchpad or the USB mouseÙ«
although <code>xinput</code> says that there is an overall "Core Pointer"
device.</p>

<p>As far as I can tellÙ« <code>xinput</code> and the X servers are reporting that
the mice involved are set up the same way; the physical mouse (and
the touchpad) are extended input devices handled by XINPUT. But
something about my fvwm environment or how I start X on my desktop
is causing these GTK smooth scroll events to not be generatedÙ« to
the confusion of at least some programs (and there will probably
be more in the future). Unfortunately I have no ideas about what
it might be or how to track it down.</p>

<p>(After some further testingÙ« I can say that OpenBox on my laptop
and Cinnamon inside a VMWare virtual machine both cause GTK to
generate smooth scroll events. The VMWare virtual machine is using
my desktop"s mouseÙ« but the xinput mouse configuration is different
because of VMWware stuff.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/unix/XInputOldAndNew', 'Input events on X have an old world and a new world', '1592277422000',  14, '<div class="wikitext"><p>The <a href="https://en.wikipedia.org/wiki/X_Window_System_protocols_and_architecture">X Window System</a>
is now very oldÙ« and it never had what you could call "protocol
agility" in the core X protocol. As a resultÙ« over the years X has
been extended through both conventions (such as <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/XFontTypes">modern X fonts</a>) and X server extensions. In theory both forms of
extension are optional and servers and clients may not support any
specific one; in practiceÙ« various common things are now mandatory
for any X server or client that wants to work right in the modern
world.</p>

<p>(For instanceÙ« X servers increasingly don"t have many old style X
fonts available for you to use and they"re often not very good
looking.)</p>

<p>As part of X"s evolution over timeÙ« input event handling has gone
through a practical changeÙ« although one that is what you could
call unevenly distributed. The original X protocol has input eventsÙ«
of courseÙ« which are sometimes now called <a href="https://en.wikipedia.org/wiki/X_Window_System_protocols_and_architecture#Events">core input events</a>.
You can see what core events are generated from various activities
through the venerable <a href="https://linux.die.net/man/1/xev"><code>xev</code></a>
programÙ« and many straightforward X programs continue to interact
only with core events.</p>

<p>HoweverÙ« core input events have limitations that date from X"s
origins.  Core input events are only really designed to deal with
straightforward keyboards and mice with buttons. Even mouse scroll
wheels have an awkward representation in core X events; moving the
scroll wheel actually generates mouse button events for pressing
and releasing button 4 or 5 (for normalÙ« implicitly vertical scroll
wheels). I don"t think there"s anything in the X protocol that
reserves these buttons for scroll wheelsÙ« it"s just a convention
that people came up with when they started needing to handle scroll
wheels in X.</p>

<p>I suspect that what pushed people over the edge on X input handling
was laptop touchpads and trackpads. You can pretend that a touchpad is
a mouse and manufacture appropriate X events from finger touches and
pressesÙ« but this isn"t really a good representation of what is actually
going on. More sophisticated programs might want to know all sorts of
additional information that a touchpad can deliverÙ« and then there"s
additional input devices like pens.</p>

<p>The solution to this is <a href="https://www.x.org/releases/X11R7.7/doc/libXi/inputlib.html">the X Input (Device) Extension</a>. This
extension understands that you may have multiple input devices
connectedÙ« not just one (for example you may have both a touchpad
and an external mouse) and it delivers a much richer event stream
to programs that want to use it. It also generates core input events
from this richerÙ« more sophisticated input event stream. You can
more or less see what XIE events are generated when you do things
with "<a href="https://linux.die.net/man/1/xinput"><code>xinput test-xi2</code></a>"Ù«
although you probably need to know more than you do to interpret
<code>xev</code> output.</p>

<p>Programs using a modern toolkit like GTK+ will often attempt to use
XIE (and may in practice require it). On Linux (and perhaps other
Unixes)Ù« one sign of such programs is that they use the <a href="https://gitlab.freedesktop.org/xorg/lib/libxi">libXi</a> shared libraryÙ«
which is the X client library for dealing with the X Input Extension.
A C program that isn"t using this shared library is very unlikely
to be using XIE; a C program that has loaded it very likely is using
XIE in preference to core input eventsÙ« especially if it"s using a
toolkit like GTK+.</p>

<p>One of the important consequences of this split between core input
events and XIE events is that events that look identical at the
core input event level (for exampleÙ« as shown by <code>xev</code>) may be
different at the XIE level (as interpreted by libXi and then toolkit
librariesÙ« and perhaps as shown by <code>xinput</code>). This means that some
programs will treat them exactly the same because they"re
indistinguishable and some programs may react to them differently.
This can cause rather odd issuesÙ« but that"s a story for <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/XInputGtkScrollPuzzle">another
entry</a>.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/XInputOldAndNew?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/ProductAndUtilityCode', 'Product code and utility code', '1592185003000',  14, '<div class="wikitext"><p>Over timeÙ« I"ve noticed that I seem to have a relatively different
experience of programming than many people do (or at least the
people who write articles that show up in my Internet reading). I
think that part of this difference can be attributed to me working
on a different sort of code than most people. To explain thatÙ« let"s
talk about a split (that is really a continuum) between two sorts
of codeÙ« <em>product code</em> and <em>utility code</em>.</p>

<p>Product code is what you use to deliver your business. Sometimes
the product code is your business (either selling the software or
directly providing an online service)Ù« and sometimes it directly
supports your business activities. Product code almost always needs
to keep changing and evolving because what you deliver in your
business inevitably keeps changing and evolving itself. If you try
to freeze product code in the face of a changing businessÙ« eventually
you get a wider and wider gap between what the code does and what
your people need. Your people will bridge this gap as best they
canÙ« through new code that connects to your codeÙ« awkward proceduresÙ«
and eventually bypassing the old code and doing the business with
spreadsheets and so on.</p>

<p>Utility code supports what you doÙ« but it"s not tied to business
requirements (or at least not very tightly; it"s connected in that
you shouldn"t be doing things unless the business needs them for
some reason). This is the code that works quietly in the background
keeping the wheels on and turningÙ« supporting both the environment
that product code exists in and the generally stable internal
processes of the organization. Because it"s not tied very strongly
to the businessÙ« utility code doesn"t necessarily need very many
changes; the further from business operations it is generally the
fewer changes it needs over time. Utility code for stable and well
established internal processes like expense reports or onboarding
new people into some aspects of the organization can be essentially
static.</p>

<p>If you work on product codeÙ« your code is constantly changing anyway
and you don"t necessarily see the appeal of being able to stabilize
it and walk away. Unchanging product code is almost always dead and
abandoned; either it"s out ot step with the business or the part
of the business it"s associated with has been frozen and is probably
dying. If you work on utility codeÙ« you frequently stabilize it and
walk awayÙ« because what it needs to do is often pretty fixed; if
you can"t stabilize the code despite fixed requirementsÙ« something
is wrong and you"re unhappy about it.</p>

<p>(A corollary of this is that you almost always have people who are
familiar with how your product code worksÙ« because there"s generally
someone working on itÙ« but you may not have anyone who remembers how
some bit of utility code works.)</p>

<p>This makes a difference when code needs to change for reasons other
than business requirements changing. Product code is always changing
anywayÙ« so you can often naturally roll in those other changes as
part of your ongoing regular changes. Utility code is often frozenÙ«
so now you have to thaw it outÙ« make changesÙ« stabilize thingsÙ« and
freeze it againÙ« all to stay in the same place as far as organizational
needs and functionality go.</p>

<p>(As you might guess from all of thisÙ« I feel that I mostly work on
utility code. <a href="https://support.cs.toronto.edu/">We</a> don"t really
have any product code we"re responsible forÙ« although it does exist
within <a href="https://www.cs.toronto.edu/">the department</a>.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/ProductAndUtilityCode?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/MailcapDocx2txtTangle', 'An interesting combination of flaws in some <code>/etc/mailcap</code> handling', '1592105488000',  14, '<div class="wikitext"><p>Somewhat recently we ran into an interestingly tangled issue around
<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/UbuntuMailcapBasics"><code>/etc/mailcap</code></a> and MIME handlers on our
Ubuntu 18.04 user login machinesÙ« one of those situations where
there seem to be multiple problems that when combined together lead
to an undesirable result.  What happened is that we installed the
<a href="http://docx2txt.sourceforge.net/">docx2txt</a> Ubuntu package after
it was requested by someoneÙ« but then found that this broke at least
<a href="http://exmh.sourceforge.net/">exmh</a>"s ability to display MS Office
"docx" file attachments. HoweverÙ« the interesting story is why.</p>

<p>As part of its packageÙ« docx2txt includes a <code>/usr/lib/mime/packages</code>
file to describe what it can be used to displayÙ« which then causes
<a href="https://manpages.ubuntu.com/manpages/xenial/man8/update-mime.8.html"><code>update-mime</code></a> to
update the MIME handling information in <code>/etc/mailcap</code>. Because
docx2txt prints what it converts to standard outputÙ« its mailcap
entry has the "<code>copiousoutput</code>" tagÙ« and also appears to set its
priority to 2Ù« which is relatively low (5 is the default). The first
thing that goes wrong is that docx2txt has an uncaught typo in this;
it actually sets "<code>prority</code>" to 2Ù« leaving it at the default priority
of 5.  Also installed on our Ubuntu machines is <a href="https://www.libreoffice.org/">LibreOffice</a>Ù« and LibreOffice Writer also has
<code>/usr/lib/mime/packages</code> file. LibreOffice"s entry for docx files
has priority 3Ù« theoretically higher than docx2txt"s (and a standard
condition to say "I need to be in a GUI session to work")Ù« but
docx2txt"s typo means that docx2txt"s mailcap entry should actually
be preferred over LibreOffice"s.</p>

<p>The second thing that happensÙ« which is at least unclearÙ« is that
<a href="https://manpages.ubuntu.com/manpages/xenial/man8/update-mime.8.html"><code>update-mime</code></a> doesn"t pass the <code>priority</code> field through to
<code>/etc/mailcap</code>. I think update-mime orders the generated <code>/etc/mailcap</code>
from highest priority to lowestÙ« and assumes that programs that use
mailcap will pick the first matching entry. If this is what you"re
supposed to do to handle priorities in mailcap entriesÙ« I couldn"t
find anything that explicitly said it. Since this ordering doesn"t
seem to be explicitly written upÙ« it"s at most folk knowledge and
you have to hope that the mailcap parser used by any particular
program follows this. Update-mime also doesn"t reject docx2txt"s
partially malformed mailcap line; instead it accepts it as an
entry with the default priority (and puts the "prority" field
in the generated <code>/etc/mailcap</code>Ù« where it may mislead you if
you"re reading fast).</p>

<p>The third thing going wrong is that <a href="http://exmh.sourceforge.net/">exmh</a> turns out to have bad
handling of mailcap entries that write their results to standard
outputÙ« so that you can theoretically display it inline. What you
would expect to happen is that <a href="http://exmh.sourceforge.net/">exmh</a> would run the handler (either
automatically or on request) and then display the result inline.
InsteadÙ« it has a little display for that attachment that looks
like you can"t do anything (normally it will say "you can view this
with ..."Ù« so you know the section can be handled)Ù« and if you
actually ask exmh to run the mailcap handler to generate the outputÙ«
it writes the generated output to its standard error (which almost
certainly isn"t connected to anything useful). Given that this is
spectacularly uselessÙ« exmh clearly hasn"t been used very much with
mailcap entries that want to do this instead of running an external
program that will display things on its own.</p>

<p>Exmh"s bad handling of "<code>copiousoutput</code>" mailcap entries wouldn"t
be an issue except for the mangled priority field of docx2txt;
without thatÙ« exmh picks LibreOffice instead (which works fine).
Docx2txt"s bad "prority" field wouldn"t have persisted if update-mime
(or some other tool) checked for and rejected improperly formed
mailcap entries; instead update-mime covered up the problem and
increased docx2txt"s priority over what it had been intended. It
took a cascade of flaws to expose this issue.</p>

<p>(Our solution was to uninstall docx2txt again. It"s not important
enough to break exmh for people using itÙ« and anything else that
may also have problems with such an entry. Now that I understand
the issueÙ« I will see if I have enough energy to file a Debian bug
report against docx2txtÙ« which still has the bug in <a href="https://salsa.debian.org/debian/docx2txt">the current
package source</a>. Of course
it will be years before any bug fix is available in Ubuntu.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/GMailPopTLSVerificationII', 'The safety of GMail"s POP server TLS certificate verification (or lack of it)', '1592018043000',  14, '<div class="wikitext"><p>A while back I wrote an entry on <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/GMailPopTLSVerification">how GMail hadn"t been doing full
TLS server certificate verification when fetching mail from remote
POP servers</a>. GMail may have verified that
the POP server"s TLS certificate was properly signed by a CAÙ« but
<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertVerifyTwoParts">it didn"t check the server nameÙ« which is the second part of
server verification</a>. This is not safe in
general (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSVerifyByIPNotSafe">even if you verify the IP address</a>)Ù«
but Google (and GMail) aren"t everyone and they sit in a very special
position in several ways.</p>

<p>I don"t know if GMail"s lack of verification was truly safeÙ« and
certainly it skips <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertHostVerifyReasons">part of the purpose of verifying the TLS server
hostname</a>Ù« but Google skipping this check
can be safer than it is for almost anyone else. The basic reason
why is that Google is in a position to be very confident that it"s
not talking to an impostorÙ« if it wants to go to the effort. FirstÙ«
Google can check what it sees for DNS lookupsÙ« network routingÙ« and
TLS certificates from multiple vantage points around the Internet.
This means that any tampering and MITM attacks must be globalÙ« not
localÙ« which generally means very close to the final network
connection to the target.</p>

<p>(Of courseÙ« doing this sort of global check can run into issues
with services that give you localized DNS resultsÙ« with anycast
routingÙ« and so on. Nothing is perfect here.)</p>

<p>SecondÙ« Google can keep a history of all of this. If everything is
consistent over time (and your previous connections worked and gave
sensible results)Ù« you can be relatively confident that you"re still
connecting to the same thing. If you accepted the thing beforeÙ« you
can keep accepting it now. We weren"t presenting the same TLS server
key every time (as far as I knowÙ« <a href="https://certbot.eff.org/">Certbot</a>
generates a new keypair every time it renews your TLS certificateÙ«
which is about every 60 days)Ù« but we were presenting a valid TLS
certificate for the same set of TLS names (that were valid DNS names
for our IMAP and POP server).</p>

<p>None of this could make GMail"s lack of full checking completely
safe. But it at least could make it a lot safer than an isolated
program or service trying to do the same thing. Google"s in a
position to have a lot of information that let it "authenticate"
(in some sense) your serverÙ« which is <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertHostVerifyReasons">part of the reasons for
verifying the server name</a>.</p>

<p>(At the same timeÙ« I expect that GMail"s behavior was ultimately
for pragmatic reasons. It seems likely that they found that too
many people had POP servers with TLS certificates that didn"t include
the right name. I can"t throw stones about thisÙ« since we accidentally
did thisÙ« as covered in <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/GMailPopTLSVerification">my first entry</a>.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DualDisplayVsMultiDesktop', 'Dual displays contrasting with virtual screens (aka multiple desktops)', '1591935072000',  14, '<div class="wikitext"><p>At workÙ« I have dual displays on <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/WorkMachine2017">my office desktop</a>Ù« specifically two Dell U2412M monitors
(which are 24" diagonal with 1920 x 1200 resolution). This gives
me a lot of space to work inÙ« and lets me do things like have a
full sized <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">Grafana dashboard</a> on the
left one while carpeting the right one with windows that are
investigating the problems shown on the dashboard. Of courseÙ« given
<a href="https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic">world and local events</a> I"m
not at workÙ« I"m working from home. At home I have <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/4KHiDPIIsVisible">a nice HiDPI
display</a>Ù« but it"s a Dell P2715Q which
means it"s only 27" diagonal (and a 16:9 display compared to the
16:10 of the dual monitors). This is not anywhere near as much space
as two displaysÙ« and <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/DualDisplaysNaturalSplit">the space doesn"t split naturally or as nicely</a>.</p>

<p>One of the things that <a href="http://www.fvwm.org/">my window manager</a>
supports is what is variously called virtual screens or multiple
desktops. I have multiple virtual screens set up on <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/MyDesktopTour">my desktop</a> at work as well as at homeÙ« but at work I"ve generally
not used them very often or for much. Generally I would switch virtual
screens only if I was interrupted in the middle of something and so
needed a whole new set of windows on top of the set that I already
had. OtherwiseÙ« I did everything on my primary virtual screenÙ«
because it had enough room.</p>

<p>This isn"t really the case with working from home. Now I"m routinely
out of what I consider enough spaceÙ« and so my work sprawls across
multiple virtual screens. Sometimes this is different parts of my
work; I might be <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/HomeInternetAcceptableX">running virtual machines</a> on one virtual screen and looking
at a Grafana dashboard on another. This sort of split across virtual
screens is okayÙ« and some people would find it an improvement over
putting everything on the primary screenÙ« although I"m not sure I
do (having everything iconified in one spot is convenient). HoweverÙ«
sometimes my single screen and lack of as much space forces me to
split one thing between two virtual screens. The most common case
is looking at Grafana dashboardsÙ« which really want to be full
screen on my display. A full screen dashboard leaves me no room for
other windows to investigate thingsÙ« so I often wind up flipping
back and forth between a virtual screen with a Grafana dashboard
and a virtual screen where I"m doing something about what the
dashboard is telling me. This isÙ« naturallyÙ« not the best experience;
I can"t see both things at once and I lose some context and flow
as I flip back and forth.</p>

<p>Even with different parts of my workÙ« it"s not infrequently a bit
more annoying to switch virtual screens than to have one set of
things on one display and another set of things on the other. One
area this especially comes up in is reading email as it comes in.
At workÙ« my email client de-iconifies on the left side of my right
display (more or less in the center of where I look)Ù« and I tend
to first use the left display for things like terminal windows and
workÙ« which means that there"s space left for the email client to
open upÙ« for me to write replies to emailÙ« and so on. At homeÙ« the
de-iconified email client is competing for space with all sorts of
other thingsÙ« so if email comes in while I"m working I"ll often
switch to another clean virtual screen to read it. This is more of
an interruption than it is on my work dual display.</p>

<p>At the same timeÙ« the clean virtual screen that I get at home is
in its own way a nicer thing. I can"t deny that there"s clutter and
a bunch of distractions on my primary virtual screen at workÙ« both
passive ones (things I could do) and active ones (things I"m currently
doing). A forced switch to a different virtual screen at home wipes
away all of that and gives me a cleanÙ« low distraction slate (at
least until I start cluttering up the second virtual screen). The
very lack of space that I don"t like pushes me to switch virtual
screens more often and thus to get that newÙ« unclutteredÙ« lower
distraction experience more often.</p>

<p>My current feelings are that virtual screens at home don"t make up
for not having dual displays. I can get my work doneÙ« but it"s not
as nice an experience as it is at workÙ« and not as flowing (for
lack of a better term). I"m cramming too much into too little spaceÙ«
and my virtual screens are mostly a method of trying to get more
space (as opposed toÙ« sayÙ« trying to keep things organized).</p>

<p>(Some people like using virtual screens to separate various things
from each otherÙ« but my current view is that I don"t want to do
that for various reasons beyond the scope of this entry.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DualDisplayVsMultiDesktop?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/tech/DualDisplaysNaturalSplit', 'A dual display setup creates a natural split between things', '1591847091000',  14, '<div class="wikitext"><p>Sometimes you notice things only when you don"t have them. At work
I have a dual display setup on my work desktop (arranged horizontally)Ù«
but I only have a single display at home (mostly for space reasons).
One of the differences I"ve noticed in how I use my screen space
is that <strong>dual displays provide a natural division and split between
things</strong>Ù« because of the literal physical split between the two
displays.</p>

<p>(I"ve been noticing this lately because I"m working from homeÙ« so
for once I"m spending a lot of time doing the same sort of things
at home that I normally do at work.)</p>

<p>This split tends to manifest in two waysÙ« which I can call active
and passive. The active type split is how I often wind up dynamically
using windows as I work on something. On a dual display systemÙ«
it"s natural to open up a full "screen" (really display) view of a
<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">Grafana dashboard</a> on
one display while using the second display to look into the specifics
of what the dashboard is showing meÙ« through terminal windows and
other things. Similarly it feels natural to park documentation on
one screen while actively working on the otherÙ« or use one display
to monitor logs while I"m making a change on the other one. The
passive type split is how I organize iconified or idle windows;
rather than sprawl across both displaysÙ« they tend to wind up
entirely on one or the other.</p>

<p>In theory I could split my display at home in the same way (it"d
take some window manager support to make it convenientÙ« but I use
a very flexible window manager). In practice such a split would
feel artificial. I"d be drawing an arbitrary line down my screen
somewhereÙ« with no particularly good reason for it except that I
wanted it. The split in a dual display setup is anything but
arbitraryÙ« because there"s a clear discontinuity and visual gap
(one created by the bezels of the two displays). You can"t have
something straddle the gap and look normal.</p>

<p>I suspect that I"d still feel this way even if I had a single display
at home that was the size of my dual displays at work. I would probably
start splitting up the layout so that some things consistently went to
the leftÙ« some to the rightÙ« and some in the centerÙ« and I definitely
would have a "maximize to one half (or one third) horizontally" option
in my window manager (because a true full screen window would be far too
big). But I suspect that things would wind up passively sprawled out
all overÙ« instead of grouped into areas. It would just be too tempting
to expand things into some of that empty space with no obvious division
between it and the occupied space.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/DualDisplaysNaturalSplit?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/tech/FediverseDiversityChallenge', 'The practical people problem with instance diversity in the Fediverse', '1591760728000',  14, '<div class="wikitext"><p>Recently I was reading Kev Quirk"s <a href="https://kevq.uk/centralisation-and-mastodon/">Centralisation and Mastodon</a> (<a href="https://lobste.rs/s/d4t4ex/centralisation_mastodon">via</a>)Ù« which
notes how central <a href="https://mastodon.social/">Mastodon.social</a>
and a few other big instances are to the overall FediverseÙ« making
it hardly a decentralized network in practice. The article concludes
with a call to action:</p>

<blockquote><p>If youâ€™re thinking about joining MastodonÙ« donâ€™t just join the
first instance you come across. Take a look at the sign up section of
<a href="https://joinmastodon.org/">the Mastodon homepage</a>. There is a list
[of] alternative instances that you can joinÙ« all arranged by topic.</p>
</blockquote>

<p>I think that more genuine decentralization in the Fediverse isn"t
a bad thingÙ« but I also think that there are practical considerations
pushing against it. To put it one wayÙ« if you"re joining the Fediverse
your choice of instance is a risky decision that you"re mostly not
interested in and are generally not well equipped to make.</p>

<p>Your choice of instance is risky in that if you pick badlyÙ« you"ll
wind up having to go through various sorts of annoyance and pain.
Picking what is clearly a big and popular instance has an intuitive
appeal to reduce those risks; a popular instance is probably not a
bad choice. As far as actively choosing an instance goesÙ« this is
usually not what you"re interested in. Most people are interested
in joining the Fediverse as a wholeÙ« and one of the points of it
being a decentralized network is that it isn"t supposed to matter
where you join. So you might as well take a low risk choice.</p>

<p>FinallyÙ« if you"re trying to actively pick a good instanceÙ« most
people have the twin problems that they don"t know what they care
about (or should care about) in instancesÙ« and even if they do know
they have things they care about they don"t know enough to how to
evaluate instances. OhÙ« you can read an instance"s policies and
poke around a bitÙ« but that may not give you clear and honest
answersÙ« and on top of that a lot of things in the Fediverse are
only clear to people who are immersed in the Fediverse already.  To
put it one wayÙ« there are a lot of problems with instances (and
problem instances) that aren"t obvious and clear to outsiders.</p>

<p>All of this should be unsurprisingÙ« because it"s all a version of
<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SecurityChoiceProblem">the problem of forcing users to make choices in security</a>. People mostly don"t careÙ« and even if they
do care they mostly don"t know enough to make good choices. This is
especially the case if they"re new to the Fediverse.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/FediverseDiversityChallenge?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/SwapOnZramMixedFeelings', 'My mixed feelings about "swap on zram" for Linux', '1591675356000',  14, '<div class="wikitext"><p>Recently I read about how <a href="https://fedoraproject.org/wiki/Changes/SwapOnZRAM">Fedora will be enabling "swap on zram"</a>Ù« including for
upgraded machinesÙ« in a future version of Fedora. I suspect that a
similar change may some day come to Ubuntu as wellÙ« because it"s
an attractive feature from some perspectives. My feelings are a bit
more mixed.</p>

<p><a href="https://en.wikipedia.org/wiki/Zram">Zram</a> is a dynamically sized
compressed block device in RAM (ie a compressed ramdisk); "swap on
zram" is using a zram device as a swap device (or as your sole swap
device). This effectively turns inactive RAM pages into compressed
RAM in an indirect way while pacifying the kernel"s traditional
desire to have some swap space. The pitch for swap on zram is very
nicely summarized on <a href="https://fedoraproject.org/wiki/Changes/SwapOnZRAM">the Fedora page</a> as "swap is
usefulÙ« except when it"s slow". Being in RAMÙ« swap on zram is very
fast; it"s the fastest swap device you can haveÙ« faster than SSD
or even NVMe.</p>

<p>(This implies that how much of an advantage swap on zram is for
your system depends partly on how fast your existing swap storage
is. But RAM is still much faster than even NVMe.)</p>

<p>The drawback of swap on zram is that it is not really freeing up
all of your memory to "swap things out"; instead the estimate is
that it will generally compress to about half the previous size.
This drawback is the source of my mixed feelings about swap on zram
for my Fedora desktops and our Ubuntu servers.</p>

<p>On my Fedora desktopsÙ« I generally barely use any swap spaceÙ« which
means that swap on zram would be harmless. If I do temporarily use
a surge of swap spaceÙ« being able to get the contents back fast
is probably good; Linux has generally had an irritating tendency
to swap out things I wantedÙ« like bits of my window manager"s
processes. Both <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2018">my home machine</a> and <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/WorkMachine2017">my work
machine</a> have 32 GB of RAMÙ« and peak swap usage over
the past 120 days has been under a gigabyteÙ« so I"m barely going to
notice the memory effects. As a result I"m likely to leave swap on
zram in its default enabled state when Fedora gives it to me.</p>

<p>Unfortunately this is not the case for our Ubuntu LTS servers. Those
of our Ubuntu servers that use much swap at all tend to eventually
end up with their swap space full or mostly full of completely idle
data that just sits there. Keeping even a compressed version of
this data in RAM is not what we want; we really want it to be swapped
out of memory entirely. Swap on zram would be a loss of RAM for us
on our Ubuntu servers. As a resultÙ« if and when Ubuntu enables this
by defaultÙ« I expect us to turn it off again.</p>

<p>One way to put this is that swap on zram is faster than conventional
swap but not as useful and effective for clearing RAM. Which of
these is more important is not absolute but depends on your situation.
If you"re actively swappingÙ« then speed matters (fast swap lowers
the chances of <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/SwapSizingII">swapping yourself to death</a>).
If you"re instead pushing out idle or outright dormant memory in
order to make room for more productive uses of that RAMÙ« then
clearing RAM matters most.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/SwapOnZramMixedFeelings?showcomments#comments">5 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoTimeParsingTZIssue', 'A Go time package gotcha with parsing time strings that use named time zones', '1591582568000',  14, '<div class="wikitext"><p>Go has a generally well regarded <a href="https://golang.org/pkg/time/"><code>time</code></a>
package. One of the things it can do is parse a string representation
of a time based on a specification of the time formatÙ« using
<a href="https://golang.org/pkg/time/#Parse"><code>time.Parse()</code></a>; for exampleÙ«
to parse times like "Sat Mar 7 11:06:39 PST 2015" or "SatÙ« 07 Mar
2015 11:06:39 -0800" (which are in Unix date format and "RFC 1123 Z"
format respectively). As usualÙ« <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoTimeHasLocation">these parsed <code>time.Time</code> values have
a location</a>Ù« ie a time zone.  HoweverÙ« if you"re
dealing with time strings with named time zonesÙ« like "PST"Ù« this
parsing has a very large catch.  This catch is sort of spelled out in
the official documentationÙ« but not quite completely clearly:</p>

<blockquote><p>When parsing a time with a zone abbreviation like MSTÙ« if the zone
abbreviation has a defined offset in the current locationÙ« then that
offset is used. The zone abbreviation "UTC" is recognized as UTC
regardless of location. <strong>If the zone abbreviation is unknownÙ« Parse
records the time as being in a fabricated location with the given zone
abbreviation and a zero offset</strong>.</p>
</blockquote>

<p>MST is a widely known zone abbreviationÙ« so you might think that
it will always have "a defined offset in the current location".
This is not so. If your current location doesn"t ever use "MST"
as a zone abbreviationÙ« then it"s not considered "a defined offset"
and you get a time that claims it is in "MST" but that has a 0
offset from UTC. <strong>This is not a correctly parsed time as any
human being would understand it</strong>. Go is making up an offset
in order to not report an error.</p>

<p>What Go means by "a defined offset in the current location" is that
you can use "EST" and "EDT" if you"re in Eastern time. This means that
<strong>Go will parse a time string containing a named time zone differently
depending on your local time zone</strong>. If you parse a string that uses
"MST" as its time zone and you are in Mountain timeÙ« you will get one
<code>time.Time</code> value; if you are in Eastern time (or <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ServerUTCTimeViews">this server is in
UTC time</a>)Ù« you will get a completely
different <code>time.Time</code> value.</p>

<p>(This implies that if you write out a time string using a named
time zoneÙ« change your time zone (either personally or server wide)Ù«
and then parse the time string againÙ« you will get a different
time. One way to change your personal time zone is to move a file
containing time strings from one server to another.)</p>

<p>This also means that it very much matters whether the source of the
time string is using named time zones or numeric time zone offsets.
The choice between "<a href="https://tools.ietf.org/html/rfc1123">RFC 1123</a>"
time format (using named time zones) and "RFC 1123 Z" format (using
numeric values) will give you what is theoretically the same time
that Go will not infrequently parse as very different time zones.
<strong>Only time formats using numeric time zone offsets are safe to use
with Go</strong> (and even then <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoTimeHasLocation">there is a catch when later formatting
them</a>).</p>

<p>My personal opinion is that this is a serious bug in Go"s time
parsing. If a named time zone offset is given and Go cannot safely
determine its actual zone offsetÙ« the parse should fail with an
error. Turning "Sat Mar 7 11:06:39 PST 2015" into March 7 11:06:39
UTC 2015 is not correct behavior; instead it is actively dangerous.
If this means that too many time strings fail to parseÙ« then Go
time parsing needs to get smarter about looking up popular named
time zone offsetsÙ« or it should provide a "parse liberally" function
with the current behavior of <code>time.Parse()</code>.</p>

<p>Another consequence of this behavior is that a <code>time.Time</code> time
zone that is printed as "EST" is not always "EST" (and the same for
any named time offset). Sometimes it is "EST (-0500)" and sometimes
it is "EST (+0000)"Ù« ie "UTC but we are claiming that it is called
EST". In my opinionÙ« Go should also stop doing this. If it is going
to accept "EST" but treat it as UTCÙ« it should actually set the
location to UTC so that people are not fooled by how the same two
timesÙ« apparently equal because they format with the same outputÙ«
are in fact not equal.</p>

<p>(To Go"s creditÙ« the default string format for <code>time.Time</code> valuesÙ« as
shown in <a href="https://golang.org/pkg/fmt/"><code>fmt</code></a>"s <code>%v</code> formatÙ« does show
both the time zone name and the numerical offset. This gives you odd but
honest output like "2015-03-07 11:06:39 +0000 MST". But if you format
with just the named time zoneÙ« you can have two times that format the
same but don"t compare equal.)</p>

<p>(This entire issue was brought to my attention by James Antill"s
comments on <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoTimeHasLocation">my entry about how <code>time.Time</code> values have locations</a>.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoTimeParsingTZIssue?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ChangeSubtleDangerExample', 'Why sysadmins don"t like changing thingsÙ« illustrated', '1591501616000',  14, '<div class="wikitext"><p>System administrators are famously reluctant to change anything
unless they have to; once a system worksÙ« they like to freeze it
that way and not touch it. This is sometimes written off as irrational
over-concernÙ« and to be honest sometimes it is; <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/AvoidingRebootFetish">you can make a
fetish out of anything</a>. HoweverÙ« it isn"t
just superstition and fetish. We can say general things like <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/StabilityViaChangeControl">on
good systemsÙ« you control stability by controlling changes</a> and note that <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/CheckForChangeEffects">harmless changes aren"t
always actually harmless</a>Ù« but surely if you
take appropriate care you can monitor your systems while applying
controlled changesÙ« promptly detect and understand any problemsÙ«
and either fix them or roll back.</p>

<p>WellÙ« let me tell you a story about thatÙ« and about spooky subtle
action at a distance. (A story that I mentioned in passing <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusAlertTimeFormatting">recently</a>.)</p>

<p>We have <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">a Prometheus based monitoring and alerting system</a>Ù« that among other things sends out
alert notificationsÙ« which come from a Prometheus component called
<a href="https://prometheus.io/docs/alerting/alertmanager/">the Alertmanager</a>.
Those alert notifications include the start and end times of the
alerts (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusAlertsWhyTimes">for good reasons</a>)Ù« and <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ServerUTCTimeViews">since
we generally deal in local time</a>Ù« these are in
local time. Or at least they"re supposed to be. Quite recently a
co-worker noticed that these times were wrong; after a short
investigationÙ« it was obvious that they were in UTC. Further
investigation showed that they hadn"t always been in UTC time; ever
since we started with Prometheus in late 2018 they"d been in local
timeÙ« as we expectedÙ« and then early in May they"d changed to UTC.</p>

<p>We have <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ChecklistEvolution">reasonably good records of what we"ve changed on our
systems</a>Ù« so I could go back to what we"d changed
on the day when the alert times switched from local time to UTCÙ«
and I could also look at the current state of the system. What I
expected to find was one of four changes; the system switching
timezones for some reasonÙ« an Ubuntu package update of a time related
packageÙ« an update to <a href="https://prometheus.io/docs/alerting/alertmanager/">Alertmanager</a> itself (with a
change related to this behavior)Ù« or that the systemd service for
Alertmanager was putting it into UTC time. I found none of them.
Instead the cause of the timezone shift in our alert messages was
an update to the Prometheus daemonÙ« and the actual change in
Prometheus was not even in its release notes (I found it only by
searching Git commit logsÙ« which led me to <a href="https://github.com/prometheus/prometheus/commit/7646cbca328278585be15fa615e22f2a50b47d06">here</a>).</p>

<p>Here is an undesirable change in overall system behavior that we
didn"t notice for some time and that was ultimately caused by us
upgrading something that wasn"t obviously related to the issue.
The actual cause of the behavior change was considered so minor
that it didn"t appear in the release notesÙ« so even reading them
(both before and after the upgrade) didn"t give us any sign of
problems.</p>

<p>This shows usÙ« once againÙ« that you can"t notice all changes in
behavior immediatelyÙ« not in practiceÙ« you can"t predict them in
advance from due diligence like reading release notes and trying
things out on test systemsÙ« and they aren"t always from things that
you expect; a change in one place can cause spooky action at a
distance. Our alert time stamps are formatted in Alertmanager when
it generates alertsÙ« but it turned out through a long chain of
actions that a minor detail of how they were created inside Prometheus
made a difference in our setup.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusAlertsWhyTimes', 'Why we put alert start and end times in our Prometheus alert messages', '1591411029000',  14, '<div class="wikitext"><p>As I mentioned in <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusAlertTimeFormatting">Formatting alert start and end times in
Alertmanager messages</a>Ù« we put the
alert start times and if applicable the alert end times in the
(email) alert messages that we send out. Generally these look
like one of these two:</p>

<blockquote><ul><li>for a current alert <br>
(alert started at 15:16:02 EDT 2020-06-05Ù« likely detected ~90s earlier)<p>
</li>
<li>for an alert that has ended <br>
(alert active from 15:16:02 EDT 2020-06-05 to 15:22:02 EDT 2020-06-05)</li>
</ul>
</blockquote>

<p>(The "likely detected .." bit is there because most of our Prometheus
alert rules have a "<code>for:</code>" clauseÙ« so the alert condition becomes
true somewhat before the alert itself starts.)</p>

<p>At the beginning of life with Prometheus and AlertmanagerÙ« it may not be
obvious why this is useful and sometimes even necessary; after allÙ« the
alert message itself already has a time when it was emailedÙ« posted to
your communication channelÙ« or whatever.</p>

<p>The lesser reason we do thisÙ« especially for alert end timesÙ« is
that it"s convenient to have this information in one place when
we"re going back through email. If we have a "this alert is resolved"
emailÙ« we don"t have to search back to see when it started; the
information is right there in the final message. There"s a similar
but smaller convenience with email about the start of single alertsÙ«
since you can just directly read off the start time from the text
of the message without looking back to however your mail client is
displaying the email"s sending time.</p>

<p>The larger reason is how <a href="https://prometheus.io/docs/alerting/alertmanager/">Alertmanager</a> works with
grouped alerts (which is almost all of our alerts). Alertmanager"s
core model is that rather than sending you new alerts or resolved
alerts (or both)Ù« it will send you the entire current state of the
group"s alerts any time that stage changes. What this means is that
if at first alert A is raisedÙ« then somewhat later alert BÙ« then
finally alert CÙ« you will get an email listing "alert A is active"Ù«
then one saying "alert A and B are active"Ù« then a third saying
"alerts AÙ« BÙ« and C are active".</p>

<p>When you get these emailsÙ« you generally want to know what alerts
are new and what alerts are existing older alerts. You"re probably
already looking at the existing alertsÙ« but the new alerts may be
for new extra problems that you also need to look atÙ« and they may
be a sign that things are getting worse. And this is why you want
the alert start timesÙ« because they let you tell which alerts are
more recent (and more likely to be new ones you haven"t seen before)
and which ones are older. It"s not as good as being clearly told
which alerts are new in this messageÙ« but it"s as good as we can
get in the Alertmanager model of the world.</p>

<p>(I don"t know if Alertmanager puts the alerts in these messages
in any particular order. Even if it does so todayÙ« there"s no
documentation about it so it"s not an official feature and may
change in the future. It would be nice if Alertmanager used a
documented and useful orderÙ« or let you sort the alerts based
on start and end times.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusAlertsWhyTimes?showcomments#comments">One comment</a>.) </div>'),('https://kieranhealy.org/blog/archives/2020/08/25/some-data-packages/', 'Some Data Packages', '1598360503000',  15, '<p>If you&rsquo;re teaching statisticsÙ« data analysisÙ« or data visualization with R this semesterÙ« especially in the social sciencesÙ« I&rsquo;ve pulled together various bits of data into packages that I use in my own teaching. You might find them useful once you&rsquo;re sick of Gapminder. They cover a variety of topics and range from single tables of data to whole longitudinal and panel surveys.</p>
<p class = "clearfix"><a href="http://kjhealy.github.io/uscenpops"><img src = "/files/misc/hex-cavax.png" width = "140" align = "left"></a> The <a href="http://kjhealy.github.io/cavax">cavax package</a> contains a school-level table of rates of Personal Belief Exemptions (PBEs) in California kindergartens for the 2014-15 school year. At that time (the rules have since changed)Ù« a PBE allowed a child to enter kindergarten without having received the usual complement of vaccinations. Information on the school"s nameÙ« districtÙ« cityÙ« countyÙ« and type is includedÙ« along with the size of the kindergarten class.</p>
<p class = "clearfix"><a href="http://kjhealy.github.io/ukelection2019"><img src = "/files/misc/hex-uk2019.png" width = "140" align = "left"></a> The <a href="http://kjhealy.github.io/ukelection2019">ukelection2019 package</a> contains candidate-level vote data by constituency on the UK general election of 2019Ù« scraped from the BBC"s election website.</p>
<p class = "clearfix"><a href="http://kjhealy.github.io/uscenpops"><img src = "/files/misc/hex-uscenpops.png" width = "140" align = "left"></a> The <a href="http://kjhealy.github.io/uscenpops">uscenpops package</a> contains a table of birth counts for the United States by year-of-age and sex for every year from 1900 to 2018.</p>
<p class = "clearfix"><a href="http://kjhealy.github.io/nycdogs"><img src = "/files/misc/hex-nycdogs.png" width = "140" align = "left"></a> The <a href="http://kjhealy.github.io/nycdogs">nycdogs package</a> is a fun dataset (actually three separate tibbles: licensesÙ« bitesÙ« and zip codes) taken from New York City"s Open Data initiativeÙ« cleaned up and packaged for R. It"s useful for teaching <a href ="http://dplyr.tidyverse.org">dplyr</a>Ù« for drawing mapsÙ« and for seeing where dogs with particular names live. </p>
<p class = "clearfix"><a href="http://kjhealy.github.io/covdata"><img src = "/files/misc/hex-covdata.png" width = "140" align = "left"></a> The <a href="http://kjhealy.github.io/covdata">covdata package</a> contains data on reported cases of and deaths from COVID-19 from from a variety of sources. Amongst other thingsÙ« the package provides (1) National-level case and mortality data from the ECDCÙ« U.S. state-level case and morality data from the CDC and the New York TimesÙ« patient-level data from the CDC"s public use dataset. (2) All-cause mortality and excess mortality data from the Human Mortality Database. (3) Mobility and activity data from Apple and Google. (4) Policy data from the <a href = "https://coronanet-project.org">CoronaNet Project</a>.
<p class = "clearfix"><a href="http://kjhealy.github.io/gssr"><img src = "/files/misc/hex-gssr.png" width = "140" align = "left"></a> The <a href="http://kjhealy.github.io/gssr">gssr package</a> provides the complete General Social Survey cumulative data file (1972-2018) and Three Wave Panel data files in an R-friendly formatÙ« together with their codebooks. </p>
<p class = "clearfix"><a href="http://kjhealy.github.io/socviz"><img src = "/files/misc/hex-socviz.png" width = "140" align = "left"></a> All of these packages work well with  the <a href="http://kjhealy.github.io/socviz">socviz package</a> which supports my <a href="https://www.amazon.com/Data-Visualization-Introduction-Kieran-Healy/dp/0691181624"><em>Data Visualization</em></a> book with a collection of datasets and utility functions to help you draw good graphs in R and ggplot. </p>
'),('https://kieranhealy.org/blog/archives/2020/06/03/the-politics-of-disorder/', 'The Politics of Disorder', '1591182337000',  15, '<p>The wave of protest and unrest in the wake of George Floyd&rsquo;s killing by the police shows little sign of abating just yet. Unrest nationwide isÙ« if anythingÙ« increasing as protesters are met with repression by the police. Civil unrest of this scope is unusual. The conjunction of mass protest and widespread disorder should be worrying to those in authority.</p>
<p>When property damage and theft happens as a side-effect of real mass protestÙ« authorities in a democracy cannot batonÙ« tear gasÙ« or shoot their way to legitimacy. People want social orderÙ« but this isn&rsquo;t like quelling a riot after a sports game. The key issueâ€”as the Governor of Minnesota put it the other dayâ€”is that &ldquo;there are more of them than us&rdquo;. All the tactical gear in the world isn&rsquo;t worth a damnÙ« ultimatelyÙ« if enough of the population ends up in open revolt against civil authority. There are just too many people.</p>
<p>Thatâ€™s one reason the Army are on the scene already in DC. If the mobilization is large enough and itâ€™s met with police repression and brutalityâ€”rather than some more accommodating strategyâ€”then it will only take a few days before things seem to spin right out of control. The desire to present a &ldquo;show of force&rdquo; to protesters is understandable. It can be strategically sensibleÙ« tooÙ« insofar as it is aimed both at dealing with those in the streets and at securing the support of an approving audience who just want things to calm down. This calculus can change rapidlyÙ« howeverÙ« as larger and larger numbers of people become directly and indirectly supportive of the protests.</p>
<p>Those actually running citiesÙ« and city police forcesÙ« are usually aware of this. Practical experience and decades of research makes it clear what&rsquo;s at stake when &ldquo;ordinary criminal behavior&rdquo; is happening in the context of mass protest rather than as mere disorderly conduct. This is one of the reasons that authorities tend to blame â€œoutside agitatorsâ€ or â€œthe mediaâ€ or â€œprotesters from out of stateâ€ as being the real cause of unrest. Protest organizers will do this tooÙ« often enoughÙ« blaming disorder on fringe groups or provocateurs who have illegitimately attached themselves to an otherwise peaceful protest. But if the bulk of a city&rsquo;s population really is directly engaged in mass protest or indirectly supportive of itÙ« and these protests are met with force by the authoritiesÙ« then violent disorder will start to look less like pockets of disruption disapproved of by all and more like the loss of legitimacy.</p>
<p>In the United StatesÙ« these pressures are exacerbated by racial stratification. The deep-seated racism of almost all aspects of U.S. lifeÙ« and the residential racial segregation of many citiesÙ« makes it easier to mobilize the support of whites for the use of force in the name of social order. Even hereÙ« crises have been accommodated by efforts to redirect unrest towards an ordinary political process. The demand for social order without repressionÙ« after allÙ« is not restricted to whites.</p>
<p>President Trump has no interest in routine politics. His instincts are authoritarianÙ« his interest in the mechanics of governance is nilÙ« and his attention span is minimal. He has been happy to cultivate the political support of the police and to egg on its paramilitary elements. Trump&rsquo;s temperament intersects badly with long-term trends. The increasingly paramilitary culture (and equipment) of U.S. police forces has been noted by observers over the past twenty five years. The police were already aware thatÙ« thanks to astonishingly strong union contractsÙ« weak internal oversightÙ« and the doctrine of qualified immunityÙ« individual officers would face no or minimal consequences for the use of excessive forceÙ« up to and including force that resulted in someone&rsquo;s death.</p>
<p>Trump&rsquo;s personal attitudes merely catalyzed what was already there. But it did so on both sides. Trump started out as a very unpopular leader and the scale of the economic crisis accompanying the COVID-19 pandemic has made everything much worse. StructurallyÙ« lockdown has put millions of people out of work. ContingentlyÙ« the relatively small but highly visible wave of reopening protests threw the current unrest into sharp relief. In the former caseÙ« white protesters were allowed to vent their anger directly in the faces of police in ordinary uniform. Masked men with armalite rifles were permitted to walk onto the floor of state legislatures in the name of liberty. Such things are of course simply inconceivable in the context of black-led protest.</p>
<p>Thus were created the conditions for the fusion of mass protest and violent unrest. In the absence of mass mobilization for protestÙ« imposing &ldquo;Law and Order&rdquo; by force is usually a politically successful tacticÙ« at least in the short-run. The demand for order is the most basic demand of political life. But attempting to impose order by force when people are protesting in the streets en masse is much riskierÙ« both for the leader wanting to &ldquo;dominate&rdquo; and for political institutions generally. A competent democratic leader may effectively de-escalate conflict and return it to the sphere of ordinary political struggle. AlternativelyÙ« a competent authoritarian may secure control of the police and military and get the backing of enough people to leave democracy behind. What you generally canâ€™t do in a democracyÙ« thoughÙ« is â€œcrushâ€ or â€œdominateâ€ real mass dissent purely by force without also causing political institutions to come crashing down around your head.</p>
'),('https://kieranhealy.org/blog/archives/2020/05/23/get-apples-mobility-data/', 'Get Apple"s Mobility Data', '1590253874000',  15, '<p>I&rsquo;ve been maintaining <a href="https://kjhealy.github.io/covdata/">covdata</a>Ù« an R package with a variety of COVID-related datasets in it. That means I&rsquo;ve been pulling down updated files from various sources every couple of days. Most of these files are at static locations. While their internal structure may change occasionallyÙ« and maybe they&rsquo;ve moved once or twice at most since I started looking at themÙ« they&rsquo;re generally at a stable location. <a href="https://www.apple.com/covid19/mobility">Apple&rsquo;s Mobility Data</a> is an exception. The URL for the CSV file changes dailyÙ« and not just by incrementing the date or something like that. Instead the file path is a function of whatever version the web CMS is onÙ« and its versioning moves around. WorseÙ« the webpage is dynamically generated in Javascript when it&rsquo;s requestedÙ« which means we can&rsquo;t easily scrape it and just look for the URL embedded in the &ldquo;Download the Data&rdquo; button.</p>
<p>I resigned myself to doing the update manually for a bitÙ« and then I got stuck in the weeds of using a headless browser from within R that could execute the Javascript and thus find the URL. But this was a huge pain. When I lamented my situation on TwitterÙ« David Cabo pointed out to me that there&rsquo;s an <code>index.json</code> file that&rsquo;s stably-located and contains the information I needed to generate the URL of the day. Here&rsquo;s how to do just thatÙ« and then pull in the data to a tibble.</p>
<p>The <code>index.json</code> file is just a string of metadata. It looks like this:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-json" data-lang="json">

<span class="p">{</span><span class="nt">&#34;basePath&#34;</span><span class="p">:</span><span class="s2">&#34;/covid19-mobility-data/2008HotfixDev38/v3&#34;</span><span class="p">Ù«</span>
 <span class="nt">&#34;mobilityDataVersion&#34;</span><span class="p">:</span><span class="s2">&#34;2008HotfixDev38:2020-05-21&#34;</span><span class="p">Ù«</span>
 <span class="nt">&#34;regions&#34;</span><span class="p">:{</span><span class="nt">&#34;en-us&#34;</span><span class="p">:{</span><span class="nt">&#34;jsonPath&#34;</span><span class="p">:</span><span class="s2">&#34;/en-us/applemobilitytrends.json&#34;</span><span class="p">Ù«</span>
                     <span class="nt">&#34;localeNamesPath&#34;</span><span class="p">:</span><span class="s2">&#34;/en-us/locale-names.json&#34;</span><span class="p">Ù«</span>
                     <span class="nt">&#34;csvPath&#34;</span><span class="p">:</span><span class="s2">&#34;/en-us/applemobilitytrends-2020-05-21.csv&#34;</span><span class="p">Ù«</span>
                     <span class="nt">&#34;initialPath&#34;</span><span class="p">:</span><span class="s2">&#34;/en-us/initial-data.json&#34;</span><span class="p">Ù«</span>
                     <span class="nt">&#34;shards&#34;</span><span class="p">:{</span><span class="nt">&#34;defaults&#34;</span><span class="p">:</span><span class="s2">&#34;/en-us/shards/defaults.json&#34;</span><span class="p">}}}}</span>

</code></pre></td></tr></table>
</div>
</div>

<p>SoÙ« we grab this file (whose URL we know) and extract the information we want about the <code>basePath</code> and <code>csvPath</code> that point to the data:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">get_apple_target</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">cdn_url</span> <span class="o">=</span> <span class="s">&#34;https://covid19-static.cdn-apple.com&#34;</span><span class="p">Ù«</span>
                             <span class="n">json_file</span> <span class="o">=</span> <span class="s">&#34;covid19-mobility-data/current/v3/index.json&#34;</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">tf</span> <span class="o">&lt;-</span> <span class="nf">tempfile</span><span class="p">(</span><span class="n">fileext</span> <span class="o">=</span> <span class="s">&#34;.json&#34;</span><span class="p">)</span>
  <span class="n">curl</span><span class="o">::</span><span class="nf">curl_download</span><span class="p">(</span><span class="nf">paste0</span><span class="p">(</span><span class="n">cdn_url</span><span class="p">Ù«</span> <span class="s">&#34;/&#34;</span><span class="p">Ù«</span> <span class="n">json_file</span><span class="p">)Ù«</span> <span class="n">tf</span><span class="p">)</span>
  <span class="n">json_data</span> <span class="o">&lt;-</span> <span class="n">jsonlite</span><span class="o">::</span><span class="nf">fromJSON</span><span class="p">(</span><span class="n">tf</span><span class="p">)</span>
  <span class="nf">paste0</span><span class="p">(</span><span class="n">cdn_url</span><span class="p">Ù«</span> <span class="n">json_data</span><span class="o">$</span><span class="n">basePath</span><span class="p">Ù«</span> <span class="n">json_data</span><span class="o">$</span><span class="n">regions</span><span class="o">$</span><span class="n">`en-us`</span><span class="o">$</span><span class="n">csvPath</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1">## &gt; get_apple_target()</span>
<span class="c1">## [1] &#34;https://covid19-static.cdn-apple.com/covid19-mobility-data/2008HotfixDev38/v3/en-us/applemobilitytrends-2020-05-21.csv&#34;</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Then we can grab the data itselfÙ« with this function:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">get_apple_data</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">url</span> <span class="o">=</span> <span class="nf">get_apple_target</span><span class="p">()Ù«</span>
                             <span class="n">fname</span> <span class="o">=</span> <span class="s">&#34;applemobilitytrends-&#34;</span><span class="p">Ù«</span>
                             <span class="n">date</span> <span class="o">=</span> <span class="n">stringr</span><span class="o">::</span><span class="nf">str_extract</span><span class="p">(</span><span class="nf">get_apple_target</span><span class="p">()Ù«</span> <span class="s">&#34;\\d{4}-\\d{2}-\\d{2}&#34;</span><span class="p">)Ù«</span>
                             <span class="n">ext</span> <span class="o">=</span> <span class="s">&#34;csv&#34;</span><span class="p">Ù«</span>
                             <span class="n">dest</span> <span class="o">=</span> <span class="s">&#34;data-raw/data&#34;</span><span class="p">Ù«</span>
                             <span class="n">save_file</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;n&#34;</span><span class="p">Ù«</span> <span class="s">&#34;y&#34;</span><span class="p">))</span> <span class="p">{</span>

  <span class="n">save_file</span> <span class="o">&lt;-</span> <span class="nf">match.arg</span><span class="p">(</span><span class="n">save_file</span><span class="p">)</span>
  <span class="nf">message</span><span class="p">(</span><span class="s">&#34;target: &#34;</span><span class="p">Ù«</span> <span class="n">url</span><span class="p">)</span>

  <span class="n">destination</span> <span class="o">&lt;-</span> <span class="n">fs</span><span class="o">::</span><span class="nf">path</span><span class="p">(</span><span class="n">here</span><span class="o">::</span><span class="nf">here</span><span class="p">(</span><span class="s">&#34;data-raw/data&#34;</span><span class="p">)Ù«</span>
                          <span class="nf">paste0</span><span class="p">(</span><span class="s">&#34;apple_mobility&#34;</span><span class="p">Ù«</span> <span class="s">&#34;_daily_&#34;</span><span class="p">Ù«</span> <span class="n">date</span><span class="p">)Ù«</span> <span class="n">ext</span> <span class="o">=</span> <span class="n">ext</span><span class="p">)</span>

  <span class="n">tf</span> <span class="o">&lt;-</span> <span class="nf">tempfile</span><span class="p">(</span><span class="n">fileext</span> <span class="o">=</span> <span class="n">ext</span><span class="p">)</span>
  <span class="n">curl</span><span class="o">::</span><span class="nf">curl_download</span><span class="p">(</span><span class="n">url</span><span class="p">Ù«</span> <span class="n">tf</span><span class="p">)</span>

  <span class="c1">## We don&#39;t save the file by default</span>
  <span class="nf">switch</span><span class="p">(</span><span class="n">save_file</span><span class="p">Ù«</span>
         <span class="n">y</span> <span class="o">=</span> <span class="n">fs</span><span class="o">::</span><span class="nf">file_copy</span><span class="p">(</span><span class="n">tf</span><span class="p">Ù«</span> <span class="n">destination</span><span class="p">)Ù«</span>
         <span class="n">n</span> <span class="o">=</span> <span class="kc">NULL</span><span class="p">)</span>

  <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">(</span><span class="n">readr</span><span class="o">::</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">tf</span><span class="p">))</span>
<span class="p">}</span>

</code></pre></td></tr></table>
</div>
</div>

<p>This will pull the data into a tibbleÙ« which you can then clean further (e.g.Ù« put into long format) as desired.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">apple</span> <span class="o">&lt;-</span> <span class="nf">get_apple_data</span><span class="p">()</span>

<span class="c1">## target: https://covid19-static.cdn-apple.com/covid19-mobility-data/2008HotfixDev38/v3/en-us/applemobilitytrends-2020-05-21.csv</span>
<span class="c1">## Parsed with column specification:</span>
<span class="c1">## cols(</span>
<span class="c1">##   .default = col_double()Ù«</span>
<span class="c1">##   geo_type = col_character()Ù«</span>
<span class="c1">##   region = col_character()Ù«</span>
<span class="c1">##   transportation_type = col_character()Ù«</span>
<span class="c1">##   alternative_name = col_character()Ù«</span>
<span class="c1">##   `sub-region` = col_character()Ù«</span>
<span class="c1">##   country = col_character()Ù«</span>
<span class="c1">##   `2020-05-11` = col_logical()Ù«</span>
<span class="c1">##   `2020-05-12` = col_logical()</span>
<span class="c1">## )</span>
<span class="c1">## See spec(...) for full column specifications.</span>

<span class="n">apple</span>

<span class="c1">### A tibble: 3Ù«625 x 136</span>
<span class="c1">##   geo_type region transportation_â€¦ alternative_name sub_region country x2020_01_13 x2020_01_14 x2020_01_15</span>
<span class="c1">##   &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;            &lt;chr&gt;            &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;</span>
<span class="c1">## 1 countryâ€¦ Albanâ€¦ driving          NA               NA         NA              100        95.3       101. </span>
<span class="c1">## 2 countryâ€¦ Albanâ€¦ walking          NA               NA         NA              100       101.         98.9</span>
<span class="c1">## 3 countryâ€¦ Argenâ€¦ driving          NA               NA         NA              100        97.1       102. </span>
<span class="c1">## 4 countryâ€¦ Argenâ€¦ walking          NA               NA         NA              100        95.1       101. </span>
<span class="c1">## 5 countryâ€¦ Austrâ€¦ driving          AU               NA         NA              100       103.        104. </span>
<span class="c1">## 6 countryâ€¦ Austrâ€¦ transit          AU               NA         NA              100       102.        101. </span>
<span class="c1">## 7 countryâ€¦ Austrâ€¦ walking          AU               NA         NA              100       101.        102. </span>
<span class="c1">## 8 countryâ€¦ Austrâ€¦ driving          Ã–sterreich       NA         NA              100       101.        104. </span>
<span class="c1">## 9 countryâ€¦ Austrâ€¦ walking          Ã–sterreich       NA         NA              100       102.        106. </span>
<span class="c1">##10 countryâ€¦ Belgiâ€¦ driving          BelgiÃ«|Belgique  NA         NA              100       101.        107. </span>
<span class="c1">### â€¦ with 3Ù«615 more rowsÙ« and 127 more variables: x2020_01_16 &lt;dbl&gt;Ù« x2020_01_17 &lt;dbl&gt;Ù« x2020_01_18 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_01_19 &lt;dbl&gt;Ù« x2020_01_20 &lt;dbl&gt;Ù« x2020_01_21 &lt;dbl&gt;Ù« x2020_01_22 &lt;dbl&gt;Ù« x2020_01_23 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_01_24 &lt;dbl&gt;Ù« x2020_01_25 &lt;dbl&gt;Ù« x2020_01_26 &lt;dbl&gt;Ù« x2020_01_27 &lt;dbl&gt;Ù« x2020_01_28 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_01_29 &lt;dbl&gt;Ù« x2020_01_30 &lt;dbl&gt;Ù« x2020_01_31 &lt;dbl&gt;Ù« x2020_02_01 &lt;dbl&gt;Ù« x2020_02_02 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_02_03 &lt;dbl&gt;Ù« x2020_02_04 &lt;dbl&gt;Ù« x2020_02_05 &lt;dbl&gt;Ù« x2020_02_06 &lt;dbl&gt;Ù« x2020_02_07 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_02_08 &lt;dbl&gt;Ù« x2020_02_09 &lt;dbl&gt;Ù« x2020_02_10 &lt;dbl&gt;Ù« x2020_02_11 &lt;dbl&gt;Ù« x2020_02_12 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_02_13 &lt;dbl&gt;Ù« x2020_02_14 &lt;dbl&gt;Ù« x2020_02_15 &lt;dbl&gt;Ù« x2020_02_16 &lt;dbl&gt;Ù« x2020_02_17 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_02_18 &lt;dbl&gt;Ù« x2020_02_19 &lt;dbl&gt;Ù« x2020_02_20 &lt;dbl&gt;Ù« x2020_02_21 &lt;dbl&gt;Ù« x2020_02_22 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_02_23 &lt;dbl&gt;Ù« x2020_02_24 &lt;dbl&gt;Ù« x2020_02_25 &lt;dbl&gt;Ù« x2020_02_26 &lt;dbl&gt;Ù« x2020_02_27 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_02_28 &lt;dbl&gt;Ù« x2020_02_29 &lt;dbl&gt;Ù« x2020_03_01 &lt;dbl&gt;Ù« x2020_03_02 &lt;dbl&gt;Ù« x2020_03_03 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_03_04 &lt;dbl&gt;Ù« x2020_03_05 &lt;dbl&gt;Ù« x2020_03_06 &lt;dbl&gt;Ù« x2020_03_07 &lt;dbl&gt;Ù« x2020_03_08 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_03_09 &lt;dbl&gt;Ù« x2020_03_10 &lt;dbl&gt;Ù« x2020_03_11 &lt;dbl&gt;Ù« x2020_03_12 &lt;dbl&gt;Ù« x2020_03_13 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_03_14 &lt;dbl&gt;Ù« x2020_03_15 &lt;dbl&gt;Ù« x2020_03_16 &lt;dbl&gt;Ù« x2020_03_17 &lt;dbl&gt;Ù« x2020_03_18 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_03_19 &lt;dbl&gt;Ù« x2020_03_20 &lt;dbl&gt;Ù« x2020_03_21 &lt;dbl&gt;Ù« x2020_03_22 &lt;dbl&gt;Ù« x2020_03_23 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_03_24 &lt;dbl&gt;Ù« x2020_03_25 &lt;dbl&gt;Ù« x2020_03_26 &lt;dbl&gt;Ù« x2020_03_27 &lt;dbl&gt;Ù« x2020_03_28 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_03_29 &lt;dbl&gt;Ù« x2020_03_30 &lt;dbl&gt;Ù« x2020_03_31 &lt;dbl&gt;Ù« x2020_04_01 &lt;dbl&gt;Ù« x2020_04_02 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_04_03 &lt;dbl&gt;Ù« x2020_04_04 &lt;dbl&gt;Ù« x2020_04_05 &lt;dbl&gt;Ù« x2020_04_06 &lt;dbl&gt;Ù« x2020_04_07 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_04_08 &lt;dbl&gt;Ù« x2020_04_09 &lt;dbl&gt;Ù« x2020_04_10 &lt;dbl&gt;Ù« x2020_04_11 &lt;dbl&gt;Ù« x2020_04_12 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_04_13 &lt;dbl&gt;Ù« x2020_04_14 &lt;dbl&gt;Ù« x2020_04_15 &lt;dbl&gt;Ù« x2020_04_16 &lt;dbl&gt;Ù« x2020_04_17 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_04_18 &lt;dbl&gt;Ù« x2020_04_19 &lt;dbl&gt;Ù« x2020_04_20 &lt;dbl&gt;Ù« x2020_04_21 &lt;dbl&gt;Ù« x2020_04_22 &lt;dbl&gt;Ù«</span>
<span class="c1">###   x2020_04_23 &lt;dbl&gt;Ù« x2020_04_24 &lt;dbl&gt;Ù« â€¦</span>
<span class="c1">##</span>
</code></pre></td></tr></table>
</div>
</div>

'),('https://kieranhealy.org/blog/archives/2020/05/21/the-kitchen-counter-observatory/', 'The Kitchen Counter Observatory', '1590096352000',  15, '<p>Every day begins in the same way. I get up. I make my coffee. I look at the data. Everything about this is absurd. To begin withÙ« thereâ€™s the absurdity that everyone with a job like mine faces each day. Locked down at home with the kidsÙ« trying to get things doneÙ« unable to properly teachÙ« writeÙ« or think. The household is like a little spacecraftÙ« drifting in the void. Occasionally you venture outside to get suppliesÙ« or to check the shields. I find the days are speeding up nowÙ« because even though things drag from moment to momentÙ« each twenty-four hour period is essentially identical. It reminds me of when my children were newborns. Itâ€™s a daily slog thatÙ« in retrospectÙ« fuses into a gray blob almost impossible to recall in any sort of differentiated way.</p>
<p>Far betterÙ« of courseÙ« to have a mild case of lockdown <em>ennui</em> than to be in the situation of those directly fighting the pandemicÙ« those whose health or livelihood has been devastated by itÙ« or those who carry on out in the worldÙ« working to fulfil essential roles. I see some of them individuallyÙ« at my door or in my social media. I see them in the aggregate in the data. Thereâ€™s <em>so much</em> data. People working at international agenciesÙ« universitiesÙ« newspapersÙ« magazinesÙ« and state and local governments put out more each dayÙ« trying to capture the scale and scope of the pandemic. And itâ€™s not just official agencies and businessesÙ« either. One of the best sources of daily information on the pandemic in the United States is being run by a rapidly-assembled team of freelance journalists and volunteers. The <a href="https://covidtracking.com">COVID Tracking Project</a> was brought into existence by the realization that the Centers for Disease Control were failing to provide the sort of daily updates on case counts and deaths that was part of their reason for existing.</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/us-cities-kitchen-counter.png"
         alt="City Driving Data from Apple"/> <figcaption>
            <p>Driving activity over the past three months.</p>
        </figcaption>
</figure>
<p>With a laptopÙ« some free softwareÙ« and a cup of coffeeÙ« I can examine what <em>ought</em> to seem like a staggering amount of information. HereÙ« for exampleÙ« is a picture showing what driving patterns have looked like every day in one hundred American cities over the past four months. As if that were a reasonable thing to be able to know while confined to your house! I drew it using information that Apple has been releasing to help researchers quantify the scope of the lockdown around the world. At this pointÙ« the full dataset has about half a million observations in it. Google is putting out a similar resourceÙ« about four times as largeÙ« that lets you see how busy different kinds of places are around the world over the same time period. This sort of thing doesnâ€™t count as â€œbig dataâ€ anymore. Back when I was a graduate studentÙ« I spent three days in a library manually copying down a few hundred numbers from a long-shelved report about blood donors. Now I sit here at homeÙ« surveying the scope of whatâ€™s being inflicted on people across the country and around the world as this disease spreads.</p>
<p>People sometimes think (or complain) that working with quantitative data like this inures you to the reality of the human lives that lie behind the numbers. Numbers and measures are crude; they pick up the wrong things; they strip out the meaning of whatâ€™s happening to real people; they make it easy to ignore what canâ€™t be counted. Thereâ€™s something to those complaints. But itâ€™s mostly a lazy critique. In practiceÙ« I find that far from distancing you from questions of meaningÙ« quantitative data forces you to confront them. The numbers draw you in. Working with data like this is an unending exercise in humilityÙ« a constant compulsion to think through what you can and cannot seeÙ« and a standing invitation to understand what the measures really captureâ€”what they meanÙ« and for whom. Those regular spikes in the driving data are the pulse of everyday life as people go out to have a good time at the weekend. That peak there is the Mardi Gras parade in New Orleans. That bump in Detroit was a Garth Brooks concert. Right across the countryÙ« that is the sudden shock of the shutdown the second weekend in March. It was a huge collective effort to buy time thatÙ« as it turns outÙ« the federal government has more or less entirely wasted. And now through May here comes the gradual return to something like the baseline level of activity from JanuaryÙ« proceeding much more quickly in some cities than in others.</p>
<p>I sit at my kitchen-counter observatory and look at the numbers. Before my coffee is readyÙ« I can quickly pull down a few million rows of data courtesy of a national computer network originally designed by the government to be disaggregated and robustÙ« because they were convinced that was what it would take for communication to survive a nuclear war. I can process it using software originally written by academics in their spare timeÙ« because they were convinced that sophisticated tools should be available to everyone for free. Through this observatory I can look out without even looking upÙ« surveying the scale and scope of the countryâ€™s ongoingÙ« hugeÙ« avoidable failure. Everything about this is absurd.</p>
'),('https://kieranhealy.org/blog/archives/2020/05/09/covid-concept-generator/', 'Covid Concept Generator', '1589029416000',  15, '<p>To save everyone some timeÙ« here&rsquo;s a generator for the next five years of conceptual advances in social theory. Choose once at random from each column to secure your contribution.</p>
<table>
<thead>
<tr>
<th>Column 1</th>
<th>Column 2</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sequenced</td>
<td>Stratification</td>
</tr>
<tr>
<td>Algorithmic</td>
<td>Differences</td>
</tr>
<tr>
<td>Automated</td>
<td>Capital</td>
</tr>
<tr>
<td>Robust</td>
<td>Contagion</td>
</tr>
<tr>
<td>COVID</td>
<td>Masking</td>
</tr>
<tr>
<td>Epidemiologic</td>
<td>Others</td>
</tr>
<tr>
<td>Viral</td>
<td>Politics</td>
</tr>
<tr>
<td>Rhizomatic</td>
<td>Inequality</td>
</tr>
<tr>
<td>Infectious</td>
<td>Sexualities</td>
</tr>
<tr>
<td>Compartmentalized</td>
<td>Classification</td>
</tr>
<tr>
<td>Pandemic</td>
<td>Causality</td>
</tr>
<tr>
<td>Epizootic</td>
<td>Discrimination</td>
</tr>
<tr>
<td>Transmissible</td>
<td>Polarization</td>
</tr>
<tr>
<td>Leucocyte</td>
<td>Paradox</td>
</tr>
<tr>
<td>Intersectional</td>
<td>Bodies</td>
</tr>
<tr>
<td>Corona</td>
<td>Disparities</td>
</tr>
<tr>
<td>Liquid</td>
<td>Isomorphism</td>
</tr>
<tr>
<td>Genomic</td>
<td>Populism</td>
</tr>
<tr>
<td>Nucleotide</td>
<td>Interdependence</td>
</tr>
<tr>
<td>Masked</td>
<td>Colorism</td>
</tr>
</tbody>
</table>
'),('https://kieranhealy.org/blog/archives/2020/04/28/new-orleans-and-normalization/', 'New Orleans and Normalization', '1588117010000',  15, '<p>My post about <a href="https://kieranhealy.org/blog/archives/2020/04/23/apples-covid-mobility-data/">Apple&rsquo;s mobility data</a> from a few days ago has been doing the rounds. (People have been <a href="https://sixcolors.com/link/2020/04/parsing-through-apples-covid-mobility-data/">very</a> <a href="https://daringfireball.net/linked/2020/04/26/healy-covid-mobility-data">kind</a>.) UnsurprisinglyÙ« one of the most thoughtful responses came from Dr. DrangÙ« who wrote up a great discussion about the importance of choosing the right baseline if you&rsquo;re going to be indexing change with respect to some time. His discussion of <a href="https://leancrew.com/all-this/2020/04/small-multiples-and-normalization/">Small Multiples and Normalization</a> is really worth your while.</p>
<p>Dr. Drang&rsquo;s eye was caught by the case of SeattleÙ« where the transit series was odd in a way that was related to Apple&rsquo;s arbitrary choice of January 13th as the baseline for its series:</p>
<blockquote>
<p>One effect of this normalization choice is to make the recent walking and driving requests in Seattle look higher than they should. Appleâ€™s scores suggest that they are currently averaging 50â€“65% of what they were pre-COVIDÙ« but those are artificially high numbers because the norm was set artificially low.</p>
<p>A better way to normalize the data would be to take a weekâ€™s averageÙ« or a few weeksâ€™ averageÙ« before social distancing and scale all the data with that set to 100.</p>
</blockquote>
<p>I&rsquo;ve been continuing to update my <a href="https://kjhealy.github.io/covdata">covdata package for R</a> as AppleÙ« GoogleÙ« and other sources release more data. This weekÙ« Apple substantially expanded the number of cities and regions it is providing data for. The number of cities in the dataset went up from about 90 to about 150Ù« for example. As I was looking at that data this afternoonÙ« I saw that one of the new cities was New Orleans. Like SeattleÙ« it&rsquo;s an important city in the story of COVID-19 transmission within its region. AndÙ« as it turns outÙ« even more so than SeattleÙ« its series in this particular dataset is warped by the choice of start date. Here are three views of the New Orleans data: the raw series for each modeÙ« the trend component of an STL time series decompositionÙ« and the remainder component of the decomposition. (The methods and code are the same as <a href="https://kieranhealy.org/blog/archives/2020/04/23/apples-covid-mobility-data/">previously shown</a>.)</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/nolac_raw.png"
         alt="Raw New Orleans series"/> <figcaption>
            <p>The New Orleans series as provided by Apple. Click or touch to zoom in.</p>
        </figcaption>
</figure>
<figure>
    <img src="https://kieranhealy.org/files/misc/nolac_trend.png"
         alt="New Orleans trend component"/> <figcaption>
            <p>The trend component of the New Orleans series. Click or touch to zoom in.</p>
        </figcaption>
</figure>
<figure>
    <img src="https://kieranhealy.org/files/misc/nolac_remainders.png"
         alt="New Orleans remainder component"/> <figcaption>
            <p>The remainder component of the New Orleans series. Click or touch to zoom in.</p>
        </figcaption>
</figure>
<p>Two things are evident right away. FirstÙ« New Orleans has a huge spike in foot-traffic (and other movement around town) the weekend before Mardi GrasÙ« and on Shrove Tuesday itself. The spike is likely accentuated by the tourist traffic. As I noted beforeÙ« because Apple&rsquo;s data is derived from the use of Maps for directionsÙ« the movements of people who know their way around town aren&rsquo;t going to show up.</p>
<p>The second thing that jumps out about the series is that for most of January and FebruaryÙ« the city is wayÙ« way below its notional baseline. How can weekday foot trafficÙ« in particularÙ« routinely be 75 percentage points below the January starting point?</p>
<p>The answer is that on January 13thÙ« <a href="https://www.ncaa.com/game/3959666">Clemson played LSU in the NCAA National Football Championship</a> at the New Orleans Superdome. (LSU won 42-25.) This presumably brought a big influx of visitors to townÙ« many of whom were using their iPhones to direct themselves around the city. Because Apple chose January 13th as its baseline dayÙ« this unusually busy Monday was marked as the &ldquo;100&rdquo; mark against which subsequent activity was indexed. AgainÙ« as with <a href="https://kieranhealy.org/blog/archives/2020/04/23/apples-covid-mobility-data/">the strange case of European urban transit</a>Ù« a naive analysisÙ« or even a &ldquo;sophisticated&rdquo; one where the researcher did not bother to <a href="https://www.amazon.com/Data-Visualization-Introduction-Kieran-Healy/dp/0691181624">look at the data first</a>Ù« might easily lead up the garden path.</p>
<p>Dr. Drang has <a href="https://leancrew.com/all-this/2020/04/small-multiples-and-normalization/">already said</a> most of what I&rsquo;d say at this point about the value of checking the sanity of one&rsquo;s starting point (and unlike meÙ« he says it in Python) so I won&rsquo;t belabor the point. You can seeÙ« thoughÙ« just how huge Mardi Gras is in New Orleans. Were the data properly normalizedÙ« the Fat Tuesday spike would be farÙ« far higher than most of the rest of the dataset.</p>
'),('https://kieranhealy.org/blog/archives/2020/04/23/apples-covid-mobility-data/', 'Apple"s COVID Mobility Data', '1587644168000',  15, '<div class="admonition info"><p class="admonition-title">Update</p>
<p>I&rsquo;ve added a <a href="https://github.com/kjhealy/apple_covid_post">GitHub repository</a> containing the code needed to reproduce the graphs in this postÙ« as what&rsquo;s shown here isn&rsquo;t self-contained.</p>
</div>
<p>Apple recently released <a href="https://www.apple.com/covid19/mobility">a batch of mobility data</a> in connection with the COVID-19 pandemic. The data is aggregated from requests for directions in Apple Maps and is provided at the level of whole countries and also for a selection of large cities around the world. I folded the dataset into the <a href="https://kjhealy.github.io/covdata/">covdata package for R</a> that I&rsquo;ve been updatingÙ« as I plan to use it this Fall in a course I&rsquo;ll be teaching. Here I&rsquo;ll take a quick look at some of the data. Along the way&mdash;as it turns out&mdash;I end up reminding myself of a lesson I&rsquo;ve learned before about making sure you understand your measure before you think you understand what it is showing.</p>
<p>Apple released time series data for countries and cities for each of three modes of getting around: drivingÙ« public transitÙ« and walking. The series begins on January 13th andÙ« at the time of writingÙ« continues down to April 20th. The mobility measures for every country or city are indexed to 100 at the beginning of the seriesÙ« so trends are relative to that baseline. We don&rsquo;t know anything about the absolute volume of usage of the Maps service.</p>
<p>Here&rsquo;s what the data look like:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="o">&gt;</span> <span class="n">apple_mobility</span>
<span class="c1"># A tibble: 39Ù«500 x 5</span>
   <span class="n">geo_type</span>       <span class="n">region</span>  <span class="n">transportation_type</span> <span class="n">date</span>       <span class="n">index</span>
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>          <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>               <span class="o">&lt;</span><span class="n">date</span><span class="o">&gt;</span>     <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>
 <span class="m">1</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-13</span> <span class="m">100</span>  
 <span class="m">2</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-14</span>  <span class="m">95.3</span>
 <span class="m">3</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-15</span> <span class="m">101</span><span class="n">. </span>
 <span class="m">4</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-16</span>  <span class="m">97.2</span>
 <span class="m">5</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-17</span> <span class="m">104</span><span class="n">. </span>
 <span class="m">6</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-18</span> <span class="m">113</span><span class="n">. </span>
 <span class="m">7</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-19</span> <span class="m">105</span><span class="n">. </span>
 <span class="m">8</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-20</span>  <span class="m">94.4</span>
 <span class="m">9</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-21</span>  <span class="m">94.1</span>
<span class="m">10</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-22</span>  <span class="m">93.5</span>
<span class="c1"># â€¦ with 39Ù«490 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>The <code>index</code> is the measured outcomeÙ« tracking relative usage of directions for each mode of transportation. Let&rsquo;s take a look at the data for New York.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">raw_ny</span> <span class="o">&lt;-</span> <span class="n">apple_mobility</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">region</span> <span class="o">==</span> <span class="s">&#34;New York City&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">region</span><span class="o">:</span><span class="n">index</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">rename</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">transportation_type</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">tools</span><span class="o">::</span><span class="nf">toTitleCase</span><span class="p">(</span><span class="n">mode</span><span class="p">)Ù«</span>
         <span class="n">weekend</span> <span class="o">=</span> <span class="nf">isWeekend</span><span class="p">(</span><span class="n">date</span><span class="p">)Ù«</span>
         <span class="n">holiday</span> <span class="o">=</span> <span class="nf">isHoliday</span><span class="p">(</span><span class="nf">as.timeDate</span><span class="p">(</span><span class="n">date</span><span class="p">)Ù«</span> <span class="nf">listHolidays</span><span class="p">()))</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">max_day</span> <span class="o">=</span> <span class="nf">ifelse</span><span class="p">(</span><span class="nf">is_max</span><span class="p">(</span><span class="n">index</span><span class="p">)Ù«</span> <span class="n">date</span><span class="p">Ù«</span> <span class="kc">NA</span><span class="p">)Ù«</span>
         <span class="n">max_day</span> <span class="o">=</span> <span class="nf">as_date</span><span class="p">(</span><span class="n">max_day</span><span class="p">))</span>

<span class="n">p_raw_ny</span> <span class="o">&lt;-</span> <span class="nf">ggplot</span><span class="p">(</span><span class="n">raw_ny</span><span class="p">Ù«</span> <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">date</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="n">index</span><span class="p">Ù«</span>
                                      <span class="n">group</span> <span class="o">=</span> <span class="n">mode</span><span class="p">Ù«</span> <span class="n">color</span> <span class="o">=</span> <span class="n">mode</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">geom_vline</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">subset</span><span class="p">(</span><span class="n">raw_ny</span><span class="p">Ù«</span> <span class="n">holiday</span> <span class="o">==</span> <span class="kc">TRUE</span><span class="p">)Ù«</span>
             <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">xintercept</span> <span class="o">=</span> <span class="n">date</span><span class="p">)Ù«</span>
             <span class="n">color</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">)</span><span class="n">[5]</span><span class="p">Ù«</span> <span class="n">size</span> <span class="o">=</span> <span class="m">2.9</span><span class="p">Ù«</span> <span class="n">alpha</span> <span class="o">=</span> <span class="m">0.1</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_hline</span><span class="p">(</span><span class="n">yintercept</span> <span class="o">=</span> <span class="m">100</span><span class="p">Ù«</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;gray40&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_line</span><span class="p">()</span> <span class="o">+</span>
  <span class="nf">geom_text_repel</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">label</span> <span class="o">=</span> <span class="nf">format</span><span class="p">(</span><span class="n">max_day</span><span class="p">Ù«</span> <span class="n">format</span> <span class="o">=</span> <span class="s">&#34;%a %b %d&#34;</span><span class="p">))Ù«</span>
                  <span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">)Ù«</span> <span class="n">nudge_x</span> <span class="o">=</span> <span class="m">1</span><span class="p">Ù«</span> <span class="n">show.legend</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Date&#34;</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Relative Mobility&#34;</span><span class="p">Ù«</span>
       <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;Mode&#34;</span><span class="p">Ù«</span>
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;New York City&#39;s relative trends in activity. Baseline data with no correction for weekly seasonality&#34;</span><span class="p">Ù«</span>
       <span class="n">subtitle</span> <span class="o">=</span> <span class="s">&#34;Data are indexed to 100 for usage on January 13th 2020. Weekends shown as vertical bars. Date with highest relative activity index labeled.\nNote that in Apple&#39;s data &#39;Days&#39; are defined as Midnight to Midnight PST.&#34;</span><span class="p">Ù«</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Data: Apple. Graph: @kjhealy&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;top&#34;</span><span class="p">)</span>

<span class="n">p_raw_ny</span>
</code></pre></td></tr></table>
</div>
</div>

<figure>
    <img src="https://kieranhealy.org/files/misc/apple_nyc_raw.png"
         alt="Relative Mobility in New York City. Touch or click to zoom."/> <figcaption>
            <p>Relative Mobility in New York City. Touch or click to zoom.</p>
        </figcaption>
</figure>
<p>As you can seeÙ« we have three series. The weekly pulse of activity is immediately visible as people do more or less walkingÙ« drivingÙ« and taking the subway depending on what day it is. Remember that the data is based on requests for directions. So on the one handÙ« taxis and Ubers might be making that sort of request every trip. But people living in New York do not require turn-by-turn or step-by-step directions in order to get to work. They already know how to get to work. Even if overall activity is down at the weekendsÙ« requests for directions go up as people figure out how to get to restaurantsÙ« social eventsÙ« or other destinations. On the graph here I&rsquo;ve marked the highest relative value of requests for directionsÙ« which is for foot-traffic on February 22nd. I&rsquo;m not interested in that particular date for New YorkÙ« but when we look at more than one city it might be useful to see how the maximum values vary.</p>
<p>The big COVID-related drop-off in mobility clearly comes in mid-March. We might want to see just that trendÙ« removing the &ldquo;noise&rdquo; of daily variation. When looking at time seriesÙ« we often want to decompose the series into componentsÙ« in order to see some underlying trend. There are many ways to do thisÙ« and many decisions to be made if we&rsquo;re going to be making any strong inferences from the data. Here I&rsquo;ll just keep it straightforward and use some of the very handy tools provided by the <a href="https://tidyverts.org">tidyverts</a> (sic) packages for time-series analysis. We&rsquo;ll use an <a href="https://feasts.tidyverts.org/reference/STL.html">STL decomposition</a> to decompose the series into <em>trend</em>Ù« <em>seasonal</em>Ù« and <em>remainder</em> components. In this case the &ldquo;season&rdquo; is a week rather than a month or a calendar quarter. The trend is a locally-weighted regression fitted to the dataÙ« net of seasonality. The remainder is the residual left over on any given day once the underlying trend and &ldquo;normal&rdquo; daily fluctuations have been accounted for. Here&rsquo;s the trend for New York.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">resids_ny</span> <span class="o">&lt;-</span> <span class="n">apple_mobility</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">region</span> <span class="o">==</span> <span class="s">&#34;New York City&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">region</span><span class="o">:</span><span class="n">index</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">rename</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">transportation_type</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">tools</span><span class="o">::</span><span class="nf">toTitleCase</span><span class="p">(</span><span class="n">mode</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">as_tsibble</span><span class="p">(</span><span class="n">key</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">region</span><span class="p">Ù«</span> <span class="n">mode</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">model</span><span class="p">(</span><span class="nf">STL</span><span class="p">(</span><span class="n">index</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">components</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">weekend</span> <span class="o">=</span> <span class="nf">isWeekend</span><span class="p">(</span><span class="n">date</span><span class="p">)Ù«</span>
         <span class="n">holiday</span> <span class="o">=</span> <span class="nf">isHoliday</span><span class="p">(</span><span class="nf">as.timeDate</span><span class="p">(</span><span class="n">date</span><span class="p">)Ù«</span> <span class="nf">listHolidays</span><span class="p">()))</span> <span class="o">%&gt;%</span>
  <span class="nf">as_tibble</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">max_day</span> <span class="o">=</span> <span class="nf">ifelse</span><span class="p">(</span><span class="nf">is_max</span><span class="p">(</span><span class="n">remainder</span><span class="p">)Ù«</span> <span class="n">date</span><span class="p">Ù«</span> <span class="kc">NA</span><span class="p">)Ù«</span>
         <span class="n">max_day</span> <span class="o">=</span> <span class="nf">as_date</span><span class="p">(</span><span class="n">max_day</span><span class="p">))</span>

<span class="n">p_resid_ny</span> <span class="o">&lt;-</span> <span class="nf">ggplot</span><span class="p">(</span><span class="n">resids_ny</span><span class="p">Ù«</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">date</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="n">remainder</span><span class="p">Ù«</span> <span class="n">group</span> <span class="o">=</span> <span class="n">mode</span><span class="p">Ù«</span> <span class="n">color</span> <span class="o">=</span> <span class="n">mode</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">geom_vline</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">subset</span><span class="p">(</span><span class="n">resids</span><span class="p">Ù«</span> <span class="n">holiday</span> <span class="o">==</span> <span class="kc">TRUE</span><span class="p">)Ù«</span>
             <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">xintercept</span> <span class="o">=</span> <span class="n">date</span><span class="p">)Ù«</span>
             <span class="n">color</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">)</span><span class="n">[5]</span><span class="p">Ù«</span> <span class="n">size</span> <span class="o">=</span> <span class="m">2.9</span><span class="p">Ù«</span> <span class="n">alpha</span> <span class="o">=</span> <span class="m">0.1</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_line</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="m">0.5</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_text_repel</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">label</span> <span class="o">=</span> <span class="nf">format</span><span class="p">(</span><span class="n">max_day</span><span class="p">Ù«</span> <span class="n">format</span> <span class="o">=</span> <span class="s">&#34;%a %b %d&#34;</span><span class="p">))Ù«</span>
                  <span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">)Ù«</span> <span class="n">nudge_x</span> <span class="o">=</span> <span class="m">1</span><span class="p">Ù«</span> <span class="n">show.legend</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Date&#34;</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Remainder&#34;</span><span class="p">Ù«</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;Mode&#34;</span><span class="p">Ù«</span>
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;New York CityÙ« Remainder component for activity data&#34;</span><span class="p">Ù«</span>
       <span class="n">subtitle</span> <span class="o">=</span> <span class="s">&#34;Weekends shown as vertical bars. Date with highest remainder component labeled.\nNote that in Apple&#39;s data &#39;Days&#39; are defined as Midnight to Midnight PST.&#34;</span><span class="p">Ù«</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Data: Apple. Graph: @kjhealy&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;top&#34;</span><span class="p">)</span>
  
 <span class="n">p_resid_ny</span> 
</code></pre></td></tr></table>
</div>
</div>

<figure>
    <img src="https://kieranhealy.org/files/misc/apple_nyc_trend.png"
         alt="Trend component of the New York series. Touch or click to zoom."/> <figcaption>
            <p>Trend component of the New York series. Touch or click to zoom.</p>
        </figcaption>
</figure>
<p>We can make a small multiple graph showing the raw data (or the componentsÙ« as we please) for all the cities in the dataset if we like:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">p_base_all</span> <span class="o">&lt;-</span> <span class="n">apple_mobility</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">geo_type</span> <span class="o">==</span> <span class="s">&#34;city&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">region</span><span class="o">:</span><span class="n">index</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">rename</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">transportation_type</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">ggplot</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">date</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="n">index</span><span class="p">Ù«</span> <span class="n">group</span> <span class="o">=</span> <span class="n">mode</span><span class="p">Ù«</span> <span class="n">color</span> <span class="o">=</span> <span class="n">mode</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">geom_line</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="m">0.5</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">facet_wrap</span><span class="p">(</span><span class="o">~</span> <span class="n">region</span><span class="p">Ù«</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">8</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Date&#34;</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Trend&#34;</span><span class="p">Ù«</span>
       <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;Mode&#34;</span><span class="p">Ù«</span>
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;All ModesÙ« All CitiesÙ« Base Data&#34;</span><span class="p">Ù«</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Data: Apple. Graph: @kjhealy&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;top&#34;</span><span class="p">)</span>

<span class="n">p_base_all</span>
</code></pre></td></tr></table>
</div>
</div>

<figure>
    <img src="https://kieranhealy.org/files/misc/apple_all_cities_raw.png"
         alt="Data for all cities. Touch or click to zoom."/> <figcaption>
            <p>Data for all cities. Touch or click to zoom.</p>
        </figcaption>
</figure>
<p>This isn&rsquo;t the sort of graph that&rsquo;s going to look great on your phoneÙ« but it&rsquo;s useful for getting some overall sense of the trends. Beyond the sharp declines everywhere&mdash;with slightly different timingsÙ« something that&rsquo;d be worth looking at separately&mdash;a few other things pop out. There&rsquo;s a fair amount of variation across cities by mode of transport and also by the intensity of the seasonal component. Some sharp spikes are evidentÙ« tooÙ« not always on the same day or by the same mode of transport. We can take a closer look at some of the cities of interest on this front.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">focus_on</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;Rio de Janeiro&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Lyon&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Bochum - Dortmund&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Dusseldorf&#34;</span><span class="p">Ù«</span>
              <span class="s">&#34;Barcelona&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Detroit&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Toulouse&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Stuttgart&#34;</span><span class="p">Ù«</span>
              <span class="s">&#34;Cologne&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Hamburg&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Cairo&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Lille&#34;</span><span class="p">)</span>

<span class="n">raw_ts</span> <span class="o">&lt;-</span> <span class="n">apple_mobility</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">geo_type</span> <span class="o">==</span> <span class="s">&#34;city&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">region</span><span class="o">:</span><span class="n">index</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">rename</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">transportation_type</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">tools</span><span class="o">::</span><span class="nf">toTitleCase</span><span class="p">(</span><span class="n">mode</span><span class="p">)Ù«</span>
         <span class="n">weekend</span> <span class="o">=</span> <span class="nf">isWeekend</span><span class="p">(</span><span class="n">date</span><span class="p">)Ù«</span>
         <span class="n">holiday</span> <span class="o">=</span> <span class="nf">isHoliday</span><span class="p">(</span><span class="nf">as.timeDate</span><span class="p">(</span><span class="n">date</span><span class="p">)Ù«</span> <span class="nf">listHolidays</span><span class="p">()))</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">region</span> <span class="o">%in%</span> <span class="n">focus_on</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">region</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">max_day</span> <span class="o">=</span> <span class="nf">ifelse</span><span class="p">(</span><span class="nf">is_max</span><span class="p">(</span><span class="n">index</span><span class="p">)Ù«</span> <span class="n">date</span><span class="p">Ù«</span> <span class="kc">NA</span><span class="p">)Ù«</span>
         <span class="n">max_day</span> <span class="o">=</span> <span class="nf">as_date</span><span class="p">(</span><span class="n">max_day</span><span class="p">))</span>
         
<span class="nf">ggplot</span><span class="p">(</span><span class="n">raw_ts</span><span class="p">Ù«</span> <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">date</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="n">index</span><span class="p">Ù«</span>
                                      <span class="n">group</span> <span class="o">=</span> <span class="n">mode</span><span class="p">Ù«</span> <span class="n">color</span> <span class="o">=</span> <span class="n">mode</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">geom_vline</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">subset</span><span class="p">(</span><span class="n">raw_ts</span><span class="p">Ù«</span> <span class="n">holiday</span> <span class="o">==</span> <span class="kc">TRUE</span><span class="p">)Ù«</span>
             <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">xintercept</span> <span class="o">=</span> <span class="n">date</span><span class="p">)Ù«</span>
             <span class="n">color</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">)</span><span class="n">[5]</span><span class="p">Ù«</span> <span class="n">size</span> <span class="o">=</span> <span class="m">1.5</span><span class="p">Ù«</span> <span class="n">alpha</span> <span class="o">=</span> <span class="m">0.1</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_hline</span><span class="p">(</span><span class="n">yintercept</span> <span class="o">=</span> <span class="m">100</span><span class="p">Ù«</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;gray40&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_line</span><span class="p">()</span> <span class="o">+</span>
  <span class="nf">geom_text_repel</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">label</span> <span class="o">=</span> <span class="nf">format</span><span class="p">(</span><span class="n">max_day</span><span class="p">Ù«</span> <span class="n">format</span> <span class="o">=</span> <span class="s">&#34;%a %b %d&#34;</span><span class="p">))Ù«</span>
                  <span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">)Ù«</span> <span class="n">nudge_x</span> <span class="o">=</span> <span class="m">1</span><span class="p">Ù«</span> <span class="n">show.legend</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">facet_wrap</span><span class="p">(</span><span class="o">~</span> <span class="n">region</span><span class="p">Ù«</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">2</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Date&#34;</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Relative Mobility&#34;</span><span class="p">Ù«</span>
       <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;Mode&#34;</span><span class="p">Ù«</span>
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Relative trends in activityÙ« selected cities. No seasonal correction.&#34;</span><span class="p">Ù«</span>
       <span class="n">subtitle</span> <span class="o">=</span> <span class="s">&#34;Data are indexed to 100 for each city&#39;s usage on January 13th 2020. Weekends shown as vertical bars.\nDate with highest relative activity index labeled.\nNote that in Apple&#39;s data &#39;Days&#39; are defined as Midnight to Midnight PST.&#34;</span><span class="p">Ù«</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Data: Apple. Graph: @kjhealy&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;top&#34;</span><span class="p">)</span>         

</code></pre></td></tr></table>
</div>
</div>

<figure>
    <img src="https://kieranhealy.org/files/misc/apple_raw_tall.png"
         alt="Selected cities only. Touch or click to zoom."/> <figcaption>
            <p>Selected cities only. Touch or click to zoom.</p>
        </figcaption>
</figure>
<p>Look at all those transit peaks on February 17th. What&rsquo;s going on here? At this pointÙ« we could take a look at the residual or remainder component of the series rather than looking at the raw dataÙ« so we can see if something interesting is happening.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">resids</span> <span class="o">&lt;-</span> <span class="n">apple_mobility</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">geo_type</span> <span class="o">==</span> <span class="s">&#34;city&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">region</span><span class="o">:</span><span class="n">index</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">rename</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">transportation_type</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">tools</span><span class="o">::</span><span class="nf">toTitleCase</span><span class="p">(</span><span class="n">mode</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">region</span> <span class="o">%in%</span> <span class="n">focus_on</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">as_tsibble</span><span class="p">(</span><span class="n">key</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">region</span><span class="p">Ù«</span> <span class="n">mode</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">model</span><span class="p">(</span><span class="nf">STL</span><span class="p">(</span><span class="n">index</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">components</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">weekend</span> <span class="o">=</span> <span class="nf">isWeekend</span><span class="p">(</span><span class="n">date</span><span class="p">)Ù«</span>
         <span class="n">holiday</span> <span class="o">=</span> <span class="nf">isHoliday</span><span class="p">(</span><span class="nf">as.timeDate</span><span class="p">(</span><span class="n">date</span><span class="p">)Ù«</span> <span class="nf">listHolidays</span><span class="p">()))</span> <span class="o">%&gt;%</span>
  <span class="nf">as_tibble</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">region</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">max_day</span> <span class="o">=</span> <span class="nf">ifelse</span><span class="p">(</span><span class="nf">is_max</span><span class="p">(</span><span class="n">remainder</span><span class="p">)Ù«</span> <span class="n">date</span><span class="p">Ù«</span> <span class="kc">NA</span><span class="p">)Ù«</span>
         <span class="n">max_day</span> <span class="o">=</span> <span class="nf">as_date</span><span class="p">(</span><span class="n">max_day</span><span class="p">))</span>
         
<span class="nf">ggplot</span><span class="p">(</span><span class="n">resids</span><span class="p">Ù«</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">date</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="n">remainder</span><span class="p">Ù«</span> <span class="n">group</span> <span class="o">=</span> <span class="n">mode</span><span class="p">Ù«</span> <span class="n">color</span> <span class="o">=</span> <span class="n">mode</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">geom_vline</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">subset</span><span class="p">(</span><span class="n">resids</span><span class="p">Ù«</span> <span class="n">holiday</span> <span class="o">==</span> <span class="kc">TRUE</span><span class="p">)Ù«</span>
             <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">xintercept</span> <span class="o">=</span> <span class="n">date</span><span class="p">)Ù«</span>
             <span class="n">color</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">)</span><span class="n">[5]</span><span class="p">Ù«</span> <span class="n">size</span> <span class="o">=</span> <span class="m">1.5</span><span class="p">Ù«</span> <span class="n">alpha</span> <span class="o">=</span> <span class="m">0.1</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_line</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="m">0.5</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_text_repel</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">label</span> <span class="o">=</span> <span class="nf">format</span><span class="p">(</span><span class="n">max_day</span><span class="p">Ù«</span> <span class="n">format</span> <span class="o">=</span> <span class="s">&#34;%a %b %d&#34;</span><span class="p">))Ù«</span>
                  <span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">)Ù«</span> <span class="n">nudge_x</span> <span class="o">=</span> <span class="m">1</span><span class="p">Ù«</span> <span class="n">show.legend</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">facet_wrap</span><span class="p">(</span><span class="o">~</span> <span class="n">region</span><span class="p">Ù«</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">2</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Date&#34;</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Remainder&#34;</span><span class="p">Ù«</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;Mode&#34;</span><span class="p">Ù«</span>
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Remainder component for activity data (after trend and weekly components removed)&#34;</span><span class="p">Ù«</span>
       <span class="n">subtitle</span> <span class="o">=</span> <span class="s">&#34;Weekends shown as vertical bars. Date with highest remainder component labeled.\nNote that in Apple&#39;s data &#39;Days&#39; are defined as Midnight to Midnight PST.&#34;</span><span class="p">Ù«</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Data: Apple. Graph: @kjhealy&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;top&#34;</span><span class="p">)</span>         
</code></pre></td></tr></table>
</div>
</div>

<figure>
    <img src="https://kieranhealy.org/files/misc/apple_remainders_tall.png"
         alt="Remainder components only. Touch or click to zoom."/> <figcaption>
            <p>Remainder components only. Touch or click to zoom.</p>
        </figcaption>
</figure>
<p>We can see that there&rsquo;s a fair amount of correspondence between the spikes in activityÙ« but it&rsquo;s not clear what the explanation is. For some cities things seem straightforward. Rio de Janiero&rsquo;s huge spike in foot traffic corresponds to the Carnival parade around the week of Mardi Gras. As it turns out&mdash;<a href="https://twitter.com/FOchsenfeld/status/1253047574392684546?s=20">thanks</a> to some <a href="https://twitter.com/RenseC/status/1253035699999211526?s=20">local</a> <a href="https://twitter.com/Andre_Serious/status/1253035880568193030?s=20">informants</a> for <a href="https://twitter.com/Eule_Geheule/status/1253036239445536768?s=20">this</a>&mdash;the same is true of CologneÙ« where Carnival season (<a href="https://en.wikipedia.org/wiki/Carnival_in_GermanyÙ«_Switzerland_and_Austria">Fasching</a>) is also a big thing. But that doesn&rsquo;t explain the spikes that repeatedly show up for February 17th in a number of German and French provincial cities. It&rsquo;s a week too early. And why specifically in <em>transit</em> requests? What&rsquo;s going on there? Initially I speculated that it might be connected to events like football matches or something like thatÙ« but that didn&rsquo;t seem very convincingÙ« because those happen week-in week-outÙ« and if it were an unusual event (like a final) we wouldn&rsquo;t see it across so many cities. A second possibility was some widely-shared calendar event that would cause a lot of people to start riding public transit. The beginning or end of school holidaysÙ« for exampleÙ« seemed like a plausible candidate. But if that were the case why didn&rsquo;t we see it in otherÙ« larger cities in these countries? And are France and Germany on the same school calendars? This isn&rsquo;t around EasterÙ« so it seems unlikely.</p>
<p>After wondering aloud about this on TwitterÙ« the best candidate for an explanation came from <a href="https://twitter.com/SebastianGeukes/status/1253074673123897357?s=20">Sebastian Geukes</a>. He pointed out that the February 17th spikes coincide with <a href="https://www.cultofmac.com/685221/apple-maps-transit-directions-expand-europe/">Apple rolling out expanded coverage of many European cities in the Maps app</a>. That Monday marks the beginning of public transit directions becoming available to iPhone users in these cities. And soÙ« unsurprisinglyÙ« the result is a surge in people using Maps for that purposeÙ« in comparison to when it wasn&rsquo;t a feature. I say &ldquo;unsurprisingly&rdquo;Ù« but of course it took a little while to figure this out! And I didn&rsquo;t figure it out myselfÙ« either. It&rsquo;s an excellent illustration of a rule of thumb I wrote about <a href="https://kieranhealy.org/blog/archives/2018/08/01/i-cant-believe-its-not-butter/">a while ago</a> in a similar context.</p>
<blockquote>
<p>As a ruleÙ« when you see a sharp change in a long-running time-seriesÙ« you should always check to see if some aspect of the data-generating process changedâ€”such as the measurement device or the criteria for inclusion in the datasetâ€”before coming up with any substantive stories about what happened and why. This is especially the case for something susceptible to change over timeÙ« but not to extremely rapid fluctuations. &hellip;  As Tom SmithÙ« the director of the General Social SurveyÙ« likes to sayÙ« if you want to measure changeÙ« you canâ€™t change the measure.</p>
</blockquote>
<p>In this caseÙ« there&rsquo;s a further wrinkle. I probably would have been quicker to twig what was going on had I looked a little harder at the raw data rather than moving to the remainder component of the time series decomposition. Having had my eye caught by Rio&rsquo;s big Carnival spike I went to look at the remainder component for all these cities and so ended up focusing on that. But if you look again at the raw city trends you can see that the transit data series (the blue line) spikes up on February 17th but then <em>sticks around</em> afterwardsÙ« settling in to a regular presenceÙ« at quite a high relative level in comparison to its previous non-existence. And this of course is because people have begun to use this new feature regularly. If we&rsquo;d had raw data on the absolute levels of usage in transit directions this would likely have been clear more quickly.</p>
<p>The tendency to launch right into what social scientists call the &ldquo;Storytime!&rdquo; phase of data analysis when looking at some graph or table of results is really strong. We already know from other COVID-related analysis how tricky and indeed dangerous it can be to mistakenly infer too much from what you think you see in the data. (<a href="https://statmodeling.stat.columbia.edu/2020/04/19/fatal-flaws-in-stanford-study-of-coronavirus-prevalence/">Here&rsquo;s a recent example.</a>) Taking care to understand what your measurement instrument is doing really does matter. In this caseÙ« I thinkÙ« it&rsquo;s all the more important because with data of the sort that Apple (and also <a href="https://www.google.com/covid19/mobility/index.html?hl=en">Google</a>) have releasedÙ« it&rsquo;s fun to just jump into it and start speculating. That&rsquo;s because we don&rsquo;t often get to play with even highly aggregated data from sources like this. I wonder ifÙ« in the next year or soÙ« someone doing an ecologicalÙ« city-level  analysis of social response to COVID-19 will inadvertently get caught out by the change in the measure lurking in this dataset.</p>
'),('https://kieranhealy.org/blog/archives/2020/04/16/upset-plots/', 'Upset Plots', '1587065371000',  15, '<p>The other day <a href="https://www.nature.com/articles/d41586-020-01023-2">Nature</a> reported some preliminary results from a study of COVID-19 symptoms that&rsquo;s being carried out via a phone app. The report noted that loss of sense of smell (or &ldquo;Anosmia&rdquo;) seemed to be a common symptom. The report was accompanied by this graphicÙ« showing the co-occurrence of symptoms in about 1Ù«700 self-reports via the app.</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/covid-symptoms-venn.jpg"
         alt="COVID Symptoms Venn Diagram"/> <figcaption>
            <p>A species of Venn Diagram showing the co-occurrence of reported COVID-19 symptoms.</p>
        </figcaption>
</figure>
<p>(AgainÙ« please bear in mind that these are preliminary results from the users of a single smartphone app.)</p>
<p>I think it&rsquo;s fair to say that this way of representing the data is pushing the Venn Diagram approach to its limits. It&rsquo;s hard to get a sense of what&rsquo;s going on. That saidÙ« representing what are in effect tables of cross-classified counts or frequencies is one of those aspects of data visualization that is surprisingly hard to do effectively. If you have a large number of categories and cross-classifications of discrete measuresÙ« things get messy very fast. Continuous data are much easier to displayÙ« by comparison.</p>
<p>StillÙ« we can do better. One familiar option would be a heatmap of some sortÙ« showing a matrix of symptoms&mdash;perhaps clustered how often they occur together&mdash;with the cells shaded by the counts or frequencies. More recentlyÙ« the <em>upset plot</em>Ù« developed by <a href="https://ieeexplore.ieee.org/document/6876017">Lex et al</a> (2014)Ù« has emerged as a useful alternative. An upset plot arranges your co-occurring variables into sets and shows you a bar chart of their frequency. The trick is that it tries to make it easy to see the elements that make up the set.</p>
<p>There are several implementations of upset plots in R. I&rsquo;m going to use the <a href="https://github.com/krassowski/complex-upset">Complex UpSet</a> packageÙ« but they&rsquo;re all good. Check out <a href="https://github.com/hms-dbmi/UpSetR">UpSetR</a>Ù« and <a href="https://github.com/const-ae/ggupset">ggupset</a> as well.</p>
<p>I used a spreadsheet to copy out the data from the <em>Nature</em> reportÙ« and then loaded it in to R.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">symptoms</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;Anosmia&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Cough&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Fatigue&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Diarrhea&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Breath&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Fever&#34;</span><span class="p">)</span>
<span class="nf">names</span><span class="p">(</span><span class="n">symptoms</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="n">symptoms</span>


<span class="n">dat</span> <span class="o">&lt;-</span> <span class="n">readxl</span><span class="o">::</span><span class="nf">read_xlsx</span><span class="p">(</span><span class="s">&#34;data/symptoms.xlsx&#34;</span><span class="p">)</span> 
<span class="n">dat</span> <span class="o">%&gt;%</span> <span class="nf">print</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">dat</span><span class="p">))</span>

<span class="c1">## # A tibble: 32 x 2</span>
<span class="c1">##    combination                                 count</span>
<span class="c1">##    &lt;chr&gt;                                       &lt;dbl&gt;</span>
<span class="c1">##  1 Anosmia                                       140</span>
<span class="c1">##  2 Cough                                          57</span>
<span class="c1">##  3 Fatigue                                       198</span>
<span class="c1">##  4 Diarrhea                                       12</span>
<span class="c1">##  5 Breath                                          5</span>
<span class="c1">##  6 Fever                                          11</span>
<span class="c1">##  7 Cough&amp;Fatigue                                 179</span>
<span class="c1">##  8 Fatigue&amp;Fever                                  28</span>
<span class="c1">##  9 Breath&amp;Fatigue                                 10</span>
<span class="c1">## 10 Diarrhea&amp;Fatigue                               43</span>
<span class="c1">## 11 Anosmia&amp;Fatigue                               281</span>
<span class="c1">## 12 Breath&amp;Cough                                    1</span>
<span class="c1">## 13 Anosmia&amp;Diarrhea&amp;Fatigue                       64</span>
<span class="c1">## 14 Breath&amp;Cough&amp;Fatigue                           22</span>
<span class="c1">## 15 Anosmia&amp;Cough&amp;Fatigue                         259</span>
<span class="c1">## 16 Anosmia&amp;Fever&amp;Fatigue                          46</span>
<span class="c1">## 17 Cough&amp;Fever&amp;Fatigue                            54</span>
<span class="c1">## 18 Cough&amp;Diarrhea                                  7</span>
<span class="c1">## 19 Cough&amp;Diarrhea&amp;Fatigue                         31</span>
<span class="c1">## 20 Anosmia&amp;Breath&amp;Cough&amp;Fatigue                   26</span>
<span class="c1">## 21 Anosmia&amp;Cough&amp;Fatigue&amp;Fever                    69</span>
<span class="c1">## 22 Anosmia&amp;Breath&amp;Cough&amp;Diarrhea&amp;Fatigue          18</span>
<span class="c1">## 23 Anosmia&amp;Breath&amp;Cough&amp;Fatigue&amp;Fever             17</span>
<span class="c1">## 24 Breath&amp;Cough&amp;Fatigue&amp;Fever                     11</span>
<span class="c1">## 25 Breath&amp;Cough&amp;Diarrhea&amp;Fatigue                   7</span>
<span class="c1">## 26 Breath&amp;Cough&amp;Diarrhea&amp;Fatigue&amp;Fever             8</span>
<span class="c1">## 27 Diarrhea&amp;Fatigue&amp;Fever                         12</span>
<span class="c1">## 28 Cough&amp;Diarrhea&amp;Fatigue&amp;Fever                   17</span>
<span class="c1">## 29 Anosmia&amp;Diarrhea&amp;Fatigue&amp;Fever                 17</span>
<span class="c1">## 30 Anosmia&amp;Diarrhea&amp;Cough&amp;Fatigue                 41</span>
<span class="c1">## 31 Anosmia&amp;Breath&amp;Cough&amp;Diarrhea&amp;Fatigue&amp;Fever    23</span>
<span class="c1">## 32 Anosmia&amp;Cough&amp;Diarrhea&amp;Fatigue&amp;Fever           50</span>

</code></pre></td></tr></table>
</div>
</div>

<p>We have six basic symptoms (&ldquo;Breath&rdquo; means &ldquo;Shortness of Breath&rdquo;). They occur in various combinations. We need to get this data into a shape we can work with. We have two tasks. FirstÙ« it will be convenient to convert this summary back into an observation-level table. The <code>tidyr</code> package has a <a href="https://tidyr.tidyverse.org/reference/uncount.html">handy function</a> called <code>uncount</code> that will do this for us. HoweverÙ« we can&rsquo;t do that directly. Think of the table as showing counts of where various combinations of symptoms are <code>TRUE</code>. ImplicitlyÙ« where we don&rsquo;t see a symptomÙ« it&rsquo;s implicitly <code>FALSE</code> in those cases where it isn&rsquo;t there. For exampleÙ« in the first rowÙ« the 140 patients reporting Anosmia are implicitly also reporting they don&rsquo;t have any of the other five symptoms. If we don&rsquo;t get those implicit negatives backÙ« we won&rsquo;t get a proper picture of the clustering.</p>
<p>SoÙ« we&rsquo;re going to generate table of <code>TRUE</code> and <code>FALSE</code> values for our symptom combinations. There&rsquo;s probably a substantially more elegant way to do this than shown hereÙ« but let&rsquo;s press on regardless.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">subsets</span> <span class="o">&lt;-</span> <span class="n">dat</span><span class="o">$</span><span class="n">combination</span>

<span class="c1">## Check if each subset mentions each symptom or not</span>
<span class="n">symptom_mat</span> <span class="o">&lt;-</span> <span class="nf">map_dfc</span><span class="p">(</span><span class="n">subsets</span><span class="p">Ù«</span> <span class="n">str_detect</span><span class="p">Ù«</span> <span class="n">symptoms</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="nf">data.frame</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">t</span><span class="p">()</span> <span class="o">%&gt;%</span> <span class="c1"># transpose the resultÙ« ugh</span>
    <span class="nf">as_tibble</span><span class="p">()</span>

<span class="nf">colnames</span><span class="p">(</span><span class="n">symptom_mat</span><span class="p">)</span>  <span class="o">&lt;-</span> <span class="n">symptoms</span>

<span class="n">symptom_mat</span><span class="o">$</span><span class="n">count</span> <span class="o">&lt;-</span> <span class="n">dat</span><span class="o">$</span><span class="n">count</span>

<span class="n">symptom_mat</span> <span class="o">%&gt;%</span> <span class="nf">print</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">symptom_mat</span><span class="p">))</span>

<span class="c1">## # A tibble: 32 x 7</span>
<span class="c1">##    Anosmia Cough Fatigue Diarrhea Breath Fever count</span>
<span class="c1">##    &lt;lgl&gt;   &lt;lgl&gt; &lt;lgl&gt;   &lt;lgl&gt;    &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt;</span>
<span class="c1">##  1 TRUE    FALSE FALSE   FALSE    FALSE  FALSE   140</span>
<span class="c1">##  2 FALSE   TRUE  FALSE   FALSE    FALSE  FALSE    57</span>
<span class="c1">##  3 FALSE   FALSE TRUE    FALSE    FALSE  FALSE   198</span>
<span class="c1">##  4 FALSE   FALSE FALSE   TRUE     FALSE  FALSE    12</span>
<span class="c1">##  5 FALSE   FALSE FALSE   FALSE    TRUE   FALSE     5</span>
<span class="c1">##  6 FALSE   FALSE FALSE   FALSE    FALSE  TRUE     11</span>
<span class="c1">##  7 FALSE   TRUE  TRUE    FALSE    FALSE  FALSE   179</span>
<span class="c1">##  8 FALSE   FALSE TRUE    FALSE    FALSE  TRUE     28</span>
<span class="c1">##  9 FALSE   FALSE TRUE    FALSE    TRUE   FALSE    10</span>
<span class="c1">## 10 FALSE   FALSE TRUE    TRUE     FALSE  FALSE    43</span>
<span class="c1">## 11 TRUE    FALSE TRUE    FALSE    FALSE  FALSE   281</span>
<span class="c1">## 12 FALSE   TRUE  FALSE   FALSE    TRUE   FALSE     1</span>
<span class="c1">## 13 TRUE    FALSE TRUE    TRUE     FALSE  FALSE    64</span>
<span class="c1">## 14 FALSE   TRUE  TRUE    FALSE    TRUE   FALSE    22</span>
<span class="c1">## 15 TRUE    TRUE  TRUE    FALSE    FALSE  FALSE   259</span>
<span class="c1">## 16 TRUE    FALSE TRUE    FALSE    FALSE  TRUE     46</span>
<span class="c1">## 17 FALSE   TRUE  TRUE    FALSE    FALSE  TRUE     54</span>
<span class="c1">## 18 FALSE   TRUE  FALSE   TRUE     FALSE  FALSE     7</span>
<span class="c1">## 19 FALSE   TRUE  TRUE    TRUE     FALSE  FALSE    31</span>
<span class="c1">## 20 TRUE    TRUE  TRUE    FALSE    TRUE   FALSE    26</span>
<span class="c1">## 21 TRUE    TRUE  TRUE    FALSE    FALSE  TRUE     69</span>
<span class="c1">## 22 TRUE    TRUE  TRUE    TRUE     TRUE   FALSE    18</span>
<span class="c1">## 23 TRUE    TRUE  TRUE    FALSE    TRUE   TRUE     17</span>
<span class="c1">## 24 FALSE   TRUE  TRUE    FALSE    TRUE   TRUE     11</span>
<span class="c1">## 25 FALSE   TRUE  TRUE    TRUE     TRUE   FALSE     7</span>
<span class="c1">## 26 FALSE   TRUE  TRUE    TRUE     TRUE   TRUE      8</span>
<span class="c1">## 27 FALSE   FALSE TRUE    TRUE     FALSE  TRUE     12</span>
<span class="c1">## 28 FALSE   TRUE  TRUE    TRUE     FALSE  TRUE     17</span>
<span class="c1">## 29 TRUE    FALSE TRUE    TRUE     FALSE  TRUE     17</span>
<span class="c1">## 30 TRUE    TRUE  TRUE    TRUE     FALSE  FALSE    41</span>
<span class="c1">## 31 TRUE    TRUE  TRUE    TRUE     TRUE   TRUE     23</span>
<span class="c1">## 32 TRUE    TRUE  TRUE    TRUE     FALSE  TRUE     50</span>

</code></pre></td></tr></table>
</div>
</div>

<p>OKÙ« so with that table in placeÙ« we can use the <code>uncount()</code> function to turn our summary back into quasi-individual-level data:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">indvs</span> <span class="o">&lt;-</span> <span class="n">symptom_mat</span> <span class="o">%&gt;%</span>
    <span class="nf">uncount</span><span class="p">(</span><span class="n">count</span><span class="p">)</span> 

<span class="n">indvs</span>

<span class="c1">## # A tibble: 1Ù«764 x 6</span>
<span class="c1">##    Anosmia Cough Fatigue Diarrhea Breath Fever</span>
<span class="c1">##    &lt;lgl&gt;   &lt;lgl&gt; &lt;lgl&gt;   &lt;lgl&gt;    &lt;lgl&gt;  &lt;lgl&gt;</span>
<span class="c1">##  1 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  2 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  3 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  4 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  5 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  6 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  7 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  8 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  9 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">## 10 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">## # â€¦ with 1Ù«754 more rows</span>
</code></pre></td></tr></table>
</div>
</div>

<p>If we hadn&rsquo;t done that tabulationÙ« <code>uncount</code> would have given us the wrong answers. Ask me how I know!</p>
<p>Now that we&rsquo;ve reconstituted the dataÙ« we can draw our graph.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="nf">library</span><span class="p">(</span><span class="n">ComplexUpset</span><span class="p">)</span>

<span class="nf">upset</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">indvs</span><span class="p">Ù«</span> <span class="n">intersect</span> <span class="o">=</span> <span class="n">symptoms</span><span class="p">Ù«</span> 
      <span class="n">name</span><span class="o">=</span><span class="s">&#34;Symptom Groupings by Frequency. Total pool is 1Ù«764 individuals.&#34;</span><span class="p">Ù«</span> 
      <span class="n">min_size</span> <span class="o">=</span> <span class="m">0</span><span class="p">Ù«</span>
      <span class="n">width_ratio</span> <span class="o">=</span> <span class="m">0.125</span><span class="p">)</span> <span class="o">+</span>
    <span class="nf">labs</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Co-Occurence of COVID-19 Symptoms&#34;</span><span class="p">Ù«</span>
         <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Data: covid.joinzoe.com/us | Graph: @kjhealy&#34;</span><span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div>

<figure>
    <img src="https://kieranhealy.org/files/misc/covid-upset-plot-1.png"
         alt="COVID Symptoms Upset Plot"/> <figcaption>
            <p>An UpSet plot showing the co-occurrence of reported COVID-19 symptoms. Click or touch to zoom.</p>
        </figcaption>
</figure>
<p>The plot has three pieces. The bar chart shows the number of people in the data who reported some particular combination of symptoms. Each bar is a different combination. Underneath it is a graphical table showing what those combinations are. Each row is one of our six symptoms: FatigueÙ« AnosmiaÙ« CoughÙ« FeverÙ« DiarrheaÙ« and (shortness of) Breath. The black dots and lines show the combination of symptoms that make up each cluster or subset of symptoms. Reading from left to rightÙ« we can see that the most common subset of symptoms is the combination of Fatigue and AnosmiaÙ« and nothing else. A total of 281 respondents reported this combination. Next is FatigueÙ« AnosmiaÙ« and CoughÙ« with 259 reportsÙ« followed by Fatigue alone with 198. And so on across the table. You can seeÙ« for exampleÙ« that there are 23 reports of all six symptomsÙ« and only one report of <em>just</em> the combination of Cough and shortness of Breath.</p>
<p>The third component of the plot is the smaller bar chart to the left of the graphical table. This shows the unconditional frequency count of each symptom across all subsets. You can see that almost everyone reported suffering from FatigueÙ« for instanceÙ« and that Shortness of Breath was the least commonly-reported symptom in absolute terms.</p>
<p>I think upset plots are very usefulÙ« on the whole. They clearly outperform Venn diagrams when there&rsquo;s more than a few overlapping setsÙ« and they avoid some of the problems associated with heatmapsÙ« too. Nicholas Tierney puts them to very good use in <a href="https://github.com/njtierney/naniar">naniar</a>Ù« his package for visualizing missing data. The technique doesn&rsquo;t make the problems with visualizing cross-classified counts magically disappearÙ« of course. If you have a large number of intersecting groups it will become unwieldy as well. But then of course you&rsquo;d start to look for ways to focus on the intersections that matter mostÙ« or on alternative ways of ordering the combinationsÙ« and so on. (The upset packages have some of these methods built in.) In the meantimeÙ« it&rsquo;s often your best option for this kind of task.</p>
<p>The code and data used in this post are <a href="https://github.com/kjhealy/covid_symptoms">available on GitHub</a>.</p>
'),('https://kieranhealy.org/blog/archives/2020/04/10/covdata-package/', 'Covdata Package', '1586550478000',  15, '<figure>
    <img src="https://kieranhealy.org/files/misc/hex-covdata.png"
         alt="The covdata logo"/> <figcaption>
            <p>The covdata logo</p>
        </figcaption>
</figure>
<p>Partly because it grew out of a few code-throughs I was doingÙ« but mostly as a classroom exerciseÙ« I pulled together a small data package for R called <a href="https://kjhealy.github.io/covdata/index.html">covdata</a>Ù« available at <a href="https://kjhealy.github.io/covdata/">https://kjhealy.github.io/covdata/</a>. It contains COVID-19 data from three sources:</p>
<ul>
<li>National level data from the <a href="https://www.ecdc.europa.eu/en">European Centers for Disease Control</a>.</li>
<li>State-level data for the United States from the <a href="https://covidtracking.com">COVID Tracking Project</a>.</li>
<li>State-level and county-level data for the United States from the <a href="https://github.com/nytimes/covid-19-data"><em>New York Times</em></a>.</li>
</ul>
<p>I&rsquo;ll keep it up to date for at least the near future. If I get a chance I&rsquo;ll write up a little walkthrough about the process of making a package like this. I find that making data packages for R is both intrinsically useful for data that will be used more than onceÙ« and also generally a very accessible and handy way to introduce students to the mechanics of R packaging. It&rsquo;s much more common for regular users of R to have some data that would benefit from packaging than for them to have some set of functions that might usefully be packaged up for other people.</p>
<p>Here are what the three tables look likeÙ« plus a figure at the end.</p>
<h3 id="country-level-data-from-the-ecdc">Country-Level Data from the ECDC</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">covdata</span><span class="p">)</span>

<span class="n">covnat</span>
<span class="c1">#&gt; # A tibble: 9Ù«858 x 8</span>
<span class="c1">#&gt; # Groups:   iso3 [205]</span>
<span class="c1">#&gt;    date       cname       iso3  cases deaths  pop_2018 cu_cases cu_deaths</span>
<span class="c1">#&gt;    &lt;date&gt;     &lt;chr&gt;       &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;</span>
<span class="c1">#&gt;  1 2019-12-31 Afghanistan AFG       0      0  37172386        0         0</span>
<span class="c1">#&gt;  2 2019-12-31 Algeria     DZA       0      0  42228429        0         0</span>
<span class="c1">#&gt;  3 2019-12-31 Armenia     ARM       0      0   2951776        0         0</span>
<span class="c1">#&gt;  4 2019-12-31 Australia   AUS       0      0  24992369        0         0</span>
<span class="c1">#&gt;  5 2019-12-31 Austria     AUT       0      0   8847037        0         0</span>
<span class="c1">#&gt;  6 2019-12-31 Azerbaijan  AZE       0      0   9942334        0         0</span>
<span class="c1">#&gt;  7 2019-12-31 Bahrain     BHR       0      0   1569439        0         0</span>
<span class="c1">#&gt;  8 2019-12-31 Belarus     BLR       0      0   9485386        0         0</span>
<span class="c1">#&gt;  9 2019-12-31 Belgium     BEL       0      0  11422068        0         0</span>
<span class="c1">#&gt; 10 2019-12-31 Brazil      BRA       0      0 209469333        0         0</span>
<span class="c1">#&gt; # â€¦ with 9Ù«848 more rows</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="us-state-level-data-from-the-covid-tracking-project">US State-Level Data from the COVID Tracking Project</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">covus</span>
<span class="c1">#&gt; # A tibble: 27Ù«216 x 11</span>
<span class="c1">#&gt;    date       state fips  measure count pos_neg death_increase hospitalized_inâ€¦ negative_increaâ€¦ positive_increaâ€¦</span>
<span class="c1">#&gt;    &lt;date&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;</span>
<span class="c1">#&gt;  1 2020-04-09 AK    02    positiâ€¦   235    7223              0                0              146                9</span>
<span class="c1">#&gt;  2 2020-04-09 AK    02    negatiâ€¦  6988    7223              0                0              146                9</span>
<span class="c1">#&gt;  3 2020-04-09 AK    02    pending    NA    7223              0                0              146                9</span>
<span class="c1">#&gt;  4 2020-04-09 AK    02    hospitâ€¦    NA    7223              0                0              146                9</span>
<span class="c1">#&gt;  5 2020-04-09 AK    02    hospitâ€¦    27    7223              0                0              146                9</span>
<span class="c1">#&gt;  6 2020-04-09 AK    02    in_icuâ€¦    NA    7223              0                0              146                9</span>
<span class="c1">#&gt;  7 2020-04-09 AK    02    in_icuâ€¦    NA    7223              0                0              146                9</span>
<span class="c1">#&gt;  8 2020-04-09 AK    02    on_venâ€¦    NA    7223              0                0              146                9</span>
<span class="c1">#&gt;  9 2020-04-09 AK    02    on_venâ€¦    NA    7223              0                0              146                9</span>
<span class="c1">#&gt; 10 2020-04-09 AK    02    recoveâ€¦    49    7223              0                0              146                9</span>
<span class="c1">#&gt; # â€¦ with 27Ù«206 more rowsÙ« and 1 more variable: total_test_results_increase &lt;dbl&gt;</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="state-level-and-county-level-cumulative-data-from-the-_new-york-times_">State-Level and County-Level (Cumulative) Data from the <em>New York Times</em></h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">nytcovstate</span>
<span class="c1">#&gt; # A tibble: 2Ù«105 x 5</span>
<span class="c1">#&gt;    date       state      fips  cases deaths</span>
<span class="c1">#&gt;    &lt;date&gt;     &lt;chr&gt;      &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;</span>
<span class="c1">#&gt;  1 2020-01-21 Washington 53        1      0</span>
<span class="c1">#&gt;  2 2020-01-22 Washington 53        1      0</span>
<span class="c1">#&gt;  3 2020-01-23 Washington 53        1      0</span>
<span class="c1">#&gt;  4 2020-01-24 Illinois   17        1      0</span>
<span class="c1">#&gt;  5 2020-01-24 Washington 53        1      0</span>
<span class="c1">#&gt;  6 2020-01-25 California 06        1      0</span>
<span class="c1">#&gt;  7 2020-01-25 Illinois   17        1      0</span>
<span class="c1">#&gt;  8 2020-01-25 Washington 53        1      0</span>
<span class="c1">#&gt;  9 2020-01-26 Arizona    04        1      0</span>
<span class="c1">#&gt; 10 2020-01-26 California 06        2      0</span>
<span class="c1">#&gt; # â€¦ with 2Ù«095 more rows</span>
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">nytcovcounty</span>
<span class="c1">#&gt; # A tibble: 45Ù«880 x 6</span>
<span class="c1">#&gt;    date       county      state      fips  cases deaths</span>
<span class="c1">#&gt;    &lt;date&gt;     &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;</span>
<span class="c1">#&gt;  1 2020-01-21 Snohomish   Washington 53061     1      0</span>
<span class="c1">#&gt;  2 2020-01-22 Snohomish   Washington 53061     1      0</span>
<span class="c1">#&gt;  3 2020-01-23 Snohomish   Washington 53061     1      0</span>
<span class="c1">#&gt;  4 2020-01-24 Cook        Illinois   17031     1      0</span>
<span class="c1">#&gt;  5 2020-01-24 Snohomish   Washington 53061     1      0</span>
<span class="c1">#&gt;  6 2020-01-25 Orange      California 06059     1      0</span>
<span class="c1">#&gt;  7 2020-01-25 Cook        Illinois   17031     1      0</span>
<span class="c1">#&gt;  8 2020-01-25 Snohomish   Washington 53061     1      0</span>
<span class="c1">#&gt;  9 2020-01-26 Maricopa    Arizona    04013     1      0</span>
<span class="c1">#&gt; 10 2020-01-26 Los Angeles California 06037     1      0</span>
<span class="c1">#&gt; # â€¦ with 45Ù«870 more rows</span>
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">nytcovcounty</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">uniq_name</span> <span class="o">=</span> <span class="nf">paste</span><span class="p">(</span><span class="n">county</span><span class="p">Ù«</span> <span class="n">state</span><span class="p">))</span> <span class="o">%&gt;%</span> <span class="c1"># Can&#39;t use FIPS because of how the NYT bundled cities</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">uniq_name</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">days_elapsed</span> <span class="o">=</span> <span class="n">date</span> <span class="o">-</span> <span class="nf">min</span><span class="p">(</span><span class="n">date</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">ggplot</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">days_elapsed</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="n">cases</span><span class="p">Ù«</span> <span class="n">group</span> <span class="o">=</span> <span class="n">uniq_name</span><span class="p">))</span> <span class="o">+</span> 
  <span class="nf">geom_line</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="m">0.25</span><span class="p">Ù«</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;gray20&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">scale_y_log10</span><span class="p">(</span><span class="n">labels</span> <span class="o">=</span> <span class="n">scales</span><span class="o">::</span><span class="nf">label_number_si</span><span class="p">())</span> <span class="o">+</span> 
  <span class="nf">guides</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">facet_wrap</span><span class="p">(</span><span class="o">~</span> <span class="n">state</span><span class="p">Ù«</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">5</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">labs</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s">&#34;COVID-19 Cumulative Recorded Cases by US County&#34;</span><span class="p">Ù«</span>
       <span class="n">subtitle</span> <span class="o">=</span> <span class="nf">paste</span><span class="p">(</span><span class="s">&#34;New York is bundled into a single area in this data.\nData as of&#34;</span><span class="p">Ù«</span> <span class="nf">format</span><span class="p">(</span><span class="nf">max</span><span class="p">(</span><span class="n">nytcovcounty</span><span class="o">$</span><span class="n">date</span><span class="p">)Ù«</span> <span class="s">&#34;%AÙ« %B %eÙ« %Y&#34;</span><span class="p">))Ù«</span>
       <span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Days since first case&#34;</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Count of Cases (log 10 scale)&#34;</span><span class="p">Ù«</span> 
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Data: The New York Times | Graph: @kjhealy&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">theme_minimal</span><span class="p">()</span>
<span class="c1">#&gt; Don&#39;t know how to automatically pick scale for object of type difftime. Defaulting to continuous.</span>
<span class="c1">#&gt; Warning: Transformation introduced infinite values in continuous y-axis</span>
</code></pre></td></tr></table>
</div>
</div><figure>
    <img src="https://kieranhealy.org/files/misc/nyt-covid-county-sm.png"
         alt="County-level plot faceted by stateÙ« from the New York Times data."/> <figcaption>
            <p>County-level plot faceted by stateÙ« from the New York Times data.</p>
        </figcaption>
</figure>
'),('https://kieranhealy.org/blog/archives/2020/03/28/this-is-just-to-try-to-say/', 'This Is Just to Try to Say', '1585407255000',  15, '<p>This is Just to Say</p>
<p>I have â€¦ nnn ;<br>
the â€¦ uâ€¦s<br>
that â€”â€” in<br>
eâ€”boÙ« Ù« ; ~ ~</p>
<p>and wâ€”&lt;â€¦<br>
you /â€“ /â€“ /â€“<br>
saving<br>
; :       :      ~ ~ ~</p>
<p>Forgive me<br>
th[ â€” @ râ€”]<br>
so â€¦ ~<br>
â€¦ so cold</p>
'),('https://kieranhealy.org/blog/archives/2020/03/27/a-covid-small-multiple/', 'A COVID Small Multiple', '1585321358000',  15, '<p>John Burn-Murdoch has been doing <a href="https://www.ft.com/coronavirus-latest">very good work at the Financial Times</a> producing various visualizations of the progress of COVID-19. One of his recent images is a small-multiple plot of cases by countryÙ« showing the trajectory of the outbreak for a large number of countriesÙ« with a the background of each small-multiple panel also showing (in grey) the trajectory of every other country for comparison. It&rsquo;s a useful technique. In this exampleÙ« I&rsquo;ll draw a version of it in R and ggplot. The main difference is that instead of ordering the panels alphabetically by countryÙ« I&rsquo;ll order them from highest to lowest current reported cases.</p>
<p>Here&rsquo;s the figure we&rsquo;ll end up with:</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/cov_case_sm.png"
         alt="covid small multiple"/> <figcaption>
            <p>Cumulative reported COVID-19 cases to dateÙ« top 50 Countries</p>
        </figcaption>
</figure>
<p>There are two small tricks. FirstÙ« getting <em>all</em> the data to show (in grey) in each panel while highlighting just <em>one</em> country. SecondÙ« for reasons of spaceÙ« moving the panel labels (in ggplot&rsquo;s terminologyÙ« the strip labels) inside the panelsÙ« in order to tighten up the space a bit. Doing this is really the same trick both timesÙ« vizÙ« creating a some mini-datasets to use for particular layers of the plot.</p>
<p>The code for this (including code to pull the data) is in <a href="https://github.com/kjhealy/covid">my COVID GitHub repository</a>. See the <a href="https://github.com/kjhealy/covid">repo</a> for details on downloading and cleaning it. Just this morning the ECDC changed how it&rsquo;s supplying its dataÙ« moving from an Excel file to your choice of JSONÙ« CSVÙ« or XMLÙ« so <a href="https://kieranhealy.org/blog/archives/2020/03/21/covid-19-tracking/">this earlier post walking through the process for the Excel file</a> is already out of date for the downloading step. There&rsquo;s a new function in the repoÙ« though.</p>
<p>We&rsquo;ll start with the data mostly cleaned and organized.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="o">&gt;</span> <span class="n">covid</span>
<span class="c1"># A tibble: 7Ù«320 x 14</span>
   <span class="n">date_rep</span>     <span class="n">day</span> <span class="n">month</span>  <span class="n">year</span> <span class="n">cases</span> <span class="n">deaths</span> <span class="n">countries_and_territories</span> <span class="n">geo_id</span> <span class="n">countryterritory_code</span> <span class="n">pop_data2018</span> <span class="n">date</span>       <span class="n">iso2</span>  <span class="n">iso3</span>  <span class="n">cname</span>      
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>      <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>                     <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>                        <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">date</span><span class="o">&gt;</span>     <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>      
 <span class="m">1</span> <span class="m">28</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">28</span>     <span class="m">3</span>  <span class="m">2020</span>    <span class="m">16</span>      <span class="m">1</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-28</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">2</span> <span class="m">27</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">27</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-27</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">3</span> <span class="m">26</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">26</span>     <span class="m">3</span>  <span class="m">2020</span>    <span class="m">33</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-26</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">4</span> <span class="m">25</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">25</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">2</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-25</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">5</span> <span class="m">24</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">24</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">6</span>      <span class="m">1</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-24</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">6</span> <span class="m">23</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">23</span>     <span class="m">3</span>  <span class="m">2020</span>    <span class="m">10</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-23</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">7</span> <span class="m">22</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">22</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-22</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">8</span> <span class="m">21</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">21</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">2</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-21</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">9</span> <span class="m">20</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">20</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-20</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
<span class="m">10</span> <span class="m">19</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">19</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-19</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
<span class="c1"># â€¦ with 7Ù«310 more rows</span>
</code></pre></td></tr></table>
</div>
</div>

<p>This is the data as we get it from the ECDCÙ« with some cleaning of the country codes and the date format. We&rsquo;ll calculate some cumulative totals and do some final recoding of the country labels.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">cov_case_curve</span> <span class="o">&lt;-</span> <span class="n">covid</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">date</span><span class="p">Ù«</span> <span class="n">cname</span><span class="p">Ù«</span> <span class="n">iso3</span><span class="p">Ù«</span> <span class="n">cases</span><span class="p">Ù«</span> <span class="n">deaths</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">drop_na</span><span class="p">(</span><span class="n">iso3</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">iso3</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">arrange</span><span class="p">(</span><span class="n">date</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">cu_cases</span> <span class="o">=</span> <span class="nf">cumsum</span><span class="p">(</span><span class="n">cases</span><span class="p">)Ù«</span> 
         <span class="n">cu_deaths</span> <span class="o">=</span> <span class="nf">cumsum</span><span class="p">(</span><span class="n">deaths</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">cu_cases</span> <span class="o">&gt;</span> <span class="m">99</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">days_elapsed</span> <span class="o">=</span> <span class="n">date</span> <span class="o">-</span> <span class="nf">min</span><span class="p">(</span><span class="n">date</span><span class="p">)Ù«</span>
          <span class="n">end_label</span> <span class="o">=</span> <span class="nf">ifelse</span><span class="p">(</span><span class="n">date</span> <span class="o">==</span> <span class="nf">max</span><span class="p">(</span><span class="n">date</span><span class="p">)Ù«</span> <span class="n">cname</span><span class="p">Ù«</span> <span class="kc">NA</span><span class="p">)Ù«</span>
          <span class="n">end_label</span> <span class="o">=</span> <span class="nf">recode</span><span class="p">(</span><span class="n">end_label</span><span class="p">Ù«</span> <span class="n">`United States`</span> <span class="o">=</span> <span class="s">&#34;USA&#34;</span><span class="p">Ù«</span>
                        <span class="n">`IranÙ« Islamic Republic of`</span> <span class="o">=</span> <span class="s">&#34;Iran&#34;</span><span class="p">Ù«</span> 
                        <span class="n">`KoreaÙ« Republic of`</span> <span class="o">=</span> <span class="s">&#34;South Korea&#34;</span><span class="p">Ù«</span> 
                        <span class="n">`United Kingdom`</span> <span class="o">=</span> <span class="s">&#34;UK&#34;</span><span class="p">)Ù«</span>
         <span class="n">cname</span> <span class="o">=</span> <span class="nf">recode</span><span class="p">(</span><span class="n">cname</span><span class="p">Ù«</span> <span class="n">`United States`</span> <span class="o">=</span> <span class="s">&#34;USA&#34;</span><span class="p">Ù«</span>
                        <span class="n">`IranÙ« Islamic Republic of`</span> <span class="o">=</span> <span class="s">&#34;Iran&#34;</span><span class="p">Ù«</span> 
                        <span class="n">`KoreaÙ« Republic of`</span> <span class="o">=</span> <span class="s">&#34;South Korea&#34;</span><span class="p">Ù«</span> 
                        <span class="n">`United Kingdom`</span> <span class="o">=</span> <span class="s">&#34;UK&#34;</span><span class="p">))</span>
                        
<span class="o">&gt;</span> <span class="n">cov_case_curve</span>
<span class="c1"># A tibble: 1Ù«262 x 9</span>
<span class="c1"># Groups:   iso3 [97]</span>
   <span class="n">date</span>       <span class="n">cname</span> <span class="n">iso3</span>  <span class="n">cases</span> <span class="n">deaths</span> <span class="n">cu_cases</span> <span class="n">cu_deaths</span> <span class="n">days_elapsed</span> <span class="n">end_label</span>
   <span class="o">&lt;</span><span class="n">date</span><span class="o">&gt;</span>     <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>    <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>     <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">drtn</span><span class="o">&gt;</span>       <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>    
 <span class="m">1</span> <span class="m">2020-01-19</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">136</span>      <span class="m">1</span>      <span class="m">216</span>         <span class="m">3</span> <span class="m">0</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">2</span> <span class="m">2020-01-20</span> <span class="n">China</span> <span class="n">CHN</span>      <span class="m">19</span>      <span class="m">0</span>      <span class="m">235</span>         <span class="m">3</span> <span class="m">1</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">3</span> <span class="m">2020-01-21</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">151</span>      <span class="m">3</span>      <span class="m">386</span>         <span class="m">6</span> <span class="m">2</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">4</span> <span class="m">2020-01-22</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">140</span>     <span class="m">11</span>      <span class="m">526</span>        <span class="m">17</span> <span class="m">3</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">5</span> <span class="m">2020-01-23</span> <span class="n">China</span> <span class="n">CHN</span>      <span class="m">97</span>      <span class="m">0</span>      <span class="m">623</span>        <span class="m">17</span> <span class="m">4</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">6</span> <span class="m">2020-01-24</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">259</span>      <span class="m">9</span>      <span class="m">882</span>        <span class="m">26</span> <span class="m">5</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">7</span> <span class="m">2020-01-25</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">441</span>     <span class="m">15</span>     <span class="m">1323</span>        <span class="m">41</span> <span class="m">6</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">8</span> <span class="m">2020-01-26</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">665</span>     <span class="m">15</span>     <span class="m">1988</span>        <span class="m">56</span> <span class="m">7</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">9</span> <span class="m">2020-01-27</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">787</span>     <span class="m">25</span>     <span class="m">2775</span>        <span class="m">81</span> <span class="m">8</span> <span class="n">days</span>       <span class="kc">NA</span>       
<span class="m">10</span> <span class="m">2020-01-28</span> <span class="n">China</span> <span class="n">CHN</span>    <span class="m">1753</span>     <span class="m">25</span>     <span class="m">4528</span>       <span class="m">106</span> <span class="m">9</span> <span class="n">days</span>       <span class="kc">NA</span>       
<span class="c1"># â€¦ with 1Ù«252 more rows                        </span>

</code></pre></td></tr></table>
</div>
</div>

<p>Then we pick out the top 50 countriesÙ« isolating their maximum case value.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="c1">## Top 50 countries by &gt;&gt; 100 casesÙ« let&#39;s say. </span>
<span class="n">top_50</span> <span class="o">&lt;-</span> <span class="n">cov_case_curve</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">cname</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">cu_cases</span> <span class="o">==</span> <span class="nf">max</span><span class="p">(</span><span class="n">cu_cases</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">ungroup</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">top_n</span><span class="p">(</span><span class="m">50</span><span class="p">Ù«</span> <span class="n">cu_cases</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">iso3</span><span class="p">Ù«</span> <span class="n">cname</span><span class="p">Ù«</span> <span class="n">cu_cases</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">days_elapsed</span> <span class="o">=</span> <span class="m">1</span><span class="p">Ù«</span> 
             <span class="n">cu_cases</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">cov_case_curve</span><span class="o">$</span><span class="n">cu_cases</span><span class="p">)</span> <span class="o">-</span> <span class="m">1e4</span><span class="p">)</span> 


<span class="o">&gt;</span> <span class="n">top_50</span>

<span class="c1"># A tibble: 50 x 4</span>
   <span class="n">iso3</span>  <span class="n">cname</span>     <span class="n">cu_cases</span> <span class="n">days_elapsed</span>
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>        <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>        <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>
 <span class="m">1</span> <span class="n">PAK</span>   <span class="n">Pakistan</span>     <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">2</span> <span class="n">THA</span>   <span class="n">Thailand</span>     <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">3</span> <span class="n">ARG</span>   <span class="n">Argentina</span>    <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">4</span> <span class="n">AUS</span>   <span class="n">Australia</span>    <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">5</span> <span class="n">AUT</span>   <span class="n">Austria</span>      <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">6</span> <span class="n">BEL</span>   <span class="n">Belgium</span>      <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">7</span> <span class="n">BRA</span>   <span class="n">Brazil</span>       <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">8</span> <span class="n">CAN</span>   <span class="n">Canada</span>       <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">9</span> <span class="n">CHL</span>   <span class="n">Chile</span>        <span class="m">94686</span>            <span class="m">1</span>
<span class="m">10</span> <span class="n">CHN</span>   <span class="n">China</span>        <span class="m">94686</span>            <span class="m">1</span>
<span class="c1"># â€¦ with 40 more rows</span>
</code></pre></td></tr></table>
</div>
</div>

<p>This gives us our label layer. We&rsquo;ve set <code>days_elapsed</code> and <code>cu_cases</code> values to the same thing for every countryÙ« because these are the x and y locations where the country labels will go.</p>
<p>NextÙ« a data layer for the grey line traces and a data layer for the little endpoints at the current case-count value.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">cov_case_curve_bg</span> <span class="o">&lt;-</span> <span class="n">cov_case_curve</span> <span class="o">%&gt;%</span> 
  <span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">cname</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">iso3</span> <span class="o">%in%</span> <span class="n">top_50</span><span class="o">$</span><span class="n">iso3</span><span class="p">)</span> 

<span class="n">cov_case_curve_endpoints</span> <span class="o">&lt;-</span> <span class="n">cov_case_curve</span> <span class="o">%&gt;%</span> 
  <span class="nf">filter</span><span class="p">(</span><span class="n">iso3</span> <span class="o">%in%</span> <span class="n">top_50</span><span class="o">$</span><span class="n">iso3</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">iso3</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">cu_cases</span> <span class="o">==</span> <span class="nf">max</span><span class="p">(</span><span class="n">cu_cases</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">cname</span><span class="p">Ù«</span> <span class="n">iso3</span><span class="p">Ù«</span> <span class="n">days_elapsed</span><span class="p">Ù«</span> <span class="n">cu_cases</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">ungroup</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div>

<p>We drop <code>cname</code> in the <code>cov_case_curve_bg</code> layerÙ« because we&rsquo;re going to facet by that value with the main dataset in a moment. That&rsquo;s the trick that allows the traces for all the countries to appear in each panel.</p>
<p>And now we can draw the plot.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="hl"><span class="lnt"> 5
</span></span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="hl"><span class="lnt"> 9
</span></span><span class="lnt">10
</span><span class="lnt">11
</span><span class="hl"><span class="lnt">12
</span></span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="hl"><span class="lnt">19
</span></span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="hl"><span class="lnt">27
</span></span><span class="lnt">28
</span><span class="hl"><span class="lnt">29
</span></span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="hl"><span class="lnt">39
</span></span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">cov_case_sm</span> <span class="o">&lt;-</span> <span class="n">cov_case_curve</span>  <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">iso3</span> <span class="o">%in%</span> <span class="n">top_50</span><span class="o">$</span><span class="n">iso3</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">ggplot</span><span class="p">(</span><span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">days_elapsed</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="n">cu_cases</span><span class="p">))</span> <span class="o">+</span> 
<span class="hl">  <span class="c1"># The line traces for every countryÙ« in every panel</span>
</span>  <span class="nf">geom_line</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">cov_case_curve_bg</span><span class="p">Ù«</span> 
            <span class="nf">aes</span><span class="p">(</span><span class="n">group</span> <span class="o">=</span> <span class="n">iso3</span><span class="p">)Ù«</span>
            <span class="n">size</span> <span class="o">=</span> <span class="m">0.15</span><span class="p">Ù«</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;gray80&#34;</span><span class="p">)</span> <span class="o">+</span> 
<span class="hl">  <span class="c1"># The line trace in redÙ« for the country in any given panel</span>
</span>  <span class="nf">geom_line</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="s">&#34;firebrick&#34;</span><span class="p">Ù«</span>
            <span class="n">lineend</span> <span class="o">=</span> <span class="s">&#34;round&#34;</span><span class="p">)</span> <span class="o">+</span> 
<span class="hl">  <span class="c1"># The point at the end. Bonus trick: some points can have fills!</span>
</span>  <span class="nf">geom_point</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">cov_case_curve_endpoints</span><span class="p">Ù«</span> 
             <span class="n">size</span> <span class="o">=</span> <span class="m">1.1</span><span class="p">Ù«</span> 
             <span class="n">shape</span> <span class="o">=</span> <span class="m">21</span><span class="p">Ù«</span> 
             <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;firebrick&#34;</span><span class="p">Ù«</span>
             <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;firebrick2&#34;</span>
             <span class="p">)</span> <span class="o">+</span> 
<span class="hl">  <span class="c1"># The country label inside the panelÙ« in lieu of the strip label</span>
</span>  <span class="nf">geom_text</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">top_50</span><span class="p">Ù«</span> 
             <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">label</span> <span class="o">=</span> <span class="n">cname</span><span class="p">)Ù«</span> 
             <span class="n">vjust</span> <span class="o">=</span> <span class="s">&#34;inward&#34;</span><span class="p">Ù«</span> 
             <span class="n">hjust</span> <span class="o">=</span> <span class="s">&#34;inward&#34;</span><span class="p">Ù«</span>
             <span class="n">fontface</span> <span class="o">=</span> <span class="s">&#34;bold&#34;</span><span class="p">Ù«</span> 
             <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;firebrick&#34;</span><span class="p">Ù«</span> 
             <span class="n">size</span> <span class="o">=</span> <span class="m">2.1</span><span class="p">)</span> <span class="o">+</span> 
<span class="hl">  <span class="c1"># Log transform and friendly labels</span>
</span>  <span class="nf">scale_y_log10</span><span class="p">(</span><span class="n">labels</span> <span class="o">=</span> <span class="n">scales</span><span class="o">::</span><span class="nf">label_number_si</span><span class="p">())</span> <span class="o">+</span> 
<span class="hl">  <span class="c1"># Facet by countryÙ« order from high to low</span>
</span>  <span class="nf">facet_wrap</span><span class="p">(</span><span class="o">~</span> <span class="nf">reorder</span><span class="p">(</span><span class="n">cname</span><span class="p">Ù«</span> <span class="o">-</span><span class="n">cu_cases</span><span class="p">)Ù«</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">5</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Days Since 100th Confirmed Case&#34;</span><span class="p">Ù«</span> 
       <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Cumulative Number of Cases (log10 scale)&#34;</span><span class="p">Ù«</span> 
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Cumulative Number of Reported Cases of COVID-19: Top 50 Countries&#34;</span><span class="p">Ù«</span> 
       <span class="n">subtitle</span> <span class="o">=</span> <span class="nf">paste</span><span class="p">(</span><span class="s">&#34;Data as of&#34;</span><span class="p">Ù«</span> <span class="nf">format</span><span class="p">(</span><span class="nf">max</span><span class="p">(</span><span class="n">cov_curve</span><span class="o">$</span><span class="n">date</span><span class="p">)Ù«</span> <span class="s">&#34;%AÙ« %B %eÙ« %Y&#34;</span><span class="p">))Ù«</span> 
        <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Kieran Healy @kjhealy / Data: https://www.ecdc.europa.eu/&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">theme</span><span class="p">(</span><span class="n">plot.title</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1</span><span class="p">)Ù«</span> <span class="n">face</span> <span class="o">=</span> <span class="s">&#34;bold&#34;</span><span class="p">)Ù«</span>
          <span class="n">plot.subtitle</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">0.7</span><span class="p">))Ù«</span>
          <span class="n">plot.caption</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1</span><span class="p">))Ù«</span>
<span class="hl">          <span class="c1"># turn off the strip label and tighten the panel spacing</span>
</span>          <span class="n">strip.text</span> <span class="o">=</span> <span class="nf">element_blank</span><span class="p">()Ù«</span>
          <span class="n">panel.spacing.x</span> <span class="o">=</span> <span class="nf">unit</span><span class="p">(</span><span class="m">-0.05</span><span class="p">Ù«</span> <span class="s">&#34;lines&#34;</span><span class="p">)Ù«</span>
          <span class="n">panel.spacing.y</span> <span class="o">=</span> <span class="nf">unit</span><span class="p">(</span><span class="m">0.3</span><span class="p">Ù«</span> <span class="s">&#34;lines&#34;</span><span class="p">)Ù«</span>
          <span class="n">axis.text.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">0.5</span><span class="p">))Ù«</span>
          <span class="n">axis.title.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1</span><span class="p">))Ù«</span>
          <span class="n">axis.title.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1</span><span class="p">))Ù«</span>
          <span class="n">axis.text.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">0.5</span><span class="p">))Ù«</span>
          <span class="n">legend.text</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1</span><span class="p">)))</span>

<span class="nf">ggsave</span><span class="p">(</span><span class="s">&#34;figures/cov_case_sm.png&#34;</span><span class="p">Ù«</span> 
       <span class="n">cov_case_sm</span><span class="p">Ù«</span> <span class="n">width</span> <span class="o">=</span> <span class="m">10</span><span class="p">Ù«</span> <span class="n">height</span> <span class="o">=</span> <span class="m">12</span><span class="p">Ù«</span> <span class="n">dpi</span> <span class="o">=</span> <span class="m">300</span><span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div>'),('https://kieranhealy.org/blog/archives/2020/03/21/covid-19-tracking/', 'Covid 19 Tracking', '1584819904000',  15, '<h2 id="get-your-epidemiology-from-epidemiologists">Get Your Epidemiology from Epidemiologists</h2>
<p>The COVID-19 pandemic continues to rage. I&rsquo;m strongly committed to what should be the uncontroversial view that we should listen to the recommendations of those institutions and individuals with strong expertise in the relevant fields of Public HealthÙ« EpidemiologyÙ« Disease ControlÙ« and Infection Modeling. I also think that the open availability of dataÙ« and the free availability of methods to look at dataÙ« is generally a good thing. The tricky part is when these potentially conflict. For exampleÙ« in a period of crisis it is reasonable to want to find out what&rsquo;s happening and to inform yourself as much as possible about how events are unfolding. People who work with data of some sort will naturally want to look at the available trends themselves. But maybe those same people don&rsquo;t know a great deal about how disease worksÙ« or how information about it is collected and processedÙ« or what is likely to happen in a situation like the one we&rsquo;re experiencing. At such timesÙ« there&rsquo;s a balance to be struck between using the available tools to come to an informed opinion and recklessly mucking about with data when you don&rsquo;t really know what you&rsquo;re doing. This is especially important whenÙ« as is the case nowÙ« the Executive response to the crisis in the United States (and in several other countries) has been criminally irresponsibleÙ« to the point where even elementary facts about the spread of the disease over the past few months are being distorted.</p>
<p>Speaking for myselfÙ« I definitely want look at what the trends are and I prefer to do so by working directly with the data that official agencies and reliable reporting produces. So in this post I&rsquo;ll show how I&rsquo;m doing that. But I definitely <em>don&rsquo;t</em> want to publicly mess around beyond this. While I might idly fit some models or play with various extrapolations of the data in the privacy of my own homeÙ« I&rsquo;m very conscious that I am not in a position to do this in a professional capacity. So I will firmly set that aside here. There are already many well-qualified people working publicly to actually analyze and model the dataÙ« as opposed to looking descriptively at what is happening. For a very good overview of some of the challenges and standard approaches to modeling and forecasting epidemicsÙ« read <a href="https://robjhyndman.com/hyndsight/forecasting-covid19/">Rob Hyndman&rsquo;s excellent post</a>. His summary is particularly useful (and cautionary) for anyone coming to the data from e.g. an Econometric or Time Series point of view where it&rsquo;s natural to think in terms of forecasting with lagged variables.</p>
<p>AnywayÙ« I just want to get an overview of best-available counts of deaths. I&rsquo;m going to show you how to get the data to draw this graph.</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/covid_cumulative_22-03-20.png"
         alt="Cumulative COVID-19 Deaths"/> <figcaption>
            <p>Cumulative COVID-19 Deaths</p>
        </figcaption>
</figure>
<h2 id="looking-at-covid-19-data-from-the-european-centers-for-disease-control">Looking at COVID-19 Data from the European Centers for Disease Control</h2>
<p>Each dayÙ« the <a href="https://www.ecdc.europa.eu">ECDC</a> publishes a <a href="https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide">a summary spreadsheet of global case and death counts</a> since the beginning of the epidemic. This is good data collated by an EU-wide agencyÙ« and it&rsquo;s what I&rsquo;ve been using to keep up with the trends. There are other reliable sourcesÙ« tooÙ« most notably the <a href="https://coronavirus.jhu.edu/map.html">Johns Hopkins Coronavirus Dashboard</a>. Here&rsquo;s what I&rsquo;ve been doing to get it into R. Again my principal reason for sharing this code is <em>not</em> to add much of anything on the public side. It&rsquo;s much more of a pedagogical exercise. If you want to look at this dataÙ« here&rsquo;s one way to do that. Along the way I&rsquo;ll talk about a few of the things needed to work with the data in a reasonably clean way. Then I&rsquo;ll end up drawing the plot that everyone draws&mdash;showing cumulative trends by country in deathsÙ« counted in days since a threshold level of fatalities.</p>
<h2 id="preparation">Preparation</h2>
<p>First we load some libraries to help us out.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">lubridate</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">here</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">janitor</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">socviz</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">ggrepel</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">paletteer</span><span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div>

<p>NextÙ« we set things up by writing some functions that will help us grab and clean the data. In realityÙ« of courseÙ« these functions got written piecemeal and were then cleaned up and moved to the front of the file. I didn&rsquo;t sit down and write them off the top of my head.</p>
<p>The first one is going to grab the spreadsheet from the ECDC and both save the <code>.xlsx</code> file to our <code>data/</code> folder and create a tibble of the results.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="c1">## Download today&#39;s excel fileÙ« saving it to data/ and reading it in</span>
<span class="n">get_ecdc_data</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">url</span> <span class="o">=</span> <span class="s">&#34;https://www.ecdc.europa.eu/sites/default/files/documents/&#34;</span><span class="p">Ù«</span>
                          <span class="n">fname</span> <span class="o">=</span> <span class="s">&#34;COVID-19-geographic-distribution-worldwide-&#34;</span><span class="p">Ù«</span> 
                          <span class="n">date</span> <span class="o">=</span> <span class="n">lubridate</span><span class="o">::</span><span class="nf">today</span><span class="p">()Ù«</span> 
                          <span class="n">ext</span> <span class="o">=</span> <span class="s">&#34;xlsx&#34;</span><span class="p">Ù«</span> 
                          <span class="n">dest</span> <span class="o">=</span> <span class="s">&#34;data&#34;</span><span class="p">)</span> <span class="p">{</span>
  
  <span class="n">target</span> <span class="o">&lt;-</span>  <span class="nf">paste0</span><span class="p">(</span><span class="n">url</span><span class="p">Ù«</span> <span class="n">fname</span><span class="p">Ù«</span> <span class="n">date</span><span class="p">Ù«</span> <span class="s">&#34;.&#34;</span><span class="p">Ù«</span> <span class="n">ext</span><span class="p">)</span>
  <span class="nf">message</span><span class="p">(</span><span class="s">&#34;target: &#34;</span><span class="p">Ù«</span> <span class="n">target</span><span class="p">)</span>

  <span class="n">destination</span> <span class="o">&lt;-</span> <span class="n">fs</span><span class="o">::</span><span class="nf">path</span><span class="p">(</span><span class="n">here</span><span class="o">::</span><span class="nf">here</span><span class="p">(</span><span class="s">&#34;data&#34;</span><span class="p">)Ù«</span> <span class="nf">paste0</span><span class="p">(</span><span class="n">fname</span><span class="p">Ù«</span> <span class="n">date</span><span class="p">)Ù«</span> <span class="n">ext</span> <span class="o">=</span> <span class="n">ext</span><span class="p">)</span>
  <span class="nf">message</span><span class="p">(</span><span class="s">&#34;saving to: &#34;</span><span class="p">Ù«</span> <span class="n">destination</span><span class="p">)</span>
  
  <span class="n">tf</span> <span class="o">&lt;-</span> <span class="nf">tempfile</span><span class="p">(</span><span class="n">fileext</span> <span class="o">=</span> <span class="n">ext</span><span class="p">)</span>
  <span class="n">curl</span><span class="o">::</span><span class="nf">curl_download</span><span class="p">(</span><span class="n">target</span><span class="p">Ù«</span> <span class="n">tf</span><span class="p">)</span>
  <span class="n">fs</span><span class="o">::</span><span class="nf">file_copy</span><span class="p">(</span><span class="n">tf</span><span class="p">Ù«</span> <span class="n">destination</span><span class="p">)</span>
  
  <span class="nf">switch</span><span class="p">(</span><span class="n">ext</span><span class="p">Ù«</span> 
  <span class="n">xls</span> <span class="o">=</span> <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">(</span><span class="n">readxl</span><span class="o">::</span><span class="nf">read_xls</span><span class="p">(</span><span class="n">tf</span><span class="p">))Ù«</span>
  <span class="n">xlsx</span> <span class="o">=</span> <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">(</span><span class="n">readxl</span><span class="o">::</span><span class="nf">read_xlsx</span><span class="p">(</span><span class="n">tf</span><span class="p">))</span>
  <span class="p">)</span>
<span class="p">}</span>                          

</code></pre></td></tr></table>
</div>
</div>

<p>Things to notice: We have to  use <code>curl_download()</code> to get the fileÙ« because <code>read_xls</code> cannot directly grab an Excel file from a URL in the way that e.g. <code>read_csv()</code> can for a <code>.csv</code> file. So we create a temporary file handle and use <code>curl</code> to download the data file to it. Then we copy the file to its permanent home in our <code>data/</code> folderÙ« and we read the target file into R with the appropriate <code>readxl</code> function.</p>
<p>As we&rsquo;ll see in a momentÙ« the country codes contained in the ECDC data are not quite standard. It will be useful in the long run to make sure that every country has standardized two- and three-letter abbreviations. Some of the countries in the ECDC&rsquo;s <code>geo_id</code> variable are missing these. This is a very common situation in data cleaningÙ« where we have a big table with some data we know is missing (e.g.Ù« a country code)Ù« <em>and</em> we know for sure which cases the data are missing forÙ« <em>and</em> we have a little lookup table that can fill in the blanks. The operation we will need to perform here is called a <em>coalescing join</em>. Before I knew that&rsquo;s what it was calledÙ« I used to do this manually (I&rsquo;ll show you below). But a little googling eventually revealed both the proper name for this operation and also a very useful functionÙ« written by <a href="https://alistaire.rbind.io">Edward Visel</a> that does <a href="https://alistaire.rbind.io/blog/coalescing-joins/">exactly what I want</a>:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">coalesce_join</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">Ù«</span> <span class="n">y</span><span class="p">Ù«</span> 
                          <span class="n">by</span> <span class="o">=</span> <span class="kc">NULL</span><span class="p">Ù«</span> <span class="n">suffix</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;.x&#34;</span><span class="p">Ù«</span> <span class="s">&#34;.y&#34;</span><span class="p">)Ù«</span> 
                          <span class="n">join</span> <span class="o">=</span> <span class="n">dplyr</span><span class="o">::</span><span class="n">full_join</span><span class="p">Ù«</span> <span class="kc">...</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">joined</span> <span class="o">&lt;-</span> <span class="nf">join</span><span class="p">(</span><span class="n">x</span><span class="p">Ù«</span> <span class="n">y</span><span class="p">Ù«</span> <span class="n">by</span> <span class="o">=</span> <span class="n">by</span><span class="p">Ù«</span> <span class="n">suffix</span> <span class="o">=</span> <span class="n">suffix</span><span class="p">Ù«</span> <span class="kc">...</span><span class="p">)</span>
    <span class="c1"># names of desired output</span>
    <span class="n">cols</span> <span class="o">&lt;-</span> <span class="n">dplyr</span><span class="o">::</span><span class="nf">union</span><span class="p">(</span><span class="nf">names</span><span class="p">(</span><span class="n">x</span><span class="p">)Ù«</span> <span class="nf">names</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    
    <span class="n">to_coalesce</span> <span class="o">&lt;-</span> <span class="nf">names</span><span class="p">(</span><span class="n">joined</span><span class="p">)</span><span class="n">[</span><span class="o">!</span><span class="nf">names</span><span class="p">(</span><span class="n">joined</span><span class="p">)</span> <span class="o">%in%</span> <span class="n">cols]</span>
    <span class="n">suffix_used</span> <span class="o">&lt;-</span> <span class="n">suffix</span><span class="nf">[ifelse</span><span class="p">(</span><span class="nf">endsWith</span><span class="p">(</span><span class="n">to_coalesce</span><span class="p">Ù«</span> <span class="n">suffix[1]</span><span class="p">)Ù«</span> <span class="m">1</span><span class="p">Ù«</span> <span class="m">2</span><span class="p">)</span><span class="n">]</span>
    <span class="c1"># remove suffixes and deduplicate</span>
    <span class="n">to_coalesce</span> <span class="o">&lt;-</span> <span class="nf">unique</span><span class="p">(</span><span class="nf">substr</span><span class="p">(</span>
        <span class="n">to_coalesce</span><span class="p">Ù«</span> 
        <span class="m">1</span><span class="p">Ù«</span> 
        <span class="nf">nchar</span><span class="p">(</span><span class="n">to_coalesce</span><span class="p">)</span> <span class="o">-</span> <span class="nf">nchar</span><span class="p">(</span><span class="n">suffix_used</span><span class="p">)</span>
    <span class="p">))</span>
    
    <span class="n">coalesced</span> <span class="o">&lt;-</span> <span class="n">purrr</span><span class="o">::</span><span class="nf">map_dfc</span><span class="p">(</span><span class="n">to_coalesce</span><span class="p">Ù«</span> <span class="o">~</span><span class="n">dplyr</span><span class="o">::</span><span class="nf">coalesce</span><span class="p">(</span>
        <span class="n">joined[</span><span class="nf">[paste0</span><span class="p">(</span><span class="n">.x</span><span class="p">Ù«</span> <span class="n">suffix[1]</span><span class="p">)</span><span class="n">]]</span><span class="p">Ù«</span> 
        <span class="n">joined[</span><span class="nf">[paste0</span><span class="p">(</span><span class="n">.x</span><span class="p">Ù«</span> <span class="n">suffix[2]</span><span class="p">)</span><span class="n">]]</span>
    <span class="p">))</span>
    <span class="nf">names</span><span class="p">(</span><span class="n">coalesced</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="n">to_coalesce</span>
    
    <span class="n">dplyr</span><span class="o">::</span><span class="nf">bind_cols</span><span class="p">(</span><span class="n">joined</span><span class="p">Ù«</span> <span class="n">coalesced</span><span class="p">)</span><span class="n">[cols]</span>
<span class="p">}</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Next we set up some country codes using ISO2 and ISO3 abbreviations.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">iso3_cnames</span> <span class="o">&lt;-</span> <span class="nf">read_csv</span><span class="p">(</span><span class="s">&#34;data/countries_iso3.csv&#34;</span><span class="p">)</span>
<span class="n">iso2_to_iso3</span> <span class="o">&lt;-</span> <span class="nf">read_csv</span><span class="p">(</span><span class="s">&#34;data/iso2_to_iso3.csv&#34;</span><span class="p">)</span>

<span class="n">cname_table</span> <span class="o">&lt;-</span> <span class="nf">left_join</span><span class="p">(</span><span class="n">iso3_cnames</span><span class="p">Ù«</span> <span class="n">iso2_to_iso3</span><span class="p">)</span>

<span class="n">cname_table</span>

<span class="c1"># A tibble: 249 x 3</span>
   <span class="n">iso3</span>  <span class="n">cname</span>               <span class="n">iso2</span> 
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>               <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>
 <span class="m">1</span> <span class="n">AFG</span>   <span class="n">Afghanistan</span>         <span class="n">AF</span>   
 <span class="m">2</span> <span class="n">ALA</span>   Ã…<span class="n">land</span> <span class="n">Islands</span>       <span class="n">AX</span>   
 <span class="m">3</span> <span class="n">ALB</span>   <span class="n">Albania</span>             <span class="n">AL</span>   
 <span class="m">4</span> <span class="n">DZA</span>   <span class="n">Algeria</span>             <span class="n">DZ</span>   
 <span class="m">5</span> <span class="n">ASM</span>   <span class="n">American</span> <span class="n">Samoa</span>      <span class="n">AS</span>   
 <span class="m">6</span> <span class="n">AND</span>   <span class="n">Andorra</span>             <span class="n">AD</span>   
 <span class="m">7</span> <span class="n">AGO</span>   <span class="n">Angola</span>              <span class="n">AO</span>   
 <span class="m">8</span> <span class="n">AIA</span>   <span class="n">Anguilla</span>            <span class="n">AI</span>   
 <span class="m">9</span> <span class="n">ATA</span>   <span class="n">Antarctica</span>          <span class="n">AQ</span>   
<span class="m">10</span> <span class="n">ATG</span>   <span class="n">Antigua</span> <span class="n">and</span> <span class="n">Barbuda</span> <span class="n">AG</span>   
<span class="c1"># â€¦ with 239 more rows</span>
<span class="n">eu</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;AUT&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BEL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BGR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;HRV&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CYP&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CZE&#34;</span><span class="p">Ù«</span> <span class="s">&#34;DNK&#34;</span><span class="p">Ù«</span> <span class="s">&#34;EST&#34;</span><span class="p">Ù«</span> <span class="s">&#34;FIN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;FRA&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;DEU&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GRC&#34;</span><span class="p">Ù«</span> <span class="s">&#34;HUN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;IRL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ITA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;LVA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;LTU&#34;</span><span class="p">Ù«</span> <span class="s">&#34;LUX&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MLT&#34;</span><span class="p">Ù«</span> <span class="s">&#34;NLD&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;POL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;PRT&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ROU&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SVK&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SVN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ESP&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SWE&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GBR&#34;</span><span class="p">)</span>

<span class="n">europe</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;ALB&#34;</span><span class="p">Ù«</span> <span class="s">&#34;AND&#34;</span><span class="p">Ù«</span> <span class="s">&#34;AUT&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BLR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BEL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BIH&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BGR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;HRV&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CYP&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CZE&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;DNK&#34;</span><span class="p">Ù«</span> <span class="s">&#34;EST&#34;</span><span class="p">Ù«</span> <span class="s">&#34;FRO&#34;</span><span class="p">Ù«</span> <span class="s">&#34;FIN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;FRA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;DEU&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GIB&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GRC&#34;</span><span class="p">Ù«</span> <span class="s">&#34;HUN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ISL&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;IRL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ITA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;LVA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;LIE&#34;</span><span class="p">Ù«</span> <span class="s">&#34;LTU&#34;</span><span class="p">Ù«</span> <span class="s">&#34;LUX&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MKD&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MLT&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MDA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MCO&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;NLD&#34;</span><span class="p">Ù«</span> <span class="s">&#34;NOR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;POL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;PRT&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ROU&#34;</span><span class="p">Ù«</span> <span class="s">&#34;RUS&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SMR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SRB&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SVK&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SVN&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;ESP&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SWE&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CHE&#34;</span><span class="p">Ù«</span> <span class="s">&#34;UKR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GBR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;VAT&#34;</span><span class="p">Ù«</span> <span class="s">&#34;RSB&#34;</span><span class="p">Ù«</span> <span class="s">&#34;IMN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MNE&#34;</span><span class="p">)</span>

<span class="n">north_america</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;AIA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ATG&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ABW&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BHS&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BRB&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BLZ&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BMU&#34;</span><span class="p">Ù«</span> <span class="s">&#34;VGB&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CAN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CYM&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;CRI&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CUB&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CUW&#34;</span><span class="p">Ù«</span> <span class="s">&#34;DMA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;DOM&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SLV&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GRL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GRD&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GLP&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GTM&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;HTI&#34;</span><span class="p">Ù«</span> <span class="s">&#34;HND&#34;</span><span class="p">Ù«</span> <span class="s">&#34;JAM&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MTQ&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MEX&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SPM&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MSR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ANT&#34;</span><span class="p">Ù«</span> <span class="s">&#34;KNA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;NIC&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;PAN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;PRI&#34;</span><span class="p">Ù«</span> <span class="s">&#34;KNA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;LCA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SPM&#34;</span><span class="p">Ù«</span> <span class="s">&#34;VCT&#34;</span><span class="p">Ù«</span> <span class="s">&#34;TTO&#34;</span><span class="p">Ù«</span> <span class="s">&#34;TCA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;VIR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;USA&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;SXM&#34;</span><span class="p">)</span>

<span class="n">south_america</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;ARG&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BOL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BRA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CHL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;COL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ECU&#34;</span><span class="p">Ù«</span> <span class="s">&#34;FLK&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GUF&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GUY&#34;</span><span class="p">Ù«</span> <span class="s">&#34;PRY&#34;</span><span class="p">Ù«</span>
                   <span class="s">&#34;PER&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SUR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;URY&#34;</span><span class="p">Ù«</span> <span class="s">&#34;VEN&#34;</span><span class="p">)</span>


<span class="n">africa</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;DZA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;AGO&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SHN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BEN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BWA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BFA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BDI&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CMR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CPV&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CAF&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;TCD&#34;</span><span class="p">Ù«</span> <span class="s">&#34;COM&#34;</span><span class="p">Ù«</span> <span class="s">&#34;COG&#34;</span><span class="p">Ù«</span> <span class="s">&#34;DJI&#34;</span><span class="p">Ù«</span> <span class="s">&#34;EGY&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GNQ&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ERI&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ETH&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GAB&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GMB&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;GHA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GNB&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GIN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CIV&#34;</span><span class="p">Ù«</span> <span class="s">&#34;KEN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;LSO&#34;</span><span class="p">Ù«</span> <span class="s">&#34;LBR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;LBY&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MDG&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MWI&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;MLI&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MRT&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MUS&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MYT&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MAR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MOZ&#34;</span><span class="p">Ù«</span> <span class="s">&#34;NAM&#34;</span><span class="p">Ù«</span> <span class="s">&#34;NER&#34;</span><span class="p">Ù«</span> <span class="s">&#34;NGA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;STP&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;REU&#34;</span><span class="p">Ù«</span> <span class="s">&#34;RWA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;STP&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SEN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SYC&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SLE&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SOM&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ZAF&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SHN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SDN&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;SWZ&#34;</span><span class="p">Ù«</span> <span class="s">&#34;TZA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;TGO&#34;</span><span class="p">Ù«</span> <span class="s">&#34;TUN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;UGA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;COD&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ZMB&#34;</span><span class="p">Ù«</span> <span class="s">&#34;TZA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ZWE&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SSD&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;COD&#34;</span><span class="p">)</span>

<span class="n">asia</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;AFG&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ARM&#34;</span><span class="p">Ù«</span> <span class="s">&#34;AZE&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BHR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BGD&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BTN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;BRN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;KHM&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CHN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;CXR&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;CCK&#34;</span><span class="p">Ù«</span> <span class="s">&#34;IOT&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GEO&#34;</span><span class="p">Ù«</span> <span class="s">&#34;HKG&#34;</span><span class="p">Ù«</span> <span class="s">&#34;IND&#34;</span><span class="p">Ù«</span> <span class="s">&#34;IDN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;IRN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;IRQ&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ISR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;JPN&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;JOR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;KAZ&#34;</span><span class="p">Ù«</span> <span class="s">&#34;PRK&#34;</span><span class="p">Ù«</span> <span class="s">&#34;KOR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;KWT&#34;</span><span class="p">Ù«</span> <span class="s">&#34;KGZ&#34;</span><span class="p">Ù«</span> <span class="s">&#34;LAO&#34;</span><span class="p">Ù«</span> <span class="s">&#34;LBN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MAC&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MYS&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;MDV&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MNG&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MMR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;NPL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;OMN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;PAK&#34;</span><span class="p">Ù«</span> <span class="s">&#34;PHL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;QAT&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SAU&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SGP&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;LKA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;SYR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;TWN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;TJK&#34;</span><span class="p">Ù«</span> <span class="s">&#34;THA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;TUR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;TKM&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ARE&#34;</span><span class="p">Ù«</span> <span class="s">&#34;UZB&#34;</span><span class="p">Ù«</span> <span class="s">&#34;VNM&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;YEM&#34;</span><span class="p">Ù«</span> <span class="s">&#34;PSE&#34;</span><span class="p">)</span>

<span class="n">oceania</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;ASM&#34;</span><span class="p">Ù«</span> <span class="s">&#34;AUS&#34;</span><span class="p">Ù«</span> <span class="s">&#34;NZL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;COK&#34;</span><span class="p">Ù«</span> <span class="s">&#34;FJI&#34;</span><span class="p">Ù«</span> <span class="s">&#34;PYF&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GUM&#34;</span><span class="p">Ù«</span> <span class="s">&#34;KIR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MNP&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MHL&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;FSM&#34;</span><span class="p">Ù«</span> <span class="s">&#34;UMI&#34;</span><span class="p">Ù«</span> <span class="s">&#34;NRU&#34;</span><span class="p">Ù«</span> <span class="s">&#34;NCL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;NZL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;NIU&#34;</span><span class="p">Ù«</span> <span class="s">&#34;NFK&#34;</span><span class="p">Ù«</span> <span class="s">&#34;PLW&#34;</span><span class="p">Ù«</span> <span class="s">&#34;PNG&#34;</span><span class="p">Ù«</span> <span class="s">&#34;MNP&#34;</span><span class="p">Ù«</span>
        <span class="s">&#34;SLB&#34;</span><span class="p">Ù«</span> <span class="s">&#34;TKL&#34;</span><span class="p">Ù«</span> <span class="s">&#34;TON&#34;</span><span class="p">Ù«</span> <span class="s">&#34;TUV&#34;</span><span class="p">Ù«</span> <span class="s">&#34;VUT&#34;</span><span class="p">Ù«</span> <span class="s">&#34;UMI&#34;</span><span class="p">Ù«</span> <span class="s">&#34;WLF&#34;</span><span class="p">Ù«</span> <span class="s">&#34;WSM&#34;</span><span class="p">Ù«</span> <span class="s">&#34;TLS&#34;</span><span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div>

<h2 id="now-actually-get-the-data">Now Actually Get the Data</h2>
<p>The next step is to read the data. The file <em>should</em> be called <code>COVID-19-geographic-distribution-worldwide-</code> with the date appended and the extension <code>.xlsx</code>. But as it turns out there is a typo in the filename. The <code>distribution</code> part is misspelled <code>disbtribution</code>. I think it must have been introduced early on in the data collection process and so far&mdash;possibly by accidentÙ« but also possibly so as not to break a thousand scripts like this one&mdash;they have not been fixing the typo.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">covid_raw</span> <span class="o">&lt;-</span> <span class="nf">get_ecdc_data</span><span class="p">(</span><span class="n">url</span> <span class="o">=</span> <span class="s">&#34;https://www.ecdc.europa.eu/sites/default/files/documents/&#34;</span><span class="p">Ù«</span>
                           <span class="n">fname</span> <span class="o">=</span> <span class="s">&#34;COVID-19-geographic-disbtribution-worldwide-&#34;</span><span class="p">Ù«</span>
                           <span class="n">ext</span> <span class="o">=</span> <span class="s">&#34;xlsx&#34;</span><span class="p">)</span>
<span class="n">covid_raw</span>

<span class="c1"># A tibble: 6Ù«012 x 8</span>
   <span class="n">date_rep</span>              <span class="n">day</span> <span class="n">month</span>  <span class="n">year</span> <span class="n">cases</span> <span class="n">deaths</span> <span class="n">countries_and_t</span>â€¦
   <span class="o">&lt;</span><span class="n">dttm</span><span class="o">&gt;</span>              <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>           
 <span class="m">1</span> <span class="m">2020-03-21</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">21</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">2</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">2</span> <span class="m">2020-03-20</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">20</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">3</span> <span class="m">2020-03-19</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">19</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">4</span> <span class="m">2020-03-18</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">18</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">1</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">5</span> <span class="m">2020-03-17</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">17</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">5</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">6</span> <span class="m">2020-03-16</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">16</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">6</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">7</span> <span class="m">2020-03-15</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">15</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">3</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">8</span> <span class="m">2020-03-11</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">11</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">3</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">9</span> <span class="m">2020-03-08</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>     <span class="m">8</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">3</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
<span class="m">10</span> <span class="m">2020-03-02</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>     <span class="m">2</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
<span class="c1"># â€¦ with 6Ù«002 more rowsÙ« and 1 more variable: geo_id &lt;chr&gt;</span>


</code></pre></td></tr></table>
</div>
</div>

<p>That&rsquo;s our base data. The <code>get_ecdc_data()</code> function uses <code>file_copy()</code> from the <code>fs</code> library to move the temporary file to the <code>data/</code> folder. It will not overwrite a file if it finds one with that name already there. So if you grab the data more than once a dayÙ« you&rsquo;ll need to decide what to do with the file you already downloaded.</p>
<p>The <code>geo_id</code> country code column isn&rsquo;t visible here. We&rsquo;re going to duplicate it (naming it <code>iso2</code>) and then join our table of two- and three-letter country codes. It has an <code>iso2</code> column as well.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">covid</span> <span class="o">&lt;-</span> <span class="n">covid_raw</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">date</span> <span class="o">=</span> <span class="n">lubridate</span><span class="o">::</span><span class="nf">ymd</span><span class="p">(</span><span class="n">date_rep</span><span class="p">)Ù«</span>
         <span class="n">iso2</span> <span class="o">=</span> <span class="n">geo_id</span><span class="p">)</span>

<span class="c1">## merge in the iso country names</span>
<span class="n">covid</span> <span class="o">&lt;-</span> <span class="nf">left_join</span><span class="p">(</span><span class="n">covid</span><span class="p">Ù«</span> <span class="n">cname_table</span><span class="p">)</span>

<span class="n">covid</span>

<span class="c1"># A tibble: 6Ù«012 x 12</span>
   <span class="n">date_rep</span>              <span class="n">day</span> <span class="n">month</span>  <span class="n">year</span> <span class="n">cases</span> <span class="n">deaths</span> <span class="n">countries_and_t</span>â€¦
   <span class="o">&lt;</span><span class="n">dttm</span><span class="o">&gt;</span>              <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>           
 <span class="m">1</span> <span class="m">2020-03-21</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">21</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">2</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">2</span> <span class="m">2020-03-20</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">20</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">3</span> <span class="m">2020-03-19</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">19</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">4</span> <span class="m">2020-03-18</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">18</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">1</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">5</span> <span class="m">2020-03-17</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">17</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">5</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">6</span> <span class="m">2020-03-16</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">16</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">6</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">7</span> <span class="m">2020-03-15</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">15</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">3</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">8</span> <span class="m">2020-03-11</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">11</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">3</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">9</span> <span class="m">2020-03-08</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>     <span class="m">8</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">3</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
<span class="m">10</span> <span class="m">2020-03-02</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>     <span class="m">2</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
<span class="c1"># â€¦ with 6Ù«002 more rowsÙ« and 5 more variables: geo_id &lt;chr&gt;Ù«</span>
<span class="c1">#   date &lt;date&gt;Ù« iso2 &lt;chr&gt;Ù« iso3 &lt;chr&gt;Ù« cname &lt;chr&gt;</span>

</code></pre></td></tr></table>
</div>
</div>

<p>At this point we can notice a couple of things about the dataset. For exampleÙ« not everything in the dataset is a country. This one&rsquo;s a cruise ship:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="c1">## Looks like a missing data code</span>
<span class="n">covid</span> <span class="o">%&gt;%</span> 
  <span class="nf">filter</span><span class="p">(</span><span class="n">cases</span> <span class="o">==</span> <span class="m">-9</span><span class="p">)</span>

<span class="c1"># A tibble: 1 x 12</span>
  <span class="n">date_rep</span>              <span class="n">day</span> <span class="n">month</span>  <span class="n">year</span> <span class="n">cases</span> <span class="n">deaths</span> <span class="n">countries_and_t</span>â€¦
  <span class="o">&lt;</span><span class="n">dttm</span><span class="o">&gt;</span>              <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>           
<span class="m">1</span> <span class="m">2020-03-10</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">10</span>     <span class="m">3</span>  <span class="m">2020</span>    <span class="m">-9</span>      <span class="m">1</span> <span class="n">Cases_on_an_int</span>â€¦
<span class="c1"># â€¦ with 5 more variables: geo_id &lt;chr&gt;Ù« date &lt;date&gt;Ù« iso2 &lt;chr&gt;Ù«</span>
<span class="c1">#   iso3 &lt;chr&gt;Ù« cname &lt;chr&gt;</span>

</code></pre></td></tr></table>
</div>
</div>

<p>We can also learnÙ« using an <code>anti_join()</code> that not all the ECDC&rsquo;s <code>geo_id</code> country codes match up with the ISO codes:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="nf">anti_join</span><span class="p">(</span><span class="n">covid</span><span class="p">Ù«</span> <span class="n">cname_table</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">geo_id</span><span class="p">Ù«</span> <span class="n">countries_and_territories</span><span class="p">Ù«</span> <span class="n">iso2</span><span class="p">Ù«</span> <span class="n">iso3</span><span class="p">Ù«</span> <span class="n">cname</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">distinct</span><span class="p">()</span>

<span class="c1"># A tibble: 7 x 5</span>
  <span class="n">geo_id</span>   <span class="n">countries_and_territories</span>               <span class="n">iso2</span>    <span class="n">iso3</span>  <span class="n">cname</span>
  <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>    <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>                                   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>
<span class="m">1</span> <span class="n">JPG11668</span> <span class="n">Cases_on_an_international_conveyance_J</span>â€¦ <span class="n">JPG116</span>â€¦ <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> 
<span class="m">2</span> <span class="n">PYF</span>      <span class="n">French_Polynesia</span>                        <span class="n">PYF</span>     <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> 
<span class="m">3</span> <span class="n">EL</span>       <span class="n">Greece</span>                                  <span class="n">EL</span>      <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> 
<span class="m">4</span> <span class="n">XK</span>       <span class="n">Kosovo</span>                                  <span class="n">XK</span>      <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> 
<span class="m">5</span> <span class="kc">NA</span>       <span class="n">Namibia</span>                                 <span class="kc">NA</span>      <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> 
<span class="m">6</span> <span class="n">AN</span>       <span class="n">Netherlands_Antilles</span>                    <span class="n">AN</span>      <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> 
<span class="m">7</span> <span class="n">UK</span>       <span class="n">United_Kingdom</span>                          <span class="n">UK</span>      <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> 

</code></pre></td></tr></table>
</div>
</div>

<p>Let&rsquo;s fix this. I made a small crosswalk file that can be coalesced into the missing values. In an added little wrinkleÙ« we need to specify the <code>na</code> argument in <code>read_csv</code> explicity because the missing country codes include NamibiaÙ« which has an ISO country code of &ldquo;NA&rdquo;! This is different from the missing data code <code>NA</code> but <code>read_csv()</code> won&rsquo;t know this by default.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">cname_xwalk</span> <span class="o">&lt;-</span> <span class="nf">read_csv</span><span class="p">(</span><span class="s">&#34;data/ecdc_to_iso2_xwalk.csv&#34;</span><span class="p">Ù«</span>
                        <span class="n">na</span> <span class="o">=</span> <span class="s">&#34;&#34;</span><span class="p">)</span>

<span class="n">cname_xwalk</span>

<span class="c1"># A tibble: 4 x 3</span>
  <span class="n">geo_id</span> <span class="n">iso3</span>  <span class="n">cname</span>         
  <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>         
<span class="m">1</span> <span class="n">UK</span>     <span class="n">GBR</span>   <span class="n">United</span> <span class="n">Kingdom</span>
<span class="m">2</span> <span class="n">EL</span>     <span class="n">GRC</span>   <span class="n">Greece</span>        
<span class="m">3</span> <span class="kc">NA</span>     <span class="n">NAM</span>   <span class="n">Namibia</span>       
<span class="m">4</span> <span class="n">XK</span>     <span class="n">XKV</span>   <span class="n">Kosovo</span>        

</code></pre></td></tr></table>
</div>
</div>

<p>I used to do coalescing like this:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="c1"># covid &lt;- covid %&gt;%</span>
<span class="c1">#   left_join(cname_xwalkÙ« by = &#34;geo_id&#34;) %&gt;% </span>
<span class="c1">#   mutate(iso3 = coalesce(iso3.xÙ« iso3.y)Ù«</span>
<span class="c1">#          cname = coalesce(cname.xÙ« cname.y)) %&gt;% </span>
<span class="c1">#   select(-iso3.xÙ« -iso3.yÙ« cname.xÙ« cname.y)</span>

</code></pre></td></tr></table>
</div>
</div>

<p>ActuallyÙ« I <em>used</em> to do it using <code>match()</code> and some index vectorsÙ« like an animal. But now I can use Edward Visel&rsquo;s handy function instead.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">covid</span> <span class="o">&lt;-</span> <span class="nf">coalesce_join</span><span class="p">(</span><span class="n">covid</span><span class="p">Ù«</span> <span class="n">cname_xwalk</span><span class="p">Ù«</span> 
                       <span class="n">by</span> <span class="o">=</span> <span class="s">&#34;geo_id&#34;</span><span class="p">Ù«</span> <span class="n">join</span> <span class="o">=</span> <span class="n">dplyr</span><span class="o">::</span><span class="n">left_join</span><span class="p">)</span>

<span class="c1">## Take a look again</span>
<span class="nf">anti_join</span><span class="p">(</span><span class="n">covid</span><span class="p">Ù«</span> <span class="n">cname_table</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">geo_id</span><span class="p">Ù«</span> <span class="n">countries_and_territories</span><span class="p">Ù«</span> <span class="n">iso2</span><span class="p">Ù«</span> <span class="n">iso3</span><span class="p">Ù«</span> <span class="n">cname</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">distinct</span><span class="p">()</span>

<span class="c1"># A tibble: 7 x 5</span>
  <span class="n">geo_id</span>   <span class="n">countries_and_territories</span>         <span class="n">iso2</span>    <span class="n">iso3</span>  <span class="n">cname</span>      
  <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>    <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>                             <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>      
<span class="m">1</span> <span class="n">JPG11668</span> <span class="n">Cases_on_an_international_convey</span>â€¦ <span class="n">JPG116</span>â€¦ <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>       
<span class="m">2</span> <span class="n">PYF</span>      <span class="n">French_Polynesia</span>                  <span class="n">PYF</span>     <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>       
<span class="m">3</span> <span class="n">EL</span>       <span class="n">Greece</span>                            <span class="n">EL</span>      <span class="n">GRC</span>   <span class="n">Greece</span>     
<span class="m">4</span> <span class="n">XK</span>       <span class="n">Kosovo</span>                            <span class="n">XK</span>      <span class="n">XKV</span>   <span class="n">Kosovo</span>     
<span class="m">5</span> <span class="kc">NA</span>       <span class="n">Namibia</span>                           <span class="kc">NA</span>      <span class="n">NAM</span>   <span class="n">Namibia</span>    
<span class="m">6</span> <span class="n">AN</span>       <span class="n">Netherlands_Antilles</span>              <span class="n">AN</span>      <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>       
<span class="m">7</span> <span class="n">UK</span>       <span class="n">United_Kingdom</span>                    <span class="n">UK</span>      <span class="n">GBR</span>   <span class="n">United</span> <span class="n">Kin</span>â€¦

</code></pre></td></tr></table>
</div>
</div>

<p>Looks like a couple of new territories have been added to the ECDC file since I made the crosswalk file. I&rsquo;ll have to update that soon.</p>
<h2 id="calculate-and-plot-cumulative-mortality">Calculate and Plot Cumulative Mortality</h2>
<p>Now we can actually analyze the data (in the privacy of our own home). Let&rsquo;s draw the plot that everyone drawsÙ« looking at cumulative counts. We&rsquo;ll take an arbitrary threshold for number of deathsÙ« let&rsquo;s say tenÙ« start every country from zero days when they hit ten deathsÙ« and count the cumulative deaths since that day. AgainÙ« note that we are not modeling or extrapolating from the data hereÙ« we&rsquo;re just focusing on getting a count of deaths attributed to the disease. The numbers are definitely undercounts because not all deaths directly attributable to COVID-19 have been counted as such at this point. Not everyone who died from it was tested for itÙ« and so e.g. a chunk of direct COVID-19 deaths will have been mis-classified as flu deaths.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">cov_curve</span> <span class="o">&lt;-</span> <span class="n">covid</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">date</span><span class="p">Ù«</span> <span class="n">cname</span><span class="p">Ù«</span> <span class="n">iso3</span><span class="p">Ù«</span> <span class="n">cases</span><span class="p">Ù«</span> <span class="n">deaths</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">drop_na</span><span class="p">(</span><span class="n">iso3</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">iso3</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">arrange</span><span class="p">(</span><span class="n">date</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">cu_cases</span> <span class="o">=</span> <span class="nf">cumsum</span><span class="p">(</span><span class="n">cases</span><span class="p">)Ù«</span> 
         <span class="n">cu_deaths</span> <span class="o">=</span> <span class="nf">cumsum</span><span class="p">(</span><span class="n">deaths</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">cu_deaths</span> <span class="o">&gt;</span> <span class="m">9</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">days_elapsed</span> <span class="o">=</span> <span class="n">date</span> <span class="o">-</span> <span class="nf">min</span><span class="p">(</span><span class="n">date</span><span class="p">)Ù«</span>
         <span class="n">end_label</span> <span class="o">=</span> <span class="nf">ifelse</span><span class="p">(</span><span class="n">date</span> <span class="o">==</span> <span class="nf">max</span><span class="p">(</span><span class="n">date</span><span class="p">)Ù«</span> <span class="n">cname</span><span class="p">Ù«</span> <span class="kc">NA</span><span class="p">))</span>

<span class="n">cov_curve</span>

<span class="c1"># A tibble: 245 x 9</span>
<span class="c1"># Groups:   iso3 [21]</span>
   <span class="n">date</span>       <span class="n">cname</span> <span class="n">iso3</span>  <span class="n">cases</span> <span class="n">deaths</span> <span class="n">cu_cases</span> <span class="n">cu_deaths</span> <span class="n">days_elapsed</span>
   <span class="o">&lt;</span><span class="n">date</span><span class="o">&gt;</span>     <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>    <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>     <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">drtn</span><span class="o">&gt;</span>      
 <span class="m">1</span> <span class="m">2020-01-22</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">140</span>     <span class="m">11</span>      <span class="m">526</span>        <span class="m">17</span> <span class="m">0</span> <span class="n">days</span>      
 <span class="m">2</span> <span class="m">2020-01-23</span> <span class="n">China</span> <span class="n">CHN</span>      <span class="m">97</span>      <span class="m">0</span>      <span class="m">623</span>        <span class="m">17</span> <span class="m">1</span> <span class="n">days</span>      
 <span class="m">3</span> <span class="m">2020-01-24</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">259</span>      <span class="m">9</span>      <span class="m">882</span>        <span class="m">26</span> <span class="m">2</span> <span class="n">days</span>      
 <span class="m">4</span> <span class="m">2020-01-25</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">441</span>     <span class="m">15</span>     <span class="m">1323</span>        <span class="m">41</span> <span class="m">3</span> <span class="n">days</span>      
 <span class="m">5</span> <span class="m">2020-01-26</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">665</span>     <span class="m">15</span>     <span class="m">1988</span>        <span class="m">56</span> <span class="m">4</span> <span class="n">days</span>      
 <span class="m">6</span> <span class="m">2020-01-27</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">787</span>     <span class="m">25</span>     <span class="m">2775</span>        <span class="m">81</span> <span class="m">5</span> <span class="n">days</span>      
 <span class="m">7</span> <span class="m">2020-01-28</span> <span class="n">China</span> <span class="n">CHN</span>    <span class="m">1753</span>     <span class="m">25</span>     <span class="m">4528</span>       <span class="m">106</span> <span class="m">6</span> <span class="n">days</span>      
 <span class="m">8</span> <span class="m">2020-01-29</span> <span class="n">China</span> <span class="n">CHN</span>    <span class="m">1466</span>     <span class="m">26</span>     <span class="m">5994</span>       <span class="m">132</span> <span class="m">7</span> <span class="n">days</span>      
 <span class="m">9</span> <span class="m">2020-01-30</span> <span class="n">China</span> <span class="n">CHN</span>    <span class="m">1740</span>     <span class="m">38</span>     <span class="m">7734</span>       <span class="m">170</span> <span class="m">8</span> <span class="n">days</span>      
<span class="m">10</span> <span class="m">2020-01-31</span> <span class="n">China</span> <span class="n">CHN</span>    <span class="m">1980</span>     <span class="m">43</span>     <span class="m">9714</span>       <span class="m">213</span> <span class="m">9</span> <span class="n">days</span>      
<span class="c1"># â€¦ with 235 more rowsÙ« and 1 more variable: end_label &lt;chr&gt;</span>


</code></pre></td></tr></table>
</div>
</div>

<p>See how at the end there we create an <code>end_label</code> variable for use in the plot. It only has values for the most recent day in the dataset (i.e. the country name if <code>date</code> is <code>max(date)</code>Ù« otherwise <code>NA</code>).</p>
<p>Now we&rsquo;ll narrow our focus to a few countries and make the plot.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">focus_cn</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;CHN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;GBR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;USA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;IRN&#34;</span><span class="p">Ù«</span> <span class="s">&#34;JPN&#34;</span><span class="p">Ù«</span>
              <span class="s">&#34;KOR&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ITA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;FRA&#34;</span><span class="p">Ù«</span> <span class="s">&#34;ESP&#34;</span><span class="p">)</span>


<span class="n">cov_curve</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">iso3</span> <span class="o">%in%</span> <span class="n">focus_cn</span><span class="p">)</span> <span class="o">%&gt;%</span> <span class="c1">## focus on just a few countriesÙ« defined above</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">end_label</span> <span class="o">=</span> <span class="nf">recode</span><span class="p">(</span><span class="n">end_label</span><span class="p">Ù«</span> <span class="n">`United States`</span> <span class="o">=</span> <span class="s">&#34;USA&#34;</span><span class="p">Ù«</span>
                        <span class="n">`IranÙ« Islamic Republic of`</span> <span class="o">=</span> <span class="s">&#34;Iran&#34;</span><span class="p">Ù«</span> 
                        <span class="n">`KoreaÙ« Republic of`</span> <span class="o">=</span> <span class="s">&#34;South Korea&#34;</span><span class="p">Ù«</span> 
                        <span class="n">`United Kingdom`</span> <span class="o">=</span> <span class="s">&#34;UK&#34;</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">ggplot</span><span class="p">(</span><span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">days_elapsed</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="n">cu_deaths</span><span class="p">Ù«</span> 
         <span class="n">color</span> <span class="o">=</span> <span class="n">cname</span><span class="p">Ù«</span> <span class="n">label</span> <span class="o">=</span> <span class="n">end_label</span><span class="p">Ù«</span> 
         <span class="n">group</span> <span class="o">=</span> <span class="n">cname</span><span class="p">))</span> <span class="o">+</span> 
  <span class="nf">geom_line</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="m">0.8</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">geom_text_repel</span><span class="p">(</span><span class="n">nudge_x</span> <span class="o">=</span> <span class="m">1.1</span><span class="p">Ù«</span>
                  <span class="n">nudge_y</span> <span class="o">=</span> <span class="m">0.1</span><span class="p">Ù«</span> 
                  <span class="n">segment.color</span> <span class="o">=</span> <span class="kc">NA</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">guides</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="n">prismatic</span><span class="o">::</span><span class="nf">clr_darken</span><span class="p">(</span><span class="nf">paletteer_d</span><span class="p">(</span><span class="s">&#34;ggsci::category20_d3&#34;</span><span class="p">)Ù«</span> <span class="m">0.2</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">scale_y_continuous</span><span class="p">(</span><span class="n">labels</span> <span class="o">=</span> <span class="n">scales</span><span class="o">::</span><span class="nf">comma_format</span><span class="p">(</span><span class="n">accuracy</span> <span class="o">=</span> <span class="m">1</span><span class="p">)Ù«</span> 
                     <span class="n">breaks</span> <span class="o">=</span> <span class="m">2</span><span class="nf">^seq</span><span class="p">(</span><span class="m">4</span><span class="p">Ù«</span> <span class="m">12</span><span class="p">)Ù«</span>
                     <span class="n">trans</span> <span class="o">=</span> <span class="s">&#34;log2&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Days Since 10th Confirmed Death&#34;</span><span class="p">Ù«</span> 
       <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Cumulative Number of Deaths (log scale)&#34;</span><span class="p">Ù«</span> 
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Cumulative Deaths from COVID-19Ù« Selected Countries&#34;</span><span class="p">Ù«</span> 
       <span class="n">subtitle</span> <span class="o">=</span> <span class="nf">paste</span><span class="p">(</span><span class="s">&#34;Data as of&#34;</span><span class="p">Ù«</span> <span class="nf">format</span><span class="p">(</span><span class="nf">max</span><span class="p">(</span><span class="n">cov_curve</span><span class="o">$</span><span class="n">date</span><span class="p">)Ù«</span> <span class="s">&#34;%AÙ« %B %eÙ« %Y&#34;</span><span class="p">))Ù«</span> 
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Kieran Healy @kjhealy / Data: ECDC&#34;</span><span class="p">)</span> <span class="o">+</span> 
    <span class="nf">theme</span><span class="p">(</span><span class="n">plot.title</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">)Ù«</span> <span class="n">face</span> <span class="o">=</span> <span class="s">&#34;bold&#34;</span><span class="p">)Ù«</span>
          <span class="n">plot.subtitle</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1.5</span><span class="p">))Ù«</span>
          <span class="n">axis.text.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">))Ù«</span>
          <span class="n">axis.title.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1.5</span><span class="p">))Ù«</span>
          <span class="n">axis.title.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1.5</span><span class="p">))Ù«</span>
          <span class="n">axis.text.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">))Ù«</span>
          <span class="n">legend.text</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">))</span>
          <span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div>

<p>AgainÙ« a few small details polish the plot. We do a quick bit of recoding on the <code>end_label</code> to shorten some country namesÙ« and use <code>geom_text_repel()</code> to put the labels at the end of the line. We get our y-axis breaks with <code>2^seq(4Ù« 12)</code>Ù« which (as case numbers rise) will be easier to extend than manually typing all the numbers. I use a base 2 log scale for the reasons <a href="https://leancrew.com/all-this/2020/03/exponential-growth-and-log-scales/">Dr Drang gives here</a>. It&rsquo;s useful to look at the doubling timeÙ« which base 2 helps you seeÙ« rather than powers of ten. (The graphs won&rsquo;t look any different.) Finally on the thematic side we can date-stamp the title of the graph using the opaque but standard <a href="https://gist.github.com/nikreiman/1408399">UNIX date formatting codes</a>Ù« with <code>paste(&quot;Data as of&quot;Ù« format(max(cov_curve$date)Ù« &quot;%AÙ« %B %eÙ« %Y&quot;))</code>.</p>
<p>And here&rsquo;s our figure.</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/covid_cumulative_22-03-20.png"
         alt="Cumulative COVID-19 Deaths"/> <figcaption>
            <p>Cumulative COVID-19 Deaths</p>
        </figcaption>
</figure>
<p>The <a href="https://github.com/kjhealy/covid">GitHub repository</a> for this post also has some code to pull U.S. data from the <a href="https://covidtracking.com/">COVID Tracking Project</a> currently being run by a group of volunteers.</p>
'),('https://kieranhealy.org/blog/archives/2020/03/15/u.s.-census-counts-data/', 'U.S. Census Counts Data', '1584324764000',  15, '<p>As <a href="https://kieranhealy.org/blog/archives/2020/03/14/animating-u.s.-population-distributions/">promised previously</a>Ù« I packaged up the U.S. Census data that I pulled together to make the population density and pyramid animations. The package is called <a href="https://kjhealy.github.io/uscenpops/">uscenpops</a> and it&rsquo;s available to install via GitHub or with <code>install.packages()</code> if you set up <a href="http://eddelbuettel.github.io/drat/">drat</a> first. The instructions are on the <a href="https://kjhealy.github.io/uscenpops/">package homepage</a>.</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/us-pop-smallmult.png"
         alt="A small multiple of population pyramids in selected years"/> <figcaption>
            <p>A small multiple plot of selected population pyramids</p>
        </figcaption>
</figure>
<p>Instead of an animationÙ« let&rsquo;s make the less-flashy butÙ« franklyÙ« in all likelihood more useful small multiple plot seen here. With the package installed we can produce it as follows:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">uscenpops</span><span class="p">)</span>

<span class="n">uscenpops</span>
<span class="c1">#&gt; # A tibble: 10Ù«520 x 5</span>
<span class="c1">#&gt;     year   age     pop   male female</span>
<span class="c1">#&gt;    &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;</span>
<span class="c1">#&gt;  1  1900     0 1811000 919000 892000</span>
<span class="c1">#&gt;  2  1900     1 1835000 928000 907000</span>
<span class="c1">#&gt;  3  1900     2 1846000 932000 914000</span>
<span class="c1">#&gt;  4  1900     3 1848000 932000 916000</span>
<span class="c1">#&gt;  5  1900     4 1841000 928000 913000</span>
<span class="c1">#&gt;  6  1900     5 1827000 921000 906000</span>
<span class="c1">#&gt;  7  1900     6 1806000 911000 895000</span>
<span class="c1">#&gt;  8  1900     7 1780000 899000 881000</span>
<span class="c1">#&gt;  9  1900     8 1750000 884000 866000</span>
<span class="c1">#&gt; 10  1900     9 1717000 868000 849000</span>
<span class="c1">#&gt; # â€¦ with 10Ù«510 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>That&rsquo;s what the dataset looks like. We&rsquo;ll lengthen itÙ« calculate a relative frequency (that we won&rsquo;t use in this particular plot) and add a base value that we&rsquo;ll use for the ribbon boundaries below.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">pop_pyr</span> <span class="o">&lt;-</span> <span class="n">uscenpops</span> <span class="o">%&gt;%</span> <span class="nf">select</span><span class="p">(</span><span class="n">year</span><span class="p">Ù«</span> <span class="n">age</span><span class="p">Ù«</span> <span class="n">male</span><span class="p">Ù«</span> <span class="n">female</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_longer</span><span class="p">(</span><span class="n">male</span><span class="o">:</span><span class="n">female</span><span class="p">Ù«</span> <span class="n">names_to</span> <span class="o">=</span> <span class="s">&#34;group&#34;</span><span class="p">Ù«</span> <span class="n">values_to</span> <span class="o">=</span> <span class="s">&#34;count&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">year</span><span class="p">Ù«</span> <span class="n">group</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">total</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">count</span><span class="p">)Ù«</span> 
         <span class="n">pct</span> <span class="o">=</span> <span class="p">(</span><span class="n">count</span><span class="o">/</span><span class="n">total</span><span class="p">)</span><span class="o">*</span><span class="m">100</span><span class="p">Ù«</span> 
         <span class="n">base</span> <span class="o">=</span> <span class="m">0</span><span class="p">)</span> 

<span class="n">pop_pyr</span>

<span class="c1">#&gt; # A tibble: 21Ù«040 x 7</span>
<span class="c1">#&gt; # Groups:   yearÙ« group [240]</span>
<span class="c1">#&gt;     year   age group   count    total   pct  base</span>
<span class="c1">#&gt;    &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;</span>
<span class="c1">#&gt;  1  1900     0 male   919000 38867000  2.36     0</span>
<span class="c1">#&gt;  2  1900     0 female 892000 37227000  2.40     0</span>
<span class="c1">#&gt;  3  1900     1 male   928000 38867000  2.39     0</span>
<span class="c1">#&gt;  4  1900     1 female 907000 37227000  2.44     0</span>
<span class="c1">#&gt;  5  1900     2 male   932000 38867000  2.40     0</span>
<span class="c1">#&gt;  6  1900     2 female 914000 37227000  2.46     0</span>
<span class="c1">#&gt;  7  1900     3 male   932000 38867000  2.40     0</span>
<span class="c1">#&gt;  8  1900     3 female 916000 37227000  2.46     0</span>
<span class="c1">#&gt;  9  1900     4 male   928000 38867000  2.39     0</span>
<span class="c1">#&gt; 10  1900     4 female 913000 37227000  2.45     0</span>
<span class="c1">#&gt; # â€¦ with 21Ù«030 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Next we set up some little vectors of labels and colorsÙ« and then make a mini-dataframe of what we&rsquo;ll use as labels in the plot areaÙ« rather than using the default strip labels in <code>facet_wrap()</code>.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="c1">## Axis labels</span>
<span class="n">mbreaks</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;1M&#34;</span><span class="p">Ù«</span> <span class="s">&#34;2M&#34;</span><span class="p">Ù«</span> <span class="s">&#34;3M&#34;</span><span class="p">)</span>

<span class="c1">## colors</span>
<span class="n">pop_colors</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;#E69F00&#34;</span><span class="p">Ù«</span> <span class="s">&#34;#0072B2&#34;</span><span class="p">)</span>

<span class="c1">## In-plot year labels</span>
<span class="n">dat_text</span> <span class="o">&lt;-</span> <span class="nf">data.frame</span><span class="p">(</span>
  <span class="n">label</span> <span class="o">=</span>  <span class="nf">c</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">1900</span><span class="p">Ù«</span> <span class="m">2015</span><span class="p">Ù«</span> <span class="m">5</span><span class="p">)Ù«</span> <span class="m">2019</span><span class="p">)Ù«</span>
  <span class="n">year</span>  <span class="o">=</span>  <span class="nf">c</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">1900</span><span class="p">Ù«</span> <span class="m">2015</span><span class="p">Ù«</span> <span class="m">5</span><span class="p">)Ù«</span> <span class="m">2019</span><span class="p">)Ù«</span>
  <span class="n">age</span> <span class="o">=</span> <span class="nf">rep</span><span class="p">(</span><span class="m">95</span><span class="p">Ù«</span> <span class="m">25</span><span class="p">)Ù«</span> 
  <span class="n">count</span> <span class="o">=</span> <span class="nf">rep</span><span class="p">(</span><span class="m">-2.75e6</span><span class="p">Ù«</span> <span class="m">25</span><span class="p">)</span>
<span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div>

<p>As beforeÙ« the trick to making the pyramid is to set all the values for one category (hereÙ« males) to negative numbers.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">pop_pyr</span><span class="o">$</span><span class="n">count[pop_pyr</span><span class="o">$</span><span class="n">group</span> <span class="o">==</span> <span class="s">&#34;male&#34;</span><span class="n">]</span> <span class="o">&lt;-</span> <span class="o">-</span><span class="n">pop_pyr</span><span class="o">$</span><span class="n">count[pop_pyr</span><span class="o">$</span><span class="n">group</span> <span class="o">==</span> <span class="s">&#34;male&#34;</span><span class="n">]</span>

<span class="n">p</span> <span class="o">&lt;-</span> <span class="n">pop_pyr</span> <span class="o">%&gt;%</span> 
  <span class="nf">filter</span><span class="p">(</span><span class="n">year</span> <span class="o">%in%</span> <span class="nf">c</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">1900</span><span class="p">Ù«</span> <span class="m">2015</span><span class="p">Ù«</span> <span class="m">5</span><span class="p">)Ù«</span> <span class="m">2019</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">ggplot</span><span class="p">(</span><span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">age</span><span class="p">Ù«</span> <span class="n">ymin</span> <span class="o">=</span> <span class="n">base</span><span class="p">Ù«</span>
                       <span class="n">ymax</span> <span class="o">=</span> <span class="n">count</span><span class="p">Ù«</span> <span class="n">fill</span> <span class="o">=</span> <span class="n">group</span><span class="p">))</span>

<span class="n">p</span> <span class="o">+</span> <span class="nf">geom_ribbon</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="m">0.9</span><span class="p">Ù«</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;black&#34;</span><span class="p">Ù«</span> <span class="n">size</span> <span class="o">=</span> <span class="m">0.1</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_label</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">dat_text</span><span class="p">Ù«</span> 
             <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">age</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="n">count</span><span class="p">Ù«</span> 
                           <span class="n">label</span> <span class="o">=</span> <span class="n">label</span><span class="p">)Ù«</span> <span class="n">inherit.aes</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">Ù«</span> 
             <span class="n">vjust</span> <span class="o">=</span> <span class="s">&#34;inward&#34;</span><span class="p">Ù«</span> <span class="n">hjust</span> <span class="o">=</span> <span class="s">&#34;inward&#34;</span><span class="p">Ù«</span>
             <span class="n">fontface</span> <span class="o">=</span> <span class="s">&#34;bold&#34;</span><span class="p">Ù«</span> 
             <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;gray40&#34;</span><span class="p">Ù«</span> 
             <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;gray95&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">scale_y_continuous</span><span class="p">(</span><span class="n">labels</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">rev</span><span class="p">(</span><span class="n">mbreaks</span><span class="p">)Ù«</span> <span class="s">&#34;0&#34;</span><span class="p">Ù«</span> <span class="n">mbreaks</span><span class="p">)Ù«</span> 
                     <span class="n">breaks</span> <span class="o">=</span> <span class="nf">seq</span><span class="p">(</span><span class="m">-3e6</span><span class="p">Ù«</span> <span class="m">3e6</span><span class="p">Ù«</span> <span class="m">1e6</span><span class="p">)Ù«</span> 
                     <span class="n">limits</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">-3e6</span><span class="p">Ù«</span> <span class="m">3e6</span><span class="p">))</span> <span class="o">+</span> 
  <span class="nf">scale_x_continuous</span><span class="p">(</span><span class="n">breaks</span> <span class="o">=</span> <span class="nf">seq</span><span class="p">(</span><span class="m">10</span><span class="p">Ù«</span> <span class="m">100</span><span class="p">Ù«</span> <span class="m">10</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">scale_fill_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="n">pop_colors</span><span class="p">Ù«</span> <span class="n">labels</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;Females&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Males&#34;</span><span class="p">))</span> <span class="o">+</span> 
  <span class="nf">guides</span><span class="p">(</span><span class="n">fill</span> <span class="o">=</span> <span class="nf">guide_legend</span><span class="p">(</span><span class="n">reverse</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Age&#34;</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Population in Millions&#34;</span><span class="p">Ù«</span>
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Age Distribution of the U.S. PopulationÙ« 1900-2019&#34;</span><span class="p">Ù«</span>
       <span class="n">subtitle</span> <span class="o">=</span> <span class="s">&#34;Age is top-coded at 75 until 1939Ù« at 85 until 1979Ù« and at 100 since then&#34;</span><span class="p">Ù«</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Kieran Healy / kieranhealy.org / Data: US Census Bureau.&#34;</span><span class="p">Ù«</span>
       <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;bottom&#34;</span><span class="p">Ù«</span>
        <span class="n">plot.title</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">)Ù«</span> <span class="n">face</span> <span class="o">=</span> <span class="s">&#34;bold&#34;</span><span class="p">)Ù«</span>
        <span class="n">strip.background</span> <span class="o">=</span> <span class="nf">element_blank</span><span class="p">()Ù«</span>  
        <span class="n">strip.text.x</span> <span class="o">=</span> <span class="nf">element_blank</span><span class="p">())</span> <span class="o">+</span>
  <span class="nf">coord_flip</span><span class="p">()</span> <span class="o">+</span> 
  <span class="nf">facet_wrap</span><span class="p">(</span><span class="o">~</span> <span class="n">year</span><span class="p">Ù«</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">5</span><span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div>

<p>The calls to <code>geom_ribbon()</code> and <code>geom_label()</code> draw the actual plotsÙ« and everything else is just a little attention to detail in order to make it come out nicely.</p>
'),('https://kieranhealy.org/blog/archives/2020/03/14/animating-u.s.-population-distributions/', 'Animating U.S. Population Distributions', '1584219472000',  15, '<p>With the 2020 U.S. Census in motion alreadyÙ« I&rsquo;ve been looking at various pieces of data from the <a href="http://census.gov">Census Bureau</a>. I decided I wanted to draw some population pyramids for the U.S. over as long a time series as I could. What&rsquo;s needed for that are tables forÙ« sayÙ« as many years as possible that show the number of males and females alive at every year of age from zero to the highest age you&rsquo;re willing to track. This sort of data <em>is</em> available on the Census website. But it tuned out to be somewhat tedious to assemble into a single usable series. (Perhaps it&rsquo;s available in an easy-to-digest form elsewhereÙ« but I couldn&rsquo;t find it.) I initially worked with a couple of the excellent R packages that talk to the Census API (<code>tidycensus</code> and <code>censusapi</code>)Ù« hoping they&rsquo;d give me what I needed. But in the end I wrangled an annual year-of-age series from 1900 to 2019 by grabbing the data from the Census and cleaning it myself. As alwaysÙ« 95% of data analysis is in fact data acquisition and data cleaning.</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/us_pyramid_1980.png"/> 
</figure>
<p>First we get ourselves set up as usual.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">here</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">janitor</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">socviz</span><span class="p">)</span>

<span class="nf">library</span><span class="p">(</span><span class="n">gganimate</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">transformr</span><span class="p">)</span>

<span class="c1">## --------------------------------------------------------------------</span>
<span class="c1">## Custom font and themeÙ« omit if you don&#39;t have the myriad library</span>
<span class="c1">## (https://github.com/kjhealy/myriad) and associated Adobe fonts.</span>
<span class="c1">## --------------------------------------------------------------------</span>
<span class="nf">library</span><span class="p">(</span><span class="n">showtext</span><span class="p">)</span>
<span class="nf">showtext_auto</span><span class="p">()</span>
<span class="nf">library</span><span class="p">(</span><span class="n">myriad</span><span class="p">)</span>
<span class="nf">import_myriad_semi</span><span class="p">()</span>

<span class="nf">theme_set</span><span class="p">(</span><span class="nf">theme_myriad_semi</span><span class="p">())</span>

</code></pre></td></tr></table>
</div>
</div>

<p>NowÙ« the data. What we want are the decennial and intercensal estimates by yearÙ« sexÙ« and year of age. These aren&rsquo;t all in the same place. MoreoverÙ« they aren&rsquo;t all in the same format. The estimates for 1900 to 1979 are available <a href="https://www2.census.gov/programs-surveys/popest/tables/1900-1980/national/asrh/?C=N;O=D">at this link</a>Ù« but (as quickly became clear)Ù« the format of the CSV file changes slightly. Subsequent decades vary their format and expand the range of measures counted. Some of the formats are rather difficult to work with. For exampleÙ« here&rsquo;s part of the description of the 1980-89 files:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">The 1990 monthly postcensal national population estimate data files have
an identical layout.  All records contain 222 characters.  All data fields
are right-justified.

Location            Type        Data

1-2                 Character   Series
3-4                 Numeric     Month
5-8                 Numeric     Year
9-11                Numeric     Age (years)
12                  (blank)     (blank)
13-22               Numeric     Total population
23-32               Numeric     Total male population
33-42               Numeric     Total female population
43-52               Numeric     White male population
53-62               Numeric     White female population
63-72               Numeric     Black male population
73-82               Numeric     Black female population

</code></pre></td></tr></table>
</div>
</div><p>And then:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">Within each fileÙ« the records are first sorted by the reference date
(Month-Year) in chronological order.  For each reference dateÙ« the first
record lists the population counts for all ages combined.  The remaining
records list the population counts by single year of age in ascending
order.
</code></pre></td></tr></table>
</div>
</div><p>That means that the data file for any particular year during this period looks something like this:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">2I 780 98      14234      3485 
2I 780 99       9652      2409 
2I 780100      15099      3244 
2I1080999  227924215 110746612 
2I1080  0    3582352   1832733 
2I1080  1    3360607   1718828 
2I1080  2    3217219   1645162 
</code></pre></td></tr></table>
</div>
</div><p>Not so nice. The cleanest way to work with stuff like this would be to write a spec to read in the data by column position. In the end I wrote a series of short scripts using some old-fashioned Unix toolsÙ« especially <code>sed</code>Ù« to do the slicing and dicing for me. They looked like this:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash">
<span class="c1">## Extract every row between the first</span>
<span class="c1">## July estimate (^2I 7) to oct (2I10)</span>
<span class="k">for</span> filename in *.TXT<span class="p">;</span> <span class="k">do</span>
    gsed -i.bak -n <span class="s1">&#39;/^2I 7/Ù«/2I10/p;/^\+/p&#39;</span> <span class="s2">&#34;</span><span class="nv">$filename</span><span class="s2">&#34;</span> 
<span class="k">done</span>

<span class="c1">## cut away the first 7 columns</span>
<span class="k">for</span> filename in *.TXT<span class="p">;</span> <span class="k">do</span>
   cut -c7- &lt;<span class="s2">&#34;</span><span class="nv">$filename</span><span class="s2">&#34;</span> &gt;<span class="s2">&#34;</span><span class="si">${</span><span class="nv">filename</span><span class="p">%.TXT</span><span class="si">}</span><span class="s2">.new&#34;</span>
<span class="k">done</span>

<span class="c1">## trim the first and last lines</span>
<span class="k">for</span> filename in *.new<span class="p">;</span> <span class="k">do</span>
    gsed -i <span class="s1">&#39;1d;$d&#39;</span> <span class="s2">&#34;</span><span class="nv">$filename</span><span class="s2">&#34;</span>
<span class="k">done</span>
</code></pre></td></tr></table>
</div>
</div>

<p>In the end I had some fairly clean delimited files that I could work with that needed only a little more cleaning in R. For each batch of files I&rsquo;d do something like this: get a list of the files needed from the directoryÙ« read the contents into a tibble and harmonize the column names if needed. Here&rsquo;s the segment for the 1980s filesÙ« for example:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">target</span> <span class="o">&lt;-</span> <span class="s">&#34;1980_1989&#34;</span>
<span class="n">path</span> <span class="o">&lt;-</span> <span class="nf">paste0</span><span class="p">(</span><span class="s">&#34;data/&#34;</span><span class="p">Ù«</span><span class="n">target</span><span class="p">)</span>

<span class="n">filenames</span> <span class="o">&lt;-</span> <span class="nf">dir</span><span class="p">(</span><span class="n">path</span> <span class="o">=</span> <span class="nf">here</span><span class="p">(</span><span class="n">path</span><span class="p">)Ù«</span>
                 <span class="n">pattern</span> <span class="o">=</span> <span class="s">&#34;*.new$&#34;</span><span class="p">Ù«</span>
                 <span class="n">full.names</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>

<span class="n">pop_1980_1989</span> <span class="o">&lt;-</span> <span class="nf">tibble</span><span class="p">(</span>
  <span class="n">year</span> <span class="o">=</span> <span class="nf">get_80syr</span><span class="p">(</span><span class="n">filenames</span><span class="p">)Ù«</span>
  <span class="n">path</span> <span class="o">=</span> <span class="n">filenames</span><span class="p">Ù«</span> 
  <span class="n">data</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span><span class="n">filenames</span><span class="p">Ù«</span> <span class="o">~</span> <span class="nf">read_delim</span><span class="p">(</span><span class="n">.Ù«</span> <span class="n">delim</span> <span class="o">=</span> <span class="s">&#34; &#34;</span><span class="p">))</span>
  <span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span><span class="n">data</span><span class="p">Ù«</span> <span class="o">~</span> 
                       <span class="n">.x</span> <span class="o">%&gt;%</span> 
                         <span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.character</span><span class="p">Ù«</span> <span class="n">as.numeric</span><span class="p">)))</span>

<span class="n">pop_1980_1989</span>

<span class="c1"># A tibble: 10 x 3</span>
   <span class="n">year</span>  <span class="n">path</span>                                           <span class="n">data</span>          
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>                                          <span class="o">&lt;</span><span class="n">list</span><span class="o">&gt;</span>        
 <span class="m">1</span> <span class="m">1980</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>â€¦ <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> â€¦
 <span class="m">2</span> <span class="m">1981</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>â€¦ <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> â€¦
 <span class="m">3</span> <span class="m">1982</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>â€¦ <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> â€¦
 <span class="m">4</span> <span class="m">1983</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>â€¦ <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> â€¦
 <span class="m">5</span> <span class="m">1984</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>â€¦ <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> â€¦
 <span class="m">6</span> <span class="m">1985</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>â€¦ <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> â€¦
 <span class="m">7</span> <span class="m">1986</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>â€¦ <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> â€¦
 <span class="m">8</span> <span class="m">1987</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>â€¦ <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> â€¦
 <span class="m">9</span> <span class="m">1988</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>â€¦ <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> â€¦
<span class="m">10</span> <span class="m">1989</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>â€¦ <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> â€¦
</code></pre></td></tr></table>
</div>
</div>

<p>Eventually all the series are read in and can be bound together and the yearÙ« ageÙ« and population counts extracted.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="c1"># Now we&#39;re suckin&#39; diesel</span>
<span class="n">pop_data</span> <span class="o">&lt;-</span> <span class="nf">bind_rows</span><span class="p">(</span><span class="n">pop_1900_1959</span><span class="p">Ù«</span> 
                      <span class="n">pop_1960_1979</span><span class="p">Ù«</span> 
                      <span class="n">pop_1980_1989</span><span class="p">Ù«</span>
                      <span class="n">pop_1990_1999</span><span class="p">Ù«</span> 
                      <span class="n">pop_2000_2009</span><span class="p">Ù«</span> 
                      <span class="n">pop_2010_2019</span><span class="p">)</span>

<span class="n">pop_series</span> <span class="o">&lt;-</span> <span class="nf">unnest</span><span class="p">(</span><span class="n">pop_data</span><span class="p">Ù«</span> <span class="n">cols</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">path</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">year</span><span class="p">Ù«</span> <span class="n">age</span><span class="p">Ù«</span> <span class="n">pop</span><span class="p">Ù«</span> <span class="n">male</span><span class="p">Ù«</span> <span class="n">female</span><span class="p">)</span> 

<span class="n">pop_series</span>

<span class="c1"># A tibble: 10Ù«520 x 5</span>
   <span class="n">year</span>    <span class="n">age</span>     <span class="n">pop</span>   <span class="n">male</span> <span class="n">female</span>
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>
 <span class="m">1</span> <span class="m">1900</span>      <span class="m">0</span> <span class="m">1811000</span> <span class="m">919000</span> <span class="m">892000</span>
 <span class="m">2</span> <span class="m">1900</span>      <span class="m">1</span> <span class="m">1835000</span> <span class="m">928000</span> <span class="m">907000</span>
 <span class="m">3</span> <span class="m">1900</span>      <span class="m">2</span> <span class="m">1846000</span> <span class="m">932000</span> <span class="m">914000</span>
 <span class="m">4</span> <span class="m">1900</span>      <span class="m">3</span> <span class="m">1848000</span> <span class="m">932000</span> <span class="m">916000</span>
 <span class="m">5</span> <span class="m">1900</span>      <span class="m">4</span> <span class="m">1841000</span> <span class="m">928000</span> <span class="m">913000</span>
 <span class="m">6</span> <span class="m">1900</span>      <span class="m">5</span> <span class="m">1827000</span> <span class="m">921000</span> <span class="m">906000</span>
 <span class="m">7</span> <span class="m">1900</span>      <span class="m">6</span> <span class="m">1806000</span> <span class="m">911000</span> <span class="m">895000</span>
 <span class="m">8</span> <span class="m">1900</span>      <span class="m">7</span> <span class="m">1780000</span> <span class="m">899000</span> <span class="m">881000</span>
 <span class="m">9</span> <span class="m">1900</span>      <span class="m">8</span> <span class="m">1750000</span> <span class="m">884000</span> <span class="m">866000</span>
<span class="m">10</span> <span class="m">1900</span>      <span class="m">9</span> <span class="m">1717000</span> <span class="m">868000</span> <span class="m">849000</span>
<span class="c1"># â€¦ with 10Ù«510 more rows</span>
</code></pre></td></tr></table>
</div>
</div>

<p>From there we pivot series to long format:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">pop_lon</span> <span class="o">&lt;-</span> <span class="n">pop_series</span> <span class="o">%&gt;%</span> <span class="nf">select</span><span class="p">(</span><span class="n">year</span><span class="p">Ù«</span> <span class="n">age</span><span class="p">Ù«</span> <span class="n">male</span><span class="p">Ù«</span> <span class="n">female</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_longer</span><span class="p">(</span><span class="n">male</span><span class="o">:</span><span class="n">female</span><span class="p">Ù«</span> <span class="n">names_to</span> <span class="o">=</span> <span class="s">&#34;group&#34;</span><span class="p">Ù«</span> <span class="n">values_to</span> <span class="o">=</span> <span class="s">&#34;count&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">year</span><span class="p">Ù«</span> <span class="n">group</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">total</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">count</span><span class="p">)Ù«</span> 
         <span class="n">pct</span> <span class="o">=</span> <span class="p">(</span><span class="n">count</span><span class="o">/</span><span class="n">total</span><span class="p">)</span><span class="o">*</span><span class="m">100</span><span class="p">Ù«</span> 
         <span class="n">base</span> <span class="o">=</span> <span class="m">0</span><span class="p">)</span> 

<span class="n">pop_lon</span>

<span class="c1"># A tibble: 21Ù«040 x 7</span>
<span class="c1"># Groups:   yearÙ« group [240]</span>
   <span class="n">year</span>    <span class="n">age</span> <span class="n">group</span>   <span class="n">count</span>    <span class="n">total</span>   <span class="n">pct</span>  <span class="n">base</span>
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>    <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>
 <span class="m">1</span> <span class="m">1900</span>      <span class="m">0</span> <span class="n">male</span>   <span class="m">919000</span> <span class="m">38867000</span>  <span class="m">2.36</span>     <span class="m">0</span>
 <span class="m">2</span> <span class="m">1900</span>      <span class="m">0</span> <span class="n">female</span> <span class="m">892000</span> <span class="m">37227000</span>  <span class="m">2.40</span>     <span class="m">0</span>
 <span class="m">3</span> <span class="m">1900</span>      <span class="m">1</span> <span class="n">male</span>   <span class="m">928000</span> <span class="m">38867000</span>  <span class="m">2.39</span>     <span class="m">0</span>
 <span class="m">4</span> <span class="m">1900</span>      <span class="m">1</span> <span class="n">female</span> <span class="m">907000</span> <span class="m">37227000</span>  <span class="m">2.44</span>     <span class="m">0</span>
 <span class="m">5</span> <span class="m">1900</span>      <span class="m">2</span> <span class="n">male</span>   <span class="m">932000</span> <span class="m">38867000</span>  <span class="m">2.40</span>     <span class="m">0</span>
 <span class="m">6</span> <span class="m">1900</span>      <span class="m">2</span> <span class="n">female</span> <span class="m">914000</span> <span class="m">37227000</span>  <span class="m">2.46</span>     <span class="m">0</span>
 <span class="m">7</span> <span class="m">1900</span>      <span class="m">3</span> <span class="n">male</span>   <span class="m">932000</span> <span class="m">38867000</span>  <span class="m">2.40</span>     <span class="m">0</span>
 <span class="m">8</span> <span class="m">1900</span>      <span class="m">3</span> <span class="n">female</span> <span class="m">916000</span> <span class="m">37227000</span>  <span class="m">2.46</span>     <span class="m">0</span>
 <span class="m">9</span> <span class="m">1900</span>      <span class="m">4</span> <span class="n">male</span>   <span class="m">928000</span> <span class="m">38867000</span>  <span class="m">2.39</span>     <span class="m">0</span>
<span class="m">10</span> <span class="m">1900</span>      <span class="m">4</span> <span class="n">female</span> <span class="m">913000</span> <span class="m">37227000</span>  <span class="m">2.45</span>     <span class="m">0</span>
<span class="c1"># â€¦ with 21Ù«030 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>HereÙ« within each  year and for males and femalesÙ« we calculate the percentage of the total population that is of any particular age. As I mentionedÙ« one feature of the Census data is that over the years the top-code for age&mdash;the highest age the Census tables report&mdash;gradually increases. We can see what those limits are and when they change:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">pop_series</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">year</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">summarize</span><span class="p">(</span><span class="n">max_age</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">age</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">max_age</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">summarize</span><span class="p">(</span><span class="n">minyr</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">year</span><span class="p">)Ù«</span> 
            <span class="n">maxyr</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">year</span><span class="p">))</span>

<span class="c1"># A tibble: 3 x 3</span>
  <span class="n">max_age</span> <span class="n">minyr</span> <span class="n">maxyr</span>
    <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>
<span class="m">1</span>      <span class="m">75</span> <span class="m">1900</span>  <span class="m">1939</span> 
<span class="m">2</span>      <span class="m">85</span> <span class="m">1940</span>  <span class="m">1979</span> 
<span class="m">3</span>     <span class="m">100</span> <span class="m">1980</span>  <span class="m">2019</span> 
</code></pre></td></tr></table>
</div>
</div>

<p>Now we can make some animations. FirstÙ« rather than a population pyramidÙ« we&rsquo;ll use <code>geom_density()</code> to produce kernel density estimates of the age distribution for every yearÙ« for both males and females. In cases like thisÙ« when we have a variable like <code>year</code> and a summary count for each age in that year (but not individual-level observations)Ù« the way to get the density is to put <code>age</code> on the x-axis and use the proportion (<code>pct/100</code>) to weight each year-of-age. (Weights need to sum to 1Ù« hence the use of proportions rather than percents.) Here we&rsquo;re using the <code>after_stat()</code> function that&rsquo;s new in the <code>scales</code> package and <code>ggplot2</code> version 3.3.0. This way of expressing what we want to do replaces earlier syntaxes like the double-period <code>..density..</code> convention.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">p_dens</span> <span class="o">&lt;-</span> <span class="n">pop_lon</span> <span class="o">%&gt;%</span>
  <span class="nf">ggplot</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">age</span><span class="p">Ù«</span> 
           <span class="n">y</span> <span class="o">=</span> <span class="nf">after_stat</span><span class="p">(</span><span class="n">density</span><span class="p">)Ù«</span>
           <span class="n">weight</span> <span class="o">=</span> <span class="n">pct</span><span class="o">/</span><span class="m">100</span><span class="p">Ù«</span>
           <span class="n">fill</span> <span class="o">=</span> <span class="n">group</span><span class="p">Ù«</span> 
           <span class="n">group</span> <span class="o">=</span> <span class="n">group</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">geom_density</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="s">&#34;black&#34;</span><span class="p">Ù«</span> <span class="n">alpha</span> <span class="o">=</span> <span class="m">0.5</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">scale_fill_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">)Ù«</span> 
                    <span class="n">labels</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;Female&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Male&#34;</span><span class="p">))</span> <span class="o">+</span> 
  <span class="nf">scale_x_continuous</span><span class="p">(</span><span class="n">breaks</span> <span class="o">=</span> <span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">Ù«</span> <span class="m">100</span><span class="p">Ù«</span> <span class="m">10</span><span class="p">)Ù«</span> 
                    <span class="n">labels</span> <span class="o">=</span> <span class="nf">as.character</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">Ù«</span> <span class="m">100</span><span class="p">Ù«</span> <span class="m">10</span><span class="p">)))</span> <span class="o">+</span>
  <span class="nf">guides</span><span class="p">(</span><span class="n">fill</span> <span class="o">=</span> <span class="nf">guide_legend</span><span class="p">(</span><span class="n">label.position</span> <span class="o">=</span> <span class="s">&#34;bottom&#34;</span><span class="p">Ù«</span> <span class="n">keywidth</span> <span class="o">=</span> <span class="m">2</span><span class="p">)Ù«</span>
               <span class="n">color</span> <span class="o">=</span> <span class="nf">guide_legend</span><span class="p">(</span><span class="n">label.position</span> <span class="o">=</span> <span class="s">&#34;bottom&#34;</span><span class="p">Ù«</span> <span class="n">keywidth</span> <span class="o">=</span> <span class="m">2</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Age&#34;</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Estimated Density&#34;</span><span class="p">Ù«</span> 
      <span class="n">color</span> <span class="o">=</span> <span class="kc">NULL</span><span class="p">Ù«</span> <span class="n">fill</span> <span class="o">=</span> <span class="kc">NULL</span><span class="p">Ù«</span> 
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;{frame_time}. Relative Age Distribution of the U.S. Population by Sex&#34;</span><span class="p">Ù«</span> 
       <span class="n">subtitle</span> <span class="o">=</span> <span class="s">&#34;Age is top-coded at 75 until 1939Ù« at 85 until 1979Ù« and at 100 since 1980.&#34;</span><span class="p">Ù«</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;@kjhealy / http://kieranhealy.org.&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;bottom&#34;</span><span class="p">Ù«</span>
          <span class="n">plot.title</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">)Ù«</span> <span class="n">face</span> <span class="o">=</span> <span class="s">&#34;bold&#34;</span><span class="p">)Ù«</span>
          <span class="n">plot.subtitle</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))Ù«</span>
          <span class="n">plot.caption</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">))Ù«</span>
          <span class="n">axis.text.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))Ù«</span>
          <span class="n">axis.title.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))Ù«</span>
          <span class="n">axis.title.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))Ù«</span>
          <span class="n">axis.text.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))Ù«</span>
          <span class="n">legend.text</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">)))</span> <span class="o">+</span>
  <span class="nf">transition_time</span><span class="p">(</span><span class="nf">as.integer</span><span class="p">(</span><span class="nf">year</span><span class="p">(</span><span class="n">year</span><span class="p">)))</span> <span class="o">+</span> 
  <span class="nf">ease_aes</span><span class="p">(</span><span class="s">&#34;linear&#34;</span><span class="p">)</span> <span class="o">+</span> 
    <span class="nf">transition_time</span><span class="p">(</span><span class="nf">as.integer</span><span class="p">(</span><span class="n">year</span><span class="p">))</span> <span class="o">+</span> 
    <span class="nf">ease_aes</span><span class="p">(</span><span class="s">&#34;cubic-in-out&#34;</span><span class="p">)</span>
    
<span class="nf">animate</span><span class="p">(</span><span class="n">p_dens</span><span class="p">Ù«</span> <span class="n">fps</span> <span class="o">=</span> <span class="m">25</span><span class="p">Ù«</span> <span class="n">duration</span> <span class="o">=</span> <span class="m">30</span><span class="p">Ù«</span> <span class="n">width</span> <span class="o">=</span> <span class="m">1024</span><span class="p">Ù«</span> <span class="n">height</span> <span class="o">=</span> <span class="m">1024</span><span class="p">Ù«</span> <span class="n">renderer</span> <span class="o">=</span> <span class="nf">ffmpeg_renderer</span><span class="p">())</span>

</code></pre></td></tr></table>
</div>
</div>

<p>The <code>theme()</code> calls are all about making the default label text largerÙ« using the handy <code>rel()</code> function to boost size in relative terms rather than worrying about units. We get the animation almost for freeÙ« thanks to Thomas Lin Pedersen&rsquo;s <code>gganimate</code> package. Just the two functionsÙ« <code>transition_time()</code> and <code>ease_aes()</code> do all the work. Then we use <code>animate()</code> to actually render the animation. After saving the results as an <code>mp4</code> fileÙ« here&rsquo;s what we get.</p>
<figure>
<video controls src="https://kieranhealy.org/files/misc/census_density_anim.mp4"></video>
</figure>
<p>The curves here are estimated kernel densities. A more conventional way to represent the demographic data we have is with a <em>population pyramid</em>Ù« where we put ages on the x axis and population counts (or percentages) on the y axisÙ« and then put males on the left and females on the right. To accomplish this in R we&rsquo;ll use <code>geom_ribbon()</code> and cheat a little bit by making the ages for males all be negative. Then we&rsquo;ll set the base of the male and female ribbons to be zero. Here&rsquo;s how that works. We&rsquo;re going to show the absolute rather than the relative population distributionÙ« so we can watch the size of the pyramid grow over time as well as see its shape change.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">pop_pyr</span> <span class="o">&lt;-</span> <span class="n">pop_lon</span>

<span class="c1">## Make all the Male ages negative</span>
<span class="n">pop_pyr</span><span class="o">$</span><span class="n">count[pop_pyr</span><span class="o">$</span><span class="n">group</span> <span class="o">==</span> <span class="s">&#34;male&#34;</span><span class="n">]</span> <span class="o">&lt;-</span> <span class="o">-</span><span class="n">pop_pyr</span><span class="o">$</span><span class="n">count[pop_pyr</span><span class="o">$</span><span class="n">group</span> <span class="o">==</span> <span class="s">&#34;male&#34;</span><span class="n">]</span>
</code></pre></td></tr></table>
</div>
</div>

<p>The code for the plot is very similar to before:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">mbreaks</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;1M&#34;</span><span class="p">Ù«</span> <span class="s">&#34;2M&#34;</span><span class="p">Ù«</span> <span class="s">&#34;3M&#34;</span><span class="p">)</span>

<span class="n">p</span> <span class="o">&lt;-</span> <span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">pop_pyr</span><span class="p">Ù«</span>
            <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">age</span><span class="p">Ù«</span> <span class="n">ymin</span> <span class="o">=</span> <span class="n">base</span><span class="p">Ù«</span>
                          <span class="n">ymax</span> <span class="o">=</span> <span class="n">count</span><span class="p">Ù«</span> <span class="n">fill</span> <span class="o">=</span> <span class="n">group</span><span class="p">))</span>

<span class="n">p_pyr_count</span> <span class="o">&lt;-</span> <span class="n">p</span> <span class="o">+</span> <span class="nf">geom_ribbon</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="m">0.5</span><span class="p">)</span> <span class="o">+</span>
    <span class="nf">scale_y_continuous</span><span class="p">(</span><span class="n">labels</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">rev</span><span class="p">(</span><span class="n">mbreaks</span><span class="p">)Ù«</span> <span class="s">&#34;0&#34;</span><span class="p">Ù«</span> <span class="n">mbreaks</span><span class="p">)Ù«</span> 
                       <span class="n">breaks</span> <span class="o">=</span> <span class="nf">seq</span><span class="p">(</span><span class="m">-3e6</span><span class="p">Ù«</span> <span class="m">3e6</span><span class="p">Ù«</span> <span class="m">1e6</span><span class="p">)Ù«</span> 
                       <span class="n">limits</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">-3e6</span><span class="p">Ù«</span> <span class="m">3e6</span><span class="p">))</span> <span class="o">+</span> 
    <span class="nf">scale_x_continuous</span><span class="p">(</span><span class="n">breaks</span> <span class="o">=</span> <span class="nf">seq</span><span class="p">(</span><span class="m">10</span><span class="p">Ù«</span> <span class="m">100</span><span class="p">Ù«</span> <span class="m">10</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">scale_fill_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">)Ù«</span> <span class="n">labels</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;Female&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Male&#34;</span><span class="p">))</span> <span class="o">+</span> 
    <span class="nf">guides</span><span class="p">(</span><span class="n">fill</span> <span class="o">=</span> <span class="nf">guide_legend</span><span class="p">(</span><span class="n">reverse</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">))</span> <span class="o">+</span>
    <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Age&#34;</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Number of People&#34;</span><span class="p">Ù«</span>
         <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;{frame_time}. Absolute Age Distribution of the U.S. Population by Sex&#34;</span><span class="p">Ù«</span>
         <span class="n">subtitle</span> <span class="o">=</span> <span class="s">&#34;Age is top-coded at 75 until 1939Ù« at 85 until 1979Ù« and at 100 since 1980.&#34;</span><span class="p">Ù«</span>
         <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Kieran Healy / kieranhealy.org / Data: US Census Bureau.&#34;</span><span class="p">Ù«</span>
         <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;&#34;</span><span class="p">)</span> <span class="o">+</span>
    <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;bottom&#34;</span><span class="p">Ù«</span>
          <span class="n">plot.title</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">)Ù«</span> <span class="n">face</span> <span class="o">=</span> <span class="s">&#34;bold&#34;</span><span class="p">)Ù«</span>
          <span class="n">plot.subtitle</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))Ù«</span>
          <span class="n">plot.caption</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">))Ù«</span>
          <span class="n">axis.text.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))Ù«</span>
          <span class="n">axis.text.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))Ù«</span>
          <span class="n">axis.title.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))Ù«</span>
          <span class="n">axis.title.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))Ù«</span>
          <span class="n">legend.text</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">)))</span> <span class="o">+</span>
    <span class="nf">coord_flip</span><span class="p">()</span> <span class="o">+</span> 
    <span class="nf">transition_time</span><span class="p">(</span><span class="nf">as.integer</span><span class="p">(</span><span class="n">year</span><span class="p">))</span> <span class="o">+</span> 
    <span class="nf">ease_aes</span><span class="p">(</span><span class="s">&#34;cubic-in-out&#34;</span><span class="p">)</span>
    
    
<span class="nf">animate</span><span class="p">(</span><span class="n">p_pyr_count</span><span class="p">Ù«</span> <span class="n">fps</span> <span class="o">=</span> <span class="m">25</span><span class="p">Ù«</span> <span class="n">duration</span> <span class="o">=</span> <span class="m">60</span><span class="p">Ù«</span> <span class="n">width</span> <span class="o">=</span> <span class="m">1024</span><span class="p">Ù«</span> <span class="n">height</span> <span class="o">=</span> <span class="m">1024</span><span class="p">Ù«</span> <span class="n">renderer</span> <span class="o">=</span> <span class="nf">ffmpeg_renderer</span><span class="p">())</span>
</code></pre></td></tr></table>
</div>
</div>

<p>The main changes are in the labeling. <code>geom_ribbon</code> needs a <code>ymin</code> and a <code>ymax</code> value. The former will always be zero. The latter will be the population count for that age. We make a little vector of population labelsÙ« <code>mbreaks</code>Ù« for the x-axisÙ« and join it up first in reverseÙ« and then in regular order on either side of zero: <code>labels = c(rev(mbreaks)Ù« &quot;0&quot;Ù« mbreaks)</code>. We also set the breaks between -3 million and 3 millon in steps of 1 millon: <code>breaks = seq(-3e6Ù« 3e6Ù« 1e6)</code>. The <code>cubic-in-out</code> easing function makes for a better-looking step-by-step animation than the default <code>linear</code>Ù« which bobbles around too much.</p>
<p>And here&rsquo;s the result.</p>
<figure>
<video controls src="https://kieranhealy.org/files/misc/census_abs_anim.mp4"></video
</figure>
<p>Just look at those Boomers go after 1946.</p>
<p>I&rsquo;ve been a little sketchy about the details of the cleaning process above because what I want to do is package up the clean dataset shortly so that other people don&rsquo;t have to experience the thrill of learning about the many virtues of <a href="https://www.gnu.org/software/sed/manual/sed.html">sed</a>.</p>
'),('https://kieranhealy.org/blog/archives/2020/03/07/this-be-the-kirsch/', 'This Be the Kirsch', '1583632066000',  15, '<blockquote>
They pluck your plumsÙ« your mum and dad<br />
They eat them for their supperÙ« too<br />
They gobble all the fruit you had<br />
And leave some bullshit note for you<br />
<br />
But they were robbed blind in their day<br />
Of damsonsÙ« prunesÙ« and blackthorn sloes<br />
Their breakfast treats were poached away<br />
And justified with old-style prose<br />
<br />
â€œForgive usâ€ both your parents moan<br />
â€œThey were deliciousÙ« sweetÙ« and coldâ€<br />
They wonder why I never phone<br />
And from them my own kids withhold<br />
</blockquote>
<p>(<a href="https://kieranhealy.org/blog/archives/2014/07/19/this-is-just-to-say-he-wishes/">See also</a>)</p>
'),('https://kieranhealy.org/blog/archives/2020/03/05/spanish-flu/', 'Spanish Flu', '1583458107000',  15, '<p>I was teaching some dplyr and ggplot today. Because Coronavirus is in theÙ« uhÙ« airÙ« I decided to work with the mortality data from <a href="http://mortality.org">http://mortality.org</a> and have the students practice getting a bunch of data files into R and then plotting the resulting data quickly and informatively. We took a look at the years around the 1918 Influenza Epidemic andÙ« after poking at the data for a little whileÙ« came to realize why it was called the <em>Spanish</em> Flu. Here&rsquo;s some code you can run if you download the (freely available) 1x1 mortality files from &lt;mortality.org&gt;.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="nf">library</span><span class="p">(</span><span class="n">here</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">janitor</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>

<span class="c1">## Where the data is locally</span>
<span class="n">path</span> <span class="o">&lt;-</span> <span class="s">&#34;data/Mx_1x1/&#34;</span>

<span class="c1">## Colors for later</span>
<span class="n">my_colors</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;#0072B2&#34;</span><span class="p">Ù«</span> <span class="s">&#34;#E69F00&#34;</span><span class="p">)</span>

<span class="c1">## Some utility functions for cleaning</span>
<span class="n">get_country_name</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">){</span>
  <span class="nf">read_lines</span><span class="p">(</span><span class="n">x</span><span class="p">Ù«</span> <span class="n">n_max</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="nf">str_extract</span><span class="p">(</span><span class="s">&#34;.+?Ù«&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="nf">str_remove</span><span class="p">(</span><span class="s">&#34;Ù«&#34;</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">shorten_name</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">){</span>
  <span class="nf">str_replace_all</span><span class="p">(</span><span class="n">x</span><span class="p">Ù«</span> <span class="s">&#34; -- &#34;</span><span class="p">Ù«</span> <span class="s">&#34; &#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="nf">str_replace</span><span class="p">(</span><span class="s">&#34;The United States of America&#34;</span><span class="p">Ù«</span> <span class="s">&#34;USA&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">snakecase</span><span class="o">::</span><span class="nf">to_any_case</span><span class="p">()</span>
<span class="p">}</span>

<span class="n">make_ccode</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">){</span>
  <span class="nf">str_extract</span><span class="p">(</span><span class="n">x</span><span class="p">Ù«</span> <span class="s">&#34;[:upper:]+((?=\\.))&#34;</span><span class="p">)</span>
<span class="p">}</span>

</code></pre></td></tr></table>
</div>
</div>

<p>First we&rsquo;re going to make a little tibble of country codesÙ« namesÙ« and associated file paths.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">filenames</span> <span class="o">&lt;-</span> <span class="nf">dir</span><span class="p">(</span><span class="n">path</span> <span class="o">=</span> <span class="nf">here</span><span class="p">(</span><span class="n">path</span><span class="p">)Ù«</span>
                 <span class="n">pattern</span> <span class="o">=</span> <span class="s">&#34;*.txt&#34;</span><span class="p">Ù«</span>
                 <span class="n">full.names</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>

<span class="n">countries</span> <span class="o">&lt;-</span> <span class="nf">tibble</span><span class="p">(</span><span class="n">country</span> <span class="o">=</span> <span class="nf">map_chr</span><span class="p">(</span><span class="n">filenames</span><span class="p">Ù«</span> <span class="n">get_country_name</span><span class="p">)Ù«</span>
                    <span class="n">cname</span> <span class="o">=</span> <span class="nf">map_chr</span><span class="p">(</span><span class="n">country</span><span class="p">Ù«</span> <span class="n">shorten_name</span><span class="p">)Ù«</span>
                    <span class="n">ccode</span> <span class="o">=</span> <span class="nf">map_chr</span><span class="p">(</span><span class="n">filenames</span><span class="p">Ù«</span> <span class="n">make_ccode</span><span class="p">)Ù«</span>
                    <span class="n">path</span> <span class="o">=</span> <span class="n">filenames</span><span class="p">)</span>

<span class="n">countries</span>

<span class="c1"># A tibble: 49 x 4</span>
   <span class="n">country</span>    <span class="n">cname</span>     <span class="n">ccode</span> <span class="n">path</span>                                    
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>      <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>     <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>                                   
 <span class="m">1</span> <span class="n">Australia</span>  <span class="n">australia</span> <span class="n">AUS</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>â€¦
 <span class="m">2</span> <span class="n">Austria</span>    <span class="n">austria</span>   <span class="n">AUT</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>â€¦
 <span class="m">3</span> <span class="n">Belgium</span>    <span class="n">belgium</span>   <span class="n">BEL</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>â€¦
 <span class="m">4</span> <span class="n">Bulgaria</span>   <span class="n">bulgaria</span>  <span class="n">BGR</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>â€¦
 <span class="m">5</span> <span class="n">Belarus</span>    <span class="n">belarus</span>   <span class="n">BLR</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>â€¦
 <span class="m">6</span> <span class="n">Canada</span>     <span class="n">canada</span>    <span class="n">CAN</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>â€¦
 <span class="m">7</span> <span class="n">Switzerla</span>â€¦ <span class="n">switzerl</span>â€¦ <span class="n">CHE</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>â€¦
 <span class="m">8</span> <span class="n">Chile</span>      <span class="n">chile</span>     <span class="n">CHL</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>â€¦
 <span class="m">9</span> <span class="n">Czechia</span>    <span class="n">czechia</span>   <span class="n">CZE</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>â€¦
<span class="m">10</span> <span class="n">East</span> <span class="n">Germ</span>â€¦ <span class="n">east_ger</span>â€¦ <span class="n">DEUTE</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>â€¦
<span class="c1"># â€¦ with 39 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Next we ingest the data as a nested columnÙ« clean it a littleÙ« and subset it to those countries that we actually have mortality data for from the relevant time period.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">mortality</span> <span class="o">&lt;-</span> <span class="n">countries</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span><span class="n">path</span><span class="p">Ù«</span>
                    <span class="o">~</span> <span class="nf">read_table</span><span class="p">(</span><span class="n">.Ù«</span> <span class="n">skip</span> <span class="o">=</span> <span class="m">2</span><span class="p">Ù«</span> <span class="n">na</span> <span class="o">=</span> <span class="s">&#34;.&#34;</span><span class="p">)))</span> <span class="o">%&gt;%</span>
  <span class="nf">unnest</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">age</span> <span class="o">=</span> <span class="nf">as.integer</span><span class="p">(</span><span class="nf">recode</span><span class="p">(</span><span class="n">age</span><span class="p">Ù«</span> <span class="s">&#34;110+&#34;</span> <span class="o">=</span> <span class="s">&#34;110&#34;</span><span class="p">)))</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">path</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">nest</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">year</span><span class="o">:</span><span class="n">total</span><span class="p">))</span>

<span class="c1">## Subset to flu years / countries</span>
<span class="n">flu</span> <span class="o">&lt;-</span> <span class="n">mortality</span> <span class="o">%&gt;%</span> 
  <span class="nf">unnest</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">country</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">year</span><span class="p">)</span> <span class="o">&lt;</span> <span class="m">1918</span><span class="p">)</span>

<span class="n">flu</span>

<span class="c1"># A tibble: 298Ù«923 x 8</span>
<span class="c1"># Groups:   country [14]</span>
   <span class="n">country</span> <span class="n">cname</span>   <span class="n">ccode</span>  <span class="n">year</span>   <span class="n">age</span>  <span class="n">female</span>    <span class="n">male</span>   <span class="n">total</span>
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">int</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>
 <span class="m">1</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">0</span> <span class="m">0.152</span>   <span class="m">0.187</span>   <span class="m">0.169</span>  
 <span class="m">2</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">1</span> <span class="m">0.0749</span>  <span class="m">0.0741</span>  <span class="m">0.0745</span> 
 <span class="m">3</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">2</span> <span class="m">0.0417</span>  <span class="m">0.0398</span>  <span class="m">0.0408</span> 
 <span class="m">4</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">3</span> <span class="m">0.0255</span>  <span class="m">0.0233</span>  <span class="m">0.0244</span> 
 <span class="m">5</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">4</span> <span class="m">0.0185</span>  <span class="m">0.0171</span>  <span class="m">0.0178</span> 
 <span class="m">6</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">5</span> <span class="m">0.0139</span>  <span class="m">0.0124</span>  <span class="m">0.0132</span> 
 <span class="m">7</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">6</span> <span class="m">0.0128</span>  <span class="m">0.0102</span>  <span class="m">0.0115</span> 
 <span class="m">8</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">7</span> <span class="m">0.0109</span>  <span class="m">0.00800</span> <span class="m">0.00944</span>
 <span class="m">9</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">8</span> <span class="m">0.00881</span> <span class="m">0.00701</span> <span class="m">0.00789</span>
<span class="m">10</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">9</span> <span class="m">0.00814</span> <span class="m">0.00696</span> <span class="m">0.00754</span>
<span class="c1"># â€¦ with 298Ù«913 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>For the purposes of labeling an upcoming plotÙ« we&rsquo;re going to make a little dummy dataset.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">dat_text</span> <span class="o">&lt;-</span> <span class="nf">data.frame</span><span class="p">(</span>
  <span class="n">label</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;1918&#34;</span><span class="p">Ù«</span> <span class="nf">rep</span><span class="p">(</span><span class="kc">NA</span><span class="p">Ù«</span> <span class="m">5</span><span class="p">))Ù«</span>
  <span class="n">agegrp</span> <span class="o">=</span> <span class="nf">factor</span><span class="p">(</span><span class="nf">paste</span><span class="p">(</span><span class="s">&#34;Age&#34;</span><span class="p">Ù«</span> <span class="nf">seq</span><span class="p">(</span><span class="m">10</span><span class="p">Ù«</span> <span class="m">60</span><span class="p">Ù«</span> <span class="m">10</span><span class="p">)))Ù«</span>
  <span class="n">year</span>     <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">1920</span><span class="p">Ù«</span> <span class="nf">rep</span><span class="p">(</span><span class="kc">NA</span><span class="p">Ù«</span> <span class="m">5</span><span class="p">))Ù«</span>
  <span class="n">female</span>     <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">0.04</span><span class="p">Ù«</span> <span class="nf">rep</span><span class="p">(</span><span class="kc">NA</span><span class="p">Ù«</span> <span class="m">5</span><span class="p">))Ù«</span> 
  <span class="n">flag</span> <span class="o">=</span> <span class="nf">rep</span><span class="p">(</span><span class="kc">NA</span><span class="p">Ù«</span> <span class="m">6</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">dat_text</span>

<span class="n">label</span> <span class="n">agegrp</span> <span class="n">year</span> <span class="n">female</span> <span class="n">flag</span>
<span class="m">1</span>  <span class="m">1918</span> <span class="n">Age</span> <span class="m">10</span> <span class="m">1920</span>   <span class="m">0.04</span>   <span class="kc">NA</span>
<span class="m">2</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> <span class="n">Age</span> <span class="m">20</span>   <span class="kc">NA</span>     <span class="kc">NA</span>   <span class="kc">NA</span>
<span class="m">3</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> <span class="n">Age</span> <span class="m">30</span>   <span class="kc">NA</span>     <span class="kc">NA</span>   <span class="kc">NA</span>
<span class="m">4</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> <span class="n">Age</span> <span class="m">40</span>   <span class="kc">NA</span>     <span class="kc">NA</span>   <span class="kc">NA</span>
<span class="m">5</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> <span class="n">Age</span> <span class="m">50</span>   <span class="kc">NA</span>     <span class="kc">NA</span>   <span class="kc">NA</span>
<span class="m">6</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> <span class="n">Age</span> <span class="m">60</span>   <span class="kc">NA</span>     <span class="kc">NA</span>   <span class="kc">NA</span>


</code></pre></td></tr></table>
</div>
</div>

<p>And now we filter the data to look only at female mortality between 1900 and 1929 for a series of specific ages: every decade from 10 years old to 60 years old. We&rsquo;ll use that dummy dataset to label the first (but only the first) panel in the faceted plot we&rsquo;re going to draw.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">p0</span> <span class="o">&lt;-</span> <span class="n">flu</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">country</span><span class="p">Ù«</span> <span class="n">year</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">year</span> <span class="o">&gt;</span> <span class="m">1899</span> <span class="o">&amp;</span> <span class="n">year</span> <span class="o">&lt;</span> <span class="m">1930</span><span class="p">Ù«</span> <span class="n">age</span> <span class="o">%in%</span> <span class="nf">seq</span><span class="p">(</span><span class="m">10</span><span class="p">Ù«</span> <span class="m">60</span><span class="p">Ù«</span> <span class="n">by</span> <span class="o">=</span> <span class="m">10</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">flag</span> <span class="o">=</span> <span class="n">country</span> <span class="o">%in%</span> <span class="s">&#34;Spain&#34;</span><span class="p">Ù«</span> 
         <span class="n">agegrp</span> <span class="o">=</span> <span class="nf">paste</span><span class="p">(</span><span class="s">&#34;Age&#34;</span><span class="p">Ù«</span> <span class="n">age</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">ggplot</span><span class="p">(</span><span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">year</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="n">female</span><span class="p">Ù«</span> <span class="n">color</span> <span class="o">=</span> <span class="n">flag</span><span class="p">))</span> <span class="o">+</span> 
  <span class="nf">geom_vline</span><span class="p">(</span><span class="n">xintercept</span> <span class="o">=</span> <span class="m">1918</span><span class="p">Ù«</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;gray80&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">geom_line</span><span class="p">(</span><span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">group</span> <span class="o">=</span> <span class="n">country</span><span class="p">))</span> 

<span class="n">p1</span> <span class="o">&lt;-</span> <span class="n">p0</span> <span class="o">+</span>  <span class="nf">geom_text</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">dat_text</span><span class="p">Ù«</span> 
                <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">year</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="n">female</span><span class="p">Ù«</span> <span class="n">label</span> <span class="o">=</span> <span class="n">label</span><span class="p">)Ù«</span> 
                <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;black&#34;</span><span class="p">Ù«</span> 
                <span class="n">show.legend</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">Ù«</span> 
                <span class="n">group</span> <span class="o">=</span> <span class="m">1</span><span class="p">Ù«</span> 
                <span class="n">size</span> <span class="o">=</span> <span class="m">3</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="n">my_colors</span><span class="p">Ù«</span> 
                     <span class="n">labels</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;Other Countries&#34;</span><span class="p">Ù«</span> <span class="s">&#34;Spain&#34;</span><span class="p">))</span> <span class="o">+</span> 
  <span class="nf">scale_y_continuous</span><span class="p">(</span><span class="n">labels</span> <span class="o">=</span> <span class="n">scales</span><span class="o">::</span><span class="n">percent</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">labs</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Female MortalityÙ« Selected Ages and Countries 1900-1929&#34;</span><span class="p">Ù«</span> 
       <span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Year&#34;</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Female Mortality Rate&#34;</span><span class="p">Ù«</span> <span class="n">color</span> <span class="o">=</span> <span class="kc">NULL</span><span class="p">Ù«</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;@kjhealy / Data: mortality.org&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">facet_wrap</span><span class="p">(</span><span class="o">~</span> <span class="n">agegrp</span><span class="p">Ù«</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;top&#34;</span><span class="p">)</span>
  
<span class="n">p1</span>

</code></pre></td></tr></table>
</div>
</div>

<figure>
    <img src="https://kieranhealy.org/files/misc/spanish-flu.png"/> 
</figure>
<p>And thusÙ« Spanish Flu. Though it looks like it was no joke to be an older woman in Spain during any part of the early 20th century.</p>
'),('https://kieranhealy.org/blog/archives/2020/02/26/a-new-baby-boom-poster/', 'A New Baby Boom Poster', '1582748242000',  15, '<p>I wanted to work through a few examples of more polished graphics done mostly but perhaps not entirely in R. SoÙ« I revisited the Baby Boom visualizations I made a while ago and made a new poster with them. This allowed me to play around with a few packages that I either hadn&rsquo;t made use of or that weren&rsquo;t available the first time around. The most notable additions are <a href="https://robjhyndman.com/software/">Rob Hyndman&rsquo;s suite of tidy tools for time series analysis</a> and Thomas Lin Pedersen&rsquo;s packages <a href="https://ggforce.data-imaginist.com">ggforce</a> and <a href="https://patchwork.data-imaginist.com">patchwork</a>. These are all fantastic resources. The time series decomposition was done with the <code>tsibble</code> family of tools. Meanwhile <code>ggforce</code> and <code>patchwork</code> allow for a tremendous degree of flexibility in laying out multiple plots while still being very straightforward to use. Here&rsquo;s a preview of the result:</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/okboomer_composite_poster-300-01.png"
         alt="OK boomer"/> <figcaption>
            <p>OK Boomer</p>
        </figcaption>
</figure>
<p>For nowÙ« the annotations were done in post-production (as they say in the movie biz) rather than in RÙ« but I think I&rsquo;ll be looking to see whether it&rsquo;s worth taking advantage of some other packages to do those in R as well.</p>
<p>The time series decomposition takes the births series and separates it into trendÙ« seasonalÙ« and remainder components. (It&rsquo;s an STL decomposition; there are a bunch of other alternatives.) OftenÙ« the seasonal and remainder components will end up on quite different scales from the trend. The default plotting methods for decompositions will often show variably-sized vertical bars to the left of each panelÙ« to remind the viewer that the scales are different. But <code>ggforce</code> has a <code>facet_col()</code> function that allows the space taken up by a facet to vary in the same way that one can allow the scales on an ordinary facet&rsquo;s axes to vary. UsuallyÙ« variable scaling isn&rsquo;t desirable in a small-multipleÙ« because the point is to make comparisons across panels. But in this case the combination of free scales and free spacing is very helpful.</p>
<p>Here&rsquo;s the snippet of code that makes the time series line graphs:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">p_trends</span> <span class="o">&lt;-</span> <span class="nf">ggplot</span><span class="p">(</span><span class="n">data_lon</span><span class="p">Ù«</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">date</span><span class="p">Ù«</span> <span class="n">y</span> <span class="o">=</span> <span class="n">value</span><span class="p">))</span> <span class="o">+</span> 
    <span class="nf">geom_line</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="s">&#34;gray20&#34;</span><span class="p">)</span> <span class="o">+</span> 
    <span class="nf">scale_x_date</span><span class="p">(</span><span class="n">breaks</span> <span class="o">=</span> <span class="n">break_vec</span><span class="p">Ù«</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">break_labs</span><span class="p">Ù«</span> <span class="n">expand</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">Ù«</span><span class="m">0</span><span class="p">))</span> <span class="o">+</span> 
    <span class="nf">facet_col</span><span class="p">(</span><span class="o">~</span> <span class="n">name</span><span class="p">Ù«</span> <span class="n">space</span> <span class="o">=</span> <span class="s">&#34;free&#34;</span><span class="p">Ù«</span> <span class="n">scales</span> <span class="o">=</span> <span class="s">&#34;free_y&#34;</span><span class="p">)</span> <span class="o">+</span> 
    <span class="nf">theme</span><span class="p">(</span>  <span class="n">strip.background</span> <span class="o">=</span> <span class="nf">element_blank</span><span class="p">()Ù«</span>
            <span class="n">strip.text.x</span> <span class="o">=</span> <span class="nf">element_blank</span><span class="p">())</span> <span class="o">+</span> 
    <span class="nf">labs</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="kc">NULL</span><span class="p">Ù«</span> <span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Year&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div>

<p>Meanwhile combining the trends plot with the tiled heatmap (called <code>p_tile</code>) is a piece of cake with <code>patchwork</code>:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="p">(</span><span class="n">p_tile</span> <span class="o">/</span> <span class="n">p_trends</span><span class="p">)</span> <span class="o">+</span> <span class="nf">plot_layout</span><span class="p">(</span><span class="n">heights</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">30</span><span class="p">Ù«</span> <span class="m">70</span><span class="p">))</span> 
</code></pre></td></tr></table>
</div>
</div>

<p>The <code>/</code> convention means stack the plot objectsÙ« and <code>plot_layout()</code> proportionally divides the available space.</p>
<p>Chances are that I&rsquo;ll make some posters of these and other recent visualizations. Because people often askÙ« I&rsquo;ve been looking into options for making them available for sale in various formats &hellip; hopefully that&rsquo;ll be sorted out soon and I can join e.g. <em>Waterlilies</em>Ù« <em>The Kiss</em>Ù« and John Belushi on dorm room walls everywhere.</p>
<p>The code for the decomposition and the core plots is <a href="https://github.com/kjhealy/us_births">on GitHub</a>.</p>
'),('https://kieranhealy.org/blog/archives/2020/02/18/dataviz-workshop-at-rstudioconf/', 'Dataviz Workshop at RStudio::conf', '1582046991000',  15, '<blockquote>
<p>Workshop materials are available here:  <a href="https://rstd.io/conf20-dataviz">https://rstd.io/conf20-dataviz</a> <br>
Consider buying the book; it&rsquo;s good: <a href="http://socviz.co">Data Visualization: A Practical Introduction</a> / <a href="https://www.amazon.com/Data-Visualization-Introduction-Kieran-Healy/dp/0691181624">Buy on Amazon</a></p>
</blockquote>
<p>I was delighted to have the opportunity to teach a two-day workshop on Data Visualization using ggplot2 at this year&rsquo;s <a href="https://rstudio.com/conference/">rstudio::conf(2020)</a> in January. It was my first time attending the conference and it was a terrific experience. I particularly appreciated the friendly and constructive atmosphere that RStudio so clearly goes out of its way to encourage and sustain.</p>
<p>The workshop focused on learning how to think about good data visualization in principleÙ« and how to do it in practice. After many years of trying and often failing to learn how to make good visualizations myselfÙ« I became convinced of two things. FirstÙ« there is a real need for an approach that effectively combines the <em>why</em> of visualization with the <em>how</em>. A lot of otherwise excellent introductions to data visualization will teach you why some visualizations work better than othersÙ« and will present a series of mouth-watering examples of fabulous graphics. Then you sit down in front of an empty <code>.Rmarkdown</code> file and &hellip; now what? How do I <em>do</em> that?</p>
<p>MeanwhileÙ« many very goodÙ« detailed introductions to writing ggplot2 code may be a little out of reach for beginners or&mdash;perhaps more often&mdash;will tend to get picked up by users in a recipe-like or piecemeal way. People cast around to find out how to more or less solve a particular problem they are having. But they leave without really having a good grasp on why the code they are using looks the way it does. The result is that even people who are pretty used to working in R and who regularly make graphs from data end up with a hazy idea of what they&rsquo;re doing when they use ggplot.</p>
<p>The second thing I became convinced of as I developed this material was that data visualization is a <em>fantastic</em> way to introduce people to the world of data analysis with R generally. When visualizing data with R and ggplotÙ« it&rsquo;s possible to produce satisfying results almost right away. That makes it easier to introduce other tidyverse principles and tools in an organic fashion.</p>
<p>For both of those reasonsÙ« I ended up <a href="http://socviz.co">writing a book</a> that approached things in just the way I wanted: a practical introduction to data visualization using ggplot2 that kept both the ideas and the code in viewÙ« and tried to do so in an engaging and approachable way. It was this text that formed the core of the workshop.</p>
<p>While teaching over the two daysÙ« I was assisted by four TAs:</p>
<ul>
<li><a href="http://www.twitter.com/dataandme/">Mara Averick</a></li>
<li><a href="https://www.twitter.com/paleolimbot/">Dewey Dunnington</a></li>
<li><a href="https://www.twitter.com/ariespirgel/">Ari Spirgel</a></li>
<li><a href="https://www.twitter.com/thomasp85">Thomas Lin Pedersen</a></li>
</ul>
<p>When I saw the rosterÙ« my first reaction was that mine was the only name I didn&rsquo;t recognize. Having Thomas as a TAÙ« in particularÙ« did rather threaten to cross the line from the merely embarrassing to the faintly absurd. It was a real treat to meet and work with everyone for the first time.</p>
<p>The materials from the workshop are available at the <a href="https://rstd.io/conf20-dataviz">GitHub repository for the course</a>. The repo contains all the code we went through as well as PDFs of all of the slides. The code and the slides also include additional examples and other extensions that we did not have time to cover in over the two daysÙ« or that I just mentioned in passing.</p>
<p>One of the benefits of teaching a short course like this is that I get a (sometimes sharp!) reminder of what works best and what needs tweaking across the various topics covered. Revisiting the codeÙ« in particularÙ« is always necessary just because the best way to do something will change over time. For exampleÙ« a few of the small tricks and workarounds that I show for dealing with boxplots will shortly become unneccessaryÙ« thanks to the work of ThomasÙ« DeweyÙ« and others on the next version of ggplot. I&rsquo;m looking forward to incorporating those elements and more into the next version of the workshop.</p>
<p>Data visualization is a powerful way to explore your own data and communicate your results to other people. One of the themes of the bookÙ« and the workshopÙ« is that it is in most ways a tool like any other. It won&rsquo;t magically render you immune to error or make it impossible for you to fool othersÙ« or fool yourself. But once you get a feel for how to work with itÙ« it makes your work easier and better in many ways. The great strength of the approach taken by the grammar of graphics in general and ggplot in particular is that it gives people a powerful &ldquo;flow of action&rdquo; to follow. It provides a set of concepts&mdash;mappingsÙ« geomsÙ« scalesÙ« facetsÙ« layersÙ« and so on&mdash;that let you look at other people&rsquo;s graphics and really see how their component pieces fit together. And it implements those concepts as a series of functions that let you coherently assemble graphics yourself. The goal of the workshop was to bring people to the point where they could comfortably write code that would clearly say what they wanted to see.</p>
'),('https://kieranhealy.org/blog/archives/2019/11/10/cleaning-the-table/', 'Cleaning the Table', '1573405973000',  15, '<p>While I&rsquo;m talking about <a href="https://kieranhealy.org/blog/archives/2019/11/09/reading-in-data/">getting data into R</a> this weekendÙ« here&rsquo;s another quick example that came up in class this week. The mortality data in the <a href="https://kieranhealy.org/blog/archives/2019/11/09/reading-in-data/">previous example</a> were nice and clean coming in the door. That&rsquo;s usually not the case. Data can be and usually is messy in all kinds of ways. One of the most commonÙ« particularly in the case of summary tables obtained from some source or otherÙ« is that the values aren&rsquo;t directly usable. The following summary table was copied and pasted into Excel from an external sourceÙ« saved as a CSV fileÙ« and arrived looking like this:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>

<span class="n">rfm_tbl</span> <span class="o">&lt;-</span> <span class="nf">read_csv</span><span class="p">(</span><span class="s">&#34;data/rfm_table.csv&#34;</span><span class="p">)</span>


<span class="c1">## Parsed with column specification:</span>
<span class="c1">## cols(</span>
<span class="c1">##   SEGMENT = col_character()Ù«</span>
<span class="c1">##   DESCRIPTION = col_character()Ù«</span>
<span class="c1">##   R = col_character()Ù«</span>
<span class="c1">##   F = col_character()Ù«</span>
<span class="c1">##   M = col_character()</span>
<span class="c1">## )</span>


<span class="n">rfm_tbl</span> 


<span class="c1">## # A tibble: 23 x 5</span>
<span class="c1">##    SEGMENT        DESCRIPTION                             R     F     M    </span>
<span class="c1">##    &lt;chr&gt;          &lt;chr&gt;                                   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;</span>
<span class="c1">##  1 &lt;NA&gt;           &lt;NA&gt;                                    &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; </span>
<span class="c1">##  2 Champions      Bought recentlyÙ« buy often and spend tâ€¦ 4â€“ 5  4â€“ 5  4â€“ 5 </span>
<span class="c1">##  3 &lt;NA&gt;           &lt;NA&gt;                                    &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; </span>
<span class="c1">##  4 Loyal Customeâ€¦ Spend good money. Responsive to promotâ€¦ 2â€“ 5  3â€“ 5  3â€“ 5 </span>
<span class="c1">##  5 &lt;NA&gt;           &lt;NA&gt;                                    &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; </span>
<span class="c1">##  6 Potential Loyâ€¦ Recent customersÙ« spent good amountÙ« bâ€¦ 3â€“ 5  1â€“ 3  1â€“ 3 </span>
<span class="c1">##  7 &lt;NA&gt;           &lt;NA&gt;                                    &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; </span>
<span class="c1">##  8 New Customers  Bought more recentlyÙ« but not often     4â€“ 5  &lt;= 1  &lt;= 1 </span>
<span class="c1">##  9 &lt;NA&gt;           &lt;NA&gt;                                    &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; </span>
<span class="c1">## 10 Promising      Recent shoppersÙ« but havenâ€™t spent much 3â€“ 4  &lt;= 1  &lt;= 1 </span>
<span class="c1">## # â€¦ with 13 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>This is messy and we can&rsquo;t do anything with the values in <code>R</code>Ù« <code>F</code>Ù« and <code>M</code>. Ultimately we want a table with separate columns containing the low and high values for these variables. If no lower bound is shownÙ« the lower bound is zero. We&rsquo;re going to use a few toolsÙ« notably <code>separate()</code> to get where we want to be. I&rsquo;ll step through this pipeline one piece at a timeÙ« so you can see how the table is being changed from start to finish.</p>
<p>First let&rsquo;s clean clean the variable names and remove the entirely blank lines.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">rfm_tbl</span> <span class="o">%&gt;%</span> 
  <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">filter_all</span><span class="p">(</span><span class="nf">any_vars</span><span class="p">(</span><span class="o">!</span><span class="nf">is.na</span><span class="p">(</span><span class="n">.)</span><span class="p">))</span> 


<span class="c1">## # A tibble: 11 x 5</span>
<span class="c1">##    segment        description                             r     f     m    </span>
<span class="c1">##    &lt;chr&gt;          &lt;chr&gt;                                   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;</span>
<span class="c1">##  1 Champions      Bought recentlyÙ« buy often and spend tâ€¦ 4â€“ 5  4â€“ 5  4â€“ 5 </span>
<span class="c1">##  2 Loyal Customeâ€¦ Spend good money. Responsive to promotâ€¦ 2â€“ 5  3â€“ 5  3â€“ 5 </span>
<span class="c1">##  3 Potential Loyâ€¦ Recent customersÙ« spent good amountÙ« bâ€¦ 3â€“ 5  1â€“ 3  1â€“ 3 </span>
<span class="c1">##  4 New Customers  Bought more recentlyÙ« but not often     4â€“ 5  &lt;= 1  &lt;= 1 </span>
<span class="c1">##  5 Promising      Recent shoppersÙ« but havenâ€™t spent much 3â€“ 4  &lt;= 1  &lt;= 1 </span>
<span class="c1">##  6 Need Attention Above average recencyÙ« frequency &amp; monâ€¦ 2â€“ 3  2â€“ 3  2â€“ 3 </span>
<span class="c1">##  7 About To Sleep Below average recencyÙ« frequency &amp; monâ€¦ 2â€“ 3  &lt;= 2  &lt;= 2 </span>
<span class="c1">##  8 At Risk        Spent big moneyÙ« purchased often but lâ€¦ &lt;= 2  2â€“ 5  2â€“ 5 </span>
<span class="c1">##  9 Canâ€™t Lose Thâ€¦ Made big purchases and oftenÙ« but longâ€¦ &lt;= 1  4â€“ 5  4â€“ 5 </span>
<span class="c1">## 10 Hibernating    Low spendersÙ« low frequencyÙ« purchasedâ€¦ 1â€“ 2  1â€“ 2  1â€“ 2 </span>
<span class="c1">## 11 Lost           Lowest recencyÙ« frequency &amp; monetary sâ€¦ &lt;= 2  &lt;= 2  &lt;= 2</span>
</code></pre></td></tr></table>
</div>
</div>

<p>Next we start work on the values. I thought about different ways of doing thisÙ« notably working out a way to apply or map <code>separate()</code> to each of the columns I want to change. I got slightly bogged down doing thisÙ« and instead decided to lengthen the <code>r</code>Ù« <code>f</code>Ù« and <code>m</code> variables into a single key-value pairÙ« do the recoding thereÙ« and then widen the result again. FirstÙ« lengthen the data:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">rfm_tbl</span> <span class="o">%&gt;%</span> 
  <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">filter_all</span><span class="p">(</span><span class="nf">any_vars</span><span class="p">(</span><span class="o">!</span><span class="nf">is.na</span><span class="p">(</span><span class="n">.)</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_longer</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="n">r</span><span class="o">:</span><span class="n">m</span><span class="p">)</span>


<span class="c1">## # A tibble: 33 x 4</span>
<span class="c1">##    segment         description                                  name  value</span>
<span class="c1">##    &lt;chr&gt;           &lt;chr&gt;                                        &lt;chr&gt; &lt;chr&gt;</span>
<span class="c1">##  1 Champions       Bought recentlyÙ« buy often and spend the moâ€¦ r     4â€“ 5 </span>
<span class="c1">##  2 Champions       Bought recentlyÙ« buy often and spend the moâ€¦ f     4â€“ 5 </span>
<span class="c1">##  3 Champions       Bought recentlyÙ« buy often and spend the moâ€¦ m     4â€“ 5 </span>
<span class="c1">##  4 Loyal Customers Spend good money. Responsive to promotions   r     2â€“ 5 </span>
<span class="c1">##  5 Loyal Customers Spend good money. Responsive to promotions   f     3â€“ 5 </span>
<span class="c1">##  6 Loyal Customers Spend good money. Responsive to promotions   m     3â€“ 5 </span>
<span class="c1">##  7 Potential Loyaâ€¦ Recent customersÙ« spent good amountÙ« boughtâ€¦ r     3â€“ 5 </span>
<span class="c1">##  8 Potential Loyaâ€¦ Recent customersÙ« spent good amountÙ« boughtâ€¦ f     1â€“ 3 </span>
<span class="c1">##  9 Potential Loyaâ€¦ Recent customersÙ« spent good amountÙ« boughtâ€¦ m     1â€“ 3 </span>
<span class="c1">## 10 New Customers   Bought more recentlyÙ« but not often          r     4â€“ 5 </span>
<span class="c1">## # â€¦ with 23 more rows</span>
</code></pre></td></tr></table>
</div>
</div>

<p>I&rsquo;m quite sure that there&rsquo;s an elegant way to use one of the <code>map()</code> functions to process the <code>r</code>Ù« <code>f</code>Ù« and <code>m</code> columns in sequence. But seeing as I couldn&rsquo;t quickly figure it outÙ« this alternative strategy works just fine. In factÙ« as a general approach I think it&rsquo;s always worth remembering that the tidyverse really &ldquo;wants&rdquo; your data to be in long formÙ« and lots of things that are awkward or conceptually tricky can suddenly become <em>much</em> easier if you get the data into the shape that the function toolbox wants it to be in. Lengthening the data you&rsquo;re working with is very often the right approachÙ« and you know you can widen it later on once you&rsquo;re done cleaning or otherwise manipulating it.</p>
<p>With our table in long format we can now use <code>separate()</code> on the value column. The <code>separate()</code> function is very handy for pulling apart variables that should be in different columns. Its defaults are goodÙ« too. In this case I didn&rsquo;t have to write a regular expression to specify the characters that are dividing up the values. In the function call we use <code>convert = TRUE</code> to turn the results into integersÙ« and <code>fill = &quot;left&quot;</code> because there&rsquo;s an implicit zero on the left of each entry that looks like e.g. <code>&lt;= 2</code>.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">rfm_tbl</span> <span class="o">%&gt;%</span> 
  <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">filter_all</span><span class="p">(</span><span class="nf">any_vars</span><span class="p">(</span><span class="o">!</span><span class="nf">is.na</span><span class="p">(</span><span class="n">.)</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_longer</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="n">r</span><span class="o">:</span><span class="n">m</span><span class="p">)</span> <span class="o">%&gt;%</span> 
  <span class="nf">separate</span><span class="p">(</span><span class="n">col</span> <span class="o">=</span> <span class="n">value</span><span class="p">Ù«</span> <span class="n">into</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;lo&#34;</span><span class="p">Ù«</span> <span class="s">&#34;hi&#34;</span><span class="p">)Ù«</span> 
           <span class="n">remove</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">Ù«</span> <span class="n">convert</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">Ù«</span> 
           <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;left&#34;</span><span class="p">)</span> 


<span class="c1">## # A tibble: 33 x 6</span>
<span class="c1">##    segment       description                        name  value    lo    hi</span>
<span class="c1">##    &lt;chr&gt;         &lt;chr&gt;                              &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt;</span>
<span class="c1">##  1 Champions     Bought recentlyÙ« buy often and spâ€¦ r     4â€“ 5      4     5</span>
<span class="c1">##  2 Champions     Bought recentlyÙ« buy often and spâ€¦ f     4â€“ 5      4     5</span>
<span class="c1">##  3 Champions     Bought recentlyÙ« buy often and spâ€¦ m     4â€“ 5      4     5</span>
<span class="c1">##  4 Loyal Customâ€¦ Spend good money. Responsive to pâ€¦ r     2â€“ 5      2     5</span>
<span class="c1">##  5 Loyal Customâ€¦ Spend good money. Responsive to pâ€¦ f     3â€“ 5      3     5</span>
<span class="c1">##  6 Loyal Customâ€¦ Spend good money. Responsive to pâ€¦ m     3â€“ 5      3     5</span>
<span class="c1">##  7 Potential Loâ€¦ Recent customersÙ« spent good amouâ€¦ r     3â€“ 5      3     5</span>
<span class="c1">##  8 Potential Loâ€¦ Recent customersÙ« spent good amouâ€¦ f     1â€“ 3      1     3</span>
<span class="c1">##  9 Potential Loâ€¦ Recent customersÙ« spent good amouâ€¦ m     1â€“ 3      1     3</span>
<span class="c1">## 10 New Customers Bought more recentlyÙ« but not oftâ€¦ r     4â€“ 5      4     5</span>
<span class="c1">## # â€¦ with 23 more rows</span>
</code></pre></td></tr></table>
</div>
</div>

<p>Before widening the data again we drop the <code>value</code> column. We don&rsquo;t need it anymore. (It will mess up the widening if we keep itÙ« too: try it and see what happens.)</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">rfm_tbl</span> <span class="o">%&gt;%</span> 
  <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">filter_all</span><span class="p">(</span><span class="nf">any_vars</span><span class="p">(</span><span class="o">!</span><span class="nf">is.na</span><span class="p">(</span><span class="n">.)</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_longer</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="n">r</span><span class="o">:</span><span class="n">m</span><span class="p">)</span> <span class="o">%&gt;%</span> 
  <span class="nf">separate</span><span class="p">(</span><span class="n">col</span> <span class="o">=</span> <span class="n">value</span><span class="p">Ù«</span> <span class="n">into</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;lo&#34;</span><span class="p">Ù«</span> <span class="s">&#34;hi&#34;</span><span class="p">)Ù«</span> 
           <span class="n">remove</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">Ù«</span> <span class="n">convert</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">Ù«</span> 
           <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;left&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">value</span><span class="p">)</span> 


<span class="c1">## # A tibble: 33 x 5</span>
<span class="c1">##    segment        description                             name     lo    hi</span>
<span class="c1">##    &lt;chr&gt;          &lt;chr&gt;                                   &lt;chr&gt; &lt;int&gt; &lt;int&gt;</span>
<span class="c1">##  1 Champions      Bought recentlyÙ« buy often and spend tâ€¦ r         4     5</span>
<span class="c1">##  2 Champions      Bought recentlyÙ« buy often and spend tâ€¦ f         4     5</span>
<span class="c1">##  3 Champions      Bought recentlyÙ« buy often and spend tâ€¦ m         4     5</span>
<span class="c1">##  4 Loyal Customeâ€¦ Spend good money. Responsive to promotâ€¦ r         2     5</span>
<span class="c1">##  5 Loyal Customeâ€¦ Spend good money. Responsive to promotâ€¦ f         3     5</span>
<span class="c1">##  6 Loyal Customeâ€¦ Spend good money. Responsive to promotâ€¦ m         3     5</span>
<span class="c1">##  7 Potential Loyâ€¦ Recent customersÙ« spent good amountÙ« bâ€¦ r         3     5</span>
<span class="c1">##  8 Potential Loyâ€¦ Recent customersÙ« spent good amountÙ« bâ€¦ f         1     3</span>
<span class="c1">##  9 Potential Loyâ€¦ Recent customersÙ« spent good amountÙ« bâ€¦ m         1     3</span>
<span class="c1">## 10 New Customers  Bought more recentlyÙ« but not often     r         4     5</span>
<span class="c1">## # â€¦ with 23 more rows</span>
</code></pre></td></tr></table>
</div>
</div>

<p>Now we can widen the dataÙ« with <code>pivot_wider()</code>.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">rfm_tbl</span> <span class="o">%&gt;%</span> 
  <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">filter_all</span><span class="p">(</span><span class="nf">any_vars</span><span class="p">(</span><span class="o">!</span><span class="nf">is.na</span><span class="p">(</span><span class="n">.)</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_longer</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="n">r</span><span class="o">:</span><span class="n">m</span><span class="p">)</span> <span class="o">%&gt;%</span> 
  <span class="nf">separate</span><span class="p">(</span><span class="n">col</span> <span class="o">=</span> <span class="n">value</span><span class="p">Ù«</span> <span class="n">into</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;lo&#34;</span><span class="p">Ù«</span> <span class="s">&#34;hi&#34;</span><span class="p">)Ù«</span> 
           <span class="n">remove</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">Ù«</span> <span class="n">convert</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">Ù«</span> 
           <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;left&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">value</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_wider</span><span class="p">(</span><span class="n">names_from</span> <span class="o">=</span> <span class="n">name</span><span class="p">Ù«</span> 
              <span class="n">values_from</span> <span class="o">=</span> <span class="n">lo</span><span class="o">:</span><span class="n">hi</span><span class="p">)</span> 


<span class="c1">## # A tibble: 11 x 8</span>
<span class="c1">##    segment     description               lo_r  lo_f  lo_m  hi_r  hi_f  hi_m</span>
<span class="c1">##    &lt;chr&gt;       &lt;chr&gt;                    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;</span>
<span class="c1">##  1 Champions   Bought recentlyÙ« buy ofâ€¦     4     4     4     5     5     5</span>
<span class="c1">##  2 Loyal Custâ€¦ Spend good money. Respoâ€¦     2     3     3     5     5     5</span>
<span class="c1">##  3 Potential â€¦ Recent customersÙ« spentâ€¦     3     1     1     5     3     3</span>
<span class="c1">##  4 New Customâ€¦ Bought more recentlyÙ« bâ€¦     4    NA    NA     5     1     1</span>
<span class="c1">##  5 Promising   Recent shoppersÙ« but haâ€¦     3    NA    NA     4     1     1</span>
<span class="c1">##  6 Need Attenâ€¦ Above average recencyÙ« â€¦     2     2     2     3     3     3</span>
<span class="c1">##  7 About To Sâ€¦ Below average recencyÙ« â€¦     2    NA    NA     3     2     2</span>
<span class="c1">##  8 At Risk     Spent big moneyÙ« purchaâ€¦    NA     2     2     2     5     5</span>
<span class="c1">##  9 Canâ€™t Loseâ€¦ Made big purchases and â€¦    NA     4     4     1     5     5</span>
<span class="c1">## 10 Hibernating Low spendersÙ« low frequâ€¦     1     1     1     2     2     2</span>
<span class="c1">## 11 Lost        Lowest recencyÙ« frequenâ€¦    NA    NA    NA     2     2     2</span>
</code></pre></td></tr></table>
</div>
</div>

<p>Finally we put back those implicit zeros using <code>replace_na()</code> and reorder the columns to our liking. Using <code>replace_na()</code> is fine here because we know that every missing value should in fact be a zero.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">rfm_tbl</span> <span class="o">%&gt;%</span> 
  <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">filter_all</span><span class="p">(</span><span class="nf">any_vars</span><span class="p">(</span><span class="o">!</span><span class="nf">is.na</span><span class="p">(</span><span class="n">.)</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_longer</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="n">r</span><span class="o">:</span><span class="n">m</span><span class="p">)</span> <span class="o">%&gt;%</span> 
  <span class="nf">separate</span><span class="p">(</span><span class="n">col</span> <span class="o">=</span> <span class="n">value</span><span class="p">Ù«</span> <span class="n">into</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;lo&#34;</span><span class="p">Ù«</span> <span class="s">&#34;hi&#34;</span><span class="p">)Ù«</span> 
           <span class="n">remove</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">Ù«</span> <span class="n">convert</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">Ù«</span> 
           <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;left&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">value</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_wider</span><span class="p">(</span><span class="n">names_from</span> <span class="o">=</span> <span class="n">name</span><span class="p">Ù«</span> 
              <span class="n">values_from</span> <span class="o">=</span> <span class="n">lo</span><span class="o">:</span><span class="n">hi</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.integer</span><span class="p">Ù«</span> <span class="n">replace_na</span><span class="p">Ù«</span> <span class="m">0</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">segment</span><span class="p">Ù«</span> 
         <span class="n">lo_r</span><span class="p">Ù«</span> <span class="n">hi_r</span><span class="p">Ù«</span> 
         <span class="n">lo_f</span><span class="p">Ù«</span> <span class="n">hi_f</span><span class="p">Ù«</span> 
         <span class="n">lo_m</span><span class="p">Ù«</span> <span class="n">hi_m</span><span class="p">Ù«</span> 
         <span class="n">description</span><span class="p">)</span>


<span class="c1">## # A tibble: 11 x 8</span>
<span class="c1">##    segment      lo_r  hi_r  lo_f  hi_f  lo_m  hi_m description             </span>
<span class="c1">##    &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                   </span>
<span class="c1">##  1 Champions       4     5     4     5     4     5 Bought recentlyÙ« buy ofâ€¦</span>
<span class="c1">##  2 Loyal Custâ€¦     2     5     3     5     3     5 Spend good money. Respoâ€¦</span>
<span class="c1">##  3 Potential â€¦     3     5     1     3     1     3 Recent customersÙ« spentâ€¦</span>
<span class="c1">##  4 New Customâ€¦     4     5     0     1     0     1 Bought more recentlyÙ« bâ€¦</span>
<span class="c1">##  5 Promising       3     4     0     1     0     1 Recent shoppersÙ« but haâ€¦</span>
<span class="c1">##  6 Need Attenâ€¦     2     3     2     3     2     3 Above average recencyÙ« â€¦</span>
<span class="c1">##  7 About To Sâ€¦     2     3     0     2     0     2 Below average recencyÙ« â€¦</span>
<span class="c1">##  8 At Risk         0     2     2     5     2     5 Spent big moneyÙ« purchaâ€¦</span>
<span class="c1">##  9 Canâ€™t Loseâ€¦     0     1     4     5     4     5 Made big purchases and â€¦</span>
<span class="c1">## 10 Hibernating     1     2     1     2     1     2 Low spendersÙ« low frequâ€¦</span>
<span class="c1">## 11 Lost            0     2     0     2     0     2 Lowest recencyÙ« frequenâ€¦</span>
</code></pre></td></tr></table>
</div>
</div>

<p>Much nicer.</p>
'),('https://kieranhealy.org/blog/archives/2019/11/09/reading-in-data/', 'Reading in Data', '1573320912000',  15, '<p>Here&rsquo;s a common situation: you have a folder full of similarly-formatted CSV or otherwise structured text files that you want to get into R quickly and easily. Reading data into R is one of those tasks that can be a real source of frustration for beginnersÙ« so I like collecting real-life examples of the many ways it&rsquo;s become much easier.</p>
<p>This week in class I was working with country-level historical mortality rate estimates. These are available from <a href="http://mortality.org">mortality.org</a>Ù« a fabulous resource. They have a variety of data available but I was interested in the 1x1 year estimates of mortality for all available countries. By &ldquo;1x1&rdquo; I mean that the tables show (for menÙ« womenÙ« and in total) age-specific morality rate estimates for yearly ages from 0 to 110 and aboveÙ« for every available historical year (e.g. from 1850 to 2016 or what have you). So you can have an estimate of the mortality rate forÙ« sayÙ« 28 year olds in France in 1935.</p>
<p>Downloading this data gives me a folder of text filesÙ« one for each country. (Or ratherÙ« country-like unit: there are separate series forÙ« e.g. East GermanyÙ« West GermanyÙ« and Germany as a wholeÙ« for exampleÙ« along with some countries where sub-populations are broken out historically.) The names of the files are consistently formattedÙ« as is the data inside themÙ« and they have a <code>.txt</code> extension. What I wanted to do was get each one of these files into RÙ« ideally putting them all into a single big table that could be the jumping-off point for subsetting and further analysis.</p>
<p>I know from the documentation provided by <a href="http://mortality.org">mortality.org</a> that the files all have the same basic formatÙ« which of course makes things much easier. The data is already clean. It&rsquo;s just a matter of loading it all in efficientlyÙ« or &ldquo;ingesting&rdquo; itÙ« to use the charming image that seems to be preferred at present.</p>
<p>Here we go. FirstÙ« some libraries.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">janitor</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">here</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div>


<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="c1">## here() starts at /Users/kjhealy/Source/demog</span>
</code></pre></td></tr></table>
</div>
</div>

<p>We get a list of the filenames in our raw data folderÙ« along with their full paths. Then we take a look at them.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">filenames</span> <span class="o">&lt;-</span> <span class="nf">dir</span><span class="p">(</span><span class="n">path</span> <span class="o">=</span> <span class="nf">here</span><span class="p">(</span><span class="s">&#34;rawdata&#34;</span><span class="p">)Ù«</span>
                 <span class="n">pattern</span> <span class="o">=</span> <span class="s">&#34;*.txt&#34;</span><span class="p">Ù«</span>
                 <span class="n">full.names</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>

<span class="n">filenames</span>

<span class="c1">##  [1] &#34;/Users/kjhealy/Source/demog/rawdata/AUS.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [2] &#34;/Users/kjhealy/Source/demog/rawdata/AUT.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [3] &#34;/Users/kjhealy/Source/demog/rawdata/BEL.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [4] &#34;/Users/kjhealy/Source/demog/rawdata/BGR.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [5] &#34;/Users/kjhealy/Source/demog/rawdata/BLR.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [6] &#34;/Users/kjhealy/Source/demog/rawdata/CAN.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [7] &#34;/Users/kjhealy/Source/demog/rawdata/CHE.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [8] &#34;/Users/kjhealy/Source/demog/rawdata/CHL.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [9] &#34;/Users/kjhealy/Source/demog/rawdata/CZE.Mx_1x1.txt&#34;    </span>
<span class="c1">## [10] &#34;/Users/kjhealy/Source/demog/rawdata/DEUTE.Mx_1x1.txt&#34;  </span>
<span class="c1">## [11] &#34;/Users/kjhealy/Source/demog/rawdata/DEUTNP.Mx_1x1.txt&#34; </span>
<span class="c1">## [12] &#34;/Users/kjhealy/Source/demog/rawdata/DEUTW.Mx_1x1.txt&#34;  </span>
<span class="c1">## [13] &#34;/Users/kjhealy/Source/demog/rawdata/DNK.Mx_1x1.txt&#34;    </span>
<span class="c1">## [14] &#34;/Users/kjhealy/Source/demog/rawdata/ESP.Mx_1x1.txt&#34;    </span>
<span class="c1">## [15] &#34;/Users/kjhealy/Source/demog/rawdata/EST.Mx_1x1.txt&#34;    </span>
<span class="c1">## [16] &#34;/Users/kjhealy/Source/demog/rawdata/FIN.Mx_1x1.txt&#34;    </span>
<span class="c1">## [17] &#34;/Users/kjhealy/Source/demog/rawdata/FRACNP.Mx_1x1.txt&#34; </span>
<span class="c1">## [18] &#34;/Users/kjhealy/Source/demog/rawdata/FRATNP.Mx_1x1.txt&#34; </span>
<span class="c1">## [19] &#34;/Users/kjhealy/Source/demog/rawdata/GBR_NIR.Mx_1x1.txt&#34;</span>
<span class="c1">## [20] &#34;/Users/kjhealy/Source/demog/rawdata/GBR_NP.Mx_1x1.txt&#34; </span>
<span class="c1">## [21] &#34;/Users/kjhealy/Source/demog/rawdata/GBR_SCO.Mx_1x1.txt&#34;</span>
<span class="c1">## [22] &#34;/Users/kjhealy/Source/demog/rawdata/GBRCENW.Mx_1x1.txt&#34;</span>
<span class="c1">## [23] &#34;/Users/kjhealy/Source/demog/rawdata/GBRTENW.Mx_1x1.txt&#34;</span>
<span class="c1">## [24] &#34;/Users/kjhealy/Source/demog/rawdata/GRC.Mx_1x1.txt&#34;    </span>
<span class="c1">## [25] &#34;/Users/kjhealy/Source/demog/rawdata/HRV.Mx_1x1.txt&#34;    </span>
<span class="c1">## [26] &#34;/Users/kjhealy/Source/demog/rawdata/HUN.Mx_1x1.txt&#34;    </span>
<span class="c1">## [27] &#34;/Users/kjhealy/Source/demog/rawdata/IRL.Mx_1x1.txt&#34;    </span>
<span class="c1">## [28] &#34;/Users/kjhealy/Source/demog/rawdata/ISL.Mx_1x1.txt&#34;    </span>
<span class="c1">## [29] &#34;/Users/kjhealy/Source/demog/rawdata/ISR.Mx_1x1.txt&#34;    </span>
<span class="c1">## [30] &#34;/Users/kjhealy/Source/demog/rawdata/ITA.Mx_1x1.txt&#34;    </span>
<span class="c1">## [31] &#34;/Users/kjhealy/Source/demog/rawdata/JPN.Mx_1x1.txt&#34;    </span>
<span class="c1">## [32] &#34;/Users/kjhealy/Source/demog/rawdata/KOR.Mx_1x1.txt&#34;    </span>
<span class="c1">## [33] &#34;/Users/kjhealy/Source/demog/rawdata/LTU.Mx_1x1.txt&#34;    </span>
<span class="c1">## [34] &#34;/Users/kjhealy/Source/demog/rawdata/LUX.Mx_1x1.txt&#34;    </span>
<span class="c1">## [35] &#34;/Users/kjhealy/Source/demog/rawdata/LVA.Mx_1x1.txt&#34;    </span>
<span class="c1">## [36] &#34;/Users/kjhealy/Source/demog/rawdata/NLD.Mx_1x1.txt&#34;    </span>
<span class="c1">## [37] &#34;/Users/kjhealy/Source/demog/rawdata/NOR.Mx_1x1.txt&#34;    </span>
<span class="c1">## [38] &#34;/Users/kjhealy/Source/demog/rawdata/NZL_MA.Mx_1x1.txt&#34; </span>
<span class="c1">## [39] &#34;/Users/kjhealy/Source/demog/rawdata/NZL_NM.Mx_1x1.txt&#34; </span>
<span class="c1">## [40] &#34;/Users/kjhealy/Source/demog/rawdata/NZL_NP.Mx_1x1.txt&#34; </span>
<span class="c1">## [41] &#34;/Users/kjhealy/Source/demog/rawdata/POL.Mx_1x1.txt&#34;    </span>
<span class="c1">## [42] &#34;/Users/kjhealy/Source/demog/rawdata/PRT.Mx_1x1.txt&#34;    </span>
<span class="c1">## [43] &#34;/Users/kjhealy/Source/demog/rawdata/RUS.Mx_1x1.txt&#34;    </span>
<span class="c1">## [44] &#34;/Users/kjhealy/Source/demog/rawdata/SVK.Mx_1x1.txt&#34;    </span>
<span class="c1">## [45] &#34;/Users/kjhealy/Source/demog/rawdata/SVN.Mx_1x1.txt&#34;    </span>
<span class="c1">## [46] &#34;/Users/kjhealy/Source/demog/rawdata/SWE.Mx_1x1.txt&#34;    </span>
<span class="c1">## [47] &#34;/Users/kjhealy/Source/demog/rawdata/TWN.Mx_1x1.txt&#34;    </span>
<span class="c1">## [48] &#34;/Users/kjhealy/Source/demog/rawdata/UKR.Mx_1x1.txt&#34;    </span>
<span class="c1">## [49] &#34;/Users/kjhealy/Source/demog/rawdata/USA.Mx_1x1.txt&#34;</span>

</code></pre></td></tr></table>
</div>
</div>

<p>What does each of these files look like? Let&rsquo;s take a look at the first oneÙ« using <code>read_lines()</code> to show us the top of the file.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="nf">read_lines</span><span class="p">(</span><span class="n">filenames[1]</span><span class="p">Ù«</span> <span class="n">n_max</span> <span class="o">=</span> <span class="m">5</span><span class="p">)</span>

<span class="c1">## [1] &#34;AustraliaÙ« Death rates (period 1x1)Ù« \tLast modified: 26 Sep 2017;  Methods Protocol: v6 (2017)&#34;</span>
<span class="c1">## [2] &#34;&#34;                                                                                               </span>
<span class="c1">## [3] &#34;  Year          Age             Female            Male           Total&#34;                         </span>
<span class="c1">## [4] &#34;  1921           0             0.059987        0.076533        0.068444&#34;                        </span>
<span class="c1">## [5] &#34;  1921           1             0.012064        0.014339        0.013225&#34;</span>

</code></pre></td></tr></table>
</div>
</div>

<p>All the files have a header section like this. When we read the data in we&rsquo;ll want to ignore that and go straight to the data. But seeing as it&rsquo;s thereÙ« we can make use of it to grab the name of the country. It saves us typing it ourselves. Let&rsquo;s say we&rsquo;d also like to have a code-friendly version of those names (i.e.Ù« in lower-case with underscores instead of spaces). And finally&mdash;while we&rsquo;re at it&mdash;let&rsquo;s grab those all-caps country codes used in the file namesÙ« too. We write three functions:</p>
<ul>
<li><code>get_country_name()</code> grabs the first word or words on the first line of each fileÙ« up to the first comma. That&rsquo;s our country name.</li>
<li><code>shorten_name()</code> makes the names lower-case and replaces spaces with underscoresÙ« and also shortens &ldquo;The United States of America&rdquo; to &ldquo;USA&rdquo;.</li>
<li><code>make_ccode()</code> wraps a regular expression that finds and extracts the capitalized country codes in the file names.</li>
</ul>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">get_country_name</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">){</span>
    <span class="nf">read_lines</span><span class="p">(</span><span class="n">x</span><span class="p">Ù«</span> <span class="n">n_max</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span> <span class="o">%&gt;%</span>
        <span class="nf">str_extract</span><span class="p">(</span><span class="s">&#34;.+?Ù«&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
        <span class="nf">str_remove</span><span class="p">(</span><span class="s">&#34;Ù«&#34;</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">shorten_name</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">){</span>
    <span class="nf">str_replace_all</span><span class="p">(</span><span class="n">x</span><span class="p">Ù«</span> <span class="s">&#34; -- &#34;</span><span class="p">Ù«</span> <span class="s">&#34; &#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
        <span class="nf">str_replace</span><span class="p">(</span><span class="s">&#34;The United States of America&#34;</span><span class="p">Ù«</span> <span class="s">&#34;USA&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
        <span class="n">snakecase</span><span class="o">::</span><span class="nf">to_any_case</span><span class="p">()</span>
<span class="p">}</span>

<span class="n">make_ccode</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">){</span>
    <span class="nf">str_extract</span><span class="p">(</span><span class="n">x</span><span class="p">Ù«</span> <span class="s">&#34;[:upper:]+((?=\\.))&#34;</span><span class="p">)</span>
<span class="p">}</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Now we create a tibble of summary information by mapping the functions to the filenames.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">countries</span> <span class="o">&lt;-</span> <span class="nf">tibble</span><span class="p">(</span><span class="n">country</span> <span class="o">=</span> <span class="nf">map_chr</span><span class="p">(</span><span class="n">filenames</span><span class="p">Ù«</span> <span class="n">get_country_name</span><span class="p">)Ù«</span>
                        <span class="n">cname</span> <span class="o">=</span> <span class="nf">map_chr</span><span class="p">(</span><span class="n">country</span><span class="p">Ù«</span> <span class="n">shorten_name</span><span class="p">)Ù«</span>
                        <span class="n">ccode</span> <span class="o">=</span> <span class="nf">map_chr</span><span class="p">(</span><span class="n">filenames</span><span class="p">Ù«</span> <span class="n">make_ccode</span><span class="p">)Ù«</span>
                        <span class="n">path</span> <span class="o">=</span> <span class="n">filenames</span><span class="p">)</span>

<span class="n">countries</span>

<span class="c1">## # A tibble: 49 x 4</span>
<span class="c1">##    country     cname       ccode path                                      </span>
<span class="c1">##    &lt;chr&gt;       &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;                                     </span>
<span class="c1">##  1 Australia   australia   AUS   /Users/kjhealy/Source/demog/rawdata/AUS.Mâ€¦</span>
<span class="c1">##  2 Austria     austria     AUT   /Users/kjhealy/Source/demog/rawdata/AUT.Mâ€¦</span>
<span class="c1">##  3 Belgium     belgium     BEL   /Users/kjhealy/Source/demog/rawdata/BEL.Mâ€¦</span>
<span class="c1">##  4 Bulgaria    bulgaria    BGR   /Users/kjhealy/Source/demog/rawdata/BGR.Mâ€¦</span>
<span class="c1">##  5 Belarus     belarus     BLR   /Users/kjhealy/Source/demog/rawdata/BLR.Mâ€¦</span>
<span class="c1">##  6 Canada      canada      CAN   /Users/kjhealy/Source/demog/rawdata/CAN.Mâ€¦</span>
<span class="c1">##  7 Switzerland switzerland CHE   /Users/kjhealy/Source/demog/rawdata/CHE.Mâ€¦</span>
<span class="c1">##  8 Chile       chile       CHL   /Users/kjhealy/Source/demog/rawdata/CHL.Mâ€¦</span>
<span class="c1">##  9 Czechia     czechia     CZE   /Users/kjhealy/Source/demog/rawdata/CZE.Mâ€¦</span>
<span class="c1">## 10 East Germaâ€¦ east_germaâ€¦ DEUTE /Users/kjhealy/Source/demog/rawdata/DEUTEâ€¦</span>
<span class="c1">## # â€¦ with 39 more rows</span>


</code></pre></td></tr></table>
</div>
</div>

<p>Nice. We could have written each of those operations as anonymous functions directly inside of <code>map_chr()</code>. This would have been more compact. But often it can be useful to break out the steps as shown hereÙ« for clarity&mdash;especially if <code>map()</code> operations have a tendency to break your brainÙ« as they do mine.</p>
<p>We still haven&rsquo;t touched the actual data filesÙ« of course. But now we can just use this <code>countries</code> table as the basis for reading inÙ« I mean <em>ingesting</em>Ù« everything in the files. We&rsquo;re going to just add a list column named <code>data</code> to the end of the table and put the data for each country in it. We&rsquo;ll temporarily unnest it to clean the column names and recode the <code>age</code> variableÙ« then drop the file paths column and nest the data again.</p>
<p>The hard work is done by the <code>map()</code> call. This time we will use <code>~</code> formula notation inside <code>map()</code> to write what we want to do. We&rsquo;re going to feed every filename in <code>path</code> to <code>read_table()</code>Ù« one at a time. We tell <code>read_table()</code> to skip the first two lines of every file it readsÙ« and also tell it that in these files missing data are represented by a <code>.</code> character. Everything read in ends up in a new list column named <code>data</code>.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">mortality</span> <span class="o">&lt;-</span> <span class="n">countries</span> <span class="o">%&gt;%</span>
    <span class="nf">mutate</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span><span class="n">path</span><span class="p">Ù«</span>
                      <span class="o">~</span> <span class="nf">read_table</span><span class="p">(</span><span class="n">.Ù«</span> <span class="n">skip</span> <span class="o">=</span> <span class="m">2</span><span class="p">Ù«</span> <span class="n">na</span> <span class="o">=</span> <span class="s">&#34;.&#34;</span><span class="p">)))</span> <span class="o">%&gt;%</span>
    <span class="nf">unnest</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">%&gt;%</span>
    <span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">mutate</span><span class="p">(</span><span class="n">age</span> <span class="o">=</span> <span class="nf">as.integer</span><span class="p">(</span><span class="nf">recode</span><span class="p">(</span><span class="n">age</span><span class="p">Ù«</span> <span class="s">&#34;110+&#34;</span> <span class="o">=</span> <span class="s">&#34;110&#34;</span><span class="p">)))</span> <span class="o">%&gt;%</span>
    <span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">path</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="nf">nest</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">year</span><span class="o">:</span><span class="n">total</span><span class="p">))</span>

<span class="n">mortality</span>


<span class="c1">## # A tibble: 49 x 4</span>
<span class="c1">##    country      cname        ccode           data</span>
<span class="c1">##    &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt; &lt;list&lt;df[Ù«5]&gt;&gt;</span>
<span class="c1">##  1 Australia    australia    AUS     [10Ù«434 Ã— 5]</span>
<span class="c1">##  2 Austria      austria      AUT      [7Ù«881 Ã— 5]</span>
<span class="c1">##  3 Belgium      belgium      BEL     [19Ù«425 Ã— 5]</span>
<span class="c1">##  4 Bulgaria     bulgaria     BGR      [7Ù«104 Ã— 5]</span>
<span class="c1">##  5 Belarus      belarus      BLR      [6Ù«438 Ã— 5]</span>
<span class="c1">##  6 Canada       canada       CAN     [10Ù«101 Ã— 5]</span>
<span class="c1">##  7 Switzerland  switzerland  CHE     [15Ù«651 Ã— 5]</span>
<span class="c1">##  8 Chile        chile        CHL      [1Ù«887 Ã— 5]</span>
<span class="c1">##  9 Czechia      czechia      CZE      [7Ù«437 Ã— 5]</span>
<span class="c1">## 10 East Germany east_germany DEUTE    [6Ù«660 Ã— 5]</span>
<span class="c1">## # â€¦ with 39 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>And we&rsquo;re done. Forty nine tables of data smoothly imported and bundled together. Each of the country-level data tables is a row in <code>data</code> that we can take a look at as we like:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">mortality</span> <span class="o">%&gt;%</span> 
  <span class="nf">filter</span><span class="p">(</span><span class="n">country</span> <span class="o">==</span> <span class="s">&#34;Austria&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span> 
  <span class="nf">unnest</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>


<span class="c1">## # A tibble: 7Ù«881 x 8</span>
<span class="c1">##    country cname   ccode  year   age   female     male    total</span>
<span class="c1">##    &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;</span>
<span class="c1">##  1 Austria austria AUT    1947     0 0.0798   0.0994   0.0899  </span>
<span class="c1">##  2 Austria austria AUT    1947     1 0.00657  0.00845  0.00753 </span>
<span class="c1">##  3 Austria austria AUT    1947     2 0.00425  0.00469  0.00447 </span>
<span class="c1">##  4 Austria austria AUT    1947     3 0.00337  0.00340  0.00339 </span>
<span class="c1">##  5 Austria austria AUT    1947     4 0.00235  0.00270  0.00253 </span>
<span class="c1">##  6 Austria austria AUT    1947     5 0.00174  0.00195  0.00184 </span>
<span class="c1">##  7 Austria austria AUT    1947     6 0.00131  0.00152  0.00142 </span>
<span class="c1">##  8 Austria austria AUT    1947     7 0.00132  0.00169  0.00151 </span>
<span class="c1">##  9 Austria austria AUT    1947     8 0.00115  0.00149  0.00132 </span>
<span class="c1">## 10 Austria austria AUT    1947     9 0.000836 0.000997 0.000918</span>
<span class="c1">## # â€¦ with 7Ù«871 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Now you can get on with the actual analysis.</p>
<p>There isn&rsquo;t anything especially unusual in the steps shown here. It&rsquo;s just a pretty common operation that&rsquo;s worth knowing how to do cleanly. One nice thing about this approach is that it&rsquo;s immediately applicable toÙ« sayÙ« a folder containing the 5-year mortality estimates rather than the 1 year estimates. You don&rsquo;t have to do anything newÙ« and there&rsquo;s no mucking around with manually naming files and so on.</p>
'),('https://www.youtube.com/watch?v=kNVuTAVYxpM', 'Vendor Locking AMD EPYC CPUs Great for Security at a Cost', '1599614809000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/AgreeableLandscape">AgreeableLandscape</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>4 points | <a href="https://dev.lemmy.ml/post/40229">6 comments</a>'),('https://blog.mozilla.org/blog/2020/09/07/mozilla-ceo-mitchell-baker-urges-european-commission-to-seize-once-in-a-generation-opportunity/', 'Mozilla CEO Mitchell Baker urges European Commission to seize â€˜once-in-a-generationâ€™ opportunity â€“ The Mozilla Blog', '1599560219000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/ajz">ajz</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>8 points | <a href="https://dev.lemmy.ml/post/40196">2 comments</a>'),('invalid', 'Anyway to block certain domains/websites from appearing in search results?', '1599587640000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/Stayawesome">Stayawesome</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>3 points | <a href="https://dev.lemmy.ml/post/40218">0 comments</a><p>I have heard of this (one)[https://addons.mozilla.org/en-US/firefox/addon/personal-blocklist/]  but that only applies to google and not other search engines i.e duckduckgo.</p>
'),('https://proarea.co/blog/how-to-design-a-banking-application/', 'How to design a banking application', '1599565799000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/yuliaproarea">yuliaproarea</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>1 points | <a href="https://dev.lemmy.ml/post/40201">0 comments</a><p>If your banking application doesnâ€™t meet the market requirementsÙ« it will be too difficult to stay on it.</p>
'),('https://www.engadget.com/tiktok-suicide-video-221041082.html', 'TikTok is trying to stop a suicide video from spreading', '1599553372000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/QuentinCallaghan">QuentinCallaghan</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>2 points | <a href="https://dev.lemmy.ml/post/40192">0 comments</a>'),('https://the-evolving-web.blogspot.com/2020/09/the-art-of-finishing-incomplete.html', 'The art of finishing incomplete projects and tasks', '1599550256000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/noble_pleb">noble_pleb</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>2 points | <a href="https://dev.lemmy.ml/post/40191">0 comments</a>'),('https://www.debugpoint.com/2020/09/vivaldi-browser-3-3/', 'Vivaldi Browser 3.3 Brings Break Mode to Pause Internet', '1599560397000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/ajz">ajz</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>0 points | <a href="https://dev.lemmy.ml/post/40198">1 comments</a>'),('https://www.youtube.com/watch?v=DWWU-8_4wu0', 'NEWater: A Singapore Success Story', '1599534030000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/AgreeableLandscape">AgreeableLandscape</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>2 points | <a href="https://dev.lemmy.ml/post/40182">0 comments</a>'),('https://www.youtube.com/watch?v=nS_HgfanRjA', 'A solar water heater and greywater treatment system in one', '1599533948000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/AgreeableLandscape">AgreeableLandscape</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>1 points | <a href="https://dev.lemmy.ml/post/40178">0 comments</a>'),('http://yarh.io/yarh-io-mki.html', '800x480 Touchscreen Raspberry Pi 3B+ Hackable Linux Handheld', '1599509116000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/yogthos">yogthos</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>4 points | <a href="https://dev.lemmy.ml/post/40161">0 comments</a>'),,,('https://www.debugbear.com/blog/front-end-javascript-performance', 'Front-end JavaScript performance', '1599609600000',  24, 'invalid'),('https://www.debugbear.com/blog/is-the-web-getting-slower', 'Is the web getting slower?', '1598227200000',  24, 'invalid'),('https://www.debugbear.com/blog/gpt-3-on-web-performance', 'GPT-3 on web performance', '1596153600000',  24, 'invalid'),('https://www.debugbear.com/blog/improve-server-response-time', 'How to improve server response time (TTFB)?', '1594166400000',  24, 'invalid'),('https://www.debugbear.com/blog/counting-chrome-extensions', 'Counting Chrome Extensions â€“Â Statistics on the Chrome Web Store', '1593475200000',  24, 'invalid'),('https://www.debugbear.com/blog/2020-chrome-extension-performance-report', '2020 Chrome Extension Performance Report', '1592179200000',  24, 'invalid'),('https://www.debugbear.com/blog/save-data-adoption', 'How many websites support the Save-Data header?', '1583712000000',  24, 'invalid'),('https://www.debugbear.com/blog/performant-front-end-architecture', 'Performant front-end architecture', '1581292800000',  24, 'invalid'),('https://www.debugbear.com/blog/intermittent-compression', 'What"s causing intermittent gzip compression?', '1579996800000',  24, 'invalid'),('https://www.debugbear.com/blog/how-does-browser-support-impact-bundle-size', 'How does browser support impact JavaScript bundle size?', '1573603200000',  24, 'invalid'),('https://www.debugbear.com/blog/web-performance-metrics-lab-vs-rum', 'Monitoring web performance: lab-based testing vs collecting field data', '1568160000000',  24, 'invalid'),('https://www.debugbear.com/blog/lazy-loading-angular-components-without-a-router', 'Lazy loading Angular components without a router', '1567468800000',  24, 'invalid'),('https://www.debugbear.com/blog/why-is-my-lighthouse-score-different-from-pagespeed-insights', 'Why is my Lighthouse score different from PageSpeed Insights?', '1566345600000',  24, 'invalid'),('https://www.debugbear.com/blog/chat-widget-site-performance', 'How do different chat widgets impact site performance?', '1563148800000',  24, 'invalid'),('https://www.debugbear.com/blog/measuring-react-app-performance', 'Measuring React app performance', '1561507200000',  24, 'invalid'),('https://www.debugbear.com/blog/resource-hints-rel-preload-prefetch-preconnect', 'Browser Resource Hints: preloadÙ« prefetchÙ« and preconnect', '1557705600000',  24, 'invalid'),('https://www.debugbear.com/blog/image-element-timing', 'Measuring when images are displayed with the experimental Element Timing API', '1556496000000',  24, 'invalid'),('https://www.debugbear.com/blog/custom-front-end-performance-metrics', 'Custom front-end performance metrics with the User Timing API', '1554076800000',  24, 'invalid'),('https://www.debugbear.com/blog/network-throttling-methods', 'Understanding network throttling: DevTools vs. Lighthouse vs. Netem', '1552435200000',  24, 'invalid'),('https://www.debugbear.com/blog/bundle-splitting-components-with-webpack-and-react', 'Bundle splitting components with Webpack and React', '1547510400000',  24, 'invalid'),('https://www.debugbear.com/blog/measuring-the-performance-impact-of-chrome-extensions', 'Measuring the performance impact of Chrome extensions', '1543968000000',  24, 'invalid'),('https://www.debugbear.com/blog/reducing-javascript-bundle-size', 'Keeping your JavaScript bundle size in check', '1540252800000',  24, 'invalid');
SQLITE_ERROR: near ",": syntax error
