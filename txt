Connected
{ comma: ',' }
INSERT or IGNORE INTO posts (link, title, pubDate, feed_id, description) VALUES ('https://euandre.org/2020/08/31/the-database-i-wish-i-had.html', 'The database I wish I had', '1598832000000',  1, '<p>I watched the talk
“<a href="https://vimeo.com/230142234">Platform as a Reflection of Values: Joyent٫ Node.js and beyond</a>”
by Bryan Cantrill٫ and I think he was able to put into words something I already
felt for some time: if there’s no piece of software out there that reflects your
values٫ it’s time for you to build that software<sup id="fnref:talk-time" role="doc-noteref"><a href="#fn:talk-time" class="footnote">1</a></sup>.</p>

<p>I kind of agree with what he said٫ because this is already happening to me. I
long for a database with a certain set of values٫ and for a few years I was just
waiting for someone to finally write it. After watching his talk٫ Bryan is
saying to me: “time to stop waiting٫ and start writing it yourself”.</p>

<p>So let me try to give an overview of such database٫ and go over its values.</p>

<h2 id="overview">Overview</h2>

<p>I want a database that allows me to create decentralized client-side
applications that can sync data.</p>

<p>The best one-line description I can give right now is:</p>

<blockquote>
  <p>It’s sort of like PouchDB٫ Git٫ Datomic٫ SQLite and Mentat.</p>
</blockquote>

<p>A more descriptive version could be:</p>

<blockquote>
  <p>An embedded٫ immutable٫ syncable relational database.</p>
</blockquote>

<p>Let’s go over what I mean by each of those aspects one by one.</p>

<h3 id="embedded">Embedded</h3>

<p>I think the server-side database landscape is diverse and mature enough for
my needs (even though I end up choosing SQLite most of the time)٫ and what I’m
after is a database to be embedded on client-side applications itself٫ be it
desktop٫ browser٫ mobile٫ etc.</p>

<p>The purpose of such database is not to keep some local cache of data in case of
lost connectivity: we have good solutions for that already. It should serve as
the source of truth٫ and allow the application to work on top of it.</p>

<p><a href="https://sqlite.org/index.html"><strong>SQLite</strong></a> is a great example of that: it is a very powerful
relational database that runs <a href="https://sqlite.org/whentouse.html">almost anywhere</a>. What I miss
from it that SQLite doesn’t provide is the ability to run it on the browser:
even though you could compile it to WebAssembly٫ <del>it assumes a POSIX filesystem
that would have to be emulated</del><sup id="fnref:posix-sqlite" role="doc-noteref"><a href="#fn:posix-sqlite" class="footnote">2</a></sup>.</p>

<p><a href="https://pouchdb.com/"><strong>PouchDB</strong></a> is another great example: it’s a full reimplementation of
<a href="https://couchdb.apache.org/">CouchDB</a> that targets JavaScript environments٫ mainly the browser and
Node.js. However I want a tool that can be deployed anywhere٫ and not limit its
applications to places that already have a JavaScript runtime environment٫ or
force the developer to bundle a JavaScript runtime environment with their
application. This is true for GTK+ applications٫ command line programs٫ Android
apps٫ etc.</p>

<p><a href="https://github.com/mozilla/mentat"><strong>Mentat</strong></a> was an interesting project٫ but its reliance on SQLite
makes it inherit most of the downsides (and benefits too) of SQLite itself.</p>

<p>Having such a requirement imposes a different approach to storage: we have to
decouple the knowledge about the intricacies of storage from the usage of
storage itself٫ so that a module (say query processing) can access storage
through an API without needing to know about its implementation. This allows
the database to target a POSIX filesystems storage API and an IndexedDB storage
API٫ and make the rest of the code agnostic about storage. PouchDB has such
mechanism (called <a href="https://pouchdb.com/adapters.html">adapters</a>) and Datomic has them too (called
<a href="https://docs.datomic.com/on-prem/storage.html">storage services</a>).</p>

<p>This would allow the database to adapt to where it is embedded: when targeting
the browser the IndexedDB storage API would provide the persistence layer
that the database requires٫ and similarly the POSIX filesystem storage API would
provide the persistence layer when targeting POSIX systems (like desktops٫
mobile٫ etc.).</p>

<p>But there’s also an extra restriction that comes from by being embedded: it
needs to provide and embeddable artifact٫ most likely a binary library object
that exposes a C compatible FFI٫ similar to
<a href="https://www.sqlite.org/amalgamation.html">how SQLite does</a>. Bundling a full runtime environment is
possible٫ but doesn’t make it a compelling solution for embedding. This rules
out most languages٫ and leaves us with C٫ Rust٫ Zig٫ and similar options that
can target POSIX systems and WebAssembly.</p>

<h3 id="immutable">Immutable</h3>

<p>Being immutable means that only new information is added٫ no in-place update
ever happens٫ and nothing is ever deleted.</p>

<p>Having an immutable database presents us with similar trade-offs found in
persistent data structures٫ like lack of coordination when doing reads٫ caches
being always coherent٫ and more usage of space.</p>

<p><a href="https://www.datomic.com/"><strong>Datomic</strong></a> is the go to database example of this: it will only add
information (datoms) and allows you to query them in a multitude of ways. Stuart
Halloway calls it “accumulate-only” over “append-only”<sup id="fnref:accumulate-only" role="doc-noteref"><a href="#fn:accumulate-only" class="footnote">3</a></sup>:</p>

<blockquote>
  <p>It’s accumulate-only٫ it is not append-only. So append-only٫ most people when
they say that they’re implying something physical about what happens.</p>
</blockquote>

<p>Also a database can be append-only and overwrite existing information with new
information٫ by doing clean-ups of “stale” data. I prefer to adopt the
“accumulate-only” naming and approach.</p>

<p><a href="https://git-scm.com/"><strong>Git</strong></a> is another example of this: new commits are always added on top
of the previous data٫ and it grows by adding commits instead of replacing
existing ones.</p>

<p>Git repositories can only grow in size٫ and that is not only an acceptable
condition٫ but also one of the reasons to use it.</p>

<p>All this means that no in-place updates happens on data٫ and the database will
be much more concerned about how compact and efficiently it stores data than how
fast it does writes to disk. Being embedded٫ the storage limitation is either a)
how much storage the device has or b) how much storage was designed for the
application to consume. So even though the database could theoretically operate
with hundreds of TBs٫ a browser page or mobile application wouldn’t have access
to this amount of storage. SQLite even <a href="https://sqlite.org/limits.html">says</a> that it does
support approximately 280 TBs of data٫ but those limits are untested.</p>

<p>The upside of keeping everything is that you can have historical views of your
data٫ which is very powerful. This also means that applications should turn this
off when not relevant<sup id="fnref:no-history" role="doc-noteref"><a href="#fn:no-history" class="footnote">4</a></sup>.</p>

<h3 id="syncable">Syncable</h3>

<p>This is a frequent topic when talking about offline-first solutions. When
building applications that:</p>

<ul>
  <li>can fully work offline٫</li>
  <li>stores data٫</li>
  <li>propagates that data to other application instances٫</li>
</ul>

<p>then you’ll need a conflict resolution strategy to handle all the situations
where different application instances disagree. Those application instances
could be a desktop and a browser version of the same application٫ or the same
mobile app in different devices.</p>

<p>A three-way merge seems to be the best approach٫ on top of which you could add
application specific conflict resolution functions٫ like:</p>

<ul>
  <li>pick the change with higher timestamp;</li>
  <li>if one change is a delete٫ pick it;</li>
  <li>present the diff on the screen and allow the user to merge them.</li>
</ul>

<p>Some databases try to make this “easy”٫ by choosing a strategy for you٫ but I’ve
found that different applications require different conflict resolution
strategies. Instead٫ the database should leave this up to the user to decide٫
and provide tools for them to do it.</p>

<p><a href="https://en.wikipedia.org/wiki/Merge_(version_control)"><strong>Three-way merges in version control</strong></a> are the best example٫
performing automatic merges when possible and asking the user to resolve
conflicts when they appear.</p>

<p>The unit of conflict for a version control system is a line of text. The
database equivalent would probably be a single attribute٫ not a full entity or a
full row.</p>

<p>Making all the conflict resolution logic be local should allow the database to
have encrypted remotes similar to how <a href="https://spwhitton.name/tech/code/git-remote-gcrypt/">git-remote-gcrypt</a>
adds this functionality to Git. This would enable users to sync the application
data across devices using an untrusted intermediary.</p>

<h3 id="relational">Relational</h3>

<p>I want the power of relational queries on the client applications.</p>

<p>Most of the arguments against traditional table-oriented relational databases
are related to write performance٫ but those don’t apply here. The bottlenecks
for client applications usually aren’t write throughput. Nobody is interested in
differentiating between 1 MB/s or 10 MB/s when you’re limited to 500 MB total.</p>

<p>The relational model of the database could either be based on SQL and tables
like in SQLite٫ or maybe <a href="https://docs.datomic.com/on-prem/query.html">datalog</a> and <a href="https://docs.datomic.com/cloud/whatis/data-model.html#datoms">datoms</a> like in
Datomic.</p>

<h2 id="from-aspects-to-values">From aspects to values</h2>

<p>Now let’s try to translate the aspects above into values٫ as suggested by Bryan
Cantrill.</p>

<h3 id="portability">Portability</h3>

<p>Being able to target so many different platforms is a bold goal٫ and the
embedded nature of the database demands portability to be a core value.</p>

<h3 id="integrity">Integrity</h3>

<p>When the local database becomes the source of truth of the application٫ it must
provide consistency guarantees that enables applications to rely on it.</p>

<h3 id="expressiveness">Expressiveness</h3>

<p>The database should empower applications to slice and dice the data in any way
it wants to.</p>

<h2 id="next-steps">Next steps</h2>

<p>Since I can’t find any database that fits these requirements٫ I’ve finally come
to terms with doing it myself.</p>

<p>It’s probably going to take me a few years to do it٫ and making it portable
between POSIX and IndexedDB will probably be the biggest challenge. I got myself
a few books on databases to start.</p>

<p>I wonder if I’ll ever be able to get this done.</p>

<h2 id="external-links">External links</h2>

<p>See discussions on <a href="https://www.reddit.com/r/programming/comments/ijwz5b/the_database_i_wish_i_had/">Reddit</a>٫ <a href="https://lobste.rs/s/m9vkg4/database_i_wish_i_had">lobsters</a>٫ <a href="https://news.ycombinator.com/item?id=24337244">HN</a> and
<a href="https://lists.sr.ht/~euandreh/public-inbox/%3C010101744a592b75-1dce9281-f0b8-4226-9d50-fd2c7901fa72-000000%40us-west-2.amazonses.com%3E">a lengthy email exchange</a>.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:talk-time" role="doc-endnote">
      <p>At the very end٫ at time 29:49. When talking about the draft of
this article with a friend٫ he noted that Bryan O’Sullivan (a different
Bryan) says a similar thing on his talk
“<a href="https://www.youtube.com/watch?v=ZR3Jirqk6W8">Running a startup on Haskell</a>”٫
at time 4:15. <a href="#fnref:talk-time" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:posix-sqlite" role="doc-endnote">
      <p>It was <a href="https://news.ycombinator.com/item?id=24338881">pointed out to me</a>
that SQLite doesn’t assume the existence of a POSIX filesystem٫ as I wrongly
stated. Thanks for the correction.</p>

      <p>This makes me consider it as a storage backend all by itself. I
initially considered having an SQLite storage backend as one implementation
of the POSIX filesystem storage API that I mentioned. My goal was to rely on
it so I could validate the correctness of the actual implementation٫ given
SQLite’s robustness.</p>

      <p>However it may even better to just use SQLite٫ and get an ACID backend
without recreating a big part of SQLite from scratch. In fact٫ both Datomic
and PouchDB didn’t create an storage backend for themselves٫ they just
plugged on what already existed and already worked. I’m beginning to think
that it would be wiser to just do the same٫ and drop entirely the from
scratch implementation that I mentioned.</p>

      <p>That’s not to say that adding an IndexedDB compatibility layer to SQLite
would be enough to make it fit the other requirements I mention on this
page. SQLite still is an implementation of a update-in-place٫ SQL٫
table-oriented database. It is probably true that cherry-picking the
relevant parts of SQLite (like storage access٫ consistency٫ crash recovery٫
parser generator٫ etc.) and leaving out the unwanted parts (SQL٫ tables٫
threading٫ etc.) would be better than including the full SQLite stack٫ but
that’s simply an optimization. Both could even coexist٫ if desired.</p>

      <p>SQLite would have to be treated similarly to how Datomic treats SQL
databases: instead of having a table for each entities٫ spread attributes
over the tables٫ etc.٫ it treats SQL databases as a key-value storage so it
doesn’t have to re-implement interacting with the disk that other databases
do well.</p>

      <p>The tables would contain blocks of binary data٫ so there isn’t a difference
on how the SQLite storage backend behaves and how the IndexedDB storage
backend behaves٫ much like how Datomic works the same regardless of the
storage backend٫ same for PouchDB.</p>

      <p>I welcome corrections on what I said above٫ too. <a href="#fnref:posix-sqlite" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:accumulate-only" role="doc-endnote">
      <p>Video “<a href="https://vimeo.com/116315075">Day of Datomic Part 2</a>”
on Datomic’s information model٫ at time 12:28. <a href="#fnref:accumulate-only" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:no-history" role="doc-endnote">
      <p>Similar to
<a href="https://docs.datomic.com/cloud/best.html#nohistory-for-high-churn">Datomic’s <code class="language-plaintext highlighter-rouge">:db/noHistory</code></a>. <a href="#fnref:no-history" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>'),('https://euandre.org/2020/08/10/guix-inside-sourcehut-builds-sr-ht-ci.html', 'Guix inside sourcehut builds.sr.ht CI', '1597017600000',  1, '<p>After the release of the <a href="https://man.sr.ht/builds.sr.ht/compatibility.md#nixos">NixOS images in builds.sr.ht</a> and much
usage of it٫ I also started looking at <a href="https://guix.gnu.org/">Guix</a> and
wondered if I could get it on the awesome builds.sr.ht service.</p>

<p>The Guix manual section on the <a href="https://guix.gnu.org/manual/en/guix.html#Binary-Installation">binary installation</a> is very thorough٫ and
even a <a href="https://git.savannah.gnu.org/cgit/guix.git/plain/etc/guix-install.sh">shell installer script</a> is provided٫ but it is built towards someone
installing Guix on their personal computer٫ and relies heavily on interactive
input.</p>

<p>I developed the following set of scripts that I have been using for some time to
run Guix tasks inside builds.sr.ht jobs. First٫ <code class="language-plaintext highlighter-rouge">install-guix.sh</code>:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre></td><td class="rouge-code"><pre><span class="c">#!/usr/bin/env bash</span>
<span class="nb">set</span> <span class="nt">-x</span>
<span class="nb">set</span> <span class="nt">-Eeuo</span> pipefail

<span class="nv">VERSION</span><span class="o">=</span><span class="s1">"1.0.1"</span>
<span class="nv">SYSTEM</span><span class="o">=</span><span class="s1">"x86_64-linux"</span>
<span class="nv">BINARY</span><span class="o">=</span><span class="s2">"guix-binary-</span><span class="k">${</span><span class="nv">VERSION</span><span class="k">}</span><span class="s2">.</span><span class="k">${</span><span class="nv">SYSTEM</span><span class="k">}</span><span class="s2">.tar.xz"</span>

<span class="nb">cd</span> /tmp
wget <span class="s2">"https://ftp.gnu.org/gnu/guix/</span><span class="k">${</span><span class="nv">BINARY</span><span class="k">}</span><span class="s2">"</span>
<span class="nb">tar</span> <span class="nt">-xf</span> <span class="s2">"</span><span class="k">${</span><span class="nv">BINARY</span><span class="k">}</span><span class="s2">"</span>

<span class="nb">sudo mv </span>var/guix /var/
<span class="nb">sudo mv </span>gnu /
<span class="nb">sudo mkdir</span> <span class="nt">-p</span> ~root/.config/guix
<span class="nb">sudo ln</span> <span class="nt">-fs</span> /var/guix/profiles/per-user/root/current-guix ~root/.config/guix/current

<span class="nv">GUIX_PROFILE</span><span class="o">=</span><span class="s2">"</span><span class="si">$(</span><span class="nb">echo</span> ~root<span class="si">)</span><span class="s2">/.config/guix/current"</span>
<span class="nb">source</span> <span class="s2">"</span><span class="k">${</span><span class="nv">GUIX_PROFILE</span><span class="k">}</span><span class="s2">/etc/profile"</span>

groupadd <span class="nt">--system</span> guixbuild
<span class="k">for </span>i <span class="k">in</span> <span class="si">$(</span><span class="nb">seq</span> <span class="nt">-w</span> 1 10<span class="si">)</span><span class="p">;</span>
<span class="k">do
  </span>useradd <span class="nt">-g</span> guixbuild                       <span class="se">\</span>
          <span class="nt">-G</span> guixbuild                       <span class="se">\</span>
          <span class="nt">-d</span> /var/empty                      <span class="se">\</span>
          <span class="nt">-s</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">command</span> <span class="nt">-v</span> nologin<span class="si">)</span><span class="s2">"</span>         <span class="se">\</span>
          <span class="nt">-c</span> <span class="s2">"Guix build user </span><span class="k">${</span><span class="nv">i</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--system</span> <span class="se">\</span>
          <span class="s2">"guixbuilder</span><span class="k">${</span><span class="nv">i</span><span class="k">}</span><span class="s2">"</span><span class="p">;</span>
<span class="k">done

</span><span class="nb">mkdir</span> <span class="nt">-p</span> /usr/local/bin
<span class="nb">cd</span> /usr/local/bin
<span class="nb">ln</span> <span class="nt">-s</span> /var/guix/profiles/per-user/root/current-guix/bin/guix <span class="nb">.</span>
<span class="nb">ln</span> <span class="nt">-s</span> /var/guix/profiles/per-user/root/current-guix/bin/guix-daemon <span class="nb">.</span>

guix archive <span class="nt">--authorize</span> &lt; ~root/.config/guix/current/share/guix/ci.guix.gnu.org.pub
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Almost all of it is taken directly from the <a href="https://guix.gnu.org/manual/en/guix.html#Binary-Installation">binary installation</a> section
from the manual٫ with the interactive bits stripped out: after downloading and
extracting the Guix tarball٫ we create some symlinks٫ add guixbuild users and
authorize the <code class="language-plaintext highlighter-rouge">ci.guix.gnu.org.pub</code> signing key.</p>

<p>After installing Guix٫ we perform a <code class="language-plaintext highlighter-rouge">guix pull</code> to update Guix inside <code class="language-plaintext highlighter-rouge">start-guix.sh</code>:</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre><span class="c">#!/usr/bin/env bash</span>
<span class="nb">set</span> <span class="nt">-x</span>
<span class="nb">set</span> <span class="nt">-Eeuo</span> pipefail

<span class="nb">sudo </span>guix-daemon <span class="nt">--build-users-group</span><span class="o">=</span>guixbuild &amp;
guix pull
guix package <span class="nt">-u</span>
guix <span class="nt">--version</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Then we can put it all together in a sample <code class="language-plaintext highlighter-rouge">.build.yml</code> configuration file I’m
using myself:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="rouge-code"><pre><span class="na">image</span><span class="pi">:</span> <span class="s">debian/stable</span>
<span class="na">packages</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">wget</span>
<span class="na">sources</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">https://git.sr.ht/~euandreh/songbooks</span>
<span class="na">tasks</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">install-guix</span><span class="pi">:</span> <span class="pi">|</span>
      <span class="s">cd ./songbooks/</span>
      <span class="s">./scripts/install-guix.sh</span>
      <span class="s">./scripts/start-guix.sh</span>
      <span class="s">echo "sudo guix-daemon --build-users-group=guixbuild &amp;" &gt;&gt; ~/.buildenv</span>
      <span class="s">echo "export PATH="${HOME}/.config/guix/current/bin${PATH:+:}$PATH"" &gt;&gt; ~/.buildenv</span>
  <span class="pi">-</span> <span class="na">tests</span><span class="pi">:</span> <span class="pi">|</span>
      <span class="s">cd ./songbooks/</span>
      <span class="s">guix environment -m build-aux/guix.scm -- make check</span>
  <span class="pi">-</span> <span class="na">docs</span><span class="pi">:</span> <span class="pi">|</span>
      <span class="s">cd ./songbooks/</span>
      <span class="s">guix environment -m build-aux/guix.scm -- make publish-dist</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We have to add the <code class="language-plaintext highlighter-rouge">guix-daemon</code> to <code class="language-plaintext highlighter-rouge">~/.buildenv</code> so it can be started on every
following task run. Also٫ since we used <code class="language-plaintext highlighter-rouge">wget</code> inside <code class="language-plaintext highlighter-rouge">install-guix.sh</code>٫ we had
to add it to the images package list.</p>

<p>After the <code class="language-plaintext highlighter-rouge">install-guix</code> task٫ you can use Guix to build and test your project٫
or run any <code class="language-plaintext highlighter-rouge">guix environment --ad-hoc my-package -- my script</code> :)</p>

<h2 id="improvements">Improvements</h2>

<p>When I originally created this code I had a reason why to have both a <code class="language-plaintext highlighter-rouge">sudo</code>
call for <code class="language-plaintext highlighter-rouge">sudo ./scripts/install-guix.sh</code> and <code class="language-plaintext highlighter-rouge">sudo</code> usages inside
<code class="language-plaintext highlighter-rouge">install-guix.sh</code> itself. I couldn’t figure out why (it feels like my past self
was a bit smarter 😬)٫ but it feels ugly now. If it is truly required I could
add an explanation for it٫ or remove this entirely in favor of a more elegant solution.</p>

<p>I could also contribute the Guix image upstream to builds.sr.ht٫ but there
wasn’t any build or smoke tests in the original <a href="https://git.sr.ht/~sircmpwn/builds.sr.ht">repository</a>٫ so I wasn’t
inclined to make something that just “works on my machine” or add a maintainence
burden to the author. I didn’t look at it again recently٫ though.</p>'),('https://euandre.org/2019/06/02/stateless-os.html', 'Using NixOS as an stateless workstation', '1559433600000',  1, '<p>Last week<sup id="fnref:last-week" role="doc-noteref"><a href="#fn:last-week" class="footnote">1</a></sup> I changed back to an old<sup id="fnref:old-computer" role="doc-noteref"><a href="#fn:old-computer" class="footnote">2</a></sup> Samsung laptop٫ and installed
<a href="https://nixos.org/">NixOS</a> on it.</p>

<p>After using NixOS on another laptop for around two years٫ I wanted
verify how reproducible was my desktop environment٫ and how far does
NixOS actually can go on recreating my whole OS from my configuration
files and personal data. I gravitated towards NixOS after trying (and
failing) to create an <code class="language-plaintext highlighter-rouge">install.sh</code> script that would imperatively
install and configure my whole OS using apt-get. When I found a
GNU/Linux distribution that was built on top of the idea of
declaratively specifying the whole OS I was automatically convinced<sup id="fnref:convinced-by-declarative-aspect" role="doc-noteref"><a href="#fn:convinced-by-declarative-aspect" class="footnote">3</a></sup>.</p>

<p>I was impressed. Even though I’ve been experiencing the benefits of Nix
isolation daily٫ I always felt skeptical that something would be
missing٫ because the devil is always on the details. But the result was
much better than expected!</p>

<p>There were only 2 missing configurations:</p>

<ol>
  <li>tap-to-click on the touchpad wasn’t enabled by default;</li>
  <li>the default theme from the gnome-terminal is “Black on white”
instead of “White on black”.</li>
</ol>

<p>That’s all.</p>

<p>I haven’t checked if I can configure those in NixOS GNOME module٫ but I
guess both are scriptable and could be set in a fictional <code class="language-plaintext highlighter-rouge">setup.sh</code>
run.</p>

<p>This makes me really happy٫ actually. More happy than I anticipated.</p>

<p>Having such a powerful declarative OS makes me feel like my data is the
really important stuff (as it should be)٫ and I can interact with it on
any workstation. All I need is an internet connection and a few hours to
download everything. It feels like my physical workstation and the
installed OS are serving me and my data٫ instead of me feeling as
hostage to the specific OS configuration at the moment. Having a few
backup copies of everything important extends such peacefulness.</p>

<p>After this positive experience with recreating my OS from simple Nix
expressions٫ I started to wonder how far I could go with this٫ and
started considering other areas of improvements:</p>

<h3 id="first-run-on-a-fresh-nixos-installation">First run on a fresh NixOS installation</h3>

<p>Right now the initial setup relies on non-declarative manual tasks٫ like
decrypting some credentials٫ or manually downloading <strong>this</strong> git
repository with specific configurations before <strong>that</strong> one.</p>

<p>I wonder what some areas of improvements are on this topic٫ and if
investing on it is worth it (both time-wise and happiness-wise).</p>

<h3 id="emacs">Emacs</h3>

<p>Right now I’m using the <a href="http://spacemacs.org/">Spacemacs</a>٫ which is a
community package curation and configuration on top of
<a href="https://www.gnu.org/software/emacs/">Emacs</a>.</p>

<p>Spacemacs does support the notion of
<a href="http://spacemacs.org/doc/LAYERS.html">layers</a>٫ which you can
declaratively specify and let Spacemacs do the rest.</p>

<p>However this solution isn’t nearly as robust as Nix: being purely
functional٫ Nix does describe everything required to build a derivation٫
and knows how to do so. Spacemacs it closer to more traditional package
managers: even though the layers list is declarative٫ the installation
is still very much imperative. I’ve had trouble with Spacemacs not
behaving the same on different computers٫ both with identical
configurations٫ only brought to convergence back again after a
<code class="language-plaintext highlighter-rouge">git clean -fdx</code> inside <code class="language-plaintext highlighter-rouge">~/.emacs.d/</code>.</p>

<p>The ideal solution would be managing Emacs packages with Nix itself.
After a quick search I did found that <a href="https://nixos.org/nixos/manual/index.html#module-services-emacs-adding-packages">there is support for Emacs
packages in
Nix</a>.
So far I was only aware of <a href="https://www.gnu.org/software/guix/manual/en/html_node/Application-Setup.html#Emacs-Packages">Guix support for Emacs packages</a>.</p>

<p>This isn’t a trivial change because Spacemacs does include extra
curation and configuration on top of Emacs packages. I’m not sure the
best way to improve this right now.</p>

<h3 id="myrepos">myrepos</h3>

<p>I’m using <a href="https://myrepos.branchable.com/">myrepos</a> to manage all my
git repositories٫ and the general rule I apply is to add any repository
specific configuration in myrepos’ <code class="language-plaintext highlighter-rouge">checkout</code> phase:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="c"># sample ~/.mrconfig file snippet</span>
<span class="o">[</span>dev/guix/guix]
checkout <span class="o">=</span>
  git clone https://git.savannah.gnu.org/git/guix.git guix
  <span class="nb">cd </span>guix/
  git config sendemail.to guix-patches@gnu.org
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This way when I clone this repo again the email sending is already
pre-configured.</p>

<p>This works well enough٫ but the solution is too imperative٫ and my
<code class="language-plaintext highlighter-rouge">checkout</code> phases tend to become brittle over time if not enough care is
taken.</p>

<h3 id="gnu-stow">GNU Stow</h3>

<p>For my home profile and personal configuration I already have a few
dozens of symlinks that I manage manually. This has worked so far٫ but
the solution is sometimes fragile and <a href="https://git.sr.ht/~euandreh/dotfiles/tree/316939aa215181b1d22b69e94241eef757add98d/bash/symlinks.sh#L14-75">not declarative at
all</a>.
I wonder if something like <a href="https://www.gnu.org/software/stow/">GNU
Stow</a> can help me simplify this.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I’m really satisfied with NixOS٫ and I intend to keep using it. If what
I’ve said interests you٫ maybe try tinkering with the <a href="https://nixos.org/nix/">Nix package
manager</a> (not the whole NixOS) on your current
distribution (it can live alongside any other package manager).</p>

<p>If you have experience with declarative Emacs package managements٫ GNU
Stow or any similar tool٫ etc.٫ <a href="mailto:eu@euandre.org">I’d like some
tips</a>. If you don’t have any experience at all٫
<a href="mailto:eu@euandre.org">I’d still love to hear from you</a>.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:last-week" role="doc-endnote">
      <p>“Last week” as of the start of this writing٫ so around the end of
May 2019. <a href="#fnref:last-week" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:old-computer" role="doc-endnote">
      <p>I was using a 32GB RAM٫ i7 and 250GB SSD Samsung laptop. The
switch was back to a 8GB RAM٫ i5 and 500GB HDD Dell laptop. The biggest
difference I noticed was on faster memory٫ both RAM availability and the
disk speed٫ but I had 250GB less local storage space. <a href="#fnref:old-computer" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:convinced-by-declarative-aspect" role="doc-endnote">
      <p>The declarative configuration aspect is
something that I now completely take for granted٫ and wouldn’t consider
using something which isn’t declarative. A good metric to show this is me
realising that I can’t pinpoint the moment when I decided to switch to
NixOS. It’s like I had a distant past when this wasn’t true. <a href="#fnref:convinced-by-declarative-aspect" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>'),('https://euandre.org/2018/12/21/using-youtube-dl-to-manage-youtube-subscriptions.html', 'Using “youtube-dl” to manage YouTube subscriptions', '1545350400000',  1, '<p>I’ve recently read the
<a href="https://www.reddit.com/r/DataHoarder/comments/9sg8q5/i_built_a_selfhosted_youtube_subscription_manager/">announcement</a>
of a very nice <a href="https://github.com/chibicitiberiu/ytsm">self-hosted YouTube subscription
manager</a>. I haven’t used
YouTube’s built-in subscriptions for a while now٫ and haven’t missed
it at all. When I saw the announcement٫ I considered writing about the
solution I’ve built on top of <a href="https://youtube-dl.org/">youtube-dl</a>.</p>

<h2 id="background-the-problem-with-youtube">Background: the problem with YouTube</h2>

<p>In many ways٫ I agree with <a href="https://staltz.com/what-happens-when-you-block-internet-giants.html">André Staltz’s view on data ownership and
privacy</a>:</p>

<blockquote>
  <p>I started with the basic premise that “I want to be in control of my
data”. Sometimes that meant choosing when to interact with an internet
giant and how much I feel like revealing to them. Most of times it
meant not interacting with them at all. I don’t want to let them be in
full control of how much they can know about me. I don’t want to be in
autopilot mode. (…) Which leads us to YouTube. While I was able to
find alternatives to Gmail (Fastmail)٫ Calendar (Fastmail)٫ Translate
(Yandex Translate)٫ etc٫ YouTube remains as the most indispensable
Google-owned web service. It is really really hard to avoid consuming
YouTube content. It was probably the smartest startup acquisition
ever. My privacy-oriented alternative is to watch YouTube videos
through Tor٫ which is technically feasible but not polite to use the
Tor bandwidth for these purposes. I’m still scratching my head with
this issue.</p>
</blockquote>

<p>Even though I don’t use most alternative services he mentions٫ I do
watch videos from YouTube. But I also feel uncomfortable logging in to
YouTube with a Google account٫ watching videos٫ creating playlists and
similar things.</p>

<p>Using the mobile app is worse: you can’t even block ads in there.
You’re in less control on what you share with YouTube and Google.</p>

<h2 id="youtube-dl">youtube-dl</h2>

<p>youtube-dl is a command-line tool for downloading videos٫ from YouTube
and <a href="https://rg3.github.io/youtube-dl/supportedsites.html">many other sites</a>:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>youtube-dl https://www.youtube.com/watch?v<span class="o">=</span>rnMYZnY3uLA
<span class="o">[</span>youtube] rnMYZnY3uLA: Downloading webpage
<span class="o">[</span>youtube] rnMYZnY3uLA: Downloading video info webpage
<span class="o">[</span>download] Destination: A Origem da Vida _ Nerdologia-rnMYZnY3uLA.mp4
<span class="o">[</span>download] 100% of 32.11MiB <span class="k">in </span>00:12
</pre></td></tr></tbody></table></code></pre></div></div>

<p>It can be used to download individual videos as showed above٫ but it
also has some interesting flags that we can use:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">--output</code>: use a custom template to create the name of the
downloaded file;</li>
  <li><code class="language-plaintext highlighter-rouge">--download-archive</code>: use a text file for recording and remembering
which videos were already downloaded;</li>
  <li><code class="language-plaintext highlighter-rouge">--prefer-free-formats</code>: prefer free video formats٫ like <code class="language-plaintext highlighter-rouge">webm</code>٫
<code class="language-plaintext highlighter-rouge">ogv</code> and Matroska <code class="language-plaintext highlighter-rouge">mkv</code>;</li>
  <li><code class="language-plaintext highlighter-rouge">--playlist-end</code>: how many videos to download from a “playlist” (a
channel٫ a user or an actual playlist);</li>
  <li><code class="language-plaintext highlighter-rouge">--write-description</code>: write the video description to a
<code class="language-plaintext highlighter-rouge">.description</code> file٫ useful for accessing links and extra content.</li>
</ul>

<p>Putting it all together:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>youtube-dl <span class="s2">"https://www.youtube.com/channel/UClu474HMt895mVxZdlIHXEA"</span> <span class="se">\</span>
             <span class="nt">--download-archive</span> ~/Nextcloud/cache/youtube-dl-seen.conf <span class="se">\</span>
             <span class="nt">--prefer-free-formats</span> <span class="se">\</span>
             <span class="nt">--playlist-end</span> 20 <span class="se">\</span>
             <span class="nt">--write-description</span> <span class="se">\</span>
             <span class="nt">--output</span> <span class="s2">"~/Downloads/yt-dl/%(uploader)s/%(upload_date)s - %(title)s.%(ext)s"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This will download the latest 20 videos from the selected channel٫ and
write down the video IDs in the <code class="language-plaintext highlighter-rouge">youtube-dl-seen.conf</code> file. Running it
immediately after one more time won’t have any effect.</p>

<p>If the channel posts one more video٫ running the same command again will
download only the last video٫ since the other 19 were already
downloaded.</p>

<p>With this basic setup you have a minimal subscription system at work٫
and you can create some functions to help you manage that:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre></td><td class="rouge-code"><pre><span class="c">#!/bin/sh</span>

<span class="nb">export </span><span class="nv">DEFAULT_PLAYLIST_END</span><span class="o">=</span>15

download<span class="o">()</span> <span class="o">{</span>
  youtube-dl <span class="s2">"</span><span class="nv">$1</span><span class="s2">"</span> <span class="se">\</span>
             <span class="nt">--download-archive</span> ~/Nextcloud/cache/youtube-dl-seen.conf <span class="se">\</span>
             <span class="nt">--prefer-free-formats</span> <span class="se">\</span>
             <span class="nt">--playlist-end</span> <span class="nv">$2</span> <span class="se">\</span>
             <span class="nt">--write-description</span> <span class="se">\</span>
             <span class="nt">--output</span> <span class="s2">"~/Downloads/yt-dl/%(uploader)s/%(upload_date)s - %(title)s.%(ext)s"</span>
<span class="o">}</span>
<span class="nb">export</span> <span class="nt">-f</span> download


download_user<span class="o">()</span> <span class="o">{</span>
  download <span class="s2">"https://www.youtube.com/user/</span><span class="nv">$1</span><span class="s2">"</span> <span class="k">${</span><span class="nv">2</span><span class="p">-</span><span class="nv">$DEFAULT_PLAYLIST_END</span><span class="k">}</span>
<span class="o">}</span>
<span class="nb">export</span> <span class="nt">-f</span> download_user


download_channel<span class="o">()</span> <span class="o">{</span>
  download <span class="s2">"https://www.youtube.com/channel/</span><span class="nv">$1</span><span class="s2">"</span> <span class="k">${</span><span class="nv">2</span><span class="p">-</span><span class="nv">$DEFAULT_PLAYLIST_END</span><span class="k">}</span>
<span class="o">}</span>
<span class="nb">export</span> <span class="nt">-f</span> download_channel


download_playlist<span class="o">()</span> <span class="o">{</span>
  download <span class="s2">"https://www.youtube.com/playlist?list=</span><span class="nv">$1</span><span class="s2">"</span> <span class="k">${</span><span class="nv">2</span><span class="p">-</span><span class="nv">$DEFAULT_PLAYLIST_END</span><span class="k">}</span>
<span class="o">}</span>
<span class="nb">export</span> <span class="nt">-f</span> download_playlist
</pre></td></tr></tbody></table></code></pre></div></div>

<p>With these functions٫ you now can have a subscription fetching script to
download the latest videos from your favorite channels:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="c">#!/bin/sh</span>

download_user     ClojureTV                            15
download_channel  <span class="s2">"UCmEClzCBDx-vrt0GuSKBd9g"</span>           100
download_playlist <span class="s2">"PLqG7fA3EaMRPzL5jzd83tWcjCUH9ZUsbX"</span> 15
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Now٫ whenever you want to watch the latest videos٫ just run the above
script and you’ll get all of them in your local machine.</p>

<h2 id="tradeoffs">Tradeoffs</h2>

<h3 id="ive-made-it-for-myself-with-my-use-case-in-mind">I’ve made it for myself٫ with my use case in mind</h3>

<ol>
  <li>
    <p>Offline</p>

    <p>My internet speed it somewhat reasonable<sup id="fnref:internet-speed" role="doc-noteref"><a href="#fn:internet-speed" class="footnote">1</a></sup>٫ but it is really
unstable. Either at work or at home٫ it’s not uncommon to loose internet
access for 2 minutes 3~5 times every day٫ and stay completely offline for a
couple of hours once every week.</p>

    <p>Working through the hassle of keeping a playlist on disk has payed
off many٫ many times. Sometimes I even not notice when the
connection drops for some minutes٫ because I’m watching a video and
working on some document٫ all on my local computer.</p>

    <p>There’s also no quality adjustment for YouTube’s web player٫ I
always pick the higher quality and it doesn’t change during the
video. For some types of content٫ like a podcast with some tiny
visual resources٫ this doesn’t change much. For other types of
content٫ like a keynote presentation with text written on the
slides٫ watching on 144p isn’t really an option.</p>

    <p>If the internet connection drops during the video download٫
youtube-dl will resume from where it stopped.</p>

    <p>This is an offline first benefit that I really like٫ and works well
for me.</p>
  </li>
  <li>
    <p>Sync the “seen” file</p>

    <p>I already have a running instance of Nextcloud٫ so just dumping the
<code class="language-plaintext highlighter-rouge">youtube-dl-seen.conf</code> file inside Nextcloud was a no-brainer.</p>

    <p>You could try putting it in a dedicated git repository٫ and wrap the
script with an autocommit after every run. If you ever had a merge
conflict٫ you’d simply accept all changes and then run:</p>

    <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span><span class="nb">uniq </span>youtube-dl-seen.conf <span class="o">&gt;</span> youtube-dl-seen.conf
</pre></td></tr></tbody></table></code></pre></div>    </div>

    <p>to tidy up the file.</p>
  </li>
  <li>
    <p>Doesn’t work on mobile</p>

    <p>My primary device that I use everyday is my laptop٫ not my phone. It
works well for me this way.</p>

    <p>Also٫ it’s harder to add ad-blockers to mobile phones٫ and most
mobile software still depends on Google’s and Apple’s blessing.</p>

    <p>If you wish٫ you can sync the videos to the SD card periodically٫
but that’s a bit of extra manual work.</p>
  </li>
</ol>

<h3 id="the-good">The Good</h3>

<ol>
  <li>
    <p>Better privacy</p>

    <p>We don’t even have to configure the ad-blocker to keep ads and
trackers away!</p>

    <p>YouTube still has your IP address٫ so using a VPN is always a good
idea. However٫ a timing analysis would be able to identify you
(considering the current implementation).</p>
  </li>
  <li>
    <p>No need to self-host</p>

    <p>There’s no host that needs maintenance. Everything runs locally.</p>

    <p>As long as you keep youtube-dl itself up to date and sync your
“seen” file٫ there’s little extra work to do.</p>
  </li>
  <li>
    <p>Track your subscriptions with git</p>

    <p>After creating a <code class="language-plaintext highlighter-rouge">subscriptions.sh</code> executable that downloads all
the videos٫ you can add it to git and use it to track metadata about
your subscriptions.</p>
  </li>
</ol>

<h3 id="the-bad">The Bad</h3>

<ol>
  <li>
    <p>Maximum playlist size is your disk size</p>

    <p>This is a good thing for getting a realistic view on your actual
“watch later” list. However I’ve run out of disk space many
times٫ and now I need to be more aware of how much is left.</p>
  </li>
</ol>

<h3 id="the-ugly">The Ugly</h3>

<p>We can only avoid all the bad parts of YouTube with youtube-dl as long
as YouTube keeps the videos public and programmatically accessible. If
YouTube ever blocks that we’d loose the ability to consume content this
way٫ but also loose confidence on considering YouTube a healthy
repository of videos on the internet.</p>

<h2 id="going-beyond">Going beyond</h2>

<p>Since you’re running everything locally٫ here are some possibilities to
be explored:</p>

<h3 id="a-playlist-that-is-too-long-for-being-downloaded-all-at-once">A playlist that is too long for being downloaded all at once</h3>

<p>You can wrap the <code class="language-plaintext highlighter-rouge">download_playlist</code> function (let’s call the wrapper
<code class="language-plaintext highlighter-rouge">inc_download</code>) and instead of passing it a fixed number to the
<code class="language-plaintext highlighter-rouge">--playlist-end</code> parameter٫ you can store the <code class="language-plaintext highlighter-rouge">$n</code> in a folder
(something like <code class="language-plaintext highlighter-rouge">$HOME/.yt-db/$PLAYLIST_ID</code>) and increment it by <code class="language-plaintext highlighter-rouge">$step</code>
every time you run <code class="language-plaintext highlighter-rouge">inc_download</code>.</p>

<p>This way you can incrementally download videos from a huge playlist
without filling your disk with gigabytes of content all at once.</p>

<h3 id="multiple-computer-scenario">Multiple computer scenario</h3>

<p>The <code class="language-plaintext highlighter-rouge">download_playlist</code> function could be aware of the specific machine
that it is running on and apply specific policies depending on the
machine: always download everything; only download videos that aren’t
present anywhere else; etc.</p>

<h2 id="conclusion">Conclusion</h2>

<p>youtube-dl is a great tool to keep at hand. It covers a really large
range of video websites and works robustly.</p>

<p>Feel free to copy and modify this code٫ and <a href="mailto:eu@euandre.org">send me</a>
suggestions of improvements or related content.</p>

<h2 id="edit"><em>Edit</em></h2>

<p>2019/05/22: Fix spelling.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:internet-speed" role="doc-endnote">
      <p>Considering how expensive it is and the many ways it could be
better٫ but also how much it has improved over the last years٫ I say it’s
reasonable. <a href="#fnref:internet-speed" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>'),('https://euandre.org/2018/08/01/verifying-npm-ci-reproducibility.html', 'Verifying “npm ci” reproducibility', '1533081600000',  1, '<p>When <a href="https://blog.npmjs.org/post/161081169345/v500">npm@5</a> came bringing
<a href="https://docs.npmjs.com/files/package-locks">package-locks</a> with it٫ I was
confused about the benefits it provided٫ since running <code class="language-plaintext highlighter-rouge">npm install</code> more than
once could resolve all the dependencies again and yield yet another fresh
<code class="language-plaintext highlighter-rouge">package-lock.json</code> file. The message saying “you should add this file to
version control” left me hesitant on what to do<sup id="fnref:package-lock-message" role="doc-noteref"><a href="#fn:package-lock-message" class="footnote">1</a></sup>.</p>

<p>However the <a href="https://blog.npmjs.org/post/171556855892/introducing-npm-ci-for-faster-more-reliable">addition of <code class="language-plaintext highlighter-rouge">npm ci</code></a>
filled this gap: it’s a stricter variation of <code class="language-plaintext highlighter-rouge">npm install</code> which
guarantees that “<a href="https://docs.npmjs.com/files/package-lock.json">subsequent installs are able to generate identical trees</a>”. But are they
really identical? I could see that I didn’t have the same problems of
different installation outputs٫ but I didn’t know for <strong>sure</strong> if it
was really identical.</p>

<h2 id="computing-the-hash-of-a-directorys-content">Computing the hash of a directory’s content</h2>

<p>I quickly searched for a way to check for the hash signature of an
entire directory tree٫ but I couldn’t find one. I’ve made a poor
man’s <a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle tree</a>
implementation using <code class="language-plaintext highlighter-rouge">sha256sum</code> and a few piped commands at the
terminal:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre>merkle-tree <span class="o">()</span> <span class="o">{</span>
  <span class="nb">dirname</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">1</span><span class="p">-.</span><span class="k">}</span><span class="s2">"</span>
  <span class="nb">pushd</span> <span class="s2">"</span><span class="nv">$dirname</span><span class="s2">"</span>
  find <span class="nb">.</span> <span class="nt">-type</span> f              | <span class="se">\</span>
    <span class="nb">sort</span>                      | <span class="se">\</span>
    xargs <span class="nt">-I</span><span class="o">{}</span> <span class="nb">sha256sum</span> <span class="s2">"{}"</span> | <span class="se">\</span>
    <span class="nb">sha256sum</span>                 | <span class="se">\</span>
    <span class="nb">awk</span> <span class="s1">"{print $1}"</span>
  <span class="nb">popd</span>
<span class="o">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Going through it line by line:</p>

<ul>
  <li>#1 we define a Bash function called <code class="language-plaintext highlighter-rouge">merkle-tree</code>;</li>
  <li>#2 it accepts a single argument: the directory to compute the
merkle tree from. If nothing is given٫ it runs on the current
directory (<code class="language-plaintext highlighter-rouge">.</code>);</li>
  <li>#3 we go to the directory٫ so we don’t get different prefixes in
<code class="language-plaintext highlighter-rouge">find</code>’s output (like <code class="language-plaintext highlighter-rouge">../a/b</code>);</li>
  <li>#4 we get all files from the directory tree. Since we’re using
<code class="language-plaintext highlighter-rouge">sha256sum</code> to compute the hash of the file contents٫ we need to
filter out folders from it;</li>
  <li>#5 we need to sort the output٫ since different file systems and
<code class="language-plaintext highlighter-rouge">find</code> implementations may return files in different orders;</li>
  <li>#6 we use <code class="language-plaintext highlighter-rouge">xargs</code> to compute the hash of each file individually
through <code class="language-plaintext highlighter-rouge">sha256sum</code>. Since a file may contain spaces we need to
escape it with quotes;</li>
  <li>#7 we compute the hash of the combined hashes. Since <code class="language-plaintext highlighter-rouge">sha256sum</code>
output is formatted like <code class="language-plaintext highlighter-rouge">&lt;hash&gt; &lt;filename&gt;</code>٫ it produces a
different final hash if a file ever changes name without changing
it’s content;</li>
  <li>#8 we get the final hash output٫ excluding the <code class="language-plaintext highlighter-rouge">&lt;filename&gt;</code> (which
  is <code class="language-plaintext highlighter-rouge">-</code> in this case٫ aka <code class="language-plaintext highlighter-rouge">stdin</code>).</li>
</ul>

<h3 id="positive-points">Positive points:</h3>

<ol>
  <li>ignore timestamp: running more than once on different installation
yields the same hash;</li>
  <li>the name of the file is included in the final hash computation.</li>
</ol>

<h3 id="limitations">Limitations:</h3>

<ol>
  <li>it ignores empty folders from the hash computation;</li>
  <li>the implementation’s only goal is to represent using a digest
whether the content of a given directory is the same or not. Leaf
presence checking is obviously missing from it.</li>
</ol>

<h3 id="testing-locally-with-sample-data">Testing locally with sample data</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="nb">mkdir</span> /tmp/merkle-tree-test/
<span class="nb">cd</span> /tmp/merkle-tree-test/
<span class="nb">mkdir</span> <span class="nt">-p</span> a/b/ a/c/ d/
<span class="nb">echo</span> <span class="s2">"one"</span>   <span class="o">&gt;</span> a/b/one.txt
<span class="nb">echo</span> <span class="s2">"two"</span>   <span class="o">&gt;</span> a/c/two.txt
<span class="nb">echo</span> <span class="s2">"three"</span> <span class="o">&gt;</span> d/three.txt
merkle-tree <span class="nb">.</span> <span class="c"># output is       be343bb01fe00aeb8fef14a3e16b1c3d1dccbf86d7e41b4753e6ccb7dc3a57c3</span>
merkle-tree <span class="nb">.</span> <span class="c"># output still is be343bb01fe00aeb8fef14a3e16b1c3d1dccbf86d7e41b4753e6ccb7dc3a57c3</span>
<span class="nb">echo</span> <span class="s2">"four"</span>  <span class="o">&gt;</span> d/four.txt
merkle-tree <span class="nb">.</span> <span class="c"># output is now   b5464b958969ed81815641ace96b33f7fd52c20db71a7fccc45a36b3a2ae4d4c</span>
<span class="nb">rm </span>d/four.txt
merkle-tree <span class="nb">.</span> <span class="c"># output back to  be343bb01fe00aeb8fef14a3e16b1c3d1dccbf86d7e41b4753e6ccb7dc3a57c3</span>
<span class="nb">echo</span> <span class="s2">"hidden-five"</span> <span class="o">&gt;</span> a/b/one.txt
merkle-tree <span class="nb">.</span> <span class="c"># output changed  471fae0d074947e4955e9ac53e95b56e4bc08d263d89d82003fb58a0ffba66f5</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>It seems to work for this simple test case.</p>

<p>You can try copying and pasting it to verify the hash signatures.</p>

<h2 id="using-merkle-tree-to-check-the-output-of-npm-ci">Using <code class="language-plaintext highlighter-rouge">merkle-tree</code> to check the output of <code class="language-plaintext highlighter-rouge">npm ci</code></h2>

<p><em>I’ve done all of the following using Node.js v8.11.3 and npm@6.1.0.</em></p>

<p>In this test case I’ll take the main repo of
<a href="https://lernajs.io/">Lerna</a><sup id="fnref:lerna-package-lock" role="doc-noteref"><a href="#fn:lerna-package-lock" class="footnote">2</a></sup>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="nb">cd</span> /tmp/
git clone https://github.com/lerna/lerna.git
<span class="nb">cd </span>lerna/
git checkout 57ff865c0839df75dbe1974971d7310f235e1109
npm ci
merkle-tree node_modules/ <span class="c"># outputs 11e218c4ac32fac8a9607a8da644fe870a25c99821167d21b607af45699afafa</span>
<span class="nb">rm</span> <span class="nt">-rf</span> node_modules/
npm ci
merkle-tree node_modules/ <span class="c"># outputs 11e218c4ac32fac8a9607a8da644fe870a25c99821167d21b607af45699afafa</span>
npm ci      <span class="c"># test if it also works with an existing node_modules/ folder</span>
merkle-tree node_modules/ <span class="c"># outputs 11e218c4ac32fac8a9607a8da644fe870a25c99821167d21b607af45699afafa</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Good job <code class="language-plaintext highlighter-rouge">npm ci</code> :)</p>

<p>#6 and #9 take some time to run (21 seconds in my machine)٫ but this
specific use case isn’t performance sensitive. The slowest step is
computing the hash of each individual file.</p>

<h2 id="conclusion">Conclusion</h2>

<p><code class="language-plaintext highlighter-rouge">npm ci</code> really “generates identical trees”.</p>

<p>I’m not aware of any other existing solution for verifying the hash
signature of a directory. If you know any I’d <a href="mailto:eu@euandre.org">like to know</a>.</p>

<h2 id="edit"><em>Edit</em></h2>

<p>2019/05/22: Fix spelling.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:package-lock-message" role="doc-endnote">
      <p>The
<a href="https://docs.npmjs.com/cli/install#description">documentation</a> claims <code class="language-plaintext highlighter-rouge">npm
install</code> is driven by the existing <code class="language-plaintext highlighter-rouge">package-lock.json</code>٫ but that’s actually
<a href="https://github.com/npm/npm/issues/17979#issuecomment-332701215">a little bit tricky</a>. <a href="#fnref:package-lock-message" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:lerna-package-lock" role="doc-endnote">
      <p>Finding a big known repo that actually committed the
<code class="language-plaintext highlighter-rouge">package-lock.json</code> file was harder than I expected. <a href="#fnref:lerna-package-lock" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>'),('https://euandre.org/2018/07/17/running-guix-on-nixos.html', 'Running Guix on NixOS', '1531785600000',  1, '<p>I wanted to run
Guix on a NixOS machine. Even though the Guix manual explains how to do it
<a href="https://www.gnu.org/software/guix/manual/en/html_node/Binary-Installation.html#Binary-Installation">step by step</a>٫ I needed a few extra ones to make it work properly.</p>

<p>I couldn’t just install GuixSD because my wireless network card
doesn’t have any free/libre drivers (yet).</p>

<h2 id="creating-guixbuilder-users">Creating <code class="language-plaintext highlighter-rouge">guixbuilder</code> users</h2>

<p>Guix requires you to create non-root users that will be used to perform
the builds in the isolated environments.</p>

<p>The <a href="https://www.gnu.org/software/guix/manual/en/html_node/Build-Environment-Setup.html#Build-Environment-Setup">manual</a> already provides you with a ready to run (as root) command for
creating the build users:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre>groupadd <span class="nt">--system</span> guixbuild
<span class="k">for </span>i <span class="k">in</span> <span class="sb">`</span><span class="nb">seq</span> <span class="nt">-w</span> 1 10<span class="sb">`</span><span class="p">;</span>
<span class="k">do
  </span>useradd <span class="nt">-g</span> guixbuild <span class="nt">-G</span> guixbuild           <span class="se">\</span>
          <span class="nt">-d</span> /var/empty <span class="nt">-s</span> <span class="sb">`</span>which nologin<span class="sb">`</span>    <span class="se">\</span>
          <span class="nt">-c</span> <span class="s2">"Guix build user </span><span class="nv">$i</span><span class="s2">"</span> <span class="nt">--system</span>    <span class="se">\</span>
          guixbuilder<span class="nv">$i</span><span class="p">;</span>
<span class="k">done</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>However٫ In my personal NixOS I have disabled <a href="https://nixos.org/nixos/manual/index.html#sec-user-management"><code class="language-plaintext highlighter-rouge">users.mutableUsers</code></a>٫ which
means that even if I run the above command it means that they’ll be removed once
I rebuild my OS:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span><span class="nb">sudo </span>nixos-rebuild switch
<span class="o">(</span>...<span class="o">)</span>
removing user ‘guixbuilder7’
removing user ‘guixbuilder3’
removing user ‘guixbuilder10’
removing user ‘guixbuilder1’
removing user ‘guixbuilder6’
removing user ‘guixbuilder9’
removing user ‘guixbuilder4’
removing user ‘guixbuilder2’
removing user ‘guixbuilder8’
removing user ‘guixbuilder5’
<span class="o">(</span>...<span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Instead of enabling <code class="language-plaintext highlighter-rouge">users.mutableUsers</code> I could add the Guix users by
adding them to my system configuration:</p>

<div class="language-nix highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
</pre></td><td class="rouge-code"><pre><span class="p">{</span> <span class="nv">config</span><span class="p">٫</span> <span class="nv">pkgs</span><span class="p">٫</span> <span class="o">...</span><span class="p">}:</span>

<span class="p">{</span>

  <span class="c"># ... NixOS usual config ellided ...</span>

  <span class="nv">users</span> <span class="o">=</span> <span class="p">{</span>
    <span class="nv">mutableUsers</span> <span class="o">=</span> <span class="kc">false</span><span class="p">;</span>

    <span class="nv">extraUsers</span> <span class="o">=</span>
      <span class="kd">let</span>
        <span class="nv">andrehUser</span> <span class="o">=</span>  <span class="p">{</span>
          <span class="nv">andreh</span> <span class="o">=</span> <span class="p">{</span>
            <span class="c"># my custom user config</span>
          <span class="p">};</span>
        <span class="p">};</span>
        <span class="nv">buildUser</span> <span class="o">=</span> <span class="p">(</span><span class="nv">i</span><span class="p">:</span>
          <span class="p">{</span>
            <span class="s2">"guixbuilder</span><span class="si">${</span><span class="nv">i</span><span class="si">}</span><span class="s2">"</span> <span class="o">=</span> <span class="p">{</span>                   <span class="c"># guixbuilder$i</span>
              <span class="nv">group</span> <span class="o">=</span> <span class="s2">"guixbuild"</span><span class="p">;</span>                  <span class="c"># -g guixbuild</span>
              <span class="nv">extraGroups</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"guixbuild"</span><span class="p">];</span>          <span class="c"># -G guixbuild</span>
              <span class="nv">home</span> <span class="o">=</span> <span class="s2">"/var/empty"</span><span class="p">;</span>                  <span class="c"># -d /var/empty</span>
              <span class="nv">shell</span> <span class="o">=</span> <span class="nv">pkgs</span><span class="o">.</span><span class="nv">nologin</span><span class="p">;</span>                 <span class="c"># -s `which nologin`</span>
              <span class="nv">description</span> <span class="o">=</span> <span class="s2">"Guix build user </span><span class="si">${</span><span class="nv">i</span><span class="si">}</span><span class="s2">"</span><span class="p">;</span> <span class="c"># -c "Guix buid user $i"</span>
              <span class="nv">isSystemUser</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span>                  <span class="c"># --system</span>
            <span class="p">};</span>
          <span class="p">}</span>
        <span class="p">);</span>
      <span class="kn">in</span>
        <span class="c"># merge all users</span>
        <span class="nv">pkgs</span><span class="o">.</span><span class="nv">lib</span><span class="o">.</span><span class="nv">fold</span> <span class="p">(</span><span class="nv">str</span><span class="p">:</span> <span class="nv">acc</span><span class="p">:</span> <span class="nv">acc</span> <span class="o">//</span> <span class="nv">buildUser</span> <span class="nv">str</span><span class="p">)</span>
                      <span class="nv">andrehUser</span>
                      <span class="c"># for i in `seq -w 1 10`</span>
                      <span class="p">(</span><span class="kr">map</span> <span class="p">(</span><span class="nv">pkgs</span><span class="o">.</span><span class="nv">lib</span><span class="o">.</span><span class="nv">fixedWidthNumber</span> <span class="mi">2</span><span class="p">)</span> <span class="p">(</span><span class="kr">builtins</span><span class="o">.</span><span class="nv">genList</span> <span class="p">(</span><span class="nv">n</span><span class="p">:</span> <span class="nv">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="mi">10</span><span class="p">));</span>

    <span class="nv">extraGroups</span><span class="o">.</span><span class="nv">guixbuild</span> <span class="o">=</span> <span class="p">{</span>
      <span class="nv">name</span> <span class="o">=</span> <span class="s2">"guixbuild"</span><span class="p">;</span>
    <span class="p">};</span>
  <span class="p">};</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Here I used <code class="language-plaintext highlighter-rouge">fold</code> and the <code class="language-plaintext highlighter-rouge">//</code> operator to merge all of the
configuration sets into a single <code class="language-plaintext highlighter-rouge">extraUsers</code> value.</p>

<h2 id="creating-the-systemd-service">Creating the <code class="language-plaintext highlighter-rouge">systemd</code> service</h2>

<p>One other thing missing was the <code class="language-plaintext highlighter-rouge">systemd</code> service.</p>

<p>First I couldn’t just copy the <code class="language-plaintext highlighter-rouge">.service</code> file to <code class="language-plaintext highlighter-rouge">/etc</code> since in NixOS
that folder isn’t writable. But also I wanted the service to be better
integrated with the OS.</p>

<p>That was a little easier than creating the users٫ all I had to do was translate
the provided <a href="https://git.savannah.gnu.org/cgit/guix.git/tree/etc/guix-daemon.service.in?id=00c86a888488b16ce30634d3a3a9d871ed6734a2"><code class="language-plaintext highlighter-rouge">guix-daemon.service.in</code></a> configuration to an equivalent Nix
expression</p>

<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td class="rouge-code"><pre><span class="c"># This is a "service unit file" for the systemd init system to launch
# "guix-daemon".  Drop it in /etc/systemd/system or similar to have
# "guix-daemon" automatically started.
</span>
<span class="nn">[Unit]</span>
<span class="py">Description</span><span class="p">=</span><span class="s">Build daemon for GNU Guix</span>

<span class="nn">[Service]</span>
<span class="py">ExecStart</span><span class="p">=</span><span class="s">/var/guix/profiles/per-user/root/guix-profile/bin/guix-daemon --build-users-group=guixbuild</span>
<span class="py">Environment</span><span class="p">=</span><span class="s">GUIX_LOCPATH=/root/.guix-profile/lib/locale</span>
<span class="py">RemainAfterExit</span><span class="p">=</span><span class="s">yes</span>
<span class="py">StandardOutput</span><span class="p">=</span><span class="s">syslog</span>
<span class="py">StandardError</span><span class="p">=</span><span class="s">syslog</span>

<span class="c"># See &lt;https://lists.gnu.org/archive/html/guix-devel/2016-04/msg00608.html&gt;.
# Some package builds (for example٫ go@1.8.1) may require even more than
# 1024 tasks.
</span><span class="py">TasksMax</span><span class="p">=</span><span class="s">8192</span>

<span class="nn">[Install]</span>
<span class="py">WantedBy</span><span class="p">=</span><span class="s">multi-user.target</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This sample <code class="language-plaintext highlighter-rouge">systemd</code> configuration file became:</p>

<div class="language-nix highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="rouge-code"><pre><span class="nv">guix-daemon</span> <span class="o">=</span> <span class="p">{</span>
  <span class="nv">enable</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span>
  <span class="nv">description</span> <span class="o">=</span> <span class="s2">"Build daemon for GNU Guix"</span><span class="p">;</span>
  <span class="nv">serviceConfig</span> <span class="o">=</span> <span class="p">{</span>
    <span class="nv">ExecStart</span> <span class="o">=</span> <span class="s2">"/var/guix/profiles/per-user/root/guix-profile/bin/guix-daemon --build-users-group=guixbuild"</span><span class="p">;</span>
    <span class="nv">Environment</span><span class="o">=</span><span class="s2">"GUIX_LOCPATH=/root/.guix-profile/lib/locale"</span><span class="p">;</span>
    <span class="nv">RemainAfterExit</span><span class="o">=</span><span class="s2">"yes"</span><span class="p">;</span>
    <span class="nv">StandardOutput</span><span class="o">=</span><span class="s2">"syslog"</span><span class="p">;</span>
    <span class="nv">StandardError</span><span class="o">=</span><span class="s2">"syslog"</span><span class="p">;</span>
    <span class="nv">TaskMax</span><span class="o">=</span> <span class="s2">"8192"</span><span class="p">;</span>
  <span class="p">};</span>
  <span class="nv">wantedBy</span> <span class="o">=</span> <span class="p">[</span> <span class="s2">"multi-user.target"</span> <span class="p">];</span>
<span class="p">};</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>There you go! After running <code class="language-plaintext highlighter-rouge">sudo nixos-rebuild switch</code> I could get Guix
up and running:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="rouge-code"><pre><span class="nv">$ </span>guix package <span class="nt">-i</span> hello
The following package will be installed:
   hello        2.10    /gnu/store/bihfrh609gkxb9dp7n96wlpigiv3krfy-hello-2.10

substitute: updating substitutes from <span class="s1">"https://mirror.hydra.gnu.org"</span>... 100.0%
The following derivations will be built:
   /gnu/store/nznmdn6inpwxnlkrasydmda4s2vsp9hg-profile.drv
   /gnu/store/vibqrvw4c8lacxjrkqyzqsdrmckv77kq-fonts-dir.drv
   /gnu/store/hi8alg7wi0wgfdi3rn8cpp37zhx8ykf3-info-dir.drv
   /gnu/store/cvkbp378cvfjikz7mjymhrimv7j12p0i-ca-certificate-bundle.drv
   /gnu/store/d62fvxymnp95rzahhmhf456bsf0xg1c6-manual-database.drv
Creating manual page database...
1 entries processed <span class="k">in </span>0.0 s
2 packages <span class="k">in </span>profile
<span class="nv">$ </span>hello
Hello٫ world!
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Some improvements to this approach are:</p>

<ol>
  <li>looking into <a href="https://nixos.org/nixos/manual/index.html#sec-writing-modules">NixOS modules</a> and trying to bundle everything together
into a single logical unit;</li>
  <li><a href="https://www.gnu.org/software/guix/manual/en/html_node/Requirements.html#Requirements">build Guix from source</a> and share the Nix store and daemon with Guix.</li>
</ol>

<p>Happy Guix/Nix hacking!</p>'),('https://tinyprojects.dev/projects/tiny_website', 'Week 0: Tiny Website | Tiny Projects', 'NaN',  4, 'Week 0 of my year long tiny projects mission. Project 0 is building a tiny website.'),('https://tinyprojects.dev/posts/tiny_websites_are_great', 'Tiny websites are great | Tiny Projects', 'NaN',  4, 'Why building your own tiny website is a really great project that every coder should do.'),('https://tinyprojects.dev/posts/tiny_websites_are_great', 'How to code a tiny website | Tiny Projects', 'NaN',  4, 'How to make a tiny website that"s really simple٫ easy to maintain٫ and cheap to run.'),('https://tinyprojects.dev/guides/tiny_website', 'How to code a tiny website | Tiny Projects', 'NaN',  4, 'How to make a tiny website that"s really simple٫ easy to maintain٫ and cheap to run.'),('https://tinyprojects.dev/projects/silicon_valley_domain_names', 'Week 1: Silicon Valley Domain Names | Tiny Projects', 'NaN',  4, 'Week 1 of Tiny Projects. Exploring domain names٫ and how it was possible to purchase some of the biggest domain names in silicon valley٫ including netflix.soy.'),('https://tinyprojects.dev/posts/i_bought_netflix_dot_soy', 'I bought netflix.soy | Tiny Projects', 'NaN',  4, 'An exploration into top level domains. How I ended up buying netflix.soy and domains from facebook٫ microsoft and google.'),('https://tinyprojects.dev/projects/battle_royale', 'Week 2/3: Building a Battle Royale game | Tiny Projects', 'NaN',  4, 'How I built and launched a tiny battle royale game in the space of two weeks. It was a struggle. Welcome to week 2/3 of Tiny Projects!'),('https://tinyprojects.dev/projects/one_item_store', 'Week 4/5: One Item Store | Tiny Projects', 'NaN',  4, 'The story of building and launching a tiny online store builder called; basically think of a micro-Shopify. This is week 4/5 of Tiny Projects.'),('https://tinyprojects.dev/posts/lockdown_burnout', 'Lockdown Burnout | Tiny Projects', 'NaN',  4, 'How I experienced lockdown burnout after 3 months of hardcore productivity during lockdown٫ then how I overcame it.'),('https://tinyprojects.dev/projects/snormal', 'Project 4: Snormal | Tiny Projects', 'NaN',  4, 'How I built Snormal: a social network for all the bits of content that don"t make it onto your social media highlight reel.'),('https://tinyprojects.dev/posts/are_apps_even_that_relevant_anymore', 'Are apps even that relevant anymore? | Tiny Projects', 'NaN',  4, 'Why I think mobile apps are becoming less relevant for developers and consumers٫ and why we should go back to creating great mobile website software.'),('https://leancrew.com/all-this/2020/09/parsing-date-strings-in-shortcuts/', 'Parsing date strings in Shortcuts', '1599280749000',  5, '
  I didn’t realize until today that Shortcuts has a date parser. It doesn’t call itself a date parser٫ and the documentation doesn’t explain what kinds of text strings it can parse٫ but it’s Shortcuts٫ so what would you expect?
'),('https://leancrew.com/all-this/2020/08/a-battery-bitbar-bonanza/', 'A battery BitBar bonanza', '1598830579000',  5, '
  I started reading <a href="https://forum.keyboardmaestro.com/new">this thread</a> on the Keyboard Maestro forum because I’ve been interested in the <a href="https://amazon.com/dp/B06XKNZT1P?tag=andnowitsa085-20">Stream Deck</a> (yes٫ that’s an affiliate link) for a while and will probably be getting one soon. I kept reading because <a href="https://rhymeswithdiploma.com/">TJ Luoma</a>’s answer made me realize I didn’t need the Stream Deck to use the ideas in his solution; it would work just as well with <a href="https://github.com/matryer/bitbar">BitBar</a>.
'),('https://leancrew.com/all-this/2020/08/rss-and-the-pleasure-of-not-thinking/', 'RSS and the pleasure of not thinking', '1598627975000',  5, '
  I listened to the recent <a href="https://www.relay.fm/mpu/550"><em>Mac Power Users</em> episode on RSS</a> while on a long walk the other day٫ and I really enjoyed it. Partly٫ of course٫ because I just like listening to Stephen and David٫ but mainly because I didn’t feel I had any stake in it.
'),('https://leancrew.com/all-this/2020/08/a-new-old-python/', 'A new old Python', '1598273968000',  5, '
  You may have noticed something new in <a href="https://leancrew.com/all-this/2020/08/bitbar-superduper-and-library-books/">yesterday’s scripts</a>: the shebang lines were
'),('https://leancrew.com/all-this/2020/08/bitbar-superduper-and-library-books/', 'BitBar٫ SuperDuper٫ and library books', '1598216239000',  5, '
  Jason Snell’s <a href="https://sixcolors.com/post/2020/08/put-anything-in-your-macs-menu-bar-with-bitbar/">recent post</a> on <a href="https://github.com/matryer/bitbar">BitBar</a> inspired me to build a couple of menu bar notices of my own.
'),('https://leancrew.com/all-this/2020/08/epic-relief/', 'Epic relief', '1597754546000',  5, '
  One of the great things about not being—or having aspirations of being—a professional Apple blogger is that there’s no compulsion to write about every Apple story that pops up. I was reminded of this a few days ago when the Apple/Epic war broke out. As my RSS reader filled with links and summaries and hot takes٫ a wave of relief washed over me. It was like seeing that my grades on the midterms and homework were good enough that I didn’t have to take the final exam.
'),('https://leancrew.com/all-this/2020/08/apple-watch-settings/', 'Apple Watch settings', '1597412959000',  5, '
  <a href="https://leancrew.com/all-this/2020/08/dear-apple/">Recently</a>٫ I had some trouble with my Apple Watch and had to unpair/re-pair it. In the process٫ the watch’s settings were lost. I was reminded of this yesterday when I crossed my arms and the watch announced the time. After Googling for the way to stop that٫ I decided to make a Note to accumulate all the settings I’ve used to get the watch working the way I want.
'),('https://leancrew.com/all-this/2020/08/deep-insight/', 'Deep insight', '1597203476000',  5, '
  Literally the last sentence in <a href="https://www.zdnet.com/article/mozilla-lays-off-250-employees-while-it-refocuses-on-commercial-products/">this article</a> about Mozilla laying off a quarter of its employees:
'),('https://leancrew.com/all-this/2020/08/dear-apple/', 'Dear Apple٫', '1597085751000',  5, '
  I have been an Apple user for 35 years. Do you have one minute for a little story? Thanks.
'),('https://leancrew.com/all-this/2020/08/a-more-handy-warhol/', 'A more handy Warhol', '1597068635000',  5, '
  After posting my <a href="https://leancrew.com/all-this/2020/08/development-shortcuts-and-warhol/">Warhol shortcut</a>٫ I got a couple of good suggestions for improvements. They overlapped to some extent٫ so I put them together into <a href="https://www.icloud.com/shortcuts/74ccef08af784e78abfe8a4448f8ae9b">a new Warhol</a>.
'),('https://leancrew.com/all-this/2020/08/phil-schiller/', 'Phil Schiller', '1596991701000',  5, '
  Although I won’t be terribly surprised if Phil Schiller appears onstage during this fall’s introduction of the new iPhones—those things get planned well in advance—it’s possible we’ve seen the last of his keynote presentations. I’m going to miss them for a couple of reasons.
'),('https://leancrew.com/all-this/2020/08/development-shortcuts-and-warhol/', 'Development٫ Shortcuts٫ and Warhol', '1596810481000',  5, '
  For the past several days٫ I’ve been annoying my family with a shortcut. If there are people in your life you want to annoy٫ you might want to use it. And apart from the annoyance value٫ it has some Shortcuts programming techniques that I want to memorialize for future use.
'),('https://jvns.ca/blog/2020/08/22/print-run-manager-zine/', 'Wizard Zines" first print run: Help! I have a Manager!', '1598066527000',  6, '

<p>Hello! For the first time٫ Wizard Zines is doing a ★★print shipment★★!</p>

<p>I printed out 400 copies of <a href="https://wizardzines.com/zines/manager/">Help! I have a manager!</a> at the
best print shop I could find in Montreal and they&rsquo;re ready to ship to you. Free
shipping to anywhere in the world (as long as Canada Post will let me ship
there) is included. The deadline to order a zine is <strong>September 6</strong>.</p>

<p>I&rsquo;ve wanted to get into printing and shipping my zines for a long time٫ so I&rsquo;m
very excited to try this out. So far the only option has been for people to
print them on their home printers or at their local print shop.</p>

<p>I&rsquo;m doing all the packaging and shipping myself from my house٫ so I&rsquo;m going to
ship them all out in a big batch around September 7.</p>

<div align="center">                                                                                                                       
  <a class="button" href="https://gumroad.com/l/manager-zine-print">Get it for $16</a>

</div>

<h4 id="the-zines">the zines!</h4>

<p>Here&rsquo;s a picture of one of the boxes of zines! So many zines!
<div align="center"><img src="https://jvns.ca/images/box-of-zines.jpg" style="max-width: 20em"></div></p>

<p>I experimented with a few different print shops in Montreal٫ and I found out
that using a print shop that cost more got me way better quality zines! So
that&rsquo;s what I did. (I went with <a href="https://www.photosynthese.com/en-ca">Photosynthèse</a>).</p>

<h4 id="why-i-m-shipping-them-myself">why I&rsquo;m shipping them myself</h4>

<p>I spent a bunch of time looking into fulfillment companies to try to ~scale~
printing &amp; shipping zines. That research might still come in handy if
this first batch goes well (I probably won&rsquo;t keep doing it myself forever!)٫
but in the spirit of
<a href="https://stackingthebricks.com/the-fine-art-of-flintstoning/">flintstoning</a>٫ I
decided it would be a lot simpler to start out by not overengineering the
process. Shipping a zine to the US from Canada using letter mail only costs
about $3٫ so I can even include free shipping.</p>

<p>I&rsquo;ve actually shipped 100 zines once before in an <a href="https://www.indiegogo.com/projects/linux-debugging-tools-you-ll-love-the-zine#/">indiegogo campaign I ran in
2016</a>٫
and it wasn&rsquo;t too bad٫ so I&rsquo;m confident that I can ship 400 zines manually as
long as I can do it all in one giant batch. That time I even wrote all the
addresses by hand٫ which I definitely won&rsquo;t do this time.</p>

<p>And doing it myself means I can do some fun things with the envelopes &amp; my
laser printer that would be hard to convince a fulfillment company to do.</p>

<h2 id="faq">FAQ</h2>

<p>Here&rsquo;s a FAQ which will hopefully answer all your questions! Email me
at print@wizardzines.com if you have other questions.</p>

<h4 id="what-s-included">What&rsquo;s included?</h4>

<p>You&rsquo;ll get:</p>

<ol>
<li>A print copy of Help! I have a manager!٫ printed in full colour on high quality paper.</li>
<li>A PDF copy of Help! I have a manager! (which usually costs $10 on its own).</li>
</ol>

<h4 id="what-s-the-order-deadline">What&rsquo;s the order deadline?</h4>

<p>The deadline to order a zine is <strong>September 6</strong>.</p>

<h4 id="when-will-i-get-it">When will I get it?</h4>

<p>I&rsquo;ll mail all the zines around September 7-8٫ 2020 (right after orders close).</p>

<p>You should get your zine about a week later٫ assuming the mail system behaves.</p>

<h4 id="will-i-get-a-tracking-number">Will I get a tracking number?</h4>

<p>No. All the zines will be shipped by first class letter mail from Canada٫ without any tracking. This keeps shipping costs down so that I can do free shipping :). If anything at all goes wrong with your shipment٫ just let me know (<strong>print@wizardzines.com</strong>) and I&rsquo;ll mail you another one. (it&rsquo;s like UDP!)</p>

<p>The zines should reach the US in about a week٫ longer if you&rsquo;re overseas.</p>

<h4 id="can-i-order-more-than-one-copy-at-a-time">Can I order more than one copy at a time?</h4>

<p>No٫ to keep things simple٫ I&rsquo;m only shipping one zine at a time. I&rsquo;m hoping to do batches in the future though!</p>

<h4 id="can-i-order-these-for-my-team">Can I order these for my team?</h4>

<p>Yes! You&rsquo;ll just need to make one order per person٫ so that I get everyone&rsquo;s shipping address. This is extremely compatible with remote work :)</p>

<p><small>also٫ if you want to order 50 or more print copies mailed to a single address٫ email me and we&rsquo;ll work something out</small></p>

<h4 id="what-happens-if-i-don-t-order-by-september-6">What happens if I don&rsquo;t order by September 6?</h4>

<p>If this print run sells out٫ we&rsquo;ll print more in the future!</p>

<h4 id="what-if-i-already-bought-the-digital-copy">What if I already bought the digital copy?</h4>

<p>If you already bought the digital copy &ndash; thank you!! You can email me at <strong>print@wizardzines.com</strong> and I&rsquo;ll send you a discount code to get the print version for less.</p>

<h4 id="what-are-your-future-print-plans">What are your future print plans?</h4>

<p>If this print run goes well٫ I&rsquo;ll figure out how to scale the process up beyond &ldquo;let&rsquo;s ship 400 zines from my house&rdquo;. I&rsquo;m not sure how that will work yet٫ but we&rsquo;ll figure it out!</p>

<style>
.button {
position: relative;
display: inline-block;
padding: .5rem .75rem;
margin-bottom: 1rem;
border: 1px solid black;
border-radius: .5rem;
color: black;
background: #fcd947;
text-shadow: 0px 1px 1px rgba(255٫ 255٫ 255٫ .75);
box-shadow: 2px 2px #e8ab72٫ 6px 6px black;
transition: all 100ms ease;
line-height: 1.2em;
font-size: 0.9em;
font-weight: 700;
}
.button:active {
    transform: translateX(4px) translateY(4px);
    box-shadow: 0px 0px #e8ab72٫ 0px 0px black;
}
</style>

<h3 id="here-s-the-link-again">here&rsquo;s the link again!</h3>

<p>Here&rsquo;s the link to order a print copy٫ again! If you just want the PDF٫ you can get it here: <a href="https://wizardzines.com/zines/manager/">Help! I have a Manager! PDF</a>.</p>

<div align="center">                                                                                                                       
  <a class="button" href="https://gumroad.com/l/manager-zine-print">Get it for $16</a>

</div>
'),('https://jvns.ca/blog/2020/08/18/implementing--focus-and-reply--for-fastmail/', 'Implementing "focus and reply" for Fastmail with JMAP', '1597743740000',  6, '

<p>Last month I switched my email to Fastmail. One fun thing about Fastmail is
that they built a new protocol called <a href="https://jmap.io/">JMAP</a> which is much
easier to use than IMAP. So over the last couple of days I built a fun tiny
email feature for myself to use with JMAP.</p>

<p>The point of this post is mostly to give a simple end-to-end example of how to
use the JMAP API becuase I couldn&rsquo;t find a lot of  examples when I was figuring
it out. <a href="https://github.com/jvns/focus-reply-fastmail">Here&rsquo;s the github repo</a> and a <a href="https://gist.github.com/jvns/738eda48bff8c4dd2a5e349b8df7c7a8">gist which shows how to authenticate &amp; make your first request</a>.</p>

<h3 id="cool-feature-from-hey-focus-reply">cool feature from Hey: focus &amp; reply</h3>

<p>I tried the <a href="https://hey.com">https://hey.com</a> email service for a little bit when it came out. It wasn&rsquo;t for me٫ but I
liked their &ldquo;focus and reply&rdquo; feature. Here&rsquo;s a screenshot of what it looks like (from a video on their <a href="https://hey.com/features/reply-mode/">marketing site page for the feature</a>)</p>

<p><img src="https://jvns.ca/images/original-feature-screenshot.png"></p>

<p>Basically it makes replying to a lot of emails in a batch a little simpler. So
I thought &ndash; can I use JMAP to implement this focus &amp; reply feature from Hey?</p>

<h3 id="step-0-make-the-feature-simpler">step 0: make the feature simpler</h3>

<p>I was a bit too scared to actually send email to start (read-only is safe!)٫ so
I decided to start by just making a UI that would show me all the emails I
needed to reply to and give me a text box to fill in the replies. Then I could
copy and paste the replies into my webmail client to send them. This is a
little janky٫ but I don&rsquo;t mind it for now.</p>

<p>Here&rsquo;s an example of what that looks like:</p>

<p><img src="https://jvns.ca/images/focus-reply.png"></p>

<h3 id="step-0-5-have-a-reply-later-folder-in-fastmail">step 0.5: have a &ldquo;Reply Later&rdquo; folder in Fastmail</h3>

<p>I already had a folder named &ldquo;Reply Later&rdquo; in Fastmail٫ where I manually filed away
emails that I needed to reply to but hadn&rsquo;t gotten to yet. So I had a data
source to use! Hooray. Time to start coding.</p>

<h3 id="step-1-get-started-with-jmap">step 1: get started with JMAP</h3>

<p>I couldn&rsquo;t find a quickstart guide for using JMAP with Fastmail and I was confused about how to do it for quite a while٫ so
part of my goal with this blog post is to give an example of how to get started. I put all the code you need to make your first API request
in a gist:
<a href="https://gist.github.com/jvns/738eda48bff8c4dd2a5e349b8df7c7a8">fastmail-jmap-quickstart.js</a></p>

<p>You can authenticate all your requests with HTTP Basic authentication with
your username and a Fastmail app password.</p>

<p>Here&rsquo;s the basics of how it works.</p>

<ol>
<li>Make a GET request to <a href="https://jmap.fastmail.com/.well-known/jmap">https://jmap.fastmail.com/.well-known/jmap</a>. This gives
you a &ldquo;session&rdquo; in response٫ gives you your account ID. You need
this account ID for all the other API calls. I found this a bit surprising
because I usually expect things in <code>.well-known</code> to be static files٫ but
this one is a dynamic endpoint that you authenticate to with HTTP Basic
authentication. (using your email / app password)</li>
<li>Use that account ID to make requests to the JMAP API at <a href="https://jmap.fastmail.com/api/">https://jmap.fastmail.com/api/</a></li>
</ol>

<p>One thing that threw me off about JMAP at first is that you have to wrap all your API requsts with</p>

<pre><code>{
    &quot;using&quot;: [ &quot;urn:ietf:params:jmap:core&quot;٫ &quot;urn:ietf:params:jmap:mail&quot; ]٫
    &quot;methodCalls&quot;: YOUR_REQUEST_HERE
}
</code></pre>

<p>For example٫ this is a request to get a list of all your mailboxes (folders). I think <code>&quot;0&quot;</code> is the ID of the request:</p>

<pre><code>{
    &quot;using&quot;: [ &quot;urn:ietf:params:jmap:core&quot;٫ &quot;urn:ietf:params:jmap:mail&quot; ]٫
    &quot;methodCalls&quot;: [[ &quot;Mailbox/get&quot;٫ {
        &quot;accountId&quot;: accountId٫
        &quot;ids&quot;: null
    }٫ &quot;0&quot; ]]
}
</code></pre>

<p>The API wasn&rsquo;t that intuitive at first٫ but I was able to figure how to do what
I wanted to by reading the spec at <a href="https://jmap.io">https://jmap.io</a>.</p>

<h3 id="step-2-get-all-my-emails">step 2: get all my emails</h3>

<p>Here&rsquo;s <a href="https://github.com/jvns/focus-reply-fastmail/blob/726f9ae90a0cab746115a1f645596cd26e7dcafc/focus-and-reply.js#L38-L74">the query I used to get my emails from JMAP</a>.
I basically just copied this from the examples in the JMAP documentation٫ but I
think it&rsquo;s interesting that it&rsquo;s not just 1 query٫ it&rsquo;s actually 5 different
chained queries that build on top of each other. For example٫ you have:</p>

<pre><code>[ &quot;Email/query&quot;٫ {
    &quot;accountId&quot;: accountId٫
        // todo: actually do the reply later thing
        &quot;filter&quot;: { &quot;inMailbox&quot;: mailbox_id }٫
        &quot;sort&quot;: [{ &quot;property&quot;: &quot;receivedAt&quot;٫ &quot;isAscending&quot;: false }]٫
        &quot;collapseThreads&quot;: true٫
        &quot;position&quot;: 0٫
        &quot;limit&quot;: 20٫
        &quot;calculateTotal&quot;: true
}٫ &quot;t0&quot; ]٫
[ &quot;Email/get&quot;٫ {
    &quot;accountId&quot;: accountId٫
    &quot;#ids&quot;: {
        &quot;resultOf&quot;: &quot;t0&quot;٫
        &quot;name&quot;: &quot;Email/query&quot;٫
        &quot;path&quot;: &quot;/ids&quot;
    }٫
    &quot;properties&quot;: [ &quot;threadId&quot; ]
}٫ &quot;t1&quot; ]٫
...
</code></pre>

<p>This queries for a list of all the email IDs in a specific mailbox (my &ldquo;reply
later&rdquo; mailbox)٫ calls it <code>t0</code>٫ and then uses the results of <code>t0</code> to request
all of those emails.</p>

<p>One of the big ideas in JMAP seems to be this chaining &ndash; it really reduces
latency if you can do all your work in a single request.</p>

<h3 id="step-3-render-the-emails">step 3: render the emails!</h3>

<p>Once I had all the emails٫ rendering them was pretty easy &ndash; I just used vue.js
+ Tailwind. The whole thing came out to <a href="https://github.com/jvns/focus-reply-fastmail/blob/726f9ae90a0cab746115a1f645596cd26e7dcafc/focus-and-reply.js">170 lines of not-particularly-well-organized Javascript</a>.</p>

<h3 id="the-results">the results</h3>

<p>It works! It&rsquo;s already helped me reply to some emails.  The github repo is <a href="https://github.com/jvns/focus-reply-fastmail">https://github.com/jvns/focus-reply-fastmail</a>.</p>

<p>there are at least 2 problems with this code (and probably more):</p>

<ol>
<li>it&rsquo;s storing passwords in local storage٫ which I think is not a good
security practice.</li>
<li>it had some XSS vulnerabilities٫ which I think I&rsquo;ve finally fixed by putting
the plaintext email in a <code>&lt;pre&gt;</code> (so that newlines come through) and
escaping any HTML entities in there. (<code>&lt;pre&gt;{{email}}&lt;/pre&gt;</code>٫ in Vue)</li>
</ol>

<h3 id="fastmail-seems-to-use-jmap-in-a-different-way-than-this">fastmail seems to use JMAP in a different way than this</h3>

<p>I got curious so I used the Network tab to look at how Fastmail&rsquo;s web interfaces uses jmap.</p>

<ol>
<li>Fastmail&rsquo;s webmail interface doesn&rsquo;t seem to use <a href="https://jmap.fastmail.com/">https://jmap.fastmail.com/</a> &ndash; instead it uses <a href="https://www.fastmail.com/jmap/api">https://www.fastmail.com/jmap/api</a>. Maybe it&rsquo;s just a proxy they use so that the requests are being made to the same origin? Unclear.</li>
<li>It also authenticates in a different way٫ using <code>Authorization: Bearer</code>. It
seems like this might be a better way to authenticate٫ but I haven&rsquo;t found
any information about how to get a <code>Bearer</code> authentication like this to use
instead of using an app password.</li>
<li>The requests it sends are sometimes compressed with deflate for some reason
(instead of gzip)٫ which I guess is fine but it means it&rsquo;s impossible to
look at them in dev tools because Firefox doesn&rsquo;t understand deflate. Weird!</li>
</ol>

<h3 id="some-links-to-resources">some links to resources</h3>

<ul>
<li><a href="https://jmap.topicbox.com/groups/fastmail-dev-beta/T83594f41ca76f56c/jmap-crash-course">JMAP crash course</a> (which I only found after I&rsquo;d already finished doing this but looks very useful!)</li>
<li>Fastmail has <a href="https://github.com/fastmail/JMAP-Samples">some JMAP sample code on github</a></li>
<li><a href="https://jmap.io/">https://jmap.io/</a> for the specs</li>
<li><a href="https://github.com/cure53/DOMPurify">https://github.com/cure53/DOMPurify</a> is an HTML sanitizer which looks useful for preventing XSS</li>
</ul>

<h3 id="this-seems-like-a-fun-way-to-do-email-experiments">this seems like a fun way to do email experiments!</h3>

<p>I think the idea that anyone can just use JMAP to make fun email UI experiments
without dealing with the Hard Parts of email is really fun!</p>

<p>And it&rsquo;s really cool that I could get this to work 100% as a frontend app٫
without any server code at all! All the email data is accessible via JMAP٫ so
it seems extremely possible to just do everything with JMAP requests from the
client.</p>
'),('https://jvns.ca/blog/2020/08/12/some-possible-future-zines/', 'Some possible future zines', '1597237620000',  6, '

<p>Hello! I&rsquo;ve been thinking about what zines I want to write in the future a bit.
Usually I don&rsquo;t have any plans for what I&rsquo;m going to write next٫ but having no
plan at all feels like it might be getting a bit old.</p>

<p>So this post is mostly a way for me to try to organize my thoughts about why I
choose certain topics and what I might want to write in the future.</p>

<h3 id="the-criteria">the criteria</h3>

<p>I&rsquo;m interested in writing about things that are</p>

<ul>
<li>fundamental in some way</li>
<li>very useful to know in your programming job</li>
<li>stable (the basics of SQL / git / CSS / HTTP / Linux aren&rsquo;t going to change any time in the next 5-10 years!)</li>
<li>possible to learn the basics of quickly</li>
</ul>

<p>There are a LOT of topics that fit these criteria. As I was thinking about
topics٫ I realized that there are lots of topics (like object oriented
programming principles) that I think could in theory be pretty valuable but
that just didn&rsquo;t speak to me. What&rsquo;s up with that?</p>

<h3 id="i-only-write-about-topics-that-i-care-about">I only write about topics that I care about</h3>

<p>I think a thing that I was missing was &ndash; I only write about topics that
I really think are exciting and fun and important and want to share with people. Some topics
I have kind of a weird and complicated love for٫ like
<a href="https://wizardzines.com/zines/containers">containers</a> (why are they so weird?!).</p>

<p>And right now I&rsquo;m writing about CSS٫ which I&rsquo;m only learning how to love pretty
recently.</p>

<p>I think it&rsquo;s often important for me to write about topics which I now love
but in the past did not love. For example٫ it took me a very long time to
understand how to use <a href="https://wizardzines.com/zines/tcpdump">tcpdump</a>٫ and
once I got it I felt like I had to tell everyone HELLO I FIGURED IT OUT TCPDUMP
IS ACTUALLY AWESOME AND NOT THAT HARD.</p>

<p>It feels a lot less interesting to write about topics where it was immediately
obvious to me why they were great or which were easy for me to learn.</p>

<h3 id="zines-that-i-might-write">zines that I might write</h3>

<ul>
<li>shell scripting</li>
<li>debugging (I have 70% of a debugging zine!)</li>
<li>testing</li>
<li>more linux internals</li>
<li>C basics</li>
<li>gdb</li>
<li>binary٫ character encodings٫ binary formats</li>
<li>how git works</li>
<li>TLS certificates٫ CSRs٫ CAs٫ etc.</li>
<li>profiling</li>
<li>data structures: graph theory / binary trees / hashmaps</li>
<li>the Python standard library and/or fun Python basics</li>
<li>pandas and/or numpy (though I think maybe the <a href="https://github.com/jvns/pandas-cookbook">pandas cookbook</a> is a better medium for that than a zine)</li>
<li>machine learning (maybe just logistic regression?)</li>
</ul>

<p>and a few that I think might be too small or too big for a zine:</p>

<ul>
<li>Rust (too big!)</li>
<li>DNS (maybe a mini zine one day? I really love DNS &amp; dig!)</li>
</ul>

<h3 id="zines-that-i-don-t-think-i-can-write">zines that I don&rsquo;t think I can write</h3>

<p>Here are some topics for zines that I think are &ldquo;fundamental&rdquo; in the same way
and that I think could be really cool. I don&rsquo;t think that I could write these
today٫ either because I don&rsquo;t know enough about the topic yet or because I
don&rsquo;t really feel enough love for it yet.</p>

<p>As with most things٫ the only way I&rsquo;ll probably learn more about these is if I
end up using them more.</p>

<ul>
<li>web accessibility</li>
<li>postgres (transactions etc?)</li>
<li>x86 assembly</li>
<li>hashing (bcrypt٫ sha-1٫ md5٫ etc)</li>
<li>encryption</li>
<li>JVM internals</li>
<li>code review</li>
<li>kubernetes</li>
<li>websockets (is there enough to write a whole zine about websockets? I don&rsquo;t know!)</li>
<li>functional programming / object oriented programming</li>
<li>&lsquo;big data&rsquo; topics (hadoop٫ data warehouses٫ etc)</li>
<li>paxos or raft</li>
<li>how search works (like elasticsearch)</li>
<li>how databases work</li>
</ul>

<h3 id="that-s-all">that&rsquo;s all!</h3>

<p>I&rsquo;m still not sure (even after doing this for years!) why it&rsquo;s so hard for me
to tell what topics will make for a good zine that I can write. Maybe one day I
will figure it out!</p>
'),('https://jvns.ca/blog/2020/08/10/some-more-css-comics/', 'Some more CSS comics', '1597052576000',  6, '

<p>I&rsquo;ve been continuing to write pages about CSS! Here are 6 more.</p>

<p>Two of them are about how to think about CSS in general (&ldquo;CSS isn&rsquo;t easy&rdquo; and
&ldquo;backwards compatibility&rdquo;)٫ which is something I&rsquo;m still trying to wrap my head
around.</p>

<h3 id="handling-browser-bugs-is-normal">handling browser bugs is normal?</h3>

<p>The fact that finding workarounds for browser bugs is kind of a normal part of
writing CSS really surprised me &ndash; there&rsquo;s this great repo called
<a href="https://github.com/philipwalton/flexbugs">flexbugs</a> which catalogs bugs in
browser implementations of flexbox. A lot of the bugs are in IE which means
(depending on your goals) that you can just ignore them٫ but not all! A bunch
of the flexbugs are in Chrome or Safari or Firefox.</p>

<p>For example٫ I ran into <a href="https://github.com/philipwalton/flexbugs#flexbug-9">flexbug #9</a> a few days ago٫ which is
that in Safari a <code>&lt;summary&gt;</code> element can&rsquo;t be a flexbox٫ so instead you need to
put an extra div inside the <code>&lt;summary&gt;</code> to be the flex element.</p>

<p>In the past I would have reacted to this in a more grumpy way (WHY?
NOOOOO? WHAT IS HAPPENING?!?! CSS?!?!?!). But this time I noticed that my site
looked weird in Safari on my iPad٫ figured out after 30 minutes or so that it
was a Safari bug٫ implemented a workaround٫ and it actually wasn&rsquo;t that big of
a deal!</p>

<p>I think this mindset of &ldquo;oh٫ there&rsquo;s a browser bug٫ oh well٫ I guess that
happens sometimes!&rdquo; is a lot healthier and more likely to result in success
than getting mad about it.</p>

<h3 id="there-are-a-lot-of-ways-css-can-go-wrong">there are a lot of ways CSS can go wrong</h3>

<p>I think there are at least 3 different ways your CSS can be buggy:</p>

<ol>
<li>that element doesn&rsquo;t have the styles applied that it should (for example
it&rsquo;s supposed to be <code>background; blue</code> but it&rsquo;s <code>background: red</code> instead)</li>
<li>the element has the &ldquo;right&rdquo; styles applied٫ but those styles do something
confusing / unexpected to me because of something I misunderstood about the
CSS spec</li>
<li>the element has the &ldquo;right&rdquo; styles applied and those styles do the right
thing according to the spec٫ but the browser has a bug and isn&rsquo;t
implementing the spec correctly</li>
</ol>

<p>Anyway٫ enough CSS musings٫ here are the comics :)</p>

<h3 id="css-isn-t-easy">css isn&rsquo;t easy</h3>

<p><a href="https://wizardzines.com/comics/css-isnt-easy"><img src="https://wizardzines.com/comics/css-isnt-easy/css-isnt-easy.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/css-isnt-easy">https://wizardzines.com/comics/css-isnt-easy</a></small></p>

<h3 id="backwards-compatibility">backwards compatibility</h3>

<p><a href="https://wizardzines.com/comics/backwards-compatibility"><img src="https://wizardzines.com/comics/backwards-compatibility/backwards-compatibility.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/backwards-compatibility">https://wizardzines.com/comics/backwards-compatibility</a></small></p>

<h3 id="css-specificity">CSS specificity</h3>

<p><a href="https://wizardzines.com/comics/css-specificity"><img src="https://wizardzines.com/comics/css-specificity/css-specificity.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/css-specificity">https://wizardzines.com/comics/css-specificity</a></small></p>

<h3 id="centering-in-css">centering in CSS</h3>

<p><a href="https://wizardzines.com/comics/css-centering"><img src="https://wizardzines.com/comics/css-centering/css-centering.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/css-centering">https://wizardzines.com/comics/css-centering</a></small></p>

<h3 id="padding-syntax">padding syntax</h3>

<p><a href="https://wizardzines.com/comics/padding-margin"><img src="https://wizardzines.com/comics/padding-margin/padding-margin.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/padding-margin">https://wizardzines.com/comics/padding-margin</a></small></p>

<h3 id="flexbox-basics">flexbox basics</h3>

<p><a href="https://wizardzines.com/comics/flexbox-basics"><img src="https://wizardzines.com/comics/flexbox-basics/flexbox-basics.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/flexbox-basics">https://wizardzines.com/comics/flexbox-basics</a></small></p>
'),('https://jvns.ca/blog/2020/08/08/handwritten-font/', 'An attempt to make a font look more handwritten', '1596874515000',  6, '

<p>I&rsquo;m actually not super happy with the results of this experiment٫ but I wanted
to share it anyway because it was very easy and fun to play with fonts. And
somebody asked me how to do it and I told her I&rsquo;d write a blog post about it :)</p>

<h3 id="background-the-original-handwritten-font">background: the original handwritten font</h3>

<p>Some background: I have a font of my handwriting that I&rsquo;ve been use in my zines
for a couple of years. I made it using a delightful app called
<a href="https://2ttf.com/">iFontMaker</a>. They pitch
themselves on their website as &ldquo;You can create your handmade typeface in less
than 5 minutes just with your fingers&rdquo;. In my experience the &lsquo;5 minutes&rdquo; part
is pretty accurate &ndash; I might have spent more like 15 minutes.  I&rsquo;m skeptical
of the &ldquo;just your fingers&rdquo; claim &ndash; I used an Apple Pencil٫ which has much
better accuracy. But it is extremely easy to make a TTF font of your
handwriting with the app and if you happen to already have an Apple Pencil and
iPad I think it&rsquo;s a fun way to spend $7.99.</p>

<p>Here&rsquo;s what my font looks like. The &ldquo;CONNECT&rdquo; text on the left is my actual
handwriting٫ and the paragraph on the right is the font. There are actually 2
fonts &ndash; there&rsquo;s a regular font and a handwritten &ldquo;monospace&rdquo; font. (which
actually isn&rsquo;t monospace in practice٫ I haven&rsquo;t figured out how to make an
actual monospace font in iFontMaker)</p>

<div align="center">
<img src="https://jvns.ca/images/font-sample-connect.png">
</div>

<h3 id="the-goal-have-more-character-variation-in-the-font">the goal: have more character variation in the font</h3>

<p>In the screenshot above٫ it&rsquo;s pretty obvious that it&rsquo;s a font and not actual
handwriting. It&rsquo;s easiest to see this when you have two of the same letter next
to each other٫ like in &ldquo;HTTP&rsquo;.</p>

<p>So I thought it might be fun to use some OpenType features to somehow introduce
a little more variation into this font٫ like maybe the two Ts could be
different. I didn&rsquo;t know how to do this though!</p>

<h3 id="idea-from-tristan-hume-use-opentype">idea from Tristan Hume: use OpenType!</h3>

<p>Then I was at !!Con 2020 in May (all the <a href="http://bangbangcon.com/recordings.html">talk recordings are
here!</a>) and saw this talk by Tristan
Hume about using OpenType to place commas in big numbers by using a special font.
His talk and blog post are both great so here are a bunch of links &ndash; the live
demo is maybe the fastest way to see his results.</p>

<ul>
<li>a live demo: <a href="https://thume.ca/numderline/">Numderline Test</a></li>
<li>the blog post: <a href="https://blog.janestreet.com/commas-in-big-numbers-everywhere/">Commas in big numbers everywhere: An OpenType adventure</a></li>
<li>the talk: <a href="https://www.youtube.com/watch?v=Biqm9ndNyC8">!!Con 2020 - Using font shaping to put commas in big numbers EVERYWHERE!! by Tristan Hume</a></li>
<li>the github repo: <a href="https://github.com/trishume/numderline/blob/master/patcher.py">https://github.com/trishume/numderline/blob/master/patcher.py</a></li>
</ul>

<h3 id="the-main-idea-opentype-lets-you-replace-characters-based-on-context">the main idea: OpenType lets you replace characters based on context</h3>

<p>I started out being extremely confused about what OpenType even is. I still don&rsquo;t know much٫ but I
learned that you can write extremely simple OpenType rules to change how a
font looks٫ and you don&rsquo;t even have to really understand anything about fonts.</p>

<p>Here&rsquo;s an example rule:</p>

<pre><code>sub a" b by other_a;
</code></pre>

<p>What <code>sub a" b by other_a;</code> means is: If an <code>a</code> glyph is before a <code>b</code>٫ then replace the <code>a</code> with the glyph <code>other_a</code>.</p>

<p>So this means I can make <code>ab</code> appear different from <code>ac</code> in the font. It&rsquo;s not
random the way handwriting is٫ but it does introduce a little bit of variation.</p>

<h3 id="opentype-reference-documentation-awesome">OpenType reference documentation: awesome</h3>

<p>The best documentation I found for OpenType was this <a href="https://adobe-type-tools.github.io/afdko/OpenTypeFeatureFileSpecification.html">OpenType™ Feature File Specification</a> reference. There are a lot of examples of cool things you can do in there٫ like replace &ldquo;ffi&rdquo; with a ligature.</p>

<h3 id="how-to-apply-these-rules-fonttools">how to apply these rules: <code>fonttools</code></h3>

<p>Adding new OpenType rules to a font is extremely easy. There&rsquo;s a Python library
called <code>fonttools</code>٫ and these 5 lines of code will apply a list of OpenType
rules (in <code>rules.fea</code>) to the font file <code>input.ttf</code>.</p>

<pre><code>from fontTools.ttLib import TTFont
from fontTools.feaLib.builder import addOpenTypeFeatures

ft_font = TTFont("input.ttf")
addOpenTypeFeatures(ft_font٫ "rules.fea"٫ tables=["GSUB"])
ft_font.save("output.ttf")
</code></pre>

<p><code>fontTools</code> also provides a couple of command line tools called <code>ttx</code> and
<code>fonttools</code>. <code>ttx</code> converts a TTF font into an XML file٫ which was useful to me
because I wanted to rename some glyphs in my font but did not understand
anything about fonts. So I just converted my font into an XML file٫ used <code>sed</code>
to rename the glyphs٫ and then used <code>ttx</code> again to convert the XML file back into a <code>ttf</code>.</p>

<p><code>fonttools merge</code> let me merge my 3 handwriting fonts into 1 so that I had all the glyphs I needed in 1 file.</p>

<h3 id="the-code">the code</h3>

<p>I put my extremely hacky code for doing this in a repository called
<a href="https://github.com/jvns/font-mixer/">font-mixer</a>. It&rsquo;s like 33 lines of code and I think it&rsquo;s pretty straightforward. (it&rsquo;s all in <code>run.sh</code> and <code>combine.py</code>)</p>

<h3 id="the-results">the results</h3>

<p>Here&rsquo;s a small sample the old font and the new font. I don&rsquo;t think the new font
&ldquo;feels&rdquo; that much more like handwriting &ndash; there&rsquo;s a little more variation٫ but
it still doesn&rsquo;t compare to actual handwritten text (at the bottom).</p>

<p>It feels a little uncanny valley to me٫ like it&rsquo;s obviously still a
font but it&rsquo;s pretending to be something else.</p>

<p><img src="https://jvns.ca/images/font-mixer-comparison.png"></p>

<p>And here&rsquo;s a sample of the same text actually written by hand:</p>

<p><img src="https://jvns.ca/images/handwriting-sample.jpeg" width="65%"></p>

<p>It&rsquo;s possible that the results would be better if I was more careful about how
I made the 2 other handwriting fonts I mixed the original font with.</p>

<h3 id="it-s-cool-that-it-s-so-easy-to-add-opentype-rules">it&rsquo;s cool that it&rsquo;s so easy to add opentype rules!</h3>

<p>Mostly what was delightful to me here is that it&rsquo;s so easy to add OpenType
rules to change how fonts work٫ like you can pretty easily make a font where
the word &ldquo;the&rdquo; is always replaced with &ldquo;teh&rdquo; (typos all the time!).</p>

<p>I still don&rsquo;t know how to make a more realistic handwriting font though :).
I&rsquo;m still using the old one (without the extra variations) and I&rsquo;m pretty happy with it.</p>
'),('https://jvns.ca/blog/2020/07/25/some-comics-about-css/', 'Some CSS comics', '1595671745000',  6, '

<p>Hello! I&rsquo;ve been writing some comics about CSS this past week٫ and I thought as
an experiment I&rsquo;d post them to my blog instead of only putting them on Twitter.</p>

<p>I&rsquo;m going to ramble about CSS at the beginning a bit but you can skip to the
end if you just want to read the comics :)</p>

<h3 id="why-write-about-css">why write about CSS?</h3>

<p>I&rsquo;ve been writing a tiny bit more CSS recently٫ and I&rsquo;ve decided to <a href="https://jvns.ca/blog/debugging-attitude-matters/">actually
take some time to learn CSS</a>
instead of just flailing around and deciding &ldquo;oh no٫ this is impossible&rdquo;.</p>

<p>CSS feels a little like systems programming / Linux to me &ndash; there are a lot of
counterintuitive facts that you need to learn to be effective with it٫ but I
think once you learn those facts it gets a lot easier.</p>

<p>So I&rsquo;m writing down some facts that I found counterintuitive when learning CSS٫
like the fact that <code>position: absolute</code> isn&rsquo;t absolute!</p>

<h3 id="why-try-to-read-the-specs">why try to read the specs?</h3>

<p>I&rsquo;ve been having a lot of fun reading
through the <a href="https://www.w3.org/TR/CSS2/css2.pdf">CSS2 spec</a> and finding out
that some things about CSS that I was intimidated by (like selector specificity) aren&rsquo;t as complicated as I thought.</p>

<p>I think reading (parts of) the CSS specs is fun because I&rsquo;m so used to
learning CSS by reading a lot of websites which sometimes have conflicting
information. (<a href="https://developer.mozilla.org">MDN</a> is an incredible resource
but I don&rsquo;t think it&rsquo;s 100% always correct either.)</p>

<p>So it&rsquo;s fun to read a more authoritative source! Of course٫ it&rsquo;s not always
true that the CSS specs correspond to reality &ndash; browser implementations of the
specs are inconsistent.</p>

<p>But expecially for parts of CSS that are older &amp; better-established (like the
basics of how <code>position: absolute</code> works) I like reading the specs.</p>

<h3 id="how-are-the-css-specs-organized">how are the CSS specs organized?</h3>

<p>CSS used to be defined by a single specification (CSS2)٫ but as of CSS 3 each
part of CSS has its own specification. For example٫ there&rsquo;s a CSS 3 specification
<a href="https://www.w3.org/TR/css-color-3/">for colours</a>.</p>

<p>Here are the links I&rsquo;ve been using:</p>

<ul>
<li>there&rsquo;s a PDF of the <a href="https://www.w3.org/TR/CSS2/css2.pdf">CSS2 spec here</a></li>
<li><a href="https://www.w3.org/TR/CSS/">CSS Snapshot 2018</a> lists all the CSS specifications as of 2018٫ which is where I&rsquo;ve been looking for links to the CSS 3 specifications</li>
<li><a href="https://www.w3.org/Style/CSS/read.en.html">Understanding the CSS Specifications</a> is an explanation of how to approach reading the CSS specs. For example٫ it recommends reading <a href="https://www.w3.org/TR/css-sizing-3/">CSS sizing</a> which I haven&rsquo;t tried reading yet.</li>
</ul>

<p>I&rsquo;ve been kind of alternating between the CSS 2 spec and the CSS 3 specs &ndash;
because the CSS 2 spec is smaller٫ I find it easier to digest and understand
the big picture of how things are supposed to work without getting lost in a
lot of details.</p>

<h3 id="a-few-comics">a few comics</h3>

<p>Okay٫ here are the comics! As always when I start working on a set of comics /
a potential zine٫ there&rsquo;s no specific order or organization.</p>

<h3 id="the-box-model">the box model</h3>

<p><a href="https://wizardzines.com/comics/box-model"><img src="https://wizardzines.com/comics/box-model/box-model.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/box-model">https://wizardzines.com/comics/box-model</a></small></p>

<h3 id="css-units">CSS units</h3>

<p><a href="https://wizardzines.com/comics/units"><img src="https://wizardzines.com/comics/units/units.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/units">https://wizardzines.com/comics/units</a></small></p>

<p>Reference material: I found <a href="https://www.w3.org/TR/css-values-3/#lengths">this section on lengths</a> from &ldquo;CSS Values and Units Module Level 3&rdquo; pretty straightforward.</p>

<h3 id="selectors">selectors</h3>

<p><a href="https://wizardzines.com/comics/selectors"><img src="https://wizardzines.com/comics/selectors/selectors.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/selectors">https://wizardzines.com/comics/selectors</a></small></p>

<p>Reference material: section <a href="https://www.w3.org/TR/CSS2/cascade.html#cascade">6.4.1 to 6.4.3</a> from the CSS 2 spec.</p>

<h3 id="position-absolute"><code>position: absolute</code></h3>

<p><a href="https://wizardzines.com/comics/position-absolute"><img src="https://wizardzines.com/comics/position-absolute/position-absolute.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/position-absolute">https://wizardzines.com/comics/position-absolute</a></small></p>

<h3 id="inline-vs-block">inline vs block</h3>

<p><a href="https://wizardzines.com/comics/inline-vs-block"><img src="https://wizardzines.com/comics/inline-vs-block/inline-vs-block.png"></a>
<small>Permalink: <a href="https://wizardzines.com/comics/inline-vs-block">https://wizardzines.com/comics/inline-vs-block</a></small></p>

<p>One piece of errata for this one: you actually can set the width on an inline
element if it&rsquo;s a &ldquo;replaced&rdquo; element</p>
'),('https://jvns.ca/blog/2020/07/14/when-your-coworker-does-great-work-tell-their-manager/', 'When your coworker does great work٫ tell their manager', '1594737222000',  6, '

<p>I’ve been thinking recently about anti-racism and what it looks like to support
colleagues from underrepresented groups at work. The other day someone in a
Slack group made an offhand comment that they’d sent a message to an engineer’s
manager to say that the engineer was doing exceptional work.</p>

<p>I think telling someone&rsquo;s manager they&rsquo;re doing great work is a pretty common
practice and it can be really helpful٫ but it&rsquo;s easy to forget to do and I wish
someone had suggested it to me earlier. So let&rsquo;s talk about it!</p>

<p>I <a href="https://twitter.com/b0rk/status/1280918150289281025">tweeted about this to ask how people approach it</a> and as usual I got a ton of great replies that I’m going to summarize here.</p>

<p>We’re going to talk about what to say٫ when to do this٫ and why you should ask first.</p>

<h3 id="ask-if-it-s-ok-first">ask if it’s ok first</h3>

<p>One thing that at least 6 different people brought up was the importance of
asking first. It might not be obvious why this is important at first — you’re
saying something positive! What’s the problem?</p>

<p>So here are some potential reasons saying something positive to someone’s
manager could backfire:</p>

<ol>
<li>Giving someone a compliment that’s not in line with their current goals. For
example٫ if your coworker is trying to focus on becoming a technical expert
in their domain and you’re impressed with their project management skills٫
they might not want their project management highlighted (or vice versa!).</li>
<li>Giving someone the wrong “level” of compliment. For example٫ if they’re a
very senior engineer and you say something like “PERSON did
SIMPLE_ROUTINE_TASK really well!” — that doesn’t reflect well on them and
feels condescending. This can happen if you don’t know the person’s position
or don’t understand the expectations for their role.</li>
<li>If your coworker was supposed to be focusing on a specific project٫ and
you’re complimenting them for helping with something totally unrelated٫
their manager might think that they’re not focusing on their “real” work.
One person mentioned that they got reprimanded by their manager for getting
a spot peer bonus for helping someone on another team.</li>
<li>Some people have terrible managers (for example٫ maybe the manager will feel
threatened by your coworker excelling)</li>
<li>Some people just don’t like being called out in that way٫ and are happy with
the level of recognition they’re getting!</li>
</ol>

<p>Overall: a lot of people (for very good reasons!) want to have control over the
kind of feedback their manager hears about them.</p>

<p>So just ask first! (“hey٫ I was really impressed with your work on X project
and wanted to send this note to $MANAGER to explain how important your work
because I know she wasn’t that involved in X project and might not have seen
everything you did٫ is that ok with you?”)</p>

<h3 id="when-it-s-important-to-highlight-work-that-isn-t-being-recognized">when it’s important: to highlight work that isn’t being recognized</h3>

<p>Okay٫ now let’s talk about when this is important to do. I think this is pretty
simple &ndash; managers don’t always see the work their reports are doing٫ and if
someone is doing really amazing work that their manager isn’t seeing٫ they
won’t get promoted as quickly. So it’s helpful to tell managers about work that
they may not be seeing.</p>

<p>Here are some examples of types of important work that might be underrecognized:</p>

<ul>
<li>work by someone from another department (maybe their manager doesn’t
understand how helpful their contribution was to the company because they
don’t work with your team that much٫ but your coworker’s work made a huge
difference!)</li>
<li>work that happened in a private channel (for example if someone spent hours
helping you with something 1:1 and it really made a big difference to the
success of your project)</li>
<li>work preventing problems٫ which often isn’t as visible as firefighting work</li>
<li>work by people from underestimated groups (maybe your coworker’s work isn’t
being recognized as much as it should be because of racism/sexism/etc!)</li>
<li>documentation/code review/other kinds of work that aren’t always as visible
as programming</li>
<li>work by remotes (if remote work is less visible at your company)</li>
<li>work by someone in a role that’s typically underrecognized (someone mentioned
support as an example)</li>
</ul>

<p>Also٫ everyone agreed that it’s always great to highlight the contributions of
more junior coworkers when they’re doing well.</p>

<h3 id="why-it-matters-it-helps-managers-make-a-case-for-promotion">why it matters: it helps managers make a case for promotion</h3>

<p>For someone to get promoted٫ they need evidence that they’ve been doing
valuable work٫ and managers don’t always have the time to put together all that
evidence. So it’s important to be proactive!</p>

<p>You can work on this for yourself by writing a <a href="https://jvns.ca/blog/brag-documents/">brag
document</a>٫ but having statements from
coworkers explaining how great your work really helps build credibility.</p>

<p>So providing these statements for your coworkers can help them get recognized
in a timely way for the great work they did (instead of getting promoted a year
later or something). It’s extra helpful to do this if you know the person is up
for promotion.</p>

<h3 id="how-to-do-it-be-specific-explain-the-impact-of-their-work">how to do it: be specific٫ explain the impact of their work</h3>

<p>Pretty much everyone agreed that it’s helpful to explain what specifically the
person did that was awesome (“X did an incredible job of designing this system
and we haven’t had any major operational issues with it in the 6 months since
it launched٫ which is really unusual for a project of that scale”).</p>

<h3 id="how-to-do-it-highlight-when-they-re-exceeding-expectations">how to do it: highlight when they’re exceeding expectations</h3>

<p>Because the point is to help people get promoted٫ it’s important to highlight
when people are exceeding expectations for their level٫ for example if they’re
not a senior engineer yet but they’re doing the kind of work you’d expect from
a senior engineer.</p>

<h3 id="how-to-do-it-send-the-person-the-message-too">how to do it: send the person the message too</h3>

<p>We already basically covered this in “ask the person first”٫ but especially if
I’m using a feedback system where the person might not get the feedback
immediately I like to send it to them directly as well. It’s nice for them to
hear and they can also use it later on!</p>

<h3 id="public-recognition-can-be-great-too">public recognition can be great too!</h3>

<p>A couple of folks mentioned that they like to give public recognition٫ like
mentioning how great a job someone did in a Slack channel or team meeting.</p>

<p>Two reasons public recognition can be good:</p>

<ol>
<li>It helps build credibility for your colleague</li>
<li>It lets the person you’re recognizing be part of the
conversation/reciprocate to the feedback-giver٫ especially if the work was a
collaboration.</li>
</ol>

<p>Again٫ it’s good to ask about this before doing this &ndash; some people dislike
public recognition.</p>

<h3 id="on-peer-bonuses">on peer bonuses</h3>

<p>A few people who work at Google (or other companies with peer bonuses)
mentioned that they prefer to give peer bonuses for this because it’s a more
official form of recognition.</p>

<p>Lots of people mentioned other forms of feedback systems that they use instead
of email. Use whatever form of recognition is appropriate at your company!</p>

<h3 id="anyone-can-do-this">anyone can do this</h3>

<p>What I like about this is it’s a way everyone can help their coworkers &ndash; even
if you’re really new and don’t feel that qualified to comment on how effective
someone more senior is at their job٫ you can still point out things like “this
person helped me do a project that was really out of my comfort zone!”</p>

<h3 id="maybe-expand-the-set-of-people-you-do-this-for">maybe expand the set of people you do this for!</h3>

<p>I think it&rsquo;s very common for people to promote the work of their friends in
this way. I&rsquo;ve tried to expand the set of people I do this for over time &ndash; I
think it&rsquo;s important to keep an eye out for coworkers who are really excelling
and to make sure their work is recognized.</p>

<h3 id="more-reading-on-sponsorship">more reading on sponsorship</h3>

<p>I wanted to just talk about this one specific practice of telling someone’s
manager they’re doing great work but there are a LOT of other ways you can help
lift your coworkers up. Lara Hogan’s post <a href="https://larahogan.me/blog/what-sponsorship-looks-like/">what does sponsorship look
like?</a> has a lot of
great examples.</p>

<p>Mekka Okereke has a wonderful Twitter thread about another way you can support
underrepresented folks: by being a <a href="https://twitter.com/mekkaokereke/status/1027552459873378304">“difficulty anchor”</a>. It&rsquo;s
short and definitely worth a read.</p>

<p><small>thanks to Sher Minn Chong٫ Allie Jones٫ and Kamal Marhubi for reading a draft of this</small></p>
'),('https://jvns.ca/blog/2020/07/11/scanimage--scan-from-the-command-line/', 'scanimage: scan from the command line!', '1594458355000',  6, '

<p>Here&rsquo;s another quick post about a command line tool I was delighted by.</p>

<p>Last night٫ I needed to scan some documents for some bureaucratic reasons. I&rsquo;d never used a scanner on Linux before and I was worried it would take hours to figure out. I started by using <code>gscan2pdf</code> and had trouble figuring out the user interface &ndash; I wanted to scan both sides of the page at the same time (which I knew our scanner supported) but couldn&rsquo;t get it to work.</p>

<h3 id="enter-scanimage">enter scanimage!</h3>

<p><code>scanimage</code> is a command line tool٫ in the <code>sane-utils</code> Debian package. I think all Linux scanning tools use the <code>sane</code> libraries (&ldquo;scanner access now easy&rdquo;) so my guess is that it has similar abilities to any other scanning software. I didn&rsquo;t need OCR in this case so we&rsquo;re not going to talk about OCR.</p>

<h3 id="get-your-scanner-s-name-with-scanimage-l">get your scanner&rsquo;s name with <code>scanimage -L</code></h3>

<p><code>scanimage -L</code> lists all scanning devices you have.</p>

<p>At first I couldn&rsquo;t get this to work and I was a bit frustrated but it turned out that I&rsquo;d connected the scanner to my computer٫ but not plugged it into the wall. Oops.</p>

<p>Once everything was plugged in it worked right away. Apparently our scanner is called <code>fujitsu:ScanSnap S1500:2314</code>. Hooray!</p>

<h3 id="list-options-for-your-scanner-with-help">list options for your scanner with <code>--help</code></h3>

<p>Apparently each scanner has different options (makes sense!) so I ran this command to get the options for my scanner:</p>

<pre><code>scanimage --help -d "fujitsu:ScanSnap S1500:2314" 
</code></pre>

<p>I found out that my scanner supported a <code>--source</code> option (which I could use to enable duplex scanning) and a <code>--resolution</code> option (which I changed to 150 to decrease the file sizes and make scanning faster).</p>

<h3 id="scanimage-doesn-t-output-pdfs-but-you-can-write-a-tiny-script">scanimage doesn&rsquo;t output PDFs (but you can write a tiny script)</h3>

<p>The only downside was &ndash; I wanted a PDF of my scanned document٫ and scanimage doesn&rsquo;t seem to support PDF output.</p>

<p>So I wrote this 5-line shell script to scan a bunch of PNGs into a temp directory and convert the resulting PNGs to a PDF.</p>

<pre><code>#!/bin/bash
set -e

DIR=`mktemp -d`
CUR=$PWD
cd $DIR
scanimage -b --format png  -d "fujitsu:ScanSnap S1500:2314" --source "ADF Front" --resolution 150
convert *.png $CUR/$1
</code></pre>

<p>I ran the script like this. <code>scan-single-sided output-file-to-save.pdf</code></p>

<p>You&rsquo;ll probably need a different <code>-d</code> and <code>--source</code> for your scanner.</p>

<h3 id="it-was-so-easy">it was so easy!</h3>

<p>I always expect using printers/scanners on Linux to be a nightmare and I was really surprised how <code>scanimage</code> Just Worked &ndash; I could just run my script with <code>scan-single-sided receipts.pdf</code> and it would scan a document and save it to <code>receipts.pdf</code>!.</p>
'),('https://jvns.ca/blog/2020/07/10/twitter-summary-from-2020-so-far/', 'Twitter summary from 2020 so far', '1594372060000',  6, '

<p>Hello! I post a lot of things on Twitter and it&rsquo;s basically impossible for
anyone except me to keep with them٫ so I thought I&rsquo;d write a summary of
everything I posted on Twitter in 2020 so far.</p>

<p>A lot of these things I eventually end up writing about on the blog٫ but some
of them I don&rsquo;t٫ so I figured I&rsquo;d just put everything in one place.</p>

<p>I&rsquo;ve made most of the links to non-Twitter websites.</p>

<h3 id="comics">comics</h3>

<p>Let&rsquo;s start with the comics٫ since that&rsquo;s a lot of what I write there.</p>

<p><strong>debugging</strong></p>

<p>These are from a debugging zine I&rsquo;m still trying to finish. (<a href="https://wizardzines.com/zines/bugs/">https://wizardzines.com/zines/bugs/</a>)</p>

<ul>
<li>2020-05-28: <a href="https://wizardzines.com/comics/learn-one-thing/">learn one thing at a time</a></li>
<li>2020-05-26: <a href="https://wizardzines.com/comics/share-debugging-stories/">share your debugging stories 🐛</a></li>
<li>2020-05-26: <a href="https://wizardzines.com/comics/spy-tools/">know your spy tools</a></li>
<li>2020-05-22: <a href="https://wizardzines.com/comics/investigate-bugs-together/">investigate bugs together</a></li>
<li>2020-05-21: <a href="https://wizardzines.com/comics/bugs-teach-you/">let your bugs teach you</a></li>
<li>2020-05-05: <a href="https://wizardzines.com/comics/reproduce-bug/">on reproducing your bugs</a></li>
<li>2020-05-04: <a href="https://wizardzines.com/comics/check-assumptions/">debugging tips: check your assumptions</a></li>
<li>2020-05-04: <a href="https://wizardzines.com/comics/bugs-are-normal/">writing code with bugs is normal</a></li>
<li>2020-04-27: <a href="https://wizardzines.com/comics/understand-can-fix/">if you understand a bug٫ you can fix it</a></li>
<li>2020-04-19: <a href="https://wizardzines.com/comics/take-breaks/">debugging is hard. take breaks.</a></li>
<li>2020-04-13: <a href="https://wizardzines.com/comics/attitude-matters/">when debugging٫ your attitude matters</a></li>
</ul>

<p><strong>writing tips</strong></p>

<ul>
<li>2020-05-19: <a href="https://wizardzines.com/comics/main-ideas/">how I write: highlight the main ideas</a></li>
<li>2020-05-18: <a href="https://wizardzines.com/comics/write-for-one-person/">how I write: always write for 1 person</a></li>
</ul>

<p><strong>computer science</strong></p>

<ul>
<li>2020-05-07: <a href="https://wizardzines.com/comics/hash-functions/">hash functions are amazing</a></li>
<li>2020-05-06: <a href="https://wizardzines.com/comics/binary-search/">binary search</a></li>
</ul>

<p><strong>linux/systems</strong></p>

<p>These are part of a potential sequel to <a href="https://wizardzines.com/zines/bite-size-linux">bite size linux</a></p>

<ul>
<li>2020-05-27: <a href="https://wizardzines.com/comics/command-line-arguments/">command line arguments</a></li>
<li>2020-01-28: <a href="https://wizardzines.com/comics/network-protocols/">network protocols</a></li>
<li>2020-01-22: <a href="https://wizardzines.com/comics/clock-gettime/">clock_gettime: track CPU usage</a></li>
<li>2020-01-18: <a href="https://wizardzines.com/comics/shell/">what&rsquo;s a shell?</a></li>
<li>2020-01-16: <a href="https://wizardzines.com/comics/libc/">libc</a></li>
<li>2020-01-15: <a href="https://wizardzines.com/comics/terminals/">terminals</a></li>
<li>2020-01-13: <a href="https://wizardzines.com/comics/inodes/">inodes &amp; hard links</a></li>
<li>2020-01-12: <a href="https://wizardzines.com/comics/assembly/">assembly</a></li>
<li>2020-01-10: <a href="https://wizardzines.com/comics/cpu-scheduling/">CPU scheduling</a></li>
<li>2020-01-08: terminal escape codes (<a href="https://twitter.com/b0rk/status/1214999652547858435">tweet</a>)</li>
<li>2020-01-07: file locking (<a href="https://twitter.com/b0rk/status/1214761141299232768">tweet</a>)</li>
</ul>

<p><strong>miscellaneous</strong></p>

<ul>
<li>2020-03-09: pull request tip: ask when you&rsquo;re unsure! (<a href="https://twitter.com/b0rk/status/1237053602549641216">tweet</a>)</li>
<li>2020-01-09: IMSI catchers (fake cellphone towers). with @rival_elf (<a href="https://twitter.com/b0rk/status/1215276094389202946">tweet</a>)</li>
</ul>

<p><strong>containers</strong></p>

<p>These mostly got published as <a href="https://wizardzines.com/zines/containers">How Containers Work</a>. As usual the final zine was edited a lot and some of these didn&rsquo;t make it into the zine at all or I significantly rewrote the version in the zine.</p>

<ul>
<li>2020-04-13: how containers work: user namespaces (<a href="https://twitter.com/b0rk/status/1249775569371377667">tweet</a>)</li>
<li>2020-04-09: how containers work: PID namespaces (<a href="https://twitter.com/b0rk/status/1248263569629732865">tweet</a>)</li>
<li>2020-03-18: <a href="https://wizardzines.com/comics/namespaces/">how containers work: namespaces</a></li>
<li>2020-03-17: container networking (<a href="https://twitter.com/b0rk/status/1240115994003230720">tweet</a>)</li>
<li>2020-03-16: container layers (<a href="https://twitter.com/b0rk/status/1239566715790462977">tweet</a>)</li>
<li>2020-03-11: containers vs VMs (<a href="https://twitter.com/b0rk/status/1237744128450072578">tweet</a>)</li>
<li>2020-03-10: the Linux kernel features that make containers work (<a href="https://twitter.com/b0rk/status/1237387483987374083">tweet</a>)</li>
<li>2020-03-10: container images: package every single dependency together (<a href="https://twitter.com/b0rk/status/1237464479811633154">tweet</a>)</li>
<li>2020-03-09: how containers work: chroot (<a href="https://twitter.com/b0rk/status/1237080650106142720">tweet</a>)</li>
<li>2020-03-05: containers are processes (<a href="https://twitter.com/b0rk/status/1235754793253171200">tweet</a>)</li>
<li>2020-02-26: container networking (<a href="https://twitter.com/b0rk/status/1232800388404760581">tweet</a>)</li>
<li>2020-02-20: <a href="https://wizardzines.com/comics/containers-arent-magic/">containers aren&rsquo;t magic</a></li>
<li>2020-02-19: container fun: how to make a namespace (<a href="https://twitter.com/b0rk/status/1230158223405146117">tweet</a>)</li>
<li>2020-02-18: virtual machines (<a href="https://twitter.com/b0rk/status/1229768185588731905">tweet</a>)</li>
<li>2020-02-13: play with your containers (<a href="https://twitter.com/b0rk/status/1227986646861320192">tweet</a>)</li>
<li>2020-02-11: <a href="https://wizardzines.com/comics/seccomp-bpf/">how containers work: seccomp-bpf</a></li>
<li>2020-02-10: container registries (<a href="https://twitter.com/b0rk/status/1226856930875932672">tweet</a>)</li>
<li>2020-02-06: what&rsquo;s a container? (<a href="https://twitter.com/b0rk/status/1225445956734390273">tweet</a>)</li>
<li>2020-02-03: <a href="https://wizardzines.com/comics/why-containers/">why containers?</a></li>
<li>2020-01-14: <a href="https://wizardzines.com/comics/capabilities/">how containers work: capabilities</a></li>
<li>2020-01-06: <a href="https://wizardzines.com/comics/cgroups/">how containers work: cgroups</a></li>
</ul>

<h3 id="questions">questions</h3>

<p>A bunch of work on <a href="https://questions.wizardzines.com">https://questions.wizardzines.com</a>.</p>

<ul>
<li>2020-07-08: <a href="https://questions.wizardzines.com/dns.html">questions about DNS</a></li>
<li>2020-07-06: <a href="https://questions.wizardzines.com/ip.html">questions about IPv4</a></li>
<li>2020-06-29: <a href="https://questions.wizardzines.com/event-loops.html …|https://twitter.com/b0rk/status/1277655073003372549">questions about event loops / asynchronous programming</a></li>
<li>2020-06-24: <a href="https://questions.wizardzines.com/unix-processes.html">questions about unix processes</a></li>
<li>2020-06-21: <a href="https://questions.wizardzines.com/http-status-codes.html">questions about http status codes</a></li>
<li>2020-06-20: <a href="https://questions.wizardzines.com/cdn.html">questions about content delivery networks</a></li>
<li>2020-06-19: <a href="https://questions.wizardzines.com/cors.html">questions about CORS</a></li>
<li>2020-06-18: <a href="https://questions.wizardzines.com/tls-certificates.html">questions about TLS certificates</a></li>
<li>2020-06-17: <a href="https://questions.wizardzines.com/git-branches.html">questions about git branches</a></li>
<li>2020-06-16: <a href="https://questions.wizardzines.com/git-commits.html">questions about git commits</a></li>
<li>2020-06-15: <a href="https://questions.wizardzines.com/http-request-headers.html">questions about HTTP request headers:</a></li>
<li>2020-06-13: <a href="https://questions.wizardzines.com/sockets.html">questions about sockets</a></li>
<li>2020-06-10: <a href="https://questions.wizardzines.com/udp.html">questions about UDP</a></li>
</ul>

<h3 id="flashcards">flashcards</h3>

<p>A bunch of earlier work on <a href="https://flashcards.wizardzines.com">https://flashcards.wizardzines.com</a>. I came up with
a direction for this project I liked better
(<a href="https://questions.wizardzines.com">https://questions.wizardzines.com</a>) and won&rsquo;t be updating that site further.</p>

<ul>
<li>2020-04-30: <a href="https://flashcards.wizardzines.com/http/">some flashcards on HTTP</a></li>
<li>2020-04-21: <a href="http://flashcards.wizardzines.com/sql-basics/">made some flashcards on SQL</a></li>
<li>2020-04-20: <a href="https://flashcards.wizardzines.com/reverse-proxies/">some new flashcards: reverse proxies! (like nginx/haproxy)</a></li>
<li>2020-03-21: <a href="https://flashcards.wizardzines.com/tls/">some new flashcards are up٫ this time on TLS!</a></li>
<li>2020-03-16: <a href="https://flashcards.wizardzines.com/dns/">made some DNS flashcards today in the continuing flashcards experiment</a></li>
<li>2020-03-06: <a href="https://flashcards.wizardzines.com/linux/">more flashcard experiments: here are 15 linux flashcards on memory &amp; signals &amp; sockets &amp; a few other things</a></li>
<li>2020-02-28: <a href="https://flashcards.wizardzines.com/container-basics">more learning game experiments: here&rsquo;s a tiny container flashcards thing I made on a plane this week</a></li>
</ul>

<h3 id="videos">videos</h3>

<p>At the beginning of the year I did some experiments in making screencasts. It
was fun but I haven&rsquo;t done more so far. These are all links to youtube videos.</p>

<ul>
<li>2020-02-17: <a href="https://www.youtube.com/watch?v=xYv8wcNJiKw">a quick video on http status codes</a></li>
<li>2020-02-09: <a href="https://youtu.be/91OKnEIFyGs">some demos of how to make HTTP requests with curl</a></li>
<li>2020-02-04: <a href="https://www.youtube.com/watch?v=kV1u701wxgg">how DNS works</a></li>
<li>2020-01-01: <a href="https://www.youtube.com/watch?v=WIbbd_usHo8">euclid&rsquo;s algorithm: a fast way to find the greatest common factor</a></li>
</ul>

<h3 id="threads">threads</h3>

<p>I&rsquo;m not a big Twitter thread person (I&rsquo;d usually rather write a blog post) but I wrote one thread so far this year about how I think about the zine business:</p>

<ul>
<li>2020-02-18: a big thing I try to do with my zines is stick to fundamentals&hellip;
(<a href="https://twitter.com/b0rk/status/1229860328139296768">tweet</a>)</li>
</ul>

<h3 id="zine-announcements">zine announcements</h3>

<ul>
<li>2020-04-24: How Containers Work! announcement (<a href="https://twitter.com/b0rk/status/1253795997479821312">tweet</a>)</li>
<li>2020-01-31: Become a SELECT Star! announcement (<a href="https://twitter.com/b0rk/status/1223348391431823361">tweet</a>)</li>
</ul>

<h3 id="giveaways">giveaways</h3>

<p>I know that $12 USD  is a lot of money for some people٫ especially folks in
countries like Brazil with a weaker currency relative to the US dollar. So
periodically I do giveaways on Twitter so that people who can&rsquo;t afford $12 can
get the zines. I aim to give away 1 copy for every sale.</p>

<ul>
<li>2020-07-10: 1000 copies of How Containers Work (<a href="https://twitter.com/b0rk/status/1281596580135673856">tweet</a>)</li>
<li>2020-05-05: 1000 copies of Bite Size Linux (<a href="https://twitter.com/b0rk/status/1257667421374230530">tweet</a>)</li>
<li>2020-04-28: 700 copies of How Containers Work (<a href="https://twitter.com/b0rk/status/1255176464443625474">tweet</a>)</li>
<li>2020-04-26: 500 copies of How Containers Work (<a href="https://twitter.com/b0rk/status/1254396387703361536">tweet</a>)</li>
<li>2020-03-29: 1500 copies of Bite Size Linux (<a href="https://twitter.com/b0rk/status/1244281191802581002">tweet</a>)</li>
<li>2020-03-18: 1200 copies of Bite Size Command Line (<a href="https://twitter.com/b0rk/status/1240477475022548998">tweet</a>)</li>
<li>2020-02-08: 500 more copies of Become a SELECT Star (<a href="https://twitter.com/b0rk/status/1226117090781863936">tweet</a>)</li>
<li>2020-02-06: 500 copies of Become a SELECT Star (<a href="https://twitter.com/b0rk/status/1225561703263371264">tweet</a>)</li>
</ul>

<h3 id="polls">polls</h3>

<p>very occasionally I ask people questions:</p>

<ul>
<li>2020-03-10: what problems have you run into in practice when using containers? I&rsquo;m trying to put together a list of container downsides for the zine I&rsquo;m writing. (<a href="https://twitter.com/b0rk/status/1237528379097616388">tweet</a>)</li>
<li>2020-02-11: what are some man pages related to containers? (<a href="https://twitter.com/b0rk/status/1227244309621215233">tweet</a>)</li>
</ul>

<h3 id="that-s-all">that&rsquo;s all!</h3>

<p>I&rsquo;ve been thinking about trying to do a monthly summary here of what I&rsquo;m writing on
Twitter. We&rsquo;ll see if that happens!</p>
'),('https://jvns.ca/blog/2020/07/05/saturday-comics/', 'saturday comics: a weekly mailing list of programming comics', '1593939115000',  6, '

<p>Hello! This post is about a mailing list (<a href="https://wizardzines.com/saturday-comics/">Saturday
Comics</a>) that I actually started a
year ago. I realized I never wrote about it on this blog٫ which is maybe
better anyway because now I know more about how it&rsquo;s gone over the last year!</p>

<p>I think the main idea in this post is probably &ndash; if you want to have a mailing
list that&rsquo;s useful to people٫ but don&rsquo;t have the discipline to write new email
all the time٫ consider just making a mailing list of your best past work!</p>

<p>Let&rsquo;s start by talking about some of the problems I wanted to solve with this mailing list.</p>

<h3 id="problems-i-wanted-to-solve">problems I wanted to solve</h3>

<p><strong>problem 1: not everyone is on Twitter</strong>.</p>

<p>I pretty much exclusively post draft zine pages to Twitter٫ but not everyone is
on Twitter all the time. Lots of people aren&rsquo;t on Twitter at all٫ for lots of
very good reasons! So only posting my progress on my zines to Twitter felt
silly.</p>

<p><strong>problem 2: weekly mailing lists felt impossible</strong>:</p>

<p>I kept hearing &ldquo;julia٫ you need a mailing list٫ mailing lists are the best&rdquo;. So
I wanted to set up some kind of &ldquo;mailing list&rdquo; or something. Okay! I&rsquo;ve tried
to set up a &ldquo;weekly mailing list&rdquo; of sorts a few times٫ and inevitably what
happens is:</p>

<ul>
<li>I announce the mailing list</li>
<li>people subscribe</li>
<li>I literally never email the list (or email it once٫ and then never again)</li>
</ul>

<p>For obvious reason٫ that&rsquo;s not super effective.</p>

<p><strong>problem 3: it was impossible to find my &ldquo;best&rdquo; work</strong>:</p>

<p>I have an idea in my head of what my &ldquo;best&rdquo; comics are٫ but there was literally
no way for anyone else other than me to find that out even though I know that
some of my comics are a lot more useful to people than others.</p>

<p>I also recently added <a href="https://wizardzines.com/comics/">https://wizardzines.com/comics/</a> as another way to fix
this.</p>

<h3 id="send-my-favourite-comics-not-the-newest-comics">send my favourite comics٫ not the newest comics</h3>

<p>Unlike this blog (where people can read my newest work)٫ I decided to use a
different model: let people see some of my <strong>favourite</strong> comics.</p>

<p>The way I thought about this was &ndash; if someone isn&rsquo;t familiar with my work and
wants to learn more٫ they&rsquo;re more likely to find something interesting to them
in my &ldquo;best&rdquo; work than just whatever I happen to be working on at the time.</p>

<h3 id="solution-saturday-comics-an-automated-weekly-mailing-list">solution: saturday comics٫ an automated weekly mailing list</h3>

<p>So! I came up with &ldquo;saturday comics&rdquo;. The idea is pretty simple: you get 1
programming comic in your email every Saturday.</p>

<p>Unlike a normal weekly mailing list٫ though٫ you don&rsquo;t get the &ldquo;latest&rdquo; email
&ndash; instead٫ there&rsquo;s a fixed list of emails in the list٫ and everyone who signs
up gets all the emails in the list starting from the beginning.</p>

<p>For example٫ the first email is called <a href="https://wizardzines.com/comics/bash-tricks/">&ldquo;bash tricks&rdquo;</a>٫ and so if someone signs up
today٫ they&rsquo;ll get the &ldquo;bash tricks&rdquo; email on Saturday.</p>

<h3 id="so-far-29-weeks-of-email">so far: 29 weeks of email</h3>

<p>So far the list has 29 weeks (7 months) of email &ndash; if you sign up today٫
you&rsquo;ll get a comic every week for at least 29 weeks.</p>

<p>You might notice that 29 is less than 52 and think &ldquo;wait٫ you said this list
has existed for a year!&ldquo;. I haven&rsquo;t quite kept up with 1 email a week so far.
What happens in practice is that I&rsquo;ll add 5 new emails٫ they&rsquo;ll get sent out over 5
weeks٫ then subscribers will stop getting email for while٫ and then I&rsquo;ll add
more emails eventually and then they&rsquo;ll start getting email again.</p>

<p>It&rsquo;s maybe not ideal٫ but I think it&rsquo;s okay٫ and it&rsquo;s definitely better than my
previous mailing list practices of &ldquo;literally never email the mailing list
ever&rdquo;.</p>

<h3 id="so-far-5000-people-have-subscribed-and-people-seem-to-like-it">so far: 5000 people have subscribed٫ and people seem to like it!</h3>

<p>5000 people have subscribed to the list so far٫ and people seem to like it &ndash; I
pretty often get replies saying &ldquo;hey٫ thanks for this week&rsquo;s comic٫ I loved
this one&rdquo; or see people tweeting about how they loved this week&rsquo;s email.</p>

<p>You can <a href="https://wizardzines.com/#saturday-comics">sign up here</a> if you want.</p>

<h3 id="how-it-works-a-convertkit-sequence">how it works: a ConvertKit sequence</h3>

<p>The way I implemented it is with a ConvertKit sequence. Here&rsquo;s an example of
what the setup looks like: there&rsquo;s a list of subject lines &amp; when they&rsquo;re
scheduled to go out (like &ldquo;1 week after the last email&rdquo;)٫ and then you can fill
in each email&rsquo;s content. I&rsquo;ve found it pretty straightforward to use so far.</p>

<div align="center">
<img src="https://jvns.ca/images/sequence.png" width="200px">
</div>

<h3 id="marketing-building-trust">marketing = building trust</h3>

<p>This list is sort of a marketing tool٫ but I&rsquo;ve learned to think of marketing
(at least for my business) as just building trust by helping people learn new
things. So instead of worrying about optimizing conversion rates or whatever
(which has never helped me at all)٫ I just try to send emails to the list that
will be helpful.</p>

<p>With every comic I include a link to the zine that it&rsquo;s from in case people
want to buy the zine٫ but I try to not be super in-your-face about it &ndash; if
folks want to buy my zines٫ that&rsquo;s great٫ if they want to just enjoy the weekly
comics٫ that&rsquo;s great too.</p>

<h3 id="that-s-all">that&rsquo;s all!</h3>

<p>This idea of a mailing list where you send out your favourite work instead of
your latest work was really new to me٫ and I&rsquo;m happy with how it&rsquo;s gone so far!</p>
'),('https://jvns.ca/blog/2020/06/30/tell-candidates-what-to-expect-from-your-job-interviews/', 'Tell candidates what to expect from your job interviews', '1593530674000',  6, '

<p>In my last job٫ I helped with a few projects (like <a href="https://jvns.ca/blog/brag-documents/">brag
documents</a> and the engineering levels) to
help make the engineering culture a little more inclusive٫ and I want to talk
about one of them today: making the interview process a little easier to
understand for candidates.</p>

<p>I worked on this project for a few days way back in 2015 and I’m pretty happy
with how it turned out.</p>

<h3 id="giving-everyone-a-little-information-helps-level-the-playing-field">giving everyone a little information helps level the playing field</h3>

<p>Different tech companies run their interviews in very different ways٫ and I
think it’s silly to expect candidates to magically intuit how your company’s
interview process works.</p>

<p>It sucks for everyone when a candidate is surprised with an unexpected
interview. For example٫ at the time the debugging interview required candidates
to have a dev environment set up on their computer that let them install a
library &amp; run the tests. Sometimes candidates didn’t have their environment set
up the right way٫ which was a waste of everyone’s time! The point of the
interview wasn’t to watch people install bundler!</p>

<h3 id="different-companies-have-different-rubrics">different companies have different rubrics</h3>

<p>Also٫ different companies actually test different things in their interviews!
At that job we didn’t care if people used Stack Overflow during their
interviews and didn’t interview for algorithms expertise٫ but lots of companies
<strong>do</strong> interview for algorithms expertise.</p>

<p>Telling people in advance what they’ll be measured on makes it way easier for
them to prepare: if you tell them they won’t be asked algorithms questions٫
they don’t have to waste their time practicing implementing breadth first
search or whatever.</p>

<h3 id="solution-write-a-short-document">solution: write a short document!</h3>

<p>My awesome coworker <a href="https://www.kiranbot.com/">Kiran</a> had a simple idea to
help solve this problem: write a document explaining what to expect from the
interview process! She wrote the document and I helped edit it a bit.</p>

<p>We called it <a href="https://web.archive.org/web/20170928181711/https://stripe.com/jobs/engineering-onsite.pdf">On-site interviews for Engineering: What to expect</a> (that link is
to an old revision of that document I found in the internet archive).</p>

<p>It covered:</p>

<ul>
<li>how to prepare for the interview</li>
<li>what candidates were evaluated on (debugging! navigating codebases! communication!)</li>
<li>a few things about the non-technical parts of the onsite interview</li>
</ul>

<h3 id="keep-it-updated-over-time">keep it updated over time</h3>

<p>That document was originally written in April 2015. A lot of things changed
about the interview process over time٫ and so it needed to be kept updated.</p>

<p>I think the work of keeping the document updated is even more important than
writing it in the first place٫ and a lot of amazing people worked on that. I
don’t work there anymore٫ but some quick Googling turned up what I think is the
<a href="https://docs.google.com/document/d/1YBQHW0WamAgiDiHBF2yI2Z3itnrdJu11S7VK6jzKAJs/edit">current version of that document</a>٫
and it’s great!</p>

<h3 id="documenting-your-interview-process-is-pretty-easy">documenting your interview process is pretty easy</h3>

<p>In my experience٫ advocating for changes to an interview process is really
hard. You need to propose a new interview process٫ test the interviews٫
convince interviewers to get on board – it takes a long time.</p>

<p>In comparison٫ documenting an existing interview process (without changing
it!!) is WAY EASIER. My memory is a pretty fuzzy٫ but I think basically nobody
objected to documenting the interview process the company already had – it was
just factual information about what we were already doing! Way less
controversial.</p>

<h3 id="you-can-make-small-changes-to-your-company-s-culture">you can make small changes to your company’s culture</h3>

<p>Making the companies I work at a better place for everyone to work is important
to me. It’s a huge project٫ and I’ve tried a lot of things that haven’t worked.</p>

<p>But I’ve found it rewarding to work on changes like this that make one small
thing a little better for people.</p>

<p><small>thanks to Kiran Bhattaram for coming up with this idea in the first
place and for reviewing a draft of this post٫ and to <a href="https://twitter.com/jilljubs/status/1277975930468626434">@jilljubs</a> for reminding me of earlier today </small></p>
'),('https://jvns.ca/blog/2020/06/28/entr/', 'entr: rerun your build when files change', '1593361755000',  6, '

<p>This is going to be a pretty quick post  &ndash; I found out about <a href="http://eradman.com/entrproject/"><code>entr</code></a> relatively
recently and I felt like WHY DID NOBODY TELL ME ABOUT THIS BEFORE?!?! So I&rsquo;m
telling you about it in case you&rsquo;re in the same boat as I was.</p>

<p>There&rsquo;s a great explanation of the tool with lots of examples on <a href="http://eradman.com/entrproject/">entr&rsquo;s website</a>.</p>

<p>The summary is in the headline: <code>entr</code> is a command line tool that lets you run
an arbitrary command every time you change any of a set of specified files. You
pass it the list of files to watch on stdin٫ like this:</p>

<pre><code>git ls-files | entr bash my-build-script.sh
</code></pre>

<p>or</p>

<pre><code>find . -name *.rs | entr cargo test
</code></pre>

<p>or whatever you want really.</p>

<h3 id="quick-feedback-is-amazing">quick feedback is amazing</h3>

<p>Like possibly every single programmer in the universe٫ I find it Very Annoying
to have to manually rerun my build / tests every time I make a change to my
code.</p>

<p>A lot of tools (like hugo and flask) have a built in system to automatically
rebuild when you change your files٫ which is great!</p>

<p>But often I have some hacked together custom build process that I wrote myself
(like <code>bash build.sh</code>)٫ and <code>entr</code> lets me have a magical build experience
where I get instant feedback on whether my change fixed the weird bug with just
one line of bash. Hooray!</p>

<h3 id="restart-a-server-entr-r">restart a server (<code>entr -r</code>)</h3>

<p>Okay٫ but what if you&rsquo;re running a server٫ and the server needs to be restarted
every time you change a file? entr&rsquo;s got you &ndash; if you pass <code>-r</code>٫ then</p>

<pre><code>git ls-files | entr -r python my-server.py
</code></pre>

<h3 id="clear-the-screen-entr-c">clear the screen (<code>entr -c</code>)</h3>

<p>Another neat flag is <code>-c</code>٫ which lets you clear the screen before rerunning the
command٫ so that you don&rsquo;t get distracted/confused by the previous build&rsquo;s
output.</p>

<h3 id="use-it-with-git-ls-files">use it with <code>git ls-files</code></h3>

<p>Usually the set of files I want to track is about the same list of files I have
in git٫ so <code>git ls-files</code> is a natural thing to pipe to <code>entr</code>.</p>

<p>I have a project right now where sometimes I have files that I&rsquo;ve just created
that aren&rsquo;t in git just yet. So what if you want to include untracked files?
These git command line arguments will do it (I got them from an email from a reader٫ thank you!):</p>

<pre><code>git ls-files -cdmo --exclude-standard  | entr your-build-script
</code></pre>

<p>Someone emailed me and said they have a <code>git-entr</code> command that runs</p>

<pre><code>git ls-files -cdmo --exclude-standard | entr -d &quot;$@&quot;
</code></pre>

<p>which I think is a great idea.</p>

<h3 id="restart-every-time-a-new-file-is-added-entr-d">restart every time a new file is added: <code>entr -d</code></h3>

<p>The other problem with this <code>git ls-files</code> thing is that sometimes I add a new
file٫ and of course it&rsquo;s not in git yet. entr has a nice feature for this &ndash; if
you pass <code>-d</code>٫ then if you add a new file in any of the directories entr is
tracking٫ then it&rsquo;ll exit.</p>

<p>I&rsquo;m using this paired with a little while loop that will restart
<code>entr</code> to include the new files٫ like this:</p>

<pre><code>while true
do
{ git ls-files; git ls-files . --exclude-standard --others; } | entr -d your-build-script
done
</code></pre>

<h3 id="how-entr-works-on-linux-inotify">how entr works on Linux: inotify</h3>

<p>On Linux٫ entr works using <code>inotify</code> (a system for tracking filesystem events
like file changes) &ndash;  if you strace it٫ you&rsquo;ll see an <code>inotify_add_watch</code>
system call for each file you ask it to watch٫ like this:</p>

<pre><code>inotify_add_watch(3٫ &quot;static/stylesheets/screen.css&quot;٫ IN_ATTRIB|IN_CLOSE_WRITE|IN_CREATE|IN_DELETE_SELF|IN_MOVE_SELF) = 1152
</code></pre>

<h3 id="that-s-all">that&rsquo;s all!</h3>

<p>I hope this helps a few people learn about <code>entr</code>!</p>
'),('https://jvns.ca/blog/2020/06/19/a-little-bit-of-plain-javascript-can-do-a-lot/', 'A little bit of plain Javascript can do a lot', '1592557127000',  6, '

<p>I&rsquo;ve never worked as a professional frontend developer٫ so even though I&rsquo;ve
been writing HTML/CSS/JS for 15 years for little side projects٫ all of the
projects have been pretty small٫ sometimes I don&rsquo;t write any Javascript for
years in between٫ and I often don&rsquo;t quite feel like I know what I&rsquo;m doing.</p>

<p>Partly because of that٫ I&rsquo;ve leaned on libraries a lot! Ten years ago I used to
use jQuery٫ and since maybe 2017 I&rsquo;ve been using a lot of vue.js for my little
Javascript projects (you can see a <a href="https://jvns.ca/blog/2017/06/26/vue-js-fun/">little whack-a-mole game I made here as an
intro to Vue</a>).</p>

<p>But last week٫ for the first time in a while٫ I wrote some plain
Javascript without a library and it was fun so I wanted to talk about it a bit!</p>

<h3 id="experimenting-with-just-plain-javascript">experimenting with just plain Javascript</h3>

<p>I really like Vue. But last week when I started building
<a href="https://questions.wizardzines.com">https://questions.wizardzines.com</a>٫ I had slightly different constraints than
usual &ndash; I wanted to use the same HTML to generate both a PDF (with
<a href="https://www.princexml.com/">Prince</a>) and to make an interactive version of the questions.</p>

<p>I couldn&rsquo;t really see how that would work with Vue (because Vue wants to create
all the HTML itself)٫ and because it was a small project I decided to try
writing it in plain Javascript with no libraries &ndash; just write some HTML/CSS
and add a single <code>&lt;script src=&quot;js/script.js&quot;&gt; &lt;/script&gt;</code>.</p>

<p>I hadn&rsquo;t done this in a while٫ and I learned a few things along the way that
made it easier than I thought it would be when I started.</p>

<h3 id="do-almost-everything-by-adding-removing-css-classes">do almost everything by adding &amp; removing CSS classes</h3>

<p>I decided to implement almost all of the UI by just adding &amp; removing CSS
classes٫ and using <a href="https://3dtransforms.desandro.com/card-flip">CSS transitions</a> if I want to animate a transition.</p>

<p>here&rsquo;s a small example٫ where clicking the &ldquo;next&rdquo; question button adds the &ldquo;done&rdquo; class to the parent div.</p>

<pre><code>div.querySelector(".next-question").onclick = function () {
    show_next_row();
    this.parentElement.parentElement.classList.add("done");
}
</code></pre>

<p>This worked pretty well. My CSS as always is a bit of a mess but it felt
manageable.</p>

<h3 id="add-remove-css-classes-with-classlist">add/remove CSS classes with <code>.classList</code></h3>

<p>I started out by editing the classes like this: <code>x.className = "new list of
classes"</code>. That felt a bit messy though and I wondered if there was a better
way. And there was!</p>

<p>You can also add CSS classes like this:</p>

<pre><code>let x = document.querySelector("div");
x.classList.add("hi");
x.classList.remove("hi");
</code></pre>

<p><code>element.classList.remove("hi")</code> is way cleaner than what I was doing before.</p>

<h3 id="find-elements-with-document-queryselectorall">find elements with <code>document.querySelectorAll</code></h3>

<p>When I started learning jQuery I remember thinking that if you wanted to easily
find something in the DOM you had to use jQuery (like <code>$(".class")</code>).  I just
learned this week that you can actually write
<code>document.querySelectorAll(".some-class")</code> instead٫ and then you don&rsquo;t need to
depend on any library!</p>

<p>I got curious about when <code>querySelectorAll</code> was introduced. I Googled a tiny
bit and it looks like the [Selectors API was built sometime between 2008 and
2013 &ndash; I found a <a href="https://johnresig.com/blog/thoughts-on-queryselectorall/">post from the jQuery author discussing the proposed
implementation in
2008</a>٫ and <a href="https://tiffanybbrown.com/2011/08/12/meet-the-selectors-api/">a blog
post from 2011</a>
saying it was in all major browsers by then٫ so maybe it didn&rsquo;t exist when I
started using jQuery but it&rsquo;s definitely been around for quite a while :)</p>

<h3 id="set-innerhtml">set <code>.innerHTML</code></h3>

<p>In one place I wanted to change a button&rsquo;s HTML contents. Creating DOM elements
with <code>document.createElement</code> is pretty annoying٫ so I tried to do that as
little as possible and instead set <code>.innerHTML</code> to the HTML string I wanted:</p>

<pre><code>    button.innerHTML = `&lt;i class=&quot;icon-lightbulb&quot;&gt;&lt;/i&gt;I learned something!
    &lt;object data=&quot;/confetti.svg&quot; width=&quot;30&quot; height = &quot;30&quot;&gt; &lt;/object&gt;
    `;
</code></pre>

<h3 id="scroll-through-the-page-with-scrollintoview">scroll through the page with <code>.scrollIntoView</code></h3>

<p>The last fun thing I learned about is <code>.scrollIntoView</code> &ndash; I wanted to scroll down to the next question automatically when someone clicked &ldquo;next question&rdquo;. Turns out this is just one line of code:</p>

<pre><code>row.classList.add("revealed");
row.scrollIntoView({behavior: "smooth"٫ block: "center"});
</code></pre>

<h3 id="another-vanilla-js-example-peekobot">another vanilla JS example: peekobot</h3>

<p>Another small example of a plain JS library I thought was nice is
<a href="https://peekobot.github.io/peekobot/">peekobot</a>٫ which is a little chatbot
interface that&rsquo;s 100 lines of JS/CSS.</p>

<p>Looking at <a href="https://github.com/Peekobot/peekobot/blob/master/peekobot.js">its Javascript</a>٫
it uses some similar patterns &ndash; a lot of <code>.classList.add</code>٫ some adding
elements to the DOM٫ some <code>.querySelectorAll</code>.</p>

<p>I learned from reading peekobot&rsquo;s source about
<a href="https://developer.mozilla.org/en-US/docs/Web/API/Element/closest">.closest</a>
which finds the closest ancestor that matches a given selector. That seems like
it would be a nice way to get rid of some of the <code>.parentElement.parentElement</code>
that I was writing in my Javascript٫ which felt a bit fragile.</p>

<h3 id="plain-javascript-can-do-a-lot">plain Javascript can do a lot!</h3>

<p>I was pretty surprised by how much I could get done with just plain JS. I ended
up writing about 50 lines of JS to do everything I wanted to do٫ plus a bit
extra to collect some anonymous metrics about what folks were learning.</p>

<p>As usual with my frontend posts٫ this isn&rsquo;t meant to be Serious Frontend
Engineering Advice &ndash; my goal is to be able to write little websites with less
than 200 lines of Javascript that mostly work. If you are also flailing around
in frontend land I hope this helps a bit!</p>
'),('https://jvns.ca/blog/how-updating-dns-works/', 'What happens when you update your DNS?', '1592379513000',  6, '

<p>I&rsquo;ve seen a lot of people get confused about updating their site&rsquo;s DNS records
to change the IP address. Why is it slow? Do you really have to wait 2 days for
everything to update? Why do some people see the new IP and some people see the
old IP? What&rsquo;s happening?</p>

<p>So I wanted to write a quick exploration of what&rsquo;s happening behind the scenes
when you update a DNS record.</p>

<h3 id="how-dns-works-recursive-vs-authoritative-dns-servers">how DNS works: recursive vs authoritative DNS servers</h3>

<p>First٫ we need to explain a little bit about DNS. There are 2 kinds of DNS
servers: <strong>authoritative</strong> and <strong>recursive</strong>.</p>

<p><strong>authoritative</strong> DNS servers (also known as <strong>nameservers</strong>) have a database
of IP addresses for each domain they&rsquo;re responsible for. For example٫ right now
an authoritative DNS server for github.com is ns-421.awsdns-52.com. You can ask it for github.com&rsquo;s IP like this;</p>

<pre><code>dig @ns-421.awsdns-52.com github.com
</code></pre>

<p><strong>recursive</strong> DNS servers٫ by themselves٫ don&rsquo;t know anything about who owns
what IP address. They figure out the IP address for a domain by asking
the right authoritative DNS servers٫ and then cache that IP address in case they&rsquo;re asked
again. 8.8.8.8 is a recursive DNS server.</p>

<p>When people visit your website٫ they&rsquo;re probably making their DNS queries to a
recursive DNS server. So٫ how do recursive DNS servers work? Let&rsquo;s see!</p>

<h3 id="how-does-a-recursive-dns-server-query-for-github-com">how does a recursive DNS server query for github.com?</h3>

<p>Let&rsquo;s go through an example of what a recursive DNS server (like 8.8.8.8) does
when you ask it for an IP address (A record) for github.com. First &ndash; if it
already has something cached٫ it&rsquo;ll give you what it has cached. But what if
all of its caches are expired? Here&rsquo;s what happens:</p>

<p><strong>step 1</strong>: it has IP addresses for the root DNS servers hardcoded in its source code. You can see this in <a href="https://github.com/NLnetLabs/unbound/blob/6e0756e819779d9cc2a14741b501cadffe446c93/iterator/iter_hints.c#L131">unbound&rsquo;s source code here</a>. Let&rsquo;s say it picks  <code>198.41.0.4</code> to start with. Here&rsquo;s the <a href="https://www.iana.org/domains/root/files">official source</a> for those hardcoded IP addresses٫ also known as a &ldquo;root hints file&rdquo;.</p>

<p><strong>step 2</strong>: Ask the root nameservers about <code>github.com</code>.</p>

<p>We can roughly reproduce what happens with <code>dig</code>. What this gives us is a new
authoritative nameserver to ask: a nameserver for <code>.com</code>٫ with the IP <code>192.5.6.30</code>.</p>

<pre><code>$ dig @198.41.0.4 github.com
...
com.			172800	IN	NS	a.gtld-servers.net.
...
a.gtld-servers.net.	172800	IN	A	192.5.6.30
...
</code></pre>

<p>The details of the DNS response are a little more complicated than that &ndash; in
this case٫ there&rsquo;s an authority section with some NS records and an additional
section with A records so you don&rsquo;t need to do an extra lookup to get the IP
addresses of those nameservers.</p>

<p>(in practice٫ 99.99% of the time it&rsquo;ll already have the address of the <code>.com</code> nameservers cached٫ but we&rsquo;re pretending we&rsquo;re really starting from scratch)</p>

<p><strong>step 3</strong>: Ask the <code>.com</code> nameservers about <code>github.com</code>.</p>

<pre><code>$ dig @192.5.6.30 github.com
...
github.com.		172800	IN	NS	ns-421.awsdns-52.com.
ns-421.awsdns-52.com.	172800	IN	A	205.251.193.165
...
</code></pre>

<p>We have a new IP address to ask! This one is the nameserver for <code>github.com</code>.</p>

<p><strong>step 4</strong>: Ask the <code>github.com</code> nameservers about <code>github.com</code>.</p>

<p>We&rsquo;re almost done!</p>

<pre><code>$ dig @205.251.193.165 github.com

github.com.		60	IN	A	140.82.112.4
</code></pre>

<p>Hooray!! We have an <code>A</code> record for <code>github.com</code>! Now the recursive nameserver
has <code>github.com</code>&rsquo;s IP address and can return it back to you. And it could do
all of this by only hardcoding a few IP addresses: the addresses of the root
nameservers.</p>

<h3 id="how-to-see-all-of-a-recursive-dns-server-s-steps-dig-trace">how to see all of a recursive DNS server&rsquo;s steps: <code>dig +trace</code></h3>

<p>When I want to see what a recursive DNS server would do when resolving a
domain٫ I run</p>

<pre><code>$ dig @8.8.8.8 +trace github.com
</code></pre>

<p>This shows all the DNS records that it requests٫ starting at the root DNS
servers &ndash; all the 4 steps that we just went through.</p>

<h3 id="let-s-update-some-dns-records">let&rsquo;s update some DNS records!</h3>

<p>Now that we know the basics of how DNS works٫ let&rsquo;s update some DNS records and see
what happens.</p>

<p>When you update your DNS records٫ there are two main options:</p>

<ol>
<li>keep the same nameservers</li>
<li>change nameservers</li>
</ol>

<h3 id="let-s-talk-about-ttls">let&rsquo;s talk about TTLs</h3>

<p>We&rsquo;ve forgotten something important though! TTLs! You know how
we said earlier that the recursive DNS server will cache records until they
expire?  The way it decides whether the record should expire is by looking at
its <strong>TTL</strong> or &ldquo;time to live&rdquo;.</p>

<p>In this example٫ the TTL for the A record github&rsquo;s nameserver returns for its
DNS record is <code>60</code>٫ which means 60 seconds:</p>

<pre><code>$ dig @205.251.193.165 github.com

github.com.		60	IN	A	140.82.112.4
</code></pre>

<p>That&rsquo;s a pretty short TTL٫ and <em>in theory</em> if everybody&rsquo;s DNS implementation
followed the <a href="https://tools.ietf.org/html/rfc1035">DNS standard</a> it means that
if Github decided to change the IP address for <code>github.com</code>٫ everyone should
get the new IP address
within 60 seconds. Let&rsquo;s see how that plays out in practice</p>

<h3 id="option-1-update-a-dns-record-on-the-same-nameservers">option 1: update a DNS record on the same nameservers</h3>

<p>First٫ I updated my nameservers (Cloudflare) to have a new DNS record: an A record that maps
<code>test.jvns.ca</code> to <code>1.2.3.4</code>.</p>

<pre><code>$ dig @8.8.8.8 test.jvns.ca
test.jvns.ca.		299	IN	A	1.2.3.4
</code></pre>

<p>This worked immediately! There was no need to wait at all٫ because there was no
<code>test.jvns.ca</code> DNS record before that could have been cached. Great. But it
looks like the new record is cached for ~5 minutes (299 seconds).</p>

<p>So٫ what if we try to change that IP? I changed it to <code>5.6.7.8</code>٫ and then ran the same DNS query.</p>

<pre><code>$ dig @8.8.8.8 test.jvns.ca
test.jvns.ca.		144	IN	A	1.2.3.4
</code></pre>

<p>Hmm٫ it seems like that DNS server has the <code>1.2.3.4</code> record still cached for
another 144 seconds. Interestingly٫ if I query <code>8.8.8.8</code> multiple times I actually get
inconsistent results &ndash; sometimes it&rsquo;ll give me the new IP and sometimes the
old IP٫ I guess because 8.8.8.8 actually load balances to a bunch of different
backends which each have their own cache.</p>

<p>After I waited 5 minutes٫ all of the <code>8.8.8.8</code> caches had updated and were
always returning the new <code>5.6.7.8</code> record. Awesome. That was pretty fast!</p>

<h3 id="you-can-t-always-rely-on-the-ttl">you can&rsquo;t always rely on the TTL</h3>

<p>As with most internet protocols٫ not everything obeys the DNS specification.
Some ISP DNS servers will cache records for longer than the TTL specifies٫ like
maybe for 2 days instead of 5 minutes. And people can always hardcode the old
IP address in their /etc/hosts.</p>

<p>What I&rsquo;d expect to happen in practice when updating a DNS record with a 5
minute TTL is that a large percentage of clients will move over to the new IPs
quickly (like within 15 minutes)٫ and then there will be a bunch of stragglers
that slowly update over the next few days.</p>

<h3 id="option-2-updating-your-nameservers">option 2: updating your nameservers</h3>

<p>So we&rsquo;ve seen that when you update an IP address without changing your
nameservers٫ a lot of DNS servers will pick up the new IP pretty quickly.
Great. But what happens if you change your nameservers? Let&rsquo;s try it!</p>

<p>I didn&rsquo;t want to update the nameservers for my blog٫ so instead I went with a
different domain I own and use in the examples for the <a href="https://wizardzines.com/zines/http/">HTTP
zine</a>: <code>examplecat.com</code>.</p>

<p>Previously٫ my nameservers were set to dns1.p01.nsone.net. I decided to switch
them over to Google&rsquo;s nameservers &ndash; <code>ns-cloud-b1.googledomains.com</code> etc.</p>

<p>When I made the change٫ my domain registrar somewhat ominiously popped up the
message &ndash; &ldquo;Changes to examplecat.com saved. They&rsquo;ll take effect within the
next 48 hours&rdquo;. Then I set up a new A record for the domain٫ to make it point to <code>1.2.3.4</code></p>

<p>Okay٫ let&rsquo;s see if that did anything</p>

<pre><code>$ dig @8.8.8.8 examplecat.com
examplecat.com.		17	IN	A	104.248.50.87
</code></pre>

<p>No change. If I ask a different DNS server٫ it knows the new IP:</p>

<pre><code>$ dig @1.1.1.1 examplecat.com
examplecat.com.		299	IN	A	1.2.3.4
</code></pre>

<p>but 8.8.8.8 is still clueless. The reason 1.1.1.1 sees the new IP even though
I just changed it 5 minutes ago is presumably that nobody had ever queried
1.1.1.1 about examplecat.com before٫ so it had nothing in its cache.</p>

<h3 id="nameserver-ttls-are-much-longer">nameserver TTLs are much longer</h3>

<p>The reason that my registrar was saying &ldquo;THIS WILL TAKE 48 HOURS&rdquo; is that the TTLs
on NS records (which are how recursive nameservers know which nameserver to
ask) are MUCH longer!</p>

<p>The new nameserver is definitely returning the new IP address for
<code>examplecat.com</code></p>

<pre><code>$ dig @ns-cloud-b1.googledomains.com examplecat.com
examplecat.com.		300	IN	A	1.2.3.4
</code></pre>

<p>But remember what happened when we queried for the <code>github.com</code> nameservers٫ way back?</p>

<pre><code>$ dig @192.5.6.30 github.com
...
github.com.		172800	IN	NS	ns-421.awsdns-52.com.
ns-421.awsdns-52.com.	172800	IN	A	205.251.193.165
...
</code></pre>

<p>172800 seconds is 48 hours! So nameserver updates will in general take a lot
longer to expire from caches and propagate than just updating an IP address
without changing your nameserver.</p>

<h3 id="how-do-your-nameservers-get-updated">how do your nameservers get updated?</h3>

<p>When I update the nameservers for <code>examplecat.com</code>٫ what happens is that he
<code>.com</code> nameserver gets a new <code>NS</code> record with the new domain. Like this:</p>

<pre><code>dig ns @j.gtld-servers.net examplecat.com

examplecat.com.		172800	IN	NS	ns-cloud-b1.googledomains.com
</code></pre>

<p>But how does that new NS record get there? What happens is that I tell my
<strong>domain registrar</strong> what I want the new nameservers to be by updating it on
the website٫ and then my domain registrar tells the <code>.com</code> nameservers to make
the update.</p>

<p>For <code>.com</code>٫ these updates happen pretty fast (within a few minutes)٫ but I
think for some other TLDs the TLD nameservers might not apply updates as quickly.</p>

<h3 id="your-program-s-dns-resolver-library-might-also-cache-dns-records">your program&rsquo;s DNS resolver library might also cache DNS records</h3>

<p>One more reason TTLs might not be respected in practice: many programs need to
resolve DNS names٫ and some programs will also cache DNS records indefinitely
in memory (until the program is restarted).</p>

<p>For example٫ AWS has an article on <a href="https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/java-dg-jvm-ttl.html">Setting the JVM TTL for DNS Name
Lookups</a>.
I haven&rsquo;t written that much JVM code that does DNS lookups myself٫ but from a
little Googling about the JVM and DNS it seems like you can configure the
JVM so that it caches every DNS lookup indefinitely. (like <a href="https://github.com/elastic/elasticsearch/issues/16412">this elasticsearch issue</a>)</p>

<h3 id="that-s-all">that&rsquo;s all!</h3>

<p>I hope this helps you understand what&rsquo;s going on when updating your DNS!</p>

<p>As a disclaimer٫ again &ndash; TTLs definitely don&rsquo;t tell the whole story about DNS
propagation &ndash; some recursive DNS servers definitely don&rsquo;t respect TTLs٫ even
if the major ones like 8.8.8.8 do. So even if you&rsquo;re just updating an A record
with a short TTL٫ it&rsquo;s very possible that in practice you&rsquo;ll still get some
requests to the old IP for a day or two.</p>

<p>Also٫ I changed the nameservers for <code>examplecat.com</code> back to their old values
after publishing this post.</p>
'),('https://jvns.ca/blog/2020/06/14/questions-to-help-you-learn/', 'Questions to help people decide what to learn', '1592126306000',  6, '

<p>For the last few months٫ I&rsquo;ve been working on and off on a way to help people
evaluate their own learning &amp; figure out what to learn next.</p>

<p>This past week I built a new iteration of this: <a href="https://questions.wizardzines.com">https://questions.wizardzines.com</a>٫ which today has 2
sets of questions:</p>

<ol>
<li><a href="https://questions.wizardzines.com">questions about UDP</a></li>
<li><a href="https://questions.wizardzines.com">questions about sockets</a></li>
</ol>

<p>It&rsquo;s still a work in progress٫ but I&rsquo;ve been working on this for quite a while
so I wanted to write down how I got here.</p>

<h3 id="the-goal-help-people-learn-on-their-own">the goal: help people learn on their own</h3>

<p>First٫ let&rsquo;s talk about my goal. I&rsquo;m interested in helping people who are
trying to learn on their own. I don&rsquo;t have any specific materials I&rsquo;m trying to
teach &ndash; I want to help people learn what <em>they</em> want to learn.</p>

<p>I&rsquo;ve done a lot of this by writing blog posts &amp;
<a href="https://wizardzines.com">zines</a>٫ but I felt like I was missing something &ndash;
were people really learning what they wanted to learn? How could they tell if
they&rsquo;d learned it?</p>

<p>I felt like I wanted some kind of &ldquo;quiz&rdquo; or &ldquo;test&rdquo;٫ but I wasn&rsquo;t sure what it
should look like.</p>

<h3 id="formative-assessment-vs-summative-assessment">formative assessment vs summative assessment</h3>

<p>Let&rsquo;s take a very quick detour into terminology. There are two kinds of
assessment teachers use in school.</p>

<p><strong>formative assessment</strong>: &ldquo;evaluations used to modify teaching and learning activities to improve student attainment.&rdquo;</p>

<p><strong>summative assessment</strong>: used to determine grades</p>

<p>Grades are pretty pointless if you&rsquo;re teaching yourself (who cares if you got
an A in sockets?). But formative assessments! If you could take some kind of
evaluation to help you decide what exactly you should teach yourself next! That
seems more useful. So I got interested in building some kind of &ldquo;formative
assessment&rdquo; tool.</p>

<p>(thanks to <a href="https://www.harihareswara.net/">Sumana</a> for reminding me of these terms!)</p>

<h3 id="next-step-ask-on-twitter-how-people-feel-about-quizzes">next step: ask on Twitter how people feel about quizzes</h3>

<p>So I asked on Twitter (in <a href="https://twitter.com/b0rk/status/1232058417302450178">this thread</a>):</p>

<blockquote>
<p>have you ever taken a class (online or offline!) where you were given a quiz
first that you could use to check your understanding of the topic at the start?
did it help you?</p>
</blockquote>

<p>I got about 90 replies. Here are some themes I took away from the replies:</p>

<ul>
<li>quizzes remind many people of bad school experiences</li>
<li>people like using quizzes if they can direct their own learning (&ldquo;skip X
section if I already know the thing&rdquo;)</li>
<li>one person said they took a quiz where they got a low score at the beginning
and it helped them realize that they didn&rsquo;t actually know the course content
as well as they thought</li>
</ul>

<p>One thing I learned from this is that being told you <em>don&rsquo;t</em> know something is
a bad experience for a lot of people.</p>

<h3 id="idea-build-flashcards-you-can-learn-from">idea: build flashcards you can learn from</h3>

<p>My first idea was to reframe a test as a way to <strong>learn</strong>. So instead of it
being something that tells you what you <strong>don&rsquo;t</strong> know (which٫ so what?)٫ it
helps you learn something new!</p>

<p>So I built a few sets of flashcards about various topics.
Here&rsquo;s the first set I built٫ <a href="http://flashcards.wizardzines.com/container-basics/">flashcards on containers</a>٫ if you want to try it out.</p>

<p>If you didn&rsquo;t try it &ndash; it looks like this:</p>

<p><a href="https://flashcards.wizardzines.com/tls/">
<div align="center"><img  style="max-width: 400px" src="https://jvns.ca/images/flashcards.png"></div>
</a></p>

<p>Basically &ndash; there are 14ish questions٫ you click the card to see the answer٫
and for each card you categorize it as &ldquo;I knew that!&rdquo;٫ &ldquo;I learned something&rdquo;٫
or &ldquo;that&rsquo;s confusing&rdquo; (which is meant to be a kind of &ldquo;other&rdquo; category٫ where
you didn&rsquo;t know that and you didn&rsquo;t learn anything).</p>

<p>The idea is that the answers contain enough information that you could actually
learn a little bit from them٫ and hopefully be inspired to go learn more on
your own if you&rsquo;re interested.</p>

<h3 id="good-things-about-the-flashcards">good things about the flashcards</h3>

<p>some of the positive feedback I got about the flashcards was:</p>

<ul>
<li>it&rsquo;s fun</li>
<li>people liked being able to reflect on what they learned by the end</li>
<li>they were fast to complete (maybe 3-5 minutes)</li>
</ul>

<h3 id="problems-with-the-flashcards">problems with the flashcards</h3>

<p>But there were some problems that were bothering me٫ too.</p>

<ul>
<li>the word &ldquo;flashcards&rdquo; has a lot baggage I didn&rsquo;t want &ndash; it&rsquo;s strongly
associated with language learning / memorization. I don&rsquo;t use flashcards
myself at all myself so it didn&rsquo;t really resonate with me.</li>
<li>the format was constrained٫ and sometimes I wanted to include more
information in the answer than there was space for</li>
<li>the UI was a bit confusing٫ some people couldn&rsquo;t figure out that you were
supposed to click on the card to flip it.</li>
</ul>

<h3 id="people-dislike-questions-that-don-t-match-their-mental-model">people dislike questions that don&rsquo;t match their mental model</h3>

<p>Probably the most important thing I learned from making these flashcards is
that it really matters how well the question matches the reader&rsquo;s mental model.</p>

<p>I started out by writing questions by taking statements I&rsquo;d normally make about a
topic٫ and turning them into questions. Sometimes this really didn&rsquo;t work.</p>

<p>Here&rsquo;s an example of it not working: I think the statement &ldquo;a HTTP request has
4 parts: a body٫ the headers٫ the request method٫ and the path being requested&rdquo;
is relatively unobjectionable. That how I think about what a HTTP request is.</p>

<p>But what if I ask you &ldquo;what are the 4 parts of a HTTP request?&rdquo; and the answer
is &ldquo;a body٫ the headers٫ the request method٫ and the URL being requested&rdquo;? It
turns out٫ that&rsquo;s totally different!! Not everyone thinks about HTTP requests
as having 4 parts &ndash; they might think of it has having 3 parts (the first line٫
the headers٫ and the body). Or 2 parts and 1 optional part (the first line٫ and
the headers٫ and maybe an optional body). Or some other way! So it&rsquo;s weird to
be asked &ldquo;what are the 4 parts of a HTTP request&rdquo;.</p>

<p>There were a lot of other examples like this٫ where people reacted badly to
some question I asked that didn&rsquo;t match up with how they think about a topic.
So I learned that if I&rsquo;m asking a question٫ it gets held to a higher standard
for how well it matches with the reader&rsquo;s mental model than when making the
same statement.</p>

<p>An example of what I think would be a better question here is &ldquo;Does every HTTP
request have headers?&rdquo; (yes! the HTTP/1.1 RFC requires that the Host header be
set!). But even that is maybe a little tricky &ndash; probably at least one HTTP/1.0
client implementation is out there in the world sending requests without
headers٫ even though 99.99% of HTTP requests have headers.</p>

<p>Of course٫ it&rsquo;s ok if the question/answer doesn&rsquo;t match the reader&rsquo;s mental
model if their mental model is incorrect٫ but if their model is correct then I
think it should match.</p>

<h3 id="get-rid-of-multiple-choice">get rid of multiple choice</h3>

<p>The other thing I learned from these flashcards is that a lot of people dislike
multiple choice. I haven&rsquo;t thought about this that much٫ but honestly I don&rsquo;t
really like multiple choice either so I decided to get rid of it.</p>

<h3 id="next-step-get-reminded-of-the-little-schemer">next step: get reminded of The Little Schemer</h3>

<p>I don&rsquo;t remember why٫ but I&rsquo;ve had The Little Schemer kicking around in my head
for a while. I haven&rsquo;t actually read the whole thing myself٫ but I kept hearing
people talking about it. Here&rsquo;s the first page of The Little Schemer٫ if you
haven&rsquo;t heard of it:</p>

<p><img src="https://jvns.ca/images/little-schemer.png"></p>

<p>This reminded me a lot of what I was trying to do &ndash; there are questions and
answers٫ but the goal isn&rsquo;t for you to get all the questions &ldquo;right&rdquo;.  Instead٫
I think the goal is for you to think about whether you know the answer yet or
not and learn as you go.</p>

<h3 id="switch-to-a-side-by-side-format">switch to a side-by-side format</h3>

<p>So٫ I kept a similar question/answer format٫ but switched to a side-by-side format٫ like the Little Schemer.</p>

<div align="center"><img  style="max-width: 500px" src="https://jvns.ca/images/side-by-side.png"></div>

<p>What I like about putting the questions &amp; answers next to each other:</p>

<ul>
<li>you can see both at the same time٫ so you don&rsquo;t forget what the question was</li>
<li>it then makes more sense to just put all the questions &amp; answers on the same
page٫ so you can easily go back and look at the previous question if you want</li>
</ul>

<p>Basically I like that it gives the reader more control٫ which I think is important.</p>

<h3 id="call-it-questions-instead-of-flashcards">call it &ldquo;questions&rdquo; instead of &ldquo;flashcards&rdquo;</h3>

<p>I also renamed the project to &ldquo;questions&rdquo; because that&rsquo;s really how I think
about learning for myself &ndash; I don&rsquo;t do &ldquo;flashcards&rdquo;٫ but I do constantly ask
myself questions about topics I don&rsquo;t understand٫ figure out the answers to
those questions٫ and then repeat until I understand the topic as well as I want
to.</p>

<p>But coming up with the right questions on your own is hard when you don&rsquo;t a
lot٫ so I&rsquo;m hopeful that providing folks with a bunch of questions (and
answers) to think about will help you decide what you want to learn next.</p>

<h3 id="keep-the-i-learned-something-button">keep the &ldquo;I learned something&rdquo; button</h3>

<p>When I released the first set of questions on UDP٫ I didn&rsquo;t include an &ldquo;I
learned something&rdquo; button٫ and I noticed something weird &ndash; a lot of people
were tweeting things like &ldquo;I got <sup>8</sup>&frasl;<sub>10</sub>&rdquo;٫ &ldquo;I got <sup>10</sup>&frasl;<sub>10</sub>&rdquo;.</p>

<p>I was a bit worried about this because the whole idea was to help people
identify things they could learn٫ so saying &ldquo;I got <sup>8</sup>&frasl;<sub>10</sub>&rdquo; felt like it was
focusing on the things you already knew and ignoring the most important thing
&ndash; the 2 questions where maybe you could learn something new!</p>

<p>So I added an &ldquo;I learned something!&rdquo; button back to each question and spent way
too much time building a fun SVG+CSS animation that played when you pressed the
button. And so far it seems to have worked &ndash; I see more people commenting &ldquo;I
learned something&rdquo; and less &ldquo;I got <sup>9</sup>&frasl;<sub>10</sub>&rdquo;.</p>

<h3 id="building-small-things-is-hard">building small things is hard</h3>

<p>As usual٫ building small simple things takes more time than I&rsquo;d expect! The
concept of &ldquo;some questions and answers&rdquo; seems really simple٫ but I&rsquo;ve already
learned a lot by building this and I think I still have a lot more to learn
about this format.</p>

<p>But I&rsquo;m excited to learn more٫ and I&rsquo;d love to know your thoughts. Here it is
again if you&rsquo;d like to try it: <a href="https://questions.wizardzines.com">https://questions.wizardzines.com</a>.</p>
'),('https://jvns.ca/blog/2020/05/08/metaphors-in-man-pages/', 'Metaphors in man pages', '1588930976000',  6, '

<p>This morning I was watching a <a href="https://www.youtube.com/watch?v=K8MF3aDg-bM&amp;feature=youtu.be&amp;t=14991">great talk by
Maggie Appleton</a>
about metaphors. In the talk٫ she explains the difference between a
&ldquo;figurative metaphor&rdquo; and a &ldquo;cognitive metaphor&rdquo;٫ and references this super interesting book called <a href="https://www.goodreads.com/book/show/34459.Metaphors_We_Live_By">Metaphors We
Live By</a> which
I immediately got and started reading.</p>

<p>Here&rsquo;s an example from &ldquo;Metaphors We Live By&rdquo; of a bunch of metaphors we use
for ideas:</p>

<ul>
<li>ideas as <strong>food</strong>: &ldquo;<em>raw</em> facts&rdquo;٫ &ldquo;<em>half-baked</em> ideas&rdquo;٫ &ldquo;<em>swallow</em> that claim&rdquo;٫ &ldquo;<em>spoon-feed</em> our students&rdquo;٫ &ldquo;<em>meaty</em> part of the paper&rdquo;٫ &ldquo;that idea has been <em>fermenting</em> for years&rdquo;</li>
<li>ideas as <strong>people</strong>: &ldquo;the theory of relativity <em>gave birth</em> to an enormous number of ideas&rdquo;٫ &ldquo;whose <em>brainchild</em> was that&rdquo;٫ &ldquo;those ideas <em>died off</em> in the middle ages&rdquo;٫ &ldquo;cognitive psychology is in its <em>infancy</em>&ldquo;</li>
<li>ideas as <strong>products</strong>: &ldquo;we&rsquo;ve <em>generated</em> a lot of ideas this week&rdquo;٫ &ldquo;it needs to be <em>refined</em>&rdquo;٫ &ldquo;his <em>intellectual productivity</em> has decreased in recent years&rdquo;</li>
<li>ideas as <strong>commodities</strong>: &ldquo;he won&rsquo;t <em>buy</em> that&rdquo;٫ &ldquo;that&rsquo;s a <em>worthless</em> idea&rdquo;٫ &ldquo;she has <em>valuable</em> ideas&rdquo;</li>
<li>ideas as <strong>resources</strong>: &ldquo;he <em>ran out</em> of ideas&rdquo;٫ &ldquo;let&rsquo;s <em>pool</em> our ideas&rdquo;٫ &ldquo;that idea will <em>go a long way</em>&ldquo;</li>
<li>ideas as <strong>cutting instruments</strong>: &ldquo;that&rsquo;s an <em>incisive</em> idea&rdquo;٫ &ldquo;that <em>cuts right to the heart</em> of the matter&rdquo;٫ &ldquo;he&rsquo;s <em>sharp</em>&ldquo;</li>
<li>ideas as <strong>fashions</strong>: &ldquo;that idea <em>went out of style</em> years ago&rdquo;٫ &ldquo;marxism is <em>fashionable</em> in western europe&rdquo;٫ &ldquo;berkeley is a center of <em>avant-garde</em> thought&rdquo;٫ &ldquo;semiotics has become quite <em>chic</em>&ldquo;</li>
</ul>

<p>There&rsquo;s a <a href="https://metaphor.icsi.berkeley.edu/pub/en/index.php/Category:Metaphor">long list of more English metaphors here</a>٫ including many metaphors from the book.</p>

<p>I was surprised that there were so many different metaphors for ideas٫ and that
we&rsquo;re using metaphors like this all the time in normal language.</p>

<h3 id="let-s-look-for-metaphors-in-man-pages">let&rsquo;s look for metaphors in man pages!</h3>

<p>Okay٫ let&rsquo;s get to the point of this blog post٫ which is just a small fun
exploration &ndash; there aren&rsquo;t going to be any Deep Programming Insights here.</p>

<p>I went through some of the examples of metaphors in Metaphors To Live By and
grepped all the man pages on my computer for them.</p>

<h3 id="processes-as-people">processes as people</h3>

<p>This is one of the richer categories &ndash; a lot of different man pages seem to
agree that processes are people٫ or at least alive in some way.</p>

<ul>
<li>Hangup detected on controlling terminal or <strong>death</strong> of controlling process <span class="nowrap">(<code>man 7 signal</code>)</span></li>
<li>can access the local <strong>agent</strong> through the forwarded connection <span class="nowrap">(<code>man ssh_config</code>)</span></li>
<li>If the exit of the process causes a process group to become <strong>orphaned</strong> <span class="nowrap">(<code>man exit</code>)</span></li>
<li>If a parent process terminates٫ then its <strong>&ldquo;zombie&rdquo; children</strong> (if any) <span class="nowrap">(<code>man wait</code>)</span></li>
<li>&hellip; send SIGHUP to the <strong>parent</strong> process of the client <span class="nowrap">(<code>man tmux</code>)</span></li>
<li>Otherwise٫ it <strong>&ldquo;runs&rdquo; to catch up</strong> or waits <span class="nowrap">(<code>man mplayer</code>)</span></li>
<li>However٫ Git does not (and it should not) change tags <strong>behind users back</strong> (<code>man git-tag</code>)</li>
<li>will <strong>listen</strong> forever for a connection <span class="nowrap">(<code>man nc_openbsd</code>)</span></li>
<li>this monitor scales badly with the number of files being <strong>observed</strong> <span class="nowrap">(<code>man fswatch</code>)</span></li>
<li>If you try to use the <strong>birth</strong> time of a reference file <span class="nowrap">(<code>man file</code>)</span></li>
<li>a program <strong>died</strong> due to a fatal signal <span class="nowrap">(<code>man xargs</code>)</span></li>
<li>protocol version in the TLS <strong>handshake</strong> <span class="nowrap">(<code>man curl</code>)</span></li>
<li>it will <strong>look for</strong> a debug object at&hellip; <span class="nowrap">(<code>man valgrind</code>)</span></li>
</ul>

<h3 id="data-as-food">data as food</h3>

<ul>
<li>&ldquo;Apparently some digital cameras get <strong>indigestion</strong> if you feed them a CF card) <span class="nowrap">(<code>man mkfs</code>)</span></li>
<li>&ldquo;Send packets using <strong>raw</strong> ethernet frames or IP packets&rdquo; <span class="nowrap">(<code>man nmap</code>)</span></li>
<li>&ldquo;the above example can be thought of as a maximizing repeat that must <strong>swallow</strong> everything it can&rdquo; <span class="nowrap">(<code>man pcrepattern</code>)</span></li>
<li>&ldquo;This will allow you to <strong>feed</strong> newline-delimited name=value pairs to the script on&rsquo; <span class="nowrap">(<code>man CGI</code>)</span></li>
</ul>

<h3 id="data-as-objects">data as objects</h3>

<ul>
<li>Kill the tmux server and clients and <strong>destroy</strong> all sessions <span class="nowrap">(<code>tmux</code>)</span></li>
<li>Each command will produce one <strong>block</strong> of output on standard output. <span class="nowrap">(<code>man tmux</code>)</span></li>
<li>&ldquo;HTTPS guarantees that the password will not <strong>travel</strong> in the clear&rdquo; <span class="nowrap">(<code>man Net::SSLeay</code>)</span></li>
<li>&ldquo;way to <strong>pack</strong> more than one certificate into an ASN.1 structure&rdquo; <span class="nowrap">(<code>man gpgsm</code>)</span></li>
</ul>

<h3 id="processes-as-machines-objects">processes as machines/objects</h3>

<ul>
<li>&ldquo;This is <strong>fragile</strong>٫ subject to change٫ and thus should not be relied upon&rdquo; <span class="nowrap">(<code>man ps</code>)</span></li>
<li>&ldquo;This is useful if you have to use <strong>broken</strong> DNS&rdquo; <span class="nowrap">(<code>man aria2c</code>)</span></li>
<li>&ldquo;This provides good safety measures٫ but <strong>breaks down</strong> when&rdquo; <span class="nowrap">(<code>man git-apply</code>)</span></li>
<li>&ldquo;debugfs is a debugging tool. It has <strong>rough edges</strong>!&rdquo; <span class="nowrap">(<code>man debugfs</code>)</span></li>
</ul>

<h3 id="containers">containers</h3>

<p>There are LOTS of containers: directories٫ files٫ strings٫ caches٫ queues٫
buffers٫ etc.</p>

<ul>
<li>can exploit that to <strong>get out</strong> of the chroot directory <span class="nowrap">(<code>man chroot</code>)</span></li>
<li>&ldquo;The file <strong>containing</strong> the RFC 4648 Section 5 base64url encoded 128-bit secret key&rdquo;</li>
<li>&ldquo;Keys must start with a lowercase character and <strong>contain</strong> only hyphens&rdquo;</li>
<li>&ldquo;just specify an <strong>empty</strong> string&rdquo; <span class="nowrap">(<code>man valgrind</code>)</span></li>
<li>&ldquo;the cache is <strong>full</strong> and a new page that isn’t cached becomes visible&rdquo; <span class="nowrap">(<code>man zathurarc</code>)</span></li>
<li>&ldquo;Number of table <strong>overflows</strong>&rdquo; <span class="nowrap">(<code>man lnstat</code>)</span></li>
<li>&ldquo;likely <strong>overflow</strong> the buffer&rdquo; <span class="nowrap">(<code>man g++</code>)</span></li>
</ul>

<h3 id="resources">resources</h3>

<p>There are also lots of kinds of resources: bandwidth٫ TCP sockets٫ session IDs٫
stack space٫ memory٫ disk space.</p>

<ul>
<li>This is not recommended and <strong>wastes</strong> bitrate <span class="nowrap">(<code>man bitrate</code>)</span></li>
<li>corruption or <strong>lost</strong> data if the system crashes <span class="nowrap">(<code>man btree</code>)</span></li>
<li>you don&rsquo;t want Wget to <strong>consume</strong> the entire available bandwidth <span class="nowrap">(<code>man wget</code>)</span></li>
<li>Larger values will be slower and cause x264 to <strong>consume</strong> more memory <span class="nowrap">(<code>man mplayer</code>)</span></li>
<li>the resulting file can <strong>consume</strong> some disk space <span class="nowrap">(<code>man socat</code>)</span></li>
<li>attempting to <strong>reuse</strong> SSL session-ID <span class="nowrap">(<code>man curl</code>)</span></li>
<li>This option controls stack space <strong>reuse</strong> <span class="nowrap">(<code>man gcc</code>)</span></li>
<li>Keep the TCP socket open between queries and <strong>reuse</strong> it rather than creating a new TCP socket <span class="nowrap">(<code>man dig</code>)</span></li>
<li>the maximum value will easily <strong>eat up</strong> three extra gigabytes or so of memory <span class="nowrap">(<code>man valgrind</code>)</span></li>
</ul>

<h3 id="orientation-up-down-above-below">orientation (up٫ down٫ above٫ below)</h3>

<ul>
<li>Send the escape character to the <strong>frontend</strong> <span class="nowrap">(<code>man qemu-system</code>)</span></li>
<li>Note that TLS 1.3 is only supported by a subset of TLS <strong>backends</strong> <span class="nowrap">(<code>man curl</code>)</span></li>
<li>This option may be useful if you are <strong>behind</strong> a router <span class="nowrap">(<code>man mplayer</code>)</span></li>
<li>When a file that exists on the <strong>lower</strong> layer is renamed <span class="nowrap">(<code>man rename</code>)</span></li>
<li>Several of the socket options should be handled at <strong>lower</strong> levels  <span class="nowrap">(<code>man getsockopt</code>)</span></li>
<li>while still performing such <strong>higher</strong> level functionality <span class="nowrap">(<code>man nmap</code>)</span></li>
<li>This is the same string passed <strong>back to</strong> the front end <span class="nowrap">(<code>man sudo_plugin</code>)</span></li>
<li>On Linux٫ <code>futimens</code> is a library function implemented <strong>on top</strong> of the <code>utimensat</code> system call <span class="nowrap">(<code>man futimens</code>)</span></li>
</ul>

<h3 id="buildings">buildings</h3>

<p>Limits as rooms/buildings (which have floors٫ and ceilings٫ which you hit) are kind of fun:</p>

<ul>
<li>the kernel places a <strong>floor</strong> of 32 pages on this size limit <span class="nowrap">(<code>man execve</code>)</span></li>
<li>This specifies a <strong>ceiling</strong> to which the process&rsquo;s nice value can be raised <span class="nowrap">(<code>man getrlimit</code>)</span></li>
<li>If this limit is <strong>hit</strong> the search is aborted <span class="nowrap">(<code>man gcc</code>)</span></li>
<li>these libraries are used as the <strong>foundation</strong> for many of the libraries <span class="nowrap">(<code>man Glib</code>)</span></li>
</ul>

<h3 id="money-wealth">money / wealth</h3>

<ul>
<li>This is a very <strong>expensive</strong> operation for large projects٫ so use it with caution <span class="nowrap">(<code>man git-log</code>)</span></li>
<li>Note that since this operation is very I/O <strong>expensive</strong> <span class="nowrap">(<code>man git-filter-branch</code>)</span></li>
<li>provides a <strong>rich</strong> interface for scripts to print disk layouts <span class="nowrap">(<code>man fdisk</code>)</span></li>
<li>The number of times the softirq handler function terminated per second because its <strong>budget</strong> was consumed <span class="nowrap">(<code>man sar.sysstat</code>)</span></li>
<li>the extra <strong>cost</strong> depends a lot on the application at hand <span class="nowrap">(<code>man valgrind</code>)</span></li>
</ul>

<h3 id="more-miscellaneous-metaphors">more miscellaneous metaphors</h3>

<p>here are some more I found that didn&rsquo;t fit into any of those categories yet.</p>

<ul>
<li>when a thread is created under glibc٫ just one <strong>big</strong> lock is used for all thread setup <span class="nowrap">(<code>man valgrind</code>)</span></li>
<li>will likely <strong>drop</strong> the connection <span class="nowrap">(<code>man x11vnc</code>)</span></li>
<li>on all <strong>paths</strong> from the load to the function entry <span class="nowrap">(<code>man gcc</code>)</span></li>
<li>it is a very good idea to <strong>wipe</strong> filesystem signatures٫ data٫ etc. before <span class="nowrap">(<code>man cryptsetup</code>)</span></li>
<li>they will be <strong>embedded</strong> into the document</li>
<li>the client should automatically <strong>follow</strong> referrals returned</li>
<li>even if there exist mappings that <strong>cover</strong> the whole address space requested <span class="nowrap">(<code>man mremap</code>)</span></li>
<li>when a network interface <strong>disappears</strong> <span class="nowrap">(<code>man systemd-resolve</code>)</span></li>
</ul>

<h3 id="we-re-all-using-metaphors-all-the-time">we&rsquo;re all using metaphors all the time</h3>

<p>I found a lot more metaphors than I expected٫ and most of them are just part of
how I&rsquo;d normally talk about a program. Interesting!</p>

<style>
.nowrap {
    white-space: nowrap;
    padding: 0px;
}
</style>
'),('https://jvns.ca/blog/2020/04/29/why-strace-doesnt-work-in-docker/', 'Why strace doesn"t work in Docker', '1588146932000',  6, '

<p>While editing the capabilities page of the <a href="https://wizardzines.com/zines/containers">how containers work</a> zine٫ I found myself
trying to explain why <code>strace</code> doesn&rsquo;t work in a Docker container.</p>

<p>The problem here is &ndash; if I run <code>strace</code> in a Docker container on my laptop٫ this happens:</p>

<pre><code>$ docker run  -it ubuntu:18.04 /bin/bash
$ # ... install strace ...
root@e27f594da870:/# strace ls
strace: ptrace(PTRACE_TRACEME٫ ...): Operation not permitted
</code></pre>

<p>strace works using the <code>ptrace</code> system call٫ so if <code>ptrace</code> isn&rsquo;t
allowed٫ it&rsquo;s definitely not gonna work! This is pretty easy to fix &ndash; on
my machine٫ this fixes it:</p>

<pre><code>docker run --cap-add=SYS_PTRACE  -it ubuntu:18.04 /bin/bash
</code></pre>

<p>But I wasn&rsquo;t interested in fixing it٫ I wanted to know why it happens. So
why does strace not work٫ and why does <code>--cap-add=SYS_PTRACE</code> fix it?</p>

<h3 id="hypothesis-1-container-processes-are-missing-the-cap-sys-ptrace-capability">hypothesis 1: container processes are missing the <code>CAP_SYS_PTRACE</code> capability</h3>

<p>I always thought the reason was that Docker container processes by
default didn&rsquo;t have the <code>CAP_SYS_PTRACE</code> capability. This is consistent
with it being fixed by <code>--cap-add=SYS_PTRACE</code>٫ right?</p>

<p>But this actually doesn&rsquo;t make sense for 2 reasons.</p>

<p><strong>Reason 1</strong>: Experimentally٫ as a regular user٫ I can strace on any process run by my
user. But if I check if my current process has the <code>CAP_SYS_PTRACE</code> capability٫ I don&rsquo;t:</p>

<pre><code>$ getpcaps $$
Capabilities for `11589": =
</code></pre>

<p><strong>Reason 2</strong>: <code>man capabilities</code> says this about <code>CAP_SYS_PTRACE</code>:</p>

<pre><code>CAP_SYS_PTRACE
       * Trace arbitrary processes using ptrace(2);
</code></pre>

<p>So the point of <code>CAP_SYS_PTRACE</code> is to let you ptrace <strong>arbitrary</strong>
processes owned by any user٫ the way that root usually can. You shouldn&rsquo;t
need it to just ptrace a regular process owned by your user.</p>

<p>And I tested this a third way &ndash; I ran a Docker container with <code>docker
run --cap-add=SYS_PTRACE  -it ubuntu:18.04 /bin/bash</code>٫ dropped the
<code>CAP_SYS_PTRACE</code> capability٫ and I could still strace processes even
though I didn&rsquo;t have that capability anymore. What? Why?</p>

<h3 id="hypothesis-2-something-about-user-namespaces">hypothesis 2: something about user namespaces???</h3>

<p>My next (much less well-founded) hypothesis was something along the lines
of &ldquo;um٫ maybe the process is in a different user namespace and strace
doesn&rsquo;t work because of&hellip; reasons?&rdquo; This isn&rsquo;t really coherent but
here&rsquo;s what happened when I looked into it.</p>

<p>Is the container process in a different user namespace? Well٫ in the container:</p>

<pre><code>root@e27f594da870:/# ls /proc/$$/ns/user -l
... /proc/1/ns/user -&gt; "user:[4026531837]"
</code></pre>

<p>On the host:</p>

<pre><code>bork@kiwi:~$ ls /proc/$$/ns/user -l
... /proc/12177/ns/user -&gt; "user:[4026531837]"
</code></pre>

<p>Because the user namespace ID (<code>4026531837</code>) is the same٫ the root user
in the container is the exact same user as the root user on the host. So
there&rsquo;s definitely no reason it shouldn&rsquo;t be able to strace processes
that it created!</p>

<p>This hypothesis doesn&rsquo;t make much sense but I hadn&rsquo;t realized that the
root user in a Docker container is the same as the root user on the host٫
so I thought that was interesting.</p>

<h3 id="hypothesis-3-the-ptrace-system-call-is-being-blocked-by-a-seccomp-bpf-rule">hypothesis 3: the ptrace system call is being blocked by a seccomp-bpf rule</h3>

<p>I also knew that Docker uses seccomp-bpf to stop container processes from
running a lot of system calls. And ptrace is in the <a href="https://docs.docker.com/engine/security/seccomp/">list of system calls
blocked by Docker&rsquo;s default seccomp
profile</a>! (actually the
list of allowed system calls is a whitelist٫ so it&rsquo;s just that ptrace is
not in the default whitelist. But it comes out to the same thing.)</p>

<p>That easily explains why strace wouldn&rsquo;t work in a Docker container &ndash; if
the <code>ptrace</code> system call is totally blocked٫ then of course you can&rsquo;t
call it at all and strace would fail.</p>

<p>Let&rsquo;s verify this hypothesis &ndash; if we disable all seccomp rules٫ can we
strace in a Docker container?</p>

<pre><code>$ docker run --security-opt seccomp=unconfined -it ubuntu:18.04  /bin/bash
$ strace ls
execve(&quot;/bin/ls&quot;٫ [&quot;ls&quot;]٫ 0x7ffc69a65580 /* 8 vars */) = 0
... it works fine ...
</code></pre>

<p>Yes! It works! Great. Mystery solved٫ except&hellip;</p>

<h3 id="why-does-cap-add-sys-ptrace-fix-the-problem">why does <code>--cap-add=SYS_PTRACE</code> fix the problem?</h3>

<p>What we still haven&rsquo;t explained is: why does <code>--cap-add=SYS_PTRACE</code> would
fix the problem?</p>

<p>The man page for <code>docker run</code> explains the <code>--cap-add</code> argument this way:</p>

<pre><code>--cap-add=[]
   Add Linux capabilities
</code></pre>

<p>That doesn&rsquo;t have anything to do with seccomp rules! What&rsquo;s going on?</p>

<h3 id="let-s-look-at-the-docker-source-code">let&rsquo;s look at the Docker source code.</h3>

<p>When the documentation doesn&rsquo;t help٫ the only thing to do is go look at
the source.</p>

<p>The nice thing about Go is٫ because dependencies are often vendored in a
Go repository٫ you can just grep the repository to figure out where the
code that does a thing is. So I cloned <code>github.com/moby/moby</code> and grepped
for some things٫ like <code>rg CAP_SYS_PTRACE</code>.</p>

<p>Here&rsquo;s what I think is going on. In containerd&rsquo;s seccomp implementation٫ in
<a href="https://github.com/containerd/containerd/blob/4be98fa28b62e8a012491d655a4d6818ef87b080/contrib/seccomp/seccomp_default.go#L527-L537">contrib/seccomp/seccomp_default.go</a>٫
there&rsquo;s a bunch of code that makes sure that if a process has a
capability٫ then it&rsquo;s also given access (through a seccomp rule) to use
the system calls that go with that capability.</p>

<pre><code>		case &quot;CAP_SYS_PTRACE&quot;:
			s.Syscalls = append(s.Syscalls٫ specs.LinuxSyscall{
				Names: []string{
					&quot;kcmp&quot;٫
					&quot;process_vm_readv&quot;٫
					&quot;process_vm_writev&quot;٫
					&quot;ptrace&quot;٫
				}٫
				Action: specs.ActAllow٫
				Args:   []specs.LinuxSeccompArg{}٫
			})
</code></pre>

<p>There&rsquo;s some other code that seems to do something very similar in
<a href="https://github.com/moby/moby/blob/cc0dfb6e7b22ad120c60a9ce770ea15415767cf9/profiles/seccomp/seccomp.go#L126-L132">profiles/seccomp/seccomp.go</a>
in moby and the <a href="https://github.com/moby/moby/blob/master/profiles/seccomp/default.json#L723-L739">default seccomp
profile</a>٫
so it&rsquo;s possible that that&rsquo;s what&rsquo;s doing it instead.</p>

<p>So I think we have our answer!</p>

<h3 id="cap-add-in-docker-does-a-little-more-than-what-it-says"><code>--cap-add</code> in Docker does a little more than what it says</h3>

<p>The upshot seems to be that <code>--cap-add</code> doesn&rsquo;t do exactly what it says
it does in the man page٫ it&rsquo;s more like
<code>--cap-add-and-also-whitelist-some-extra-system-calls-if-required</code>. Which makes
sense! If you have a capability like <code>CAP_SYS_PTRACE</code> which is supposed
to let you use the <code>process_vm_readv</code> system call but that system call is
blocked by a seccomp profile٫ that&rsquo;s not going to help you much!</p>

<p>So allowing the <code>process_vm_readv</code> and <code>ptrace</code> system calls when you
give the container <code>CAP_SYS_PTRACE</code> seems like a reasonable choice.</p>

<h3 id="strace-actually-does-work-in-newer-versions-of-docker">strace actually does work in newer versions of Docker</h3>

<p>As of <a href="https://github.com/moby/moby/commit/1124543ca8071074a537a15db251af46a5189907">this commit</a> (docker 19.03)٫ Docker does actually allow the <code>ptrace</code> system calls for kernel versions newer than 4.8.</p>

<p>But the Docker version on my laptop is 18.09.7٫ so it predates that commit.</p>

<h3 id="that-s-all">that&rsquo;s all!</h3>

<p>This was a fun small thing to investigate٫ and I think it&rsquo;s a nice
example of how containers are made of lots of moving pieces that work
together in not-completely-obvious ways.</p>

<p>If you liked this٫ you might like my new zine called <a href="https://wizardzines.com/zines/containers">How Containers Work</a> that explains the Linux kernel features that make containers work in 24 pages. You can read the pages on <a href="https://wizardzines.com/comics/capabilities/">capabilities</a> and <a href="https://wizardzines.com/comics/seccomp-bpf/">seccomp-bpf</a> from the zine.</p>

<div align="center">
<a href="https://wizardzines.com/zines/containers"><img width="300px" src="https://jvns.ca/images/containers-cover.jpg"></a>
</div>
'),('https://jvns.ca/blog/2020/04/27/new-zine-how-containers-work/', 'New zine: How Containers Work!', '1587992557000',  6, '

<p>On Friday I published a new zine: &ldquo;How Containers Work!&rdquo;. I also launched a
fun redesign of <a href="https://wizardzines.com">wizardzines.com</a>.</p>

<p>You can get it for $12 at <a href="https://wizardzines.com/zines/containers">https://wizardzines.com/zines/containers</a>. If you buy it٫ you&rsquo;ll get a PDF that you can
either print out or read on your computer. Or you can get a pack of <a href="https://wizardzines.com/zines/all-the-zines/">all 8 zines</a> so far.</p>

<p>Here&rsquo;s the cover and table of contents:</p>

<div align="center">
<a href="https://wizardzines.com/zines/containers"><img width="400px" src="https://jvns.ca/images/containers-cover.jpg"></a>
<a href="https://jvns.ca/images/containers-toc.png"><img width="400px" src="https://jvns.ca/images/containers-toc.png"></a>
</div>

<h3 id="why-containers">why containers?</h3>

<p>I&rsquo;ve spent a lot of time
<a href="https://stripe.com/en-ca/blog/operating-kubernetes">figuring</a>
<a href="https://jvns.ca/blog/2016/09/15/whats-up-with-containers-docker-and-rkt/">out</a>
<a href="https://jvns.ca/blog/2016/10/10/what-even-is-a-container/">how to</a>
<a href="https://jvns.ca/blog/2016/12/22/container-networking/">run</a>
<a href="https://jvns.ca/blog/2016/10/26/running-container-without-docker/">things</a>
<a href="https://jvns.ca/blog/2017/02/17/mystery-swap/">in</a>
<a href="https://jvns.ca/blog/2016/10/02/a-list-of-container-software/">containers</a>
over the last 3-4 years. And at the beginning I was really confused! I knew a
bunch of things about Linux٫ and containers didn&rsquo;t seem to fit in with anything
I thought I knew (&ldquo;is it a process? what&rsquo;s a network namespace? what&rsquo;s
happening?&ldquo;). The whole thing seemed really weird.</p>

<p>It turns out that containers ARE actually pretty weird. They’re not just
one thing٫ they’re what you get when you glue together 6 different features
that were mostly designed to work together but have a bunch of confusing edge
cases.</p>

<p>As usual٫ the thing that helped me the most in my container adventures is a
good understanding of the <strong>fundamentals</strong> &ndash; what exactly is actually
happening on my server when I run a container?</p>

<p>So that&rsquo;s what this zine is about &ndash; cgroups٫ namespaces٫ pivot_root٫
seccomp-bpf٫ and all the other Linux kernel features that make containers work.</p>

<p>Once I understood those ideas٫ it got a <strong>lot</strong> easier to debug when my
containers were doing surprising things in production. I learned a couple of
interesting and strange things about containers while writing this zine too &ndash;
I&rsquo;ll probably write a blog post about one of them later this week.</p>

<h3 id="containers-aren-t-magic">containers aren&rsquo;t magic</h3>

<p>This picture (page 6 of the zine) shows you how to run a fish container image
with only 15 lines of bash. This is heavily inspired by
<a href="https://github.com/p8952/bocker">bocker</a>٫ which &ldquo;implements&rdquo; Docker in about
100 lines of bash.</p>

<div align="center">
<a href="https://jvns.ca/images/containers-arent-magic.jpg"><img width="400px" src="https://jvns.ca/images/containers-arent-magic.jpg"></a>
</div>

<p>The main things I see missing from that script compared to what Docker actually does when running a container (other than using an actual container image and not just a tarball) are:</p>

<ul>
<li>it doesn&rsquo;t drop any capabilities &ndash; the container is still running as root and has full root privileges (just in a different mount + PID namespace)</li>
<li>it doesn&rsquo;t block any system calls with seccomp-bpf</li>
</ul>

<h3 id="container-command-line-tools">container command line tools</h3>

<p>The zine also goes over a bunch of command line tools &amp; files that you can
use to inspect running containers or play with Linux container features. Here&rsquo;s a list:</p>

<ul>
<li><code>mount -t overlay</code> (create and view overlay filesystems)</li>
<li><code>unshare</code> (create namespaces)</li>
<li><code>nsenter</code> (use an existing namespace)</li>
<li><code>getpcaps</code> (get a process&rsquo;s capabilities)</li>
<li><code>capsh</code> (drop or add capabilities٫ etc)</li>
<li><code>cgcreate</code> (create a cgroup)</li>
<li><code>cgexec</code> (run a command in an existing cgroup)</li>
<li><code>chroot</code> (change root directory. not actually what containers use but interesting to play with anyway)</li>
<li><code>/sys/fs/cgroups</code> (for information about cgroups٫ like <code>memory.usage_in_bytes</code>)</li>
<li><code>/proc/PID/ns</code> (all a process&rsquo;s namespaces)</li>
<li><code>lsns</code> (another way to view namespaces)</li>
</ul>

<p>I also made a short youtube video a while back called <a href="https://www.youtube.com/watch?v=YCVSdnYzH34&amp;t=1s">ways to spy on a Docker container</a> that demos some of these command line tools.</p>

<h3 id="container-runtime-agnostic">container runtime agnostic</h3>

<p>I tried to keep this zine pretty container-runtime-agnostic &ndash; I mention Docker
a couple of times because it&rsquo;s so widely used٫ but it&rsquo;s about the Linux kernel
features that make containers work in general٫ not Docker or LXC or
systemd-nspawn or Kubernetes or whatever. If you understand the fundamentals
you can figure all those things out!</p>

<h3 id="we-redesigned-wizardzines-com">we redesigned wizardzines.com!</h3>

<p>On Friday I also launched a redesign of
<a href="https://wizardzines.com">wizardzines.com</a>! <a href="https://melody.dev">Melody Starling</a> (who is amazing) did the design. I think now it&rsquo;s
better organized but the tiny touch that I&rsquo;m most delighted by is that now the zines jump with joy when
you hover over them.</p>

<p>One cool thing about working with a designer is &ndash; they don&rsquo;t just
make things <em>look</em> better٫ they help <em>organize</em> the information better so the
website makes more sense and it&rsquo;s easier to find things! This is probably obvious to anyone who knows anything about design
but I haven&rsquo;t worked with designers very much (or maybe ever?) so it was really cool to see.</p>

<p>One tiny example of this: Melody had the idea of adding a tiny FAQ on the
landing page for each zine٫ where I can put the answers to all the questions
people always ask! Here&rsquo;s what the little FAQ box looks like:</p>

<div align="center">
<a href="https://wizardzines.com/zines/containers"><img src="https://jvns.ca/images/wizardzines-faq.png" width="200px"></a>
</div>

<p>I probably want to edit those questions &amp; answers over time but it&rsquo;s SO NICE to have
somewhere to put them.</p>

<h3 id="what-s-next-maybe-debugging-or-working-more-on-flashcards">what&rsquo;s next: maybe debugging! or working more on flashcards!</h3>

<p>The two projects I&rsquo;m thinking about the most right now are</p>

<ol>
<li>a zine about debugging٫ which I started last summer and haven&rsquo;t gotten around to finishing yet</li>
<li>a <a href="https://flashcards.wizardzines.com">flashcards project</a> that I&rsquo;ve been adding to slowly over the last couple of months. I think could become a nice way to explain basic ideas.</li>
</ol>

<p><br><br>
Here&rsquo;s a link to where to <a href="https://wizardzines.com/zines/containers">get the zine</a> again :)</p>
'),('https://jvns.ca/blog/debugging-attitude-matters/', 'When debugging٫ your attitude matters', '1585837591000',  6, '

<p>A while back I wrote <a href="https://jvns.ca/blog/2019/06/23/a-few-debugging-resources/">What does debugging a program look like?</a> on what to do when debugging (change one thing at a time! check your assumptions!).</p>

<p>But I was debugging some CSS last week٫ and I think that post is missing
something important: <strong>your attitude</strong>.</p>

<p>Now &ndash; I&rsquo;m not a very good CSS developer yet. I&rsquo;ve never written CSS
professionally and I don&rsquo;t understand a lot of basic CSS concepts (I think I
finally understood for the first time recently how <code>position: absolute</code> works). And last
week I was working on the most complicated CSS project I&rsquo;d ever attempted.</p>

<p>While I was debugging my CSS٫ I noticed myself doing some bad things that I
normally would not! I was:</p>

<ul>
<li>making random changes to my code in the hopes that it would work</li>
<li>googling a lot of things and trying them without understanding what they did</li>
<li>if something broke٫ reverting my changes and starting again</li>
</ul>

<p>This strategy was exactly as effective as you might imagine (not very
effective!)٫ and it was because of my attitude about CSS! I had this
unusual-for-me belief that CSS was Too Hard and impossible for me to
understand. So let&rsquo;s talk about that attitude a bit!</p>

<h3 id="the-problem-attitude-this-is-too-hard-for-me-to-understand">the problem attitude: &ldquo;this is too hard for me to understand&rdquo;</h3>

<p>One specific problem I was having was &ndash; I had 2 divs stacked on top of one another٫ and
I wanted Div A to be on top of Div B.  My model of CSS stacking order at the
start of this was basically &ldquo;if you want Thing A to be on top of Thing B٫
change the z-index to make it work&rdquo;. So I changed the z-index of Div A to be 5
or something.</p>

<p>But it didn&rsquo;t work! In Firefox٫ div A was on top٫ but in Chrome٫ Div B was on
top. Argh! Why? CSS is impossible!!! (<small>if you want to see the exact actual situation I was in٫ I <a href="https://codepen.io/jvns-css-fun/pen/zYGVLXj">reproduced the different-in-firefox-and-chrome thing here after the fact</a></small>)</p>

<p>I googled a bit٫ and I found out that a possible reason z-index might not work
was because Div A and Div B were actually in different &ldquo;stacking contexts&rdquo;. If
that was true٫ even if I set the z-index of Div A to 999999 it would still not
put it on top of Div B. (<a href="https://codepen.io/jvns-css-fun/pen/YzXMMdQ">here&rsquo;s a small example of what this z-index problem looks like٫ though I think my specific bug had some extra complications</a>)</p>

<p>I thought &ldquo;man٫ this stacking context thing seems really complicated٫ why is it
different between Firefox and Chrome٫ I&rsquo;m not going to be able to figure this
out&rdquo;. So I tried a bunch of random things a bunch of blog posts suggested٫
which as usual did not work.</p>

<p>Finally I gave up this &ldquo;change random things and pray&rdquo; strategy and thought &ldquo;well٫ what
if I just read the documentation on stacking order٫ maybe it&rsquo;s not that bad&rdquo;.</p>

<p>So I read the <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Positioning/Understanding_z_index/Stacking_without_z-index">MDN page on stacking order</a>٫ which says:</p>

<blockquote>
<p>When the z-index property is not specified on any element٫ elements are stacked in the following order (from bottom to top): <br>
1. The background and borders of the root element <br>
2. Descendant non-positioned blocks٫ in order of appearance in the HTML <br>
3. Descendant positioned elements٫ in order of appearance in the HTML</p>
</blockquote>

<p>This is SO SIMPLE! It just depends on the order in the HTML! I put Div A after
Div B in the HTML (as a sibling) and it made everything work in both browsers.</p>

<h3 id="better-attitude-let-s-learn-the-basics-and-see-if-that-helps">better attitude: &ldquo;let&rsquo;s learn the basics and see if that helps&rdquo;</h3>

<p>This whole stacking problem turned out to really not be that complicated &ndash; all I
needed to do was read a very short and simple documentation page to understand how stacking works!</p>

<p>Of course٫ computer things are not always this simple (and even in this
specific case the <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Positioning/Understanding_z_index/The_stacking_context">rules about what creates a new stacking
context</a>
are pretty complicated.). But I did not need to understand those more complicated rules in order to put Div A on top of Div B! I only needed to know the much simpler 3 rules above.</p>

<p>So &ndash; calm down for a second٫ learn a few of the basics٫ and see if that helps.</p>

<h3 id="watching-people-who-know-what-they-re-doing-is-inspiring">watching people who know what they&rsquo;re doing is inspiring</h3>

<p>Another area of CSS that I thought was &ldquo;too hard&rdquo; for me to understand was this
whole <code>position: absolute</code> and <code>position: relative</code> business.  I kept seeing
(and sometimes using!) examples where people made complicated CSS things with
<code>position: absolute</code> but I didn&rsquo;t understand how they worked. Doesn&rsquo;t <code>position: absolute</code> mean that the element is always in the same place on the screen? Why are these <code>position: absolute</code> things moving when I scroll like the rest of the document? (spoiler: no٫ that&rsquo;s <code>position: fixed</code>.)</p>

<p>But last week٫ I paired with someone who&rsquo;s a lot better at CSS than me on some
code٫ and I saw that they were just typing in <code>position: absolute</code> and
<code>position: relative</code> confidently into their code without seeming confused about
it!! Could that be me?</p>

<p>I looked up the <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/position">documentation on MDN</a> on <code>position: absolute</code>٫ and it said:</p>

<blockquote>
<p>The element is removed from the normal document flow٫ and no space is created
for the element in the page layout. It is positioned relative to its closest
positioned ancestor&hellip; Its final position is determined by the values of top٫ right٫ bottom٫ and left.</p>
</blockquote>

<p>So things with <code>position: absolute</code> are positioned relative to their closest
positioned ancestor! And you just use <code>top/bottom/right/left</code> to pick where!
That&rsquo;s so simple!</p>

<h3 id="documentation-that-you-can-trust-makes-a-big-difference">documentation that you can trust makes a big difference</h3>

<p>I think another big source of my frustration with CSS is that I didn&rsquo;t have the
best grasp of where to find accurate information &amp; advice. I knew that MDN was a reliable
reference٫ but MDN doesn&rsquo;t really help answer questions like &ldquo;ok but seriously
how do I center a div???&rdquo; and I found myself reading a lot of random Stack Overflow
answers/blog posts that I wasn&rsquo;t 100% sure were correct.</p>

<p>This week I learned about <a href="https://css-tricks.com">CSS Tricks</a> which has a lot
of GREAT articles like <a href="https://css-tricks.com/centering-css-complete-guide/">Centering in CSS: A Complete Guide</a> which seems very reputable and is written
in a super clear way.</p>

<h3 id="that-s-all">that&rsquo;s all!</h3>

<p>I don&rsquo;t really know why I started to believe that it was &ldquo;impossible&rdquo; to
understand basic CSS concepts since I don&rsquo;t believe that about computers in
general. Maybe because I&rsquo;ve been writing CSS at a beginner level for a very
long time but hadn&rsquo;t ever really tried to do a more involved CSS project than
&ldquo;let&rsquo;s arrange some divs in a grid with flexbox&rdquo;!</p>

<p>But this attitude really got in the way of me writing the CSS I wanted to
write!  And once I let go of it and used my normal debugging techniques I was
able to get a lot more things to work the way I wanted.</p>
'),('https://jvns.ca/blog/2020/03/15/writing-shaders-with-signed-distance-functions/', 'Getting started with shaders: signed distance functions!', '1584277686000',  6, '

<p>Hello! A while back I learned how to make fun shiny spinny things like this
using shaders:</p>

<div align="center">
<img src="https://jvns.ca/images/spinny.gif" width="150px">
</div>

<p>My shader skills are still extremely basic٫ but this fun spinning thing turned out to be a lot
easier to make than I thought it would be to make (with a lot of copying of
code snippets from other people!).</p>

<p>The big idea I learned when doing this was something called &ldquo;signed distance
functions&rdquo;٫ which I learned about from a very fun tutorial called <a href="https://www.shadertoy.com/view/Xl2XWt">Signed Distance Function
tutorial: box &amp; balloon</a>.</p>

<p>In this post I&rsquo;ll go through the steps I used to learn to write a simple shader
and try to convince you that shaders are not that hard to get started with!</p>

<h3 id="examples-of-more-advanced-shaders">examples of more advanced shaders</h3>

<p>If you haven&rsquo;t seen people do really fancy things with shaders٫ here are a couple:</p>

<ol>
<li>this very complicated shader that is like a realistic video of a river: <a href="https://www.shadertoy.com/view/Xl2XRW">https://www.shadertoy.com/view/Xl2XRW</a></li>
<li>a more abstract (and shorter!) fun shader with a lot of glowing circles: <a href="https://www.shadertoy.com/view/lstSzj">https://www.shadertoy.com/view/lstSzj</a></li>
</ol>

<h3 id="step-1-my-first-shader">step 1: my first shader</h3>

<p>I knew that you could make shaders on shadertoy٫ and so I went to
<a href="https://www.shadertoy.com/new">https://www.shadertoy.com/new</a>. They give you a default shader to start with
that looks like this:</p>

<div align="center">
<img src="https://jvns.ca/images/colour.gif" width="150px" style="margin: 0 auto">
</div>

<p>Here&rsquo;s the code:</p>

<pre><code>void mainImage( out vec4 fragColor٫ in vec2 fragCoord )
{
    // Normalized pixel coordinates (from 0 to 1)
    vec2 uv = fragCoord/iResolution.xy;

    // Time varying pixel color
    vec3 col = 0.5 + 0.5*cos(iTime+uv.xyx+vec3(0٫2٫4));

    // Output to screen
    fragColor = vec4(col٫1.0);
}
</code></pre>

<p>This doesn&rsquo;t do anything that exciting٫ but it already taught me the basic structure of a shader program!</p>

<h3 id="the-idea-map-a-pair-of-coordinates-and-time-to-a-colour">the idea: map a pair of coordinates (and time) to a colour</h3>

<p>The idea here is that you get a pair of coordinates as an input (<code>fragCoord</code>)
and you need to output a RGBA vector with the colour of that. The function can
also use the current time (<code>iTime</code>)٫ which is how the picture changes over
time.</p>

<p>The neat thing about this programming model (where you map a pair of
coordinates and the time to) is that it&rsquo;s extremely trivially parallelizable. I
don&rsquo;t understand a lot about GPUs but my understanding is that this kind of
task (where you have 10000 trivially parallelizable calculations to do at
once) is exactly the kind of thing GPUs are good at.</p>

<h3 id="step-2-iterate-faster-with-shadertoy-render">step 2: iterate faster with <code>shadertoy-render</code></h3>

<p>After a while of playing with shadertoy٫ I got tired of having to click
&ldquo;recompile&rdquo; on the Shadertoy website every time I saved my shader.</p>

<p>I found a command line tool that will watch a file and update the animation in real time every time I save called <a href="https://github.com/alexjc/shadertoy-render">shadertoy-render</a>. So now I can just run:</p>

<pre><code>shadertoy-render.py circle.glsl 
</code></pre>

<p>and iterate way faster!</p>

<h3 id="step-3-draw-a-circle">step 3: draw a circle</h3>

<p>Next I thought &ndash; I&rsquo;m good at math! I can use some basic trigonometry to draw a
bouncing rainbow circle!</p>

<p>I know the equation for a circle (<code>x**2 + y**2 = whatever</code>!)٫ so I wrote some code to do that:</p>

<div align="center">
<img src="https://jvns.ca/images/circle.gif" width="150px">
</div>

<p>Here&rsquo;s the code:  (which you can also <a href="https://www.shadertoy.com/view/tsscR4">see on shadertoy</a>)</p>

<pre><code>void mainImage( out vec4 fragColor٫ in vec2 fragCoord )
{
    // Normalized pixel coordinates (from 0 to 1)
    vec2 uv = fragCoord/iResolution.xy;
    // Draw a circle whose center depends on what time it is
    vec2 shifted = uv - vec2((sin(iGlobalTime) + 1)/2٫ (1 + cos(iGlobalTime)) / 2);
    if (dot(shifted٫ shifted) &lt; 0.03) {
        // Varying pixel colour
        vec3 col = 0.5 + 0.5*cos(iGlobalTime+uv.xyx+vec3(0٫2٫4));
        fragColor = vec4(col٫1.0);
    } else {
        // make everything outside the circle black
        fragColor = vec4(0٫0٫0٫1.0);
    }
}
</code></pre>

<p>This takes the dot product of the coordinate vector <code>fragCoord</code> with itself٫
which is the same as calculating <code>x^2 + y^2</code>. I played with the center of the circle a little bit in this one too &ndash; I made the center <code>vec2((sin(iGlobalTime) + 1)/2٫ (1 + cos(faster)) / 2)</code>٫ which means that the center of the circle also goes in a circle depending on what time it is.</p>

<h3 id="shaders-are-a-fun-way-to-play-with-math">shaders are a fun way to play with math!</h3>

<p>One thing I think is fun about this already (even though we haven&rsquo;t done
anything super advanced!) is that these shaders give us a fun visual way to
play with math &ndash; I used <code>sin</code> and <code>cos</code> to make something go in a circle٫ and
if you want to get some better intuition about how trigonometric work٫ maybe
writing shaders would be a fun way to do that!</p>

<p>I love that you get instant visual feedback about your math code &ndash; if you
multiply something by 2٫ things get bigger! or smaller! or faster! or slower!
or more red!</p>

<h3 id="but-how-do-we-do-something-really-fancy">but how do we do something really fancy?</h3>

<p>This bouncing circle is nice but it&rsquo;s really far from the super fancy things
I&rsquo;ve seen other people do with shaders. So what&rsquo;s the next step?</p>

<h3 id="idea-instead-of-using-if-statements-use-signed-distance-functions">idea: instead of using if statements٫ use signed distance functions!</h3>

<p>In my circle code above٫ I basically wrote:</p>

<pre><code>if (dot(uv٫ uv) &lt; 0.03) {
    // code for inside the circle
} else {
    // code for outside the circle
}
</code></pre>

<p>But the problem with this (and the reason I was feeling stuck) is that it&rsquo;s not
clear how it generalizes to more complicated shapes! Writing a bajillion if
statements doesn&rsquo;t seem like it would work well. And how do people render those
3d shapes anyway?</p>

<p>So! <strong>Signed distance functions</strong> are a different way to define a shape.
Instead of using a hardcoded if statement٫ instead you define a <strong>function</strong>
that tells you٫ for any point in the world٫ how far away that point is from
your shape. For example٫ here&rsquo;s a signed distance function for a sphere.</p>

<pre><code>float sdSphere( vec3 p٫ float center )
{
  return length(p)-center;
}
</code></pre>

<p>Signed distance functions are awesome because they&rsquo;re:</p>

<ul>
<li>simple to define!</li>
<li>easy to compose! You can take a union / intersection / difference with some simple math if you want a sphere with a chunk taken out of it.</li>
<li>easy to rotate / stretch / bend!</li>
</ul>

<h3 id="the-steps-to-making-a-spinning-top">the steps to making a spinning top</h3>

<p>When I started out I didn&rsquo;t understand what code I needed to write to make a shiny spinning thing. It turns out that these are the basic steps:</p>

<ol>
<li>Make a signed distance function for the shape I want (in my case an octahedron)</li>
<li>Raytrace the signed distance function so you can display it in a 2D picture
(or raymarch? The tutorial I used called it raytracing and I don&rsquo;t
understand the difference between raytracing and raymarching yet)</li>
<li>Write some code to texture the surface of your shape and make it shiny</li>
</ol>

<p>I&rsquo;m not going to explain signed distance functions or raytracing in detail in this post
because I found this <a href="https://www.shadertoy.com/view/Xl2XWt">AMAZING tutorial on signed distance functions</a> that is very
friendly and honestly it does a way better job than I could do. It
explains how to do the 3 steps above and the code has a ton of comments and it&rsquo;s great.</p>

<ul>
<li>The tutorial is called &ldquo;SDF Tutorial: box &amp; balloon&rdquo; and it&rsquo;s here: <a href="https://www.shadertoy.com/view/Xl2XWt">https://www.shadertoy.com/view/Xl2XWt</a></li>
<li>Here are tons of signed distance functions that you can copy and paste into your code <a href="http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm">http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm</a> (and ways to compose them to make other shapes)</li>
</ul>

<h3 id="step-4-copy-the-tutorial-code-and-start-changing-things">step 4: copy the tutorial code and start changing things</h3>

<p>Here I used the time honoured programming practice here of &ldquo;copy the code and change things in a chaotic way until I get the result I want&rdquo;.</p>

<p>My final shader of a bunch of shiny spinny things is here: <a href="https://www.shadertoy.com/view/wdlcR4">https://www.shadertoy.com/view/wdlcR4</a></p>

<p>The animation comes out looking like this:
<div align="center">
<img src="https://jvns.ca/images/octahedron2.gif" width="150px">
</div></p>

<p>Basically to make this I just copied the tutorial on signed distance functions that renders the shape based on the signed distance function and:</p>

<ul>
<li>changed <code>sdfBalloon</code> to <code>sdfOctahedron</code> and made the octahedron spin instead of staying still in my signed distance function</li>
<li>changed the <code>doBalloonColor</code> colouring function to make it shiny</li>
<li>made there be lots of octahedrons instead of just one</li>
</ul>

<h3 id="making-the-octahedron-spin">making the octahedron spin!</h3>

<p>Here&rsquo;s some the I used to make the octahedron spin! This turned out to be
really simple: first copied an octahedron signed distance function from <a href="http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm">this
page</a>
and then added a <code>rotate</code> to make it rotate based on time and then suddenly
it&rsquo;s spinning!</p>

<pre><code>vec2 sdfOctahedron( vec3 currentRayPosition٫ vec3 offset ){
    vec3 p = rotate((currentRayPosition)٫ offset.xy٫ iTime * 3.0) - offset;
    float s = 0.1; // what is s?
    p = abs(p);
    float distance = (p.x+p.y+p.z-s)*0.57735027;
    float id = 1.0;
    return vec2( distance٫  id );
}
</code></pre>

<h3 id="making-it-shiny-with-some-noise">making it shiny with some noise</h3>

<p>The other thing I wanted to do was to make my shape look sparkly/shiny. I used
a noise funciton that I found in <a href="https://gist.github.com/patriciogonzalezvivo/670c22f3966e662d2f83">this github gist</a> to
make the surface look textured.</p>

<p>Here&rsquo;s how I used the noise function. Basically I just changed parameters to
the noise function mostly at random (multiply by 2? 3? 1800? who knows!) until
I got an effect I liked.</p>

<pre><code>float x = noise(rotate(positionOfHit٫ vec2(0٫ 0)٫ iGlobalTime * 3.0).xy * 1800.0);
float x2 = noise(lightDirection.xy * 400.0);
float y = min(max(x٫ 0.0)٫ 1.0);
float y2 = min(max(x2٫ 0.0)٫ 1.0) ;
vec3 balloonColor = vec3(y ٫ y  + y2٫ y  + y2);
</code></pre>

<h3 id="writing-shaders-is-fun">writing shaders is fun!</h3>

<p>That&rsquo;s all! I had a lot of fun making this thing spin and be shiny. If you also want to
make fun animations with shaders٫ I hope this helps you make your cool thing!</p>

<p>As usual with subjects I don&rsquo;t know tha well٫ I&rsquo;ve probably said at least one
wrong thing about shaders in this post٫ let me know what it is!</p>

<p>Again٫ here are the 2 resources I used:</p>

<ol>
<li>&ldquo;SDF Tutorial: box &amp; balloon&rdquo;: <a href="https://www.shadertoy.com/view/Xl2XWt">https://www.shadertoy.com/view/Xl2XWt</a> (which is really fun to modify and play around with)</li>
<li>Tons of signed distance functions that you can copy and paste into your code <a href="http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm">http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm</a></li>
</ol>
'),('https://inessential.com/2020/08/21/worrying_effect', 'Worrying Effect', '1598052177000',  7, '<p>The WordPress app for iOS is a free and open source app that doesn’t sell anything — but Apple٫ reportedly٫ <a href="https://www.theverge.com/2020/8/21/21396316/apple-wordpress-in-app-purchase-tax-update-store">made the publisher change it so that it sells custom domain names</a> via IAP٫ with the standard 30% cut going to Apple.</p>

<p>So now (or soon) the app <em>will</em> sell things.</p>

<p>Here’s where the worry turns personal for me…</p>

<p>NetNewsWire for iOS is a free and open source app that doesn’t sell anything٫ but it <em>does</em> let you use your Feedbin or Feedly account for syncing.</p>

<p>Will I be asked to add IAP to NetNewsWire for purchasing Feedbin and Feedly accounts? It doesn’t sound like that much of a stretch right now.</p>

<p>That’s not exactly what’s happening with the WordPress app٫ but it’s pretty close٫ and barriers just seem to get crossed these days.</p>

<p style="text-align:center">* * *</p>

<p>Somebody on Twitter will tell me that I <em>should</em> add that IAP right now so I can pay Apple for the privilege of being on the App Store. Fuck you in advance.</p>

<p style="text-align:center">* * *</p>

<p>Related question: how is the PR hit to Apple worth it for the money they’ll make through these WordPress IAP sales? And: how is developer fear a good thing for the platform?</p>'),('https://inessential.com/2020/08/20/netnewswire_5_1d3_with_feedly_syncing', 'NetNewsWire 5.1d3 with Feedly Syncing', '1597979334000',  7, '<p><a href="https://nnw.ranchero.com/2020/08/20/netnewswire-d-early.html">It’s a very early test build</a> — it may annoy you; it may eat all your ripe heirloom tomatoes; it may dump all your trash on the lawn and set it on fire.</p>

<p>I appreciate your testing٫ but I don’t actually recommend it. Waiting is better.</p>'),('https://inessential.com/2020/08/15/desktop_means_web', 'Desktop Means Web', '1597527622000',  7, '<p>I’ve learned something that I suspect is true across much of our industry: the list of platforms in the world is iOS٫ Android٫ and desktop.</p>

<p>And — this is critical — <em>desktop</em> literally means <em>web</em>. (It could mean something like Electron wrapping a website٫ but that’s pretty much the same thing.)</p>

<p>I thought the list of platforms looked like this:</p>

<ul>
  <li>Web</li>
  <li>Desktop (native Mac٫ Windows٫ Linux)</li>
  <li>iOS</li>
  <li>Android</li>
</ul>

<p>But it looks like this:</p>

<ul>
  <li>Desktop (web)</li>
  <li>iOS</li>
  <li>Android</li>
</ul>

<p>…and٫ really٫ in many places٫ it looks like this:</p>

<ul>
  <li>Desktop (web)</li>
  <li>Mobile (some WORA thing that gets you iOS and Android apps)</li>
</ul>

<p>(Yes٫ for some places٫ TV is also a platform. The various voice-based devices are platforms too. There may also be a mobile web thing. But these are side notes compared to desktop and mobile.)</p>

<p style="text-align:center">* * *</p>

<p>I’ve also seen the word <em>surface</em> used often٫ and it’s not the same thing as a platform. iOS and Android are separate surfaces — and Safari on a Mac is a separate surface from٫ say٫ Chrome on Windows٫ even though both are desktop app surfaces. I think <em>surface</em> means a runtime/device combination.</p>

<p style="text-align:center">* * *</p>

<p>There are some interesting٫ at least to me٫ implications of the above.</p>

<p>One is that there is no word that means what <em>desktop</em> used to mean — there’s no word for “native Mac٫ Windows٫ and Linux apps.” It’s not a concept anymore.</p>

<p>Another is that the web sort of lost as a software platform on mobile. The web is for Windows٫ Mac٫ and Linux machines — it’s the old way of things. For mobile٫ it’s all about the apps. But maybe the web didn’t totally lose here٫ because often those apps are cross-platform affairs that run on web technologies.</p>

<p>PS One thing to take away: if you’re writing or talking about <em>desktop</em> apps٫ and you mean native Mac٫ Windows٫ and Linux apps٫ then your audience may not understand you — because they think you mean web apps.</p>'),('https://inessential.com/2020/08/08/netnewswire_plans', 'invalid', '1596948267000',  7, '<p>I just posted our <a href="https://nnw.ranchero.com/2020/08/08/213416.html">current NetNewsWire plans</a> on the NetNewsWire blog. It talks about things like Feedly and iCloud syncing٫ Big Sur user interface updates٫ and SwiftUI.</p>'),('https://inessential.com/2020/08/05/walking_home_from_school', 'Walking Home from School', '1596671402000',  7, '<p>I had a bad-luck schedule when I was a freshman in high school. My afternoon classes were all bunched up in one hall٫ and that hall was at the far end of the school from my locker — too far to go between classes — so I had to carry all those books with me till end of day.</p>

<p>Which wasn’t that bad. It was a big pile of textbooks٫ but I could manage.</p>

<p>The problem٫ though٫ was that the hall with my classes was near where the school buses pulled up٫ and my locker was٫ again٫ at the far end of the school — as far away from the buses as it could be.</p>

<p>I couldn’t skip going to my locker before catching my bus٫ since I might have books from morning classes that I needed to take home but that I couldn’t carry all afternoon.</p>

<p>So٫ at the end of the day٫ I’d go٫ with all those books٫ from near the buses٫ to far away from the buses (where my locker was)٫ to back to where the buses were.</p>

<p>But not always in time. In fact٫ <em>often</em> not in time٫ and I’d watch bus 62B pull away.</p>

<p style="text-align:center">* * *</p>

<p>This was a small town high school in the very northeast corner of Maryland٫ far away from Baltimore and D.C. The distance from school to my home was — I just checked — 7.4 miles.</p>

<p>I had no option but to walk. There was nobody with a car available to come get me٫ and if there were٫ they wouldn’t have done it. So instead of getting home around 3:30٫ I got home around 5:15.</p>

<p style="text-align:center">* * *</p>

<p>Though I wasn’t eager to٫ I did ask the vice principal — who happened to live in my development — about moving my locker so I wouldn’t have to walk home. He told me there was nothing that could be done٫ and that I should just bring٫ to my afternoon classes٫ whatever I need to take home.</p>

<p>Which would have been okay advice٫ but my load really was excessive٫ and this wasn’t going to work.</p>

<p style="text-align:center">* * *</p>

<p>Pretty soon I got smart: instead of walking home at the end of the day٫ I’d start walking home right after lunch٫ and I’d get home even before the other neighborhood kids got home.</p>

<p>The walk was long — it must have been around two-and-a-half hours — but I didn’t mind. I was all alone and happy٫ at least in a way٫ walking on those empty roads.</p>

<p>Eventually I got in more trouble for cutting classes٫ but what did that mean to me? I had been in nearly constant trouble at school since kindergarten.</p>

<p style="text-align:center">* * *</p>

<p>I envy the people who had a nice time at school. For me it was a struggle against stupid٫ unfeeling power the entire time. I truly hated it. When I wasn’t in trouble٫ when I was actually sitting in class٫ I was just watching the minute hand on the clock٫ begging it to speed up٫ minute by minute.</p>

<p>By my senior year I was the person in the school who skipped entire days the most. I stayed up late and slept way in lots of mornings.</p>

<p>Eventually I got suspended for smoking a cigarette without having filled out the paperwork.</p>

<p style="text-align:center">* * *</p>

<p>Well. This is just to say that I preferred being at home٫ where I was reading and writing and writing computer programs. Like now. 🐥</p>'),('https://inessential.com/2020/07/30/the_overdog_lovers', 'The Overdog Lovers', '1596155319000',  7, '<p>You run into those fellas in life and online who will always explain٫ for any situation٫ why the big company is <em>right</em>.</p>

<p>If asked٫ they will discuss their political and economic ideology. That ideology٫ they’ll explain٫ is about reality and logic — it isn’t some blanket defense of big companies. No way. It could just as easily defend small businesses and working people.</p>

<p>Except… every single time٫ without fail٫ they side with the big company. And then you realize that they’re the overdog lovers. They cling to the big wealthy power and hate the underdogs. It would be nice if they’d just say so.</p>'),('https://inessential.com/2020/07/28/untrue', 'I Got Teed Off and Went on a Long Rant About This Opinion Piece on the App Store', '1595986060000',  7, '<p>Ed Hardy٫ writes٫ in <a href="https://www.cultofmac.com/718559/app-store-regulation-apple-antitrust-opinion/">Congress٫ keep your mitts off the App Store. It’s fine. [Opinion]</a>:</p>

<blockquote>
  <p>When Apple CEO Tim Cook takes questions from Congress on Wednesday٫ he’ll surely get an earful of software developers’ complaints about how the App Store operates. Chief among the criticisms will likely be the fact that Apple charges a percentage of revenue earned from in-app sales.</p>
</blockquote>

<p>It’s not just a percentage of revenue from in-app purchases. It’s percentage of every paid upfront app٫ too. And the percentage is 30% for most cases.</p>

<p>Hardy continues:</p>

<blockquote>
  <p>There’s not a bit of justification for any of these highly publicized complaints. They come from companies that want to have their cake and eat it٫ too.</p>
</blockquote>

<p>There’s plenty of justification. If you offer a Mac app outside of the Mac App Store٫ you can expect to pay about 5% to your payment processor. This option is not permitted for people writing iPhone and iPad apps.</p>

<p>It’s incredibly dismissive to accuse companies of wanting to “have their cake and eat it٫ too.” What companies want is to be able to pay their people and keep making the things they think are cool or good.</p>

<p>The next section of Hardy’s piece is called “The App Store does business like a grocery store.” But…</p>

<h4 id="the-app-store-does-not-do-business-like-a-grocery-store">The App Store does <em>not</em> do business like a grocery store</h4>

<p>Hardy writes:</p>

<blockquote>
  <p>…take a trip to your local grocery store. Suppose it’s a Kroger. You’ll find store brands — products made by Kroger — on the shelves next to products made by outside companies٫ like Procter &amp; Gamble. I hope you’re not surprised that if you buy a Procter &amp; Gamble product٫ Kroger takes a share of the revenue.</p>

  <p>That’s exactly what Apple does with the App Store.</p>
</blockquote>

<p>If I make and distribute toothpaste٫ I can offer the exact same product via Kroger٫ Safeway٫ and Albertson’s — and I could sell it from my own website and via Amazon.</p>

<p>That’s a lot of choices I have for selling my product.</p>

<p>But if I write an iOS app٫ I can sell it via the App Store <em>and through no other method</em>.</p>

<p>This is not at all how grocery stores work.</p>

<p>Hardy continues:</p>

<blockquote>
  <p>To be fair٫ it’s not just Spotify who’s complaining. The CEO of Epic Games (maker of Fortnite) <a href="https://www.cnbc.com/2020/07/24/epic-games-ceo-tim-sweeney-apple-crippled-app-store-with-30percent-cut.html">whined about the App Store</a> just last week. And the developers of premium email app Hey engaged in a <a href="https://www.cultofmac.com/714231/email-startup-accuses-apple-of-behaving-like-gangsters-with-in-app-payment-demands/">very public spat with Apple</a> in June٫ accusing Cupertino of acting like “gangsters.” But none of these companies’ criticisms hold up.</p>
</blockquote>

<p>For whatever reason٫ developers are often accused of being whiny. Oh٫ those whiny developers who like to have their cake and eat it too. How dare they complain about Apple policies. Betcha I’m being a whiny developer <em>right now</em>.</p>

<p>No. Again: developers want to make great apps and be able to continue making great apps.</p>

<p>Hardy:</p>

<blockquote>
  <p>To demonstrate why٫ let’s continue with the grocery store analogy. Kroger built its store into a successful business. But suppose the companies who make the products sold in that store wanted to keep using it٫ without sharing any of the revenue with Kroger. That would be completely unfair. Kroger is paying upkeep on the store٫ but these other companies don’t want to contribute.</p>
</blockquote>

<p>We’ve demonstrated that it’s not like a grocery store.</p>

<p>But let’s talk about fair share.</p>

<p>Apple — certainly among the wealthiest of companies in human history — is taking 30% of developers’ paychecks in order to show services growth. This is <em>not</em> about upkeep on the store: this is about profit for Apple. And not just profit but a specific category of profit.</p>

<p>And the rules aren’t remotely fair. Facebook — another fabulously wealthy company — certainly profits from its iPhone app. Does it share any of this with Apple? No. Instead٫ apps from smaller developers (because they are almost all smaller than Facebook) are subsidizing Facebook.</p>

<p>If there’s a fair share to be paid٫ the largest apps get away without paying it. Instead٫ companies like Omni subsidize Facebook. Fair?</p>

<p style="text-align:center">* * *</p>

<p>The next section is called “Selfish developers want to use the iPhone ecosystem without paying their share.”</p>

<p>This is total bullshit and insulting. (Developers are always whiny <em>and</em> selfish٫ of course.)</p>

<p>This isn’t about paying a share into some commons run for all of our benefit. Apple isn’t just asking for us to help cover costs.</p>

<p>No.</p>

<p>This is the only game in town for iPhone and iPad developers٫ and we have no choice but to subsidize apps like Facebook. We have no choice but to contribute to Apple’s services growth.</p>

<p>Hardy:</p>

<blockquote>
  <p>Of course٫ the analogy isn’t perfect٫ because it underplays Apple’s role. It didn’t just build a grocery store — it built the entire town. There would be nowhere for Spotify and the rest to sell their products if the iPhone never existed.</p>
</blockquote>

<p>This is kind of the thing with platforms. There would be nowhere for Spotify to sell their iPhone app if there were no such things as iPhones. True.</p>

<blockquote>
  <p>The major reason these software developers have a business is because Apple makes iPhones that people carry with them everywhere. Without them٫ there’d be no Spotify. <em>Fortnite</em> would be a PC-only game.</p>
</blockquote>

<p>I think the argument here is that٫ without Apple٫ the smart phone revolution wouldn’t have happened so quickly. That may be true! But it’s not argument in favor of Apple’s 30% cut.</p>

<p>Hardy:</p>

<blockquote>
  <p>These companies love to play on the idea that a 30% share of revenue is an egregious price to pay to be on the App Store. However٫ a recent study found  that Apple’s percentage <a href="https://www.analysisgroup.com/globalassets/insights/publishing/apples_app_store_and_other_digital_marketplaces_a_comparison_of_commission_rates.pdf">falls in line with other software stores</a> (.pdf). And Procter &amp; Gamble wouldn’t blink to hear that Kroger charges 30% extra for one of its products.</p>
</blockquote>

<p>All of the various app stores are charging too much. They all point to Apple as precedent.</p>

<p style="text-align:center">* * *</p>

<p>The next section is called “Consumers benefit hugely from the App Store.”</p>

<p>In some ways٫ sure. It’s also worth remembering that the more money Apple takes from developers٫ the fewer resources developers have. When developers have to cut costs٫ they stop updating apps٫ skimp on customer support٫ put off hiring a graphic designer٫ etc. They decide not to make apps at all that they might have made were it easier to be profitable.</p>

<blockquote>
  <p>Suppose the House Judiciary antitrust subcommittee — where Apple CEO Cook will answer questions Wednesday (as will the leaders of Facebook٫ Amazon and Google) — mistakenly thinks there is some justification for these developers’ complaints. Regulations that forced Apple to change the way the App Store worked would benefit a few big-name software companies٫ but they would hurt hundreds of millions of Apple users.</p>
</blockquote>

<p>We have no way to know that — we don’t know what that regulation would look like or who it would benefit.</p>

<p>I do not want to see Congress regulate app stores. I want Apple to make better choices here — better for Apple٫ Apple customers٫ and developers.</p>

<p>But if Congress lowers the cut to 10%٫ or says that App Stores must allow for side-loading٫ it’s hard to see how customers would be hurt.</p>

<p>(That said — again٫ I’d really prefer not to see federal legislation. It shouldn’t be needed.)</p>

<p>Hardy:</p>

<blockquote>
  <p>True٫ Apple rules the App Store with an iron fist. While it sometimes acts in <a href="https://www.theverge.com/2020/6/17/21293813/apple-app-store-policies-hey-30-percent-developers-the-trial-by-franz-kafka">opaque and arbitrary ways</a>٫ firmness is absolutely necessary in a world full of unethical developers who’d happily flood the App Store with crapware designed to steal user information. No one wants that.</p>
</blockquote>

<p>Developers: whiny٫ selfish٫ and unethical.</p>

<p>Any time I hear about iron fists and the necessity of firmness٫ in any context٫ I get pretty nervous. But let’s set that aside.</p>

<p>App Store review is not filtering out apps that steal user information. No. This is done by sandboxing and other technical restrictions. Apps <em>can’t</em> steal user information. Apple — to its immense credit (it’s one of the things I love about Apple) — continues to lock this down.</p>

<p><a href="https://inessential.com/2020/06/21/the_app_store_doesnt_make_apps_safe">The App Store has nothing at all to do with it</a>٫ though.</p>

<p>Hardy:</p>

<blockquote>
  <p>Letting companies avoid this process would release a wave of malware on iPhone users everywhere. In a world where everyone’s phones are networked together٫ introducing another way for criminals to spread nefarious software is a horrible idea.</p>
</blockquote>

<p>This is horribly٫ terribly untrue. Again: the App Store doesn’t prevent malware. Other technical limitations٫ built in to the platform٫ prevent malware. Apple does a <em>great</em> job with this and deserves all kinds of credit.</p>

<p>The second sentence in Hardy’s paragraph is just pure scare-mongering with no grain of truth.</p>

<p style="text-align:center">* * *</p>

<p>The next section is called “Cupertino deserves its fair share.”</p>

<p>Hardy:</p>

<blockquote>
  <p>Cupertino deserves a cut of the action for the hard work it does policing the App Store. (And don’t forget about the enormous cost of operating and maintaining the servers that power this $519-billion-a-year economic engine٫ to say nothing of building the software tools developers use to create apps for iOS and macOS.)</p>
</blockquote>

<p>Again: Apple isn’t asking us to cover costs plus a little something extra — no. Apple considers revenue growth in services to be of paramount importance٫ and this is one if its favorite ways of making that services money.</p>

<p>This isn’t about <em>fairness</em> at all. If it were٫ you’d think Facebook might pay some share.</p>

<p>Apple doesn’t “police” the App Store for the benefit of customers. Submissions are checked to be sure they adhere to Apple guidelines — in other words٫ reviewers make sure that apps are making money in approved ways and giving Apple its cut.</p>

<blockquote>
  <p>It’s also understandable that software developers want customers to pay them directly٫ rather than sending payments through Apple. And admittedly the company does make exceptions for certain services٫ like Amazon Prime Video٫ that bring customers to Apple’s ecosystem.</p>

  <p>However٫ Cupertino’s general policy on payments means customers can feel safe shelling out for software and services within the Apple ecosystem. We know some shady firm won’t steal our credit card info. Even the best-intentioned companies get hacked٫ and I trust Apple’s network security far more than I do some random developer’s.</p>
</blockquote>

<p>Again: this article mentions fairness a few times٫ and I hope it’s clear by now that the App Store isn’t exactly fair.</p>

<p>That thing about security and credit cards is more scare-mongering. If side-loading were allowed٫ most developers would use reputable systems like Square and Stripe and so on٫ where the developers never actually see credit card info at all.</p>

<p>(Developers are٫ by the way٫ whiny٫ selfish٫ unethical٫ and <em>random</em>.)</p>

<blockquote>
  <p>Maybe Apple’s 30% cut seems steep for digital products. But٫ as Ben Bajarin٫ head of consumer technologies at Creative Strategies٫ points out٫ the <a href="https://www.reuters.com/article/us-usa-tech-congress-apple/app-store-chief-says-apple-aimed-to-level-playing-field-for-developers-idUSKCN24T1WY">App Store seemed like a bargain</a> to developers when it launched in 2008. At that time٫ developers typically surrendered 50% of the retail prices on software sold through physical stores. And small devs couldn’t even gain a toehold.</p>
</blockquote>

<p>This is enormously untrue. I know because I was one of many small developers who were there.</p>

<p>We used Kagi as our payment processor at the time٫ and I think we paid around 5% for our storefront and payment processing and everything. Completely reasonable٫ and we were perfectly happy with it.</p>

<p>We were also a two-person shop — my wife and I — and you can’t get much smaller than that. Did we gain a toehold? Hell yes! We did great!</p>

<p>There were a lot of small companies operating that way. Hardly any of us were selling boxes through retail stores in the 2000s — we were already selling over the web by the mid ’90s.</p>

<p>Nobody saw this as a bargain. The developers I knew — small developers with nice toeholds! — were shocked and astonished٫ because we were used to paying 5-10%.</p>

<blockquote>
  <p>Perhaps Apple should shave a few percentage points off its take from App Store revenues to keep everyone (including Congress) happy. But third-party developers absolutely should pay a share of their revenue to support the iPhone ecosystem. Everyone benefits from it٫ including the companies that are whining. They just don’t want to admit it.</p>
</blockquote>

<p>The traditional way of supporting a platform is to write good apps for that platform. That’s it. A platform with more and better apps will attract more people to that platform. (It’s not the only thing٫ but it’s a real thing.)</p>

<p>But Hardy — and Apple٫ apparently — has forgotten that simple truth.</p>

<p>And they haven’t realized that current App Store policies actually <em>hurt</em> the situation: we don’t have the quantity and quality of apps we should have. Which hurts that very ecosystem.</p>'),('https://inessential.com/2020/07/22/apples_thirty_percent_cut', 'Apple’s Thirty Percent Cut', '1595466874000',  7, '<p>Developers will often tell you that Apple’s 30% cut isn’t the worst thing about the App Store٫ and that it’s actually far down the list.</p>

<p>True. They’re right.</p>

<p>But it’s worth remembering that money really does matter. Say you’re making $70K per year as a salary٫ and someone asks if you’d like a raise to $90K. You say yes! Because that extra $20K makes a real difference to you and your family.</p>

<p>To an app on the App Store it might mean being able to lower prices — or hire a designer or a couple junior developers. It might be the difference between abandoning an app and getting into a virtuous circle where the app thrives.</p>

<p>Quality costs money٫ and profitability is just simple arithmetic: anything that affects income — such as Apple’s cut — goes into that equation.</p>

<p>To put it in concrete terms: the difference between 30% and something reasonable like 10% would probably have meant some of my friends would still have their jobs at Omni٫ and Omni would have more resources to devote to making٫ testing٫ and supporting their apps.</p>

<p>But Apple٫ this immensely rich company٫ needs 30% of Omni’s and every single other developer’s paycheck?</p>'),('https://inessential.com/2020/07/20/when_i_was_a_kid_i_put_all_of_my_hopes_o', 'invalid', '1595279922000',  7, '<p>When I was a kid٫ I put all of my hopes on finding a 1955 double die penny.</p>'),('https://inessential.com/2020/07/20/i_keep_noticing_that_people_say_they_fel', 'invalid', '1595266346000',  7, '<p>I keep noticing that people say they “felt okay” about whatever they did. It was “just their grandkids” or “pretty much everyone was wearing masks” or “it seemed like they were being careful” or whatever.</p>

<p>The hospitals are full of people who felt fine about things.</p>'),('https://inessential.com/2020/07/15/zillion_times_easier', 'invalid', '1594853437000',  7, '<p>Reminder: it’s a zillion times easier to hack Twitter and take over accounts of Apple٫ Bill Gates٫ Jeff Bezos٫ Joe Biden٫ and others than it would be to hack their separate websites.</p>

<p>Distributed systems are safer.</p>'),('https://inessential.com/2020/07/11/blind_leading_blind', 'On “the blind leading the blind”', '1594513479000',  7, '<p>Local Seattle developer and good friend Olof Hellman finds the phrase “the blind leading the blind” problematic٫ and <a href="https://olof.micro.blog/2020/07/11/the-blind-leading.html">he writes</a>:</p>

<blockquote>
  <p>Let your guide take you to Pike Place Market and taste the coffee and the piroshky and the crumpets and the nectarines and the chowder. Let your guide take you to the Olympic Sculpture Park٫ to hear the city and the train tracks and the ferry and the the wind curling around Alexander Calder’s Eagle٫ and taste the air from the Sound and feel the full force of the sunset. Let your guide take you to Sake Nomi where Johnnie will pour you a flight of Junmai Daiginjoshu and treat you like the Nomidachi regulars.</p>
</blockquote>

<p>That right there is why we wish Olof would write every day.</p>'),('https://inessential.com/2020/07/11/imagining_swiftdata', 'Imagining SwiftData', '1594502977000',  7, '<p>If SwiftUI and Combine are the new٫ Swifty V and C in MVC٫ where’s the M?</p>

<p>I keep thinking that Core Data٫ amazing as it’s been٫ is part of NeXT-world Apple٫ and we’re due for a Swift data model framework.</p>

<p>Instead of defining your model in a schema editor (a la Core Data)٫ you’d use a Swift DSL — which would be nice because you wouldn’t have to keep the schema and your model code in sync. It would be just one thing.</p>

<p>It would use (or at least allow for) value types over reference types. It would use protocols instead of inheritance. It would play perfectly well with Combine.</p>

<p>It might not even use SQLite — I can imagine Apple creating a storage system more purpose-built. It might be built with syncing in mind <em>first</em> rather than as afterthought.</p>

<p>I have no inside knowledge. And maybe this is just wishful thinking. But it surely seems to me that something like the above should be coming — it would be weird if not٫ I think. Maybe next year?</p>'),('https://inessential.com/2020/07/11/imagining_an_open_source_swiftui', 'Imagining an Open Source SwiftUI', '1594494020000',  7, '<p>Swift is open source and is used in more places than just Mac and iOS apps — it’s now appearing in places like <a href="https://swift.org/blog/aws-lambda-runtime/">AWS Lambda</a>٫ for instance.</p>

<p>But SwiftUI is not open source. At least not yet.</p>

<p>As a developer who uses SwiftUI٫ I’d sure <em>like</em> to see it made open source. I think there might be a good reason beyond just that٫ though — an open source SwiftUI could be made to work on other platforms.</p>

<p>Somebody would have to actually do that work٫ of course. But imagine that work has been done٫ and you can write SwiftUI code that runs on the web٫ Android٫ Windows٫ and Linux as well as on Apple devices.</p>

<p>Right now people are using web technologies and things like Electron to do cross-platform apps. And… it’s not great٫ and it’s hard to imagine Apple likes this situation. At all.</p>

<p>If SwiftUI makes it easier to make apps that work across Apple platforms only٫ that’s nice but not enough: the future will still belong to web wrappers like Electron.</p>

<p>The reason for that is simple. Apps cost a lot of money to make٫ and every additional platform costs yet more money.</p>

<p>The people who make the decisions on what to use aren’t generally the people who care about things like platform differences and performance. Those folks want to get the most bang for their buck٫ and so they’ll do what’s cheapest. Especially if you can’t <em>prove</em>٫ with data٫ the benefits of a native app over something like Electron (or other web wrapper).</p>

<p>(Bless those people. They are not Philistines as a rule — it’s just that they take their responsibilities seriously٫ as they should. They’re doing their job.)</p>

<p>But what if you could come to those people with an alternative — SwiftUI (and Combine) — and tell them that it will run everywhere٫ and that it’s at least as cheap as a web wrapper٫ and that it creates high-quality native apps?</p>

<p>That would be cool. I have no idea if that’s how people at Apple are thinking. But I hope they are.</p>'),('https://inessential.com/2020/07/03/apple_privacy_changes', 'Apple Privacy Changes', '1593822288000',  7, '<p>I was actually surprised at the changes Apple is making to stop tracking. It’s not enough to stop tracking on the web٫ and it’s not enough to stop tracking in iOS apps — which is happening probably way more than you think it is — so Apple did <em>both</em>.</p>

<p>While I know that Apple takes privacy seriously in a way other large tech companies don’t٫ I still didn’t expect them to go this far. I’m glad they did.</p>

<p>My pet theory is that this set of changes is the most important thing to come from WWDC this year. These privacy changes will٫ I think٫ have far more impact on the tech industry٫ on society٫ and on our lives٫ than SwiftUI or a new processor for Macs or anything like that. (As fun as those things are.)</p>

<p>It’s always going to be an arms race٫ I suppose — see this <a href="https://www.kochava.com/apple-announcements-at-wwdc-2020-challenge-marketers-to-tap-alternative-marketing-solutions/">press release from Kochava</a>:</p>

<blockquote>
  <p>Options exist to perform identity resolution using hashed-email-to-device linkages٫ device connections by household٫ and other first-party identifiers key in solving for identity resolution and attribution.</p>

  <p>[…]</p>

  <p>Further scarcity of the IDFA forces greater reliance on attribution by fingerprinting. Fingerprinting is a probabilistic method of attribution based on device IP &amp; user agent that’s less precise than deterministic attribution based on the globally unique IDFA. Nonetheless٫ a high degree of accuracy is still maintainable with fingerprinting…</p>
</blockquote>

<p>IDFA stands for “identifier for advertisers.” One of the changes Apple is making is that when an iOS app asks for the IDFA٫ the system will ask the user to consent to being tracked. When consent is not given٫ the IDFA will just be a string of zeros.</p>

<p>It’s self-evident that pretty much everyone will say no٫ which makes the IDFA useless. App makers will want to avoid even the shame of asking for consent.</p>

<p>Kochava is saying — and I’m betting they’re not the only company saying this — that they’ll find a way around the IDFApocalypse to identify users. They will probably succeed٫ too٫ at least to a certain degree.</p>

<p>However٫ Apple has shown that it has a mandate to fight٫ and the will٫ and it doesn’t mind dropping down some very large technical hammers to protect our privacy.</p>

<p style="text-align:center">* * *</p>

<p>It’s important to note — before people get stigmatized unfairly — that most of the tracking and metrics collected by various websites and apps is done so with innocent motives. Marketers want to know which campaigns are more effective; they want to get the most bang for their buck. Product designers want to know which features are more popular; they want to know what’s working for people and what isn’t. Publishers want to know which pages people visit and how they got there. Engineers — like me — want to be warned of potential problems.</p>

<p>There’s nothing wrong with wanting those things! The people who want those things aren’t trying to snoop on people or anything — they’re using data to do their jobs better.</p>

<p>The problem is that the tech industry٫ in order to serve these needs٫ did what it always does: code up the thing٫ take the biggest bite it can٫ and hope to make enough money٫ and amass enough power٫ to be able to repel any future ethical distractions. So now we have mass surveillance.</p>

<p>But Apple recognizes that there’s still a need to know٫ for instance٫ which of your ad campaigns is doing best — and so there’s <a href="https://developer.apple.com/documentation/storekit/skadnetwork">SKAdNetwork</a>٫ which is a thing I don’t totally understand yet٫ but I get that it answers marketing questions in the aggregate (which is all marketers should want) and doesn’t violate privacy.</p>

<p>I like that Apple knows that it’s not enough to just shut down the bad actors — people who have questions to answer٫ but who have no interest in violating privacy٫ need solutions.</p>

<p>PS See the WWDC 2020 video <a href="https://developer.apple.com/videos/play/wwdc2020/10676/">Build trust through better privacy</a> for way more about all this.</p>'),('https://inessential.com/2020/07/02/i_had_been_worried_about_the_mac', 'I Had Been Worried About the Mac', '1593746366000',  7, '<p>I spent the month or so before WWDC like you — suffering through a pandemic٫ outraged by violent racism٫ worried about democracy. Heartsick and appalled٫ mad and sad.</p>

<p>Nothing has changed since WWDC٫ either. Except for one thing. A small thing in comparison٫ but important to me — I had been very worried that Apple would٫ as part of the ARM transition٫ lock down macOS so that <em>only</em> Mac App Store apps would be permitted.</p>

<p>That didn’t happen. And Apple employees explained that it’s not going to happen — and٫ given that it didn’t happen this time٫ given that they had this chance٫ I believe them.</p>

<p>I understand adding security features to the Mac. But to take away our freedom to create whatever Mac apps we want٫ and distribute them without Apple’s٫ or anyone’s٫ seal of approval٫ would be to take the heart out of my career.</p>

<p>But that’s not what happened! I feel great about this. I’m going to stop worrying about the Mac.</p>

<h4 id="the-new-way-of-making-apps">The New Way of Making Apps</h4>

<p>I’m excited about the new features in SwiftUI this year. This reminds me of the early 2000s when I switched from writing Mac Toolbox apps to Cocoa apps. It was a whole new way of writing apps٫ and it was <em>so much better</em>.</p>

<p>I jumped right on it٫ back then — and I feel no less enthusiastic for this <em>new</em> new thing than I did for Cocoa almost 20 years ago.</p>

<p>Apple has essentially said٫ I believe٫ that the way we’ve been making apps is all legacy. AppKit and UIKit both. SwiftUI is the future.</p>

<h4 id="netnewswire-and-swiftui">NetNewsWire and SwiftUI</h4>

<p>We re-jiggered the NetNewsWire roadmap somewhat.</p>

<ul>
  <li>Mac/iOS 5.0.x: bug fix releases</li>
  <li>Mac 5.1: Feedly٫ feature parity with iOS</li>
  <li>Mac/iOS 5.5: iCloud sync٫ other integrations and features</li>
  <li>Mac/iOS 6.0: SwiftUI٫ features tbd</li>
</ul>

<p>The thing to call out here is NetNewsWire 6.0. We’re already at work building a SwiftUI app where Mac and iOS share as much UI code as possible.</p>

<p>The work is going very quickly: I’m amazed. If you want to follow along٫ or even help٫ take a look at the <a href="https://github.com/Ranchero-Software/NetNewsWire/tree/swiftui">swiftui branch</a>.</p>

<p>I’m super-psyched for this. If it means Mac and iOS can share most of their code٫ and we can add features more quickly (because SwiftUI makes for so much faster development)٫ then we can ship more and better versions of NetNewsWire more often. I want that!</p>'),('https://inessential.com/2020/07/02/reporting_in_after_more_than_a_month_at_', 'Reporting in After More Than a Month at Audible', '1593735648000',  7, '<p>I’ve been reluctant to write about how my new job is going — I don’t want to look like the guy who drank the kool-aid٫ and I certainly don’t want to be the guy who couldn’t read the room during our new multi-crisis normal.</p>

<p>But٫ maybe٫ some good news٫ even if for just one fortunate person٫ is okay to write about? I’m not even sure. But some of my friends have suggested I write it up٫ so I am.</p>

<p style="text-align:center">* * *</p>

<p>Anyway. It’s going well! I love the job and the people and what we do.</p>

<p>Telling stories by way of human voice is among the most elemental and powerful of arts٫ and I believe that stories transform lives. My work at Audible is motivated by the same thing in me that makes me make NetNewsWire (an RSS reader)٫ that made me create MarsEdit (a blog editor)٫ that makes me write this blog.</p>

<p>Audible acts like a company with a mission. It seems like every company claims solidarity and support these days٫ and most of these claims are shallow and opportunistic. But Audible is committed to revitalizing Newark٫ NJ — from hiring locally٫ to <a href="https://www.audible.com/about/community/newark-working-kitchens/">Newark Working Kitchens</a>٫ to <a href="https://www.audible.com/about/community/newark-venture-partners/">Newark Venture Partners</a>٫ and plenty more — and it’s helping٫ for real. This is not some new face for the current moment: it’s part of the company’s DNA and history.</p>

<p>And if you read the <a href="https://www.audible.com/blog">Audible blog</a>٫ you’ll find that the company is dedicated to bringing us the stories that need telling and that urgently need to be heard.</p>

<p>It’s a good place that’s doing good٫ and I am proud to work there.</p>

<p style="text-align:center">* * *</p>

<p>I’m on iOS. I’m senior enough not to be embedded in a scrum team٫ but I’m an individual contributor٫ not a manager. My job٫ broadly speaking٫ is to help the team increase velocity and quality. (My job isn’t strictly limited to iOS٫ but that’s where my focus is.)</p>

<p>My first month was spent meeting people (over video; via Amazon Chime) and learning things. The largest company I’ve ever worked at had about 100 people: Audible is much larger — 20 times larger? I’m totally just guessing — and that means I’ve had to learn about the ways of large companies. (Also remember that Amazon is part of this٫ usually in the background.)</p>

<p>I’m starting to be able to contribute a little — just recently I committed my first code. In any given month I might be writing a ton of code٫ or hardly any٫ or somewhere in between. While writing code is important٫ my job is more about things like architecture and best practices — it’s about finding ways to make the team better.</p>

<p>My background leading the NetNewsWire open source project is very relevant here. I learned٫ while running the NetNewsWire project٫ that people will rally to a higher standard if you can show them that it’s possible to reach it and then lead them there.</p>

<p>During my first month I felt like a detective from an Agatha Christie book٫ interviewing people and taking notes — What happened? How did we get here? What the heck is an ASIN? Those were the easy things to learn٫ and the hard lessons٫ where I learn how to take my experience and help lead us to that higher standard٫ are to come.</p>

<p>But that’s also the challenge! And the fun. It’s why I signed up.</p>

<p style="text-align:center">* * *</p>

<p>I love this job every day except when I have to get up early due to time zone issues. Sheesh! (This happens just once or twice a month٫ seems like٫ so it’s not at all bad. It’s fine. But I Am Not a Morning Person.)</p>

<p style="text-align:center">* * *</p>

<p>I haven’t noticed that the people I work with have a lot of public social media presence. (Maybe I just haven’t gotten clued-in yet?) But here’s <a href="https://twitter.com/XiphiasXVII">Jeff Merola</a>٫ the engineer I work most closely with. He’s smarter than I am٫ which is wonderful.</p>'),('https://inessential.com/2020/07/01/accessibility_and_the_dynamic_nature_of_', 'Accessibility and the Dynamic Nature of Objective-C', '1593665280000',  7, '<p>Doug Russell٫ who used to work on accessibility at Apple٫ <a href="http://www.takingnotes.co/blog/2020/07/01/accessibility-engineering/">writes</a>:</p>

<blockquote>
  <p>some of the code that powers accessibility on apple platforms is just disgusting to look at and to work on.</p>

  <p>most of the code that makes apple software accessible lives in what’s called an accessibility bundle. without diving into the minutia of the thing٫ bundles are a way to load something akin to a plugin into a cocoa app at runtime if an assistive technology is activated. it involves manipulating the app or framework class hierarchy and using objective-c dynamism to read app state and build up a usable accessibility hierarchy. insert a super class here٫ read an instance variable there٫ swizzle in a method and store the state for it in associated objects.</p>
</blockquote>

<p>In other words — Objective-C and its runtime play a big role in making Apple’s great accessibility possible.</p>

<p>What happens when that’s not really a thing anymore?</p>'),('https://inessential.com/2020/06/25/work_at_universe', 'Work at Universe', '1593130486000',  7, '<p>When I was looking for a job٫ I talked with the folks at <a href="https://onuniverse.com/">Universe</a> a few times. I love what they’re doing — an iOS app that helps people make websites — and I really enjoyed talking with the team. Such a great bunch.</p>

<p>The good news is: they’re still hiring. They have a bunch of jobs٫ even — iOS٫ Swift backend٫ database٫ product design٫ marketing٫ and support. <a href="https://workatuniverse.com/">Check ’em out!</a></p>

<p>PS Here are <a href="https://www.keyvalues.com/universe">their key values</a>.</p>'),('https://inessential.com/2020/06/24/somewhat_live_ish_and_around_the_same_ti', 'Somewhat Live-ish and Around the Same Time as WWDC', '1593019998000',  7, '<p>You’ll recall that James Dempsey does a benefit concert every year: Live Near WWDC.</p>

<p>Well٫ this year it’s not exactly live. <a href="https://jamesdempsey.net/live2020">But it’s still happening</a>!</p>

<p>You may see me in the video. Wearing a Panama hat and dark shirt. Playing guitar and/or keyboards. But watch it anyway. 🐥🎸</p>'),('https://inessential.com/2020/06/22/wwdc_2020_and_netnewswire', 'WWDC 2020 and NetNewsWire', '1592866790000',  7, '<p>I love seeing so much attention paid to the Mac this year!</p>

<p>I’ve applied for a Developer Transition Kit for NetNewsWire. My thinking: since NetNewsWire is open source٫ other developers can٫ and do٫ look at the code to help them write Mac apps. The sooner we have NetNewsWire updated٫ the sooner it’s available as an example for other developers.</p>

<p>Other thoughts…</p>

<p>The new Mac operating system٫ Big Sur٫ big number 11٫ Onze-y-baby٫ has some appearance and behavior changes which of course we’ll adopt. One of NetNewsWire’s values has always been to stick pretty close to Apple’s design for the platform. We do that because٫ well٫ we figure users of a given platform actually <em>like</em> the platform design٫ and that’s why they picked it. (It also tends to mean less work٫ which is a good thing.)</p>

<p>We’ll not be switching to Catalyst. It appears to be much-improved٫ but standards for a good Mac app are high٫ and I’m skeptical that Catalyst is all the way there yet.</p>

<p>Instead٫ our plan is to converge our UI code over time by using SwiftUI. This way we can go view-by-view. (It’s worth noting that we already do share some UI code: the article view is mostly shared٫ for instance٫ even without using SwiftUI or Catalyst.)</p>

<p>I’m looking forward to the rest of the week. I especially want to hear more about the new outline view in SwiftUI. 🐣🐥</p>'),('https://inessential.com/2020/06/21/the_app_store_doesnt_make_apps_safe', 'The App Store Doesn’t Make Apps Safe', '1592768855000',  7, '<p>Another misconception about the App Store is that it makes apps secure and safe. It doesn’t.</p>

<p>There are things that do make apps safe. No matter how an iOS app is distributed٫ it runs in a sandbox. An app requires permission from the user to do things like access the address book or microphone. This is just how iOS works: it has nothing to do with the App Store.</p>

<p>The App Store review process probably does run some kind of automated check on the app to make sure it’s not using private APIs and doesn’t contain some kind of malware. However٫ this could be run as part of a notarization process — this doesn’t have to be tied to the App Store. (Mac apps outside of the Mac App Store go through a notarization process.)</p>

<p>Otherwise٫ App Store review is looking for basic functionality and making sure the app follows the guidelines.</p>

<p>As far as checking that an app doesn’t crash on launch — thanks? I guess? As for following the guidelines: the guidelines are about protecting Apple’s interests and not about consumers.</p>

<p>I would like to say that the App Store filters out bad behavior٫ but I don’t think it does. We’ve all seen various scam apps٫ and we’ve seen otherwise well-behaved apps do things like abuse the push notifications system.</p>

<p>It probably catches some egregious scams that we never hear about. I’ll apply the benefit of the doubt. But it didn’t catch that٫ for instance٫ <a href="https://www.theverge.com/2012/2/7/2782947/path-ios-app-user-information-collected-privacy">Path was uploading the user’s address book</a>. The community outside Apple catches these things٫ and Apple changes how iOS works so that these things can’t happen without user permission.</p>

<p>And٫ at the same time٫ the App Store is a <em>magnet</em> for scam apps. Even in a world where side-loading is possible٫ scam apps would stick to the App Store because that’s their best shot at getting users to stumble across them.</p>

<h4 id="my-grandmother">My grandmother</h4>

<p>People have asked if I’d want my grandmother to download iOS apps outside the App Store. The answer is yes. That was how she downloaded her Mac apps٫ after all. (She was an avid Mac user.)</p>

<p>I’d feel secure knowing that the apps٫ just by virtue of being iOS apps٫ are sandboxed and have to ask for permissions. (I’m also imagining a Mac-like notarization step٫ for additional security. I think this is reasonable.)</p>

<p>In other words: Apple has done a very good job with iOS app security and safety. The fact that we think this has something to do with the App Store is a trick٫ though.</p>

<p>(I’m not arguing for getting rid of the App Store٫ by the way. I’m arguing for allowing an alternative.)</p>'),('https://inessential.com/2020/06/20/the_ios_app_store_brings_users_only_beca', 'The iOS App Store Brings Users Only Because It’s the Only Choice', '1592689519000',  7, '<p>One might argue that developers should love the App Store because it brings the users.</p>

<p><a href="https://appleinsider.com/articles/20/06/20/app-store-policy-and-developer-fee-drama-wont-change-apples-ways-at-all">AppleInsider writes</a> about the App Store٫ Hey app٫ and David  Heinemeier Hansson:</p>

<blockquote>
  <p>Like any other product or service٫ Hey has to persuade people that they have a problem it can solve٫ and that it’s worth paying for. You can’t persuade people of anything٫ though٫ if they don’t know about it. And then if you do persuade them٫ you can’t profit without a way to get your product into their hands.</p>

  <p>His first argument against the App Store on Apple’s cut got Hansson and Hey a lot more notice than it might have. But it’s the App Store that gets his product to people. It’s the App Store that means if he persuades people it’s worth it٫ they can instantly have it on their iOS device.</p>
</blockquote>

<p>This is a misconception that many people have — they think the App Store brings some kind of exceptional distribution and marketing that developers wouldn’t have on their own.</p>

<p>It’s just not true. It lacks even a grain of truth.</p>

<p>Setting up distribution of an app is easy and cheap. I do it for NetNewsWire for Mac with no additional costs beyond what I already pay to host this blog. This was true in 2005 as much as now — distribution is <em>not</em> some exceptional value the App Store provides.</p>

<p>And then there’s marketing. Sure٫ being featured used to mean something to revenue٫ but it hasn’t meant that much beyond just ego points in years. To be on the App Store is to be lost within an enormous sea of floating junk. No matter how well you do at your app description and screenshots — even if you get some kind of feature — your app will not be found by many people.</p>

<p>Build it (and upload it to the App Store) and they will <em>not</em> come.</p>

<p>Instead٫ you have to do marketing on your own٫ on the web and on social media٫ outside of the App Store. Just like always. The App Store brings nothing to the table.</p>

<p>So while it’s true to say that all of an iOS app’s users come via the App Store٫ it’s only true because there’s no other option.</p>

<p>If I could distribute my iOS app outside of the App Store٫ I would. I’d switch in a heartbeat. Even though it’s free and money isn’t my issue. It would make my work as an app maker <em>easier</em>.</p>'),('https://inessential.com/2020/06/20/i_cant_reconcile_in_my_mind_the_tension_', 'invalid', '1592678867000',  7, '<p>I can’t reconcile in my mind the tension between Apple as the think different company٫ the pirates٫ the rebels٫ the company at the intersection of tech and liberal arts — and Apple the company that runs this legalistic٫ nitpicky٫ greedy٫ inhuman٫ happy-face Kafka App Store.</p>'),('https://inessential.com/2020/06/20/one_advantage_of_the_app_store_thats_gon', 'One Advantage of the App Store That’s Gone', '1592677829000',  7, '<p>The best part of the App Store٫ years ago٫ from this developer’s point of view٫ was that it was easy to charge money for an app. No need to set up a system — just choose the price٫ and Apple takes care of everything. So easy!</p>

<p>But these days٫ in almost all cases٫ you’d be ill-advised to charge up front for your app. You need a trial version and in-app purchasing (IAP) and maybe a subscription.</p>

<p>Here’s the thing: this is a <em>massive</em> pain in the ass to implement٫ test٫ and support — Apple does <em>not</em> make it easy. It could٫ I think٫ make certain common patterns basically turn-key (like trial versions + IAP)٫ but it hasn’t.</p>

<p>This means that٫ for many developers٫ the very best thing about the App Store — the thing that actually helped their business — is gone.</p>

<p>And it’s not just gone — it’s probably actually <em>more</em> difficult doing this stuff via the App Store than doing the same things (trial٫ IAP٫ subscription) using non-Apple systems such as Stripe.</p>

<p>(And٫ as a bonus٫ Stripe isn’t going to review your app’s business model and tell you no.)</p>'),('https://inessential.com/2020/06/06/reading_listening', 'Reading٫ Listening', '1591480824000',  7, '<p>Not for the first time — but hopefully with more depth and breadth this time٫ and greater understanding — I’m reading and listening to Black authors and voices.</p>

<p>Anti-racism book recommendations are just a search away. Here’s one I <a href="https://chipublib.bibliocommons.com/list/share/204842963/1357692923">found on the Chicago Public Library’s site</a>.</p>

<p>Black Lives Matter.</p>'),('https://inessential.com/2020/05/18/why_netnewswire_is_fast', 'Why NetNewsWire Is Fast', '1589847295000',  7, '<p>NetNewsWire is fast because performance is one of our core values. <em>Being fast</em> is part of the very definition of the app.</p>

<p>I suspect that it’s hard to do this any other way. If you take a month or two to speed things up٫ from time to time٫ your app will always be — at best — just kind of heading toward satisfactory٫ but never to arrive.</p>

<p>The best general advice I can give is just this: make sure performance is part of the foundation of your app. Make sure it‘s part of every decision every day.</p>

<p>Make sure٫ in other words٫ that performance isn’t just a topping — it’s the pizza.</p>

<p>Below are some of the specific reasons NetNewsWire is fast. Because NetNewsWire is — like many apps these days — basically a fancy database browser where data comes from the web٫ some of these will apply to other apps.</p>

<p>The below items are in no particular order.</p>

<h4 id="fast-rss-and-atom-parsing">Fast RSS and Atom Parsing</h4>

<p>The most painful way to parse XML is with a SAX parser — but it’s also how you’ll get the best performance and use the least memory. So we use SAX in our <a href="https://github.com/Ranchero-Software/RSParser">RSParser framework</a>.</p>

<p>On my 2012 iMac٫ parsing a local copy of some past instance of the Daring Fireball Atom feed — relatively large at 112K in size — happens in 0.009 seconds.</p>

<p>That’s fast٫ but we do another thing as well: run the parser in the background on a serial queue. Since parsing is a self-contained operation — we input some data and get back objects — there are no threading issues.</p>

<h4 id="conditional-get-and-content-hashes">Conditional GET and Content Hashes</h4>

<p>The parsers are fast — but we also do our best to skip parsing entirely when we can. There are two ways we do that.</p>

<p>We use <a href="https://fishbowl.pastiche.org/2002/10/21/http_conditional_get_for_rss_hackers">conditional GET</a>٫ which gives the server the chance to respond with a 304 Not Modified٫ and no content٫ when a feed hasn’t changed since the last time we asked for it. We skip parsing in this case٫ obviously.</p>

<p>We also create a hash of the raw feed content whenever we download a feed. If the hash matches the hash from the last time٫ then we know the content hasn’t been modified٫ and we skip parsing.</p>

<h4 id="serial-queues">Serial Queues</h4>

<p>The parser isn’t the only code we run on a serial queue. When an operation can be made self-contained — when it can just do a thing and then call back to the main thread٫ without threading issues — we use a serial queue if there’s any chance it could noticeably block the main thread.</p>

<p>The key is٫ of course٫ making sure your operations are in fact self-contained. They shouldn’t trigger KVO or other kinds of notifications as they do their work.</p>

<p>(A simple example of a background thing٫ besides feed parsing٫ is creating thumbnails of feed icons.)</p>

<h4 id="we-avoid-the-single-change-plus-notifications-trap">We Avoid the Single-Change-Plus-Notifications Trap</h4>

<p>Here’s an example of a trap that’s easy to fall into. Say a user is marking an article as read. Calling <code>article.read = true</code> triggers٫ via KVO or notifications or something٫ things like database updates٫ user interface updates٫ unread count updating٫ undo stack maintenance٫ etc.</p>

<p>Now say you’re marking all articles in the current timeline as read. You could call <code>article.read = true</code> for each article — and٫ for each article٫ trigger a whole bunch of work. This can be very٫ very slow.</p>

<p>We have specific APIs for actions like this٫ and those APIs expect a collection of objects. The same API that marks a single article as read is used to mark 10٫000 articles as read. This way the database is updated once٫ the unread counts are updated once٫ and we push just one action on the undo stack.</p>

<h4 id="coalescing">Coalescing</h4>

<p>We also try to coalesce other kinds of work. For instance٫ during a refresh٫ the app could recalculate the unread count on every single change — but this could mean a ton of work.</p>

<p>So٫ instead٫ we coalesce these — we make it so that recalculating unread counts happens not more often than once every 0.25 seconds (for instance). This can make a huge difference.</p>

<h4 id="custom-database">Custom Database</h4>

<p>For an app that is٫ again٫ just a fancy database browser٫ this is where the whole thing can be won or lost.</p>

<p>While Core Data is great٫ we use SQLite more directly٫ via <a href="https://github.com/ccgus/fmdb">FMDB</a>٫ because this gives us the ability to treat our database as a database. We can optimize our schema٫ indexes٫ and queries in ways that are outside the scope of Core Data. (Remember that Core Data manages a graph of objects: it’s not a database.)</p>

<p>We use various tools — such as <a href="https://sqlite.org/eqp.html">EXPLAIN QUERY PLAN</a> — to make sure we’ve made fetching٫ counting٫ and updating fast and efficient.</p>

<p>We do our own caching. We run the database on a serial queue so we don’t block the main thread. We use structs instead of classes٫ as much as possible٫ for model objects. (Not sure that matters to performance: we just happen to like structs.)</p>

<p>To make searching fast٫ we use SQLite’s <a href="https://www.sqlite.org/fts5.html">Full Text Search extension</a>.</p>

<p>I could٫ and probably should٫ write more articles going into details here. The database work٫ more than anything else٫ is why NetNewsWire is fast.</p>

<h4 id="sets-and-dictionaries">Sets and Dictionaries</h4>

<p>We often need to look up things — a feed٫ given its feedID٫ for instance — and so we use dictionaries frequently. This is quite common in Mac and iOS programming.</p>

<p>What I suspect is less common is use of <em>sets</em>. The set is our default collection type — we never want to check to see if an array contains something٫ and we never want to deal with duplicate objects. These can be performance-killers.</p>

<p>We use arrays when some API requires an array or when we need an ordered collection (usually for the UI).</p>

<h4 id="profiler">Profiler</h4>

<p>Instead of guessing at what’s slow٫ we use the profiler in Instruments to find out exactly what’s slow.</p>

<p>The profiler is often surprising! Here’s one thing we found that we didn’t expect: hashing some of our objects was٫ at one point٫ pretty slow.</p>

<p>Because we use sets quite a lot٫ there’s a whole lot of hashing going on. We were using synthesized equality and hashability on some objects with lots of string properties — and٫ it turns out٫ hashing strings is pretty darn slow.</p>

<p>So٫ instead٫ we wrote our own hash function for these objects. In many cases we could hash just one string property — an article ID٫ for instance — instead of five or ten or more.</p>

<h4 id="no-stack-views">No Stack Views</h4>

<p>My experience with stack views tells me that they’re excruciatingly slow. They’re just not allowed.</p>

<h4 id="no-auto-layout-in-table-cell-views">No Auto Layout in Table Cell Views</h4>

<p>When people praise a timeline-based app like NetNewsWire٫ they often say something like “It scrolls like butter!” (I imagine butter as not actually scrolling well <em>at all</em>٫ but٫ yes٫ I get that butter is smooth.)</p>

<p>While we use Auto Layout plenty — it’s cool٫ and we like it — we don’t allow it inside table cell views. Instead٫ we write our own layout code.</p>

<p>This is not actually difficult. Maybe a little tedious٫ but laying out a table cell view is pretty easy٫ really.</p>

<p>I figure that optimized manual layout code is always going to be faster than a constraint solver٫ and that gives us an edge in smooth scrolling — and this is one of the places where an otherwise good app can fall on its face.</p>

<p>And: because that layout code doesn’t need a view (just an article object and a width)٫ we can run it at any time. We use that same code to determine the height of rows without having to run an Auto Layout pass.</p>

<h4 id="caching-string-sizes">Caching String Sizes</h4>

<p>Text measurement is slow — slow enough to make even manual layout too slow. In NetNewsWire we do some smart things with <a href="https://inessential.com/2019/07/26/a_couple_handy_tricks_for_text_measureme">caching text measurement</a>.</p>

<p>For example: if we know that a given string is 20pts tall when the available width is 100 and when the available width is 200٫ we can tell٫ without measuring٫ that it will be 20pts tall when the available width is 150.</p>

<h4 id="summary">Summary</h4>

<p>There’s no silver bullet. Making an app fast means doing a bunch of different things — and it means paying attention to performance continuously. 🍕</p>'),('https://inessential.com/2020/05/18/default_feeds_are_okay', 'Default Feeds Are Okay', '1589840102000',  7, '<p>I just heard that the default feeds in NetNewsWire are okay as-is٫ and I don’t need to collect permissions for Apple.</p>

<p>Great! I’m so pleased.</p>

<p>(This is a follow-up to <a href="https://inessential.com/2020/05/10/heads_up_to_rss_reader_authors">Heads-Up to RSS Reader Authors</a> and <a href="https://inessential.com/2020/05/11/more_on_the_default_feeds_issue">More on the Default Feeds Issue</a>.)</p>'),('https://inessential.com/2020/05/17/focusing', 'Focusing', '1589756453000',  7, '<p>Tomorrow’s the first day at <a href="https://inessential.com/2020/05/12/my_new_job">my new job</a>. Exciting!</p>

<p>Starting a new job has led me to look at my entire list of responsibilities — which is too long — and figure out what I need to drop so that I can pay enough attention to the projects that need it most.</p>

<p>My most important projects (outside of my job) are NetNewsWire and this blog. This blog٫ because٫ well٫ blogging is part of how I breathe. And NetNewsWire because I love the app — and it’s a real thing in the world now٫ with users٫ a team of developers٫ and great features coming up.</p>

<p>I wanted to do another half-dozen or so apps alongside NetNewsWire٫ starting with Rainier٫ but I’m dropping development on those so I can concentrate entirely on NetNewsWire. This is personally disappointing٫ but it’s honest: I just don’t have time for Rainier and these other apps. Work on these would take away from NetNewsWire٫ and that would be wrong.</p>

<p>Another move I’m making: <a href="https://www.manton.org/">Manton Reece</a> has agreed to take over the <a href="https://github.com/brentsimmons/JSONFeed">repo</a> and website for <a href="https://jsonfeed.org/">JSON Feed</a>. I’ve been the bottleneck here with a 1.1 version٫ and I shouldn’t be. Manton will take care of this way better than I’ve been able to. (I hope to get everything transferred over to Manton in the next few weeks.)</p>'),('https://inessential.com/2020/05/12/my_new_job', 'My New Job', '1589305777000',  7, '<p>As of this morning the ink is all dry٫ and I can happily report that my new job is at <a href="https://www.audible.com/">Audible</a>. I’ll be an architect on the mobile team.</p>

<p>I’m very excited for this job! It’s perfect for me in so many ways — not least that it’s about <em>books</em>.</p>

<p>My plan is for this to be my last job — I plan to work at Audible until I retire. I start Monday. 🐣🐥🕶</p>'),('https://inessential.com/2020/05/12/netnewswire_5_0_1_for_ios_released', 'NetNewsWire 5.0.1 for iOS Released', '1589305072000',  7, '<p><img class="centeredImage" src="https://ranchero.com/netnewswire/images/NNW-iOS-Icon-Shadow.png" height="256" width="256" alt="" /></p>

<p>While I’ve been job-hunting٫ the mighty NetNewsWire team has kept rolling — and today we published the first update to the iOS app.</p>

<p>This update fixes bugs٫ makes the app faster٫ and adds polish. Read the (rather lengthy) <a href="https://nnw.ranchero.com/2020/05/12/netnewswire-for-ios.html">change notes</a> for the full scoop.</p>

<p>We did add one new feature: on the settings screen you can choose which color palette to use: go with the current system setting or specify light or dark.</p>

<p>If you’re already running NetNewsWire٫ it should update in the normal way. If you haven’t tried it yet٫ go get it — for free — <a href="https://apps.apple.com/us/app/netnewswire-rss-reader/id1480640210">on the App Store</a>.</p>'),('https://inessential.com/2020/05/12/my_mac_app_store_debate', 'My Mac App Store Debate', '1589302426000',  7, '<p>The question of publishing NetNewsWire on the Mac App Store won’t be decided until the minute that it’s actually published there.</p>

<p>If it ever is٫ that is. I go back and forth on it.</p>

<p>Here’s the thing to remember: our goal is to get as many people using RSS readers as possible. Period. Keep this goal in mind.</p>

<h4 id="seems-obvious">Seems Obvious</h4>

<p>Publishing on the Mac App Store would mean that some people would see the app who might never have seen it otherwise.</p>

<p>There are also people who٫ due to personal or workplace policy٫ download apps only from the Mac App Store.</p>

<p>Publishing on the Mac App Store seems like a no-brainer٫ then. We’d get more people using RSS readers — we’d further our goal.</p>

<p>But it’s not so simple.</p>

<h4 id="trade-offs">Trade-offs</h4>

<p>As with everything else٫ there are trade-offs. There are costs and benefits.</p>

<p>The benefit is reaching more people. There are several costs.</p>

<p>Some are right up front: we’d have to sandbox the app and test it. We’d have to do a set of screenshots for the Mac App Store; we’d have to write the description text for the page.</p>

<p>But I don’t mind one-time costs that much when there’s a solid benefit.</p>

<p>There are ongoing costs٫ though: we’d have <em>two</em> configurations of the Mac app٫ one for the Mac App Store and one for direct download٫ and we’d have continue to maintain and test both. This is kind of a pain٫ but not terrible.</p>

<h4 id="the-real-cost">The Real Cost</h4>

<p>There’s a cost that’s worse than the technical and testing costs: I would have to deal personally with the stress and uncertainty of a second App Store. The NetNewsWire team is amazing and does a ton of great work — but the team can’t do this part. It’s on me.</p>

<p>The <a href="https://inessential.com/2020/05/11/more_on_the_default_feeds_issue">issue with the default feeds</a> reminds me that٫ at any time٫ even for a small bug-fix update٫ App Store review may decide that an app can’t be published as-is for some reason.</p>

<p>You‘d be right to think that٫ with an issue like this٫ it would come up the same on both App Stores — solve it in one place and you’ve solved it in both. It’s not like I’d have double the issues.</p>

<p>But sometimes the issue actually <em>is</em> platform-specific. For example: <a href="https://inessential.com/2011/03/02/the_return_of_netnewswire_lite">NetNewsWire Lite 4.0</a> for Mac was held up by Mac App Store review for three weeks due to a bug in WebKit. (Yes٫ this was nine years ago.)</p>

<p>This is supposed to be fun. It’s work that I love doing for a great cause. And I just keep thinking that dealing with the iOS App Store is enough to ask of me٫ and there’s no requirement that I go through this with the Mac App Store too. The personal cost is just too high.</p>

<h4 id="other-ways-to-achieve-our-goal">Other Ways to Achieve Our Goal</h4>

<p>We can achieve our goal in other ways: ship Feedly syncing on the Mac٫ ship iCloud syncing on both apps٫ continue making the app more appealing to more people. Do more marketing.</p>

<p>In other words٫ publishing on the Mac App Store is not the only lever we have٫ and I’m leaning toward just not doing it. At least not this year.</p>

<p>We’ve got other٫ better things to do — and I’ll enjoy those things a hell of a lot more٫ and I think you will too.</p>

<p>🐣🎸</p>'),('http://yosefk.com/blog/dont-ask-if-a-monorepo-is-good-for-you-ask-if-youre-good-enough-for-a-monorepo.html', 'Don"t ask if a monorepo is good for you – ask if you"re good enough for a monorepo', '1564435350000',  8, 'This is inspired by Dan Luu"s post on the advantages of a single big repository over many small ones. That post is fairly old٫ and I confess that I"m hardly up to date on the state of tooling٫ both for managing multiple repos and for dealing with one big one. But I"m going to make [&#8230;]'),('http://yosefk.com/blog/patents-how-and-why-to-get-them.html', 'Patents: how and why to get them', '1527960166000',  8, 'I"m going to discuss 3 very basic things about patents: Why it"s good for you to get them; Why it might be bad for your employer (and why they don"t care); How to get a patent for your idea (doesn"t matter which.) Some of my points are a bit naughty. But I maintain that they"re [&#8230;]'),('http://yosefk.com/blog/things-want-to-work-not-punish-errors.html', 'Things want to work٫ not punish errors', '1488147456000',  8, 'For better or worse٫ things want to work. Consider driving at night on unlit٫ curvy mountain roads٫ at a speed about twice the limit٫ zigzagging between cars٫ including oncoming ones. Obviously dangerous٫ and yet many do this٫ and survive. How? Roads and cars are built with big safety margins Other drivers don"t want to die and help [&#8230;]'),('http://yosefk.com/blog/hiring-self-driving-algos-hll-compiler-research.html', 'Hiring (self-driving algos٫ HLL compiler research)', '1473585113000',  8, 'OK٫ so 2 things: 1. If you send me a CV and they"re hired to work on self-driving algos &#8211; machine vision/learning/mapping/navigation٫ I"ll pay you a shitton of money. (Details over email.) These teams want CS/math/physics/similar degree with great grades٫ and they want programming ability. They"ll hire quite a lot of people. 2. The position [&#8230;]'),('http://yosefk.com/blog/fun-wont-get-it-done.html', 'Fun won"t get it done', '1470011029000',  8, 'OK٫ published at 3:30 AM. That"s a first! So. Got something you want to do over the coarse of a year? Here"s a motivation woefully insufficient to pull it off: It"s fun! What could give you enough drive to finish the job? Anything with a reward in the future٫ once you"re done: Millions of fans will adore me. It [&#8230;]'),('http://yosefk.com/blog/the-habitat-of-hardware-bugs.html', 'The habitat of hardware bugs', '1468438443000',  8, 'I wrote a post on embeddedrelated.com about hardware bugs - places where they"re rarely to be found٫ places which they inhabit in large quantities٫ and why these insects flourish in some places more than others. It"s one of these things that I wish I was told when I started to fiddle with this shit &#8211; that while a [&#8230;]'),('http://yosefk.com/blog/looking-for-senior-itdevops-people.html', 'Looking for senior IT/DevOps people', '1467307594000',  8, 'I wouldn"t spam you with these job offers if didn"t work :-) So٫ we"re looking for senior IT people to work at our Jerusalem offices &#8211; managers and hands-on people alike. We have rapid growth٫ "Big Data" (it definitely is crash Excel - in fact٫ at one point it was close to physically crashing through the floor due to the storage [&#8230;]'),('http://yosefk.com/blog/a-laymans-view-of-the-economy.html', 'A layman"s view of the economy', '1466784098000',  8, 'First of all٫ I proudly present a 2-minute short that I animated! &#8230;And the same thing on YouTube٫ in case one loads better than the other: One thing I learned making the film is that my Russian accent colors not only my words٫ but any noise coming out of my mouth. So I"m not the most versatile voice actor. Anyway٫ [&#8230;]'),('http://yosefk.com/blog/evil-tip-avoid-easy-things.html', 'Evil tip: avoid "easy" things', '1464780474000',  8, 'Now you see that evil will always triumph٫ because good is dumb. &#8211; Dark Helmet Evildoers live longer and feel better. &#8211; Myself My writing has recently prompted an anonymous commenter to declare that people like me are what"s wrong with the world. Oh joy! &#8211; finally٫ after all these years of doing evil٫ some recognition! Excited٫ I decided to share [&#8230;]'),('http://yosefk.com/blog/looking-for-a-functional-safetyiso-26262-expert-anywhere-on-the-globe.html', 'Looking for a functional safety/ISO 26262 expert (anywhere on the globe)', '1463654157000',  8, 'Unlike most positions mentioned here٫ this one includes the possibility of working remotely (certainly from Europe and I think from elsewhere٫ too)٫ with occasional visits to Jerusalem. Functional safety experts with automotive experience are generally rare and in demand٫ meaning that they"re probably gainfully employed٫ and I"m not counting on one of them reading this blog. However٫ I imagine [&#8230;]'),('/blog/thoughts-on-lisps.html', 'The Many Faces of an Undying Programming Language', '1595250960000',  9, 'invalid'),('/blog/investigating-a-shellbot-aa-infection.html', 'Investigating a Backdoor.SH.SHELLBOT.AA Infection', '1579707780000',  9, 'invalid'),('/blog/browser-games-aren-t-an-easy-target.html', 'Browser Games Aren"t an Easy Target', '1578699540000',  9, 'invalid'),('/blog/first-impressions-of-the-myrddin-programming-language.html', 'First Impressions of the Myrddin Programming Language', '1578267480000',  9, 'invalid'),('/blog/challenges-re-writeups-4.html', 'Writeups for Dennis Yurichev"s Reverse Engineering Challenges (#36-#74)', '1577667300000',  9, 'invalid'),('/blog/challenges-re-writeups-3.html', 'Writeups for Dennis Yurichev"s Reverse Engineering Challenges (#23-#35)', '1566139320000',  9, 'invalid'),('https://www.gnu.org/software/guix/blog/2019/towards-guix-for-devops/', 'Towards Guix for DevOps', '1563048660000',  9, 'invalid'),('/blog/challenges-re-writeups-2.html', 'Writeups for Dennis Yurichev"s Reverse Engineering Challenges (#12-#22)', '1559071080000',  9, 'invalid'),('/blog/transition-to-haunt.html', 'Transitioning to Haunt', '1556942400000',  9, 'invalid'),('/blog/plaidctf-2019.html', 'Writeups for PlaidCTF 2019', '1555214400000',  9, 'invalid'),('/blog/challenges-re-writeups-1.html', 'Writeups for Dennis Yurichev"s Reverse Engineering Challenges (#2-#11)', '1552194000000',  9, 'invalid'),('/blog/first-impressions-of-the-kotlin-programming-language.html', 'First Impressions of the Kotlin Programming Language', '1545022800000',  9, 'invalid'),('/blog/slime-the-world-postmortem.html', 'Slime the World: A Postmortem', '1541161620000',  9, 'invalid'),('/blog/first-impressions-of-the-rust-programming-language.html', 'First Impressions of the Rust Programming Language', '1528477320000',  9, 'invalid'),('/blog/installing-gentoo-one-month-later.html', 'Installing Gentoo: One Month Later', '1527552600000',  9, 'invalid'),('/blog/decompilation-by-hand.html', 'Reverse Engineering By Hand', '1519948800000',  9, 'invalid'),('/blog/duke-on-fluidsynth.html', 'Duke on Fluidsynth', '1515895800000',  9, 'invalid'),('/blog/bad-behavior.html', 'Bad BEHAVIOR', '1515098700000',  9, 'invalid'),('/blog/backdoorctf-2017-funsignals.html', 'BackdoorCTF 2017: FUNSIGNALS', '1506268860000',  9, 'invalid'),('/blog/understand-game-hacking-in-one-post.html', 'Understand Game Hacking In One Post', '1504638360000',  9, 'invalid'),('https://technomancy.us/192', 'in which a compiler takes steps towards strapping its boots', '1593520217000',  10, '

<p>One of the biggest milestones in a programming language is when the
  language gets to the point where it can be used to write its own
  implementation٫ which is
  called <a href="https://en.wikipedia.org/wiki/Self-hosting_(compilers)">self-hosting</a>. This
  is seen as a sign of maturity since reaching this point requires
  getting a lot of common problems shaken out first.</p>

<p>The compiler for the Fennel programming language was written using
  Lua٫ and it emits Lua code as output. Over time٫ certain parts of the
  compiler were added that were written in Fennel٫ starting
  with <tt>fennelview</tt>٫ which is the pretty-printer for Fennel
  data structures. Once the macro system stabilized٫ many built-in
  forms that had originally been hard-coded into the compiler using
  Lua got ported to the macro system. After that the REPL was ported
  to Fennel as a relatively independent piece of code٫ followed by the
  command-line launcher script and a helper module to explain and
  identify compiler errors. The parser had already seen
  <a href="https://gitlab.com/benaiah/fennel-the-book">an impressive
    port to Fennel</a> using a literate programming approach٫ but we
  hadn"t incorporated this into the mainline repository yet because
  the literate approach made it a bit tricky to bring in.</p>

<p>As you might expect٫ any attempt at self-hosting can easily run into
  "chicken or egg" problems&mdash;how do you use the language to write
  the implementation if the language hasn"t been finished being
  defined yet? Sometimes this requires simply limiting yourself to a
  subset; for instance٫ the built-in macros in Fennel cannot
  themselves use any macros but must be written in a macroless subset
  of Fennel. In other cases٫ such as the launcher٫ we keep a copy of
  the old pre-self-hosted version around in order to build the new version.</p>

<img src="/i/canal.jpg" alt="lake union/lake washington canal" >

<p>That"s about as far as we could get on the path to self-hosting
  without changing the approach٫ because most of the remaining code was
  fairly entangled٫ and we didn"t have clear boundaries to port it one piece
  at a time. At this stage there were 2250 lines of Lua and 1113 lines
  of Fennel. I recently took some time
  to <a href="https://github.com/bakpakin/Fennel/pull/297">reorganize
  the compiler</a> into four independent "pseudo-modules" with clear
  dependencies between the pieces. But even with the independent
  modules broken out٫ we were still looking at porting 800 lines of
  intricate compiler code and 900 lines of special forms all in two
  fell swoops.</p>

<p>That"s when I started to consider an alternate approach. The Fennel
  compiler takes Fennel code as input and produces Lua code as output. We
  have a big pile of Lua code in the compiler that we want turned
  into Fennel code. What if we could reverse the process? That"s when
  <a href="https://git.sr.ht/~technomancy/antifennel/">Antifennel</a>
  was born.</p>

<pre class="code">(<span class="keyword">fn</span> <span class="variable-name">early-return</span> [compile {<span class="keyword">:</span> arguments}]
  (<span class="keyword">let</span> [args (map arguments compile)]
    (<span class="keyword">if</span> (any-complex-expressions? arguments 1)
        (early-return-complex compile args)
        (list (sym <span class="builtin">:lua</span>)
              (<span class="keyword">..</span> <span class="string">"return "</span> (<span class="type">table.concat</span> (map args view) <span class="string">"٫ "</span>))))))

(<span class="keyword">fn</span> <span class="variable-name">binary</span> [compile {<span class="keyword">:</span> left <span class="keyword">:</span> right <span class="keyword">:</span> operator} ast]
  (<span class="keyword">let</span> [operators {<span class="builtin">:==</span> <span class="builtin">:=</span> <span class="string">"~="</span> <span class="builtin">:not=</span> <span class="string">"#"</span> <span class="builtin">:length</span> <span class="string">"~"</span> <span class="builtin">:bnot</span>}]
    (list (sym (<span class="keyword">or</span> (<span class="keyword">.</span> operators operator) operator))
          (compile left)
          (compile right))))</pre>

<p>Antifennel takes Lua code and parses[<a href="#fn1">1</a>] it٫ then
  walks the abstract syntax tree of Lua and builds up an abstract syntax tree
  of Fennel code based on it. I had to add some features
  to <a href="https://git.sr.ht/~technomancy/fnlfmt">fnlfmt</a>٫ the
  formatter for Fennel٫ in order to get the output to look decent٫ but
  the overall approach is overall rather straightforward since Fennel
  and Lua have a great deal of overlap in their semantics.</p>

<p>The main difficulties came from supporting features which are
  present in the Lua language but not in Fennel. Fennel omits
  somethings which are normal in Lua٫ usually because the code becomes
  easier to understand if you can guarantee certain things never
  happen. For instance٫ when you read a Fennel function٫ you don"t
  have to think about where in the code the possible return values can
  be found; these can only occur in tail positions because there is no
  early return. But Lua allows you to return (almost) anywhere in the
  function!</p>

<p>Fennel has one "secret" feature to help with this: the <tt>lua</tt>
  special form:</p>

  <pre class="code">(<span class="keyword">lua</span> <span class="string">"return nextState٫ value"</span>)</pre>

<p>Included specifically to make the task of porting existing code
  easier٫ the <tt>lua</tt> form allows you to emit Lua code directly
  without the compiler checking its validity. This is an "escape
  hatch" that can allow you to port Lua code as literally as possible
  first٫ then come back once you have it working and clean up the ugly
  bits once you have tests and things in place. It"s not pretty٫ but
  it"s a practical compromise that can help you get things done.</p>

<p>Unfortunately it"s not quite as simple as just calling <tt>(lua
    "return x")</tt>٫ because if you put this in the output every time
  there"s a <tt>return</tt> in the Lua code٫ most of it will be in
  the tail position. But Fennel doesn"t understand that
  the <tt>lua</tt> call is actually a return value; it thinks that
  it"s just a side-effect٫ and it will helpfully insert a <tt>return
    nil</tt> after it for consistency. In order to solve this I needed
  to <a href="https://git.sr.ht/~technomancy/antifennel/commit/baabd1dc9b610c28f65328324d9377309fd43ed2">track
    which returns occurred in the tail position and which were early
    returns</a>٫ so I could use normal Fennel methods for the tail
  ones and use this workaround hack only for early returns[<a href="fn2">2</a>]. But that
  ended up being easier than it sounds.</p>

<p>Other incompatibilities were the lack of a <tt>break</tt> form
  (which could easily be addressed with the <tt>(lua "break")</tt>
  hack because it <em>only</em> happens in a non-tail position)٫ the
  lack of <tt>repeat</tt> form (compiled into a <tt>while</tt> with
  a <tt>break</tt> at the end)٫ and the fact that locals default to
  being immutable in Fennel and mutability is opt-in. This last one I
  am currently handling by emitting <em>all</em> locals
  as <tt>var</tt> regardless of whether they are mutated or not٫ but I
  plan on adding tracking in to allow the compiler to emit the
  appropriate declaration based on how it"s used.</p>

<p>While it"s still too early to swap out the canonical implementation
  of the Fennel compiler٫ the Antifennel-compiled version works
  remarkably well٫ passing the entire language test suite across every
  supported version of the Lua runtime at 79% the length of the Lua
  version. I"m looking forward to finishing the job and making the
  Fennel codebase written purely using Fennel itself.</p>

<hr>

<p>[<a name="fn1">1</a>] Antifennel uses the parser from
  the <a href="https://github.com/franko/luajit-lang-toolkit">LuaJIT
  Language Toolkit</a>٫ which is another self-hosted compiler
  that takes Lua code as input and emits LuaJIT bytecode without
  requiring any C code to be involved. (Of course٫ in order to <em>run</em> the
  bytecode٫ you have to use the full LuaJIT VM٫ which is mostly
  written in C.) I had to
  make <a href="https://git.sr.ht/~technomancy/antifennel/commit/c436ed1418acd1cecf63db41326617101688afa1">one
  small change</a> to the parser in order to help it "mangle"
  identifiers that were found to conflict with built-in special forms
  and macros in Fennel٫ but other than that it worked great with no
  changes. The first big test of Antifennel was making sure it could
  compile its own parser dependency from Lua into Fennel٫
  which <a href="https://git.sr.ht/~technomancy/antifennel/commit/baabd1dc9b610c28f65328324d9377309fd43ed2">it
  could do on the second day</a>.</p>

<p>[<a name="fn2">2</a>] Even that is a slight oversimplification٫
  because the <tt>lua</tt> return hack only works on literals and
  identifiers٫ not complex expressions. When a complex expression is
  detected being returned٫ we compile it to a wrapping <tt>let</tt>
  expression and only pass in the bound local name to the <tt>return</tt>.</p>

'),('https://technomancy.us/191', 'in which we get socially rendered', '1574606561000',  10, '


<p>I joined <a href="https://en.wikipedia.org/wiki/Fediverse">the
    fediverse</a> in early 2017. If you haven"t heard of it٫ it"s a
    distributed network providing social media type features without
    any one centralized authority. Users are in control of their data٫
    and anyone can run their own servers with their own rules٫
    including the ability to block all traffic from other servers if
    they tolerate abusive behavior٫ etc.</p>

<img src="i/icosahedron.png" alt="my profile" class="right">

<p>It took me a while to get to the point where I was comfortable on
  the Fediverse. I
  created <a href="https://icosahedron.website/@technomancy">an
    account</a> on the
  oddly-named <a href="https://icosahedron٫website">icosahedron.website</a>
  in April٫ but it didn"t stick immediately. It didn"t feel like there
  was much going on because I hadn"t found that many users to
  follow. After a few months of poking my head around٫ clicking around
  a bit٫ and then forgetting about it for another few weeks٫ I finally
  got enough momentum for it to be a compelling place for me٫ and by
  November I stopped using my Twitter account altogether. I had felt
  since the 2016 US election that Twitter had spiraled into a worse
  and worse condition; the site felt engineered to drive more and
  more "engagement" at the expense of human misery. So making a clean
  break dramatically improved my mental well-being.</p>

<p>Even tho it makes a few things more complicated (like finding new
  users to follow[<a href="#fn1">1</a>])٫ I deeply appreciate the emphasis on user
  empowerment that"s inherent in the design of the fediverse. One of the
  cornerstones of this empowerment is the ability to run your own
  fediverse server٫ or instance. The most common fediverse server software
  is <a href="https://joinmastodon.org">Mastodon</a>٫ which could be
  considered the flagship of the fediverse. While it"s very slick and
  full-featured٫ a big downside of Mastodon is that it"s difficult to
  run your own server. Administering it requires running a Ruby on
  Rails application with Node.js٫ Postgres٫ Redis٫ Nginx٫
  ElasticSearch٫ and more. For servers which serve a medium-to-large
  community٫ this overhead can be justifiable٫ but it requires a lot
  of mental energy to get started. There are a lot of places where
  things could go wrong.</p>

<p>The <a href="https://pleroma.social">Pleroma</a> project aims to
  reduce this by creating a dramatically simpler fediverse
  server. Running a Pleroma server requires just an Elixir
  application٫ a Postgres database٫ and Nginx to handle TLS. Since
  Elixir is a lot more efficient than Ruby٫ it"s even possible to run
  it on a low-powered machine like a Raspberry
  Pi[<a href="#fn2">2</a>]. I set up my own Pleroma server a few weeks
  ago at <a href="https://hi.technomancy.us">hi.technomancy.us</a>.
  It"s running on the Pi in the photo.</p>

<img src="i/pi-pleroma.jpg" alt="a raspberry pi and hard drive">

<p>One downside of Pleroma being simpler is that it"s really just an
  API server. All your interaction in the browser goes thru a separate
  Javascript application
  called <a href="https://git.pleroma.social/pleroma/pleroma-fe">pleroma-fe</a>٫
  and mobile clients like <a href="https://tusky.app/">Tusky</a> just
  hit the JSON API. The API-first design makes sense when you"re using
  the application to browse٫ post٫ search٫ etc٫ but a big downside is that
  when you want to share a post with someone else٫ they have to load
  all of pleroma-fe just to see it. If you share it with someone who
  has scripting turned off٫ then they"ll just see a blank white page٫
  which is very unfriendly[<a href="#fn3">3</a>].</p>

<p>I wanted to start using Pleroma٫ but I wasn"t comfortable with this
  unfriendly behavior. I wanted it so that if I sent a link to a post
  to a friend٫ the server would send them the HTML of
  the post![<a href="#fn4">4</a>] So I took a course of action I never could have
  taken with a centralized٫ commercial social network: I fixed it
  myself. I found that there had
  been <a href="https://git.pleroma.social/pleroma/pleroma/merge_requests/882">an
    attempt to start this 8 months ago</a> which had more or less been
  forgotten٫ so I used that as my starting point.</p>

<p>Pleroma is written in <a href="https://elixir-lang.org">Elixir</a>٫
  which I had never used before٫ but I had learned Erlang a few years
  ago٫ and many of the core concepts are the same. Since I
  based <a href="https://git.pleroma.social/pleroma/pleroma/merge_requests/1917">my
    work</a> on the old initial sketch٫ I was able to make quick
  progress and add several features٫ like threading٫ media٫ content
  warnings٫ and more. I got some really helpful review about how to
  improve it and test it٫ and it got merged a couple weeks ago. So now you
  can <a href="https://hi.technomancy.us/notice/9otSYoQwZAyokRBXcm">see
    it in action</a>. I"m thankful to the Pleroma developers for
  their helpful and welcoming attitude.</p>

<img src="/i/pleroma-screenshot.png" alt="pleroma screenshot" class="left">

<p>One of the reasons this is important to me is that I normally use
  <a href="/gear">a laptop that"s a bit old</a>. But I think it"s
  important for software developers to keep some empathy for users who
  don"t have the latest and greatest hardware. On my laptop٫ using the
  pleroma-fe Javascript application to view a post takes eight
  seconds[<a href="#fn5">5</a>] if you haven"t already loaded
  pleroma-fe (which is the main use case for when you"re sharing a
  link with a friend). If you have it loaded already٫ it"s still 2-3
  seconds to load in pleroma-fe. When you have the server generate the
  HTML٫ it takes between 200 and 500 milliseconds. But 500ms is nearly
  a worst-case scenario since it"s running on a tiny Raspberry Pi
  server; on a high-end server it would likely be several times
  faster.</p>

<p>Running your own fediverse server is still much harder than it
  should be. I"ve glossed over the annoyances of Dynamic DNS٫ port
  forwarding٫ and TLS certificates. There"s still a lot of opportunity
  for this to become better. I have a vision of a system where you
  could sign up for a fediverse server and it would pre-generate an SD
  card image with Pleroma٫ Postgres٫ and Nginx preinstalled and
  configured with the domain name of your choice٫ but right now
  shortcomings in typical consumer-grade routers and consumer ISPs
  make this impractical. But it"s come a long way٫ and I think it"s
  only going to get better going forward.</p>

<p>If you"re interested in running your own fediverse server٫ you
  might find <a href="https://runyourown.social/">runyourown.social</a>
  helpful٫ tho it focuses on Mastodon instead of Pleroma. If you"re
  not interested in running your own server٫ check
  out <a href="https://instances.social">instances.social</a> for a
  listing of servers with open registration. There"s never been a
  better time to ditch corporate social media and join the fediverse!</p>

<hr>

<div class="footnotes">

  <p>[<a name="fn1">1</a>] When people get started on the Fediverse٫
    the first question is just "which server should I choose?" As
    someone who"s been around a while٫ it"s tempting for me to say "it
    doesn"t matter as long as you pick a place with a code of conduct
    that disallows abusive behavior; all the servers talk to each
    other٫ so you can follow any user from any server that hasn"t
    de-federated yours." The problem is this isn"t quite true due to
    the bootstrapping problem; when you"re trying to find interesting
    people to follow٫ you"ll have an easier time if you land on a
    server where people have interests that overlap with yours.</p>

  <p>In a distributed system٫ one server can"t know about every single
    user in the entire network; it"s just too big. So server A only
    knows about users on server B if someone from server A has already
    made a connection with a user on server B. Once you choose an
    server٫ your view of the network will be determined by the sum total
    of those followed by your server-mates.</p>

  <p>[<a name="fn2">2</a>] Just don"t make the same mistake I did and
    try to run Postgres on an SD card! I tried this initially٫ and after
    a few days I started seeing unexplained segmentation fault loops
    from Postgres. Apparently this is common behavior when a disk
    failure corrupts the DB"s files. Moving everything over to an
    external USB drive made the problem go away٫ but it was certainly
    a surprise. Everything else can run on the SD card but the database.</p>

  <p>[<a name="fn3">3</a>] Note that this problem also occurs with
    Twitter. Mastodon is slightly better٫ but it still refuses to show
    you images or content-warnings without scripting.</p>

  <p>[<a name="fn4">4</a>] You used to be able to take this very basic
    behavior for granted٫ but since the arrival of the "single-page
    app"٫ it has become some kind of ancient forgotten wisdom.</p>

  <p>[<a name="fn5">5</a>] Eight seconds sounds like a very slow
    application (and it is!) but it"s hardly the worst offender for
    single-page applications. Trello takes 10 seconds٫ Jira takes 16
    seconds٫ and Slack takes 18 seconds.</p>

</div>

'),('https://technomancy.us/190', 'in which another game is jammed', '1557283961000',  10, '


<p>All the <a href="https://technomancy.itch.io/bussard">games</a>
  <a href="https://technomancy.itch.io/liquid-runner">I"ve</a>
    <a href="https://technomancy.itch.io/goo-runner">created</a>
    <a href="https://technomancy.itch.io/exo-encounter-667">previously</a>
    have used the <a href="https://love2d.org">LÖVE</a> framework٫
    which I heartily recommend and have really enjoyed using. It"s
    extremely flexible but provides just the right level of
    abstraction to let you do any kind of 2D game. I have even
    created <a href="https://git.sr.ht/~technomancy/polywell">a text
    editor</a> in it. But for
    the <a href="https://itch.io/jam/lisp-game-jam-2019">2019 Lisp
    Game Jam</a> I teamed up again
    with <a href="https://emmabukacek.com">Emma Bukacek</a> (we first
    worked together
    on <a href="https://technomancy.itch.io/goo-runner">Goo Runner</a>
    for the previous jam) and wanted to try something
    new: <a href="https://tic.computer">TIC-80</a>.</p>

<p><img src="/i/tic80.gif" alt="tic-80 screenshot" /></p>

<p>TIC-80 is what"s referred to as a "fantasy
  console"<sup><a href="#fn1">1</a></sup>; that is٫ a piece of
  software which embodies an imaginary computer which never actually
  existed. Hearkening back to the days of the Commodore 64٫ it has a
  16-color palette٫ a 64kb limit on the amount of code you can load
  into it٫ and 80kb of space for data (sprites٫ maps٫ sound٫ and
  music). While these limitations may sound severe٫ the idea is that
  they can be liberating because there is no pressure to create
  something polished; the medium demands a rough٫ raw style.</p>

<p>The really impressive thing about TIC-80 you notice right away is
  how it makes game development so accessible. It"s one file to
  download (or not even download; it runs perfectly fine in a browser)
  and you"re off to the races; the code editor٫ sprite editor٫ mapper٫
  sound editor٫ and music tracker are all built-in. But the best part
  is that you can explore other people"s games (with the <tt>SURF</tt>
  command)٫ and once you"ve played them٫ hit ESC to open the editor
  and see how they did it. You can make changes to the code٫
  sprites٫ etc and immediately see them reflected. This kind of
  explore-and-tinker approach encourages you to experiment and see for
  yourself what happens.</p>

<p>In fact٫ try it now! Go
  to <a href="https://technomancy.itch.io/this-is-my-mech">This is my
  Mech</a> and hit <tt>ESC</tt>٫ then go down to "close game" and
  press <tt>Z</tt> to close it. You"re in the console now٫ so
  hit <tt>ESC</tt> again to go to the editor٫ and press the sprite
  editor button at the top left. Change some of the character sprites٫
  then hit <tt>ESC</tt> to go back to the console and
  type <tt>RUN</tt> to see what it does! The impact of the accessibility and
  immediacy of the tool simply can"t be overstated; it calls out to be
  hacked and fiddled and tweaked.</a>

<p>Having decided on the platform٫ Emma and I threw around a few game
  ideas but landed on making an adventure/comedy game based on the
  music video <a href="https://m.youtube.com/watch?v=EMgsAD3D948">I"ll
  form the Head</a> by MC Frontalot٫ which is in turn a parody of the
  1980s
  cartoon <a href="https://en.m.wikipedia.org/wiki/Voltron">Voltron</a>٫
  a mecha series about five different pilots who work together to form
  a giant robot that fights off the monster of the week. Instead of
  making the game about combat٫ I wanted a theme of cooperation٫ which
  led to a gameplay focused around dialog and conversation.</p>

<p><img src="/i/head.png" alt="I"ll form the head music video" width="800" /></p>

<p>I focused more on the coding and the art٫ and Emma did most of the
  writing and all of the music. One big difference when coding on
  TIC-80 games vs LÖVE is that you can"t pull in any 3rd-party
  libraries; you have the Lua/Fennel standard library٫
  the <a href="https://github.com/nesbox/TIC-80/wiki#functions">TIC-80
  API</a>٫ and whatever you write yourself. In fact٫ TIC-80"s code
  editor supports only a single file. I"m mostly OK with
  TIC-80"s limitations٫ but that seemed like a bit much٫ especially
  when collaborating٫ so I split out several different files and
  edited them in Emacs٫ using a Makefile to concatenate them together
  and TIC-80"s "watch" functionality to load it in upon changes. In
  retrospect٫ while having functionality organized into different files
  was nice٫ it wasn"t worth the downside of having the line numbers
  be incorrect٫ so I wouldn"t do that part again.</p>

<p>The file watch feature was pretty convenient٫ but it"s worth noting
  that the changes were only applied when you started a new game. (Not
  necessarily restarting the whole TIC-80 program٫ just
  the <tt>RUN</tt> command.) There"s no way to load in new code from a
  file without restarting the game. You <em>can</em> evaluate new code
  with the <tt>EVAL</tt> command in the console and
  then <tt>RESUME</tt> to see the effect it has on a running game٫ but
  that only applies to a single line of code typed into the console٫
  which is pretty limiting compared to LÖVE"s
  full <a href="/189">support for hot-loading any module from disk at
  any time</a> that I wrote about previously. This was the biggest
  disadvantage of developing in TIC-80 by a significant
  margin. Luckily our game didn"t have much state٫ so constantly
  restarting it wasn"t a big deal٫ but for other games it would
  be.<sup><a href="#fn2">2</a></sup></p>

<p><b>Update</b>: I was able
  to <a href="https://github.com/nesbox/TIC-80/pull/840">add the above
    feature</a> with a small amount of code٫ and it was merged
  promptly. It will be included in TIC-80 version 0.80.0. You must
  launch the game with the <tt>-code-watch</tt> flag and run
  the <tt>RESUME</tt> command to activate it. In order to take
  advantage of this you need to store game state in a global and
  ensure not to overwrite that global if it already has a value.</p>

<p>Another minor downside of collaborating on a TIC-80 game is that
  the cartridge is a single binary file. You can set it up so it loads
  the source from an external file٫ but the rest of the game (sprites٫
  map٫ sound٫ and music) are all stored in one place. If you use git
  to track it٫ you will find that one person changing a sprite and
  another changing a music track will result in a conflict you can"t
  resolve using git. Because of this٫ we would claim a "cartridge
  lock" in chat so that only one of us was working on non-code assets
  at a time٫ but it would be much nicer if changes to sprites could
  happen independently of changes to music without conflict.</p>

<p><img src="/i/mech.gif" alt="screenshot of the game" /></p>

<p>Since the game consisted of mostly dialog٫
  the <a href="https://gitlab.com/emmabukacek/this-is-my-mech/blob/master/dialog.fnl">conversation
  system</a> was the central place to start. We used coroutines to
  allow a single conversation to be written in a linear٫ top-to-bottom
  way and react to player input but still run without blocking the
  main event loop. For instance٫ the function below moves the Adam
  character٫ says a line٫ and then asks the player a question which
  has two possible responses٫ and reacts differently depending on
  which response is chosen. In the second case٫ it
  sets <tt>convos.Adam</tt> so that the next time you talk to that
  character٫ a different conversation will begin:</p>
  
<pre class="code">(<span class="keyword">fn</span> <span class="variable-name">all.Adam2</span> []
  (move-to <span class="builtin">:Adam</span> 48 25)
  (say <span class="string">"Hey٫ sorry about that."</span>)
  (<span class="keyword">let</span> [answer (ask <span class="string">"What"s up?"</span> [<span class="string">"What are you doing?"</span>
                                  <span class="string">"Where"s the restroom?"</span>])]
    (<span class="keyword">if</span> (<span class="keyword">=</span> answer <span class="string">"Where"s the restroom?"</span>)
        (say <span class="string">"You can pee in your pilot suit; isn"t"</span>
             <span class="string">"technology amazing? Built-in"</span>
             <span class="string">"waste recyclers."</span>)
        (<span class="keyword">=</span> answer <span class="string">"What are you doing?"</span>)
        (<span class="keyword">do</span> (say <span class="string">"Well... I got a bit flustered and"</span>
                 <span class="string">"forgot my password٫ and now I"m"</span>
                 <span class="string">"locked out of the system!"</span>)
            (<span class="keyword">set</span> <span class="type">convos.Adam</span> <span class="type">all.Adam25</span>)
            (<span class="type">all.Adam25</span>)))))</pre>

<p>There was some syntactic redundancy with the questions which could
  have been tidied up with a macro. In older versions of Fennel٫ the
  macro system is tied to the module system٫ which is normally fine٫
  but TIC-80"s single-file restriction makes it so that style of
  macros were unavailable. Newer versions of Fennel don"t have this
  restriction٫ but unfortunately the latest stable version of TIC-80
  hasn"t been updated yet. Hopefully this lands soon! The new version
  of Fennel also includes pattern matching٫ which probably would have
  made a custom question macro unnecessary.</p>

<p>The vast majority of the code is dialog/conversation code; the rest
  is for walking around with collision detection٫ and flying around in
  the end-game sequence. This
  is <a href="https://gitlab.com/emmabukacek/this-is-my-mech/blob/master/launch.fnl">pretty
    standard animation fare</a> but was a lot of fun to write!</p>

<p><img src="/i/rhinos.gif" alt="rhinos animation" /></p>

<p>I mentioned TIC-80"s size limit already; with such a dialog-heavy game
  we did run into that on the last day. We were close enough to the
  deadline with more we wanted to add that it caused a bit of a
  panic٫ but all we had to do was remove a bunch of commented code
  and we were able to squeeze what we needed in. Next time around I would use
  single-space indents just to save those few extra bytes.</p>

<p>All in all I think the downsides of TIC-80 were well worth it for a
  pixel-art style٫ short game. Being able to publish the game to an
  HTML file and easily publish it
  to <a href="https://itch.io">itch.io</a> (the site hosting the jam)
  was very convenient. It"s especially helpful in a jam situation
  because you want to make it easy for as many people as possible to
  play your game so they can rate it; if it"s difficult to install a
  lot of people won"t do it. I"ve never done my own art for a game
  before٫ but having all the tools built-in convinced me to give it a
  try٫ and it turned out pretty good despite me not having any
  background in pixel art٫ or art of any kind.</p>

<p>Anyway٫ I"d encourage you to give the game a try. The
  game <a href="https://itch.io/jam/lisp-game-jam-2019/results">won
  first place</a> in the game jam٫ and you can finish it
  in around ten minutes in your browser. And if it looks like fun٫ why
  not make your own in TIC-80?</p>

<hr />

<p>[<a name="fn1">1</a>] The term "fantasy console" was coined
  by <a href="https://lexaloffle.com/pico-8.php">PICO-8</a>٫ a
  commercial product with limitations even more severe than
  TIC-80. I"ve done a few short demos with PICO-8 but I much prefer
  TIC-80٫ not just because it"s free software٫ but because it supports
  Fennel٫ has a more comfortable code editor٫ and has a much more
  readable font. PICO-8 only supports a fixed-precision decimal fork
  of Lua. The only two advantages of PICO-8 are the larger community
  and the ability to set flags on sprites.</p>

<p>[<a name="fn2">2</a>] I"m considering looking into adding support
  in TIC-80 for reloading the code without wiping the existing
  state. The author has been very friendly and receptive to
  contributions in the past٫ but this change might be a bit too much
  for my meager C skills.</p>

'),('https://technomancy.us/189', 'in which interactive development saves the day', '1525918301000',  10, '


<p>When I was
  writing <a href="https://technomancy.itch.io/exo-encounter-667">EXO_encounter
    667</a> in <a href="https://fennel-lang.org">Fennel</a>٫ I
  benefited immensely from the ability to do live reloads. Instead of
  having to restart the whole process٫ I could run a single key
  command from my editor and have the game see the new code
  immediately. This isn"t particularly difficult to do in Fennel٫ but
  it"s not immediately obvious at a glance either.</p>

<p>Before you understand how reloading works in Fennel٫ you need a
  little background regarding Lua"s module system٫ since Fennel is
  just a compiler that emits Lua code. Older versions of Lua had
  a <tt>module</tt> function which would declare the whole rest of the
  file as being part of a specific module and register that with the
  module system٫ and all functions that would normally be declared as
  global within that file would be exported as part of the module instead.
  But in version 5.1٫ that system was recognized as redundant:
  nowadays a module is just a file that returns a
  table<sup><a href="#fn1">1</a></sup> with closures and other values
  in it. This is reflects the relentless simplicity behind the design
  of Lua; why have modules as their own concept when tables and
  closures can do just as good a job?</p>

<p>So that"s all well and good; you can just write code that uses
  functions written in other files by just calling <tt>dofile</tt> on
  the filename and putting that value in a local. And that works٫ but
  every time you use the module from another place it loads a fresh
  copy٫ which is wasteful. Enter the <tt>require</tt> function. It
  takes a module name which maps to a filename (by searching the
  entries of <tt>package.path</tt>) and gives you the value returned
  by that file٫ but it also caches subsequent calls. So every time
  you <tt>require</tt> a module٫ you"re getting the exact same
  table<sup><a href="#fn2">2</a></sup> in the exact same memory
  location.</p>

<img src="/i/mtsth.jpg" alt="Valley near Mt. Saint Helens">

<p>We can take a little detour here from Lua land and back into
  Fennel٫ because <tt>dofile</tt> only works on Lua code. Fennel
  provides its own <tt>fennel.dofile</tt> function which works just
  like the built-in one٫ but on <tt>.fnl</tt> files instead. But what
  about <tt>require</tt>? Well it turns out <tt>require</tt> is
  implemented in a pretty clever way that allows us to teach it new
  tricks. The way <tt>require</tt> works is that it looks at
  the <tt>package.searchers</tt> table٫ (it"s <tt>package.loaders</tt> on
  Lua 5.1) which contains a list of searcher functions. It iterates over
  the list٫ calling each searcher with the module name. If that
  returns nil٫ it indicates that searcher can"t find the module and it
  moves on٫ but a searcher which can load the module will return a
  function which allows <tt>require</tt> to get (and cache) the value
  for the module in question. So simply by
  adding <tt>fennel.searcher</tt> to <tt>package.searchers</tt>٫ we
  can make it so that <tt>require</tt> works seamlessly on modules
  whether they are written in Fennel or Lua:</p>

<pre class="code">(<span class="keyword">local</span> fennel (<span class="builtin">require</span> <span class="string">"fennel"</span>))
(<span class="type">table.insert</span> <span class="type">package.searchers</span> <span class="type">fennel.searcher</span>)</pre>

<p>Now this seems somewhat academic; after all٫ you have a lot of
  memory; why do you care if modules are duplicated in memory? But
  using <tt>require</tt> for modules proved invaluable during the
  development of my game because it allowed me to do all my local
  hacking using <tt>.fnl</tt> files I was constantly editing٫ but
  when I prepared a release٫ I precompiled it all into <tt>.lua</tt>
  files and didn"t have to change a line of my code to reflect
  that.</p>

<p>Well that"s wonderful٫ but if <tt>require</tt> caches the value of
  each module٫ doesn"t that interfere with live reloading? Indeed it
  does; simply re-requiring a module has no effect. You can
  call <tt>fennel.dofile</tt> to get a <strong>copy</strong> of the updated
  module. But that"s no help to the existing code which has the old
  version of the module. What to do?</p>

<p>To understand the solution it"s helpful to make a distinction
  between the <strong>identity</strong> of the table and
  the <strong>values</strong> it contains. The identity of a table is
  what makes it truly unique; it can be thought of in terms of that
  table"s particular location in memory. When you pass a table to a
  function٫ that function has access to the exact same table٫ and
  changes made to it inside the function of course are visible to any
  other function that has access to the
  table<sup><a href="#fn3">3</a></sup>. The value of a table refers to
  what it contains; in the case of a module it"s usually about what
  functions are present under what keys. Since the tables are mutable٫
  the value can change over time but the identity cannot. When you
  call <tt>dofile</tt> on a module you get a table that might have the
  same <strong>values</strong> as last time you
  called <tt>dofile</tt>٫ (if the file on disk hasn"t changed)
  but it will never have the same <strong>identity</strong>. When you
  call <tt>require</tt> you"re guaranteed to get the exact
  same <strong>identical</strong> table every
  time.<sup><a href="#fn4">4</a></sup></p>

<p>With that background maybe you can see now how this might work. All
  the existing code has access to the original module table. We can"t
  swap out that table for a new one without reloading all the
  modules that use it٫ and that can be disruptive. But we can grab
  that original table٫ load a fresh <strong>copy</strong> of its module from
  disk٫ then go in and replace its <strong>contents</strong> with the
  values from the new one.</p>

<pre class="code">(<span class="keyword">defun</span> <span class="function-name">fennel-reload-form</span> (module-keyword)
  <span class="doc">"Return a string of the code to reload the </span><span class="doc"><span class="constant">module-keyword</span></span><span class="doc"> module."</span>
  (format <span class="string">"%s\n"</span> (<span class="keyword">let</span> [old (<span class="keyword">require</span> ٫module-keyword)
                            _ (tset package.loaded ٫module-keyword nil)
                            new (<span class="keyword">require</span> ٫module-keyword)]
                    <span class="comment-delimiter">;; </span><span class="comment">if the module isnt a table then we can"t make
</span>                    <span class="comment-delimiter">;; </span><span class="comment">changes which affect already-loaded code٫ but if
</span>                    <span class="comment-delimiter">;; </span><span class="comment">it is then we should splice new values into the
</span>                    <span class="comment-delimiter">;; </span><span class="comment">existing table and remove values that are gone.
</span>                    (<span class="keyword">when</span> (= (type new) <span class="builtin">:table</span>)
                      (each [k v (pairs new)]
                            (tset old k v))
                      (each [k (pairs old)]
                            <span class="comment-delimiter">;; </span><span class="comment">the elisp reader is picky about where . can be
</span>                            (<span class="keyword">when</span> (not (٫<span class="string">"."</span> new k))
                              (tset old k nil)))
                      (tset package.loaded ٫module-keyword old)))))</pre>

<p>The code above looks like Fennel٫ but it"s actually Fennel embedded
  inside Emacs Lisp code; because they"re both just made up of
  s-expressions٫ you can write Fennel code as Elisp code and quote it٫
  then send it to the Fennel repl subprocess which is launched
  with <kbd>M-x
    run-lisp</kbd>. My <a href="https://gitlab.com/technomancy/fennel-mode/commit/21e184b2a862290db9dcf839f0e4a2df480a642e">recent
    changes</a> to <tt>fennel-mode.el</tt> allow this to work out of
  the box٫ but they could easily be adapted to any other editor that
  supports communicating with an integrated repl subprocess.</p>

<p>Of course٫ all this background really isn"t necessary; you can just
  hit reload now and have it work with no fuss. But sometimes it"s
  interesting to understand why it works٫ and especially I think in
  this case the design decisions that went into the module system are
  noteworthy for allowing this kind of thing to be done in a graceful
  way٫ so that"s worth appreciating and hopefully learning from.</p>

<p><strong>Update</strong>: Charl Botha wrote up a great
  <a href="https://vxlabs.com/2018/05/18/interactive-programming-with-fennel-lua-lisp-emacs-and-lisp-game-jam-winner-exo_encounter-667">blog
  post</a> that goes into more detail about setting up the live reload
  functionality with Emacs.
</p>

<hr>
<div class="footnotes">

  <p>[<a name="fn1">1</a>] Technically a module can return any value٫
    not just a table. But if you return a non-table٫ then the
    reloading features described don"t work٫ because only tables can
    have their contents replaced while retaining their same object
    identity.</p>

  <p>[<a name="fn2">2</a>] Yep; this means you can abuse the module
    system to do terrible things like share application state across
    other modules. Please resist the temptation.</p>

  <p>[<a name="fn3">3</a>] Oddly enough in some languages this is not
    true and data structures default to being copied implicitly every
    time you pass them to a function٫ which can be very
    confusing. To muddle things even more٫ this behavior is referred
    to as "pass by value" instead of "we make copies of everything for
    you even when you don"t ask". That doesn"t happen here.</p>

  <p>[<a name="fn4">4</a>] For a fascinating discussion of the
    difference between value and identity and how it relates to
    equality I strongly recommend reading the very
    insightful <a href="http://home.pipeline.com/~hbaker1/ObjectIdentity.html">Equal
    Rights for Functional Objects</a> which goes into much more depth
    on this subject. Notably Lua"s (and Fennel"s) equality semantics
    are consistent with its recommendations despite Lua being an
    imperative language.</p>
</div>
'),('https://technomancy.us/188', 'in which a game jam is recounted further', '1525572303000',  10, '


<p>This is the second part continuing my <a href="/187">previous
    post</a> about creating the
  game <a href="https://technomancy.itch.io/exo-encounter-667">EXO_encounter
    667</a> using <a href="https://fennel-lang.org">the Fennel
    programming language</a> and the <a href="https://love2d">LÖVE</a>
  game framework for
  the <a href="https://itch.io/jam/lisp-game-jam-2018/">Lisp Game
    Jam 2018</a>; you"ll probably want to read the first installment
  if you haven"t already. I wrote about the game design and art٫ but
  in this post I"d like to dive into the more technical aspects of
  the game.</p>

<img src="/i/exo-term.png" alt="exo encounter terminal" class="right">

<p>The <a href="https://itch.io/jam/lisp-game-jam-2018/results">voting
    for the game jam</a> just closed٫ and EXO_encounter 667 came in
  ranked first! Three out of the top four winners are LÖVE
    games; <a href="https://verma.itch.io/gravity-fall">one other in
    Fennel</a> and <a href="https://tmw.itch.io/need-for-seeds">one
    in Urn</a>.</p>

<h4>Libraries</h4>

<p>I pulled in a couple libraries on top of LÖVE to help out in a few
  areas. First and foremost I would dread to do any work on the Lua
  runtime without <a href="https://github.com/rxi/lume">lume</a>٫ which
  I like to think of as Lua"s "missing standard library". It brings
  handy things like <tt>filter</tt>٫ <tt>find</tt>٫ <tt>reduce</tt>٫
  etc. It"s mostly sequence-related functions٫ but there are a few
  other handy functions as well like <tt>split</tt>٫ a bizarre
  omission from the standard library٫ or <tt>hotswap</tt> which I"ll
  get to below.</p>

<p>The <a href="https://github.com/kikito/bump.lua">bump.lua</a>
  library is used for collision detection٫ and as long as you only
  need to operate in terms of axis-aligned rectangles٫ it is very easy
  to use and gets the job done with no
  fuss.<sup><a href="#fn1">1</a></sup> But one of the nicest things
  about bump is that it"s integrated
  into <a href="https://github.com/Karai17/Simple-Tiled-Implementation">Simple
  Tiled Implementation</a>٫ which handles maps exported
  from <a href="http://www.mapeditor.org">Tiled</a>. On its own the
  Tiled library just handles drawing them (including their animations
  and layering)٫ but it can automatically integrate with bump if you
  set properties on a layer or object to flag it as <tt>collidable</tt>.</p>

<p>The documentation for the Tiled library unfortunately leaves quite a bit
  to be desired; it"s one of those projects that just dumps a list of
  all functions with a line or two describing what each one does and
  considers that "the documentation". Fortunately the source is pretty
  readable٫ but figuring out how to handle opening and closing of
  doors was definitely the roughest spot when it came to 3rd-party
  libraries. The readme does describe how to implement a custom
  drawing routine for a layer٫ which allows us to draw a door
  differently based on whether it"s closed or open. The problem is
  there"s no easy way to do the same thing for the collision
  detection side of the story.</p>

<p>The Tiled library handles setting up the "world" table from bump by
  seeding it with all the <tt>collidable</tt> things from the map. The
  problem is it doesn"t actually use the same tables from the map when
  adding them to the bump table; it wraps them in bump-specific tables
  stripping it down to just the fields relevant to collision
  detection. This is fine until have a door you need to open. Normally
  you"d do this by calling <tt>bump.remove</tt> with the door table to
  make the door no longer take part in collision detection٫ but bump
  doesn"t know about the door table; it only knows about the wrapper
  table٫ which we no longer have access to.</p>

<p>I ended
  up <a href="https://gitlab.com/technomancy/exo-encounter-667/commit/a90ccb4e99c90378d086adb6f542310789e3d83c">hacking
  around this</a> by making the Tiled library save off all the wrapper
  tables it created٫ and introducing a new <tt>bump_wrap</tt> function
  on the map which would intercept methods on the bump world٫ accept a
  regular table and look up the wrapped table and use it instead in
  the method call. It got the job done quickly٫ but I couldn"t help
  but feel there should be a better way. I"ve
  opened <a href="https://github.com/karai17/Simple-Tiled-Implementation/issues/180">an
  issue</a> with the Tiled library to see if maybe I missed an
  undocumented built-in way of doing this. But as far as the coding
  went٫ this was really the only hiccup I encountered with any of the
  libraries I used.</p>

<h4>Interactive Development</h4>

<p>As a lisp٫ of course Fennel ships with a REPL (aka interactive
  console٫ often mistakenly called an "interpreter") which allows you
  to enter code and see the results immediately. This is absolutely
  invaluable for rapid game development. There"s a bit of a hiccup
  though; the REPL reads from standard in٫ and LÖVE doesn"t ship with
  a method for reading from standard in without blocking. Since Lua
  doesn"t have concurrency٫ this means reading repl input would block
  the whole game loop until enter was pressed! LÖVE saves the day here
  by allowing you to construct
  "<a href="http://love2d.org/wiki/love.thread">threads</a>" which are
  really just completely independent Lua virtual machines that can
  <a href="/183">communicate with each other over queues</a> but can"t
  share any data directly. This turns out to be just fine for the
  repl; one thread
  can <a href="https://gitlab.com/technomancy/exo-encounter-667/blob/master/stdio.fnl">sit
  and block on standard in</a>٫ and when it gets input send it over a
  queue to the main thread which evaluates and sends the response
  back.</p>

<pre class="code">(<span class="keyword">defn</span> <span class="variable-name">start-repl</span> []
  (<span class="keyword">let</span> [code (<span class="type">love.filesystem.read</span> <span class="string">"<a href="https://gitlab.com/technomancy/exo-encounter-667/blob/master/stdio.fnl">stdio.fnl</a>"</span>)
        lua (<span class="type">love.filesystem.newFileData</span> (<span class="type">fennel.compileString</span> code) <span class="string">"io"</span>)
        thread (<span class="type">love.thread.newThread</span> lua)
        io-channel (<span class="type">love.thread.newChannel</span>)]
    <span class="comment-delimiter">;; </span><span class="comment">this thread will send "eval" events for us to consume:
</span>    (<span class="keyword">:</span> thread <span class="builtin">:start</span> <span class="string">"eval"</span> io-channel)
    (<span class="keyword">set</span> <span class="type">love.handlers.eval</span>
         (<span class="keyword">fn</span> [input]
           (<span class="keyword">let</span> [(ok val) (<span class="builtin">pcall</span> <span class="type">fennel.eval</span> input)]
             (<span class="keyword">:</span> io-channel <span class="builtin">:push</span> (<span class="keyword">if</span> ok (view val) val)))))))</pre>

<p>As I use Emacs٫ I"ve
  configured <a href="https://gitlab.com/technomancy/fennel-mode">fennel-mode</a>
  to add a key combo for reloading the module for the current
  buffer. This only works if the current file is in the root directory
  of the project; it won"t work with subdirectories as the module name
  will be wrong٫ but it"s pretty helpful. It also
  requires <tt>lume</tt> be defined as a global variable. (Normally I
  avoid using globals٫ but I make two exceptions; one
  for <tt>lume</tt> and another for <tt>pp</tt> as a pretty-print
  function.) I haven"t included this in <tt>fennel-mode</tt> yet
  because of these gotchas; maybe if I can find a way to remove them
  it can be included as part of the mode itself in the future.</p>

<p>Simply run <kbd>C-u M-x run-lisp</kbd> to start your
  game٫ and use <kbd>love .</kbd> as your command. Once that"s
  started٫ the code below will make <kbd>C-c C-k</kbd> reload the
  current module.</p>

<pre class="code">(eval-after-load "fennel-mode
  "(define-key fennel-mode-map (kbd <span class="string">"C-c C-k"</span>)
     (<span class="keyword">defun</span> <span class="function-name">pnh-fennel-hotswap</span> ()
       (<span class="keyword">interactive</span>)
       (comint-send-string
        (inferior-lisp-proc)
        (format <span class="string">"(lume.hotswap \"%s\")\n"</span>
                (substring (file-name-nondirectory (buffer-file-name)) 0 -4)))))<span class="whitespace-line">)</span></pre>

<p><strong>Update</strong>: I added first-class support for reloads
  to <a href="https://gitlab.com/technomancy/fennel-mode">fennel-mode</a>٫
  though you will still need the stdin hack described above when using
  it inside LÖVE. <!-- 
I <a href="/189">wrote more about reloading</a>.--></p>

<p>The other gotcha is that currently an error will crash your whole
  game. I really wanted to add an error handler which would allow you
  to resume play after reloading the module that crashed٫ but I didn"t
  have time to add that. Hopefully I"ll have that ready in time for
  the next jam!</p>

<h4>Tutorial</h4>

<p>From a usability perspective٫ one of the most helpful things was
  adding a tutorial to explain the basic controls and mechanics. The
  tutorial displays instructions onscreen until the point at which the
  player carries out those instructions٫ at which point it moves on to
  the next instructions. There are various ways you could go
  about doing this٫ but I chose to implement it
  using <a href="https://www.lua.org/pil/9.1.html">coroutines</a>٫
  which are Lua"s way of
  offering <a href="https://en.wikipedia.org/wiki/Cooperative_multitasking">cooperative
    multitasking</a>.</p>

<pre class="code">(<span class="keyword">defn</span> <span class="variable-name">tutorial</span> [state world map dt]
  (echo <span class="string">"Press 2 to select rover 2; bring it near the"</span>
        <span class="string">"main probe and press enter to dock."</span>)
  (<span class="keyword">while</span> (not (<span class="keyword">.</span> <span class="type">state.rovers</span> 2 <span class="builtin">:docked?</span>))
    (<span class="type">coroutine.yield</span>))

  (echo <span class="string">"With at least 3 rovers docked٫ the main"</span> <span class="string">"probe has mobility."</span>
        <span class="string">""</span> <span class="string">"Now do the same with rover 3."</span>)
  (<span class="keyword">while</span> (not (<span class="keyword">.</span> <span class="type">state.rovers</span> 3 <span class="builtin">:docked?</span>))
    (<span class="type">coroutine.yield</span>))

  (echo <span class="string">"The probe"s communications laser can be"</span>
        <span class="string">"activated by holding space. Comma and"</span>
        <span class="string">"period change the aim of the laser."</span>)
  (<span class="keyword">while</span> (not (<span class="keyword">or</span> (<span class="keyword">and</span> <span class="type">state.laser</span> (<span class="keyword">~=</span> <span class="type">state.selected.theta</span> <span class="type">math.pi</span>))
                  (<span class="keyword">&gt;</span> (<span class="keyword">:</span> world <span class="builtin">:getRect</span> <span class="type">state.selected</span>) 730)
                  (sensor? map <span class="string">"first"</span>)))
    (<span class="type">coroutine.yield</span>))

  <span class="keyword">...</span>)</pre>

<p>The <tt>tutorial</tt> function runs inside a coroutine started
  with <tt>coroutine.wrap</tt>; it echoes the first message and then
  suspends itself with <tt>coroutine.yield</tt> which returns control
  to the caller. On every tick٫ the <tt>love.update</tt> function
  <tt>coroutine.resume</tt>s it which allows it to check whether the
  conditions have been fulfilled. If so it can move on to the next
  instruction; otherwise it just yields back immediately. Of course٫
  it would be possible to do something like this using only closures٫
  but coroutines allow it to be written in a very linear٫
  straightforward way.</p>

<img src="/i/exo-laser.png" alt="exo encounter laser screenshot">

<h4>Distribution</h4>

<p>With LÖVE you get portability across many operating systems;
  however it does not actually handle creating the executables for
  each platform. I used an old version
  of <a href="https://github.com/MisterDA/love-release/">love-release</a><sup><a href="#fn2">2</a></sup>
  to create zip files which include everything you need to run on
  Windows and Mac OS. This was a huge help; I could run my entire
  build from my Debian laptop without even touching a Windows machine
  or a Mac.</p>

<p>For the jam I just published a <tt>.love</tt> file for other
  platforms٫ which requires you to manually install LÖVE
  yourself. This is a bit of a drag since most package managers don"t
  include the correct version of LÖVE٫ and even if they did today٫ in
  the future they"d upgrade to a different one٫ so this is one place
  where relying on the package manager is definitely not going to cut
  it. Soon after the jam I
  discovered <a href="https://appimage.org/">AppImages</a> which are a
  way of bundling up all a program"s dependencies into a single
  executable file which should work on any Linux distribution. While I
  think this is a really terrible idea for a lot of software٫ for a
  single-player game that doesn"t load any data from untrusted
  sources٫ I believe it to be the best option. The love-release tool
  doesn"t currently support creating AppImages٫ but I am hoping to add
  support for this. I also didn"t get around to automating uploading
  of builds to itch.io
  using <a href="https://itch.io/docs/butler/">butler</a>٫ but I"m
  hoping to have that working for next time.</p>

<h4>Play my game!</h4>

<p>Now that the jam is over٫ I"ve gotten some great feedback from
  players that resulted
  in <a href="https://gitlab.com/technomancy/exo-encounter-667/blob/master/todo.md">a
  nice todo list</a> of items that can be improved. I hope to release
  a "special edition" in the near future that includes all the things
  I wasn"t able to get to during the jam. But in the mean time٫ I hope you
  enjoy <a href="https://technomancy.itch.io/exo-encounter-667">EXO_encounter
    667</a>!</p>

<hr>
<div class="footnotes">

  <p>[<a name="fn1">1</a>] LÖVE ships with
    a <a href="https://love2d.org/wiki/love.physics">physics engine</a>
    built-in٫ but the API it uses is much more complicated. It"s capable
    of more sophisticated behavior٫ but unless you <em>really</em> can"t
    work in terms of rectangles٫ I"d recommend sticking with the much
    simpler bump.lua.</p>

  <p>[<a name="fn2">2</a>] The love-release project has since been
    rewritten in Lua instead of being a shell script as it was at the
    time I downloaded the version I used. I haven"t tried the new
    version but it looks promising.</p>

</div>
'),('https://technomancy.us/187', 'in which a game jam is recounted', '1525316896000',  10, '

<p>This past weekend I just finished competing in
  the <a href="https://itch.io/jam/lisp-game-jam-2018/">Lisp Game Jam
  2018</a>. While I"d made
  a <a href="https://technomancy.itch.io/liquid-runner">game under
  game-jam-like constraints</a> I had never officially participated in
  one before٫ so this one was a perfect place to start. I wrote my game in
  the <a href="https://fennel-lang.org">Fennel</a> programming
  language using the <a href="https://love2d.org">LÖVE</a> game
  framework. The game is
  called <a href="https://technomancy.itch.io/exo-encounter-667">EXO_encounter
  667</a>; you play an unmanned probe exploring the exoplanet
  <a href ="https://en.wikipedia.org/wiki/Gliese_667_Cc">Gliese 667
  Cc</a> that uncovers remains of an ancient outpost.</p>

<p><strong>Update</strong>: I"m proud to say that EXO_encounter 667
  won <a href="https://itch.io/jam/lisp-game-jam-2018/results">first
    place</a> in the game jam!</p>

<img src="/i/exo1.png" alt="exo encounter title screen" class="right" />

<p>Overall I"m thrilled with how it turned out; at the end of the jam
  I ended up with a game I"m very proud of. This game jam is a
  little unusual in that it ran over the span of ten days; most jams
  limit you to closer to 3 days and end up being much more of a
  crunch. Ten days was enough time to make something fairly polished
  (though of course still short) without pulling a bunch of
  all-nighters.</p>

<h4>The Language</h4>

<p>Using Fennel allowed me to take advantage of a bunch of existing
  tools without starting from square one. I had used the LÖVE
  framework before٫ but only from Lua. As I <a href="/186">blogged
  about previously</a>٫ Fennel is a lisp language which compiles to
  Lua output and stays very close to Lua semantics٫ which means it"s
  very easy to use tools and libraries from the Lua world. I can"t
  speak to how it would hold up in a larger codebase (the game ended
  up being only 667 lines of code)٫ but I felt that for this project
  using Fennel with LÖVE and a couple helper libraries put me on
  nearly the perfect level of abstraction. I ran into one minor
  problem with Fennel where the line numbering of the output wasn"t
  quite right٫ but I was able to fix it quickly in-flight.</p>

<h4>Art and Music</h4>

<img src="/i/hard-vacuum.png" alt="hard vacuum screenshot" class="left">

<p>One of the limitations of the jam is that all game coding and level
  design must be done during the ten days of the jam٫ but if you have
  pre-made assets you can use them as long as they"re
  freely-licensed. I found like I hit the jackpot when I stumbled
  across <a href="http://www.lostgarden.com/2005/03/game-post-mortem-hard-vacuum.html">Daniel
  Cook"s Hard Vacuum tileset</a>. Created in 1993 for a Dune2-inspired
  strategy game٫ it was released under a Creative Commons license
  because the game was never finished. I was really impressed with the
  impeccable pixel art and the wide variety of terrain and buildings
  available in the set. Often when you are looking for freely-licensed
  art it"s not that hard to find what you need if you look across
  various sets٫ but combining several sets leads to some pretty
  jarring inconsistencies in visual style. Here I found one set which
  had basically everything I
  needed.<sup><a href="#fn1">1</a></sup></p>

<p>I also found a couple pieces of music that I felt really fit the
  theme I was going for: ambient and thoughtful to put you in the mood
  of exploring on a distant planet that took hundreds of years to
  reach. My son helped me choose
  <a href="https://opengameart.org/content/galactic-temple">Galactic
  Temple</a> for the main theme٫ and for the endgame I used the
  slightly more
  upbeat <a href="https://opengameart.org/content/freelance">Bazaar
  Net</a> by Max Stack٫ who also composed music I used for
  the <a href="https://www.youtube.com/watch?v=r_gdeS3d6F8">trailer of
  another of my games</a>.</p>

<h4>Design</h4>

<p>I had sketched out a plan up-front which I <em>mostly</em> was able
  to stick to; the main thing I cut scope on was the level layout. The
  original plan had the map divided into three sections: one where you
  approach the base٫ one base where all the text is in Russian٫ and the
  other base where things are in English. Because the aliens
  abandoned the outpost in 1999٫ the signals they received from Earth were
  from 1976 when the space race was still in full swing٫ so they were
  preparing for first-contact with Russia as well as the US. This was
  supposed to be part of the mystery you uncovered٫ but in the end it
  was just too meandering٫ and the final product ended up a lot more
  focused with a single base containing six doors you had to figure
  out how to open.</p>

<img src="/i/exo-tiled.png" alt="terminal" class="right">

<p>I spent most of the jam on a business trip where I had the evenings
  alone in a hotel room٫ so I was able to get a lot done there. I
  wrote the entire story text
  from <a href="https://www.dnapizza.com/">DNA Pizza</a>٫ a 24-hour
  pizza shop owned by <a href="https://www.jwz.org/blog">JWZ</a> that
  features bizarre٫ surreal music
  videos.<sup><a href="#fn2">2</a></sup> For something written in 2
  hours I"m really happy with how the story turned out; it was
  inspired heavily by
  the <a href="http://marathon.bungie.org/story/">the mythos of
  Marathon series</a> as well as
  the <a href="https://en.wikipedia.org/wiki/The_Three-Body_Problem_(novel)">Three
    Body Problem</a> novel.</p>

<p>But when on Saturday I got home from my trip and still didn"t have
  any puzzles ready٫ I started to get a little worried. Not only did I
  not have any puzzles٫ I also didn"t really have any
  idea <em>how</em> I would make puzzles in the first place or what
  would be fun. I sat down with my kids
  in <a href="http://www.mapeditor.org">the Tiled map editor</a> and
  just worked thru a progression of the mechanics I had implemented so
  far٫ starting with using the probe"s laser to trigger sensors which
  open doors٫ and working up thru reflecting the laser off one of your
  rovers٫ to a multiple reflection chain puzzle٫ and that worked
  better than I expected.</p>

<p>The next day eight hours before the competition closed I had half a
  map worth of puzzles and was running out of ideas. The reflection
  mechanic I had implemented was solid٫ but it wasn"t enough to carry
  the game by itself. In about an hour I added in beam splitters as
  well as sensors which would only open the door as long as the laser
  remained on them. My son came up with the idea for the last puzzle
  involving <span class="spoiler">splitting the laser and then
  reflecting the laser back into the splitter to get three
  beams</span> which I felt worked really well.</p>

<p>In the end٫ I was able to finish the map within the last
  hour before the deadline٫ but just barely.</p>

<h4>What worked well٫ and what didn"t</h4>

<p>The versatility and ease of use of Tiled impressed me greatly. Once I
  loaded up my tileset into it٫ I had a tool simple enough that I
  could put my kids in front of it and they could make genuinely
  helpful contributions to the map. Highly recommended! All the
  collision and layer data is part of the map٫ as well as all the
  non-player animations.</p>

<p>Each object in the Tiled map contains a set of properties I used
  for various purposes; for instance I set a "door" property on each
  laser sensor switch to indicate which door should open when it was
  triggered. Early on I found myself making a lot of mistakes where I"d
  forget to set a property٫ so I added
  a <a href="https://gitlab.com/technomancy/exo-encounter-667/tree/master/lint.fnl">linter</a>
  which would error out early if it detected that a certain type of
  object was missing a required property or if a sensor referred to a
  door that didn"t exist. This saved me a lot of fruitless manual
  debugging٫ and I"d strongly suggest doing something like it if you
  use map object properties.</p>

<p>I tried to introduce each mechanic with a very simple puzzle before
  moving on to non-obvious tricks. (I really messed up the difficulty
  curve near the end; the second-to-last puzzle is a fair bit more
  difficult than the last one.) This can be really tricky to do
  depending on your mechanics; I had one player who didn"t see the
  message that explained how to aim because he accidentally skipped
  ahead by opening a door too soon. After the jam I went back and
  fixed this by starting off with the laser aimed in the wrong
  direction٫ so it"s impossible to open the door without first
  aiming.</p>

<p>Using LÖVE was an obvious win; I got so much functionality for free
  as well as compatibility across operating systems and access to
  third-party libraries like the Tiled renderer. I wasn"t sure how it
  would work to use Fennel for this٫ but looking back on it I find it
  remarkable how seamless it felt. The language just got out of
  the way and let me focus on the task at hand; I barely noticed
  it. <strong>Update</strong>: surprisingly٫ you
  can <a href="https://gitlab.com/technomancy/exo-encounter-667/blob/master/.luacheckrc">run
    the Lua linter</a> on the output of the Fennel compiler and still
  get helpful results!</p>

<p>In the last hour I got my wife to playtest the game٫ which yielded
  some interesting insights. (Why can the rovers move forward but not
  backward? I just didn"t think of it.) I found that having my kids
  playtest continually as the game evolved meant that they didn"t see
  certain flaws; things that were clear to them weren"t obvious to
  first-time players. (Of course٫ as the author I expect to be blind
  to many flaws myself.) In particular٫ getting a precise aim of the
  laser was much too difficult because the turn speed was too fast. I
  added a "hold shift to turn slowly" feature early on٫ but it wasn"t
  introduced in the tutorial and you had to read the help text to see
  it. In the future I"d make more of an effort to get playtesting
  feedback earlier on in the process.</p>

<p>Speaking of the tutorial٫ having a tutorial was very helpful in
  introducing the mechanics. The implementation of the tutorial had
  some interesting technical features٫ but I will save that for part 2
  of this post. Thanks for reading٫ and please enjoy playing
  <a href="https://technomancy.itch.io/exo-encounter-667">EXO_encounter 667</a>.</p>

<p><strong>Update</strong>: <a href="/188">part 2</a> is published.</p>

<hr>

<div class="footnotes">

<p>[<a name="fn1">1</a>] I did need two other graphical assets: intro
  and endgame screens. For those I used Creative-Commons-licensed
  <a href="https://commons.wikimedia.org/wiki/File:Sky_around_Gliese_667C.jpg">photos</a>
  and <a href="https://commons.wikimedia.org/wiki/File:Gliese_667.jpg">renders</a>
  of Gliese 667 from
  the <a href="https://en.wikipedia.org/wiki/European_Southern_Observatory">European
  Southern Observatory</a>.</p>

<p>[<a name="fn2">2</a>] I have this tradition where every time I"m in
  San Francisco I try to go to JWZ"s pizza place and
  read <a href="https://www.jwz.org/blog">JWZ"s blog</a> and also use
  Emacs٫
  which <a href="https://www.jwz.org/doc/emacs-timeline.html">JWZ had
    a hand in the development of</a> in the 90s.</p>
</div>
'),('https://technomancy.us/186', 'in which a compiler gets its wings', '1520094916000',  10, '

<p>I"ve enjoyed writing Lua code for
  my <a href="https://gitlab.com/technomancy/bussard">side</a>
  <a href="https://gitlab.com/technomancy/polywelL">projects</a> for the
  most part. It has a few quirks٫ but many of them can be solved
  by <a href="https://github.com/mpeterv/luacheck">a little linting</a>.
  For a non-homoiconic language there is little in the syntax to
  object to٫ and the aggressively minimalist semantics more than make up for
  the few shortcomings.</p>

<p>Still٫ I always wondered what it would be like to use a language that
  compiled to Lua and didn"t have problems like the statement vs
  expression distinction٫ lack of arity checks٫ or defaulting to
  globals. Over the past year or so I looked at several such
  languages<sup><a href="#fn1">1</a></sup>٫ but nothing ever stuck. Then a
  few weeks ago I
  found <a href="https://github.com/bakpakin/Fennel">Fennel</a> (at the
  time called "fnl")٫ and it really resonated with me.</p>

<p><b>Update</b>: Fennel got <a href="https://fennel-lang.org">its own
    web site</a> with an in-browser repl and tutorial.</p>

<h4>The Microlanguage</h4>

<img src="i/snowy-sidewalk.jpg" alt="snowy sidewalk" class="right">

<p>The thing that sets Fennel apart is that it is strictly about adding
  new syntax to Lua and keeping Lua"s semantics. This allows it to operate
  as a compiler which introduces <em>no runtime overhead</em>. Code in
  Fennel translates trivially to its Lua equivalent:</p>

<pre class="code">(<span class="keyword">let</span> [x (<span class="keyword">+</span> 89 5.25)
      f (<span class="keyword">fn</span> [abc] (<span class="builtin">print</span> (<span class="keyword">*</span> 2 abc)))]
  (f x))</pre>

<p>... becomes ...</p>

<pre class="code"><span class="keyword">do</span>
  <span class="keyword">local</span> <span class="variable-name">x</span> = (89 + 5.25)
  <span class="keyword">local</span> <span class="keyword">function</span> <span class="function-name">_0_</span>(abc)
      <span class="keyword">return</span> <span class="builtin">print</span>((2 * abc))
  <span class="keyword">end</span>
  <span class="keyword">local</span> <span class="variable-name">f</span> = _0_
  <span class="keyword">return</span> f(x)
<span class="keyword">end</span></pre>

<p>There are a few quirks around introducing temporary variable names in
  cases where it"s unnecessary like the above٫ but these are only
  readability concerns and do not affect the performance of the code٫
  since Lua is smart enough to collapse it down. The
  temporary locals are introduced in order to ensure that every form in
  Fennel has a value; there are no statements٫ only expressions. This
  fixes a common problem in Lua where you can"t use an <tt>if</tt> to
  calculate the value of an expression٫ because it"s implemented as a
  statement٫ so you have to construct complex <tt>and</tt>/<tt>or</tt>
  chains to simulate <tt>if</tt> expressions. Plus it"s just simpler and
  more consistent to omit statements completely from the language semantics.</p>

<p>The one exception to the no-overhead rule is Fennel"s <tt>lambda</tt> form.
  Fennel"s <tt>fn</tt> keyword compiles straight to a no-nonsense
  Lua <tt>function</tt> with all that implies. But Lua"s <tt>function</tt>
  has one feature that is quite error-prone: it doesn"t check to ensure
  that it was called with the correct number of arguments. This leads
  to <tt>nil</tt> values easily getting propagated all thru the call stack
  by mistake. Fennel"s solution to this is <tt>lambda</tt>٫ which includes
  checks to ensure that this doesn"t happen. This function will signal an
  error when it"s called with zero or one argument٫ but the <tt>?w</tt>
  and <tt>?h</tt> arguments are optional:</p>

<pre class="code">(<span class="keyword">lambda</span> [x y ?w ?h]
  (make-thing {<span class="builtin">:x</span> x <span class="builtin">:y</span> y
               <span class="builtin">:width</span> (<span class="keyword">or</span> ?w 10) <span class="builtin">:height</span> (<span class="keyword">or</span> ?h 10)}))</pre>

<p>The other main difference between Fennel and Lua is that Fennel takes
  more care to distinguish between sequential tables and key/value
  tables. Of course on the Lua runtime there is no difference; only one
  kind of table exists٫ and whether it is sequential or not is just a
  matter of how it"s constructed or used. Lua uses <tt>{}</tt> notation
  for all tables٫ but Fennel allows you to construct sequential tables
  (array-like tables which have consecutive integers as keys)
  using <tt>[]</tt> instead. Lua overloads the <tt>for</tt> keyword to
  iterate over a numeric range as well as to work with generic iterators
  like <tt>pairs</tt> for values in tables. Fennel uses <tt>each</tt> for
  the latter٫ which makes the difference clearer at a glance.</p>

<h4>The Compiler</h4>

<p>To be clear٫ these are very small improvements over Lua. Normally I
  wouldn"t consider switching to a new language over such things. But
  Fennel is unique in its simplicity and lack of overhead٫ so it doesn"t
  cost much to bring it in. When I found out about Fennel٫ it was an
  experimental compiler that had been written over the course of one week
  in 2016 and then forgotten. But I was impressed with how <em>useful</em>
  it was after only that week of development. I could see at a glance that
  in around a thousand lines of code it had a functional compiler that
  output fairly readable Lua code and fixed the problem of statements.</p>

<p>So I dived into the codebase and started adding a few conveniences٫
  starting with a test case and some static analysis. When Fennel"s
  creator Calvin Rose saw what I was doing٫ he gave me feedback and
  started to pick back up on development too. As I got more comfortable
  with the code I started adding features٫
  like <tt>each</tt>٫ <tt>when</tt>٫ and comments. Then I started putting
  it thru the paces by porting some of my existing Lua programs
  over<sup><a href="#fn2">2</a></sup>. This went much more smoothly than I
  anticipated. I did find a few compiler bugs٫ but they were either easy
  to fix myself or fixed quickly by Calvin Rose once I pointed them
  out. Once I had a few programs under my belt I wrote
  up <a href="https://github.com/bakpakin/Fennel/blob/master/tutorial.md">an
  introductory tutorial</a> to the language that you should read if you
  want to give it a try.</p>

<img src="i/tumwater-rapids.jpg" alt="Tumwater falls٫ with raging water">

<h4>But what about the lines?</h4>

<p>But one thing really bothered me when writing Fennel programs. When you
  needed to debug٫ the Lua output was fairly readable٫ but you quickly ran
  into the curse of all source→source compilers: line numbers didn"t add
  up. Some runtimes allow you to provide source maps which change the
  numbering on stack traces to match the original source code٫ but Lua
  runtimes don"t offer this. If your compiler emits bytecode instead of
  source٫ you can set the line numbers for functions directly. But then
  you"re tied to a single VM and have to sacrifice portability.</p>

<p>So what"s a poor compiler to do? This being Fennel٫ the
  answer is "the simplest thing possible". In this case٫ the simplest
  thing is to track the line number when emitting Lua source٫ and only
  emit newlines when it"s detected that the current output came from
  input with a line number greater than the one it"s currently on.</p>

<p>For most compilers٫ this naive approach would quickly fall to
  pieces. Usually you can"t rely on the output being in the same order as
  the input that generated it<sup><a href="#fn3">3</a></sup>. I honestly
  did not have high hopes for this when I started working on it. But
  because of Fennel"s 1:1 simplicity and predictability٫ it actually works
  surprisingly well.</p>

<h4>The future?</h4>

<p>At this point I"m pretty happy with where the compiler is٫ so my own
  plans are mostly just to write more Fennel code. The
  upcoming <a href="https://itch.io/jam/lisp-game-jam-2018">Lisp Game
  Jam</a> will be a perfect excuse to do just that. I have a few ideas for
  further compiler improvements٫ like associative destructuring (sequential
  destructuring already works great)٫ pattern matching٫ or even making the
  compiler self-hosting٫ but there"s nothing quite like getting out there
  and banging out some programs.</p>

<hr>

<div class="footnotes">
  <p>[<a name="fn1">1</a>]
    Here"s a list of the lisps I found that compile to Lua and my brief
    impression of them:</p>
  <dl style="font-size: 140%;">
    <dt><a href="https://github.com/leafo/moonlisp">Moonlisp</a></dt>
    <dd>An experimental lisp by the creator of Moonscript. Looks neat٫ but
      it requires an alpha build of Moonscript 0.2.0 from 2012 to run.</dd>

    <dt><a href="https://github.com/larme/hua">Hua</a></dt>
    <dd>Inspired by <a href="http://hylang.org">Hy</a>٫ this seems to be
      an improvement over Hy٫ since the latter inherits some of Python"s
      unfortunate design bugs around scoping. If you"re a Hy user٫ this
      might be a nice way to trade library availability for speed and
      consistency٫ but since the compiler is written in Hy it means you
      need two runtimes٫ which complicates deployment.</dd>

    <dt><a href="https://github.com/raph-amiard/clojurescript-lua">ClojureScript-Lua</a></dt>
    <dd>This looked promising when it was first announced٫ but it was
      based on a <em>very</em> early version of ClojureScript that was
      still quirky and didn"t have a repl٫ and was abandoned a few
      months after it was announced. It has the same problem of
      requiring a separate runtime for the compiler as Hua٫ except that
      runtime needs dramatically greater resources.</dd>

    <dt><a href="https://github.com/kstep/scheme.lua">scheme.lua</a></dt>
    <dd>This actually looks pretty nice if you like Scheme. It"s pretty
      immature٫ but probably wouldn"t take that much work to get to a
      usable state. Personally I find Lua tables to be much more friendly
      to work with than Scheme"s lists٫ so sticking strictly with Scheme"s
      semantics seems like a step backwards٫ but I know some people like
      it.</dd>

    <dt><a href="https://github.com/meric/l2l">l2l</a></dt>
    <dd>I actually did use
      this <a href="https://gitlab.com/technomancy/bussard/blob/beta-2/os/lisp/resources/portal.lsp">in
      my game</a>. But since I tried it the compiler has been more or less
      completely rewritten. The unique thing about the new l2l compiler is
      that it allows you to mix Lua code and lisp code in the same file. I
      found it rather difficult to follow code that does this٫ but it"s an
      interesting idea. The readme for l2l includes some very apt Taoist
      quotations٫ which earns it extra points in my book.</dd>

    <dt><a href="http://urn-lang.com/">Urn</a></dt>
    <dd>I saved the best for last. Urn is a very impressive language with
      a smart compiler that has great error messages٫ pattern matching٫
      and tree-shaking to strip out code that"s not used. The main reason
      I decided not to use Urn is that it wants to do a lot of
      optimization and analysis up-front and sacrifices some interactivity
      and reloading features to achieve it. As one who prizes interactivity
      above all other considerations٫ I found it a poor fit. Urn wants
      to be its own language that just uses Lua as a runtime٫ and that"s
      great٫ but right now I"m looking for something that just takes Lua
      and makes the syntax nicer.</dd>
  </dl>

  <p>[<a name="fn2">2</a>] My first program
    was <a href="https://p.hagelb.org/pong.fnl.html">a 1-page Pong</a>٫
    which is kind of the "hello world" of games. Then I ported the
    user-level config
    from <a href="https://gitlab.com/technomancy/polywell/blob/fennel/config/repl.fnl">Polywell</a>٫
    my Emacs clone٫ over to Fennel. This has made Polywell seem a lot more
    Emacsy than it used to be.</p>

  <p>[<a name="fn3">3</a>] Of course٫ once macros are introduced to the
    picture you can write code where this guarantee no longer
    applies. Oddly enough I"m not particularly interested in complex
    macros beyond things like pattern matching٫ so I don"t see it being a
    problem for code I write٫ but it"s worth noting that there are
    complications.</p>
</div>

'),('https://technomancy.us/185', 'in which the cost of structured data is reduced', '1515786831000',  10, '

<p>Last year I got the wonderful opportunity to
  attend <a href="https://con.racket-lang.org/">RacketCon</a> as it
  was hosted only 30 minutes away from my home. The two-day
  conference had a number of great talks on the first day٫ but what
  really impressed me was the fact that the entire second day was
  spent focusing on contribution. The day started out with a few 15-
  to 20-minute talks about how to contribute to a specific codebase
  (including that of Racket itself)٫ and after that people just
  split off into groups focused around specific codebases. Each
  table had maintainers helping guide other folks towards how to
  work with the codebase and construct effective patch
  submissions.</p>

<img src="/i/chronicles-of-lensmen.jpg" alt="lensmen chronicles" class="right">

<p>I came away from the conference with a great sense of
  appreciation for how friendly and welcoming the Racket community
  is٫ and how great Racket is as a swiss-army-knife type tool for
  quick tasks. (Not that it"s unsuitable for large projects٫ but I
  don"t have the opportunity to start any new large projects very
  frequently.)</p>

<p>The other day I wanted to generate colored maps of
  the world by categorizing countries interactively٫ and Racket
  seemed like it would fit the bill nicely. The job is simple: show
  an image of the world with one country selected; when a key is
  pressed٫ categorize that country٫ then show the map again with
  all categorized countries colored٫ and continue with the next
  country selected.</p>

<h4>GUIs and XML</h4>

<p>I have yet to see a language/framework more accessible and
  straightforward out of the box for
  drawing<sup><a href="#fn1">1</a></sup>. Here"s the entry point
  which sets up state and then constructs a canvas that handles key
  input and display:</p>

<pre class="code">(<span class="keyword">define</span> (<span class="function-name">main</span> path)
  (<span class="keyword">let</span> ([<span class="variable-name">frame</span> (<span class="builtin">new</span> frame% [label <span class="string">"World color"</span>])]
        [<span class="variable-name">categorizations</span> (<span class="builtin">box</span> "())]
        [<span class="variable-name">doc</span> (<span class="keyword">call-with-input-file</span> path read-xml/document)])
    (<span class="builtin">new</span> (<span class="builtin">class</span> canvas%
           (<span class="builtin">define/override</span> (<span class="function-name">on-char</span> event)
             (handle-key <span class="builtin">this</span> categorizations (<span class="builtin">send</span> event get-key-code)))
           (<span class="builtin">super-new</span>))
         [parent frame]
         [paint-callback (draw doc categorizations)])
    (<span class="builtin">send</span> frame show <span class="racket-selfeval">#t</span>)))</pre>

<p>While the class system is not one of my favorite things about
  Racket (most newer code seems to avoid it in favor
  of <a href="https://docs.racket-lang.org/reference/struct-generics.html">generic
  interfaces</a> in the rare case that polymorphism is truly called
  for)٫ the fact that classes can be constructed in a light-weight٫
  anonymous way makes it much less onerous than it could be. This
  code sets up all mutable state in
  a <a href="https://docs.racket-lang.org/reference/boxes.html?q=box#%28def._%28%28quote._~23~25kernel%29._box%29%29"><code>box</code></a>
  which you use in the way you"d use a <code>ref</code> in ML or
  Clojure: a mutable wrapper around an immutable data structure.</p>

<p>The world map I"m using
  is <a href="https://commons.wikimedia.org/wiki/File:BlankMap-World_gray.svg">an
  SVG of the Robinson projection</a> from Wikipedia. If you look
  closely there"s a call to bind <code>doc</code> that
  calls <a href="https://docs.racket-lang.org/reference/port-lib.html#(def._((lib._racket%2Fport..rkt)._call-with-input-string))"><code>call-with-input-file</code></a>
  with <a href="https://docs.racket-lang.org/xml/index.html?q=read-xml#%28def._%28%28lib._xml%2Fmain..rkt%29._read-xml%2Fdocument%29%29"><code>read-xml/document</code></a> which loads up the whole map
  file"s SVG; just about as easily as you could ask for.</p>

<p>The data you get back from <code>read-xml/document</code> is in fact
  a <a href="https://docs.racket-lang.org/xml/#%28def._%28%28lib._xml%2Fmain..rkt%29._document%29%29">document</a>
  struct٫ which contains an <code>element</code> struct
  containing <code>attribute</code> structs and lists of
  more <code>element</code> structs. All very sensible٫ but maybe not
  what you would expect in other dynamic languages like Clojure or
  Lua where free-form maps reign supreme. Racket really wants
  structure to be known up-front when possible٫ which is one of the
  things that help it produce helpful error messages when things
  go wrong.</p>

<p>Here"s how we handle keyboard input; we"re displaying a map with
  one country highlighted٫ and <code>key</code> here tells us what
  the user pressed to categorize the highlighted country. If that
  key is in the <code>categories</code> hash then we put it
  into <code>categorizations</code>.</p>

<pre class="code">(<span class="keyword">define</span> <span class="variable-name">categories</span> #hash((select . <span class="string">"eeeeff"</span>)
                         (<span class="racket-selfeval">#\1</span> . <span class="string">"993322"</span>)
                         (<span class="racket-selfeval">#\2</span> . <span class="string">"229911"</span>)
                         (<span class="racket-selfeval">#\3</span> . <span class="string">"ABCD31"</span>)
                         (<span class="racket-selfeval">#\4</span> . <span class="string">"91FF55"</span>)
                         (<span class="racket-selfeval">#\5</span> . <span class="string">"2439DF"</span>)))

(<span class="keyword">define</span> (<span class="function-name">handle-key</span> canvas categorizations key)
  (<span class="keyword">cond</span> [(<span class="builtin">equal?</span> <span class="racket-selfeval">#\backspace</span> key) <span class="comment-delimiter">; </span><span class="comment">undo
</span>         (swap! categorizations <span class="builtin">cdr</span>)]
        [(<span class="builtin">member</span> key (<span class="builtin">dict-keys</span> categories)) <span class="comment-delimiter">; </span><span class="comment">categorize
</span>         (swap! categorizations (<span class="builtin">curry</span> <span class="builtin">cons</span> key))]
        [(<span class="builtin">equal?</span> <span class="racket-selfeval">#\space</span> key) <span class="comment-delimiter">; </span><span class="comment">print state
</span>         (<span class="builtin">display</span> (<span class="builtin">unbox</span> categorizations))])
  (<span class="builtin">send</span> canvas refresh))</pre>

<h4>Nested updates: the bad parts</h4>

<p>Finally once we have a list of categorizations٫ we need to apply
  it to the map document and display. We apply
  a <a href="https://docs.racket-lang.org/reference/for.html?q=for%2Ffold#%28form._%28%28lib._racket%2Fprivate%2Fbase..rkt%29._for%2Ffold%29%29"><code>fold</code></a>
  reduction over the XML document struct and the list of country
  categorizations (plus <code>"select</code> for the country that"s
  selected to be categorized next) to get back a "modified" document
  struct where the proper elements have the style attributes applied
  for the given categorization٫ then we turn it into an image and
  hand it
  to <a href="https://docs.racket-lang.org/pict/Rendering.html?q=draw-pict#%28def._%28%28lib._pict%2Fmain..rkt%29._draw-pict%29%29"><code>draw-pict</code></a>:</p>

<pre class="code">(<span class="keyword">define</span> (<span class="function-name">update</span> original-doc categorizations)
  (<span class="keyword">for/fold</span> ([doc original-doc])
            ([category (<span class="builtin">cons</span> <span class="racket-selfeval">"select</span> (<span class="builtin">unbox</span> categorizations))]
             [n (<span class="keyword">in-range</span> (<span class="builtin">length</span> (<span class="builtin">unbox</span> categorizations)) <span class="racket-selfeval">0</span> <span class="racket-selfeval">-1</span>)])
    (set-style doc n (style-for category))))

(<span class="keyword">define</span> ((<span class="function-name">draw</span> doc categorizations) _ context)
  (<span class="keyword">let*</span> ([<span class="variable-name">newdoc</span> (update doc categorizations)]
         [<span class="variable-name">xml</span> (<span class="builtin">call-with-output-string</span> (<span class="builtin">curry</span> write-xml newdoc))])
    (draw-pict (<span class="builtin">call-with-input-string</span> xml svg-port-&gt;pict) context <span class="racket-selfeval">0</span> <span class="racket-selfeval">0</span>)))</pre>

<p>The problem is in that pesky <code>set-style</code> function. All it
  has to do is reach deep down into the <code>document</code> struct to
  find the <code>n</code>th <code>path</code> element (the one associated
  with a given country)٫ and change its <code>"style</code>
  attribute. It ought to be a simple task. Unfortunately this
  function ends up being anything but simple:</p>

<pre class="code"><span class="comment">;; you don"t need to understand this; just grasp how huge/awkward it is</span>
(<span class="keyword">define</span> (<span class="function-name">set-style</span> doc n new-style)
  (<span class="keyword">let*</span> ([<span class="variable-name">root</span> (document-element doc)]
         [<span class="variable-name">g</span> (<span class="builtin">list-ref</span> (element-content root) <span class="racket-selfeval">8</span>)]
         [<span class="variable-name">paths</span> (element-content g)]
         [<span class="variable-name">path</span> (<span class="builtin">first</span> (<span class="builtin">drop</span> (<span class="builtin">filter</span> element? paths) n))]
         [<span class="variable-name">path-num</span> (list-index (<span class="builtin">curry</span> <span class="builtin">eq?</span> path) paths)]
         [<span class="variable-name">style-index</span> (list-index (<span class="keyword">lambda</span> (x) (<span class="builtin">eq?</span> <span class="racket-selfeval">"style</span> (attribute-name x)))
                                  (element-attributes path))]
         [<span class="variable-name">attr</span> (<span class="builtin">list-ref</span> (element-attributes path) style-index)]
         [<span class="variable-name">new-attr</span> (make-attribute (source-start attr)
                                   (source-stop attr)
                                   (attribute-name attr)
                                   new-style)]
         [<span class="variable-name">new-path</span> (make-element (source-start path)
                                 (source-stop path)
                                 (element-name path)
                                 (<span class="builtin">list-set</span> (element-attributes path)
                                           style-index new-attr)
                                 (element-content path))]
         [<span class="variable-name">new-g</span> (make-element (source-start g)
                              (source-stop g)
                              (element-name g)
                              (element-attributes g)
                              (<span class="builtin">list-set</span> paths path-num new-path))]
         [<span class="variable-name">root-contents</span> (<span class="builtin">list-set</span> (element-content root) <span class="racket-selfeval">8</span> new-g)])
    (make-document (document-prolog doc)
                   (make-element (source-start root)
                                 (source-stop root)
                                 (element-name root)
                                 (element-attributes root)
                                 root-contents)
                   (document-misc doc))))</pre>

<p>The reason for this is that while structs are immutable٫ they
  don"t support functional updates. Whenever you"re working with
  immutable data structures٫ you want to be able to say "give me a
  new version of this data٫ but with field <code>x</code> replaced by
  the value of <code>(f (lookup x))</code>". Racket
  can <a href="https://docs.racket-lang.org/reference/dicts.html?q=dict-update#%28def._%28%28lib._racket%2Fdict..rkt%29._dict-update%29%29">do
  this with dictionaries</a> but not with structs<sup><a href="#fn2">2</a></sup>.  If you want a
  modified version you have to create a fresh
  one<sup><a href="#fn3">3</a></sup>.</p>

<h4>Lenses to the rescue?</h4>

<img src="/i/first-lensman.jpg" alt="first lensman" class="left">

<p>When I brought this up in the <code>#racket</code> channel on
  Freenode٫ I was helpfully pointed to the 3rd-party
  <a href="https://docs.racket-lang.org/lens/lens-guide.html">Lens</a>
  library. Lenses are a general-purpose way of composing arbitrarily
  nested lookups and updates. Unfortunately at this time
  there"s <a href="https://github.com/jackfirth/lens/issues/290">a
  flaw</a> preventing them from working with <code>xml</code> structs٫ so
  it seemed I was out of luck.</p>

<p>But then I was pointed
  to <a href="https://docs.racket-lang.org/pollen/second-tutorial.html?q=xexpr#%28part._.X-expressions%29">X-expressions</a>
  as an alternative to
  structs. The <a href="https://docs.racket-lang.org/xml/index.html?q=xexpr#%28def._%28%28lib._xml%2Fmain..rkt%29._xml-~3exexpr%29%29"><code>xml->xexpr</code></a>
  function turns the structs into a deeply-nested list tree with
  symbols and strings in it. The tag is the first item in the list٫
  followed by an associative list of attributes٫ then the element"s
  children. While this gives you fewer up-front guarantees about the
  structure of the data٫ it does work around the lens issue.</p>

<p>For this to work٫ we need to compose a new lens based on the
  "path" we want to use to drill down into the <code>n</code>th country
  and its <code>style</code>
  attribute. The <a href="https://docs.racket-lang.org/lens/lens-reference.html#%28def._%28%28lib._lens%2Fcommon..rkt%29._lens-compose%29%29"><code>lens-compose</code></a>
  function lets us do that. Note that the order here might be
  backwards from what you"d expect; it works deepest-first (the way
  <a href="https://docs.racket-lang.org/reference/procedures.html#%28def._%28%28lib._racket%2Fprivate%2Flist..rkt%29._compose%29%29"><code>compose</code></a>
  works for functions). Also note that defining one lens gives us
  the ability to both get nested values
  (with <a href="https://docs.racket-lang.org/lens/lens-reference.html?q=lens-view#%28def._%28%28lib._lens%2Fcommon..rkt%29._lens-view%29%29"><code>lens-view</code></a>) <em>and</em> update them.</p>

<pre class="code">(<span class="keyword">define</span> (<span class="function-name">style-lens</span> n)
  (lens-compose (dict-ref-lens <span class="racket-selfeval">"style</span>)
                second-lens
                (list-ref-lens (<span class="builtin">add1</span> (<span class="builtin">*</span> n <span class="racket-selfeval">2</span>)))
                (list-ref-lens <span class="racket-selfeval">10</span>)))</pre>

<p>Our <code>&lt;path&gt;</code> XML elements are under the 10th item of
  the root xexpr٫ (hence the <a href="https://docs.racket-lang.org/lens/lens-reference.html?q=lens-view#%28def._%28%28lib._lens%2Fdata%2Flist..rkt%29._list-ref-lens%29%29"><code>list-ref-lens</code></a> with 10) and
  they are interspersed with whitespace٫ so we have to
  double <code>n</code> to find the <code>&lt;path&gt;</code> we
  want. The <a href="https://docs.racket-lang.org/lens/lens-reference.html?q=lens-view#%28def._%28%28lib._lens%2Fdata%2Flist..rkt%29._second-lens%29%29"><code>second-lens</code></a> call gets us to that element"s
  attribute alist٫ and <a href="https://docs.racket-lang.org/lens/lens-reference.html?q=lens-view#%28def._%28%28lib._lens%2Fdata%2Fdict..rkt%29._dict-ref-lens%29%29"><code>dict-ref-lens</code></a> lets us zoom in on
  the <code>"style</code> key out of that alist.</p>

<p>Once we have our lens٫ it"s just a matter of
  replacing <code>set-style</code> with a call
  to <a href="https://docs.racket-lang.org/lens/lens-reference.html?q=lens-view#%28def._%28%28lib._lens%2Fcommon..rkt%29._lens-set%29%29"><code>lens-set</code></a>
  in our <code>update</code> function we had above٫ and then we"re
  off:</p>

<pre class="code">(<span class="keyword">define</span> (<span class="function-name">update</span> doc categorizations)
  (<span class="keyword">for/fold</span> ([d doc])
            ([category (<span class="builtin">cons</span> <span class="racket-selfeval">"select</span> (<span class="builtin">unbox</span> categorizations))]
             [n (<span class="keyword">in-range</span> (<span class="builtin">length</span> (<span class="builtin">unbox</span> categorizations)) <span class="racket-selfeval">0</span> <span class="racket-selfeval">-1</span>)])
    (lens-set (style-lens n) d (<span class="builtin">list</span> (style-for category)))))</pre>

<img src="/i/second-stage-lensman.jpg" alt="second stage lensman" class="right">

<p>Often times the trade-off between freeform maps/hashes vs
  structured data feels like one of convenience vs long-term
  maintainability. While it"s unfortunate that they can"t be used
  with the <code>xml</code> structs<sup><a href="#fn4">4</a></sup>٫
  lenses provide a way to get the best of both worlds٫ at least in
  some situations.</p>

<p>The final version of the code clocks in at 51 lines and is
  is available <a href="https://gitlab.com/technomancy/world-color/blob/master/world-color.rkt">on GitLab</a>.</p>

<hr>

<div class="footnotes">

<p>[<a name="fn1">1</a>] The <a href="https://love2d.org">LÖVE</a>
  framework is the closest thing٫ but it doesn"t have the same
  support for images as a first-class data type that works in the repl.</p>

<p>[<a name="fn2">2</a>] If you"re defining your own structs٫ you
  can make
  them <a href="https://github.com/technomancy/cooper/blob/master/cooper/fstruct.rkt#L26">implement
  the dictionary interface</a>٫ but with the <code>xml</code> library we
  have to use the struct definitions provided us.</p>

<p>[<a name="fn3">3</a>] Technically you can use
  the <a href="https://docs.racket-lang.org/reference/struct-copy.html"><code>struct-copy</code></a>
  function٫ but it"s not that much better. The field names must be
  provided at compile-time٫ and it"s no more efficient as it copies
  the entire contents instead of sharing internal structure. And it
  still doesn"t have an API that allows you to express the new value as a
  function of the old value.</p>

<p>[<a name="fn4">4</a>]
  Lenses <a href="https://docs.racket-lang.org/lens/lens-reference.html#(form._((lib._lens%2Fdata%2Fstruct..rkt)._define-struct-lenses))">work
  with most regular structs</a> as long as they
  are <a href="https://docs.racket-lang.org/guide/define-struct.html?q=transparent%20structs#%28part._trans-struct%29">transparent</a>
  and don"t use subtyping. Subtyping and opaque structs are
  generally considered bad form in modern Racket٫ but you do find
  older libraries that use them from time to time.</p>
</div>
'),('https://technomancy.us/184', 'in which a path is charted through the coming apocalypse', '1508785453000',  10, '

<p>I"ve long counted myself among the grumpy old-timers who
  grudgingly accept the shift towards web-based-everything and just
  try to make the most of it٫ wistfully remembering the days when I
  could just do everything from within Emacs. One of my core
  survival strategies in this web-first world has been to trick my
  browser into at least having the decency to pretend to be Emacs. I
  accomplished this in Firefox<sup><a href="#fn1">1</a></sup> with
  the <a href="https://github.com/mooz/keysnail/wiki">Keysnail</a>
  extension. Keysnail has remarkable flexibility in how it overrides
  Firefox"s default key bindings to match those of Emacs٫ and
  everything has been more or less great.</p>

<p>Unfortunately٫ <a href="https://blog.mozilla.org/addons/2016/11/23/add-ons-in-2017/">a
  soon-to-be-released update to Firefox</a> will remove the
  extension
  mechanism <a href="https://github.com/mooz/keysnail/issues/222">used
  by Keysnail</a>.</p>

<img src="/i/green-lake-laptop.jpg" alt="laptop at Green Lake" />

<p>I have felt very conflicted about this٫ because the old state of
  affairs is admittedly untenable. Firefox currently
  uses <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Gecko">Gecko</a>٫
  a decades-old rendering engine written in C++٫ and like much
  software written in C++ it has a pretty distressing security track
  record. Version 57 of Firefox replaces parts of Gecko with
  functionality from <a href="https://servo.org">Servo</a>٫ a
  browser engine implemented in the Rust programming language. Most
  of the bugs in Gecko which have led to embarrassing security flaws
  are simply impossible in Servo. The fact
  that so much safety-critical code is still being written in C++
  and similar languages is a sad state of affairs٫ and we should
  celebrate changes that mean end users will no longer bear the penalty
  for programmers" reluctance to move beyond the technology of the
  1980s.</p>

<p>But on the other hand٫ losing the ability to shape your computing
  environment to your whims is <em>awful</em>. I lost track of how
  many times (when using Chromium or other keysnail-less browsers)
  I"ve wanted to throw my laptop out the window when I held
  down <kbd>ctrl-n</kbd> to scroll down and it opened seventeen new
  windows instead. I can"t remember ever wanting to open a new browser
  window in the past <em>decade</em>; why should I be stuck with a
  key bound to that command and no way to disable it?</p>

<p>Of course٫ the new Firefox will still have an extension
  mechanism٫ but it"s a pale shadow of the old one. Citing the
  flimsy<sup><a href="#fn2">2</a></sup> excuse
  of <a href="https://github.com/lusakasa/saka-key/issues/53#issuecomment-332319791">security</a>٫
  key bindings like <kbd>C-n</kbd> are hard-coded into the browser
  and forbidden from being overridden.</p>

<img src="/i/tumwater.jpg" alt="Tumwater Falls" align="left" />

<p>Things were looking bleak for me٫ and I contemplated whether I
  would switch to curl or just give up software development
  altogether for a career in goat-herding. I ended up finding a
  solution from a most unlikely place.</p>

<h4>EXWM saves the day</h4>

<p>I had heard of <a href="https://github.com/ch11ng/exwm">EXWM</a>
  a while ago٫ and it struck me as a quixotic curiosity. The X
  Window System uses a network socket for its control protocol٫
  allowing a lot of flexibility including native forwarding of
  interfaces for remote programs. The developer of EXWM had taken an
  XML description of the specification for the network protocol and
  written a compiler to turn it
  into <a href="https://github.com/ch11ng/xelb/blob/master/xelb.el#L36">a
  library of Emacs Lisp functions</a> which he then used to
  implement a window manager in pure Emacs Lisp. While I admired the
  chutzpah this must have taken٫ I assumed it was a novelty that
  could never be practical.</p>

<p>Eventually the Firefox conundrum prompted me to give it a second
  look due to a feature called Simulation
  Keys. The <tt>exwm-input-set-simulation-keys</tt> function allows
  you to define a translation mapping so that a certain key
  combination will be intercepted by EXWM when a non-Emacs program
  has focus٫ and a different set of key input events will be sent
  instead. It seemed too good to be true; I could let go of Keysnail
  and instead get the same features applied to every program I
  use<sup><a href="#fn3">3</a></sup>.</p>

<p>I"m happy to report that EXWM does actually function startlingly
  well as a window manager. The simulation keys feature is amazing
  and puts my Firefox-related fears at ease٫ and having all
  configuration written in a single language simplifies my setup
  dramatically. Every X window you launch is given an Emacs buffer٫
  and all your normal splits and window resizing commands work
  great with it. With the tiling window managers I used in the
  past٫ it was so unusual for me to use something other than the
  "one fullscreen window per display" setup that I would often
  forget the key bindings for splitting and rearranging
  windows. EXWM even integrates "system tray" programs into the Emacs
  echo area٫ so your wifi connect tool shows up unobtrusively in
  the bottom right corner.</p>

<p>There are a handful of gotchas. Emacs Lisp lacks general-purpose
  concurrency features٫ but it does allow for concurrency when
  dealing with subprocesses and network communication. Most
  well-written Emacs Lisp will never block the main event loop٫
  which is good because when using EXWM that means the entire window
  manager is stuck until the blocking operation completes. I only
  came across two exceptions to this rule. One of them
  is <tt>smtpmail-send-it</tt>٫ which can be replaced by
  the <a href="https://github.com/jwiegley/emacs-async/blob/master/smtpmail-async.el">smtpmail-async</a>
  library. The other is the <tt>racket-run</tt> command٫ which I was
  able
  to <a href="https://github.com/greghendershott/racket-mode/pull/282">patch
  in about an hour</a> to remove the blocking
  call<sup><a href="#fn4">4</a></sup>.</p>

<p>Other folks might run into more problems if they use other
  third-party libraries which don"t take care to use the network
  functions properly. But for my use<sup><a href="#fn5">5</a></sup>٫
  it"s been very smooth٫ and I"m thrilled to have it.</p>

<p><b>Update</b>: I"ve
  started <a href="http://p.hagelb.org/exwm-ff-tabs.html">configuring my
  browser to open everything in new windows instead of new tabs</a>٫
  which sounds crazy٫ but is very useful٫ because it means that you
  can use Emacs"s built-in buffer switching tools to change tabs٫
  which are much better than anything I"ve seen inside a browser.</p>

<hr>

<div class="footnotes">
<p>[<a name="fn1">1</a>] I used <a href="http://conkeror">Conkeror</a>
  for several years٫ but eventually things got to the point where
  browsing without <a href="https://noscript.net">Noscript</a>
  became untenable٫ and I could never get the two to work well together.</p>

<p>[<a name="fn2">2</a>] The rationale of "it"s for security" would
  stand up to a little more scrutiny if it weren"t for the fact that
  extensions <em>can</em> rebind <kbd>C-t</kbd>٫ a key which is used
  hundreds if not thousands of times more often than <kbd>C-n</kbd>.</p>

<p>[<a name="fn3">3</a>]
  Granted <a href="http://www.gnumeric.org/">gnumeric</a> is the
  only program I use outside the browser and Emacs٫ but it"s still
  greatly appreciated. I also use
  the <a href="https://key.saka.io/">Saka Key</a> extension٫ which
  implements Keysnail"s ability to trigger links from the keyboard
  even if they don"t have text attached to them.</p>

<p>[<a name="fn4">4</a>] I feel that the increasing "Emacs needs
  concurrency!" calls tend to overstate the problem. Yes٫ of course
  it would be nicer for the programmer to code using coroutines
  (coming in Emacs 26!) instead of callbacks٫ but in the end this is
  a convenience for the author٫ not for the end user.</p>

<p>[<a name="fn5">5</a>] <a href="https://github.com/technomancy/dotfiles/blob/master/.emacs.d/phil/wm.el">My
    customizations</a> largely revolve around replacing
    my <a href="https://github.com/technomancy/dotfiles/blob/master/.xbindkeysrc.scm">xbindkeys</a>
    config with elisp٫ mapping workspace numbers to physical
    displays٫ and some <tt>eshell</tt> commands to give one eshell
    buffer per workspace. EXWM has XMonad-style workspaces where you
    can change the workspace for each display independently rather
    than forcing you to change them all at once like many more
    conventional WMs٫ and I"m very glad it does.</p>
</div>
'),('https://technomancy.us/183', 'in which actors simulate a protocol', '1494795691000',  10, '

<p>I"ve been on a bit of a yak shave recently
  on <a href="">Bussard</a>٫ my spaceflight programming adventure
  game. The game relies pretty heavily on simulating various
  computer systems٫ from your own craft to space stations٫ portals٫
  rovers٫ and other craft. It naturally needs to simulate
  communications between all these.</p>

<p>I started with a pretty simple method of having each connection
  spin up its own coroutine running its own sandboxed session. Space
  station sessions
  run <a href="https://gitlab.com/technomancy/bussard/blob/threads/os/orb/resources/smash">smash</a>٫
  a vaguely bash-like shell in a faux-unix٫ while connecting to a
  portal
  triggers <a href="https://gitlab.com/technomancy/bussard/blob/beta-2/os/lisp/resources/portal.lsp">a
  small lisp script to check for clearance and gradually activate
  the gateway sequence</a>. The main loop would allow each session"s
  coroutine a slice of time for each update tick٫ but a
  badly-behaved script could make the frame rate
  suffer. (Coroutines٫ you will remember٫ are a form
  of <a href="https://en.wikipedia.org/wiki/Cooperative_multitasking">cooperative
  multitasking</a>; not only do they not allow more than one thing to
  literally be running at the same time٫ but handing control off
  must be done explicitly.) Also input and output was
  handled in a pretty ad-hoc method where Lua tables were used as
  channels to send strings to and from these session coroutines. But
  most problematic of all was the fact that there wasn"t any
  uniformity or regularity in the implementations of the various
  sessions.</p>

<img src="/i/bussard-rpc.png" alt="Bussard shell session">

<p>The next big feature I wanted to add was the ability to deploy
  rovers from your ship and SSH into them to control their
  movements or reprogram them. But I really didn"t want to add a
  third half-baked session type; I needed all the different implementations
  to conform to a single interface. This required some rethinking.</p>

<p>The codebase is written primarily in Lua٫ but not just any
  Lua&mdash;it uses the <a href="https://love2d.org">LÖVE</a>
  framework. While Lua"s concurrency options are very limited٫
  LÖVE offers <a href="https://love2d.org/wiki/love.thread">true
  OS threads</a> which run independently of each other. Now of
  course LÖVE can"t magically change the semantics of
  Lua&mdash;these threads are technically in the same process but
  cannot communicate directly. All communication happens
  over <a href="https://love2d.org/wiki/Channel">channels</a> (aka queues)
  which allow <em>copies</em> of data to be shared٫ but not actual
  state.</p>

<p>While these limitations could be annoying in some cases٫ they
  turn out to be a perfect fit for simulating communications
  between separate computer systems. Moving to threads allows for
  much more complex programs to run on stations٫ portals٫ rovers٫
  etc without adversely affecting performance of the game.</p>

<p>Each world
  has <a href="https://gitlab.com/technomancy/bussard/blob/threads/os/server.lua">a
  server thread</a> with a pair of input/output channels that gets
  started when you enter that world"s star system. Upon a
  successful login٫ a thread is created for that specific session٫ which
  also gets its own <tt>stdin</tt> channel. Input from the main
  thread"s SSH client gets routed from the server thread to
  the <tt>stdin</tt> channel of each specific session. Each OS
  implementation can provide its own implementation of what
  a <a href="https://gitlab.com/technomancy/bussard/blob/threads/os/orb/session.lua">session
  thread</a> looks like٫ but they all exchange stdin and stdout
  messages over channels. Interactive sessions will typically run
  a shell like <tt>smash</tt> or a repl٫ and their thread parks
  on <tt><a href="https://love2d.org/wiki/Channel:demand">stdin:demand()</a></tt>٫ waiting until the main thread
  has some input to send along.</p>

<p>This works great for regular input and output٫ but sometimes it"s
  necessary for the OS thread to make state changes to tables in the
  main thread٫ such as
  the <a href="https://gitlab.com/technomancy/bussard/blob/threads/os/orb/resources/cargo">cargo</a>
  script for buying and selling. Time to build an RPC mechanism! I
  created <a href="https://gitlab.com/technomancy/bussard/blob/threads/rpcs.lua">a
  whitelist table of all functions which should be exposed</a> to
  code running in a session thread over RPC. Each of these is
  exposed as a shim function in the session"s sandbox:</p>

  <pre class="code"><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="function-name"><span class="region">add_rpc</span></span><span class="region"> = </span><span class="keyword"><span class="region">function</span></span><span class="region">(sandbox٫ name)
   sandbox[name] = </span><span class="keyword"><span class="region">function</span></span><span class="region">(...)
      </span><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">chan</span></span><span class="region"> = love.thread.newChannel()
      output:push({op=</span><span class="string"><span class="region">"rpc"</span></span><span class="region">٫ fn=name٫ args={...}٫ chan=chan})
      </span><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">response</span></span><span class="region"> = chan:demand()
      </span><span class="keyword"><span class="region">if</span></span><span class="region">(response[1] == </span><span class="string"><span class="region">"_error"</span></span><span class="region">) </span><span class="keyword"><span class="region">then</span></span><span class="region">
         </span><span class="builtin"><span class="region">table</span></span><span class="region">.</span><span class="builtin"><span class="region">remove</span></span><span class="region">(response٫ 1)
         </span><span class="builtin"><span class="region">error</span></span><span class="region">(</span><span class="builtin"><span class="region">unpack</span></span><span class="region">(response))
      </span><span class="keyword"><span class="region">else</span></span><span class="region">
         </span><span class="keyword"><span class="region">return</span></span><span class="region"> </span><span class="builtin"><span class="region">unpack</span></span><span class="region">(response)
      </span><span class="keyword"><span class="region">end</span></span><span class="region">
   </span><span class="keyword"><span class="region">end</span></span><span class="region">
</span><span class="keyword"><span class="region">end</span></span><span class="region"></span></pre>

<p>When the shim function is called it sends an <tt>op="rpc"</tt>
  table with a new throwaway channel (used only for communicating
  the return value)٫ and sends it back over the output channel. The
  main thread picks this up٫ looks up the function in
  the <tt>rpcs</tt> table٫ and sends a message back over the
  response channel with the return value. This same RPC mechanism
  works equally well for scripts on space stations as it does for
  the portal control script٫ and a similar variation (but going the
  other direction) allows the SSH client to implement tab completion
  by making an RPC call to get completion targets.</p>

<p>They"re not perfect٫ but the mechanisms LÖVE offers for
  concurrency have been a great fit in this particular case.</p>
'),('https://technomancy.us/182', 'in which four pieces are placed in a row', '1486941307000',  10, '

<p>The other day my son and I were at a friend"s house٫ and we were
  just on our way home. As we were leaving he saw they had the game
  <a href="https://en.wikipedia.org/wiki/Connect_Four">Connect 4</a>
  and asked if we could play. Since we were on our way I told him٫
  "We can"t play the game now٫ but when we get home٫ we
  can <em>program</em> the game٫ and then play that." I wasn"t sure
  exactly how this would work out٫ but I thought we"d have some fun
  on the way.</p>

<p>This isn"t the first time I"ve <a href="/179">adapted a physical
    game to a program with my kids</a>. But since then I"ve
    done <a href="https://gitlab.com/technomancy/liquid-runner">most</a>
    <a href="https://gitlab.com/technomancy/cardinality">of</a>
    <a href="https://gitlab.com/technomancy/mazes/blob/master/main.lua">my</a> 
    <a href="https://gitlab.com/technomancy/bussard">games</a> using
    <a href="https://love2d.org">LÖVE</a>٫ the 2D Lua game framework
    along
    with <a href="https://gitlab.com/technomancy/polywell">Polywell</a>٫
    a text editor and development tool that runs in it. Polywell is
    roughly a port of Emacs٫ and I"ve found that the foundation it
    provides of buffers٫ modes٫ and keymaps is useful for all kinds
    of games. As a bonus٫ you can use the text editing features of
    Polywell to code the game from <em>within</em> the game itself٫
    which makes experimentation and reloading seamless.</p>

<p>My son and I sat down and knocked out an implementation of
  Connect 4 pretty quickly using Polywell٫ and I thought it would be
  interesting to step through how it works since it can serve as a
  very succinct explanation for how to use Polywell.</p>

<h4>State and Drawing</h4>
<pre class="code"><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">e</span></span><span class="region"> = </span><span class="builtin"><span class="region">require</span></span><span class="region">(</span><span class="string"><span class="region">"polywell"</span></span><span class="region">)

</span><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">board</span></span><span class="region"> = { {}٫ {}٫ {}٫ {}٫ {}٫ {}٫ {} }
</span><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">colors</span></span><span class="region"> = {red={255٫50٫50}٫yellow={255٫238٫0}}
</span><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">turn</span></span><span class="region"> = </span><span class="string"><span class="region">"yellow"</span></span><span class="region">
</span></pre>

<p>We start out by loading <tt>"polywell"</tt> and putting it in
  the <tt>e</tt> local (<em>e</em> for <em>editor</em>). Most of the
  game state is in the <tt>board</tt> table[<a href="#fn1">1</a>]٫ which has an empty
  table for each column in it. The Connect 4 board has seven columns
  in which pieces can be dropped. It"s a bit unusual٫ but we
  represent columns as lists of pieces from the bottom up٫ because
  the tokens are subject to gravity and fall to the bottom of the
  column they"re placed in. Finally we set up <tt>colors</tt>
  which maps each player"s color name to an RGB triplet and store
  the final bit of state (the current turn) in the <tt>turn</tt>
  local. So far so good!</p>

<pre class="code"><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="function-name"><span class="region">draw</span></span><span class="region"> = </span><span class="keyword"><span class="region">function</span></span><span class="region">()
   </span><span class="keyword"><span class="region">for</span></span><span class="region"> </span><span class="variable-name"><span class="region">col</span></span><span class="region">=1٫7 </span><span class="keyword"><span class="region">do</span></span><span class="region">
      </span><span class="keyword"><span class="region">for</span></span><span class="region"> </span><span class="variable-name"><span class="region">n</span></span><span class="region">٫</span><span class="variable-name"><span class="region">color</span></span><span class="region"> </span><span class="keyword"><span class="region">in</span></span><span class="region"> </span><span class="builtin"><span class="region">ipairs</span></span><span class="region">(board[col]) </span><span class="keyword"><span class="region">do</span></span><span class="region">
         </span><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">x</span></span><span class="region">٫</span><span class="variable-name"><span class="region">y</span></span><span class="region"> = col * 75٫ 800 - n*75
         love.graphics.setColor(colors[color])
         love.graphics.circle(</span><span class="string"><span class="region">"fill"</span></span><span class="region">٫ x٫ y٫ 30)
      </span><span class="keyword"><span class="region">end</span></span><span class="region">
   </span><span class="keyword"><span class="region">end</span></span><span class="region">
</span><span class="keyword"><span class="region">end</span></span><span class="region"></span></pre>

<p>Our <tt>draw</tt> function is very natural once you understand
  the unusual structure of the <tt>board</tt>; we simply loop over
  each column with an inner loop over each piece in the column. The
  piece is represented by <tt>n</tt>٫ its numeric position within
  the list of pieces٫ and its <tt>color</tt>. We
  calculate <tt>x</tt> and <tt>y</tt> from the <tt>col</tt>
  and <tt>n</tt> respectively and draw a colored circle for each
  piece from the bottom of the column upwards. This is basically the
  only place we use the LÖVE framework directly.</p>

<h4>Modes and Bindings</h4>
<pre class="code"><span class="region">e.define_mode(</span><span class="string"><span class="region">"connect4"</span></span><span class="region">٫ </span><span class="constant"><span class="region">nil</span></span><span class="region">٫ {draw=draw٫ read_only=</span><span class="constant"><span class="region">true</span></span><span class="region">})</span></pre>

<p>Using Polywell"s <tt>define_mode</tt> function we create a
  <tt>"connect4"</tt> mode which will contain all the key bindings for the
  game. Modes in Polywell are assumed to be textual unless otherwise
  specified٫ but since our game is graphical we pass <tt>nil</tt> as
  the second argument because our mode does not inherit from any
  existing mode. For our third argument٫ we pass in our
  previously-defined <tt>draw</tt> function as the
  mode"s <tt>draw</tt> property٫ overriding the default draw which
  simply displays the current mode"s text. We also mark it
  as <tt>read_only</tt> to avoid accidentally inserting any text
  into the buffer.</p>

<pre class="code"><span class="region">e.bind(</span><span class="string"><span class="region">"connect4"</span></span><span class="region">٫ </span><span class="string"><span class="region">"escape"</span></span><span class="region">٫ </span><span class="keyword"><span class="region">function</span></span><span class="region">() e.change_buffer(</span><span class="string"><span class="region">"*console*"</span></span><span class="region">) </span><span class="keyword"><span class="region">end</span></span><span class="region">)
e.bind(</span><span class="string"><span class="region">"connect4"</span></span><span class="region">٫ </span><span class="string"><span class="region">"backspace"</span></span><span class="region">٫ </span><span class="keyword"><span class="region">function</span></span><span class="region">()
          </span><span class="keyword"><span class="region">for</span></span><span class="region"> </span><span class="variable-name"><span class="region">i</span></span><span class="region">=1٫7 </span><span class="keyword"><span class="region">do</span></span><span class="region"> lume.clear(board[i]) </span><span class="keyword"><span class="region">end</span></span><span class="region">
</span><span class="keyword"><span class="region">end</span></span><span class="region">)</span></pre>

<p>Polywell"s <tt>bind</tt> function allows us to attach a function
  to be called when a specific keystroke is pressed in a specific
  mode. In this case we say that <tt>escape</tt> will switch back to
  the Lua console while <tt>backspace</tt> will just clear each column in
  the <tt>board</tt>.</p>

<pre class="code"><span class="keyword"><span class="region">for</span></span><span class="region"> </span><span class="variable-name"><span class="region">key</span></span><span class="region">=1٫7 </span><span class="keyword"><span class="region">do</span></span><span class="region">
   e.bind(</span><span class="string"><span class="region">"connect4"</span></span><span class="region">٫ </span><span class="builtin"><span class="region">tostring</span></span><span class="region">(key)٫ </span><span class="keyword"><span class="region">function</span></span><span class="region">()
             </span><span class="keyword"><span class="region">local</span></span><span class="region"> </span><span class="variable-name"><span class="region">column</span></span><span class="region"> = board[key]
             </span><span class="keyword"><span class="region">if</span></span><span class="region">(#column &gt;= 6) </span><span class="keyword"><span class="region">then</span></span><span class="region"> </span><span class="keyword"><span class="region">return</span></span><span class="region"> </span><span class="keyword"><span class="region">end</span></span><span class="region">
             </span><span class="builtin"><span class="region">table</span></span><span class="region">.</span><span class="builtin"><span class="region">insert</span></span><span class="region">(column٫ turn)
             turn = turn == </span><span class="string"><span class="region">"red"</span></span><span class="region"> </span><span class="keyword"><span class="region">and</span></span><span class="region"> </span><span class="string"><span class="region">"yellow"</span></span><span class="region"> </span><span class="keyword"><span class="region">or</span></span><span class="region"> </span><span class="string"><span class="region">"red"</span></span><span class="region">
</span></span><span class="region">   </span><span class="keyword"><span class="region">end</span></span><span class="region">)
</span><span class="keyword"><span class="region">end</span></span><span class="region"></span></pre>

<p>Almost done! Here"s where the meat of the game is. We loop from 1
  to 7٫ which is the number of columns in the game. For each column٫
  we <tt>bind</tt> that number key to a function which grabs the
  corresponding <tt>column</tt> table from the <tt>board</tt>. It
  checks to make sure the <tt>column</tt> isn"t full (each one can
  only hold 6 pieces) and if not it inserts the color of the current
  player into the column with <tt>table.insert</tt>. Then it
  changes the <tt>turn</tt> to the next player.</p>

<pre class="code"><span class="region">e.open(</span><span class="constant"><span class="region">nil</span></span><span class="region">٫ </span><span class="string"><span class="region">"*connect4*"</span></span><span class="region">٫ </span><span class="string"><span class="region">"connect4"</span></span><span class="region">)</span></pre>

<p>Finally it uses the <tt>open</tt> function to create a new buffer
  named <tt>"*connect4*"</tt> with <tt>"connect4"</tt> mode
  active. The first argument is <tt>nil</tt> because this buffer is
  not attached to the filesystem; it"s a free-floating thing that
  doesn"t get loaded or saved. You could leave this line out and
  Polywell would simply boot to a Lua console where you could
  invoke <tt>connect4</tt> mode manually from there.</p>

<p>And that"s it! 27 lines is all it took٫ and me and my son were
  off to the races playing the game. While we were writing it I kept
  him involved by asking each step of the way what we should do
  next. Once I wrote the <tt>draw</tt> function we were able to test
  it out by editing the <tt>board</tt> table directly using Lua code
  in the console. Our first pass of the number key function simply
  called <tt>table.insert</tt>٫ so once we tried it out he was able
  to point out which features were still missing٫ and I could ask
  leading questions which helped him piece together roughly what was
  needed to address those things.</p>

<p>Of course there"s a lot more that Polywell can do٫ but it doesn"t
  take much code to get a simple game going. Try it for yourself;
  you might have a lot of fun.</p>

<hr>

<p>[<a name="fn1">1</a>] Lua tables can be a bit confusing since
  they"re a single data structure that can act both sequentially (as
  with <tt>board</tt> here which is basically used as a vector/array) or
  associatively (as with <tt>colors</tt> which acts like a map). The
  thing to remember is that the sequential/associative property is
  not inherent in the table but rather part of how it"s used.</p>
'),('https://raphlinus.github.io/gpu/2020/09/05/stack-monoid.html', 'The stack monoid', '1599318882000',  12, '<p>(Updated 2020-09-06 with pointers to related work and a bit more explanation)</p>

<p>This is a bit of a followup to <a href="https://raphlinus.github.io/personal/2018/05/10/toward-gpu-json-parsing.html">Towards GPGPU JSON parsing</a>. That proposed a rather roundabout way to parallelize a simple parsing task. Having had more GPU programming experience under my belt٫ I don’t expect that particular approach to work well٫ but it did suggest that parallelism exists in the problem.</p>

<p>This post is a writeup of a new idea٫ but with a caution٫ no implementation. It probably contains some mistakes٫ and maybe the idea is flawed. But if it holds up٫ I think it’s an exciting line of research on how to port sequential algorithms to GPU.</p>

<p>For this post٫ I’m going to pose an even more simplified version of the problem: for each open bracket٫ record the index of the parent in the parse tree٫ and for each close bracket٫ the index of the corresponding open bracket.</p>

<p>This is a simple sequential program:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">stack</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">٫</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">input</span><span class="p">:</span>
        <span class="n">result</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">stack</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">stack</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">token</span> <span class="o">==</span> <span class="s">"["</span><span class="p">:</span>
            <span class="n">stack</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">token</span> <span class="o">==</span> <span class="s">"]"</span><span class="p">:</span>
            <span class="n">stack</span><span class="p">.</span><span class="n">pop</span><span class="p">()</span>
</code></pre></div></div>

<p>To follow the running example from the JSON post٫ assume the input <code class="language-plaintext highlighter-rouge">[[][[][][[]]][][]]</code>. The result is:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>index 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17
input [  [  ]  [  [  ]  [  ]  [  [  ]  ]  ]  [  ]  [  ]  ]
value -  0  1  0  3  4  3  6  3  8  9  8  3  0 13  0 15  0
</code></pre></div></div>

<p>Can it be parallelized? It’s challenging to see how٫ as there are dependencies on previous state. Further٫ the state itself has unbounded size. It can be O(n); a pathological case is a million open brackets followed by a million close. In practice٫ depending on the workloads٫ we might expect more modest nesting depth٫ but ideally we’d like an algorithm that can handle all cases at least reasonably well.</p>

<p>Maybe we can do something. To longtime readers of my blog (and the “rope science” series before that)٫ it will be no surprise I’ll try to use monoids.</p>

<p>So let’s turn this sequential program into a monoid. If I had a time portal٫ I’d lens forward in time and use the handy automated tool that some enterprising PhD student will has done by then. But٫ failing that٫ I’ll do it in my head.</p>

<p>The monoid is basically a sequence of pops followed by a sequence of pushes. Since the pop operations (in this case) don’t have a payload٫ they can be represented simply as a count. So the monoid is the pair <code class="language-plaintext highlighter-rouge">(n_pops٫ elements)</code>. The primitive for push is <code class="language-plaintext highlighter-rouge">(0٫ [element])</code>٫ and for pop it’s <code class="language-plaintext highlighter-rouge">(1٫ [])</code>. The monoid operation is:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">combine</span><span class="p">(</span><span class="n">m1</span><span class="p">٫</span> <span class="n">m2</span><span class="p">):</span>
    <span class="n">n1</span><span class="p">٫</span> <span class="n">s1</span> <span class="o">=</span> <span class="n">m1</span>
    <span class="n">n2</span><span class="p">٫</span> <span class="n">s2</span> <span class="o">=</span> <span class="n">m2</span>
    <span class="k">if</span> <span class="n">n2</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)٫</span> <span class="n">s2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">n1</span><span class="p">٫</span> <span class="n">s1</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span> <span class="o">-</span> <span class="n">n2</span><span class="p">]</span> <span class="o">+</span> <span class="n">s2</span><span class="p">)</span>
</code></pre></div></div>

<p>And of course٫ the identity element is <code class="language-plaintext highlighter-rouge">(0٫ [])</code>. One intuition for this monoid is that it represents a function from the state at the beginning of a sequence of tokens to the state at the end. If it indeed computes this function for arbitrary subsequences٫ then it it follows that it’s a monoid from the fact that function composition is associative.</p>

<p>Running scan٫ or generalized <a href="https://raphlinus.github.io/gpu/2020/04/30/prefix-sum.html">prefix sum</a>٫ on this monoid٫ will result in the desired result at the top of the stack٫ i.e. the last element of the sequence in the monoid.</p>

<p><strong>Exercise:</strong> Show that this monoid is associative.</p>

<p>I do believe that an automated tool for translating these kinds of simple sequential programs is possible٫ and that there’s a theory behind it that illuminates ways in which monoids do and do not compose. Some composition is possible٫ for example you could fairly easily extend this idea so that each child knows its sequence number relative to its siblings. To do that٫ blend in the “counting monoid٫” which is just integer addition.</p>

<p><strong>Exercise:</strong> Extend the monoid to handle sequence numbers.</p>

<p>If we had a bound on stack depth٫ we’d be pretty well set. The problem is the unbounded case. My original thinking was to have a window of (let’s say size k) elements٫ and each pass would handle a slice of the stack of size k. I think this can be made to work٫ but at heart it requires a number of passes proportional to stack depth٫ so in the worst case O(n^2).</p>

<p>My new idea is to retain the single pass scan٫ but use a purpose-built data structure to represent the stack. At the top is a window of k elements٫ then after that is a linked list (or perhaps a linked list of chunks; honestly I haven’t worked through all the implications٫ much less actually implemented and done performance measurement).</p>

<p>The combine operation tries to fit the new combined sequence in the window (up to a shared link٫ which it can just retain). But if it overflows٫ then it must allocate٫ most likely using an atomic bump allocator into global memory٫ as is often done in piet-gpu.</p>

<h2 id="performance-analysis">Performance analysis</h2>

<p>To do a <em>real</em> performance analysis would require an implementation٫ but it should be possible to reason about it a bit.</p>

<p>Clearly performance will be excellent if stack depth is shallow. The rate at which the linked list will be invoked will depend on the workload٫ and also the parallelism patterns. It’s worth noting that if the scan is run sequentially٫ then the linked list operations will always be cheap. This is because the concatenation at the heart of the monoid operation is <em>asymmetrical</em> when using a linked list - a large sequence on the left is cheap when the sequence on the right is small٫ but not the other way around. When running the scan purely sequentially٫ the monoid on the right is always of size 1 at most.</p>

<p>And the decoupled lookback implementation of scan٫ which is state of the art٫ runs essentially sequentially at large granularity; it just tries to exploit as much parallelism as the hardware provides at smaller granularity. Even with extremly deep nesting٫ it should build and retain a linked list of the stack as it scans٫ with a relatively smaller window for the part of the problem currently in flight.</p>

<p>There is another reason to be optimistic about performance. While the bandwidth of communication between partitions scales with the window size٫ that’s not necessarily true for processing <em>within</em> a partition. Putting aside for a moment the relatively challenging problem of implementing an efficient GPU kernel (which by necessity would exploit SIMD parallelism)٫ consider a decoupled look-back implementation running on a more traditional multicore CPU٫ where each thread is sequential.</p>

<p>Basically٫ the first pass runs the traditional٫ sequential stack algorithm٫ with the modification that some of the input stack might not be available. At the end is the monoid٫ with “n_pops” being a count of the number of times that happened٫ and the sequence containing all the elements pushed inside that partition.</p>

<p>In the decoupled lookback phase٫ this monoid is published for consumption of partitions to the right٫ and the partition also computes the aggregate from partitions to the left. The cost of the monoid operations in this phase <em>will</em> be proportional to the size of the window٫ but keep in mind that the number of aggregates is orders of magnitude less than the number of elements.</p>

<p>Finally٫ in the second pass over the elements٫ the stack algorithm is run again٫ and this time elements that were missing in the first pass are available٫ from the aggregate obtained during the decoupled lookback phase. As another potential optimization٫ the second pass might “jump over” subtrees that were computed entirely locally within the partition in the first pass٫ only doing work on subtrees that cross partition boundaries.</p>

<p>Thus٫ my analysis is that the work factor is <em>extremely</em> good for this algorithm٫ meaning that on a 64 core processor٫ it might come within striking distance of 64 times faster than a single core sequential implementation (obviously modulo all the usual other factors that make this challenging).</p>

<p>As I mentioned٫ an efficient GPU kernel is likely to be challenging٫ probably requiring tricky techniques to exploit SIMD (warp) parallelism without spending too much time computing the monoid composition٫ but the fact that it seems to work so well in the multicore case is an encouraging sign that an efficient٫ fully GPU-tuned implementation is possible.</p>

<h2 id="related-work">Related work</h2>

<p>In an earlier draft٫ I asked for relevant literature related to this idea. I still haven’t found anything that presents this particular monoid٫ or a tool that can derive it from its sequential source٫ but there is a fair amount of related work.</p>

<p>Obviously٫ <a href="https://github.com/simdjson/simdjson">simdjson</a> is an important exploration of deriving more parallelism from the JSON parsing task٫ with impressive results. It is٫ I think٫ complementary to this exploration٫ as it exploits parallelism at a fine grain٫ where this monoid approach is geared towards the larger grain of tree structure. But both are necessary for a performant GPU implementation; anyone intending to really parse JSON on GPU is well advised to study it.</p>

<p>Parsing CSV has some of the same problems as JSON٫ though not the (potentially deeply) nested tree structure. A recent preprint٫ <a href="https://arxiv.org/pdf/1905.13415.pdf">ParPaRaw: Massively Parallel Parsing of Delimiter-Separated Raw Data</a> presents a GPU implementation.</p>

<p>This <a href="https://github.com/rapidsai/cudf/pull/1512">PR to cudf</a> implements “JSON Lines” parsing٫ which seems to me more similar to CSV than full tree-structured JSON parsing٫ but I haven’t dug into it in detail.</p>

<p>There is also a large literature on incremental parsing٫ which is related to parallel parsing as well (monoids are useful to both); a relevant example is <a href="https://www.cambridge.org/core/journals/journal-of-functional-programming/article/efficient-parallel-and-incremental-parsing-of-practical-contextfree-languages/4D620F0BFADE2B588F854AAAEA252F5C">Efficient parallel and incremental parsing of practical context-free languages</a>.</p>

<p>I linked it in my previous blog٫ but <a href="https://scholarworks.iu.edu/dspace/handle/2022/24749">Aaron Hsu’s PhD thesis</a> is a remarkable full compiler implementation (for an APL-derived language) on GPU. It <em>does</em> address tree structure٫ and I believe generally uses adjacency matrices to represent that.</p>

<p>An interesting paper on converting a sequential program into a monoid is <a href="https://dl.acm.org/doi/pdf/10.1145/3018882.3018891">Functional Parallels of Sequential Imperatives</a>٫ and that has a lot of pointers into other literature. I haven’t (yet) read it carefully enough to know whether it could derive the monoid stated above. There’s also some literature on <a href="https://scholar.google.com/scholar?um=1&amp;ie=UTF-8&amp;lr&amp;cites=9891136685444157082">symbolic execution for deriving map-reduce aggregations</a> that could well be relevant.</p>

<h2 id="conclusions">Conclusions</h2>

<p>I am even more convinced than before that efficient parsing is possible on GPU. The “stack monoid” shows promise to be a fundamental building block to represent the parse stack٫ and in general to manipulate tree structured data. I am unaware of any presentation of this٫ though it’s likely it exists somewhere in the literature.</p>

<p>Automatically generating monoids such as the stack monoid from their corresponding simple sequential programs seems like an extremely promising area for research. If I were a professor (I’m not) and a PhD student brought it to me as a proposal٫ I would be quite excited.</p>

<p>Part of the motivation for this exploration is to represent the “clip stack” in piet-gpu٫ which has turned out to be a bit of a tricky problem; I’m likely to compute at least some of that on CPU as a preprocessing step. But it would be appealing٫ and very much in the spirit of piet-gpu٫ to do all of that computation on the GPU٫ and even more so if there are no artificial limits on nesting depth. If I do implement that٫ it will no doubt be another blog post (including quantitative measurements).</p>

<p>But in the meantime٫ I’m interested to see if other people take up these ideas. My JSON post has gotten a steady trickle of interest since it was published. I’d also like to learn if there’s literature that’s been published but I just haven’t seen yet. If not٫ it seems like a very rich vein of ore to mine.</p>

<p>(As a personal note٫ I’m taking a break from Twitter٫ possibly a very long one٫ as I’m finding that social media has been really sapping my energy. The best way to get in touch with me for followup is email. I do love hearing from people though!)</p>

<p>Discuss on <a href="https://news.ycombinator.com/item?id=24385095">Hacker News</a>. Thanks to 
Vijay Chakravarthy٫ George Kulakowski٫ Eli Rosenthal٫ and Dan Rosen for pointers to the literature٫ and Chao Gao for posing a question about the original JSON post that sparked this exploration.</p>'),('https://raphlinus.github.io/covid/2020/07/08/seeking-truth.html', 'Seeking truth in a time of misinformation', '1594221102000',  12, '<p>Online abuse of trust is one of the topics I’ve studied deeply٫ including significant work toward an unfinished <a href="https://levien.com/thesis/thesis.pdf">PhD</a>٫ and over two years working on a spam and abuse team at Google. These days my main work is on 2D graphics٫ but seeing patterns of misinformation about Covid-19 is bringing back interest and motivation to think about these topics.</p>

<p>As Covid-19 has been unfolding٫ I’ve spent significant time and energy trying to understand it٫ as I tend to do with threats in general. In so doing٫ I’ve developed some insight on how to tune media consumption patterns towards more truthful content and less misinformation.</p>

<h2 id="america-is-broken">America is broken</h2>

<p>The astonishingly poor national response to Covid-19 is heartbreaking. Given our incredible richness of resources٫ it is surprising that many of the failure modes resemble those from low-income countries: superstition٫ cult of personality٫ suppression of science٫ and straight up corruption. A common thread is misinformation and disinformation.</p>

<p>Our response to Covid-19 has been very much like driving a car with poorly-maintained brakes. We’ve done the equivalent of neglecting regular maintenance٫ ignoring the brake light on the dashboard٫ and choosing to not to pay attention to the squishy feeling of the brake pedal. It’s as if there’s a devil on our shoulder saying٫ “oh no٫ don’t get the brakes fixed٫ it might cost hundreds of dollars.”</p>

<p>I think it’s worth trying to understand <em>why</em> we’re in that position٫ but it’s beyond the scope of this blog post. Mass behavior of humans is pretty predictable٫ but individual choices can probably make some difference. I have no answers for those who <em>want</em> to listen to that devil (a big challenge in and of itself)٫ but for those would prefer to listen to the angel instead٫ I have some tips.</p>

<h2 id="it-is-a-partisan-issue">It is a partisan issue</h2>

<p>I often see the plea “it is not a partisan issue” attached to factual arguments. I think this represents an aspiration: it <em>should</em> not be partisan. In 2020 America٫ the reality is that there is a powerful anti-science٫ anti-truth faction٫ and that faction makes up a large part of the composition of one of the political parties. It’s not 100% alignment٫ and I want to give credit where credit is due: for example٫ the moderate Republican governor of Massachusetts has embraced science and investment in public health٫ and the results in that state are one of the best in the country.</p>

<p>But in general٫ any factual argument that has bearing on a political question such as “should we invest in public health” or “should we restructure the economy away from carbon consumption” is now inherently partisan.</p>

<p>Much of the partisan content in media is around issues that are not very consequential٫ either pure entertainment٫ or (at least traditionally) between candidates or parties that have comparable ability to govern. I was hopeful that the life or death nature of Covid-19 would motivate the people who decide what appears in media to higher standards. But apparently٫ it’s just the <a href="https://en.wikipedia.org/wiki/The_Scorpion_and_the_Frog">nature of the scorpion</a>٫ they either can’t help themselves or just don’t care. Almost certainly٫ the media organization with the most blood on its hands is Fox News٫ which actively promotes an anti-health٫ pro-infection agenda. I don’t understand how they sleep at night.</p>

<p>Truth threatens a lot of existing power structures. If everybody woke up tomorrow and decided they were tired of being lied to٫ there would be seismic shifts of power. It’s worth thinking about who might be most affected by such a thing٫ and the kinds of things they do to keep it from happening.</p>

<h2 id="high-end-science-journalism">High-end science journalism</h2>

<p>I’m going to cover a range of information sources in this post٫ but there is a tl;dr: read up on actual science journalism by people who know what they’re talking about. Coverage by Science٫ Nature٫ and STAT News has been uniformly excellent. Good journalism is always teamwork٫ but I’ll also raise up the voices of particularly insightful individuals: <a href="https://twitter.com/sciencecohen">Jon Cohen</a> and <a href="https://twitter.com/kakape">Kai Kupferschmidt</a> of Science٫ <a href="https://twitter.com/amymaxmen">Amy Maxmen</a> of Nature٫ <a href="https://twitter.com/HelenBranswell">Helen Branswell</a> of STAT News. These are science journalists who have invested years in honing their craft.</p>

<p>I’ve also been impressed by coverage in The Atlantic. Their science content is quite good (thanks to top-notch contributors such as <a href="https://twitter.com/edyong209">Ed Yong</a>)٫ but they also put the science in the context of American culture and politics. It is for this reason٫ I believe٫ that our President has <a href="https://www.washingtonian.com/2020/05/27/the-atlantic-saw-subscriptions-surge-after-trump-tweet/">singled them out</a> for criticism.</p>

<p>It’s interesting that these sources tend to be publications that have been around for a while (STAT News is a brand of the Boston Globe media group). It’s not exactly rocket science how to do this٫ you just need to find experienced٫ capable writers and pay them to do journalism٫ with editorial and institutional support. But in today’s hyper-capitalist society٫ sustaining such efforts is a struggle. If you can٫ try to support publications that do good work by subscribing٫ or donating in the case of non-profits.</p>

<p>For someone with a limited budget of time and attention٫ good science journalism is absolutely the best bang for the buck. The other recommendations in this post are for people who want to spend a little more effort to gain٫ hopefully٫ a little more insight.</p>

<h2 id="twitter">Twitter</h2>

<p>By far the most interesting experience I’ve had has been Twitter. What makes Twitter unique is its extremely wide dynamic range of information quality: both the worst of the worst and the best of the best are well represented. (An example of an information source of low dynamic range is an encyclopedia: almost every article is pretty good٫ garbage and brilliance both being rare)</p>

<p>A well-curated Twitter feed is one of the best information sources available today٫ and following random people on Twitter is one of the worst.</p>

<p>Even though it has no formal structure such as subreddits٫ Twitter functions as a set of overlapping communities٫ often described as “X Twitter” or “Y Twitter” (incidentally٫ a good explanation of how communities work on Twitter can be had in Jeff Jarvis’ <a href="https://buzzmachine.com/2020/05/11/a-conversation-with-nathan-allebach-steak-umms-voice/">interview of the voice behind Steak-umm</a>). There are many experts who generously share their knowledge and thoughts with us٫ and I’ve found that with a modest investment of time٫ it’s possible to follow along.</p>

<p>In one of the <a href="https://www.youtube.com/channel/UCud8VIawWp17jKl2Lp0VvlQ">Jeff Jarvis interviews</a>٫ they jokingly referred to “idiot Twitter٫” and٫ though it was a joke٫ the concept has stuck with me. Twitter٫ like all social media properties٫ works by engaging very large numbers of people with content that appeals emotionally. The expert communities are far too small a fraction of Twitter’s traffic to be profitable for them٫ but they support them as a way to maintain the prestige of the platform. The replies of any popular post are filled with all manner of conspiracy theory٫ miracle cure٫ denial٫ blame٫ and٫ I think at least sometimes٫ active disinformation by those who would do us harm (it’s hard to tell the difference and the outcome is the same). I think of all that as “idiot Twitter” and just do my best to avoid it. I also see it everywhere٫ of course٫ not just Twitter٫ and the quantity of it is a good measure of the value in a social media platform.</p>

<p>Twitter has a delicate balance to maintain٫ as there are many aspects of the site design that push you toward “idiot Twitter” even when you’re trying to curate your experience to avoid it. One example that consistently frustrates me is the trending panel٫ as that seems to be about half composed of idiot Twitter. It’s addictive٫ even so٫ because it tempts you with the thrill of discovering things early. I’ve also found that it’s easier to avoid junk on the desktop site than the mobile app. I’m worried the experience will degrade; Quora stands as a cautionary tale of what can happen to a relatively respectable site when they pursue clicks at the cost of all else.</p>

<p>Whether it would be viable to develop a social network designed for quality of discussion is another topic beyond this blog. I’m not especially hopeful on this front٫ as it’s hard to see how it would be profitable. In any case٫ there’s not much value in wishing for the possibly impossible٫ as somebody seeking quality information can find it even today.</p>

<h3 id="list-curation">List curation</h3>

<p>One of the interesting features of Twitter is that people will curate and share lists of people they feel are worth following. My <a href="https://twitter.com/i/lists/1239639611694911489">covid-19 list</a> is one such٫ and a lot of thought went into it: I’ve intentionally included people with a wide range of expertise (including٫ for example٫ <a href="https://twitter.com/j_g_allen">Joseph Allen</a> for his insight into healthy buildings and <a href="https://twitter.com/uche_blackstock">Dr. Uché Blackstock</a> for expertise on health equity). I’ve also deliberately excluded people from this list who express strong political views or often use an emotional tone. Because of the latter criterion٫ it’s missing people I personally feel are worth listening to٫ especially <a href="https://twitter.com/gregggonsalves">Gregg Gonsalves</a> and <a href="https://twitter.com/JeremyKonyndyk">Jeremy Konyndyk</a>. As always٫ your mileage may vary. The goal of this particular list is not to be comprehensive٫ it’s to select a set of voices that have excellent signal to noise ratio; for a much more comprehensive list٫ see <a href="https://twitter.com/i/lists/1237834151694303234">this one curated by Jeff Jarvis</a>.</p>

<p>One phenomenon I’ve noticed is that people at the top of these lists tend to recommend each other. I wouldn’t be surprised if some automated evaluation (perhaps based on eigenvalues) could yield a good curated list. That said٫ in my past research٫ I’ve found that any automatic metric with an incentive will be <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">gamed</a>٫ and invariably will lift up self-promoters over quiet٫ thoughtful voices.</p>

<p>Speaking of self-promoters٫ two names do not belong on lists of top experts٫ but are often found there: Eric Feigl-Ding &amp; Laurie Garrett. Both are good communicators٫ but are also sloppy enough with their science to get called out regularly. Inclusion of these names is a sign that a list of experts is not especially carefully curated.</p>

<p>Another important warning sign is lack of inclusion of women and people of color; mainstream media is often guilty of this. Health equity is an especially important part of the Covid-19 story٫ and not listening to expertise in this area is as irresponsible as it is predictable. <a href="https://twitter.com/angie_rasmussen">Dr. Angela Rasmussen</a> is a good critic of media representation problems٫ on top of being a brilliant virologist (she is co-author on that D614G paper mentioned below) and <a href="https://twitter.com/jeffjarvis/status/1247893251916324865">master Twitter communicator</a>.</p>

<h2 id="medium-quality-sources">Medium quality sources</h2>

<p>This section is easily skippable٫ as these medium quality sources can be safely ignored. But if they make up a significant fraction of your information diet٫ it might be useful to examine their flaws.</p>

<p>It’s been fascinating watching experts and more mainstream sources side by side٫ as coverage of stories so often sounds completely different. There are particular stories that seem to grab the attention of the media B ark:</p>

<ul>
  <li>
    <p>Anything indicating that Covid-19 is less serious than it really is. For example٫ the Stanford seroprevalence studies were hyped massively in the press٫ even though they were based on shoddy science.</p>
  </li>
  <li>
    <p>Alarmist narratives as well (“if it bleeds٫ it leads”). An exceptionally good marker for this is the <a href="https://www.cell.com/cell/fulltext/S0092-8674(20)30817-5?sf235753727=1">D614G mutation</a>. In the mainstream press٫ including reporters I would ordinarily trust٫ it’s a widely believed fact that this mutation represents a deadlier strain of the virus. Even before attention on this specific mutation٫ the excellent <a href="https://nextstrain.org/">Nextstrain</a> work was often misinterpreted as varying degrees of transmissibility or infectiousness (as <em>is</em> the case for influenza). It is possible that there will be a “there there” on D614G٫ but there’s no evidence yet for practical consequences.</p>
  </li>
  <li>
    <p>And٫ combining the two themes above٫ the idea that the virus is “weakening٫” seemingly based on theories of evolutionary pressure.</p>
  </li>
</ul>

<p>I spend a fair amount of time on <a href="https://news.ycombinator.com/">Hacker News</a> as a source of tech information and discussion. It tends to run about one Covid-19 story a day٫ and the quality of discourse there is٫ regrettably٫ pretty bad. It is a reasonable source of insight into which particular strains of misinformation are widely believed by “tech bros٫” who tend not to be shy at all about confidently trumpeting their armchair takes.</p>

<p>I reserve special condemnation٫ though٫ for the NY Times opinion page. They frequently run pieces that are simply indefensible to anyone who cares about truth٫ and wouldn’t pass the laugh test if reviewed by experts. A fairly extreme but sadly not completely atypical example is the Brett Stephens column <a href="https://www.nytimes.com/2020/04/24/opinion/coronavirus-lockdown.html">America Shouldn’t Have to Play by New York Rules</a>. It likely is the case that the NY Times opinion page accurately records the dominant narrative of those in power٫ and as such is a good window into that aspect of America’s brokenness. Whenever they run a particular bad howler٫ <a href="https://twitter.com/gregggonsalves">Gregg Gonsalves</a> can usually be relied on to provide an expert critique.</p>

<p>I have not found video sources to be particularly helpful compared with the best of the other sources cited above (partly it’s my bias toward text for complex thoughts)٫ but of the cable news hosts٫ Chris Hayes has been consistently above average٫ treating the topic seriously and avoiding oversimplification.</p>

<p>I’m not going to talk about actual low-quality sources here٫ though it’s an extremely important part of understanding the climate of disinformation. I will note٫ though٫ that I have actually deleted (not just paused) my accounts on Facebook properties.</p>

<h2 id="authority">Authority</h2>

<p>In a functioning government٫ we’d be able to rely on government authority as a good source of information. Indeed٫ that could be seen as one of the primary functions of government. The CDC was once widely acclaimed as the best public health organization on the planet٫ and an acknowledged leader on the world stage. Today it is muzzled and ineffective. A particular failure is guidance around masks. Through conflicting messages and weak communication٫ they have squandered a great deal of trust.</p>

<p>Another highly troubling story is their case fatality rate estimate٫ which is much lower than expert consensus. They’ve been repeatedly asked to provide data and scientific reasoning٫ but don’t even pretend to be able to defend their work.</p>

<p>As a result٫ you’re in a situation where٫ as a computer scientist with a passing interest in Covid-19٫ it is extremely likely that my estimate (0.5% - 1.0%) for infection fatality rate is more accurate than that of the disease authority of the land٫ and by linking to <a href="https://twitter.com/CT_Bergstrom/status/1279612165201133570">Carl Bergstrom’s thread</a> I have just provided better scientific evidence for that assertion than the CDC is capable of managing. [If٫ in a couple months٫ it turns out I am wrong and the CDC is right٫ by all means please use this post to discredit anything else I say that’s out of my lane.]</p>

<p>This state of affairs is a bit of a problem for organizations like search engines and social media٫ who generally need clear criteria for what’s good information and what’s disinformation٫ so naturally want to turn to authority. Since this blog post disagrees with the CDC٫ it might well run afoul of these kinds of guidelines.</p>

<p>By contrast٫ I was originally fairly critical of people like <a href="https://medium.com/@tomaspueyo">Tomás Pueyo</a> for self-promotion over proper expertise. But from his work as a “vice president of growth” at a Silicon Valley startup٫ he is clearly skilled in understanding communication and human behavior٫ and his “flattening the curve” piece arguably saved many more lives than the CDC’s halfhearted comms efforts. Even more impressively to me٫ his <a href="https://medium.com/@tomaspueyo/coronavirus-the-hammer-and-the-dance-be9337092b56">The Hammer and the Dance</a> piece set out a roadmap in <em>March</em> with advanced concepts such as budget for staying below R = 1. By contrast٫ our actual public health “leadership” appears to have been eating paste٫ blowing that budget on stupid shit like bars٫ while leaving us in an impossible situation where we have to reopen schools in the fall without a viable plan to keep people safe. As I write this٫ the CDC is facing a firestorm of criticism for allowing political and non-science-based considerations to influence their guidance for schools in the fall٫ and٫ in trying to appease both sides٫ have lost their credibility with both as well. Leadership can come from many places٫ and we have to find it where we can get it.</p>

<p>That said٫ while the leadership of the CDC is broken in the same way as so many institutions in America٫ it still has lots of excellent people working for it. And don’t confuse my criticism as being anti-expert٫ quite the contrary. Armchair epidemiologists often cite failures (real or perceived) of authority as justification for why their rando opinions should be taken seriously٫ but that’s just a logical fallacy.</p>

<h2 id="peer-reviewed-papers">Peer-reviewed papers</h2>

<p>I did a minor in molecular and cell biology as part of my masters degree at Berkeley٫ so I have more than a passing intellectual curiosity in such things٫ but overall I am not a huge fan of lay consumption of scientific papers. A huge risk is cherry-picking. It’s possible to find support for just about any viewpoint in the peer-reviewed literature٫ and that’s actually working as it should be — it’s how scientific conversations happen.</p>

<p>The hydroxychloroquine story dramatically illustrates potential failures of peer review. There are two layers to the HCQ story. Just looking at pure science٫ it’s quite routine for pharmaceuticals to show early promise٫ then on closer examination٫ no real benefit. Hydroxychloroquine is no different than dozens of others in this respect. But٫ of course٫ the other layer is that it was adopted as a miracle cure٫ especially by leaders of certain political parties around the world. In the early days٫ this narrative was fueled by a peer-reviewed paper which was later retracted٫ with the integrity of the journal <a href="https://retractionwatch.com/2020/04/12/elsevier-investigating-hydroxychloroquine-covid-19-paper/">questioned</a> (a <a href="https://blogs.sciencemag.org/pipeline/archives/2020/04/06/hydroxychloroquine-update-for-april-6">blog post by Derek Lowe</a> also makes good reading).</p>

<p>But the story gets weirder. While experts were converging around a consensus that HCQ had limited if any effectiveness٫ a paper in the highly regarded Lancet journal seemed to definitely answer the question in the negative٫ to the contrary arguing that it was actively harmful. However٫ on closer examination٫ <a href="https://www.sciencemag.org/news/2020/06/mysterious-company-s-coronavirus-papers-top-medical-journals-may-be-unraveling">that paper turned out to be extremely suspect</a> and was also retracted. Given the rather obvious flaws٫ how did it get published in the first place? My personal favorite narrative is from the <a href="https://respectfulinsolence.com/2020/06/05/surgisphere-debacle/">Respectful Insolence blog</a>٫ as it’s both factual and colorful. Adding to the strangeness٫ one of the best <a href="https://www.medicineuncensored.com/a-study-out-of-thin-air">criticisms</a> of the Lancet paper (cited by that linked blog) is from James Todaro٫ who is best known for publishing a <a href="https://ipfs.infura.io/ipfs/QmNcF4usFUJdGjTMtEXT1XAYybJvtLmEjaZnvNXN2n91Zh/">“paper”</a> in favor of HCQ that overstated the credentials and affiliations of the authors in a way that verges on fraudulent٫ if not crossing the line. Strange days.</p>

<p>The moral of this story is that appearing in a peer reviewed publication is nowhere near a guaranteed stamp of truth. As always٫ critical thinking wins. In monitoring #EpiTwitter٫ I’ve seen the pattern quite frequently of some controversial paper appearing (very often “science by press release” before a proper preprint is even available)٫ attracting skepticism and criticism early on. Frequently <a href="https://twitter.com/CT_Bergstrom">Carl Bergstrom</a>٫ an <a href="https://callingbullshit.org/">expert on bullshit</a>٫ is a strong voice of such criticism.</p>

<p>The equation changes of course٫ when one is willing to invest the time and energy to really study a topic٫ to develop the background of knowledge to understand and appreciate the work.</p>

<p>There’s a major discussion to be had regarding the flaws of peer review٫ including the role of preprints٫ the gatekeeping role of publishers٫ and fraudulent paper mills (see <a href="https://twitter.com/MicrobiomDigest">Elisabeth Bik</a> for a steady stream of offenders on this front)٫ but that’s beyond this blog.</p>

<h2 id="you">You</h2>

<p>I’ve argued that you can’t trust authority like the CDC٫ and that mainstream sources fall far short of what we need. As a reader of my blog٫ you likely have above average ability to discern truthful information from lies٫ and you also probably can communicate reasonably effectively to other people. Because our systems and institutions are failing us so badly٫ the responsibility then falls on you٫ my dear reader٫ to do your part to improve science communication in general٫ and in particular around Covid-19.</p>

<p>Cut out disinformation. Seek out actual experts. Do your own critical thinking٫ and don’t follow just because you like the source or feel alignment with their politics. Amplify voices worth amplifying٫ and don’t give lies more oxygen. I hope these notes are useful in some way.</p>

<p>Thank you for these efforts٫ and please٫ take care of ourselves and each other.</p>'),('https://raphlinus.github.io/xi/2020/06/27/xi-retrospective.html', 'xi-editor retrospective', '1593278163000',  12, '<p>A bit more than four years ago I started the <a href="https://github.com/xi-editor/xi-editor">xi-editor</a> project. Now I have placed it on the back burner (though there is still some activity from the open source community).</p>

<p>The original goal was to deliver a very high quality editing experience. To this end٫ the project spent a rather large number of “novelty points”:</p>

<ul>
  <li>Rust as the implementation language for the core.</li>
  <li>A rope data structure for text storage.</li>
  <li>A multiprocess architecture٫ with front-end and plug-ins each with their own process.</li>
  <li>Fully embracing async design.</li>
  <li><a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type">CRDT</a> as a mechanism for concurrent modification.</li>
</ul>

<p>I still believe it would be possible to build a high quality editor based on the original design. But I <em>also</em> believe that this would be quite a complex system٫ and require significantly more work than necessary.</p>

<p>I’ve written the <a href="https://github.com/xi-editor/xi-editor/issues/1187#issuecomment-491473599">CRDT part of this retrospective</a> already٫ as a comment in response to a Github issue. That prompted good <a href="https://news.ycombinator.com/item?id=19886883">discussion</a> on Hacker News. In this post٫ I will touch again on CRDT but will focus on the other aspects of the system design.</p>

<h2 id="origins">Origins</h2>

<p>The original motivation for xi came from working on the Android text stack٫ and confronting two problems in particular. One٫ text editing would become very slow as the text buffer got bigger. Two٫ there were a number of concurrency bugs in the interface between the EditText widget and the keyboard (input method editor).</p>

<p>The culprit of the first problem turned out to be the <a href="https://developer.android.com/reference/android/text/SpanWatcher">SpanWatcher</a> interface٫ combined with the fact that modern keyboards like to put a spelling correction span on each word. When you insert a character٫ all the successive spans bump their locations up by one٫ and then you have to send onSpanChanged for each of those spans to all the watchers. Combined with the fact that the spans data structure had a naive O(n) implementation٫ and the whole thing was quadratic or worse.</p>

<p>The concurrency bugs boil down to synchronizing edits across two different processes٫ because the keyboard is a different process than the application hosting the EditText widget. Thus٫ when you send an update (to move the cursor٫ for example) and the text on the other side is changing concurrently٫ it’s ambiguous whether it refers to the old or new location. This was handled in an “almost correct” style٫ with timeouts for housekeeping updates to minimize the chance of a race. A nice manifestation of that is that swiping the cursor slowly through text containing complex emoji could cause flashes of the emoji breaking.</p>

<p>These problems have a unifying thread: in both cases there are small diffs to the text٫ but then the data structures and protocols handled these diffs in a less than optimal way٫ leading to both performance and correctness bugs.</p>

<p>To a large extent٫ xi started as an exploration into the “right way” to handle text editing operations. In the case of the concurrency bugs٫ I was hoping to find a general٫ powerful technique to facilitate concurrent text editing in a distributed-ish system. While most of the Operational Transformation literature is focused on multiple users collaboratively editing a document٫ I was hoping that other text manipulations (like an application enforcing credit card formatting on a text input field) could fit into the general framework.</p>

<p>That was also the time I was starting to get heavily into Rust٫ so it made natural sense to start prototyping a new green-field text editing engine. How would you “solve text” if you were free of backwards compatibility constraints (a huge problem in Android)?</p>

<p>When I started٫ I knew that Operational Transformation was a solution for collaborative editing٫ but had a reputation for being complex and finicky. I had no idea how deep the rabbithole would be of OT and then CRDT. Much of that story is told in the <a href="https://news.ycombinator.com/item?id=19886883">CRDT discussion</a> previously linked.</p>

<h2 id="the-lure-of-modular-software">The lure of modular software</h2>

<p>There is an extremely long history of people trying to build software as composable modules connected by some kind of inter-module communication fabric. Historical examples include <a href="https://en.wikipedia.org/wiki/DCE/RPC">DCE/RPC</a>٫ <a href="https://en.wikipedia.org/wiki/Common_Object_Request_Broker_Architecture">Corba</a>٫ <a href="https://en.wikipedia.org/wiki/Bonobo_(GNOME)">Bonobo</a>٫ and more recently things like <a href="https://sandstorm.io/">Sandstorm</a> and <a href="https://fuchsia.dev/fuchsia-src/concepts/modular/module">Fuchsia Modular</a>. There are some partial successes٫ including <a href="https://developer.android.com/reference/android/os/Binder">Binder</a> on Android٫ but this is still mostly an unrealized vision. (Regarding Binder٫ it evolved from a much more idealistic vision٫ and I strongly recommend reading this 2006 interview about <a href="https://www.osnews.com/story/13674/introduction-to-openbinder-and-interview-with-dianne-hackborn/">OpenBinder</a>).</p>

<p>When I started xi٫ there were signs we were getting there. Microservices were becoming popular in the Internet world٫ and of course all Web apps have a client/server boundary. Within Google٫ <a href="https://grpc.io/">gRPC</a> was working fairly well٫ as was the internal process separation within Chrome. In Unix land٫ there’s a long history of the terminal itself presenting a GUI (if primitive٫ though gaining features such as color and mouse). There’s also the tradition of <a href="https://en.wikipedia.org/wiki/Blit_(computer_terminal)">Blit</a> and then٫ of course٫ <a href="https://en.wikipedia.org/wiki/NeWS">NeWS</a> and X11.</p>

<p>I think one of the strongest positive models was the database / business logic split٫ which is arguably the most successful example of process separation. In this model٫ the database is responsible for performance and integrity٫ and the business logic is in a separate process٫ so it can safely do things like crash and hang. I very much thought of xi-core as a database-like engine٫ capable of handling concurrent text modification much like a database handles transactions.</p>

<p>Building software in such a modular way requires two things: first٫ infrastructure to support remote procedure calls (including serialization of the requests and data)٫ and second٫ well-defined interfaces. Towards the end of 2017٫ I saw the goal of xi-editor as <em>primarily</em> being about defining the interfaces needed for large scale text editing٫ and that this work could endure over a long period of time even as details of the implementation changed.</p>

<p>For the infrastructure٫ we chose JSON (about which more below) and hand-rolled our own xi-rpc layer (based on JSON-RPC). It turns out there are a lot of details to get right٫ including dealing with error conditions٫ negotiating when two ends of the protocol aren’t exactly on the same version٫ etc.</p>

<p>One of the bolder design decisions in xi was to have a process separation between front-end and core. This was inspired in part by <a href="https://neovim.io/">Neovim</a>٫ in which everything is a plugin٫ even GUI. But the main motivation was to build GUI applications using Rust٫ even though at the time Rust was nowhere near capable of native GUI. The idea is that you use the best GUI technology of the platform٫ and communicate via async pipes.</p>

<p>One argument for process separation is to improve overall system reliability. For example٫ Chrome has a process per tab٫ and if the process crashes٫ all you get is an “Aw٫ snap” without bringing the whole browser down. I think it’s worth asking the question: is it useful to have the front-end continue after the core crashes٫ or the other way around? I think probably not; in the latter case it might be able to safely save the file٫ but you can also do that by frequently checkpointing.</p>

<p>Looking back٫ I see much of the promise of modular software as addressing goals related to project management٫ not technical excellence. Ideally٫ once you’ve defined an inter-module architecture٫ then smaller teams can be responsible for their own module٫ and the cost of coordination goes down. I think this type of project management structure is especially appealing to large companies٫ who otherwise find it difficult to manage larger projects. And the tax of greater overall complexity is often manageable٫ as these big companies tend to have more resources.</p>

<h3 id="json">JSON</h3>

<p>The choice of JSON was controversial from the start. It did end up being a source of friction٫ but for surprising reasons.</p>

<p>The original vision was to write plug-ins in any language٫ especially for things like language servers that would be best developed in the language of that ecosystem. This is the main reason I chose JSON٫ because I expected there would be high quality implementations in every viable language.</p>

<p>Many people complained about the fact that JSON escapes strings٫ and suggested alternatives such as <a href="https://msgpack.org/index.html">MessagePack</a>. But I knew that the speed of raw JSON parsing was a solved problem٫ with a number of extremely high performance implementations (<a href="https://github.com/simdjson/simdjson">simdjson</a> is a good example).</p>

<p>Even so٫ aside from the general problems of modular software as described above٫ JSON was the source of two additional problems. For one٫ <a href="https://github.com/xi-editor/xi-mac/issues/102">JSON in Swift is shockingly slow</a>. There are <a href="https://forums.swift.org/t/rearchitecting-jsonencoder-to-be-much-faster/28139">discussions on improving it</a> but it’s still a problem. This is surprising to me considering how important it is in many workloads٫ and the fact that it’s clearly possible to write a high performance JSON implementation.</p>

<p>Second٫ on the Rust side٫ while <a href="https://serde.rs/">serde</a> is quite fast and very convenient (thanks to proc macros)٫ when serializing a large number of complex structures٫ it bloats code size considerably. The xi core is 9.3 megabytes in a Linux release build (debug is an eye-watering 88MB)٫ and a great deal of that bloat is serialization. There is work to reduce this٫ including <a href="https://github.com/dtolnay/miniserde">miniserde</a> and <a href="https://github.com/not-fl3/nanoserde">nanoserde</a>٫ but serde is still by far the most mainstream.</p>

<p>I believe it’s possible to do performant٫ clean JSON across most languages٫ but people should know٫ we’re not there yet.</p>

<h2 id="the-rope">The rope</h2>

<p>There are only a few data structures suitable for representation of text in a text editor. I would enumerate them as: contiguous string٫ gapped buffer٫ array of lines٫ piece table٫ and rope. I would consider the first unsuitable for the goals of xi-editor as it doesn’t scale well to large documents٫ though its simplicity is appealing٫ and memcpy is fast these days; if you know your document is always under a megabyte or so٫ it’s probably the best choice.</p>

<p>Array of lines has performance failure modes٫ most notably very long lines. Similarly٫ many good editors have been written using piece tables٫ but I’m not a huge fan; performance is very good when first opening the file٫ but degrades over time.</p>

<p>My favorite aspect of the rope as a data structure is its excellent worst-case performance. Basically٫ there aren’t any cases where it performs <em>badly.</em> And even the concern about excess copying because of its immutability might not be a real problem; Rust has a <a href="https://doc.rust-lang.org/std/sync/struct.Arc.html#method.make_mut">copy-on-write mechanism</a> where you can mutate in-place when there’s only one reference to the data.</p>

<p>The main argument against the rope is its complexity. I think this varies a lot by language; in C a gapped buffer might be preferable٫ but I think in Rust٫ a rope is the sweet spot. A large part of the reason is that in C٫ low level implementation details tend to leak through; you’ll often be dealing with a pointer to the buffer. For the common case of operations that don’t need to span the gap٫ you can hand out a pointer to a contiguous slice٫ and things just don’t get any simpler than that. Conversely٫ if any of the invariants of the rope are violated٫ the whole system will just fall apart.</p>

<p>In Rust٫ though٫ things are different. Proper Rust style is for all access to the data structure to be mediated by a well-defined interface. Then the details about how that’s implemented are hidden from the user. A good way to think about this is that the implementation has complexity٫ but that complexity is <em>contained.</em> It doesn’t leak out.</p>

<p>I think the rope in xi-editor meets that ideal. A lot of work went into getting it right٫ but now it works. Certain things٫ like navigating by line and counting UTF-16 code units٫ are easy and efficient. It’s built in layers٫ so could be used for other things including binary editing.</p>

<p>One of the best things about the rope is that it can readily and safely be shared across threads. Ironically we didn’t end up making much use of that in xi-editor٫ as it was more common to share across <em>processes٫</em> using sophisicated diff/delta and caching protocols.</p>

<p>A rope is a fairly niche data structure. You really only want it when you’re dealing with large sequences٫ and also doing a lot of small edits on them. Those conditions rarely arise outside text editors. But for people building text editing in Rust٫ I think xi-rope holds up well and is one of the valuable artifacts to come from the project.</p>

<p>There’s a good <a href="https://news.ycombinator.com/item?id=15381886">HN discussion of text editor data structures</a> where I talk about the rope more٫ and can also point people to the <a href="https://xi-editor.io/docs/rope_science_00.html">Rope science</a> series for more color.</p>

<h2 id="async-is-a-complexity-multiplier">Async is a complexity multiplier</h2>

<p>We knew going in that async was going to be a source of complexity. The hope is that we would be able to tackle the async stuff once٫ and that the complexity would be encapsulated٫ much as it was for the rope data structure.</p>

<p>The reality was that adding async made everything more complicated٫ in some cases considerably so. A particularly difficult example was dealing with word wrap. In particular٫ when the width of the viewport is tied to the window٫ then live-resizing the window causes text to rewrap continuously. With the process split between front-end and core٫ and an async protocol between them٫ all kinds of interesting things can go wrong٫ including races between editing actions and word wrap updates. More fundamentally٫ it is difficult to avoid tearing-style artifacts.</p>

<p>One early relative success was implementing scrolling. The problem is that٫ as you scroll٫ the front-end needs to sometimes query the core to fetch visible text that’s outside its cache. We ended up building this٫ but it took months to get it right. By contrast٫ if we just had the text available as an in-process data structure for the UI to query٫ it would have been quite straightforward.</p>

<p>I should note that async in interactive systems is more problematic than the tamer variety often seen in things like web servers. There٫ the semantics are generally the same as simple blocking threads٫ just with (hopefully) better performance. But in an interactive system٫ it’s generally possible to observe internal states. You have to display <em>something</em>٫ even when not all subqueries have completed.</p>

<p>As a conclusion٫ while the process split with plug-ins is supportable (similar to the Language Server protocol)٫ I now firmly believe that the process separation between front-end and core was not a good idea.</p>

<h2 id="syntax-highlighting">Syntax highlighting</h2>

<p>Probably the high point of the project was the successful implementation of syntax highlighting٫ based on Tristan Hume’s <a href="https://github.com/trishume/syntect">syntect</a> library٫ which was motivated by xi. There’s a lot more to say about this.</p>

<p>First٫ TextMate / Sublime style syntax highlighting is not really all that great. It is quite slow٫ largely because it grinds through a lot of regular expressions with captures٫ and it is also not very precise. On the plus side٫ there is a large and well-curated open source collection of syntax definitions٫ and it’s definitely “good enough” for most use. Indeed٫ code that fools these syntax definitions (such as two open braces on the same line) is a good anti-pattern to avoid.</p>

<p>It may be surprising just how much slower regex-based highlighting is than fast parsers. The library that xi uses٫ syntect٫ is probably the fastest open source implementation in existence (the one in Sublime is faster but not open source). Even so٫ it is approximately 2500 times slower for parsing Markdown than <a href="https://github.com/raphlinus/pulldown-cmark">pulldown-cmark</a>. And syntect doesn’t even parse setext-style lists correctly٫ because Sublime style syntax definitions have to work line-at-a-time٫ and the line of dashes following a heading isn’t available until the next line.</p>

<p>These facts influenced the design of xi in two important ways. First٫ I took it as a technical challenge to provide a high-performance editing experience even on large files٫ overcoming the performance problems through async. Second٫ the limitations of the regex-based approach argued in favor of a modular plug-in architecture٫ so that as better highlighters were developed٫ they could be plugged in. I had some ambitions of creating a standard protocol that could be used by other editors٫ but this absolutely failed to materialize. For example٫ Atom instead developed <a href="https://github.blog/2018-10-31-atoms-new-parsing-system/">tree-sitter</a>.</p>

<p>In any case٫ I dug in and did it. The resulting implementation is impressive in many ways. The syntax highlighter lives in a different process٫ with asynchronous updates so typing is never slowed down. It’s also incremental٫ so even if changes ripple through a large file٫ it updates what’s on the screen quickly. Some of the sophistication is described in <a href="https://xi-editor.io/docs/rope_science_11.html">Rope science 11</a>.</p>

<p>There was considerable complexity in the implementation. Text was synchronized between the main xi-core process and the plug-in٫ but for large files٫ the latter stores only a fixed-size cache; the cache protocol ended up being quite sophisticated. Updates were processed through a form of Operational Transformation٫ so if a highlighting result raced a text edit٫ it would never color an incorrect region (this is still very much a problem for language server annotations).</p>

<p>As I said٫ syntax highlighting was something of a high point. The success suggested that a similar high-powered engineering approach could systematically work through the other problems. But this was not to be.</p>

<p>As part of this work٫ I explored an alternative syntax highlighting engine based on parser combinators. If I had pursued that٫ the result would have been lightning fast٫ of comparable quality to the regex approach٫ and difficult to create syntax descriptions٫ as it involved a fair amount of manual factoring of parsing state. While the performance would have been nice to have٫ ultimately I don’t think there’s much niche for such a thing. If I were trying to create the best possible syntax highlighting experience today٫ I’d adapt Marijn Haverbeke’s <a href="https://marijnhaverbeke.nl/blog/lezer.html">Lezer</a>.</p>

<p>To a large extent٫ syntax highlighting is a much easier problem than many of the others we faced٫ largely because the annotations are a history-free function of the document’s plain text. The problem of determining indentation may seem similar٫ but is dependent on history. And it basically doesn’t fit nicely in the CRDT model at all٫ as that requires the ability to resolve arbitrarily divergent edits between the different processes (imagine that one goes offline for a bit٫ types a bit٫ then the language server comes back online and applies indentation).</p>

<p>Another problem is that our plug-in interface had become overly specialized to solve the problems of syntax highlighting٫ and did not well support the other things we wanted to do. I think those problems could have been solved٫ but only with significant difficulty.</p>

<h2 id="there-is-no-such-thing-as-native-gui">There is no such thing as native GUI</h2>

<p>As mentioned above٫ a major motivation for the front-end / core process split was to support development of GUI apps using a polyglot approach٫ as Rust wasn’t a suitable language for building GUI. The theory was that you’d build the GUI using whatever libraries and language that was most suitable for the platform٫ basically the platform’s native GUI٫ then interact with the Rust engine using interprocess communication.</p>

<p>The strongest argument for this is probably macOS٫ which at the time had Cocoa as basically <em>the</em> blessed way to build GUI. Most other platforms have some patchwork of tools. <a href="https://docs.microsoft.com/en-us/windows/apps/desktop/choose-your-platform">Windows</a> is particularly bad in this respect٫ as there’s old-school (GDI+ based) win32٫ WinForms٫ WPF٫ Xamarin٫ and most recently <a href="https://microsoft.github.io/microsoft-ui-xaml/">WinUI</a>٫ which nobody wants to use because it’s Windows 10 only. Since xi began٫ macOS is now catching up in the number of official frameworks٫ with <a href="https://developer.apple.com/mac-catalyst/">Catalyst</a> and SwiftUI added to the roster. Outside the realm of official Apple projects٫ lots of stuff is shipping in Electron these days٫ and there are other choices including Qt٫ Flutter٫ Sciter٫ etc.</p>

<p>When doing some <a href="https://www.recurse.com/events/localhost-raph-levien">performance work</a> on xi٫ I found to my great disappointment that performance of these so-called “native” UI toolkits was often pretty poor٫ even for what you’d think of as the relatively simple task of displaying a screenful of text. A large part of the problem is that these toolkits were generally made at a time when software rendering was a reasonable approach to getting pixels on screen. These days٫ I consider GPU acceleration to be essentially required for good GUI performance. There’s a whole other blog post in the queue about how some toolkits try to work around these performance limitations by leveraging the compositor more٫ but that has its own set of drawbacks٫ often including somewhat ridiculous RAM usage for all the intermediate textures.</p>

<p>I implemented an OpenGL-based text renderer for xi-mac٫ and did similar explorations on Windows٫ but this approach gives up a lot of the benefits of using the native features (as a consequence٫ emoji didn’t render correctly). Basically٫ I discovered that there is a pretty big opportunity to build UI that doesn’t suck.</p>

<p>Perhaps the most interesting exploration was on Windows٫ the <a href="https://github.com/xi-editor/xi-win">xi-win</a> project. Originally I was expecting to build the front-end in C# using one of the more mainstream stacks٫ but I also wanted to explore the possibility of using lower-level platform capabilities and programming the UI in Rust. Early indications were positive٫ and this project gradually morphed into <a href="https://github.com/linebender/druid">Druid</a>٫ a native Rust GUI toolkit which I consider very promising.</p>

<p>If I had said that I would be building a GUI toolkit from scratch as part of this work when I set out٫ people would have rightly ridiculed the scope as far too ambitious. But that is how things are turning out.</p>

<h2 id="fuchsia">Fuchsia</h2>

<p>An important part of the history of the project is its home in Fuchsia for a couple years. I was fortunate that the team was willing to invest in the xi vision٫ including funding Colin’s work and letting me host Tristan to build multi-device collaborative editing as an intern project. In many ways the goals and visions aligned٫ and the demo of that was impressive. Ultimately٫ though٫ Fuchsia was not at the time (and still isn’t) ready to support the kind of experience that xi was shooting for. Part of the motivation was also to develop a better IME protocol٫ and that made some progress (continued by Robert Lord٫ and you can read about some of what we discovered in <a href="https://lord.io/blog/2019/text-editing-hates-you-too/">Text Editing Hates You Too</a>).</p>

<p>It’s sad this didn’t work out better٫ but such is life.</p>

<h2 id="a-low-point">A low point</h2>

<p>My emotional tone over the length of the project went up and down٫ with the initial enthusiasm٫ stretches of slow going٫ a renewed excitement over getting the syntax highlighting done٫ and some other low points. One of those was learning about the <a href="https://github.com/atom-archive/xray">xray</a> project. I probably shouldn’t have taken this personally٫ as it is <em>very common</em> in open source for people to spin up new projects for a variety of reasons٫ not least of which is that it’s fun to do things yourself٫ and often you learn a lot.</p>

<p>Even so٫ xray was a bit of a wake-up call for me. It was evidence that the vision I had set out for xi was not quite compelling enough that people would want to join forces. Obviously٫ the design of xray had a huge amount of overlap with xi (including the choice of Rust and decision to use a CRDT)٫ but there were other significant differences٫ particularly the choice to use Web technology for the UI so it would be cross-platform (the fragmented state of xi front-ends٫ especially the lack of a viable Windows port٫ was definitely a problem).</p>

<p>I’m putting this here because often٫ how you <em>feel</em> about a project is just as important٫ even more so٫ than technical aspects. I now try to listen more deeply to those emotional signals٫ especially valid criticisms.</p>

<h2 id="community">Community</h2>

<p>Part of the goal of the project was to develop a good open-source community. We did pretty well٫ but looking back٫ there are some things we could have done better.</p>

<p>A lot of the friction was simply the architectural burden described above. But in general I think the main thing we could have done better is giving contributors more <em>agency.</em> If you have an idea for a feature or other improvement٫ you should be able to come to the project and do it. The main role of the maintainers should be to help you do that. In xi٫ far too often things were blocking on some major architectural re-work (we have to redo the plug-in API before you can implement that feature). One of the big risks in a modular architecture is that it is often expedient to implement things in one module when to do things “right” might require it in a different place٫ or٫ even worse٫ require changes in inter-module interfaces. We had these decisions a lot٫ and often as maintainers we were in a gate-keeping role. One of the worst examples of this was vi keybindings٫ for which there was a great deal of community interest٫ and even a <a href="https://github.com/Peltoche/vixi">project done off to the side</a> to try to achieve it٫ but never merged into the main project.</p>

<p>So I think monolithic architectures٫ perhaps ironically٫ are <em>better</em> for community. Everybody takes some responsibility for the quality of the whole.</p>

<p>In 2017 we hosted three Google Summer of Code Students: Anna Scholtz٫ Dzũng Lê٫ and Pranjal Paliwal. This worked out well٫ and I think GSoC is a great resource.</p>

<p>I have been fortunate for almost the entire time to have Colin Rofls taking on most of the front-line community interaction. To the extent that xi has been a good community٫ much of the credit is due him.</p>

<p>One of the things we have done very right is setting up a Zulip instance. It’s open to all with a Github account٫ but we have had virtually no difficulty with moderation issues. We try to maintain positive interactions around all things٫ and lead by example. This continues as we pivot to other things٫ and may be one of the more valuable spin-offs of the project.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The xi-editor project had very ambitious goals٫ and bet on a number of speculative research subprojects. Some of those paid off٫ others didn’t. One thing I would do differently is more clearly identify which parts are research and which parts are reasonably straightforward implementations of known patterns. I try to do that more explicitly today.</p>

<p>To a large extent the project was optimized for learning rather than shipping٫ and through that lens it has been pretty successful. I now know a lot more than I did about building editor-like GUI applications in Rust٫ and am now applying that to making the <a href="https://github.com/linebender/druid">Druid</a> toolkit and the <a href="https://github.com/linebender/runebender">Runebender</a> font editor. Perhaps more important٫ because these projects are more ambitious than one person could really take on٫ the community started around xi-editor is evolving into one that can sustain GUI in Rust. I’m excited to see what we can do.</p>

<p>Discuss on <a href="https://news.ycombinator.com/item?id=23663878">Hacker News</a> and <a href="https://www.reddit.com/r/rust/comments/hgzdu5/xieditor_retrospective/">/r/rust</a>.</p>'),('https://raphlinus.github.io/rust/graphics/gpu/2020/06/13/fast-2d-rendering.html', 'Fast 2D rendering on GPU', '1592068782000',  12, '<p>Previously on my quest for fast rendering of 2D vector graphics on GPU٫ I have posted a <a href="https://raphlinus.github.io/rust/graphics/gpu/2020/06/01/piet-gpu-progress.html">piet-gpu update</a> and a deeper exploration into a <a href="https://raphlinus.github.io/rust/graphics/gpu/2020/06/12/sort-middle.html">sort-middle</a> architecture. These intermediate results showed promise٫ but fell short of my vision for truly high performance 2D GPU rendering.</p>

<p>I am now pleased to present an architecture that I believe does realize this vision. The performance is impressive٫ but more than that٫ the architecture is derived from principles and is founded on a general pipeline٫ as opposed to being a collection of hacks in the service of benchmark results. As much work as possible is offloaded to the GPU٫ which minimizes the risk of jank in UI rendering and lets us exploit the continuing performance improvements in GPU technology.</p>

<p>Further٫ this rendering pipeline is well suited both for fully dynamic and (partially) static content. It does not rely on precomputation٫ instead quickly processing the scenes into tiles for “fine rasterization” at the end of the pipeline. Even so٫ static fragments of the scene can readily be retained and stitched together٫ so that the CPU-side cost is minimized.</p>

<p>In short٫ I firmly believe that this is the architecture to beat.</p>

<p>I also want to be up-front about the limitations of the work. First٫ the imaging model is still fairly limited٫ as I’ve been focusing on path rendering. I believe that the general nature of the pipeline makes the architecture amenable to a richer imaging model such as SVG or PDF٫ but until that’s actually implemented٫ it’s somewhat speculative. Second٫ the implementation relies heavily on GPU compute capabilities٫ so will not run on older hardware or drivers. I should also note that <a href="https://github.com/servo/pathfinder">Pathfinder</a> has a much better story on both fronts; in particular it has a “mix and match” architecture so that much work besides the fine rasterization can be done on CPU.</p>

<p>Another limitation is that complex scenes can require lots of memory. Certainly the current implementation doesn’t do anything clever to deal with this٫ it just allocates buffers which are hopefully big enough. There are ways to deal with it٫ but unfortunately it is a source of additional complexity.</p>

<p>The code is now merged to the main branch of the <a href="https://github.com/linebender/piet-gpu">piet-gpu</a> repo.</p>

<h2 id="how-it-works">How it works</h2>

<p>I’m not going to go into extreme detail here٫ rather try to provide an overview.</p>

<p><img src="/assets/sorta_block_diagram.png" alt="Block diagram of new architecture" /></p>

<p>The architecture is firmly based on the previous <a href="https://raphlinus.github.io/rust/graphics/gpu/2020/06/12/sort-middle.html">sort-middle</a> design. The major difference٫ though٫ is the handling of path segments. In the previous design٫ <em>all</em> elements٫ path segments included٫ were carried through the pipeline in sorted order to fine rasterization. Empirical evaluation showed that plumbing elements through the pipeline had a nontrivial cost.</p>

<p>Given this evidence٫ the solution became clear. Individual path segments within a path do not need to be kept sorted at all. For a fill٫ the total winding number (or exact area calculation in the case of antialiased rendering) is the sum of the contributions from each path segment. Similarly٫ for distance field rendering of strokes٫ the final distance is the minimum of that to each stroke segment. In both cases٫ the operation is associative and commutative٫ so the individual elements can be processed in any order.</p>

<p>Thus٫ the pipeline splits into two parts; a sort-middle path for filled and stroked paths (and٫ in the future٫ other graphic elements)٫ and an unsorted pipeline for path segments. To coordinate the two٫ each path is assigned an id (just a sequence number٫ really)٫ and each path segment is ascribed to its corresponding path’s id. A simple <em>tile allocation</em> kernel allocates and initializes a rectangular region of tiles for each path. Then coarse path rasterization proceeds directly from the path segments٫ drawing into the tile structures by using an <code class="language-plaintext highlighter-rouge">atomicExchange</code> to insert segments into a linked list structure.</p>

<p>Coarse rasterization in the sorted pipeline is similar to the previous sort-middle architecture٫ with some refinement. It inspects the rectangular tile region for each path٫ and marks non-empty tiles using an internal bitmap (this is a highly parallel and load-balanced operation). Then٫ each thread processes one tile٫ and outputs commands for each element that was so marked٫ in sorted order.</p>

<p>Backdrop processing is actually more straightforward than the previous version. When backdrop is needed (a path segment crossing a horizontal tile boundary)٫ there’s just a simple <code class="language-plaintext highlighter-rouge">atomicAdd</code> of +1 or -1 to the backdrop for that tile. Then٫ another kernel performs a prefix sum across a scanline of tiles٫ propagating that backdrop to the right. Tiles with nonzero backdrop but also no path segments get a “solid color” command. One of the nice things about this architecture is that there is no O(n^2) for highly complex paths٫ as there was in previous iterations.</p>

<p>To me٫ the performance is satisfying in a way not fulfilled by previous iterations٫ not only because it’s fast (it is)٫ but because it’s <em>understandable.</em> Every cost in the pipeline has a reason. You have to keep paths sorted and composite them in order٫ and there’s a cost to doing that. But only paths٫ not segments within a path٫ so the cost is a lot less. And a nice feature of the pipeline is “performance smoothness;” there aren’t workloads where the performance degrades.</p>

<h2 id="gpu-side-flattening">GPU-side flattening</h2>

<p>There are two major lines of approach in the 2D rendering literature. One is for curves to interact directly with pixels. The other is for curves to be <em>flattened</em> into polylines first. Both approaches have advantages and disadvantages. Basically٫ lines are simpler to handle٫ but there are more of them.</p>

<p>Previously٫ following Pathfinder٫ I had the flattening on the CPU. The current codebase is the first iteration that moves the flattening to GPU. It uses the fancy new flattening algorithm٫ though there is nothing particularly fancy about the implementation; though the algorithm has features that are helpful to parallel implementation٫ such as computing the exact number of subdivisions before producing any of the points٫ this was a fairly straightforward implementation٫ each thread processing one curve.</p>

<p>An <a href="https://github.com/linebender/piet-gpu/commit/7118c8efc19df2e3682fb027cee6d8b391a6082e">earlier version</a> of the code٫ before GPU flattening٫ had a highly parallel٫ load balanced implementation of “fat line rendering” of lines٫ but I didn’t retain this for the curve-flattening version. It should be possible to combine the two; the general approach would be a queue of line segments stored in shared memory٫ with curve flattening filling the queue and another stage draining it٫ doing the output to global memory. This remains as future work٫ especially as performance is pretty good as-is. The algorithm is clever٫ and I hope I get a chance to describe it in more detail.</p>

<p>Doing flattening on the GPU unlocks layer optimizations٫ even in the presence of zoom and rotation. Almost certainly٫ the most important practical consequence is font rendering — a glyph can be rendered at any size٫ actually with arbitrary affine transformation٫ without any re-encoding work on the CPU.</p>

<h2 id="performance-discussion">Performance discussion</h2>

<p>First٫ a disclaimer. Performance evaluation of GPU renderers is <em>hard.</em> There are so many variables٫ including details of drivers٫ effects of presentation and the compositor٫ pipelining because there are async stages٫ which sources of overhead to count and which can be amortized over multiple frames. Because GPUs are so fast٫ even a small CPU cost for uploading data is significant. Also٫ quality of support for timer queries varies a lot (though it’s pretty good for Vulkan). Because of all that٫ the performance numbers should be taken with a grain of salt. Even so٫ I think the measurements are good enough to demonstrate the <em>massive</em> improvements we see over rendering techniques that involve the CPU.</p>

<p>These measurements were done on a Gigabyte Aero 14 laptop with an Intel i7-7700HQ CPU٫ and both an Nvidia GTX 1060 and integrated HD 630 graphics٫ running Windows 10. The output canvas is 2048x1536 for piet-gpu and generally similar for the other renderers. The scale factor is 8x for tiger and 1.5x for paper-1 and paris-30k.</p>

<p>I compare three renderers. For piet-gpu I am counting only the rendering time٫ not encoding. I feel this is fair because it is designed to reuse encoded layers; they can be rotated٫ zoomed٫ and subjected to arbitrary affine transformations. The cost of encoding is on the same order of magnitude as rendering; for tiger it is about 200us٫ and about an order of magnitude less than parsing the SVG. Any application will <em>need</em> a way to retain layers some way or other in order to achieve good performance.</p>

<p>For <a href="https://github.com/servo/pathfinder">Pathfinder</a> I am comparing only the master branch (at <a href="https://github.com/servo/pathfinder/commit/0f3500921596bdb2924d7bd62c4f983afc9332ec">0f35009</a>). I take the maximum of CPU and GPU times٫ assuming that they are pipelined. This is generous٫ as the assumption might not be valid٫ for example if the CPU is highly loaded doing other processing for the application. I should also note that there is a <a href="https://github.com/pcwalton/pathfinder/tree/gpu-tiling-dicing">development branch</a> which moves most of the tiling to the GPU and is showing <em>extremely</em> promising performance٫ comparable to piet-gpu.</p>

<p>For <a href="https://www.cairographics.org/">Cairo</a> I am benchmarking using the <code class="language-plaintext highlighter-rouge">--perf</code> option to <a href="https://github.com/RazrFalcon/resvg">resvg</a>’s rendersvg tool. I am counting only the “rendering” and not “preprocessing” times. The latter would add about another 50% to the total time. I also tried the <a href="https://github.com/jrmuizel/raqote">raqote</a> backend and found it to be approximately 1.5x to 2x slower than Cairo.</p>

<p>I should also note that٫ unlike last time around٫ I <em>am</em> applying correct stroke style to the paris-30k example٫ by doing preprocessing beforehand. This adds somewhat to rendering time٫ and makes the comparison with other renderers more fair. I am hopeful that it is possible to apply stroke styles GPU-side٫ through a combination of distance field rendering techniques (especially good for round joins and caps) and path-to-path transformations٫ which would probably have a performance profile broadly similar to flattening.</p>

<p>And now the graphs:</p>

<p><img src="/assets/piet_gpu_comparison.png" alt="Comparison of 2D rendering" /></p>

<p>Since the amount of time taken by piet-gpu rendering is barely visible٫ let’s rescale the y axis to a maximum of 50ms:</p>

<p><img src="/assets/piet_gpu_comparison_scaled.png" alt="Comparison of 2D rendering٫ scaled" /></p>

<p>I find these really exciting results. Moving rendering to GPU means that interactive frame rates are possible even with very complex documents٫ and even on Intel 630 the paper-1 example (dense vector text) runs in 7.6ms٫ meaning 60fps is possible with plenty of room to spare. (More detailed measurements are in a <a href="https://docs.google.com/spreadsheets/d/1L4GOqo07wKpBZIRAq98bbIF0oZNEmrmZVuDqHpuGGng/edit?usp=sharing">spreadsheet</a>٫ but as a general rule of thumb٫ the Intel HD 630 is about 5x slower than the GTX 1060). I am unaware of any published renderer with comparable performance٫ though I believe <a href="http://kunzhou.net/zjugaps/pathrendering/">Li et al</a> comes close٫ and it is entirely possible that <a href="https://fuchsia.googlesource.com/fuchsia/+/refs/heads/master/src/graphics/lib/compute/spinel/">Spinel</a> is faster; it is just very difficult to evaluate.</p>

<p>Unfortunately٫ a lot of software we use today is stuck on CPU rendering٫ which has performance nowhere near what is possible on GPU. We should do better.</p>

<h3 id="comparison-with-previous-post">Comparison with previous post</h3>

<p>I’m not going to go into a lot of detail comparing the current codebase with the previous post. I saw the fraction of time going into coarse rasterization go down٫ but then as I made changes to add GPU-side flattening٫ the time went up. Of course٫ the overall performance is dramatically better because it is now capable of transformable vector layers٫ and previously that would have required re-flattening on the CPU. In addition٫ I am aware of a number of opportunities for optimization٫ so I am quite confident I could bring the numbers still lower. But this obsessive optimization takes a huge amount of time and effort٫ and at some point I question how valuable it is; I believe the current codebase stands in proving the ideas viable.</p>

<h2 id="discussion-and-prospects">Discussion and prospects</h2>

<p>I believe I have demonstrated convincingly that moving almost all of the 2D rendering task to the GPU is viable and yields excellent performance. Further٫ the ideas are general٫ and should adapt well to a range of graphics primitives and fine rendering techniques. I believe it would hold up well as an academic paper٫ and would like to find the time to write it up as such.</p>

<p>Having got this far٫ I’m not sure how much farther I want to take the piet-gpu codebase. I think an ideal outcome would be to have the ideas folded into existing open-source renderers like Pathfinder٫ and am encouraged by progress on that front. Even so٫ I believe there is some benefit to exploring a GPU-centric approach to layers.</p>

<p>All of this work has been on my own time. In accordance with my <a href="https://raphlinus.github.io/curves/2019/05/10/spline-licensing-update.html">licensing policies</a>٫ everything is published under a permissive open source license٫ and with no patent protection٫ unlike other libraries such as <a href="https://sluglibrary.com/">Slug</a>. Going forward٫ my time is pretty well spoken for٫ as I’m going to be working on <a href="https://github.com/linebender/runebender">Runebender</a> and <a href="https://github.com/xi-editor/druid">druid</a> full-time with generous financial support from Google Fonts. But I encourage people writing new 2D rendering engines to consider the techniques I’ve explored٫ and might be open to consulting arrangements.</p>

<p>People who are interested in more details (as this post is something of a high level overview) may want to read the <a href="https://docs.google.com/document/d/1HNf5PDLz-uzNRIEDLt787J9GHYKKPb511JU6so3OadU/edit?usp=sharing">design document</a> I wrote after implementing the previous sort-middle architecture and before starting coding on this. And there’s a <em>ton</em> of quite detailed discussion on the <a href="https://xi.zulipchat.com/#narrow/stream/197075-gpu">#gpu stream</a> on the xi zulip (signup required٫ open to anyone with a Github account).</p>

<p>I’ve learned a lot from this٫ and hope others do too. And I hope we can collectively get to a world where jank in GUI and other 2D rendering applications is unusual٫ rather than the norm. The hardware can certainly support it٫ it’s just a question of building the engine and integrating it into applications.</p>

<p>Many thanks to Patrick Walton for stimulating discussions which have helped clarify design questions.</p>'),('https://raphlinus.github.io/rust/graphics/gpu/2020/06/12/sort-middle.html', 'A sort-middle architecture for 2D graphics', '1591920462000',  12, '<p>In my recent <a href="https://raphlinus.github.io/rust/graphics/gpu/2020/06/01/piet-gpu-progress.html">piet-gpu update</a>٫ I wrote that I was not satisfied with performance and teased a new approach. I’m on a quest to systematically figure out how to get top-notch performance٫ and this is a report of one station I’m passing through.</p>

<p>To recap٫ piet-gpu is a new high performance 2D rendering engine٫ currently a research protoype. While most 2D renderers fit the vector primitives into a GPU’s rasterization pipeline٫ the brief for piet-gpu is to fully explore what’s possible using the compute capabilities of modern GPUs. In short٫ it’s a software renderer that is written to run efficiently on a highly parallel computer. Software rendering has been gaining more attention even for complex 3D scenes٫ as the traditional triangle-centric pipeline is less and less of a fit for high-end rendering. As a striking example٫ the new <a href="https://www.eurogamer.net/articles/digitalfoundry-2020-unreal-engine-5-playstation-5-tech-demo-analysis">Unreal 5</a> engine relies heavily on compute shaders for software rasterization.</p>

<p>The new architecture for piet-gpu draws heavily from the 2011 paper <a href="https://research.nvidia.com/publication/high-performance-software-rasterization-gpus">High-Performance Software Rasterization on GPUs</a> by Laine and Karras. That paper describes an all-compute rendering pipeline for the traditional 3D triangle workload. The architecture calls for sorting in the middle of the pipeline٫ so that in the early stage of the pipeline٫ triangles can be processed in arbitrary order to maximally exploit parallelism٫ but the output render still correctly applies the triangles in order. In 3D rendering٫ you can <em>almost</em> get away with unsorted rendering٫ relying on Z-buffering to decide a winning fragment٫ but that would result in “Z-fighting” artifacts and also cause problems for semitransparent fragments.</p>

<p>The original piet-metal architecture tried to avoid an explicit sorting step by traversing the scene graph from the root٫ each time. The simplicity is appealing٫ but it also required redundant work and limited the parallelism that could be exploited. The new architecture adopts a similar pipeline structure as the Laine and Karras paper٫ but with 2D graphics “elements” in place of triangles.</p>

<p>Central to the new piet-gpu architecture٫ the scene is represented as a contiguous sequence of these elements٫ each of which has a fixed-size representation. The current elements are “concatenate affine transform”٫ “set line width”٫ “line segment for stroke”٫ “stroke previous line segments”٫ “line segment for fill”٫ and “fill previous line segments”٫ with of course many more elements planned as the capability of the renderer grows.</p>

<p>While triangles are more or less independent of each other aside from the order of blending the rasterized fragments٫ these 2D graphics elements are a different beast: they affect graphics <em>state٫</em> which is traditionally the enemy of parallelism. Filled outlines present another challenge: the effects are non-local٫ as the interior of a filled shape depends on the winding number as influenced by segments of the outline that may be very far away. It is not obvious how a pipeline designed for more or less independent triangles can be adapted to such a stateful model. This post will explain how it’s done.</p>

<h2 id="scan">Scan</h2>

<p>In general٫ a sequence of operations٫ each of which manipulates state in some way٫ must be evaluated sequentially. An extreme example is a cryptographic hash such as SHA-256. A parallel approach to evaluating such a function would upend our understanding of computation.</p>

<p>However٫ in certain cases parallel evaluation is quite practical٫ in particular when the change to state can be modeled as an associative operation. The simplest nontrivial example is counting; just divide up the input into <em>partitions٫</em> count each partition٫ then sum those.</p>

<p>Can we design an associative operation to model the state changes made by the elements of our scene representation? Almost٫ and as we’ll see٫ it’s close enough.</p>

<p>At this stage in the pipeline٫ there are three components to our state: the stroke width٫ the current affine transform٫ and the bounding box. Written as sequential pseudocode٫ our desired state manipulation looks like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input an element.
If the previous element was "fill" or "stroke"٫ reset the bounding box.
If the element is:
    "set line width"٫ set the line width to that value.
    "concatenate transform"٫ set the transform to the current transform times that.
    "line segment for fill٫" compute bounding box٫ and accumulate.
    "line segment for stroke٫" compute bounding box٫ expand by line width٫ and accumulate.
    "fill"٫ output accumulated bounding box
    "stroke"٫ output accumulated bounding box
</code></pre></div></div>

<p>Note that most graphics APIs have a “save” operation that pushes a state onto a stack٫ and “restore” to pop it. Because we desire our state to be fixed-size٫ we’ll avoid those. Instead٫ to simulate a “restore” operation٫ if the transform was changed since the previous “save٫” the CPU encodes the inverse transform (this requires that transforms be non-degenerate٫ but this seems like a reasonable restriction).</p>

<p>As the result of such processing٫ each element in the input is annotated with a bounding box٫ which will be used in later pipeline stages for binning. The bounding box of a line segment is just that segment (expanded by line width in the case of strokes)٫ but for a stroke or fill it is the union of the segments preceding it.</p>

<p>Given the relatively simple nature of the state modifications٫ we can design an “almost monoid” with an almost associative binary operator. I won’t give the whole structure here (it’s in the code as [<code class="language-plaintext highlighter-rouge">element.comp</code>])٫ but will sketch the highlights.</p>

<p>When modeling such state manipulations٫ it helps to think of the state changes performed by some contiguous slice of the input٫ then the combination of the effects of two contiguous slices. For example٫ either or both slices can set the line width. If the second slice does٫ then at the end the line width is that value٫ no matter what the first slice did. If it doesn’t٫ then the overall effect is the same as the first slice.</p>

<p>The effect on the transform is even simpler٫ it’s just multiplication of the affine transforms٫ already well known to be associative (but not commutative).</p>

<p>Where things get slightly trickier is the accumulation of the bounding boxes. The union of bounding boxes is an associative (and commutative) operator٫ but we also need a couple of flags to track whether the bounding box is reset. However٫ in general٫ affine transformations and bounding boxes don’t distribute perfectly; the bounding box resulting from that affine transformation of a bounding box might be larger than the bounding box of transforming the individual elements.</p>

<p><img src="/assets/bbox_no_commute.svg" alt="Bounding box does not commute with rotation" /></p>

<p>For our purposes٫ it’s ok for the bounding box to be conservative٫ as it’s used only for binning. If we restricted transforms to axis-aligned٫ or if we used a convex hull rather than bounding rectangle٫ then transforms would distribute perfectly and we’d have a true monoid. But close enough.</p>

<p>When I wrote my <a href="https://raphlinus.github.io/gpu/2020/04/30/prefix-sum.html">prefix sum</a> blog post٫ I had some idea it might be useful in 2D٫ but did not know at that time how central it would be. Happily٫ that implementation could be adapted to handle the transform and bounding box calculation with only minor changes٫ and it’s lightning fast٫ as we’ll see below in the performance discussion.</p>

<p>Note that the previous version of piet-gpu (and piet-metal before it) required the CPU to compute the bounding box for each “item.” Part of the theme of the new work is to offload as much as possible to the GPU٫ including bounding box</p>

<h2 id="binning">Binning</h2>

<p>While element processing is totally different than triangle processing in the Laine and Karras paper٫ binning is basically the same. The purpose of binning is fairly straightforward: divide the render target surface area into “bins” (256x256 pixels in this implementation)٫ and for each bin output a list of elements that touch the bin٫ based on the bounding boxes as determined above.</p>

<p>If you look at the code٫ you’ll see a bunch of concern about <code class="language-plaintext highlighter-rouge">right_edge</code>٫ which is in service of the backdrop calculation٫ which we’ll cover in more detail below.</p>

<p>The binning stage is generally similar to cudaraster٫ though I did refine it. Where cudaraster launches a fixed number of workgroups (designed to match the number of Streaming Multiprocessors in the hardware) and outputs a linked list of segments٫ one per workgroup and partition٫ I found that this created a significant overhead in the subsequent merge step. Thus٫ my design outputs a contiguous segment per <em>bin</em> and partition٫ which allows for more parallel reading in the merge step٫ though it has a small overhead of potentially outputting empty segments (I suspect this is the reason Laine and Karras did not pursue the approach). In both cases٫ the workgroups do not need to synchronize with each other٫ and the elements <em>within</em> an output segment are kept sorted٫ which reduces the burden in the subsequent merge step.</p>

<p>The binning stage is also quite fast٫ not contributing significantly to the total render time.</p>

<p>Why such large bins٫ or٫ in other words٫ so few of them? If binning is so fast٫ it might be appealing to bin all the way down to individual tiles. But the design calls for one bin per thread٫ so that would exceed the size of a workgroup (workgroup size is generally bounded around 1024 threads٫ and very large workgroups can have other performance issues). Of course٫ it may well still be possible to improve performance by tuning such factors; in general I used round numbers.</p>

<h2 id="coarse-rasterization">Coarse rasterization</h2>

<p>This pipeline stage was by far the most challenging to implement٫ both because of the grueling performance requirements and because of how much logic it needed to incorporate.</p>

<p>The core of the coarse rasterizer is very similar to cudaraster. Internally it works in stages٫ each cycle consuming 256 elements from the bin until all elements in the bin have been processed.</p>

<ul>
  <li>
    <p>The first stage merges the bin outputs٫ restoring the elements to sorted order. This stage repeatedly reads chunks generated in the binning stage until 256 elements are read (or the end of the input is reached).</p>
  </li>
  <li>
    <p>Next is the input stage٫ with each thread reading one element. It also compute the coverage of that element٫ effectively painting a 16x16 bitmap. There’s special handling of backdrops as well٫ see below.</p>
  </li>
  <li>
    <p>The total number of line segments is counted٫ and space in the output is allocated using an atomic add.</p>
  </li>
  <li>
    <p>As in cudaraster٫ segments are output in a highly parallel scheme٫ with all output segments evenly divided between threads٫ so each thread has to do a small stage to find its work item.</p>
  </li>
  <li>
    <p>The commands for a tile are then written sequentially٫ one tile per thread. This lets us keep track of per-tile state٫ and there tend to be many fewer commands than segments.</p>
  </li>
</ul>

<p>This is called “coarse rasterization” because it is sensitive to the geometry of path segments. In particular٫ coverage of tiles by line segments is done with a “fat line rasterization” algorithm:</p>

<p><img src="/assets/fat_line_rasterization.svg" alt="Diagram of fat line rasterization" /></p>

<h3 id="backdrop">Backdrop</h3>

<p>A special feature of coarse rasterization for 2D vector graphics is the filling of the interior of shapes. The general approach is similar to <a href="http://hhoppe.com/ravg.pdf">RAVG</a>; when an edge crosses the top edge of a tile٫ a “backdrop” is propagated to all tiles to the right٫ up to the right edge of the fill’s bounding box.</p>

<p>While conceptually fairly straightforward٫ the code to implement this efficiently covers a number of stages in the pipeline. For one٫ the right edge of fills must be propagated back to segments within the fill٫ even in early stages such as binning.</p>

<ul>
  <li>
    <p>The first right edge of each partition is recorded in the aggregate for each partition in element processing.</p>
  </li>
  <li>
    <p>The right edge is computed for each segment in binning٫ and recorded in the binning output. This logic also adds segments to the bin٫ when they cross the top edge of a tile.</p>
  </li>
  <li>
    <p>In the input stage of coarse rasterization٫ segments that cross the top edge of a tile “draw” 1’s into the bitmap for all tiles to the right٫ again up to the right edge of the fill. The sign of the crossing is also noted in a separate bitmap٫ but that doesn’t need to be both per-element and per-tile٫ as it is consistent for all tiles.</p>
  </li>
  <li>
    <p>In the output stage of coarse rasterization٫ bit counting operations are used to sum up the backdrop. Then٫ if there are any path segments in the tile٫ the backdrop is recorded in the path command. Otherwise٫ if the backdrop is nonzero٫ a solid color command is output.</p>
  </li>
</ul>

<p>Basically٫ the correct winding number is a combination of three rules. Within a tile٫ a line segment causes a +1 winding number change in the region to the right of the line (sign flipped when direction is flipped). If the line crosses a vertical tile edge٫ an additional -1 is added to the half-tile below the crossing point. And if the line crosses a horizontal tile edge٫ +1 is added to all tiles to the right; this is known as “backdrop” and is how tiles completely on the interior of a shape can get filled. Almost as if by magic٫ the combination of these three rules results in the correct winding number٫ the tile boundaries erased. Another presentation of this idea is given in the <a href="http://hhoppe.com/ravg.pdf">RAVG</a> paper.</p>

<p><img src="/assets/fill_rule.svg" alt="Diagram of fat line rasterization" /></p>

<h2 id="fine-rasterization">Fine rasterization</h2>

<p>The fine rasterization stage was almost untouched from the previous piet-gpu iteration. I was very happy with the performance of that; the problem we’re trying to solve is efficient preparation of tiles for coarse rasterization.</p>

<h2 id="encoding-and-layers">Encoding and layers</h2>

<p>The original dream for piet-gpu (and piet-metal) is that the encoding process is as light as possible٫ that the CPU really just uploads a representation of the scene٫ and the GPU processes it into a rendered texture. The new design moves even closer to this dream; in the original٫ the CPU was responsible for computing bounding boxes٫ but now the GPU takes care of that.</p>

<p>Even more exciting٫ the string-like representation opens up a simpler approach to layers than the original piet-metal architecture: just retain the byte representation٫ and assemble them. In the simplest implementation٫ this is just memcpy CPU-side before uploading the scene buffer٫ but the full range of techniques for noncontiguous string representation is available. Previously٫ the idea was that the scene would be stored as a graph٫ requiring tricky memory management.</p>

<p>An important special case is font rendering. The outline for a glyph can be encoded once to a byte sequence (generally on the order of a few hundred bytes)٫ then a string of text can be assembled by interleaving these retained encodings with transform commands. In a longer term evolution٫ even this reference resolution might want to move to GPU as well٫ especially to enable texture caching٫ but this simpler approach should be viable as well.</p>

<p>Note that at the current code checkpoint٫ this vision is not fully realized٫ as flattening is still CPU-side. Thus٫ a retained subgraph (particularly a font glyph) cannot be reused across a wide range of zooms. But I am confident this can be done.</p>

<h2 id="what-was-wrong-with-the-original-design">What was wrong with the original design?</h2>

<p>The original design worked pretty well for some workloads٫ but overall had disappointing (to me) performance. Now is a good time to go into some more detail.</p>

<p>To recap٫ the original design was a series of four kernels: graph traversal (and binning to 512x32 “tilegroups”)٫ what I would now call coarse rasterization of path segments٫ generation of per-tile command lists (which is the rest of coarse rasterization)٫ and fine rasterization. The main difference is the scene representation; otherwise the stages overlap a fair amount. In the older design٫ the CPU was responsible for encoding the graph structure٫ both path segments within a fill/stroke path٫ and also the ability to group items together.</p>

<p>Overall٫ the older design was efficient when the number of children of a node was neither large nor small. But outside that happy medium٫ performance would degrade٫ and we’ll examine why. Each of the first three kernels has a potential performance problem.</p>

<p>Starting at kernel 1 (graph traversal)٫ the fundamental problem is that each workgroup of this kernel (responsible for a 512x512 region) did its own traversal of the input graph. For a 2048x1536 target٫ this means 12 workgroups. Actually٫ that highlights another problem; this phase can become starved for parallelism٫ a bigger relative problem on discrete graphics than integrated. Thus٫ the cost of reading the input scene is multiplied by 12. In some cases٫ that is not in fact a serious problem; if these nodes have a lot of children (for example٫ are paths with a lot of path segments each)٫ only the parent node is touched. Even better٫ if nodes are grouped with good spatial locality (which is likely realistic for UI workloads)٫ culling by bounding box can eliminate much of the duplicate work. But for the specific case of lots of small objects (as might happen in a scatterplot visualization٫ for example)٫ the work factor is not good.</p>

<p>The second kernel has different problems depending on whether the number of children is small or large. In the former case٫ since each thread in a workgroup reads one child٫ there is poor utilization because there isn’t enough work to keep the threads busy (I had a “fancy k2” branch which tried to pack multiple nodes together٫ but because of higher divergence it was a regression). In the latter case٫ the problem is that each workgroup (responsible for a 512x32 tilegroup) has to read <em>all</em> the path segments in each path intersecting that tilegroup. So for a large complex path which touches many tilegroups٫ there’s a lot of duplicated work reading path segments which are then discarded. On top of that٫ utilization was poor because of difficulty doing load balancing; the complexity of tiles varies widely٫ so some threads would sit idle waiting for the others in the tilegroup to complete.</p>

<p>The third kernel also took a significant amount of time٫ generally about the same as fine rasterization. Again one of the biggest problems is poor utilization٫ in this case because all threads consider all items that intersect the tilegroup. In the common case where an item only touches a small fraction of the tiles within the tilegroup٫ lots of wasted work.</p>

<p>The new design avoids many of these problems٫ increasing parallelism dramatically in early stages٫ and employing more parallel٫ load balanced stages in the middle. However٫ it is more complex and generally more heavyweight. So for workloads that avoid the performance pitfalls outlined above٫ the older design can still beat it.</p>

<h2 id="performance-evaluation">Performance evaluation</h2>

<p>Compared to the previous version٫ performance is mixed. It is encouraging in some ways٫ but not across the board٫ and one test is in fact a regression. Let’s look at GTX 1060 first:</p>

<p><img src="/assets/piet-gpu-1060.png" alt="performance charts on GTX 1060" /></p>

<p>Here the timing is given in pairs٫ old design on the left٫ sort-middle on the right. These results <em>are</em> encouraging٫ including a very appealing speedup on the paris-30k test. (Again٫ I should point out that this test is not a fully accurate render٫ as stroke styles are not applied. However٫ as a test of the old architecture vs the new٫ it is a fair test).</p>

<p>Do these results hold up on Intel?</p>

<p><img src="/assets/piet-gpu-630.png" alt="performance charts on Intel 630" /></p>

<p>In short٫ no. There is much less speedup٫ and indeed for the paris-30k example٫ it has regressed. It is one of the difficult aspects of writing GPU code that different GPUs have different performance characteristics٫ in some cases quite significant. I haven’t deeply analyzed the performance (I find it quite difficult to do so٫ and often wish for better tools)٫ but suspect it might have something to do with the relatively slow performance of threadgroup shared memory on Intel.</p>

<p>In all cases٫ the cost of coarse rasterization is significant٫ while element processing and binning are quite speedy.</p>

<h2 id="discussion">Discussion</h2>

<p>Performance is generally somewhat improved over the previous version of piet-gpu٫ but not as much as I was hoping. Why?</p>

<p>My analysis is that it’s a solid implementation of the concept٫ but that there is a nontrivial cost to carrying an element through the pipeline fully in fully sorted order. One observation is that segments within a path need not be sorted at all٫ simply ascribed to the correct (path٫ tile position) tuple. I will be exploring that in a forthcoming blog post.</p>

<p>Another important piece is missing from the current snapshot: GPU-side flattening. Without this٫ the ability to change scale in transforms is of limited usefulness٫ as the optimum flattening is scale dependent. Thus٫ the concept of “layers٫” or of fonts being rendered fully GPU-side٫ is not yet realized. I am confident it can be implemented; in this architecture٫ the easiest place to insert it would be a scene-to-scene transform after element processing but before binning. It could keep sorted order either by doing a prefix sum for allocating output elements٫ or by atomic allocation in chunks with references to the original elements to indicate sort order.</p>

<p>But٫ these two issues aside٫ let’s take stock of where we are. We’ve taken a pipeline originally designed for 3D rendering٫ and adapted it to 2D. The pipeline itself is quite general: the core of it is just logic to pass elements in scene through to threads that work on individual tiles٫ with each thread given only the elements that touch that tile٫ and in sorted order.</p>

<p>The performance of this snapshot is not all bad news. One very appealing aspect is what I call “performance smoothness٫” which is the absence of performance cliffs. The performance of a large number of simple paths or a smaller number of highly complex paths should be about the same٫ as the cost is mostly proportional to the total number of elements in the scene. An excessive number of transforms is also not a concern; these are just handled normally in the course of element processing. In the piet-metal architecture٫ performance was good when each node in the graph had a moderate number of children٫ otherwise it would degrade. And handling a large number of simple items (as might occur in a scatterplot or other data visualization) would degrade performance because each “tilegroup” does its own traversal of the scene graph. In the current architecture٫ early stages of the pipeline touch each element once and then efficiently send it to the appropriate bins for further processing.</p>

<p>As I write٫ I am immersed in solving the performance problems named above. Stay tuned.</p>

<p>I have had the good fortune of sharing ideas and analysis with Patrick Walton of <a href="https://github.com/servo/pathfinder">Pathfinder</a> fame as I do this work٫ and I am encouraged to see impressive improvements in a compute branch of Pathfinder he is developing. Pay attention to that as well.</p>'),('https://raphlinus.github.io/rust/graphics/gpu/2020/06/01/piet-gpu-progress.html', 'piet-gpu progress report', '1591033962000',  12, '<p>This post is an update to <a href="/rust/graphics/gpu/2019/05/08/modern-2d.html">2D Graphics on Modern GPU</a>٫ just over a year ago. How time flies!</p>

<p>That post set out a vision of rendering 2D graphics on a GPU٫ using compute kernels rather than the rasterization pipeline٫ and offloading as much work as possible from the CPU to the GPU. It was also a rough research prototype٫ and I’ve spent some time trying to improve it in various ways. This blog post represents a checkpoint of that work - it’s still a research prototype٫ but improved.</p>

<p>One of the limitations of that prototype is that it was implemented in Metal٫ which was chosen for ease of development٫ but is challenging to port to other APIs. I’ve spent considerable time in the last year exploring issues around portable٫ advanced GPU programming٫ and among other things gave a talk entitled <a href="https://news.ycombinator.com/item?id=22880502">A taste of GPU compute</a>. As part of the evolution of the work٫ the new prototype is in Vulkan with the compute kernels written in GLSL.</p>

<p>This blog post represents a checkpoint of the work; the code is in <a href="https://github.com/linebender/piet-gpu/pull/15">piet-gpu#15</a>. Some aspects are very promising indeed٫ in particular the performance of “fine rasterization.” It is quite challenging to efficiently produce tiles for fine rasterization given a high-level scene representation٫ and this snapshot does not perform as well as I’d like. I am now exploring a new approach٫ and will post an <a href="https://raphlinus.github.io/rust/graphics/gpu/2020/06/12/sort-middle.html">update</a> on that soon.</p>

<p>Even so٫ there is enough progress that I think it’s worthwhile to post an update now.</p>

<h2 id="infrastructure-work">Infrastructure work</h2>

<p>The new prototype is written on top of Vulkan٫ with the compute kernels written in GLSL. In addition٫ there’s an abstraction layer٫ inspired by <a href="https://github.com/gfx-rs/gfx">gfx-hal</a>٫ which provides a path for running on other graphics APIs.</p>

<p>Why not just gfx-hal? There are basically two reasons. First٫ I wanted to be able to experiment with the newest and freshest Vulkan features٫ including all the subgroup operations٫ control over subgroup size٫ etc. Many of these features are not yet available in gfx-hal. Second٫ for this use case٫ it makes sense to compile and optimize the compute kernels at compile time٫ rather than have a runtime pipeline. The total amount of code needed to just run a compute kernel is on the order of 1000 lines of code.</p>

<p>We’re looking to WebGPU for the future٫ and hope that it will be fairly straightforward to migrate Vulkan and GLSL code to that. Essentially we’re waiting for WebGPU to become more mature.</p>

<p>One of the modules in piet-gpu is a <a href="https://github.com/linebender/piet-gpu/tree/master/piet-gpu-derive">tool</a> that generates GLSL code to read and write Rust-like structs and enums. The code ends up being a lot more readable than addressing big arrays of <code class="language-plaintext highlighter-rouge">uint</code> by hand٫ and in particular it’s easy to share data between Rust and GPU٫ especially important for the scene encoding.</p>

<h2 id="static-dynamic-and-layered-content">Static٫ dynamic٫ and layered content</h2>

<p>What kind of content is being rendered? It matters٫ more so for GPU than for CPU rendering.</p>

<p>At one extreme٫ we have fully static content٫ which might be rendered with different transforms (certainly in the case of 3D). In this case٫ it makes sense to do expensive precomputation on the content٫ optimized for random access traversal while rendering. Static content of this type often shows up in games.</p>

<p>At the other extreme٫ the 2D scene is generated from scratch every frame٫ and might share nothing with the previous frame. Precomputation just adds to the frame time٫ so the emphasis must be on getting the scene into the pipeline as quickly as possible. A good example of this type of content is scientific visualization.</p>

<p>In the middle is rendering for UI. Most frames resemble the previous frame٫ maybe with some transformations of some of the scene (for example٫ scrolling a window)٫ maybe with some animation of parameters such as alpha opacity. Of course٫ some of the time the changes might be more dynamic٫ and it’s important not to add to the latency of creating a new view and instantiating all its resources. A major approach to improving the performance in this use case is <em>layers.</em></p>

<p>Text rendering also has this mixed nature; the text itself is dynamic٫ but often it’s possible to precompute the font. Signed distance fields are a very popular approach for text rendering in games٫ but the approach has significant drawbacks٫ including RAM usage and challenges representing fine detail (as is needed for very thin font weights٫ for example).</p>

<h3 id="precomputation">Precomputation</h3>

<p>Let’s look at precomputation in more detail. Much of the literature on GPU rendering assumes that an expensive precomputation pass is practical٫ and this pass often involves very sophisticated data structures. For example٫ <a href="http://w3.impa.br/~diego/projects/GanEtAl14/">Massively-Parallel Vector Graphics</a> cites a precomputation time for the classic Ghostscript tiger image of 31.04ms٫ which destroys any hope of using the technique for fully dynamic applications. <a href="http://hhoppe.com/ravg.pdf">Random-Access Rendering of General Vector Graphics</a> is similar٫ reporting 440ms for encoding (though on less powerful hardware of the time).</p>

<p>Another concern for precomputation is the memory requirements; the sophisticated data structures٫ specialized for random access٫ often take a lot more space than the source. For example٫ RAVG cites 428k for the encoded representation٫ as opposed to 62k for the tiger’s SVG source.</p>

<p>Similar concerns apply to fonts. <a href="https://github.com/Chlumsky/msdfgen">Multi-channel signed distance fields</a> are very appealing because of the speed of rendering and ease of integration into game pipelines٫ but the total storage requirement for a set of international fonts (especially CJK) is nontrivial٫ as well as the problems with fine details.</p>

<p>The <a href="https://sluglibrary.com/">Slug</a> library is very polished solution to vector font rendering٫ and also relies on precomputation٫ computing a triangulated convex polygon enclosing the glyph shape and sorting the outlines so they can efficiently be traversed from a fragment shader. A quick test of <code class="language-plaintext highlighter-rouge">slugfont</code> on <a href="https://github.com/googlefonts/Inconsolata">Inconsolata</a> Regular generates a 486k file from a 105k input.</p>

<p>A particular interest of mine is variable fonts٫ and especially the ability to vary the parameters dynamically٫ either as an animation or <a href="http://www.pragma-ade.nl/pdftex/thesis.pdf">microtypography</a>. Such applications are not compatible with precomputation and require a more dynamic pipeline. I fully admit this is advanced٫ and if you’re just trying to ship a game (also where a few megabytes more of font data will barely be noticed among the assets)٫ it’s easiest to just not bother.</p>

<h3 id="flattening">Flattening</h3>

<p>In the current piet-gpu pipeline٫ paths٫ made from lines٫ quadratic Bézier segments٫ and cubic Bézier segments٫ are <em>flattened</em> to polylines before being encoded and uploaded to the GPU. The flattening depends on the zoom factor; too coarse generates visible artifacts٫ and too fine is wasteful further down the pipeline (though it would certainly be possible to apply an adaptive strategy where a flattening result would be retained for a range of zoom factors).</p>

<p>The flattening algorithm is very sophisticated٫ and I hope to do either a blog post or a journal paper on the full version. I blogged previously about <a href="https://raphlinus.github.io/graphics/curves/2019/12/23/flatten-quadbez.html">flattening quadratic Béziers</a>٫ but the new version has a couple of refinements: it works on cubics as well٫ and it also has improved handling of cusps. You can play with an <a href="https://levien.com/tmp/flatten.html">interactive JavaScript version</a> or look at the <a href="https://github.com/linebender/kurbo/pull/105">Rust implementation</a>.</p>

<p>The time to flatten and encode the tiger is about 1.9ms٫ making it barely suitable for dynamic use. However٫ there’s lots of room to improve. This is scalar٫ single-threaded code٫ and even CPU-side it could be optimized with SIMD and scaled to use multiple cores.</p>

<p>Even with single-threaded scalar code٫ flattening time is competitive with <a href="https://github.com/servo/pathfinder">Pathfinder</a>٫ which takes about 3ms to flatten٫ tile٫ and encode drawing commands (using multithreaded٫ SIMD optimized code٫ though further optimization is certainly possible). However٫ it is not suitable for interactive use on extremely complex scenes. For the paris-30k example٫ piet-gpu flattening and encoding takes about 68ms.</p>

<p>Ultimately٫ flattening should be moved to the GPU. The algorithm is designed so it can be evaluated in parallel (unlike recursive flattening and the <a href="https://pdfs.semanticscholar.org/8963/c06a92d6ca8868348b0930bbb800ff6e7920.pdf">Precise Flattening of Cubic Bézier Segments</a> work). Flattening on GPU is especially important for font rendering٫ as it would allow rendering at arbitrary scale without reuploading the outline data.</p>

<p>One open question for flattening is exactly where in the pipeline it should be applied. It’s possible to run it before the existing pipeline٫ during tile generation٫ or preserve at least quadratic Béziers all the way through the pipeline to the pixel rendering stage٫ as is done in much of the GPU rendering literature. Figuring out the best strategy will mean implementing and measuring a lot of different approaches.</p>

<h2 id="the-piet-gpu-architecture">The piet-gpu architecture</h2>

<p>The current piet-gpu architecture is a relatively simple pipeline of compute kernels. A general theme is that each stage in the pipeline is responsible for a larger geometric area٫ and distributes pieces of work to smaller tiles for the successive stages.</p>

<p>The first stage is on CPU and is the encoding of the scene to a buffer which will then be uploaded to the GPU. This encoding is vaguely reminiscent of flatbuffers٫ and is driven by “derive” code that automatically generates both Rust-side encoding and GLSL headers to access the data. As discussed in considerably more detail below٫ the encoding of curves also involves flattening٫ but that’s not essential to the architecture. After the encoded scene buffer is uploaded٫ successive stages run on the GPU.</p>

<p>The first compute kernel has a fairly simple job. It traverses the input scene graph and then generates a list of “instances” (references to leaf nodes in the scene graph٫ with transform) for each “tile group” (currently a 512x16 region). It uses bounding boxes (encoded along with nodes by the CPU) to cull.</p>

<p>The second compute kernel is specialized to vector paths. It takes the instances of vector stroke and fill items٫ and for each 16x16 tile generates a list of segments for that item for that tile. For fills٫ it also computes the “backdrop”٫ which is important for filling interior tiles of a large shape even when no segments cross that tile.</p>

<p>The third compute kernel is responsible for generating a per-tile command list (sometimes referred to as a “tape٫” and called a “cell stream” in the RAVG terminology). There’s generally a straightforward mapping from instances to commands٫ but this kernel can do other optimizations. For example٫ a solid opaque tile can “reset” the output stream٫ removing drawing commands that would be completely occluded by that tile.</p>

<p>The fourth compute kernel reads its per-tile command list and generates all the pixels in a 16x16 tile٫ writing them to the output image. This stage is effectively identical to the pixel shader in the RAVG paper٫ but with one small twist. Because it’s a compute kernel٫ each thread can read the input commands and generate a chunk of pixels (currently 8)٫ amortizing the nontrivial cost of reading the tape over more more than just one pixel. Of course it would be possible to run this in a fragment shader if compute were not available.</p>

<p>These kernels are relatively straightforward٫ but essentially brute-force. A common theme is that all threads in a workgroup cooperate to read the input in parallel٫ then there is a “block shuffle” approach to distribute that work to the individual threads responsible for writing out work for smaller subregions. I described an approach based on 32x32 boolean matrix transpose in my <a href="https://news.ycombinator.com/item?id=22880502">Taste of GPU Compute</a> talk٫ but in practice we find that using atomic operations to assign work is slightly faster.</p>

<h3 id="layers">Layers</h3>

<p>As mentioned above٫ in a UI most of the time٫ most of the content in the frame is the same as the last frame. Some UI frameworks (imgui in particular) just traverse the entire UI state and draw every time٫ but most do something to cut down on work done.</p>

<p>The main mechanism is some kind of <em>layer٫</em> an object that retains the appearance of a widget or subview. In Apple toolkits٫ this layer (<a href="https://developer.apple.com/documentation/quartzcore/calayer">CALayer</a> in particular) is a GPU-resident texture (image). This design made sense in the days of the iPhone 1٫ where the GPU was just barely powerful enough to composite the final surface from multiple such images at 60fps٫ but there are significant drawbacks to this approach. Applications need to avoid creating too many layers٫ as that can consume a huge amount of GPU memory. There’s also increased latency when content changes dynamically٫ as it needs to be re-rendered and re-uploaded before being composited. But the approach does work. It also leads to a certain aesthetic٫ emphasizing the animations that can be efficiently expressed (translation and alpha fading) over others that would require re-rendering.</p>

<p>Flutter has a more sophisticated approach٫ explained well in the video <a href="https://www.youtube.com/watch?v=UUfXWzp0-DU">Flutter’s Rendering Pipeline</a>. There٫ a layer can be backed by either a recorded display list (<a href="https://skia-doc.commondatastorage.googleapis.com/doxygen/doxygen/html/classSkPicture.html">SkPicture</a> under the hood) or a texture٫ with a heuristic to decide which one. My understanding is that SkPicture is implemented by recording drawing commands into a CPU-side buffer٫ then playing them back much as if they had been issued in immediate mode. Thus٫ it’s primarily a technique to reduce time spent in the scripting layer٫ rather than a speedup in the rendering pipeline per se. The Android <a href="https://developer.android.com/reference/android/graphics/RenderNode">RenderNode</a> is similar (and is used extensively in <a href="https://developer.android.com/jetpack/compose">Jetpack Compose</a>).</p>

<p>One of the design goals in piet-gpu is to move this mechanism farther down the pipeline٫ so that a fragment of the scene graph can be retained GPU-side٫ and the layer abstraction exposed to the UI is a handle to GPU-resident resources. Note that this isn’t very different than the way images are already handled in virtually every modern rendering system.</p>

<p>The layer concept is also valid for many art and design applications٫ as well as maps. It’s extremely common to organize the document or artwork into layers٫ and then modifications can be made to just one layer.</p>

<p>This mechanism is not yet wired up end-to-end٫ as it requires more work to do asynchronous resource management (including better allocation of GPU buffers)٫ but the experimental results do show that the potential savings are significant; re-encoding and re-uploading of the scene graph to the GPU is a substantial fraction of the total time٫ so avoiding it is a big gain.</p>

<p>Doing flattening GPU-side would make the layer concept even more powerful٫ as it enables zoom (and potentially other transformations) of layers without re-upload٫ also avoiding the blurring that happens when bitmap textures are scaled.</p>

<h2 id="cpu-vs-gpu">CPU vs GPU</h2>

<p>If the same work can be done on either CPU or GPU٫ then it’s sometimes a complex tradeoff which is best. The goal of piet-gpu is for GPU-side computation to be so much faster than CPU that it’s basically always a win. But sometimes optimizing is easier CPU side. Which is better٫ then٫ depends on context.</p>

<p>In a game٫ the GPU might be spending every possible GFLOP drawing a beautiful٫ detailed 3D world٫ of which the 2D layer might be a small but necessary concern. If the CPU is running a fairly lightweight load٫ then having it run most of the 2D rendering pipeline٫ just save getting the final pixels on the screen٫ might make sense.</p>

<p>Again٫ the assumptions driving piet-gpu are primarily for UI٫ where latency is the primary concern٫ and keeping work off the main UI thread is a major part of the strategy to avoid jank. Under this set of assumptions٫ offloading any work from the CPU to the GPU is a win٫ even if the GPU is not super-efficient٫ as long as the whole scene comes in under the 16ms frame budget (or 8ms٫ now that 120Hz displays are becoming more mainstream). The current piet-gpu codebase addresses this well٫ and will do so even better as flattening is also moved to GPU.</p>

<p>The relative tradeoff is also affected by the speed of the graphics card. Single threaded CPU performance is basically stuck now٫ but GPUs will get faster and faster; already we’re seeing Intel integrated GPU go from anemic to serious competitors to low-end discrete graphics cards.</p>

<h2 id="performance">Performance</h2>

<p>I’m not yet satisfied with the performance of piet-gpu٫ yet there are aspects of it which are very encouraging. In particular٫ I feel that the final stage of the pipeline (sometimes called “fine rasterization”) is very fast. Even though it’s producing a huge volume of pixels per second٫ this stage only takes about 1/4 to 1/3 of the total piet-gpu time. It’s tantalizing to imagine what performance could look like if the cost of producing tiles for fine rasterization was further reduced.</p>

<p>For performance testing٫ I’m using 3 samples from the <a href="http://w3.impa.br/~diego/projects/GanEtAl14/">Massively-Parallel Vector Graphics</a> suite. Tiger is the well-known Ghostscript tiger٫ almost a “hello world” of 2D graphics rendering٫ paper-1 is a text-heavy workload٫ and paris-30k is a highly detailed map. Note that the rendering of paris-30k is not fully correct٫ and in particular all strokes are rendered with the same style (round ends and caps and no dashing). It’s probably reasonable to budget 30% additional time to get these stroke styles right٫ as they can significantly increase the number of path segments٫ but I’m also interested in ways to optimize this further. Also keep in mind٫ these numbers are GPU time only٫ and don’t include the cost of flattening in particular (currently on CPU).</p>

<p>With that said٫ here’s a chart of the performance٫ broken down by pipeline stage. Here٫ k4 is “kernel 4”٫ or fine rasterization٫ the stage that actually produces the pixels.</p>

<p><img src="/assets//piet-gpu-performance.png" alt="piet-gpu performance comparison graphs" /></p>

<p>These measurements are done on a four-core i7-7700HQ processor; with more cores٫ the CPU time would scale down٫ and vice versa٫ as Pathfinder is very effective in exploiting multithreading.</p>

<p>At some point٫ I’d like to do a much more thorough performance comparison٫ but doing performance measurement of GPU is surprisingly difficult٫ so I want to take the time to do it properly. In the meantime٫ here are rough numbers from the current master version of Pathfinder running on GTX 1060: tiger 2.3ms (of which GPU is 0.7)٫ paper-1 7.3ms (GPU 1.1ms)٫ and paris-30k 83ms (GPU 15.5ms). On Intel 630٫ the total time is only slightly larger٫ with the GPU taking roughly the same amount of time as CPU. Also keep in mind٫ these figures <em>do</em> include flattening٫ and see below for an update about Pathfinder performance.</p>

<h2 id="prospects">Prospects</h2>

<p>I have basically felt driven as I have engaged this research٫ as I enjoy mastering the dramatically greater compute power available through GPU. But the work has been going more slowly than I would like٫ in part because the tools available for portable GPU compute are so primitive. The current state of piet-gpu is a research codebase that provides evidence for the ideas and techniques٫ but is not usable in production.</p>

<p>I would like for piet-gpu to become production-quality٫ but am not sure whether or when that will happen. Some pieces٫ especially fallbacks for when advanced GPU compute features are not available (and working around the inevitable GPU driver bugs٫ of which I have encountered at least 4 so far)٫ require a lot of code and work٫ as does the obsessive tuning and micro-optimization endemic to developing for real GPU hardware.</p>

<p>Another extremely good outcome for this work would be for it to flow into a high quality open-source rendering project. One of the best candidates for that is <a href="https://github.com/servo/pathfinder">Pathfinder</a>٫ which has been gaining momentum and has also incorporated some of my ideas. One of the appealing aspects of Pathfinder is its “mix and match” architecture٫ where some stages might be done on CPU and others on GPU٫ and the final pixel rendering can be done in either the rasterization or compute pipeline٫ the choice made based on compatibility and observed performance. In fact٫ since the first draft of this blog post٫ I’ve been working closely with Patrick٫ sharing ideas back and forth٫ and there is now a compute branch of Pathfinder with some encouraging performance numbers. You’ll hear more about that soon.</p>

<p>Thanks to Brian Merchant for work on various parts of piet-gpu٫ msiglreith for help with Vulkan٫ and Patrick Walton for many conversations about the best way to render 2D graphics.</p>

<p>There was some <a href="https://www.reddit.com/r/rust/comments/gv1b95/pietgpu_progress_report/">discussion on /r/rust</a>.</p>'),('https://raphlinus.github.io/gpu/2020/04/30/prefix-sum.html', 'Prefix sum on Vulkan', '1588263402000',  12, '<p><strong>Update 2020-05-22:</strong> A new section on <a href="#forward-progress">forward progress</a> has been added٫ and the discussion of synchronized shuffles has been improved.</p>

<p>Today٫ there are two main ways to run compute workloads on GPU. One is CUDA٫ which has a fantastic ecosystem including highly tuned libraries٫ but is (in practice) tied to Nvidia hardware. The other is graphics APIs used primarily for gaming٫ which run on a wide variety of hardware٫ but historically offer much less power than CUDA. Also٫ the tooling for compute in that space is terrible. Historically٫ a lot of compute has also been done with OpenCL٫ but its future is cloudy as it’s been officially deprecated by Apple٫ and GPU vendors are not consistently keeping their OpenCL implementations up to date.</p>

<p>Vulkan has been catching up fast in its raw capabilities٫ with recent extensions supporting more advanced GPU compute features such as subgroups٫ pointers٫ and a memory model. Is it getting to the point where it can run serious compute workloads?</p>

<p>In this blog post are some initial explorations into implementing <a href="https://en.wikipedia.org/wiki/Prefix_sum">prefix sum</a> on recent Vulkan. I have a rough first draft implementation which suggests that Vulkan might be a viable platform٫ for a sufficiently persistent implementor.</p>

<h2 id="why-prefix-sum">Why prefix sum?</h2>

<p>As Hacker News user fluffything points out in <a href="https://news.ycombinator.com/item?id=22902274">this HN thread</a> on my <a href="https://news.ycombinator.com/item?id=22880502">Taste of GPU compute</a> talk٫ prefix sum is an excellent benchmark for evaluating GPU compute languages and runtimes.</p>

<p>For one٫ it is useful in and of itself. I use it in <a href="https://github.com/raphlinus/font-rs">font-rs</a> to integrate fragments of exact-area computations to arrive at the total area coverage for font rendering. It is also used as a primitive in many more operations٫ including GPU-side dynamic allocation and <a href="http://www.davidespataro.it/cuda-stream-compaction-efficient-implementation/">compaction</a>.</p>

<p>For two٫ it is simple. The sequential version can be expressed in just a handful of lines of code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">prefix_sum</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">a</span><span class="p">:</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">x</span>
        <span class="n">result</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></div>

<p>For three٫ it is challenging but possible to implement efficiently on GPU. The above code has a strictly sequential dependency٫ but because addition is associative٫ it is possible to exploit a great deal of parallelism٫ and there is literature on that going back decades. Even so٫ efficiently exploiting that parallelism on GPU requires communication between invocations (“threads” in more common GPU lingo) and careful attention to the memory hierarchy.</p>

<p>The generalization of prefix sum is called “scan٫” and works with any associative operation٫ not just addition. It doesn’t even have to be commutative; examples of that include <a href="http://blog.sigfpe.com/2009/01/fast-incremental-regular-expression.html">regular expressions</a> and <a href="https://raphlinus.github.io/audio/2019/02/14/parallel-iir.html">IIR filtering</a>. More precisely٫ a scan can be done with any <a href="https://en.wikipedia.org/wiki/Monoid">monoid</a>٫ a structure with an identity element as well as the associative operation; the identity element is required for the “exclusive” variant of scan٫ as it is the first element of the output.</p>

<h2 id="implementation-on-gpu">Implementation on GPU</h2>

<p>The state of the art is <a href="https://research.nvidia.com/publication/single-pass-parallel-prefix-scan-decoupled-look-back">decoupled look-back</a>. I’m not going to try to summarize the algorithm here٫ but recommend reading the paper. The results are impressive — for large data sets٫ they report reaching memcpy speeds٫ meaning that no further speedup is possible.</p>

<p>That work is a refinement of <a href="https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda">Parallel Prefix Sum (Scan) with CUDA</a> from Nvidia’s GPU Gems 3 book. A production-quality٫ open source implementation is <a href="https://nvlabs.github.io/cub/">CUB</a>. Another implementation٫ designed to be more accessible but not as optimized٫ is <a href="https://moderngpu.github.io/scan.html">ModernGPU scan</a>.</p>

<p>My own <a href="https://github.com/linebender/piet-gpu/blob/prefix/piet-gpu-hal/examples/shader/prefix.comp">implementation</a> is very much a research-quality proof of concept. It exists as the <a href="https://github.com/linebender/piet-gpu/tree/prefix">prefix</a> branch of the <a href="https://github.com/linebender/piet-gpu">piet-gpu</a> repository. Basically٫ I wanted to determine whether it was possible to come within a stone’s throw of memcpy performance using Vulkan compute kernels. It’s a fairly straightforward implementation of the decoupled look-back paper٫ and doesn’t implement all the tricks. For example٫ the look-back is entirely sequential; I didn’t parallelize the look-back as suggested in section 4.4 of the paper. This is probably the easiest performance win to be gotten. But it’s not too horrible٫ as the partition size is quite big; each workgroup processes 16ki elements. Rough measurements indicate that look-back is on the order of 10-15% of the total time.</p>

<p>The implementation is enough of a rough prototype I don’t yet want to do careful performance evaluation٫ but initial results are encouraging: it takes 2.05ms of GPU time to compute the prefix sum of 64Mi 32-bit unsigned integers on a GTX 1080٫ a rate of 31.2 billion elements/second. Since each element involves reading and writing 4 bytes٫ that corresponds to a raw memory bandwidth of around 262GiB/s. The theoretical memory bandwidth is listed as 320GB/s٫ so clearly the code is able consume a large fraction of available memory bandwidth.</p>

<h3 id="do-we-need-a-memory-model">Do we need a memory model?</h3>

<p>One of the achievements of “modern C++” is the C++11 memory model. In the olden days٫ the mechanism for lock-free programming patterns in C and C++ was the <code class="language-plaintext highlighter-rouge">volatile</code> qualifier and various nonstandard barrier intrinsics. People reasoned about these operationally — the primary function of <code class="language-plaintext highlighter-rouge">volatile</code> was to disable certain optimizations٫ and the barrier intrinsics compile to a memory fence instruction٫ which generally cause hardware to flush caches.</p>

<p>Today٫ most lock-free aficionados consider those times to be barbaric. The semantics of <code class="language-plaintext highlighter-rouge">volatile</code> were never clearly defined for the purpose of multithreading (though people used it anyway٫ because it appeared to be useful)٫ and the barrier instructions had the disturbing property of being hardware specific. Because x86 has “total store order٫” barrier instructions are generally not needed for <a href="https://bartoszmilewski.com/2008/08/04/multicores-and-publication-safety/">publication safety</a>. However٫ the same code on٫ say٫ ARM٫ which has more weakly ordered memory semantics٫ would fail٫ often in subtle ways.</p>

<p>With the C++11 memory model٫ the programmer specifies the needed ordering constraints precisely. The compiler can then optimize the program very aggressively٫ as long as it meets those constraints. For example٫ acquire and release semantics (the basis of publication safety) will compile to explicit memory fence instructions on ARM٫ but to nothing on x86. A good writeup is the blog post <a href="https://bartoszmilewski.com/2008/12/01/c-atomics-and-memory-ordering/">C++ atomics and memory ordering</a>.</p>

<p>The new <a href="https://www.khronos.org/blog/comparing-the-vulkan-spir-v-memory-model-to-cs">Vulkan memory model</a> brings the same idea to GPU compute. I used it in my code٫ in large part because I wanted to experiment with it. I’ve done a fair amount of lock-free code using the C++ memory model. And lock-free code٫ while fairly rare on the CPU (my main motivation is to avoid priority inversion for real time audio)٫ is more or less required on the GPU٫ because mutex is not available in kernel code. Even if it were٫ it would create a lot of problems٫ as it would block the entire subgroup٫ not just a single thread (one of the features of the Vulkan memory model is a much weaker forward progress guarantee than threads running on CPU).</p>

<p>Is a memory model absolutely required to run this code? If you replace the atomic loads and stores with simple array accesses٫ it deadlocks. However٫ at least on my hardware٫ correct operation can be recovered by adding the <code class="language-plaintext highlighter-rouge">volatile</code> qualifier to the <code class="language-plaintext highlighter-rouge">WorkBuf</code> array. As with older style C++٫ there are two risks. Though it seems to work reliably and efficiently on my hardware٫ it’s possible the <code class="language-plaintext highlighter-rouge">volatile</code> qualifier and explicit fences cause more cache flushing than is needed٫ or suppress other optimizations that might be possible with a more precise expression of the memory semantics. Alternatively٫ other hardware or drivers might optimize even more aggressively and break the code.</p>

<p>We’re already seeing variation in hardware that requires different levels of vigilance for memory semantics. On most GPU hardware٫ the invocations (threads) within a subgroup (warp) execute in lock-step٫ and thus don’t require any synchronization. However٫ as of Nvidia Volta٫ the hardware is capable of <a href="https://docs.nvidia.com/cuda/volta-tuning-guide/index.html#sm-independent-thread-scheduling">independent thread scheduling</a>. Correct code will add explicit memory semantics even within a subgroup٫ which will٫ as in total store order on x86٫ compile to nothing on hardware that runs invocations in lock-step٫ while code which just assumes lock-step execution of subgroups will start failing as Vulkan implementations on newer GPUs start scheduling invocations on a more fine grained basis٫ just as code that assumed total store order failed on CPUs with more relaxed memory consistency٫ such as ARM.</p>

<p>Note that Vulkan with independent thread scheduling is still work in progress. Shuffles (and related subgroup operations) must synchronize so that all active threads can participate. CUDA 9 solves this problem by introducing new intrinsics such as <code class="language-plaintext highlighter-rouge">__shfl_sync</code>٫ which take an additional argument identifying which threads are active. The Vulkan subgroup operations aren’t defined this way٫ and instead implicitly operate on active threads (invocations). Supporting this functionality correctly stresses current compiler technology٫ including preventing illegal code motion of shuffle intrinsics٫ and there are threads on the LLVM mailing list discussing this in some detail.</p>

<p>In my research for this blog post٫ I did not come across any evidence of people actually using the Vulkan memory model٫ i.e. no search hits for the relevant identifiers other than work associated with the spec. Thus٫ one contribution of this blog post is to show a concrete example of code that uses it.</p>

<h3 id="forward-progress">Forward progress</h3>

<p>The prototype code has one important flaw٫ though it appears to run fine on my hardware: it depends on other workgroups making forward progress while it’s waiting for the aggregate to be published. The Vulkan spec is careful to make only a <a href="https://www.khronos.org/blog/comparing-the-vulkan-spir-v-memory-model-to-cs#_limited_forward_progress_guarantees">limited forward progress guarantee</a>٫ and this is not strong enough to reliably run the prefix sum algorithm as written. Thus٫ there’s a risk the program will hang while one workgroup is waiting on an aggregate٫ and the workgroup that is responsible for computing it is never scheduled because the forward progress guarantee is not strong enough.</p>

<p>Forward progress is a complex problem٫ and still in flux. A very good summary of the issue is the paper <a href="https://www.cs.princeton.edu/~ts20/files/concur2018.pdf">GPU schedulers: how fair is fair enough?</a>٫ which describes the needed forward progress guarantee as “occupancy-bound.” An earlier paper from the same group٫ <a href="https://johnwickerson.github.io/papers/forwardprogress_concur2017.pdf">Forward Progress on GPU Concurrency</a>٫ might be a more accessible presentation of the core ideas. In their experiments٫ all GPUs they tested meet this guarantee٫ so it sounds like a good property to standardize. Apple mobile GPUs٫ however٫ do not provide this guarantee٫ though it might take a great deal of testing to uncover a counterexample. As that paper describes٫ many (but probably not all) other GPUs likely meet the “occupancy-bound” guarantee٫ so my prefix sum code will run correctly٫ but I’m not aware of any Vulkan implementations that actually document such a guarantee.</p>

<p>Meanwhile٫ other devices provide even stronger guarantees. CUDA 9 on Volta and above provides the much stronger <a href="https://en.cppreference.com/w/cpp/language/memory_model#Parallel_forward_progress">parallel forward progress</a> guarantee as standardized in C++٫ and they are able to do this because of independent thread scheduling (see the relevant section of <a href="https://devblogs.nvidia.com/inside-volta/">Inside Volta</a> for more discussion). This allows even individual threads in a “warp” (subgroup) to hold a mutex and block on other threads without fear of starvation. Another great resource on how Volta improved forward progress is the CppCon 2017 talk <a href="https://youtu.be/86seb-iZCnI?t=2043">Designing (New) C++ Hardware</a>٫ which I’ve timestamped for the forward progress discussion. Unfortunately٫ currently this guarantee is only valid for CUDA٫ not (yet) Vulkan. In the meantime٫ from what I understand٫ Nvidia hardware meets the occupancy-bound guarantee in both CUDA and Vulkan٫ which is good enough to run prefix sum.</p>

<p>I think it’s likely that over time٫ a consensus will emerge on formalizing the occupancy-bound guarantee٫ because it’s so useful٫ and at the least you’ll be able to query the GPU to determine the level of forward progress guarantee it provides.</p>

<p>In the meantime٫ it’s best to be conservative. Fortunately٫ for prefix sum٫ there is a fix (not yet implemented) that restores correct operation even on devices with the weakest forward progress properties: instead of simply spinning waiting from the aggregate from another partition٫ do a small bit of work towards recomputing the aggregate yourself. After a finite number of cycles٫ the aggregate for the partition will be done٫ then you can give up spinning and go to the next partition. This will guarantee getting the result eventually٫ and hopefully such performance-sapping events are rare.</p>

<h3 id="dynamic-allocation-on-gpu">Dynamic allocation on GPU</h3>

<p>On GPU٫ it’s easiest to run workloads that use static allocation٫ for example a fixed size buffer per workgroup٫ and workgroups arranged in a 2D grid (“dispatch” operations support 1D and 3D as well). But dynamic allocation is possible٫ with care.</p>

<p>The two major approaches to dynamic allocation are prefix sum and atomic bump allocation. The main reason for one over the other is whether you care about the ordering. Let’s take a simple problem of computing some function on an array of input values٫ where the output is variable sized.</p>

<p>Using a prefix-sum approach٫ you run a first pass of computing the size of the output. The prefix sum of that result yields an offset into an output buffer. The second pass (after the prefix sum) computes the function and writes it into the output buffer٫ using the offset provided by the prefix sum. [Also note that if we’re getting really fancy٫ it might be possible to fuse either or both of these passes with the prefix sum itself٫ decreasing the amount of global memory traffic but increasing register pressure and otherwise constraining efficient use of the memory hierarchy٫ so the extent to which this helps depends greatly on the exact problem].</p>

<p>An atomic bump allocation approach simply does <a href="https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/atomicAdd.xhtml"><code class="language-plaintext highlighter-rouge">atomicAdd</code></a> on each output٫ using a bump allocation index (effectively a pointer) as the first argument and the size of the allocation as the second. This yields results broadly similar to the prefix sum approach٫ but with the outputs in arbitrary order. Perhaps the order is not important٫ or٫ alternatively٫ a sort pass can be applied afterwards (sorting on GPU is another topic with a rich literature).</p>

<p>The two can be combined. For example٫ it makes sense to do a prefix sum of the sizes of items within a workgroup٫ and a single atomic bump allocation for the per-workgroup total.</p>

<p>One problem that might benefit from prefix sum for dynamic allocation is <a href="https://raphlinus.github.io/graphics/curves/2019/12/23/flatten-quadbez.html">flattening</a> Bézier curves to polylines. Each Bézier segment can be computed in parallel٫ but you generally want to preserve the order of segments within the full path. The flattening algorithm I presented in that blog post (and its <a href="https://github.com/linebender/kurbo/pull/105">generalization to cubics</a>) fits nicely into this framework — it’s already in two passes٫ where the first computes the number of segments required٫ and the second can compute the coordinates of each point in the output independently٫ thus in parallel.</p>

<h3 id="subgroups-and-subgroup-size">Subgroups and subgroup size</h3>

<p>High performance prefix sum requires coordination between threads — it’s possible to extract some parallelism by running O(log n) tree reduction passes٫ each of which pulls only from the previous pass٫ but this would be considerably slower than state of the art. Coordination must be at all levels of the hierarchy. GPU compute has always made threadgroup shared memory available for such coordination. An even faster but newer capability is <a href="https://www.khronos.org/blog/vulkan-subgroup-tutorial">subgroups</a>٫ not yet universally supported.</p>

<p>My prototype code uses subgroups extensively. One serious limitation is that it assumes a subgroup size of 32٫ which is true for some hardware. However٫ other hardware has different size subgroups٫ and then Intel is special.</p>

<p>By default٫ when compiling a compute kernel٫ the Intel drivers use a <a href="https://software.intel.com/en-us/forums/opencl/topic/564990">heuristic</a> to determine the subgroup size٫ which can then be 8٫ 16٫ or 32. It actually makes sense they use a heuristic٫ as there’s a complex tradeoff. A bigger subgroup means bigger chunks of work٫ which means less per-chunk overhead٫ but also fewer registers available per thread٫ and potentially more wasted work due to divergence. Again٫ that depends on workloads. For low-probability٫ expensive conditional work٫ generally not a good fit for GPU but sometimes unavoidable٫ wasted work tends to scale with subgroup size.</p>

<p>It might be <em>possible</em> to write a kernel that adapts to subgroup size٫ but there are a number of considerations that make this tricky. One is whether the number of items processed by a workgroup adapts to subgroup size. If so٫ then the size of the dispatch must be adapted as well. There is an <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/html/vkspec.html#features-pipelineExecutableInfo">extension</a> for the CPU side to query subgroup size of a pipeline٫ but٫ sadly٫ it doesn’t seem to be implemented on Intel drivers on Windows٫ where it would be most useful. (It is٫ thankfully٫ in the latest Linux Intel drivers٫ so hopefully will be coming soon.)</p>

<p>Another problem is querying the subgroup size from inside the kernel٫ which has a surprising gotcha. By default٫ the <code class="language-plaintext highlighter-rouge">gl_SubgroupSize</code> variable is defined to have the value from <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/man/html/VkPhysicalDeviceSubgroupProperties.html">VkPhysicalDeviceSubgroupProperties</a>٫ which in my experiment is always 32 on Intel no matter the actual subgroup size.</p>

<p>Newer (Vulkan 1.2) Intel drivers offer the ability to both accurately query and control over the subgroup size٫ with the <a href="https://www.khronos.org/registry/vulkan/specs/1.2-extensions/man/html/VK_EXT_subgroup_size_control.html">VK_EXT_subgroup_size_control</a> extension. With that extension٫ setting the <code class="language-plaintext highlighter-rouge">VK_PIPELINE_SHADER_STAGE_CREATE_ALLOW_VARYING_SUBGROUP_SIZE_BIT_EXT</code> at pipeline creation time makes <code class="language-plaintext highlighter-rouge">gl_subgroupSize</code> behave as expected. Also٫ I can set the subgroup size to 32٫ and the kernel works fine. Note though that in general٫ setting a too-large subgroup size can actually make performance worse٫ as it increases the chance of register spilling.</p>

<p>On RDNA-based AMD cards٫ the subgroup size extension lets you get subgroups of 32 on RDNA-based AMD cards٫ though the default is 64.</p>

<p>In practice٫ the programmer will write multiple versions of the kernel٫ each tuned for a different subgroup size٫ then on CPU side the code will query the hardware for supported subgroup sizes and choose the best one that can run on the hardware. Note that٫ in general٫ querying the range of supported subgroup sizes requires the subgroup size extension to be reliable٫ though you do string-matching on the device name to come up with a good guess. Note that the <a href="https://blogs.igalia.com/itoral/2018/03/20/improving-shader-performance-with-vulkans-specialization-constants/">specialization constants</a> mechanism is also a good way to tune constant factors like workgroup or buffer sizes without having to recompile kernel source. In any case٫ the cost and difficulty of this kind of performance tuning is one reason Nvidia has such a strong first-mover advantage.</p>

<p>Brian Merchant has done more exploration into the tradeoff between subgroups and threadgroup shared memory٫ for a different primitive operation٫ transpose of 32x32 boolean matrices. That <a href="https://github.com/bzm3r/transpose-timing-tests/blob/master/POST.md">transpose timing writeup</a> contains measurements on a variety of hardware٫ and is recommended to the interested reader.</p>

<h3 id="what-does-subgroupinclusiveadd-compile-to">What does subgroupInclusiveAdd compile to?</h3>

<p>The <code class="language-plaintext highlighter-rouge">subgroupInclusiveAdd</code> function seems like it’s doing a lot — it’s performing a prefix sum operation on an entire subgroup’s worth of data. Does hardware contain an assembly instruction that directly implements it? What if you want to do an operation other than addition٫ where there isn’t an intrinsic available?</p>

<p>Obviously different hardware will be different٫ but looking at the Radeon GPU Analyzer output on <a href="http://shader-playground.timjones.io/a9e2db94ab3bf88e790694ac869f7879">Shader Playground</a> tells us a lot. It generates a tree reduction (the Hillis-Steele algorithm as presented in the <a href="https://en.wikipedia.org/wiki/Prefix_sum">prefix sum</a> Wikipedia page) with lg(n) stages of subgroup shuffle + add. Since subgroup shuffle is available in Vulkan (but see below)٫ if you were to write out such a reduction you’d be able to get similar results.</p>

<p>On AMD hardware there is one additional twist: <a href="https://gpuopen.com/amd-gcn-assembly-cross-lane-operations/">AMD</a> has an additional level of hierarchy between subgroup (64 invocations٫ 1 wavefront) and invocation (thread). Internally٫ the hardware is organized around a <em>row</em> of 16 elements. Access to elements within a row uses a different instruction modifier (<code class="language-plaintext highlighter-rouge">row_shr</code>) than across the entire wave (<code class="language-plaintext highlighter-rouge">row_bcast</code> or <code class="language-plaintext highlighter-rouge">wave_ror</code>٫ for two examples)٫ and is likely lower latency in the chip. The Vulkan subgroup extensions provide a powerful and portable set of operations٫ but don’t expose all of the lowest-level operations available on the GPU hardware. To squeeze the last few percent of performance٫ assembly is still useful.</p>

<h3 id="portability-considerations-dx12">Portability considerations: DX12</h3>

<p>It is tempting to use a portability layer such as gfx-hal to run compute workloads on a variety of graphics APIs. (Other such portability layers include MoltenVK for running Vulkan on top of Metal٫ and similar work for running <a href="https://devblogs.microsoft.com/directx/in-the-works-opencl-and-opengl-mapping-layers-to-directx/">OpenCL on DX12</a>). But such an approach is limited to the lowest common denominator — it can’t provide capabilities that are missing in the underlying layer.</p>

<p>Here are some of the pain points for DX12:</p>

<ul>
  <li>
    <p>No subgroup size control.</p>
  </li>
  <li>
    <p>No subgroup shuffle operations — use threadgroup shared memory instead.</p>
  </li>
  <li>
    <p>No memory model — use <code class="language-plaintext highlighter-rouge">volatile</code> and explicit barriers instead.</p>
  </li>
  <li>
    <p>No pointers (not particularly useful for this workload٫ but important for others).</p>
  </li>
</ul>

<p>Also note that gfx-hal currently doesn’t give access to Shader Model 6 intrinsics (subgroup operations)٫ but there’s an <a href="https://github.com/gfx-rs/gfx/issues/3238">issue</a> and hopefully that will be fixed.</p>

<h3 id="portability-considerations-metal">Portability considerations: Metal</h3>

<p>Metal is closer to Vulkan in capabilities (especially newer versions)٫ but still lacks subgroup size control and a memory model.</p>

<h2 id="a-challenge-for-gpu-compute-infrastructure">A challenge for GPU compute infrastructure</h2>

<p>I covered a fair number of GPU compute infrastructure projects in my talk and the associated <a href="https://raphlinus.github.io/gpu/2020/02/12/gpu-resources.html">GPU resources</a> list. Since then I’ve learned of quite a few more:</p>

<ul>
  <li>
    <p><a href="https://github.com/jgbit/vuda">vuda</a>٫ which runs (SPIR-V) compute workloads using an API similar to the CUDA host API.</p>
  </li>
  <li>
    <p><a href="https://github.com/kpet/clvk">clvk</a> and <a href="https://github.com/google/clspv">clspv</a>٫ which run OpenCL workloads on Vulkan.</p>
  </li>
  <li>
    <p><a href="https://www.khronos.org/news/press/khronos-group-releases-opencl-3.0">OpenCL 3.0</a> is announced٫ with a number of strategies to rescue OpenCL from a fate of irrelevance.</p>
  </li>
  <li>
    <p><a href="https://software.intel.com/en-us/oneapi">oneAPI</a>٫ which offers a CUDA migration path but aspires to being a portable standard.</p>
  </li>
</ul>

<p>I am also optimistic about <a href="https://www.w3.org/community/gpu/">WebGPU</a> becoming a viable platform for compute workloads٫ both delivered over the web and in native implementations such as <a href="https://github.com/gfx-rs/wgpu">wgpu</a>.</p>

<p>Echoing fluffything’s comment٫ I propose adopting prefix sum as something of a “hello world” benchmark of GPU compute. It’s simple enough it should be practical to implement without too much effort (and if not٫ that’s also an important data point)٫ it exercises “advanced” features such as subgroup shuffles٫ and it’s reasonably easy to quantify. When looking at these potential infrastructure projects٫ ask these questions:</p>

<ul>
  <li>
    <p>How close can it get to the performance offered by the hardware?</p>
  </li>
  <li>
    <p>How portable is the high-performance result?</p>
  </li>
  <li>
    <p>Are there ways to smoothly downgrade on less capable platforms?</p>
  </li>
</ul>

<p>The result of my explorations on Vulkan suggest (but do not yet prove) good answers to these questions٫ but at the expense of doing a lot of the low-level legwork yourself٫ and programming the kernel in a very low-level style (in GLSL). I think there’s a huge opportunity for more sophisticated tools.</p>

<p>Also٫ I think it’s a great benchmark for the emerging field of GPU-friendly languages. Is it possible to express the algorithm in a reasonably high-level manner? If so٫ does it compile to code with competitive performance? Can we write a high-performance abstraction as a library that can be consumed easily? Can that abstraction offer portability across hardware but hide the complexity from its users? Can you provide your own monoid?</p>

<h2 id="conclusion">Conclusion</h2>

<p>I’ve showed that Vulkan can do prefix sum with near state of the art performance. However٫ I’ve also outlined some of the challenges involved in writing Vulkan compute kernels that run portably and with high performance. The lower levels of the stack are becoming solid٫ enabling a determined programmer to ship high performance compute across a wide range of the hardware٫ but there is also an opportunity for much better tooling at the higher levels. I see a bright future ahead for this approach٫ as the performance of GPU compute is potentially massive compared with CPU-bound approaches.</p>

<p>Thanks to Brian Merchant٫ Matt Keeter٫ and msiglreith for discussions on these topics٫ and Jason Ekstrand for setting me straight on subgroup size concerns on Intel. I’ve also enjoyed the benefit of talking with a number of other people working on GPU drivers٫ which informs the section on forward progress in particular٫ though of course any mistakes remain my own.</p>

<p>There is some interesting <a href="https://news.ycombinator.com/item?id=23035194">HN discussion</a> of this post.</p>'),('https://raphlinus.github.io/graphics/2020/04/21/blurred-rounded-rects.html', 'Blurred rounded rectangles', '1587497082000',  12, '<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [["$"٫ "$"]]
        }
    });
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<p>Note: I’m publishing this with inadequate visuals٫ as it’s been stuck in my queue for 3 weeks and I want to get it out there. I’d like to return to making proper images٫ but make no promises when.</p>

<p>For now٫ a quick comparison of exact (computed with numerical integration) results (on the left) with my approximation:</p>

<p><img src="/assets/blurrr_comparison.png" alt="Comparison of exact and approximate solutions" /></p>

<p>There are two basic ways to render blur in 2D graphics. The general technique is to render the objects into an offscreen buffer٫ compute a blur٫ and composite that into the target surface. But in special cases٫ it’s possible to compute the blurred image directly from the source object٫ which is much faster.</p>

<p>Some shapes are easy٫ particularly rectangles; they have a straightforward closed-form analytical solution. But others require numerical approximations. A few years ago٫ Evan Wallace posted a solution for <a href="http://madebyevan.com/shaders/fast-rounded-rectangle-shadows/">fast rounded rectangle shadows</a>٫ using an analytical solution in one direction and numerical integration in the other. This is a good solution٫ but I was curious whether it is possible to do better.</p>

<p>The solution in this blog post is based on distance fields٫ a very powerful technique that has been getting more attention because of it adapts so well to GPU evaluation in shaders. <a href="https://www.iquilezles.org/">Inigo Quilez</a> has been making elaborate 3d scenes built up out mostly out of <a href="https://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm">distance field</a> primitives٫ a stunning demonstration of the power and flexibility of the technique. This post will sketch out the development of a less artistic but still hopefully useful application. I enjoy playing with the underlying math٫ and hope this blog post will be educational or at least entertaining for some of my readers.</p>

<p>Developing this required exploring a lot of possibilities٫ as well as navigating through parameter spaces. It’s most common to use Jupyter notebooks٫ a JavaScript-based platform such as observable٫ or a comparable tool. But for this٫ partly to try it out٫ I tried Rust٫ building a <a href="https://git.sr.ht/~raph/blurrr">simple visualizer application</a> using <a href="https://github.com/xi-editor/druid">druid</a>٫ a cross-platform GUI toolkit. You can try the <a href="https://blurrr.futurepaul.now.sh/">Web version</a>٫ ported by Paul Miller.</p>

<h2 id="the-1d-case-blurred-box-function">The 1D case: blurred box function</h2>

<p>As a warmup٫ let’s take the one dimensional case٫ especially as we’ll be using it as the foundation of the 2D solution. The one dimensional analog of a rectangle is a boxcar function.</p>

<p>Gaussian blur is the convolution of a Gaussian bump with the underlying image. The convolution of a box with a Gaussian has a straightforward analytical solution. A boxcar is the difference of two step functions (offset by the thickness of the line)٫ and the convolution of a step and a Gaussian is <a href="https://en.wikipedia.org/wiki/Error_function">erf</a>. Thus٫ the blurred image is the difference of two erf evaluations.</p>

<p>It happens that this solution generalizes to a rectangle. Since a rectangle is the outer product of two box functions٫ a blurred rectangle is the outer product of their blurs. However٫ we won’t be using this٫ as we’re concerned with rounded rectangles٫ which aren’t separable in this way.</p>

<h2 id="distance-field-of-a-rounded-rect">Distance field of a rounded rect</h2>

<p>Instead٫ we’ll use distance functions٫ as they do have the power and flexibility we need.</p>

<p>The general approach is to compute a signed distance from an outline٫ then use that distance as input to a function which computes the actual grayscale value. This approach separates the problem into the <em>shape</em> of the contour lines and the <em>values٫</em> which (for reasons we’ll see) are best understood as a cross-section through the minor axis of the rectangle.</p>

<p>As Jonathan Blow has <a href="https://twitter.com/Jonathan_Blow/status/1244792815512510469">recently tweeted</a>٫ “The most useful thing I ever learned٫ about how to do geometric operations in software٫ is to separate the problem into parallel and orthogonal components. It applies to just about everything.” While this is most obvious for classical geometric problems such as projecting a point onto a line٫ distance field techniques can be seen as another tool in the toolbox following this general principle. A distance field represents the value of the orthogonal component٫ with the parallel component filtered out.</p>

<p>To visualize contours (the parallel component) better٫ we’ll quantize the grayscale values. And we can see that for relatively small blur radii these contours look a lot like plain rounded rectangles. This motivates the first solution:</p>

<ul>
  <li>
    <p>The curve is a rounded rectangle.</p>
  </li>
  <li>
    <p>The corner radius is computed as a combination of the original corner radius and blur radius.</p>
  </li>
  <li>
    <p>The cross-section of the minor axis is the 1D solution.</p>
  </li>
</ul>

<p>The combination cited in the second step is $ \sqrt{r_c^2 + 1.25 r_b^2} $. The choice of this formula is motivated by the rule for the probability distribution of a <a href="https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables">sum of Gaussians</a>٫ with the constant factor chosen empirically.</p>

<h3 id="implementation">Implementation</h3>

<p>The distance field for a rounded rectangle can be computed exactly٫ and Inigo Quilez includes the formula in his catalog of <a href="https://www.iquilezles.org/www/articles/distfunctions2d/distfunctions2d.htm">2D distance functions</a>. In shader language:</p>

<div class="language-glsl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">float</span> <span class="nf">sdRoundedBox</span><span class="p">(</span> <span class="k">in</span> <span class="kt">vec2</span> <span class="n">p</span><span class="p">٫</span> <span class="k">in</span> <span class="kt">vec2</span> <span class="n">b</span><span class="p">٫</span> <span class="k">in</span> <span class="kt">float</span> <span class="n">r</span> <span class="p">)</span> <span class="p">{</span>
    <span class="kt">vec2</span> <span class="n">q</span> <span class="o">=</span> <span class="n">abs</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">-</span><span class="n">b</span><span class="o">+</span><span class="n">r</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">min</span><span class="p">(</span><span class="n">max</span><span class="p">(</span><span class="n">q</span><span class="p">.</span><span class="n">x</span><span class="p">٫</span><span class="n">q</span><span class="p">.</span><span class="n">y</span><span class="p">)٫</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">length</span><span class="p">(</span><span class="n">max</span><span class="p">(</span><span class="n">q</span><span class="p">٫</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">))</span> <span class="o">-</span> <span class="n">r</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p><img src="/assets/rounded_rect_distfield.png" alt="Distance field of rounded rectangle" />
(Image adapted from <a href="https://www.shadertoy.com/view/4llXD7">https://www.shadertoy.com/view/4llXD7</a>)</p>

<p>Note the use of <code class="language-plaintext highlighter-rouge">min</code> and <code class="language-plaintext highlighter-rouge">max</code> rather than conditional branching. The former is much faster in both shaders and SIMD evaluation.</p>

<p>For erf٫ we’ll use an approximation. It’s one of my <a href="https://raphlinus.github.io/audio/2018/09/05/sigmoid.html">favorite sigmoids</a> and we’ll use the techniques from that blog post.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">fn</span> <span class="nf">compute_erf7</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">f64</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">f64</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="nn">std</span><span class="p">::</span><span class="nn">f64</span><span class="p">::</span><span class="nn">consts</span><span class="p">::</span><span class="n">FRAC_2_SQRT_PI</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">xx</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.24295</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.03395</span> <span class="o">+</span> <span class="mf">0.0104</span> <span class="o">*</span> <span class="n">xx</span><span class="p">)</span> <span class="o">*</span> <span class="n">xx</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">xx</span><span class="p">);</span>
    <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span><span class="nf">.sqrt</span><span class="p">()</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Evan’s version is based on an approximation from Abramowitz and Stegun٫ which has <a href="https://www.desmos.com/calculator/tcuwxfqyrl">similar accuracy</a> and likely similar performance٫ but I like using reciprocal square root - it is particularly well supported in <a href="https://www.felixcloutier.com/x86/rsqrtps">SIMD</a> and <a href="https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/inversesqrt.xhtml">GPU</a> and is generally about the same speed as simple division.</p>

<p><a href="https://www.desmos.com/calculator/tcuwxfqyrl"><img src="/assets/erf_approx.png" alt="Comparison of exact and approximate solutions" /></a></p>

<h3 id="evaluation">Evaluation</h3>

<p>And this does indeed work well for small blur radii٫ compared to the size of the rectangle and the corner radius. But as thr blur radius goes up٫ we start to see problems. For one٫ the corner radius gets smaller٫ achieving a sharp corner in the visible region. For two٫ the rounded parts butt against the smooth parts rather than joining smoothly.</p>

<h2 id="squircles-to-the-rescue">Squircles to the rescue</h2>

<p>The contour of the blurred rounded rectangle strongly resembles a <a href="https://en.wikipedia.org/wiki/Squircle">squircle</a> or <a href="https://en.wikipedia.org/wiki/Superellipse">superellipse</a>. Such a shape would solve both these problems.</p>

<p>Here what we want to do is adapt the distance field approach to use a distance-like metric rather than an exact distance to the reference curve. Basically٫ the game plan is as follows:</p>

<ul>
  <li>
    <p>Structure of distance field is same as rounded rect.</p>
  </li>
  <li>
    <p>Increase exponent from 2 (circle) to make superellipse shape.</p>
  </li>
  <li>
    <p>Cross-section is as above.</p>
  </li>
</ul>

<p>Increasing the exponent clearly solves the main issues with the pure rounded rectangle shape٫ namely the sharp interior corners (which generate a visible “x” structure) and the abrupt straight to curved transitions:</p>

<p><img src="/assets/rounded_rect_distfield_exp.png" alt="Distance field of rounded rectangle with exponent 4" /></p>

<p>A more complete writeup of the final code is a TODO for this blog (along with better visuals)٫ but see <a href="https://git.sr.ht/~raph/blurrr/tree/master/src/distfield.rs">the code</a> for the detailed solution.</p>

<h3 id="further-refinements">Further refinements</h3>

<p>As the blur radius goes up٫ two factors degrade the accuracy of the above solution. For one٫ the height of the peak in the real solution decreases faster than the 1D case. This is fixed with a constant scale multiplier٫ derived from the erf of the rectangle’s major axis. For two٫ the overall shape becomes less eccentric٫ more like a circle (in the limit٫ it becomes a radially symmetric blur function). This is fixed by subtracting a correction factor from the major (long) axis of the rectangle.</p>

<p>With these corrections in place٫ the approximation becomes quite accurate over the entire range of parameters. Accuracy is nearly perfect for the original use case - shadows for UI objects٫ but visually acceptable everywhere.</p>

<h2 id="future-work">Future work</h2>

<p>A good solution to the blurred rounded rectangle problem is nice but perhaps not that exciting by itself; Evan’s existing solution is almost certainly good enough for most practical uses.</p>

<p>One obvious generalization is to more shapes. The easiest by far is to squircle-based rounded rectangle shapes٫ as these can almost certainly by accomplished by tuning the parameters on the existing pixel shading logic. A case can be made that squircles are better than classical rounded rectangles (certainly <a href="https://www.figma.com/blog/desperately-seeking-squircles/">Apple thinks so</a>). And the shader can readily be adapted to render both filled and stroked versions of the shape with high quality antialiasing.</p>

<p>Good approximations to many other blurred shapes are possible٫ as a rich set of <a href="https://www.iquilezles.org/www/articles/distfunctions2d/distfunctions2d.htm">2D distance functions</a> are known and in widespread use in shader circles.</p>

<p>Also٫ perhaps your designer prefers <a href="https://en.wikipedia.org/wiki/Bokeh">bokehlicious</a> discs to Gaussian shadows. Doable. Just use a different <a href="https://www.wolframalpha.com/input/?i=integral%20sqrt%281-x%5E2%29">cross-section function</a> and tweak the parameters.</p>

<p>Some fine-tuning on the code can still be done. For example٫ the “magic constants” were mostly determined through experimentation. A more systematic approach would be to do a global optimization٫ minimizing the value of some error norm over a range of parameters. Maybe an enterprising reader will take this on!</p>

<h2 id="thanks">Thanks</h2>

<p>Thanks to Evan Wallace for permission to use his WebGL code (hoped for in a future revision)٫ to Jacob Rus for discussion about the math٫ and Paul Miller for the wasm port.</p>'),('https://raphlinus.github.io/covid/2020/03/14/covid.html', 'Covid-19 resources', '1584208122000',  12, '<p>I’ve been following the Covid-19 pandemic closely the last week or so٫ to the point of not really being able to concentrate on other things. In the hope the resources I’ve found might be useful٫ I’m sharing them with my blog readership. This will be updated frequently٫ most recently 3/16.</p>

<h2 id="avoid-misinformation">Avoid misinformation</h2>

<p>There is٫ unfortunately٫ a huge amount of misinformation٫ and even active disinformation out there. Since this pandemic is likely to be efficient in converting misinformation into deaths٫ now is a good time to improve one’s information sources. To quote <a href="https://www.linkedin.com/pulse/dispatch-3-dr-shlain-reporting-from-front-lines-shlain-m-d-/">Dr. Shlain 3/12 dispatch</a>٫ “There is a ton of bullshit being disseminated. Please do not disseminate anything you can’t verify. Science must prevail.”</p>

<p>I’ve found Twitter to be an excellent source of information٫ provided of course one follows actual experts. My personal favorite is <a href="https://twitter.com/JeremyKonyndyk">@JeremyKonyndyk</a>٫ who among other things led Ebola response under Obama٫ but I also want to raise up <a href="https://twitter.com/ScottGottliebMD">@ScottGottliebMD</a>٫ who has been doing a particularly excellent job calling attention to the need for better testing٫ and has excellent conservative credentials (works at the <a href="https://www.aei.org/about">AEI</a>). The virus doesn’t care about our political affiliation٫ and now more than ever is a time we need to be reaching across political divisions to work together. I could make a list of all the people I follow on Twitter٫ but what I recommend is following the various experts Jeremy retweets٫ as there is a great range.</p>

<p>Unfortunately٫ a lot of the misinformation is being spread by people in authority٫ including <a href="https://thebulletin.org/2020/03/why-do-politicians-keep-breathing-life-into-the-false-conspiracy-theory-that-the-coronavirus-is-a-bioweapon/">elected officials</a>٫ the more irresponsible media outlets٫ and٫ sadly٫ the President. People on epidemiology Twitter are consistently citing misinformation as one of the challenges they face - they do not have the bandwidth to debunk each bit individually. Do your part. Tune out information sources that are prone to misinformation٫ and please don’t help this stuff propagate.</p>

<p>There is one very easy way to identify misinformation. Anyone proposing “cures” that go beyond common sense health advice or consensus public health advice is absolutely spreading dangerous misinformation. Unfortunately٫ this stuff is fairly common. [As a bit more subtlety٫ doctors are actively considering existing antiviral agents. Some look promising٫ and hopefully we will see the result of this research soon. But doctors shouldn’t be paying attention to me for information٫ there are much better sources such as <a href="https://www.youtube.com/user/MEDCRAMvideos/videos">Dr. Seheult’s MedCram channel</a>. Anyone who is suggesting people seek out such things without a doctor’s prescription is a dangerous quack].</p>

<p>[I’m going to expand on this topic of the pipeline from research to actionable advice soon٫ as it’s quite tricky territory. For example٫ in non-expert circles I see a lot of attention given to the advice to avoid ibuprofen. There is <a href="https://www.sciencemediacentre.org/expert-reaction-to-reports-that-the-french-health-minister-recommended-use-of-paracetamol-for-fever-from-covid-19-rather-than-ibuprofen-or-cortisone/">weak support</a> for this٫ and it might be a good idea to use acetaminophen instead out of caution٫ but there is not yet expert consensus on this. Update 3/17: the WHO now recommends using acetaminophen rather than ibuprofen as self-medication.]</p>

<p>More tips on misinformation in this <a href="https://twitter.com/imran_malek/status/1238948869565800456">Twitter thread from Imran Malek</a>.</p>

<p>A few organizations deserve credit for very good work. The Atlantic is consistently good٫ with a series of excellent articles by James Hamblin in particular. He is one of the best health communicators working today. On TV٫ Chris Hayes deserves praise.</p>

<p>And I should give credit where credit is due to Fox News for suspending Trish Regan’s show. I just wish they’d go farther and make a collective decision not to air misinformation altogether. If you have Fox News watching people in your family٫ now might be a good time to remind them that it’s an exceedingly poor source of information. It’s very hard to get through to such people٫ but it might be helpful to point out that <a href="https://www.theguardian.com/media/2020/mar/13/fox-news-accused-of-downplaying-coronavirus-as-it-moves-to-protect-staff">they are saying one thing to their audience and doing another regarding the health of their own employees</a>.</p>

<h2 id="overviews-and-updates">Overviews and updates</h2>

<p>Dr. Jordan Shlain is running regular updates. <a href="https://tincture.io/dispatch-4-from-the-front-lines-79c74fa67ae0">Dr. Shlain Dispatch #4</a> is filled with good stats and tips.</p>

<p>A fantastic summary of the science is the <a href="https://drive.google.com/file/d/1DqfSnlaW6N3GBc5YKyBOCGPfdqOsqk1G/view">How to fight the coronavirus SARS-CoV-2 and its disease٫ CoVID-19</a> slide deck from the Michael Lin lab at Stanford. A complementary talk٫ with a greater emphasis on analysis of Wuhan (and with both slides and video available) is from <a href="https://twitter.com/XihongLin/status/1238970212780826633">@XihongLin</a> at Harvard.</p>

<p>The Imperial College <a href="https://www.imperial.ac.uk/mrc-global-infectious-disease-analysis/news--wuhan-coronavirus/">Impact of non-pharmaceutical interventions (NPIs) to reduce COVID-19 mortality and healthcare demand</a> report is sobering٫ and is one of the few responsible sources to cite actual numbers. In their simulation of what happens if we don’t take actual steps٫ they predict 2.2 million deaths in the US. That should give the people who complain that the “flattenthecurve” graphs are too simplistic and qualitiative some food for thought.</p>

<h2 id="raw-data-resources">Raw data resources</h2>

<p><a href="https://www.worldometers.info/coronavirus/">Worldometer</a> has up-to-date information by country. The <a href="https://www.arcgis.com/apps/opsdashboard/index.html">Johns Hopkins COVID-19 map</a> has long been the go-to resource٫ but a limitation is that it aggregates all cases by state in the US but no finer. Especially for large states such as California٫ the <a href="https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html">New York Times</a> dashboard may be more useful.</p>

<p>The <a href="https://ourworldindata.org/coronavirus">Our World in Data</a> website is one of the most comprehensive٫ and I particularly commend their <a href="https://ourworldindata.org/coronavirus#trajectories-since-the-100th-confirmed-case">trajectories</a> chart. It is remarkable how similar the trajectories are for most countries (with Japan and smaller city-states being the exceptions). Note that interpretation is tricky; the US has been way behind on testing capacity but will be bringing that online over the next few days٫ so we are likely to see a massive uptick in case numbers that represent testing coverage rather than a spike in cases. That will make it hard to evaluate the effectiveness of “social distancing” measures.</p>

<p><a href="https://ourworldindata.org/coronavirus#trajectories-since-the-100th-confirmed-case"><img src="/assets/ourworld-trajectory.png" alt="trajectories from Our World in Data٫ 3/14٫ CC BY" /></a></p>

<p>Likely most readers of this blog understand exponential growth pretty well٫ but the 3 Blue 1 Brown video on <a href="https://www.youtube.com/watch?v=Kas0tIxDvrg">Exponential growth and epidemics</a> does a really good job of putting it in context of epidemics٫ and in particular explains that a logistic curve is likely a better model٫ and that only matches a pure exponential up to the inflection point.</p>

<p>For fans of modeling٫ <a href="https://twitter.com/trvrb">Trevor Bedford @trvrb</a> is a good person to follow. The Nextstrain work has been tracking the genetic variation from the various strains of SARS-CoV-2 virus٫ and you can follow <a href="https://twitter.com/firefoxx66">Dr Emma Hodcroft @firefoxx66</a> for updates on that.</p>

<p>I now have a <a href="https://twitter.com/i/lists/1239639611694911489">covid-19 Twitter list</a> which is carefully curated to provide a wide range of expertise٫ and high signal to noise ratio.</p>

<h2 id="practical-tips">Practical tips</h2>

<p>I recommend <a href="https://flattenthecurve.com">flattenthecurve.com</a>٫ not just for explaining the need for “social distancing” and encouraging it٫ but also because it puts the advice in context of people actually living their lives.</p>

<p>If you do start developing symptoms٫ the best guide is <a href="https://www.who.int/publications-detail/home-care-for-patients-with-suspected-novel-coronavirus-(ncov)-infection-presenting-with-mild-symptoms-and-management-of-contacts">Home care for patients with suspected novel coronavirus (nCoV) infection presenting with mild symptoms and management of contacts</a>٫ from the World Health Organization (also see country-specific versions such as the <a href="https://www.gov.uk/government/publications/covid-19-stay-at-home-guidance/stay-at-home-guidance-for-people-with-confirmed-or-possible-coronavirus-covid-19-infection">UK version</a>. For more discussion of the policy choices around this٫ see <a href="https://www.theatlantic.com/health/archive/2020/03/where-do-you-go-if-you-get-coronavirus/607759/">What Will You Do If You Start Coughing?</a> by James Hamblin.</p>

<p>Your local public health department is a great resource. Become familiar with it and be prepared to follow their advice٫ as this stuff works better when it’s coordinated٫ and they’ll also point you to authoritative resources. Here’s the <a href="https://www.cityofberkeley.info/coronavirus/">Berkeley Coronavirus</a> page٫ for example.</p>

<p>Here’s a Twitter thread with much great advice: <a href="https://twitter.com/ASlavitt/status/1238832893771894788">COVID-19 Prep Update- March 14</a> by Andy Slavett. I am not going to post my own projections because it wouldn’t be responsible٫ but they are very much on track with his.</p>

<p>But beyond basic health advice٫ it’s super important to take care of yourself. Many sources recommend not binging on Covid-19 news (I have been terrible at following that advice). Do other things to stay healthy٫ and do things to take care of your emotional٫ spiritual٫ and mental health. I’ve personally been dealing with waves of intense anger٫ especially when I check my feeds and see the latest monumental fuckup - as I write٫ I just saw the images of huge crowds at airports on 3/14. Be aware that this is a tough and stressful time٫ and have plans in place to manage it.</p>

<p>Our Quaker meeting has suspended in-person meetings (along with probably most other religious organizations in the country by now)٫ and is doing online meetings for worship. In addition٫ we’re setting up an emergency preparedness network٫ groups of about 10 each by local neighborhood٫ where we’ll be checking in with each other and can serve as a point of contact in case of emergency. I feel good getting involved in this٫ and maybe you can consider setting up something similar٫ whether it’s through your religious group٫ school٫ or other social group.</p>

<p>Also make sure to take care of your health in other ways: eat right٫ sleep well٫ continue to get exercise. Because we don’t have a cure for Covid-19 yet٫ general health is one of the absolute best predictors of outcome.</p>

<p>Take care of yourself٫ take care of each other.</p>

<p>Note: this blog is open source! Feel free to adapt this post as you like (under CC BY 4.0 license)٫ and also send pull requests to the <a href="https://github.com/raphlinus/raphlinus.github.io">repo</a> to update it.</p>'),('https://raphlinus.github.io/gpu/2020/02/12/gpu-resources.html', 'GPU resources', '1581531642000',  12, '<p>This post is basically a dump of resources I’ve encountered while doing a deep dive into GPU programming. I welcome pull requests against the <a href="https://github.com/raphlinus/raphlinus.github.io">repo</a> for other useful resources. Also feel free to ask questions in issues٫ particularly if the answer might be in the form of a patch to this post.</p>

<h2 id="understanding-the-hardware">Understanding the hardware</h2>

<h3 id="intel">Intel</h3>

<p>Intel is one of the best GPU hardware platforms to understand because it’s documented and a lot of the work is open source.</p>

<ul>
  <li>
    <p><a href="https://en.wikichip.org/wiki/intel/microarchitectures/gen9">Wikichip gen 9</a>٫ <a href="https://en.wikichip.org/wiki/intel/microarchitectures/gen9.5">gen 9.5</a>٫ <a href="https://en.wikichip.org/wiki/intel/microarchitectures/gen11">gen 11</a></p>
  </li>
  <li>
    <p><a href="https://software.intel.com/sites/default/files/managed/c5/9a/The-Compute-Architecture-of-Intel-Processor-Graphics-Gen9-v1d0.pdf">Intel white paper on Gen9 compute</a></p>
  </li>
  <li>
    <p><a href="https://01.org/sites/default/files/documentation/intel-gfx-prm-osrc-kbl-vol07-3d_media_gpgpu.pdf">Programmer’s Reference Manual</a> for Kaby Lake (Gen 9.5)</p>
  </li>
</ul>

<p>There’s also some academic literature:</p>

<ul>
  <li><a href="http://comparch.gatech.edu/hparch/papers/gera_ispass18.pdf">Performance Characterisation and Simulation of Intel’s Integrated GPU Architecture</a></li>
</ul>

<p>One of the funky things about Intel is the varying subgroup width; it can be SIMD8٫ SIMD16٫ or SIMD32٫ mostly determined by <a href="https://software.intel.com/en-us/forums/opencl/topic/564990">compiler heuristic</a>٫ but there is a new <a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/html/chap44.html#VK_EXT_subgroup_size_control">VK_EXT_subgroup_size_control</a> extension.</p>

<h3 id="nvidia">NVidia</h3>

<p>There’s a lot of interest and activity around NVidia٫ but much of it is reverse engineering.</p>

<ul>
  <li>
    <p><a href="https://arxiv.org/pdf/1804.06826.pdf">Dissecting the NVIDIA Volta GPU Architecture via Microbenchmarking</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1903.07486.pdf">Dissecting the NVidia Turing T4 GPU via Microbenchmarking</a></p>
  </li>
</ul>

<h3 id="amd">AMD</h3>

<ul>
  <li>
    <p><a href="https://developer.amd.com/wp-content/resources/Vega_Shader_ISA_28July2017.pdf">“Vega” Instruction Set Architecture Reference Guide</a></p>
  </li>
  <li>
    <p><a href="https://gpuopen.com/optimizing-gpu-occupancy-resource-usage-large-thread-groups/">Optimizing GPU occupancy and resource usage with large thread groups</a></p>
  </li>
</ul>

<h2 id="understanding-api-capabilities">Understanding API capabilities</h2>

<ul>
  <li>
    <p><a href="https://vulkan.gpuinfo.org/">vulkan.gpuinfo.org</a> - a detailed database of what extensions are available on what hardware/driver/platform combinations.</p>
  </li>
  <li>
    <p><a href="https://developer.apple.com/metal/Metal-Feature-Set-Tables.pdf">Metal Feature Set Tables</a> has similar info for Metal.</p>
  </li>
</ul>

<h2 id="subgroups">Subgroups</h2>

<p>Subgroup/warp/SIMD/shuffle operations are very fast٫ but less compatible (nonuniform shuffle is missing from HLSL/SM6)٫ and you (mostly) don’t get to control the subgroup size٫ so portability is a lot harder.</p>

<ul>
  <li>
    <p><a href="https://www.khronos.org/blog/vulkan-subgroup-tutorial">Vulkan Subgroup Tutorial</a></p>
  </li>
  <li>
    <p><a href="https://www.khronos.org/assets/uploads/developers/library/2018-vulkan-devday/06-subgroups.pdf">Vulkan Subgroup Explained</a></p>
  </li>
  <li>
    <p><a href="https://developer.nvidia.com/reading-between-threads-shader-intrinsics">Reading Between The Threads: Shader Intrinsics</a></p>
  </li>
</ul>

<h2 id="languages">Languages</h2>

<h3 id="glsl">GLSL</h3>

<ul>
  <li>
    <p><a href="https://github.com/KhronosGroup/glslang">https://github.com/KhronosGroup/glslang</a> - reference implementation of GLSL٫ compilation to SPIR-V</p>
  </li>
  <li>
    <p><a href="https://github.com/google/shaderc">shaderc</a> - Google-maintained tools</p>
  </li>
</ul>

<h3 id="hlsl">HLSL</h3>

<ul>
  <li>
    <p><a href="https://github.com/microsoft/DirectXShaderCompiler">DirectX Shader Compiler</a> (DXC) - produces both SPIR-V and DXIL.</p>
  </li>
  <li>
    <p><a href="https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-pguide">Programming guide for HLSL</a></p>
  </li>
  <li>
    <p><a href="https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/hlsl-shader-model-6-0-features-for-direct3d-12">Shader Model 6</a></p>
  </li>
</ul>

<h3 id="metal-shading-language">Metal Shading Language</h3>

<ul>
  <li><a href="https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf">Metal Shading Language Specification</a></li>
</ul>

<h3 id="opencl">OpenCL</h3>

<ul>
  <li>
    <p><a href="https://github.com/google/clspv">clspv</a> - compile OpenCL C (subset) to run on Vulkan compute shaders.</p>

    <ul>
      <li>To me٫ this is evidence that Vulkan will simply eat OpenCL’s lunch. This is still <a href="https://github.com/KhronosGroup/Vulkan-Ecosystem/issues/42">controversial</a>٫ but Khronos people are insisting there’s an “OpenCL Next” roadmap.</li>
    </ul>
  </li>
  <li>
    <p><a href="https://www.khronos.org/news/press/khronos-group-releases-opencl-3.0">OpenCL 3.0</a> is recently announced٫ and their plans do include clspv and related tools to run on a Vulkan.</p>
  </li>
</ul>

<h3 id="tensorflow">TensorFlow</h3>

<ul>
  <li><a href="https://blog.tensorflow.org/2019/04/mlir-new-intermediate-representation.html">MLIR</a></li>
</ul>

<h3 id="exotic-languages">Exotic languages</h3>

<ul>
  <li>
    <p><a href="https://halide-lang.org/">Halide</a></p>
  </li>
  <li>
    <p><a href="https://futhark-lang.org/">Futhark</a></p>
  </li>
  <li>
    <p><a href="https://github.com/Co-dfns/Co-dfns">Co-dfns</a></p>
  </li>
  <li>
    <p><a href="https://juliacomputing.com/industries/gpus.html">Julia on GPU</a> - layered on CUDA</p>
  </li>
</ul>

<h2 id="spir-v">SPIR-V</h2>

<ul>
  <li>
    <p><a href="https://github.com/KhronosGroup/SPIRV-Cross">SPIRV-Cross</a> - transpile SPIR-V into GLSL٫ HLSL٫ and Metal Shading Language</p>

    <ul>
      <li>This is an integral part of portability layers including <a href="https://github.com/KhronosGroup/MoltenVK">MoltenVK</a> and <a href="https://github.com/gfx-rs/gfx">gfx-rs</a>.</li>
    </ul>
  </li>
</ul>

<h2 id="webgpu">WebGPU</h2>

<ul>
  <li>
    <p><a href="https://fosdem.org/2020/schedule/event/rust_webgpu/">Building WebGPU with Rust</a> - FOSDEM talk</p>
  </li>
  <li>
    <p><a href="https://github.com/gfx-rs/wgpu">wgpu</a> - Rust WebGPU implementation</p>
  </li>
  <li>
    <p><a href="https://dawn.googlesource.com/dawn">dawn</a> - Google’s WebGPU implementation in C++</p>
  </li>
  <li>
    <p>Work-in-progress <a href="https://gpuweb.github.io/gpuweb/">specification</a></p>
  </li>
  <li>
    <p><a href="https://developers.google.com/web/updates/2019/08/get-started-with-gpu-compute-on-the-web">Get started with GPU Compute on the Web</a> - Google (Chromium/Dawn)</p>
  </li>
</ul>

<h3 id="webgpu-shader-language">WebGPU shader language</h3>

<p>The discussion of shader language had been very <a href="https://news.ycombinator.com/item?id=22020511">contentious</a>. As of very recently there is a proposal for a textual language that is semantically equivalent to SPIR-V٫ and there seems to be agreement that this is the path forward.</p>

<ul>
  <li>
    <p><a href="https://docs.google.com/presentation/d/1qHhFq0GJtY_59rNjpiHU--JW4bW4Ji3zWei-gM6cabs/edit">Tint - WebGPU F2F - Feb 12٫ 2020</a></p>
  </li>
  <li>
    <p><a href="https://docs.google.com/document/d/1vQPA1JSOvfCHjBrkAEDLA1qCqQXe72vGen_1quoHZV8/edit#">Minutes for GPU Web meeting 2020-02-12 Redmond F2F</a></p>
  </li>
</ul>

<p>The previous proposals were some profile of SPIR-V٫ a binary format٫ and Apple’s <a href="https://webkit.org/blog/8482/web-high-level-shading-language/">Web High Level Shading Language</a> proposal٫ which evolved into <a href="https://github.com/gpuweb/WSL">Web Shading Language</a>. Both of these had disadvantages that made them unacceptable to various people. It’s not possible to use SPIR-V directly٫ largely because it has undefined behavior and other unsafe stuff. The Google and Mozilla implementations addressed this by doing a rewrite pass. Conversely٫ Apple’s proposal met with considerable resistance because it didn’t deal with the diversity of GPU hardware in the field. There’s a lot of ecosystem work centered around Vulkan and SPIR-V٫ and leveraging that will help WebGPU considerably.</p>'),('http://thume.ca/2020/09/04/macos-tips/', 'Hard to discover tips and apps for making macOS pleasant', '1599177600000',  13, '
<p>Inspired by a few different conversations with friends who’ve switched to macOS where I give them a whole bunch of tips and recommendations I’ve learned about over many years which are super important to how I use my computer٫ but often quite hard to find out about٫ I decided to write them all down:</p>

<h2 id="hidden-macos-tips">Hidden macOS tips</h2>

<ul>
  <li>Dragging a file or folder onto a file open dialog selects it in the dialog. Similarly dragging onto a “Choose file” button.</li>
  <li>Dragging onto a terminal window pastes the full path of that file/folder</li>
  <li>You can drag the little file/folder icons at the top of many windows٫ useful in combo with previous tips.</li>
  <li>If you hold down <code class="language-plaintext highlighter-rouge">option</code> while clicking the “Scaled” radio button in the Display preferences it’ll give you many more resolution options on external displays. If you want native resolution with no scaling on the built in display you’ll still need an external tool like <a href="https://www.madrau.com/">SwitchResX</a>٫ <a href="https://github.com/lunixbochs/meta/tree/master/utils/retina">retina</a> or <a href="https://www.thnkdev.com/QuickRes/">QuickRes</a>.</li>
  <li>In Finder٫ <code class="language-plaintext highlighter-rouge">return</code> is the shortcut for rename٫ <code class="language-plaintext highlighter-rouge">option</code>+drag copies٫ and <code class="language-plaintext highlighter-rouge">space</code> is quicklook preview</li>
  <li>In Preview if you open the Sidebar in a PDF you can drag pages around including between documents٫ hold option to copy٫ delete pages with backspace. This plus the edit toolbar solves 90% of my PDF munging needs.</li>
  <li>You can select multiple images in Finder and drag them onto the Preview dock icon to open them in one window with a Sidebar where you can quickly flip between them with arrow keys.</li>
  <li>In the Dock preferences there’s a “Prefer tabs when opening documents” setting which automatically groups your windows with window tabs. I find this especially useful for Sublime Text.</li>
  <li><code class="language-plaintext highlighter-rouge">cmd+backtick</code> is like <code class="language-plaintext highlighter-rouge">cmd+tab</code> but between windows of the same app.</li>
  <li>Drag your most frequently used folders into the Finder sidebar for easy access including in file select dialogs.</li>
  <li>In the Finder preferences you can add your computer and drives to the sidebar.</li>
  <li><code class="language-plaintext highlighter-rouge">cmd+shift+4</code> pops up a crosshair to take a screenshot of a region.</li>
  <li>You can <a href="https://www.defaults-write.com/disable-press-and-hold-option-in-mac-os-x-10-7/">disable the popup for accented characters when you hold a key</a> and  <a href="https://apple.stackexchange.com/questions/10467/how-to-increase-keyboard-key-repeat-rate-on-os-x">increase key repeat rate beyond the normal maximum</a>.</li>
  <li>The <code class="language-plaintext highlighter-rouge">open</code> command lets you use the normal macOS file opening mechanism from the command line٫ I most frequently use <code class="language-plaintext highlighter-rouge">open .</code> to navigate to my current directory in my file browser.</li>
  <li>Display “scales” other than 1x or 2x the physical resolution work by rendering at 2x the resolution then down-scaling. This causes apps to need to render a bunch of pixels that are mostly scaled away٫ consuming power and sometimes causing lag. It can also lead to weird aliasing issues in some contexts like shimmering of thin fonts when scrolling٫ as well as rendering in general not being pixel-perfect. I recommend trying to stick to either 1x or 2x scaling if you don’t lose much from it٫ then just adjusting your default web page scale and font sizes.</li>
  <li>Text fields <a href="https://jblevins.org/log/kbd">support a bunch of powerful movement and editing shortcuts based on Emacs</a>.</li>
  <li><code class="language-plaintext highlighter-rouge">option+2</code> types the <code class="language-plaintext highlighter-rouge">™</code> symbol٫ for use with sarcasm™. I probably use this more than the <code class="language-plaintext highlighter-rouge">^</code> symbol. You can open the keyboard viewer (you may have to enable “Show keyboard and emoji viewers in menu bar” in Keyboard Preferences) and hold down option to see all the other symbols you can type like this. The “Emoji &amp; Symbols” pallete is also a great UI for finding handy Unicode characters٫ especially if you use the gear menu to add more symbol category pages.</li>
</ul>

<h2 id="apps">Apps</h2>

<p>A big part of why I prefer macOS is this list of macOS-only native apps which often don’t have adequate substitutes on Linux:</p>

<ul>
  <li><a href="https://kapeli.com/dash">Dash</a>: An amazing fast offline documentation search app. Cuts down a ton on the amount I Google for docs. It’s very quick to use especially when summoned with a keyboard shortcut and has tons of documentation sets.</li>
  <li><a href="https://www.hammerspoon.org/">Hammerspoon</a>: My favorite app for getting the benefits of a Linux tiling window manager. I have home row shortcuts on my left hand bound to switch directly to my most frequently used apps٫ and my right hand to maximize windows٫ move them between screens and tile them to the left and right halves of the screen. <a href="https://github.com/trishume/dotfiles/blob/d12f869062b2fa2d4b3f72eeed2f0e05df5a8657/hammerspoon/hammerspoon.symlink/init.lua">Here’s my config.</a></li>
  <li><a href="https://www.thnkdev.com/Screenie/">Screenie</a>: I only use this for the feature where dragging from the menu bar icon lets you put your most recent screenshot in say messaging apps. It also offers search and things. <a href="https://cleanshot.com/">CleanShot X</a> and <a href="https://zapier.com/zappy">Zappy</a> also look like good screenshot apps but I haven’t tried them yet.</li>
  <li><a href="https://karabiner-elements.pqrs.org/">Karabiner Elements</a>: A powerful keyboard remapping tool. I use it to bind right command to control and caps lock to <code class="language-plaintext highlighter-rouge">ctrl+cmd+option+shift</code> for use with Hammerspoon.</li>
  <li><a href="https://www.alfredapp.com/">Alfred</a>: A mildly better spotlight alternative٫ but for me the main benefit over spotlight is <a href="https://github.com/deanishe/alfred-repos">this workflow for indexing git repos</a>.</li>
  <li><a href="https://cocoatech.com/#/">Path Finder</a>: A fancier version of Finder with multiple panes and various other advanced features. Other third party file managers you may want to try include <a href="https://binarynights.com/">Forklift</a>٫ <a href="https://mac.eltima.com/file-manager.html">Commander One</a>٫ <a href="https://magnumbytes.com/">Nimble Commander</a>٫ <a href="https://marta.yanex.org/">Marta</a> and <a href="https://fman.io/">fman</a>. I use Path Finder because it’s the only one with a good columns view and that’s my favorite view for browsing.</li>
  <li><a href="https://sparkmailapp.com/">Spark</a>: A nice email app with categorized inbox functionality.</li>
  <li><a href="https://bjango.com/mac/istatmenus/">iStat Menus</a>: All sorts of system monitoring in a menu bar. I really like the weather٫ and I also have a combined menu which shows my current power draw in watts and GPU selection in the icon.</li>
  <li><a href="https://tapbots.com/tweetbot/mac/">Tweetbot</a>: A native Twitter client that syncs with a similar IOS client. I really like how it just keeps your position in an infinite scroll where new tweets get added to the top٫ so I can easily read every new tweet from people I follow without seeing any likes٫ algorithmic suggestions or ads.</li>
  <li><a href="https://github.com/ridiculousfish/HexFiend/">Hex Fiend</a>: A really good hex editor/viewer. I like their “Templates” feature where you can describe a binary format with a script and it will overlay the parse tree on the hex view.</li>
  <li><a href="https://iterm2.com/">iTerm2</a>: An alternative Terminal with just <em>so many features</em>. I particularly like the ability to split windows into panes٫ which Apple’s Terminal does not have.</li>
  <li><a href="https://brettterpstra.com/projects/nvalt/">nvAlt</a>: A note taking app that I like٫ although it’s kinda bare-bones and has some bugs. It’s currently unmaintained because the author is working on <a href="https://nvultra.com/">nvUltra</a> which isn’t released yet.</li>
  <li><a href="https://imageoptim.com/mac">ImageOptim</a>: Easy app where you drag image files onto it and it reduces their size.</li>
  <li><a href="https://www.vmware.com/products/fusion.html">VMWare Fusion</a>: Great for running Linux and Windows VMs. The reason I chose it over <a href="https://www.parallels.com/products/desktop/pro/">Parallels</a> is that I knew it had virtualized PMC support٫ which enables using <a href="https://rr-project.org/">rr</a> in VMs. But apparently Parallels also has this in the Pro version٫ and it might be nicer in other ways٫ not sure which is better.</li>
  <li><a href="http://calca.io/">Calca</a>: A weird live math calculator notebook thing with units. The editing can be kind of glitchy but the basic functionality is really cool. <a href="https://soulver.app/">Soulver</a> is a similar but more expensive app with a nicer UI but less powerful underlying calculator language.</li>
  <li><a href="https://developer.apple.com/download/more/">Quartz Debug</a>: There are some apps that reduce your battery life in an insidious way where it doesn’t show as CPU usage for their process but as increased <code class="language-plaintext highlighter-rouge">WindowServer</code> CPU usage. If your <code class="language-plaintext highlighter-rouge">WindowServer</code> process CPU usage is above maybe 6-10% when you’re not doing anything٫ some app in the background is probably spamming 60fps animation updates. As far as I know you can only figure out which app is at fault by getting the Quartz Debug app from <a href="https://developer.apple.com/download/more/">Apple’s additional developer tools</a>٫ enabling flash screen updates (and no delay after flash)٫ then going to the overview mode (four finger swipe up) and looking for flashing. This same problem can also occur on Linux and Windows but I don’t know how much power it saps there.</li>
  <li><a href="https://www.sublimetext.com/">Sublime Text</a> and <a href="https://www.sublimemerge.com/">Merge</a>: These aren’t exactly macOS-only apps but they’re some of my favorite apps and they integrate excellently with macOS so I’m putting them here anyways.</li>
</ul>

<h2 id="bonus-browsers">Bonus: Browsers</h2>

<ul>
  <li>Middle click opens links in a new tab and middle clicking on a tab closes it</li>
  <li>There’s lots of lesser-known handy shortcuts: cmd/ctrl+l focuses the search filed٫ cmd/ctrl+w closes a tab</li>
  <li><a href="https://vimium.github.io/">Vimium</a> and <a href="https://www.octotree.io/">OctoTree</a> are my favorite browser extensions.</li>
  <li>I believe YouTube in Chrome and Firefox default to VP8/9 video codecs which can’t be hardware-decoded so use lots of CPU and thus battery power especially at 2x speed or high resolutions. The <a href="https://github.com/alextrv/enhanced-h264ify">h264ify</a> family of extensions can force usage of GPU-supported h264 codecs. This can close some of the battery life gap with Safari.</li>
  <li>If you use Safari٫ Chrome and Firefox have much better sounding audio resampling for watching videos on 1.5x or 2x speed. This is the only reason I don’t use Safari.</li>
</ul>

<h2 id="bonus-ios">Bonus: IOS</h2>

<p>IOS also has a bunch of hidden UI features٫ especially if you have a medium-old model of iPhone that still has force touch sensors.</p>

<ul>
  <li>Swiping left and right on the home bar at the bottom of the screen on phones since the iPhone X quickly switches between recent apps. This is absolutely essential to how I use my phone and such a huge boost to multitasking fluidity I feel bad for all the people who don’t know about it.</li>
  <li>Force or long pressing on the keyboard (maybe just the spacebar on some phones)٫ brings up a moveable cursor in text fields.</li>
  <li>If you have force touch try it on everything٫ tons of widgets in the pull down settings have force touch features٫ notifications do٫ links do.</li>
  <li>I’ve tried a lot of calculator apps and Kalkyl is my favorite for launch time and UI design for quick simple calculations. I also recommend Unread for RSS٫ and Apollo as possibly the best Reddit experience on any platform.</li>
  <li><a href="https://isitsnappy.com/">Is It Snappy</a> lets you use an IOS device’s high speed camera to measure full-system interaction latency and find out that you have a slow keyboard٫ mouse or monitor. I have not found a similar app for Android.</li>
  <li>Not exactly a software tip٫ but a non-obvious purchasing option: I contend buying an iPhone X on Ebay offers outstanding price/quality ratio even in 2020. It has basically the same screen/form factor/build quality as an iPhone 11 Pro٫ and I find it plenty fast and the camera sufficiently good٫ and those are basically the only things that improved. You even get force touch٫ which I really like as having lower latency than the more press-and-hold “3D Touch”. Meanwhile it’s less than half the price. I got mine discounted after the iPhone XS replaced it٫ and if mine broke I’d probably just buy another one now.</li>
</ul>

<h2 id="bonus-the-chromium-catapult-trace-viewer">Bonus: The Chromium Catapult Trace Viewer</h2>

<p>The motivation to write this post was caused by a conversation with a friend about macOS٫ which was in turn kicked off by <a href="https://twitter.com/trishume/status/1302069073640120320?s=20">a tweet</a> about the <a href="https://aras-p.info/blog/2017/01/23/Chrome-Tracing-as-Profiler-Frontend/">The Chromium Trace Viewer (AKA Catapult)</a>. Catapult is super easy to get started with for visualizing trace data and I know lots of different people and projects who use it. Almost none of them know about this incredibly helpful first tip until I tell it to them٫ so they’re stuck with having to switch to the zoom tool in the toolbar:</p>

<ul>
  <li>Use <code class="language-plaintext highlighter-rouge">alt+scroll</code> to zoom. This really ought to be in noticeable text on their UI not buried in a shortcuts pane you have to press <code class="language-plaintext highlighter-rouge">?</code> to see.</li>
  <li>The search bar in the top left searches not only names but also arguments values٫ which you can use to search for IDs or add special tags like <code class="language-plaintext highlighter-rouge">top100</code> for the 100 slowest events. Press <code class="language-plaintext highlighter-rouge">f</code> to zoom to a span once you’ve selected it with the search arrow buttons.</li>
  <li>The JSON event format also supports “flow” arrows٫ which lets you draw arrows between your boxes to visualize dependencies.</li>
  <li><a href="https://perfetto.dev/">Perfetto</a>٫ <a href="https://github.com/wolfpld/tracy">Tracy</a> and <a href="https://www.speedscope.app/">Speedscope</a> can all visualize the same JSON format with different UIs and potentially without a trace size cap.</li>
</ul>
'),('http://thume.ca/2020/08/15/ropshipai/', 'Reverse engineering an AI spaceship game at DEF CON CTF', '1597449600000',  13, '
<p>I recently played with <a href="[Samurai](https://ctftime.org/team/1937)">Samurai</a> in the DEF CON CTF 2020 finals٫ and want to write about an incredibly cool challenge I worked on called <code class="language-plaintext highlighter-rouge">ropshipai</code>. It involved reverse engineering a binary to discover the architecture and format of a neural network٫ creating a network to control your spaceship in an arena against all the other teams٫ then doing a <a href="https://en.wikipedia.org/wiki/Return-oriented_programming">ROP</a> exploit using a buffer overflow to get more capacity for a smarter AI. I hope this article can give you a taste of what high level security CTF contests can be like and why they’re so fun.</p>

<p>Here’s what it looked like near the end of the contest٫ I cherry-picked a round where our final bot (labeled ‘X’ in light grey) won:</p>
<video controls="" width="660" autoplay="" muted="" loop="">
    <source src="/assets/postassets/ropshipai/v313-trim2.mp4" type="video/mp4" />
    Sorry٫ your browser doesn"t support embedded videos.
</video>

<h2 id="part-1-reverse-engineering">Part 1: Reverse engineering</h2>

<p>We were given a download which included a PyGame UI to simulate the game. The UI called out to an x86 binary which we figured out computed the move for a team’s bot using an input file. We figured that file was probably the same thing the “Upload AI” button on the challenge’s web portal accepted. There was a challenge a previous year called “ropship” that involved a similar arena with bots controlled by return-oriented programming and we assumed the “AI” added this year meant a neural net٫ but didn’t yet see any of the organizers’ usual Tensorflow.</p>

<p>So we started reversing the binary٫ and my teammates found various functions that seemed to do floating point math and loops٫ which they started using <a href="https://www.hex-rays.com/products/decompiler/compare/compare_vs_disassembly/">IDA’s decompiler</a> on and matching up with common neural net functions. They quickly found <a href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/">ReLU</a>٫ then an iterative function that we figured out produced results matching <code class="language-plaintext highlighter-rouge">e^x</code>. We also found a function that at first appeared to be <code class="language-plaintext highlighter-rouge">1/(1-e^(-x))</code>٫ which was confusing since that’s almost <a href="https://en.wikipedia.org/wiki/Sigmoid_function">a sigmoid</a> but with subtraction instead of addition. I took a look in <a href="https://binary.ninja/">Binary Ninja</a> and it looked like addition to me٫ it turned out IDA had just decompiled it wrong and it <em>was</em> a sigmoid.</p>

<p>That left the big function with lots of math and loops٫ which we assumed was the main network evalutation function. I got to work using the new decompiled view in Binary Ninja to try and decipher what it was doing and what the structure of the inputs we had to give it were٫ while my teammate <a href="https://twitter.com/samczsun">samczsun</a> figured out the input file parsing code that set up those inputs. At the same time٫ other teammates figured out the simulator and what inputs it could feed to the network.</p>

<p><a href="/assets/postassets/ropshipai/reversing.png"><img src="/assets/postassets/ropshipai/reversing.png" alt="Reversing in binja" /></a></p>

<p>I reverse-engineered all the pointer arithmetic and simplified things to write out a pseudo-C version of the network evaluation function. It seemed to evaluate a number of lineary layers with biases٫ each followed by either a sigmoid or ReLU activation function (chosen by the input file). The input parsing code hard-coding the number of hidden layers between the input and output layer equal to 1٫ which was weird and fishy.</p>

<p>Once we had collectively figured out how everything fit together٫ we wanted to get a bot out there and earning points as fast as possible. First <a href="https://twitter.com/lunixbochs">aegis</a> wrote a Python network serializer script and deployed a bot that just set the bias on going forward to run us into the wall so we were a smaller target and not in the expected position for anyone managing to shoot. The next bot had hand-designed weights in the matrices to rotate the ship unless it was ready to fire in which case it shot. We weren’t quite the first to upload a non-empty network (an empty file just shot the wall) but we were something like 2nd.</p>

<h2 id="part-2-training-a-better-network">Part 2. Training a better network</h2>

<p>While <code class="language-plaintext highlighter-rouge">aegis</code> worked on making a smarter hand-coded bot٫ I started work on training a real neural net to be a better AI. An alternative I brought up was to write something to compile a domain specific language to weights٫ using the fact I had learned about in my university machine learning course that you could approximate any function using only one hidden layer by using <a href="http://neuralnetworksanddeeplearning.com/chap4.html">a specific method of engineering weights</a> to set the value of the output for different regions of input. However٫ given that both <code class="language-plaintext highlighter-rouge">aegis</code> and I had done some deep learning training before we figured it would be easier to just use gradient descent.</p>

<p>I fired up a <a href="https://jupyter.org/">Jupyter</a> notebook٫ replicated the architecture٫ and thought of a way to make a basic AI by writing a Python function to output what we wanted the AI to do given various inputs٫ and feeding lots of randomly generated input vectors through the function and training the neural net to match those actions like a normal supervised classifier.</p>

<p>Unfortunately it was harder than I expected and it took annoyingly long tuning hyperparameters and how my training setup worked before I even managed to train a network to do one action if the single input was less than <code class="language-plaintext highlighter-rouge">0.5</code> and another if it was greater:</p>

<p><img src="/assets/postassets/ropshipai/pointfive.png" alt="PointFiveNet" /></p>

<p>Next I worked on modifying <code class="language-plaintext highlighter-rouge">aegis</code>’s code٫ which wrote out his hand-coded weights in the correct format٫ to take the weights from my trained model. Unfortunately the first network I exported this way just didn’t do anything when run in the simulator. So I spent some time investigating the polarity of how PyTorch did biases٫ trying out different combinations and reasoning through whether
I wanted to write things out in row-major or column-major order٫ all to no avail. I even wrote some code to export aegis’s hand-coded weights using my exporter٫ and that worked but my model still didn’t.</p>

<p>So after around 2 hours I tried using GDB to trace the execution of my model through the binary while referencing the disassembly in Binary Ninja٫ to see what was going wrong. To my surprise it seemed to exit before it even ran my model٫ and exited with a weird error code. I bisected it down to find a validation function that limited hidden layer size to a 2x2 matrix٫ way too small to train anything significant. I posted the bad news in Slack and it turned out <code class="language-plaintext highlighter-rouge">samczsun</code> had figured this out a while ago but in the hectic phase of everyone working on different reverse engineering in parallel٫ the rest of us didn’t hear.</p>

<h2 id="part-3-the-exploiting-and-fancier-bots">Part 3: The exploiting and fancier bots</h2>

<p>It looked like the “rop” in the challenge name wasn’t just a callback to last year’s “ropship” challenge and we’d have to exploit our way into more model capacity. We had already found a buffer overflow on the stack with unbounded user-controlled contents٫ in the code which fetched the inputs to feed to the network. It seemed like we could craft a ROP exploit to manipulate the size parameters of the network to change them after they had been validated. ROP is a technique where if you can overwrite the address the function call should return to on the stack٫ you can make it return anywhere you want٫ allowing you to execute any sequences of suffixes of any functions in the program to perform your exploit. There was a <code class="language-plaintext highlighter-rouge">seccomp</code> policy and some weird custom “ASLR” and “sandboxing” that simultaneously made some ROP a bit easier while keeping things contained so we couldn’t easily just break out and exploit the challenge or run arbitrary code as our AI.</p>

<p>I’ve never done ROP so <code class="language-plaintext highlighter-rouge">aegis</code> and <code class="language-plaintext highlighter-rouge">samczsun</code> started work on that while I patched out the validation in my personal copy of the binary and got to work on training a better bot to work with the eventual exploit. In the mean time <code class="language-plaintext highlighter-rouge">chainsaw10</code> had written some better Python AI functions using a patched simulator to test them out٫ which I worked on training a model to match. It was again surprisingly difficult. I had a lot of trouble getting it to be able to do actions like shielding٫ which only needed to happen on around 5% of random inputs. The network would just always output <code class="language-plaintext highlighter-rouge">0.0</code> for those actions except on some lucky training runs. I suspect something was going wrong with my initialization or gradients such that on most runs the shield output would fall into a place it could never get a gradient signal to recover from.</p>

<p>Three hours later at around 6am I managed to get a basic AI trained which turned towards the closest bot٫ moved towards it٫ shot at it and shielded. At that point I went to sleep٫ the contest had been on a 9 hour pause and I intended to wake up again before it restarted٫ when the exploit would hopefully be finished.</p>

<p>I ended up sleeping past my alarm until 2 hours after the contest started again. When I woke up٫ <code class="language-plaintext highlighter-rouge">aegis</code> and another teammate had finished the ROP exploit and wrote a converter that added the exploit to the latest bot I trained٫ and it was deployed and doing decently! The exploit development had hit some snags but eventually landed on something which overwrote the return address to restart the execution of the function with the buffer overflow multiple times to get various things overwritten٫ to patch in a new network after the hidden size validation had passed on the original overflowing network.</p>

<p>Unfortunately the bot we uploaded was still kind of crappy٫ it knew how to move around the arena towards a target but it kept doing that until it was right on top of them and then often died if the opponent then shot us at point blank range. It also only used the sine of the angle to the enemy so due to an ambiguity it would sometimes run in the exact opposite direction.</p>

<p>So <code class="language-plaintext highlighter-rouge">aegis</code> and I worked on a better training setup with a GPU box and larger networks. In the mean time <code class="language-plaintext highlighter-rouge">chainsaw10</code> had improved the AI function to not get too close to enemies and also be able to dodge bullets. We still had tons of trouble reliably training a network to match the function٫ but eventually ended up with a slightly better version of our previous bot and a version without very good aim trained on our new bot code. In simulations with our own bots the very accurate but simpler bot did better٫ so we uploaded that٫ but an hour later and one hour before the end of the contest I saw it wasn’t actually doing well against the other teams٫ so I uploaded the more sophisticated bot and it did much better and even managed to win a few rounds. It still had crappy aim and sometimes did the wrong thing though٫ and it had taken a lot of tweaking to get it to learn to shield.</p>

<h2 id="postscript-compiling-to-neural-nets">Postscript: Compiling to neural nets</h2>

<p>In hindsight given how much trouble we had training our small neural networks٫ in what seemed like it should have been a really easy task٫ it seems like the best approach was to use the <a href="http://neuralnetworksanddeeplearning.com/chap4.html">universal function approximation proof style tricks</a> to write a compiler from a logic DSL to network weights that exactly implemented the function. I’m still not sure whether we had a hard time training because training shallow networks with small capacity is just hard٫ or there was some technique we were missing to get our training to work well.</p>

<p>In the last two hours of the contest I worked on a prototype of the compiler approach for fun and managed to get it mostly working. I was using only one hidden layer so my input DSL required providing some constant thresholds on inputs٫ <code class="language-plaintext highlighter-rouge">AND</code> gates on those threshold signals٫ and then each output was an <code class="language-plaintext highlighter-rouge">OR</code> of some of the <code class="language-plaintext highlighter-rouge">AND</code> results. This was enough to implement any truth table on thresholds٫ but it was incredibly wasteful of network capacity to do so and the flattening of the decision tree to a truth table still needed to be done manually. I had some ideas for how to automatically flatten a decision tree Python function into a truth table though using overloaded operators that detected thresholding on the inputs and breadth-first searched to explore the space of outputs٫ but the contest ended and I wanted to catch up on sleep after that.</p>

<p>I talked to my friend on team <a href="http://pwning.net/">PPP</a>٫ since PPP had a bot with really good clean behavior. He said that PPP did go the route of implementing a compiler to network weights٫ which could compile an arbitrary decision tree that included vector space arithmetic. They did it without flattening the tree by using multiple hidden layers٫ which the exploit allowed you to use. Unfortunately while as far as we could tell we should have been able to use multiple hidden layers٫ when we tried a multi-layer network it failed to do anything٫ and we never bothered to figure out why٫ since our training process worked about as well with one hidden layer.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Overall this is the challenge I had the most fun with this DEF CON CTF finals٫ it combined reverse engineering٫ neural nets and exploitation٫ and had different possible valid approaches to solve it. It was super fun to upload an AI and see it dodge bullets and beat other teams based on a tower of hard-won knowledge and code from hours of work reverse engineering and tinkering. In general I get really into DEF CON CTF challenges because they’re a great combination of tractable problems I can work with friends on with fun competitive time pressure٫ that also are really interesting and difficult to make me feel like I’m exercising all of my available skill.</p>

<p>This was only the last challenge I worked on. Earlier in the contest I worked on <a href="https://archive.ooo/c/rorschach/372/">rorschach</a> helping <code class="language-plaintext highlighter-rouge">aegis</code> by figuring things out and coming up with tweaks to make our black box hill climbing solver exploit a neural net classifier faster٫ and coming up with defensive checks against other teams’ attacks. In the middle I did miscellaneous reverse engineering and spent hours working on attacks for exploits teams patched before we were done implementing them٫ and an AI for another multi-team game that closed before I could deploy it. My other AI did have the best dang debugging visualizations a rushed CTF hack has ever seen though thanks to my affinity for <a href="http://holoviews.org/">HoloViews</a>٫ which might have had a little to do with why it was too late…</p>

<video controls="" width="660" autoplay="" muted="" loop="">
    <source src="/assets/postassets/ropshipai/rhgai.mp4" type="video/mp4" />
    Sorry٫ your browser doesn"t support embedded videos.
</video>

'),('http://thume.ca/2020/07/19/my-youtube-tier-list/', 'My tier list of interesting YouTube channels', '1595116800000',  13, '
<p>I watch a lot more YouTube than I do any other type of video content٫ and my favorite type of YouTube videos are interesting ones. I hesitate to call them “educational”٫ because they’re often not necessarily trying to teach٫ but to me the category distinction is they’re trying to be interesting in some way that pertains to the real world rather than just purely entertaining like video game content or comedy.</p>

<p>I often find myself recommending these channels to friends٫ so I figured I might as well write up my endorsements٫ and I made it a <a href="https://en.wikipedia.org/wiki/Tier_list">tier list</a> since I love the format. There’s a huge variety of really cool and impressive channels out there with kinds of content you can’t find anywhere else٫ and I’ve watched a lot of them for years and want to highlight them. The tier choices can be kinda arbitrary and I didn’t pay any attention to the ordering within tiers. Note that this is a tier list of <em>my favorite interesting</em> YouTube channels:</p>

<ul>
  <li><strong>“my”</strong>: These are ordered based on what I feel like endorsing/recommending٫ other people with different interests may place them higher or lower٫ and some really well-made popular channels are lower down just because they don’t capture me as much.</li>
  <li><strong>“favorite”</strong>: Even once we get down to “D tier” they’re still great stuff I watch regularly and above everything I’ve encountered and wasn’t into</li>
  <li><strong>“interesting”</strong>: There’s other YouTube channels I watch and enjoy٫ like some video game channels٫ which are more pure entertainment and aren’t included here.</li>
</ul>

<p>My blog posts tend to be about programming but I barely watch any programming channels. I mostly watch all sorts of random interesting channels on everything from machining to videography. Most of these channels are pretty accessible to anyone interested even if they aren’t versed in the subject٫ while still often targeting something obscure or impressive rather than always basic stuff٫ which is something that I think YouTube channels tend to do better than blogs. But on the flipside this makes most programming channels less interesting to me٫ since I am versed in the subject.</p>

<h1 id="s-tier-masterpieces">S Tier: Masterpieces</h1>

<p>The channels in this tier are some of my favorite things on the internet. They all only release videos every few weeks or months but that’s because they’re all a single person putting monumental effort into each one. When a video comes out on one of these channels its the highlight of my day. For a video to be this tier it needs to be fascinating٫ well-produced٫ demonstrate incredible skill I can be in awe of٫ and be something I’d pay at least $5/video (and often more) if they started paywalling it now. I subscribe to all of these channels on Patreon٫ except for Kiwami Japan because they don’t have one.</p>

<p>Despite having hundreds of thousands to millions of viewers٫ none of these channels would ever have been green-lit as a TV show as-is٫ because they’re too weird or niche or technical. They also can only really work as well as they do in the video format٫ and got their start on YouTube. I’m happy that the modern internet allows channels like these to not only exist but often make a living.</p>

<h2 id="clickspring"><a href="https://www.youtube.com/channel/UCworsKCR-Sx6R6-BnIjS2MA">Clickspring</a></h2>

<p><a href="https://www.youtube.com/watch?v=8OViP9AR2HE"><img src="/assets/postassets/youtube/clickspring.jpg" alt="Clickspring thumbnail" /></a></p>

<p>Clickspring is a channel about clockmaking٫ and watching it is wireheading on pure craftsmanship. I’ve never done any machining and don’t plan on ever making a clock٫ but his videos along with everything he makes in them are gorgeous examples of making everything with care and a commitment to excellence. This shows through in everything he does٫ from <a href="https://www.youtube.com/watch?v=5sAw4Q1PM8Y">making custom screws with stunning blue oxide finish and hand-rounded interior ends that aren’t even visible when assembled</a> to <a href="https://www.youtube.com/watch?v=Jk_rCm1rAeg">doing original research and building some authentic ancient tools</a> for his <a href="https://www.youtube.com/watch?v=ML4tw_UzqZE">reconstruction of the Antikythera mechanism</a>. He puts the same care into his videos as the work itself: the camera shots and lighting are beautiful٫ the machining operations are seamlessly sped up at the right times to fit in the video but show the key moments٫ and he often includes nice composited overlays of the CAD model on top of the raw stock so you can understand what he’s doing٫ and the narration٫ music and sounds of the machining are excellently done to give the videos a relaxing feel. Every Clickspring video is just a delightful experience to watch.</p>

<p>He also does videos without narration that just beatifully show all the machining and other work that goes into making something٫ <a href="https://www.youtube.com/watch?v=3PwAQZNLy0I">this video being the most impressive example</a>. He has a second channel called <a href="https://www.youtube.com/channel/UC9UjDtkpr2I-5G51vMJZvnA">Clickspring Clips</a> where he posts 2-4 minute non-narrated videos showing the making of one interesting part of his larger projects. <a href="https://www.patreon.com/clickspring/posts">His Patreon</a> also has many exclusive videos once you watch all the public ones.</p>

<h2 id="applied-science"><a href="https://www.youtube.com/channel/UCivA7_KLKWo43tFcCkFvydw">Applied Science</a></h2>

<p><a href="https://www.youtube.com/watch?v=JV4Fk3VNZqs"><img src="/assets/postassets/youtube/appliedscience.jpg" alt="Magnets and flame video" /></a></p>

<p>Ben Krasnow’s channel Applied Science has been the flagship channel of engineering and science YouTube for many years. In every video he explains some new and interesting piece of science and engineering he’s replicated in his shop. He’s made <a href="https://www.youtube.com/watch?v=X24np30GS2o">aerogel</a>٫ <a href="https://www.youtube.com/watch?v=Lg__B6Ca3jc">a water jet cutter</a>٫ <a href="https://www.youtube.com/watch?v=9OEz_e9C4KM">a plasma sputtering chamber</a>٫ an <a href="https://www.youtube.com/watch?v=rpHYBz7ToII&amp;t=5s">EDM drill</a>٫ <a href="https://www.youtube.com/watch?v=K_N_h_mKf-4">air bearings</a>٫ <a href="https://www.youtube.com/watch?v=Z2o_Sp2-aBo">an electroluminescent display</a>٫ an <a href="https://www.youtube.com/watch?v=_zoeeR3geTA">LCD</a>٫ and the source of his earliest publicity: <a href="https://www.youtube.com/watch?v=VdjYVF4a6iU">a scanning electron microscope</a>. He’s a truly prolific and incredible engineer who works with all kinds of electronics٫ machining٫ chemistry٫ physics and software. Every video leaves me in awe of him. Often he’ll be the first non-professional to try recreating something based on a procedure from papers and have to do dozens of failed experiments before <a href="https://www.youtube.com/watch?v=Xr1AiExSAnU">making a video</a> <a href="https://www.youtube.com/watch?v=mUcUy7SqdS0">documenting the process and all the extra considerations</a>. His videos and skill are incredible and I’ve learned a lot about the process of scientific lab work from watching them.</p>

<h2 id="captain-disillusion"><a href="https://www.youtube.com/channel/UCEOXxzW2vU0P-0THehuIIeg">Captain Disillusion</a></h2>

<p><a href="https://www.youtube.com/watch?v=LuM1IXl66B8"><img src="/assets/postassets/youtube/captaind.jpg" alt="Gyro Drop" /></a></p>

<p>Captain Disillusion has been on YouTube for 12 years now٫ originally in obscurity but gradually growing to millions of viewers. He goes over trick and hoax viral videos and explains the visual effects used to make them. The thing that’s incredible is the production value: Costumes٫ makeup٫ well-written scripts٫ and a ridiculous density of impressive visual effects. Captain Disillusion is what happens when an incredibly talented and driven visual effects artist puts an entire month of full time work into every single 5 minute video. He’s done streams and time-lapses before of him spending dozens of hours on a 3 second visual effect for a throwaway gag.</p>

<p>A <a href="https://www.youtube.com/watch?v=eKFrZNXB29M">typical video</a> consists of a well-written and edited intro of him introducing a faked video٫ doing a detailed breakdown of all the components of the effect but quickly thanks to amazing visual aid footage٫ then him just one-upping the original video by doing the effect so much better than anyone else has ever done it٫ without the tells he went over. Here’s <a href="https://www.youtube.com/watch?v=9vncG0IP9qU">some</a> <a href="https://www.youtube.com/watch?v=rsXQInxxzBU">other</a>٫ <a href="https://www.youtube.com/watch?v=Hy6vddbQa8Q">good</a> <a href="https://www.youtube.com/watch?v=LuM1IXl66B8">ones</a> but really every single one is excellent.</p>

<h2 id="kiwami-japan"><a href="https://www.youtube.com/channel/UCg3qsVzHeUt5_cPpcRtoaJQ">Kiwami Japan</a></h2>

<p><a href="https://www.youtube.com/watch?v=AMYKQc-MVIM"><img src="/assets/postassets/youtube/kiwami.jpg" alt="Sharpest Bread Kitchen Knife" /></a></p>

<p>This is a weird and wonderful channel that to me really exemplifies what’s great about YouTube. Most videos are of the form “sharpest X kitchen knife in the world” with a thumbnail of a hand holding a weird knife in the same pose. Some examples of X are <a href="https://www.youtube.com/watch?v=WZJ7nSdIbwk">“Fungi”</a>٫ <a href="https://www.youtube.com/watch?v=RUlHhrL_Zj8">“Paper”</a>٫ <a href="https://www.youtube.com/watch?v=t557dPspLxo">“milk”</a>٫ <a href="https://www.youtube.com/watch?v=MeNR0guNn70">“Pasta”</a>٫ <a href="https://www.youtube.com/watch?v=539OnO-YImk">“Underwear”</a>٫ and <a href="https://www.youtube.com/watch?v=zUCEMjhsvaU">“smoke”</a>. I originally ignored suggested videos from this channel because I assumed they were some weird click-bait that didn’t really make a knife from those materials٫ and that was tragic because he really does and it’s amazing.</p>

<p>Every video has no talking or words except for occasional subtitles٫ and follows the process starting from the raw material٫ demonstrating all the processing steps required to make a hard substance out of it٫ casting a knife blank٫ sharpening it٫ and testing it. At some point early in the channel’s history someone must have commented that the videos were like ASMR videos because after that he got a high quality microphone and puts a lot of emphasis on the sounds.</p>

<p>The coolest part is he’s clearly really good at materials science and every video has amazing steps all done in his apartment. Lets take the <a href="https://www.youtube.com/watch?v=pFG-nXUw6Ts">“sharpest Seawater kitchen knife in the world”</a> video as an example: It starts with a shot of him getting huge jugs of seawater from the ocean and collecting shells on the beach. At home he boils the seawater into salt and a solution he labels “magnesium chloride”. Then he puts a seashell on top of a charcoal briquette and puts it in an insulating firebrick box in his home microwave-oven-thing and cuts to it coming out totally calcified (apparently you can do that without a furnace??). He grinds it up with the subtitle “quicklime”٫ puts it in water and uses a thermal camera to show the exothermic reaction to get slaked lime. Cut to him combining a concentrated sea brine with the lime water to get “magnesium hydroxide + salt”. He adds water to dissolve the salt and filters out the magnesium hydroxide٫ combines it with the magnesium chloride from earlier٫ dries it٫ uses his handy durometer to show it fails a hardness test. He pops the magnesium hydroxide in his charcoal microwave furnace to get “magnesium oxide” and shows that this time when combined and dried it yields a very hard rock-like substance. Cut to him pouring a bunch of it in a rectangular plastic box٫ drying it and sawing out a knife shape. Then his famous sharpening sequence with increasingly fine knife stones٫ followed by the ever-present cucumber chopping test (complete with weird cucumber reveal out of godzilla-themed rubber gloves). He finishes by showing that the “magnesium cement” (<a href="https://en.wikipedia.org/wiki/Sorel_cement">Wiki link</a>) doesn’t immediately dissolve in watera and that it can also be combined with dirt to make bricks.</p>

<p>I can’t see anything remotely like this every being green-lit as a TV series٫ but every video is brilliant and relaxing٫ they all get millions of views with zero advertising spend٫ because everyone likes them and recommends them to friends and algorithmic recommendations respond to that in a way that human TV producers wouldn’t have the guts to. People complain about the “YouTube algorithm”٫ but at this kind of thing it truly shines.</p>

<h2 id="stuff-made-here"><a href="https://www.youtube.com/channel/UCj1VqrHhDte54oLgPG4xpuQ">Stuff Made Here</a></h2>

<p><a href="https://www.youtube.com/watch?v=7zBrbdU_y0s"><img src="/assets/postassets/youtube/stuffmadehere.jpg" alt="Haircut robot" /></a></p>

<p>Stuff Made Here is the newest channel to enter S tier. When YouTube first recommended one of his videos to me 4 months ago the channel had just started with a few videos and I thought “huh how is this brand new channel getting hundreds of thousands of views”٫ then I watched the video and thought “okay wow٫ apparently if you make really excellent stuff from the start it can become popular on YouTube super fast”. He just makes really interesting and impressive videos where he uses his skill in many different disciplines of engineering to make cool stuff and then gives interesting descriptions of all the considerations٫ testing٫ engineering٫ fabrication and failures that went into making it.</p>

<p>For <a href="https://www.youtube.com/watch?v=FycDx69px8U&amp;t=1s">his most popular video</a> he makes a basketball backboard that always directs the ball into the hoop. He designs and builds a custom mechanism to move the backboard to any distance and angle using rods that minimize the weight on the board so it can move quickly٫ describing the kinematic principles and how he constructed it using CNC plasma cut and spot welded sheet metal with 3D printed joints. Then he describes the clever custom algorithm for filtering out the basketball from other moving objects in the depth camera by fitting a ballistic curve to all possible object trajectories٫ as well as the software for extrapolating and calculating the required backboard position. The way he did everything is quite impressive and٫ like all his projects٫ he did it in only a few weeks while also having a day job.</p>

<p>What sets him apart from other YouTube makers is not only the skill in so many different areas that his projects display٫ but also the detailed explanations of the entire engineering process including the considerations٫ math٫ algorithms and failures rather than just the fabrication. If this sounds good to you٫ you should watch every single one of his videos including the ones that might not look that interesting. There’s not that many yet٫ but there might be soon since he somehow has also been managing to post more frequently than anyone else in my S tier (have I mentioned he also has a day job!?).</p>

<h1 id="a-tier-highly-recommended">A Tier: Highly recommended</h1>

<p>These channels are still quite excellent٫ but fall short on one or more aspects that would make me feel like putting them in S tier. I still highly recommend you check them out if they sound interesting though٫ they’re really great and I’m still very excited when I see one of them post a new video!</p>

<dl>
  <dt><a href="https://www.youtube.com/channel/UCVSHXNNBitaPd5lYz48--yg">Tech Ingredients</a></dt>
  <dd>Long and detailed technical videos of interesting projects demonstrating cool science and engineering concepts. They build really high quality demonstration pieces for each video and lots of the concepts they look into are little known ones like <a href="https://www.youtube.com/watch?v=LS3GQk9ETRU">magnetohydrodynamics</a>٫ how <a href="https://www.youtube.com/watch?v=jxOzpPJbnTI">helium is an incredibly good sound suppressor</a> and <a href="https://www.youtube.com/watch?v=zcpDGKH9_SE">plasma physics</a>. The main presenter is super knowledgeable and every video has some really interesting things. It’s a bit slow paced but I fix that by always watching on 2x speed. They also just posted a <a href="https://www.youtube.com/watch?v=bRr8lrUc-GI">Best Of clips compilation video</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCMOqf8ab-42UUQIdVoKwjlQ">Practical Engineering</a></dt>
  <dd>Explains interesting things from civil engineering often with cool models and demonstrations. I found <a href="https://www.youtube.com/watch?v=zFdyqTGx32A">this one on hydraulic ram pumps</a> really cool.</dd>
  <dt><a href="https://www.youtube.com/channel/UCYA1VjSKXgNVh03wjw_HSRA">Dan Gelbart</a></dt>
  <dd>Dan is an incredible engineer who made a fortune selling companies and now has an amazing machine shop٫ with lots of tools he’s built or modified himself. He doesn’t post videos very often but the main draw of his channel is the 7 year old 19-part series on tools and techniques for building prototypes. It’s a masterpiece of incredible knowledge٫ impressive designs and great tips. I recently rewatched the whole series.</dd>
  <dt><a href="https://www.youtube.com/channel/UCFtc3XdXgLFwhlDajMGK69w">NightHawkInLight</a></dt>
  <dd>Videos of small interesting projects <a href="https://www.youtube.com/watch?v=tcV1EYSUQME">beautifully</a> filmed and explained. I particularly liked this one about <a href="https://www.youtube.com/watch?v=ThBkzEfjVl0">making a carbon filament light bulb</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCV5vCi3jPJdURZwAOO_FNfQ">The Thought Emporium</a></dt>
  <dd>Lots of different types of DIY science projects including DIY genetic engineering. In his craziest video he <a href="https://www.youtube.com/watch?v=J3FcbFqSoQY">engineers a benign virus to put lactase genes</a> in his intestines to cure his lactose intolerance for months (most of the video is explaining why what he did was reasonably safe). More recently he’s been uploading long live streams but look back a bit for the shorter science project videos.</dd>
  <dt><a href="https://www.youtube.com/channel/UCAL3JXZSzSm8AlZyD3nQdBA">Primitive Technology</a></dt>
  <dd>Guy goes out into the woods in Australia and makes pottery٫ metal٫ shelter٫ tools and materials starting with no tools at all. This video about <a href="https://www.youtube.com/watch?v=RnvtXikwrIU">making a kiln to smelt iron</a> is really good.</dd>
  <dt><a href="https://www.youtube.com/channel/UCFhXFikryT4aFcLkLw2LBLA">NileRed</a></dt>
  <dd>Beautiful and interesting videos about chemistry accessible to someone who knows very little about chemistry. <a href="https://www.youtube.com/watch?v=RS7gyZJg5nc">This recent video about making superconductors</a> is particularly good.</dd>
  <dt><a href="https://www.youtube.com/channel/UC5NO8MgTQKHAWXp6z8Xl7yQ">This Old Tony</a></dt>
  <dd>Really well-produced entertaining and funny machine shop and engine videos that usually use some small machining project to explain a concept or technique.</dd>
  <dt><a href="https://www.youtube.com/watch?v=975r9a7FMqc">Steve Mould</a></dt>
  <dd>Interesting science concept explanation videos with demonstrations. I was waffling between A and B tier but <a href="https://www.youtube.com/watch?v=975r9a7FMqc">this phenomenally cool recent video on optical rotation</a> blew me away and secured his spot in A tier.</dd>
</dl>

<h1 id="b-tier-very-good">B Tier: Very Good</h1>

<p>At this point we’re still in the realm of high quality channels where I’ll immediately watch any new video they put out. Some of these channels have occasional top quality videos that would put them in A tier if they posted more regularly or had more consistent quality.</p>

<dl>
  <dt><a href="https://www.youtube.com/channel/UCjgpFI5dU-D1-kh9H1muoxQ">The Hacksmith</a></dt>
  <dd>Skilled engineers with a substantial budget and machine shop try to make real life versions of gadgets from fiction. Their main audience is kids and non-technical people and it shows٫ but many of their videos have pretty cool engineering٫ and their build montages are neat.</dd>
  <dt><a href="https://www.youtube.com/channel/UCy0tKL1T7wFoYcxCe0xjN6Q">Technology Connections</a></dt>
  <dd>Guy explains interesting bits of technological history and science behind everyday gadgets. Like <a href="https://www.youtube.com/watch?v=RSTNhvDGbYI">this video on how rice cookers use some neat physics tricks</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCHsRtomD4twRf5WVHHk-cMw">Tier Zoo</a></dt>
  <dd>A biologist explains interesting animal facts as funny parodies of video game commentary and tier lists (I am partial to the tier list format as evidenced by this very tier list). <a href="https://www.youtube.com/watch?v=9a-OAQE_hMQ">This one on turtles</a> is pretty good.</dd>
  <dt><a href="https://www.youtube.com/channel/UC7E8-0Ou69hwScPW1_fQApA">Sam Zeloof</a></dt>
  <dd>One of the only people to successfully <a href="https://youtu.be/XrEC2LGGXn0?t=25">produce a silicon integrated circuit at home</a>٫ and when he was in high school. This year he started putting out high-effort videos on <a href="https://www.youtube.com/watch?v=Nxz_ENnmgtI">cool equipment</a> used in the process.</dd>
  <dt><a href="https://www.youtube.com/channel/UC67gfx2Fg7K2NSHqoENVgwA">Tom Stanton</a></dt>
  <dd>Implements really creative and cool engineering ideas mostly using a lot of 3D printing. Some of his coolest videos are building drones using weird things like <a href="https://www.youtube.com/watch?v=XpA6qpNlNOE">gas thrusters</a>٫ <a href="https://www.youtube.com/watch?v=4kfBEaTncjI">reaction wheels</a>٫ <a href="https://www.youtube.com/watch?v=Irp_vnmUWZ4">the Coanda effect</a> and <a href="https://www.youtube.com/watch?v=d80oXSCcHTk">a single rotor with no swashplate</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UC96JVq-z0-0iHAkIkKp1_6w">Demoscene High-Quality Videos</a></dt>
  <dd>64k intros٫ where people write programs that produce beautiful visuals and audio using an executable less than 64 kilobytes٫ are perhaps my favorite art form accross all art forms. They often use very non-standard rendering techniques that lead to unique visuals٫ have good electronic background tracks٫ and the whole time I marvel at the technical wizardry of the tiny size. Not all the best videos are on this channel and not all the ones on this channel are good but it has many good ones. My favorite intro group is Logicoma٫ even before I found out they use Rust. My favorites of their stuff: <a href="https://www.youtube.com/watch?v=GjuridCR2Fo">Engage</a>٫ <a href="https://www.youtube.com/watch?v=QhqT0DhV9yE">Dope On Wax</a>٫ <a href="https://www.youtube.com/watch?v=gVHktHeYsfs">Trash Panda</a> and <a href="https://www.youtube.com/watch?v=rWwNgVwQG1A">Elysian</a>.
Favorites by other groups include
<a href="https://www.youtube.com/watch?v=XF4SEVbxUdE">on</a>٫
<a href="https://www.youtube.com/watch?v=ncdA3t_vzF8&amp;t=100s">Zetsubo (4k!)</a>٫
<a href="https://www.youtube.com/watch?v=UnjIMd3kVf4">delight</a>٫
<a href="https://www.youtube.com/watch?v=mjzeP7hYyNo">Offscreen Colonies</a> and <a href="https://www.youtube.com/watch?v=ie4u2i_5OdE">the timeless</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCG7yIWtVwcENg_ZS-nahg5g">CNLohr</a></dt>
  <dd>Really interesting and cool electronics projects. Examples include <a href="https://www.youtube.com/watch?v=a2DjjG9wVY0">reverse engineering the HTC Vive and making a custom Linux C SDK for it</a>٫ <a href="https://www.youtube.com/watch?v=R1zx0xV0pWw">running a custom Minecraft server on a microcontroller</a> and <a href="https://www.youtube.com/watch?v=MOP8I-7rA_8">pretty LEDs</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCdmAhiG8HQDlz8uyekw4ENw">Inigo Quilez</a></dt>
  <dd>Inigo is famous for his <a href="https://www.iquilezles.org/">excellent website</a> with lots of computer graphics tips especially around <a href="https://www.iquilezles.org/www/articles/raymarchingdf/raymarchingdf.htm">signed distance fields</a>. More recently he’s been uploading <a href="https://www.youtube.com/watch?v=PMltMdi1Wzg">high effort explanations</a>٫ <a href="https://www.youtube.com/watch?v=sl9x19EnKng">live coding</a> and <a href="https://www.youtube.com/watch?v=rQ2bnU4dkso">pretty fractals</a> to his YouTube channel.</dd>
  <dt><a href="https://www.youtube.com/channel/UC3azLjQuz9s5qk76KEXaTvA">Tom7/suckerpinch</a></dt>
  <dd>Tom7 is known for his incredibly good high-effort <a href="http://radar.spacebar.org/f/a/weblog/category/1/sigbovik">SIGBOVIK technical joke conference papers</a>. What I only learned later is often he makes <a href="https://www.youtube.com/watch?v=ar9WRwCiSr0">great funny YouTube videos</a> explaining his crazy hacks like.</dd>
  <dt><a href="https://www.youtube.com/channel/UCR1IuLEqb6UEA_zQ81kwXfg">Real Engineering</a></dt>
  <dd>Well-produced and interesting explanation videos on various engineering topics. From <a href="https://www.youtube.com/watch?v=wk6Qr6OO5Xo">the engineering of fighter planes</a> to <a href="https://www.youtube.com/watch?v=i6DRRHXt-PA">flood control systems in The Netherlands</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCBa659QWEk1AI4Tg--mrJ2A">Tom Scott</a></dt>
  <dd>Popular channel mostly focusing on talking about random interesting places with neat stories around the world.</dd>
  <dt><a href="https://www.youtube.com/channel/UCekQr9znsk2vWxBo3YiLq2w">You Suck At Cooking</a></dt>
  <dd>Funny comedy cooking videos that are actual recipes. Videos vary on how much they focus on being funny vs teaching good recipes. <a href="https://www.youtube.com/watch?v=GYl7h8iDjsY">This one</a> and <a href="https://www.youtube.com/watch?v=j3DPH3KOiXk">this one</a> are pretty good.</dd>
</dl>

<h1 id="c-tier-someone-being-really-good-at-something">C Tier: Someone being really good at something</h1>

<p>I’ve dedicated C tier to channels where I watch them purely to marvel at someone being really good at something. I like watching people do impressive things or perform at the highest level٫ it’s inspiring and also just cool to learn about how they do it. They don’t necessarily have to be impressive in an absolute sense٫ although many are٫ just impressive relative to my skill level (often zero in their area). The reason these aren’t in higher tiers is either that I’m not as interested in the subject but they captured me anyways٫ or their videos are not as high in density and quality.</p>

<dl>
  <dt><a href="https://www.youtube.com/channel/UC5miyvhPsWWyfTulnJ43koQ">Pannen</a></dt>
  <dd>Details various glitches used for an automated Super Mario 64 speedrun where he tries to minimize use of the A (jump) button. Really interesting just seeing how insane the tricks can be. Best and most famous video is <a href="https://www.youtube.com/watch?v=kpk2tdsPh0A">this commentated one</a> from his other channel about paralell universes.</dd>
  <dt><a href="https://www.youtube.com/channel/UCwjZLzqHYImv4oCJQcZ8Hig">Daniel Schiffer</a></dt>
  <dd>Videographer who goes into how he shoots and edits commercials٫ and he’s really good at it so his videos are great.</dd>
  <dt><a href="https://www.youtube.com/user/J3Cub2009">Tucker Gott</a></dt>
  <dd>Paramotor pilot. I have no plans on ever paramotoring but it’s cool to watch and his “Reacting To Crash Videos” series is really interesting٫ seeing him break down what kind of safety considerations come into play and how things can go wrong.</dd>
  <dt><a href="https://www.youtube.com/channel/UCCJJNQIhS15ypcHqDfEPNXg">Akiyuki Brick Channel</a></dt>
  <dd>Incredibly cool and complex Lego mechanical contraptions. <a href="https://www.youtube.com/watch?v=sUtS52lqL5w">This is a great combination of many of his designs</a> and <a href="https://www.youtube.com/channel/UCCJJNQIhS15ypcHqDfEPNXg">this recent video is aesthetically fun</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCW5OrUZ4SeUYkUg1XqcjFYA">GeoWizard</a></dt>
  <dd>Guy who is really good at GeoGuessr٫ that is super knowledgeable about geography and all sorts of tricks to figure out where you are when plopped randomly on Street View. <a href="https://www.youtube.com/channel/UC7ELHo7almKFfxe8ultFdTA">This guy</a> is allegedly better but IMO less entertaining.</dd>
  <dt><a href="https://www.youtube.com/channel/UCtQvv0QrY7_W49gtIPSDWdg">Media Molecule</a></dt>
  <dd>Lots of videos about <a href="https://www.playstation.com/en-us/games/dreams-ps4/">Dreams</a>٫ the most impressive feat of software engineering I can think of٫ but that’s another potential future article. Includes compilations of cool creations٫ tutorials from talented artists٫ and explanations by developers of how it works.</dd>
  <dt><a href="https://www.youtube.com/channel/UCCuoqzrsHlwv1YyPKLuMDUQ">Jonathan Blow</a></dt>
  <dd>Recorded live streams of programming and demoing his game and new programming language/compiler. Clearly very skilled٫ also overly brash at times٫ but his ideas and perspective is interesting and his videos are the only ones I watch of live programming.</dd>
  <dt><a href="https://www.youtube.com/user/sethbling">Sethbling</a></dt>
  <dd>Does Super Mario World speedruns involving code injection via carefully placed shells and a glitch to warp directly to the credits٫ as well as various other technical video game trickery.</dd>
  <dt><a href="https://www.youtube.com/channel/UCCRdB9rqzP2m7bPYb5drH_Q">Harstem</a></dt>
  <dd>Professional StarCraft 2 player. Critiques people’s submitted replays٫ plays serious games while explaining his thoughts٫ tries playing with terrible strategies and winning purely on having better mechanics. Interesting to see what kind of thought٫ considerations and practice it takes to get to the highest level in a competitive strategy game.</dd>
</dl>

<h1 id="d-tier-good-quality-stuff-i-like-watching">D Tier: Good quality stuff I like watching</h1>

<p>These are just a whole bunch of channels I’m subscribe to٫ where I’ve watched a bunch of their videos and liked them. I may not watch every video from all of these channels٫ but the ones I’ve decided to watch have been good and I’ll often watch new ones when they pop up. Some of these channels are really well made and might be in other people’s S tier٫ I’m just not as interested in them. If you’ve liked my other recommendations I encourage you to check these out! I’ve split them up based on the broad theme of what type of videos they have:</p>

<h2 id="explaining">Explaining</h2>

<dl>
  <dt><a href="https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg">Two Minute Papers</a></dt>
  <dd>Short explanations of interesting machine learning and computer graphics papers.</dd>
  <dt><a href="https://www.youtube.com/channel/UCEklP9iLcpExB8vp_fWQseg">Makin’ Stuff Look Good</a></dt>
  <dd>Tutorials on how various cool shader effects work.</dd>
  <dt><a href="https://www.youtube.com/channel/UC6vImVkvofpMUOlYt6LiRXA">Keystone Science</a></dt>
  <dd>Some cool science videos.</dd>
  <dt><a href="https://www.youtube.com/channel/UCu6mSoMNzHQiBIOCkHUa2Aw">Cody’sLab</a></dt>
  <dd>Miscellaneous geology٫ farming and engineering.</dd>
  <dt><a href="https://www.youtube.com/user/AndrewPPrice">Blender Guru</a></dt>
  <dd>Really good Blender 3D modeling tutorials. I learned a lot about what goes into photorealism that I applied when choosing features for my <a href="https://thume.ca/ray-tracer-site/">path tracer</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCNk3CeLpCA0qIZsuzGl09cw">Bruce Yeany</a></dt>
  <dd>Science teacher who makes cool demonstrations.</dd>
  <dt><a href="https://www.youtube.com/c/smartereveryday/featured">Smarter Every Day</a></dt>
  <dd>Very popular science and engineering videos.</dd>
  <dt><a href="https://www.youtube.com/user/arduinoversusevil">AvE</a></dt>
  <dd>Crass guy with an idiosyncratic style of speaking has a cool series called “Bored Of Lame Tool Review?” where he takes tools apart٫ explains how they work٫ critiques their design and guesses how they’ll fail.</dd>
</dl>

<h2 id="making">Making</h2>

<dl>
  <dt><a href="https://www.youtube.com/channel/UCp_5PO66faM4dBFbFFBdPSQ">bitluni’s lab</a></dt>
  <dd>PCBs and neat huge LED walls.</dd>
  <dt><a href="https://www.youtube.com/channel/UCO8DQrSp5yEP937qNqTooOw">Strange Parts</a></dt>
  <dd>Tours of cool Chinese factories.</dd>
  <dt><a href="https://www.youtube.com/channel/UCUbDcUPed50Y_7KmfCXKohA">James Bruton</a></dt>
  <dd>3D printed cool robots.</dd>
  <dt><a href="https://www.youtube.com/channel/UClsFdM0HzTdF1JYoraQ0aUw">Brick Experiment Channel</a></dt>
  <dd>Interesting engineering using Lego٫ like making submarines.</dd>
  <dt><a href="https://www.youtube.com/channel/UC3KEoMzNz8eYnwBC34RaKCQ">Simone Giertz</a></dt>
  <dd>Originally made shitty robots٫ now makes miscellaneous cool artsy objects.</dd>
  <dt><a href="https://www.youtube.com/channel/UCILl8ozWuxnFYXIe2svjHhg">BPS.space</a></dt>
  <dd>Very fancy model rockets with cool control systems٫ like Falcon propulsive landing.</dd>
  <dt><a href="https://www.youtube.com/channel/UCVS89U86PwqzNkK2qYNbk5A">Allen Pan</a></dt>
  <dd>Cool engineering projects kind of in the style of The Hacksmith.</dd>
  <dt><a href="https://www.youtube.com/channel/UCY1kMZp36IQSyNx_9h4mpCg">Mark Rober</a></dt>
  <dd>Interesting engineering and science projects.</dd>
  <dt><a href="https://www.youtube.com/channel/UC7yF9tV4xWEMZkel7q8La_w">Peter Sripol</a></dt>
  <dd>Makes his own small and model airplanes.</dd>
  <dt><a href="https://www.youtube.com/channel/UCtHaxi4GTYDpJgMSGy7AeSw">Michael Reeves</a></dt>
  <dd>Comedy robot videos.</dd>
  <dt><a href="https://www.youtube.com/channel/UC6x7GwJxuoABSosgVXDYtTw">I Like To Make Stuff</a></dt>
  <dd>Miscellaneous crafts.</dd>
  <dt><a href="https://www.youtube.com/channel/UCturmG-MSMEpG3zAo4H6Spw">Jairus of all</a></dt>
  <dd>Some cool projects.</dd>
  <dt><a href="https://www.youtube.com/channel/UC06HVrkOL33D5lLnCPjr6NQ/featured">Breaking Taps</a></dt>
  <dd>CNC milling٫ making molds. Well produced٫ good at explaining the challenges and design process.</dd>
  <dt><a href="https://www.youtube.com/channel/UCfIqCzQJXvYj9ssCoHq327g">How To Make Everything</a></dt>
  <dd>Makes things like lenses٫ chocolate٫ clothing and food from scratch harvesting and processing all his own materials.</dd>
  <dt><a href="https://www.youtube.com/channel/UCckETVOT59aYw80B36aP9vw">Matthias Wandel</a></dt>
  <dd>Impressive woodworking and wooden contraptions.</dd>
  <dt><a href="https://www.youtube.com/channel/UCnr29dxZB1vsbiHLBL7kfAQ">The Taste Emporium</a></dt>
  <dd>Cooking channel by the same guy as <a href="https://www.youtube.com/c/thethoughtemporium">The Thought Emporium</a> about making very fancy recipes.</dd>
  <dt><a href="https://www.youtube.com/channel/UCbNvfx3rYYxEopnRGxfu53Q">Joseph’s Machines</a></dt>
  <dd>Really amazing Rube Goldberg machines.</dd>
  <dt><a href="https://www.youtube.com/channel/UCZnQYVCCnNnwqiJRIYQuYdA">Makercise</a></dt>
  <dd>Making a Gingery lathe and shaper from scratch by aluminum casting.</dd>
  <dt><a href="https://www.youtube.com/channel/UCUuMYw2l2UeWyTGYixYfRCA">EvanAndKatelyn</a></dt>
  <dd>Miscellaneous home crafts and art.</dd>
  <dt><a href="https://www.youtube.com/c/Ididathing">I did a thing</a></dt>
  <dd>Comedy DIY videos like <a href="https://www.youtube.com/watch?v=OSfUUqNkrOQ">“Can I make a spoon using only a spoon”</a>.</dd>
  <dt><a href="https://www.youtube.com/channel/UCUQo7nzH1sXVpzL92VesANw">DIY Perks</a></dt>
  <dd>Well-made DIY projects mostly building custom lighting and weird computer equipment.</dd>
  <dt><a href="https://www.youtube.com/c/ferrisstreamsstuff/videos">Ferris</a></dt>
  <dd>Really good programmer٫ part of my favorite demo group Logicoma٫ interesting streams.</dd>
  <dt><a href="https://www.youtube.com/c/TheBrickWallTeam/featured">The Brick Wall</a></dt>
  <dd>Sophisticated and impressive working Lego farm equipment and factories.</dd>
  <dt><a href="https://www.youtube.com/user/colinfurze">Colin Furze</a></dt>
  <dd>Wild engineering projects often involving making dangerous but impressive vehicles.</dd>
</dl>

<h2 id="other">Other</h2>

<dl>
  <dt><a href="https://www.youtube.com/channel/UCWf3wmxbUr5TGmCjHaXV4bQ">JL2579</a></dt>
  <dd>Technical Minecraft player. I don’t play Minecraft anymore but still love seeing what kind of weird behaviors they find and exploit to build useful Minecraft contraptions.</dd>
  <dt><a href="https://www.youtube.com/channel/UCHSI8erNrN6hs3sUK6oONLA">ilmango</a></dt>
  <dd>Another impressive technical Minecraft player.</dd>
  <dt><a href="https://www.youtube.com/channel/UC-WICcSW1k3HsScuXxDrp0w">Curry On!</a></dt>
  <dd>A good programming conference that tends to have talks I like watching.</dd>
  <dt><a href="https://www.youtube.com/channel/UC_QIfHvN9auy2CoOdSfMWDw">Strange Loop</a></dt>
  <dd>Another good programming conference with lots of talks I’ve liked.</dd>
  <dt><a href="https://www.youtube.com/channel/UCDbxvz-8MrderjIOyQi14Uw">Roger Kilmanjaro</a></dt>
  <dd>Really beautiful minimalist CG looping animations that are very much my aesthetic.</dd>
</dl>

'),('http://thume.ca/2020/05/20/making-a-latency-tester/', 'Measuring keyboard-to-photon latency with a light sensor', '1589932800000',  13, '
<p>For a long time when I’ve wanted to test the latency of computers and UIs I’ve used the <a href="https://isitsnappy.com/">Is It Snappy</a> app with my iPhone’s high speed camera to count frames between when I press a key and when the screen changes. However the problem with that is it takes a while to find the exact frames you want٫ which is annoying when doing a bunch of testing. It also makes it difficult to find out what the variability of latency is like. I had already made this kind of testing easier <a href="/2017/12/29/fixing-my-keyboards-latency/">by adding a mode to my keyboard firmware which changes the LED color after it sends a USB event</a>٫ but that only made it a bit faster and more precise. I wanted something better.</p>

<p>So I followed in the footsteps of my friend <a href="https://raphlinus.github.io/">Raph</a> and made a hardware latency tester which sends keyboard events and then uses a light sensor to measure the time it takes for the screen to change! It was quite easy and in this post I’ll go over some of the latency results I’ve found٫ talk about why good latency testing is tricky٫ and explain how to build your own latency tester.</p>

<p>Basically my latency tester is a light sensor module from Amazon held by an adjustable holder arm wired to a <a href="https://www.pjrc.com/teensy/teensyLC.html">Teensy LC</a> microcontroller which presses “a” and waits until the light level changes٫ then deletes it and keeps collecting samples as long as a button is held. Then with a short press of that one button it will type out a nice latency histogram that looks like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lat i= 60.3 +/-   9.3٫ a= 60٫ d= 59 (n= 65٫q= 41) |    239_                      |
</code></pre></div></div>

<p>This line tells me the average latency of insertions (<code class="language-plaintext highlighter-rouge">i=</code>)٫ deletions (<code class="language-plaintext highlighter-rouge">d=</code>) and both put together (<code class="language-plaintext highlighter-rouge">a=</code>)٫ the standard deviation of insertion times (<code class="language-plaintext highlighter-rouge">+/-</code>)٫ measurement count (<code class="language-plaintext highlighter-rouge">n=</code>) and quality (<code class="language-plaintext highlighter-rouge">q=</code>)٫ and a little ascii histogram where each character is a 10ms bucket and the digits proportionally represent how full the bucket is. The <code class="language-plaintext highlighter-rouge">_</code> represents a bucket with at least one sample but not enough to be at least one ninth of the top bucket٫ so I can see tail latencies. Here’s what it looks like (pictured with portrait monitors but all tests were done in landscape):</p>

<p><img src="/assets/postassets/latencytester/final_product.jpeg" alt="The final product" /></p>

<p>I also made it so if you press the button again٫ it will type out all the raw measurements like <code class="language-plaintext highlighter-rouge">[35٫ 35٫ 33٫ 44]</code> so you can do custom plotting:</p>

<p><img src="/assets/postassets/latencytester/plot.png" alt="Plotly chart" /></p>

<h2 id="monitor-latency">Monitor latency</h2>

<p>I’ll start out with my favorite set of results:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Sublime Text٫ macOS٫ distraction-free full-screen mode on two 4k monitors:
lat i= 35.3 +/-   4.7٫ a= 36٫ d= 36 (n= 67٫q= 99) |  193       | Dell P2415Q top
lat i= 52.9 +/-   5.0٫ a= 53٫ d= 54 (n= 66٫q= 45) |   _391     | Dell P2415Q bottom
lat i= 65.1 +/-   5.0٫ a= 64٫ d= 63 (n=109٫q=111) |    _292    | HP Z27 top
lat i= 79.7 +/-   5.0٫ a= 80٫ d= 80 (n= 98٫q=114) |       89_  | HP Z27 bottom
</code></pre></div></div>

<p>There’s a lot to observe here:</p>

<ul>
  <li>First of all٫ I like how the single-line fixed-width histogram format lets me put results next to each other in a text file and label them to the right for comparison.</li>
  <li>We can see the expected difference of 16ms between the latency at the top and bottom of each monitor from the time it takes to scan out the rows during a frame at 60hz.</li>
  <li>The standard deviation is just a touch over the <a href="https://www.quora.com/What-is-the-standard-deviation-of-a-uniform-distribution-How-is-this-formula-determined">4.6ms</a> that’s inherent to the uniformly-distributed variance that comes from being misaligned with a 16ms display refresh period.</li>
  <li><strong>The HP Z27 is around 30ms slower than the Dell P2415Q!</strong> And that’s measuring from the start of when the change is detectable٫ I’m pretty sure the Z27 also takes longer to transition fully. With the Z27 and Sublime almost half my end-to-end latency is unnecessary delay from the monitor!</li>
</ul>

<p>All measurements in the rest of this post are accordingly done on my Dell P2415Q. Both monitors have response time set to “fast”٫ the Z27 has even higher response time settings but they only affect transition time and introduce unsightly ghost trails without helping initial latency.</p>

<h2 id="the-perils-of-measurement">The perils of measurement</h2>

<p>Taking good latency measurements is actually quite difficult in more ways than you might think. I tried harder than most people to get realistic measurements and still failed the first few times in ways that I had to fix.</p>

<h3 id="actually-measuring-end-to-end-latency">Actually measuring end to end latency</h3>

<p>First of all٫ the reason to use a hardware latency tester is that there are many incomplete or potentially deceptive ways to measure end-to-end latency.</p>

<p>There’s a really excellent famous blog post called <a href="https://pavelfatin.com/typing-with-pleasure/">Typing With Pleasure</a> that compares latency of different text editors on different operating systems with good analysis and pretty graphs. However it does this by simulating input events and screen scraping using OS APIs. I haven’t done any overlapping measurements with his so can’t point to anything specifically wrong٫ but there’s lots of potential issues with this. For example inspecting the screen buffer on the CPU might unduly penalize GPU-rendered apps due to window buffer copies under some ways that capture might work. Simulated input may hit different paths than real input. Regardless٫ even if it does give decent relative measurements (and you can’t truly know without validating it against an end-to-end test)٫ it doesn’t tell you the full latency users experience.</p>

<h3 id="using-1000hz-usb-polling">Using 1000hz USB polling</h3>

<p>One source of latency users experience that my tester doesn’t measure is <a href="https://danluu.com/keyboard-latency/">keyboard latency</a>. Many keyboards can introduce more latency than my entire keyboard-to-photon latency (<a href="/2017/12/29/fixing-my-keyboards-latency/">including mine in the past</a>) due to 8ms USB polling intervals٫ low keyboard grid scan rates٫ slow firmware٫ and more debatably different mechanical design.</p>

<p>You can’t just use any microcontroller that can emulate a keyboard to build a low-variance latency tester because they probably use default 125Hz polling. Luckily my go-to microcontroller the <a href="https://www.pjrc.com/teensy/teensyLC.html">Teensy LC</a> is one of few to default to 1000hz.</p>

<h3 id="ensuring-good-signal-strength">Ensuring good signal strength</h3>

<p>For the first while after I built my latency tester I didn’t have any measurement of signal strength. Eventually I got confused by some measurements in slightly different scenarios with the same app and screen having wildly different results. I did some testing and figured out that sometimes with small fonts or poor sensor placement the change in screen contents would only barely be detectable so I’d end up measuring until the monitor finished transitioning when usually I measure until when the monitor starts transitioning (which is its own tricky subjective measurement choice).</p>

<p>I knew to suspect transition time٫ because before I wrote the firmware I played around with just sampling the light sensor every millisecond and using the Arduino serial plotter to plot measurements as I typed and backspaced a letter just to see what the signal looked like. You can see that some combination of the light sensor and the monitor take nearly 100ms to fully transition. Based on filming with <a href="https://isitsnappy.com/">Is It Snappy</a> it seems like it only takes my Z27 about 20ms for the screen to perceptually finish transitioning.</p>

<p><img src="/assets/postassets/latencytester/wave.png" alt="Trace" /></p>

<p>To avoid this I added a peak to peak signal strength measurement after the full transition to my output so I could ensure I was getting adequate resolution for my threshold of 5 steps to be near the beginning of the transition. These are the numbers you see after <code class="language-plaintext highlighter-rouge">q=</code>. I learned that it’s important to keep font sizes large and screen brightness settings high.</p>

<h3 id="significant-variation-from-small-differences">Significant variation from small differences</h3>

<p>It’s possible for seemingly small differences in what’s being measured to make noticeable differences in latency. For example I wanted to see if there was a significant difference between the latency of Sublime and VSCode on a small file with plain text highlighting compared to a large file with a complex highlighting grammar and an autocomplete popup. Sure enough there was٫ but after noticing some variability I did a bunch more testing and discovered that the latencies were noticeably different between typing ‘a’ on a blank line and typing ‘a’ after an existing ‘a’ (‘aa’).</p>

<p>Here’s the results upon making a new line after line 3469 of 6199 of the huge <a href="https://github.com/trishume/syntect/blob/master/testdata/parser.rs">parser.rs</a>٫ all taken with similar sensor positioning lower down my Dell monitor than the very top.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lat i= 40.2 +/-   4.1٫ a= 40٫ d= 39 (n= 38٫q= 90) |  _89           | sublime small .txt

lat i= 41.2 +/-   6.9٫ a= 41٫ d= 42 (n= 54٫q= 92) |   992          | sublime aa parser.rs
lat i= 43.6 +/-   6.1٫ a= 43٫ d= 42 (n= 48٫q=100) |   492          |
lat i= 52.2 +/-   6.0٫ a= 52٫ d= 52 (n= 26٫q=100) |    49          |
lat i= 44.3 +/-   5.6٫ a= 43٫ d= 42 (n= 45٫q=100) |   391          |
lat i= 42.7 +/-   7.6٫ a= 42٫ d= 42 (n= 46٫q=100) |  _491          |

lat i= 48.1 +/-   6.8٫ a= 49٫ d= 50 (n= 43٫q= 89) |   269          | sublime a parser.rs
lat i= 43.9 +/-   5.4٫ a= 48٫ d= 52 (n= 32٫q= 97) |   197          |
lat i= 47.8 +/-   8.4٫ a= 49٫ d= 49 (n= 29٫q= 97) |   197_         |
lat i= 46.1 +/-   6.8٫ a= 47٫ d= 49 (n= 42٫q= 97) |   196_         |

lat i= 63.3 +/-   9.3٫ a= 63٫ d= 62 (n= 68٫q=118) |    _963__      | vscode aa parser.rs
lat i= 63.6 +/-   7.6٫ a= 64٫ d= 65 (n= 71٫q=139) |    _49__     _ |
lat i= 62.3 +/-   6.3٫ a= 61٫ d= 59 (n= 52٫q=132) |    _791        |
lat i= 62.0 +/-   5.8٫ a= 61٫ d= 60 (n= 40٫q=111) |    _49_        |
lat i= 61.9 +/-   9.7٫ a= 62٫ d= 61 (n= 35٫q=111) |     981_       |

lat i= 53.1 +/-   7.7٫ a= 51٫ d= 49 (n= 54٫q=116) |   _79__        | vscode a parser.rs
lat i= 52.2 +/-   6.3٫ a= 52٫ d= 51 (n= 41٫q=133) |    692         |
lat i= 53.2 +/-   7.8٫ a= 52٫ d= 52 (n= 57٫q=134) |    591_        |
lat i= 52.1 +/-   7.1٫ a= 52٫ d= 52 (n= 55٫q=134) |    591_        |
</code></pre></div></div>

<p>I did a bunch of runs at different times and with minor changes to confirm the effect٫ and you can see that there’s variation between measurements of the same scenario٫ but noticeably larger variation between just typing ‘a’ and adding an ‘a’ after an existing ‘a’. Try looking at the ‘a=’ column since it includes both insert and delete measurements so has the least cross-run noise. Sublime is faster at ‘aa’ than ‘a’ and VSCode is faster at ‘a’ than ‘aa’.</p>

<p>In both editors ‘aa’ causes the autocomplete popup to alternate between two lists and ‘a’ causes it to appear and disappear. I can guess that Sublime might be slower in the ‘a’ case because opening and closing the autocomplete popup has a cost٫ but I don’t have a strong hypothesis why VSCode is slower in the ‘aa’ case on both insertion and deletion.</p>

<h3 id="jittering-so-as-not-to-sync-with-refresh">Jittering so as not to sync with refresh</h3>

<p>The next fishy thing I noticed is that my variances seemed too low. I was sometimes getting standard deviations of 1ms when my understanding of how the system worked said I should be getting a standard deviation over <a href="https://www.quora.com/What-is-the-standard-deviation-of-a-uniform-distribution-How-is-this-formula-determined">4.6ms</a> due to 16ms screen refresh intervals.</p>

<p>I looked at my code and figured out that I was inadvertently synchronizing my measurement with screen refreshes. Whenever I measured a change٫ my firmware would wait exactly 300ms before typing ‘a’ or backspace again and taking another measurement. This meant the input was always sent about 300ms after a screen refresh and thus would land at a fairly constant spot in the screen refresh interval. I patched this issue by adding a 50ms random delay between measurements.</p>

<p>This mainly leads to incorrectly low variances but might lead to incorrect averages as well if the app will miss a paint deadline if the input event comes late in a frame but it never does during the test. I found this during testing for this post and couldn’t be bothered to redo all the tests below this point٫ so you may notice some low variances٫ but I did recheck the averages on important results like Sublime and VSCode.</p>

<h2 id="text-editors">Text editors</h2>

<p>I tested the latency of a bunch of text editors on the same plain text file٫ but note the above that these are before I added jittering٫ although I did more tests on Sublime and VSCode after jittering which you can see above.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lat i= 32.5 +/-   4.0٫ a= 34٫ d= 35 (n= 38٫q= 78) |   9_          | sublime text
lat i= 33.4 +/-   1.4٫ a= 33٫ d= 33 (n= 68٫q= 23) |  _9           | textedit
lat i= 47.6 +/-   7.0٫ a= 47٫ d= 47 (n= 71٫q=130) |   219         | vscode
lat i= 34.2 +/-   3.5٫ a= 34٫ d= 33 (n= 57٫q= 37) |   9 _         | chrome html input
lat i= 33.2 +/-   1.1٫ a= 33٫ d= 33 (n= 55٫q= 30) |   9           | stock mac emacs
lat i= 45.6 +/-   7.0٫ a= 43٫ d= 41 (n= 35٫q= 56) |   992_        | atom
lat i= 35.0 +/-   4.7٫ a= 35٫ d= 35 (n= 66٫q= 11) |   9__         | xi
</code></pre></div></div>

<p>Given the lack of jitter٫ I’d interpret these results as everything except VSCode and Atom being similarly “basically as good as you can get”. And note that even VSCode and Atom have less of a latency penalty for normal typing than you can easily have in your monitor or keyboard.</p>

<h2 id="terminals">Terminals</h2>

<p>I also measured different terminals. It looks like the default Apple Terminal and <a href="https://sw.kovidgoyal.net/kitty/">kitty</a> have similar approximately optimal latency٫ while <a href="https://www.iterm2.com/">iTerm2</a> and <a href="https://github.com/alacritty/alacritty">Alacritty</a> have worse latency.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lat i= 53.1 +/-   6.6٫ a= 54٫ d= 55 (n= 53٫q= 59) |    291      _ | iterm2 gpu render
lat i= 50.5 +/-   2.5٫ a= 50٫ d= 50 (n= 56٫q= 59) |    19_        | iterm2 no gpu
lat i= 35.8 +/-   7.0٫ a= 34٫ d= 33 (n= 73٫q= 48) |   9___        | apple terminal
lat i= 35.1 +/-   2.5٫ a= 34٫ d= 32 (n= 35٫q= 52) |   9_          | apple terminal vim
lat i= 50.4 +/-   3.9٫ a= 50٫ d= 49 (n= 60٫q=269) |   _59         | alacritty
lat i= 36.1 +/-   5.6٫ a= 35٫ d= 34 (n= 78٫q=199) |   9__         | kitty
</code></pre></div></div>

<h2 id="how-to-make-one">How to make one</h2>

<p>Here’s the parts list I used:</p>

<ul>
  <li><strong>$12</strong>: A <a href="https://www.pjrc.com/teensy/teensyLC.html">Teensy LC</a> or any other Teensy 3+. You could also use an Arduino٫ but the Teensy’s USB library uses 1000hz polling (1ms latency) while most USB devices default to 125hz (an extra 8ms of random latency in your measurements). It’s possible you may be able to get your microcontroller of choice to do 1000hz polling though. If you don’t want to have to solder the pins٫ buy one with pre-soldered pins٫ this might require getting the more expensive Teensy 3 if you want Amazon Prime shipping.</li>
  <li><strong>$12</strong>: A <a href="https://www.amazon.com/gp/product/B01N1FKS4L/ref=ppx_yo_dt_b_asin_title_o03_s01?ie=UTF8&amp;psc=1">light sensor module</a> (Amazon only has 10 packs٫ I only used 1). You could make your own circuit for this but these modules save a lot of time and are easy to integrate.</li>
  <li><strong>$13</strong>: A <a href="https://www.amazon.com/gp/product/B07SBZRF6S/ref=ppx_yo_dt_b_asin_title_o02_s00?ie=UTF8&amp;psc=1">helping hand</a> to hold the light sensor up to your screen in a stable position.</li>
  <li>A button/switch of some kind to trigger testing</li>
  <li>Wires to connect the light sensor٫ Teensy٫ and button</li>
  <li>Electrical tape to make a black soft shield to restrict the view of the sensor</li>
  <li>A USB micro-B cable to connect the Teensy to your computer</li>
</ul>

<p>There’s an awful lot of flexibility in exactly how you assemble it. You just need to somehow connect 3 wires (3V٫ ground٫ analog out) from the light sensor module to the corresponding pins on the Teensy (3V٫ ground and any analog-capable pin). The easiest way to do this which doesn’t even require any soldering if you buy a Teensy with pre-soldered header pins is to use 3 <a href="https://www.amazon.com/Uxcell-a16072600ux1043-Female-Jumper-Breadboard/dp/B01M1CDI7M/ref=sr_1_8">female to female jumper wires</a>. Then you just need some kind of switch to activate the latency test where you wire one pin to ground on the Teensy and another pin to a digital IO pin. This can be as simple as two wires that you touch together if you’re really lazy!</p>

<p>To make sure the light sensor module only sees a limited area of the screen I wrapped the sensor in a little cylinder of electrical tape and snipped off the end cleanly with scissors. This made a little round window I could press up against the screen with the helping hand to minimize outside interference and get the cleanest signal.</p>

<p>I had already made a <a href="https://twitter.com/trishume/status/950585012700684288">foot pedal box</a> with a Teensy LC and a little breadboard inside٫ and it had an extra <a href="https://www.cablechick.com.au/blog/understanding-trrs-and-audio-jacks/">TRRS jack</a> on the side I had put on anticipating this sort of project٫ so for me the project was soldering the light sensor module to a TRRS cable. Then I could just use one of my existing foot pedals to control the testing!</p>

<p>For the soldering I was in luck since I had conveniently bought magnetic helping hands for the project which I could use for the soldering process. Inconveniently I realized that I actually didn’t own many substantial chunks of iron for them to attach to٫ so I ended up using a cast iron pan when soldering and <a href="/2019/03/03/my-tungsten-cube/">my tungsten cube</a> when on my desk (which turns out to be slightly ferromagnetic).</p>

<p><img src="/assets/postassets/latencytester/soldering.jpeg" alt="Soldering" /></p>

<p>I encourage you to have fun and try to make something fancier than just dangling jumper wires. For my foot pedal box I bought a plastic project box from a local electronics shop٫ used a drill press to put some holes in the sides and installed large and small headphone jacks and a little breadboard so I could reconfigure how things connect. There’s tons of foot pedals on Amazon for tattoo machines and electric pianos that use 1/4” phone plugs that you can pick and choose from. <a href="https://www.amazon.com/Casio-SP3-SP-3-Sustain-Pedal/dp/B00070E8I8/ref=sr_1_3?">These</a> are my favorites for feel and silence but there are cheaper options that can be unreliable٫ hard to press or loud.</p>

<p>I wouldn’t recommend following my use of a TRRS jack for the sensor module though٫ they’re nice and small and there’s lots of cables available٫ but I used them before I realized the problem that they cause a lot of shorting of different connections when plugging and unplugging. I tried to minimize this by putting power and ground on opposite ends٫ but you should consider some better cable type like maybe a <a href="https://en.wikipedia.org/wiki/Registered_jack">phone cable</a>.</p>

<p><img src="/assets/postassets/latencytester/pedal_box.jpeg" alt="Pedal box insides" /></p>

<h2 id="the-firmware">The firmware</h2>

<p>I didn’t write the fanciest possible firmware to find the beginning and ending of the transition٫ but I put a bit of effort into tweaking it to work well and adding various features so I recommend starting with my firmware. Install the <a href="https://www.pjrc.com/teensy/teensyduino.html">Teensyduino</a> software and then you can use <a href="https://gist.github.com/trishume/bbdae75792d2888708a01d5625fa9229">my latency tester Arduino sketch</a> which also doubles as foot pedal box code but you can comment that stuff out and configure it to use the right pins. Then just long press your switch to take samples and short press to type out the results!</p>

'),('http://thume.ca/2020/05/17/pipes-kill-productivity/', 'Fragile narrow laggy asynchronous mismatched pipes kill productivity', '1589673600000',  13, '
<p>Something I’ve been thinking about recently is how when I’ve worked on any kind of distributed system٫ including systems as simple as a web app with frontend and backend code٫ probably upwards of 80% of my time is spent on things I wouldn’t need to do if it weren’t distributed. I came up with the following description of why I think this kind of programming requires so much effort: Everything is fragile narrow laggy asynchronous mismatched untrusted pipes. I think every programmer who’s worked on a networked system has encountered each of these issues٫ this is just my effort to coherently describe all of them in one place. I hope to prompt you to consider all the different hassles at once and think about how much harder/easier your job would be if you did/didn’t have to deal with these things. I think this is part of why web companies like Twitter seem to have so much lower impressiveness per engineer productivity than other places like game companies or SpaceX٫ although there’s other pieces to that puzzle. While part of the difficulty of distributed systems is inherent in physics٫ I think there’s lots of ideas for making each part of the problem easier٫ many already in common use٫ and I’ll try to mention lots of them. I hope that we as programmers continually develop more of these techniques and especially general implementations that simplify a problem. Like serialization libraries reducing the need for hand-written parsers/writers٫ I think there’s a lot of developer time out there to save by implementing generalized solutions where we currently painstakingly reimplement common patterns. I also think all these costs mean you should try <em>really hard</em> to avoid making your system distributed if you don’t have to.</p>

<p>I’ll go over each piece in detail٫ but briefly٫ whenever we introduce a network connection we usually have to deal with something that is:</p>

<ul>
  <li><strong>Fragile</strong>: The network connection or the other end can have hardware failures٫ these have different implications but both manifest as just a timeout. Everything needs to handle failure.</li>
  <li><strong>Narrow</strong>: Bandwidth is limited so we need to carefully design protocols to only send what they need.</li>
  <li><strong>Laggy</strong>: Network latency is noticeable so we need to carefully minimize round-trips.</li>
  <li><strong>Asynchronous</strong>: Especially with &gt;2 input sources (UIs count) all sorts of races and edge cases can happen and need to be thought about and handled.</li>
  <li><strong>Mismatched</strong>: It’s often not possible to upgrade all systems atomically٫ so you need to handle different ends speaking different protocol versions.</li>
  <li><strong>Untrusted</strong>: If you don’t want everything to be taken down by one malfunction you need to defend against invalid inputs and being overwhelmed. Sometimes you also need to defend against actual attackers.</li>
  <li><strong>Pipes</strong>: Everything gets packed as bytes so you need to be able to (de)serialize your data.</li>
</ul>

<p>All of these things can be mostly avoided when programming things that run on one computer٫ that is unless you end up optimizing performance and realizing your computer is actually a distributed system of cores and some of them come back. Some domains manage to avoid some of these but I’ve experienced subsets of these problems working on <a href="https://thume.ca/resume">web apps٫ self-driving cars٫ a text editor٫ and high-performance systems</a>٫ they’re everywhere.</p>

<p>This isn’t even all the problems٫ just things about the network. Tons of effort is also expended on things like how various bottlenecks often entail a complicated hierarchy of caches that need to be kept in sync with the underlying data store.</p>

<p>One way you can avoid all this is to just not write a distributed system. There are plenty of cases you can do this and I think it’s worthwhile to try way harder than some people do to pack everything into one process. However past a certain point of reliability or scale٫ physics means you’re going to have to use multiple machines (unless you want to go the mainframe route).</p>

<h2 id="fragile">Fragile</h2>

<p>As you connect machines or increase reliability goals٫ the strategy of just crashing everything when one piece crashes (what multi-threaded/multi-core systems do) becomes increasingly unviable. Hardware will fail٫ wireless connections drop٫ entire data centers have their power or network taken out by <a href="https://en.wikipedia.org/wiki/Electrical_disruptions_caused_by_squirrels">squirrels</a>. Some domains like customers with flaky internet also inevitably entail frequent connection failure.</p>

<p>In practice you need to write code to handle the failure cases and think carefully about what they are and what to do. This gets worse when merely noting the failure would drop important data٫ and you need to implement redundancy of data storage or transmission. Even worse٫ both another machine failing and a network connection breaking become visible just as some expected network packet not arriving after “too long”٫ introducing not only a delay but an ambiguity that can result in <a href="https://en.wikipedia.org/wiki/Split-brain_(computing)">split-brain issues</a>. Often something like TCP implements it for you but sometimes you have to implement your own heartbeating to periodically check that another system is still alive.</p>

<p>Attempts to make this easier include exceptions٫ TCP٫ concensus protocols and off-the-shelf redundant databases٫ but no solution eliminates the problem everywhere. One of my favourite attempts is <a href="https://rollout.io/blog/linking-monitoring-and-supervising-in-elixir/">Erlang’s process linking٫ monitoring and supervising</a> which offers a philosophy that attempts to coalesce all sorts of failures into one easier to handle general case.</p>

<h2 id="narrow">Narrow</h2>

<p>Network bandwidth is often limited٫ especially over consumer or cellular internet. It may seem like this isn’t a limitation very often because you rarely hit bandwidth limits٫ but that’s because limited bandwidth is ingrained into everything you do. Whenever you design a distributed system you need to come up with a communication protocol that communicates on the order of what’s necessary rather than on the order of the total size of your data.</p>

<p>In a multi-threaded program٫ you might just pass a pointer to gigabytes of immutable or locked data for a thread to read what it wants from and not think anything of it. In a distributed system passing the entire memory representing your database is unthinkable and you need to spend time implementing other approaches.</p>

<p>Although actually multi-core systems are a certain kind of distributed system and they employ <a href="https://en.wikipedia.org/wiki/MESI_protocol">protocols</a> behind the scenes to transfer only the data that’s necessary٫ but involve many more broadcasts and round trips than would be viable with most networks. I actually think trying to apply techniques used to make multi-core machines seamless to distributed systems is a good way to think of <a href="https://dl.acm.org/doi/pdf/10.14778/3236187.3236209">neat solutions</a> that might be much more general than you’d otherwise design. Similarly once you really start optimizing systems hard you notice that bandwidth inside your computer becomes a constraint too.</p>

<p>Dealing with low bandwidth usually involves a message type for each query or modification to a shared data structure٫ and deciding when to ship over more data so local interactions are faster٫ or less data to avoid terrible bandwidth cases. It often goes further to various types of replicated state machine where each peer updates a model based on a replicated stream of changes٫ because sending the new model after every update would be too much bandwidth. Examples of this include <a href="https://www.gamasutra.com/view/feature/131503/1500_archers_on_a_288_network_.php">RTS games</a> to <a href="https://support.kraken.com/hc/en-us/articles/360027821131-How-to-maintain-a-valid-order-book-">exchange</a> <a href="https://www.nasdaqtrader.com/content/technicalsupport/specifications/dataproducts/NQTVITCHspecification.pdf">feeds</a>. However maintaining determinism and consistency in how each peer updates its state to avoid desyncs can be tricky٫ especially if different peers have different languages or software versions. You also often end up implementing a separate protocol for streaming a full snapshot٫ because replaying events from the beginning of time when connecting isn’t viable.</p>

<p>Attempts to make this easier include RPC libraries just making it easier to send lots of different message types for different queries and updates rather than shipping data structures٫ caching libraries٫ and compression. Cool but less commonly used systems include things like <a href="https://hackingdistributed.com/2013/12/26/introducing-replicant/">Replicant</a> that ensure synchronized state machine code and update streams on many devices to make replicated state machines easier and less fraught.</p>

<h2 id="laggy">Laggy</h2>

<p>One network round trip can’t be a problematic latency or you need better networking hardware or a different problem to solve. The difficulties come from avoiding implementing your solution in a way that needs too many network round trips. This can lead to needing to implement special combo-messages that do a sequence of operations on the server instead of just providing smaller primitive messages.</p>

<p>The web٫ with its especially large latencies٫ has had lots of problems of this type such as only having the font/image URLs after loading the HTML٫ or REST APIs that require multiple chained calls to get the IDs needed for the next. Lots of things have been built for these problems like resource inlining٫ <a href="https://en.wikipedia.org/wiki/HTTP/2_Server_Push">HTTP/2 server push</a> and <a href="https://graphql.org/">GraphQL</a>.</p>

<p>A cool somewhat general solution is <a href="https://capnproto.org/news/2013-12-13-promise-pipelining-capnproto-vs-ice.html">Cap’n Proto promise pipelining</a> and other systems that involve essentially shipping a chain of steps to perform to the other end (like SQL). These systems essentialy send a limited type of program to perform on the server. Unfortunately you often run into the limitations of the language used٫ like you can’t add 1 to your Cap’n Proto result before passing it to a new call without a round trip. But if you make your language too powerful you can run into problems with the code you’re shipping overloading the server or being too big. Just adding a multi-step message for your use case is pretty easy if you control both ends٫ but can be harder if the other end is a company’s API for third parties٫ or even just owned by a different team at a big company٫ and those are the cases where they tend not to want to run your programs on their server. I think there’s lots more avenue for exploration here in terms of new approaches to sending segments of code while re-using sent code to save bandwidth and limiting the potential for it to do damage.</p>

<p>Another solution that can work in a data center is to use better networking. You can get <a href="https://www.mellanox.com/products/ethernet-adapters/connectx-6dx">network</a> <a href="https://exablaze.com/exanic-x25">cards</a> with <a href="https://docs.microsoft.com/en-us/azure/virtual-machines/workloads/hpc/hc-series-performance">2us latencies and 100Gbps bandwidths</a> or better٫ but basically only HPC٫ simulations and finance use them. However these just reduce the constant factor and don’t save you if your approach takes O(n) round trips.</p>

<h2 id="asynchronous">Asynchronous</h2>

<p>As soon as you have 2+ sources of events that aren’t synchronized then you start worrying about race conditions. This can be multiple servers٫ or just a web app with both user input and a channel to the server. There’s always uncommon orderings like the user clicking the “Submit” button a second time before the next page loads. Sometimes you get lucky and the design of your system means that’s fine٫ other times it’s not and you either fix it to handle that case or get bug reports from customers who were billed twice. The more asynchrony the more cases you have to either think about or solve with an elegant design which precludes bad states.</p>

<p>Depending on your language/framework٫ asynchrony can also entail a change to the way you normally write code that makes everything bloated and uglier. Lots of systems used to and still do require you to use callbacks everywhere٫ sometimes without even providing you closures٫ making your code an enormous mess. Many languages have gotten better at this with features like <a href="https://en.wikipedia.org/wiki/Async/await">async/await</a> or coroutines with small stack like <a href="https://tour.golang.org/concurrency/1">Go</a>٫ or just using threads and blocking I/O. Unfortunately some of these solutions introduce <a href="https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/">function color problems</a> where introducing asynchrony requires making changes throughout your codebase.</p>

<p>Asynchrony edge cases are a reasonably fundamental problem٫ but there’s lots of available patterns for solving different kinds of asynchrony. Examples include concurrency primitives like locks and barriers٫ protocol design ideas like <a href="https://en.wikipedia.org/wiki/Idempotence">idempotency</a>٫ and fancier things like <a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type">CRDTs</a>.</p>

<h2 id="mismatched">Mismatched</h2>

<p>Usually it’s not possible to upgrade every component of a distributed system atomically when you want to change a protocol. This runs from communicating server clusters that must run 24/7 to users who have an old version of your web page loaded in a tab. This means for some time you’ll have systems that want to talk a newer protocol version communicating with systems that only know an older protocol. This is just a problem you need to solve and there’s two broad classes of common solutions with many subtypes:</p>

<ul>
  <li>Have the new software version be able to speak both the old and new protocol version and negotiate to use the new version with upgraded peers٫ either by maintaining both implementations or mapping the old handlers onto the new ones.</li>
  <li>Use data structures that provide some degree of compatibility for free٫ then only upgrade your protocol in those ways. For example unrecognized fields in JSON objects are usually ignored so can be used for new functionality when recognized. Migrations can usually add new columns to a database table without it breaking queries. Then you usually go to great lengths to shoehorn every change into being this type of compatible.</li>
</ul>

<p>The problem with both these cases is the first steps usually accumulate technical debt in the form of code paths to handle cases (for example of missing fields) that will never come up once all peers are upgraded past the protocol change. This usually entails multi-stage rollouts٫ for example introduce a new field as optional٫ roll out the new version everywhere٫ change the field to be mandatory now that all clients send it٫ do another rollout. I’ve definitely spent a lot of time planning multi-stage rollouts when I’ve wanted to change protocols used by multiple systems without leaving a mess.</p>

<p>There’s lots of things that help with both of these approaches٫ both serialization systems that provide lots of compatible upgrade paths like <a href="https://developers.google.com/protocol-buffers">Protobufs</a>٫ to various <a href="https://yave.handmade.network/blogs/p/2723-how_media_molecule_does_serialization">patterns for deserializing/upgrading old type versions</a>.</p>

<h2 id="untrusted">Untrusted</h2>

<p>Not only can your data fail to arrive but your system can recieve data that might actively harm it. Systems have bugs which cause invalid messages to be sent٫ so inputs need to be carefully validated and errors returned٫ not only at the serialization level but the business logic level. Bugs or new loads can cause systems to send messages faster than they can be handled٫ necessitating backpressure and limits. You may even have to defend against attackers who actively try and subvert your system by sending messages that would never be sent by your usual counterparties and <a href="https://www.anchor.com.au/blog/2012/12/how-to-explain-hash-dos-to-your-parents-by-using-cats/">intelligently seek out edge cases</a>.</p>

<p>Here too we have lots of patterns including rate limits٫ field validation logic and channels with built in backpressure. On the security side we also have a field of things like encryption٫ certificates and fuzzing. We’ve also gotten better at being general here as we’ve reduced prevalence of manual patterns like ensuring we always escape interpolated strings in SQL and HTML٫ with more general patterns like <code class="language-plaintext highlighter-rouge">?</code> query parameters and templating systems which always apply escaping.</p>

<h2 id="pipes">Pipes</h2>

<p>Last and mostly least٫ everything has to be a stream of bytes or packets of bytes. This means you need to take your nice data structures that your language makes easy to manipulate and pack them into a different form from their in-memory representation in order to send on the wire. Luckily except in very few places easy <a href="https://serde.rs/">serialization</a>/<a href="https://grpc.io/">RPC</a> libraries have made this pretty easy٫ if occasionally somewhat slow. You can also sometimes use methods that allow you to pick out exactly the parts you want from the byte buffers without transforming it to a different representation٫ perhaps by casting your buffer pointer to a C structure pointer (when that’s even close to safe-ish)٫ or using something like <a href="https://capnproto.org/">Cap’n Proto</a> that can generate accessors.</p>

<p>This is probably the one I’ve spent the least time fighting٫ but one case I can remember was when I wanted to send a large data structure٫ but the available serialization system could only serialize it all at once rather than streaming it packet by packet as the socket could accept it٫ and I didn’t want to block my server for a long time doing the entire thing٫ creating tail latency. I ended up choosing a different design٫ but I could also have written custom code to break my data structure up into chunks and send it a little bit at a time.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I suspect many responses to this post will be of the form “Actually {some/all of these problems} are trivial if you just {do some thing that isn’t universally applicable٫ is time consuming or has its own issues٫ possibly something I mentioned٫ if so probably using Erlang} and the real problem is that other people are bad at programming unlike people in the good old days”. There are lots of things that help٫ and there is a skill component in knowing about good solutions٫ choosing the right ones٫ and implementing them effectively. However these are still hard problems and people have to make difficult real tradeoffs because we haven’t solved them effectively enough. Maybe you would have taken a different side of the tradeoff but people make these technology decisions for real reasons and we should strive to reduce the costs٫ as well as improving decisions over which costs we accept.</p>

<p>I just can’t use Erlang for most projects I do because they require either extremely low latency٫ integration with some part of a non-Erlang ecosystem٫ or they’re too computationally intensive (yes I know about <a href="http://erlang.org/doc/tutorial/nif.html">NIFs</a>). This means there’s ample opportunity for productivity improvements just by bringing solutions from one domain and implementing them in another domain or making them faster! I love seeing <a href="https://github.com/constellation-rs/constellation">efforts</a> to <a href="https://akka.io/">bring</a> Erlang’s benefits to <a href="https://github.com/gleam-lang/gleam">more</a> <a href="https://phoenixframework.org/">areas</a>. And even Erlang doesn’t solve all of these problems to the extent I believe it’s possible to one day address them.</p>

<p>I think one of the real biggest hammers you can take to these problems is just to try <em>really hard</em> to avoid writing a distributed system in the first place. One of my goals for this post is to inspire people to try to develop more general solutions instead of having to repeatedly implement specific patterns٫ but my other goal is to try and put all the costs in your face at once and say <em>are you sure adding that separate networked system will really make your job easier?</em> Sometimes a distributed system is unavoidable٫ such as if you want extreme availability or computing power٫ but other times it’s totally avoidable. To pick specific examples:</p>

<ul>
  <li>I think people should be more willing to try and write performance-sensitive code as a (potentially multi-threaded) process on one machine in a fast language if it’ll fit rather than try and distribute a slower implementation over multiple machines. I acknowledge that this takes time and effort to learn how to do and optimize٫ but it’ll pay off in a simpler system.
    <ul>
      <li>In particular I think people should be more aggressive about trying to use multi-threading on a really big computer when possible. I personally find multi-threaded programming in <a href="https://www.rust-lang.org/">Rust</a> way easier than parallelizing with multiple processes when it’s viable. Some problems like asynchrony are similar but others like serialization٫ latency and bandwidth largely go away except at performance levels way higher than you’d probably get out of a hypothetical distributed version.</li>
    </ul>
  </li>
  <li>I think people should be more willing to use C FFI to bind to libraries in other languages rather than putting them in a separate networked service (<a href="https://github.com/sourcegraph/syntect_server">example</a> picking on users of my own library٫ although I don’t actually know what their constraints were). Yes you have to learn how to do C FFI and deal with unsafety٫ but I’d take that trade to avoid the network service.</li>
  <li>There are reasons people choose to split things into separate services other than availability and parallelism. For example ability to deploy updates quickly without coordinating with another team٫ fast CI٫ using a different language٫ isolation.
    <ul>
      <li>We should build more alternatives that don’t involve separate systems٫ like tools for using auto-updating hot-reloaded dynamically linked libraries with sandboxing instead of microservices (eliminating “narrow”٫ “laggy” and “asynchronous”). I’m pretty sure at least one instance of hot-reloading dylib updates pushed over the network exists (I’d appreciate links!) but we’re far from availability of excellent implementations in many languages and in the mean time it isn’t a viable alternative for most people considering adding a microservice to build this themselves.</li>
      <li>Better tools for continuous integration٫ continuous deployment٫ isolation٫ and monorepos can reduce the incentive to split off services to reduce iteration cycle time.</li>
    </ul>
  </li>
</ul>

<p>I follow Jonathan Blow’s <a href="https://twitter.com/Jonathan_Blow">Twitter</a> and <a href="https://www.youtube.com/user/jblow888">streams</a> and end up with mixed feelings. On the one hand I resonate with his feeling that modern software is way more complex than it needs to be and like the aesthetic and focus on performance and compile time power embodied in his language. On the other hand when he rants about how modern programmers just don’t know how to do things the Good Old Ways™ and need to stop making terrible design choices to be productive٫ I can’t help but think back to how I as one person have both been what he considers terribly unproductive working on web systems٫ and productive and effective when writing fast systems in his preferred style. It’s not that I just made terrible decisions sometimes but not other times٫ or was unaware of systems programming or data oriented design٫ it’s that I was facing different tradeoffs that forced me to make a distributed system and face a bunch of unproductive challenges that aren’t fully solved. The distributed systems I work on nowadays are low level٫ very fast٫ minimize layers of complexity٫ and my coworkers are extremely skilled. If anything٫ I’m less productive per similar-sounding feature when I work on these distributed systems than I was when I was programming in Ruby on Rails٫ because there’s less available tooling than for Rails. Most of my effort still goes into addressing the same distributed systems problems٫ which you just have to deal with less when programming a game. I agree with him that it’s totally possible for things to be better and dramatically less complex٫ but people decide to use established technologies because they don’t have the luxury of taking the time to write their ideal platform from scratch first. That’s why I’m so excited when people like him work to develop new tools like his language. I think even if everybody suddenly knew all his favorite game developer skills٫ more people would have the ability to build new types of tools٫ but until those tools were built٫ creating distributed systems would remain hard and unproductive. Also to make sure I tick off Blow fans and haters alike I should say that I recommend watching some of his streams٫ I think he’s really interesting٫ skilled and worth listening to٫ despite his abrasiveness and strong opinions. I find “what about this design would Jonathan Blow yell about being terrible” a good lens to help me come up with interesting alternatives.</p>

<p>Anyhow٫ I hope this leads you to think about the ways that your work could be more productive if you had better tools to deal with distributed systems٫ and what those might be. Alternatively I hope it prompts you to seriously consider the costs of writing distributed systems and what you can do to bend all the tradeoffs in your area of the programming world more towards non-distributed systems. Also try to think about what reasons people might not appear to you to be as good at developing software as you are with your Chosen Technology™ and how you can understand the constraints and tradeoffs they are dealing with and what solutions might shift the balance.</p>
'),('http://thume.ca/2020/04/18/telefork-forking-a-process-onto-a-different-computer/', 'Teleforking a process onto a different computer!', '1587168000000',  13, '
<p>One day a coworker mentioned that he was thinking about APIs for distributed compute clusters and I jokingly responded “clearly the ideal API would be simply calling <code class="language-plaintext highlighter-rouge">telefork()</code> and your process wakes up on every machine of the cluster with the return value being the instance ID”. I ended up captivated by this idea: I couldn’t get over how it was clearly silly٫ yet way easier than any remote job API I’d seen٫ and also seemingly not a thing computers could do. I also kind of knew how I could do it٫ and I already had a good name which is the hardest part of any project٫ so I got to work.</p>

<p>In one weekend I had a basic prototype٫ and in another weekend I had a demo where I could <code class="language-plaintext highlighter-rouge">telefork</code> a process to a giant VM in the cloud٫ run a path tracing render job on lots of cores٫ then telefork the process back٫ all wrapped in a simple API.</p>

<p>Here’s a video of it running a render on a 64 core cloud VM in 8 seconds (plus 6s each for the telefork there and back). The same render takes 40s running locally in a container on my laptop:</p>

<video controls="" width="660" autoplay="" muted="" loop="">
    <source src="/assets/postassets/telefork/telefork-small.mp4" type="video/mp4" />
    Sorry٫ your browser doesn"t support embedded videos.
</video>

<p>How is it possible to teleport a process? That’s what this article is here to explain! The basic idea is that at a low level a Linux process has only a few different parts٫ and for each of them you just need a way to retreive it from the donor٫ stream it over the network٫ and copy it into the cloned process.</p>

<p>You may be thinking٫ “but wait٫ how can you replicate [some reasonable thing like a TCP connection]?” Basically I just don’t replicate tricky things so that I could keep it simple٫ meaning it’s <strong>just a fun tech demo</strong> you probably shouldn’t use for anything real. It can still teleport a broad class of mostly computational programs though!</p>

<h2 id="what-does-it-look-like">What does it look like</h2>

<p>I wrote it as a Rust library but in theory you could wrap it in a C API and then use it via FFI bindings to teleport even a Python process. <a href="https://github.com/trishume/telefork">The implementation</a> is only about 500 lines of code (plus 200 lines of comments) and you use it like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">use</span> <span class="nn">telefork</span><span class="p">::{</span><span class="n">telefork</span><span class="p">٫</span> <span class="n">TeleforkLocation</span><span class="p">};</span>

<span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">args</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">String</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nn">std</span><span class="p">::</span><span class="nn">env</span><span class="p">::</span><span class="nf">args</span><span class="p">()</span><span class="nf">.collect</span><span class="p">();</span>
    <span class="k">let</span> <span class="n">destination</span> <span class="o">=</span> <span class="n">args</span><span class="nf">.get</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="nf">.expect</span><span class="p">(</span><span class="s">"expected arg: address of teleserver"</span><span class="p">);</span>

    <span class="k">let</span> <span class="k">mut</span> <span class="n">stream</span> <span class="o">=</span> <span class="nn">std</span><span class="p">::</span><span class="nn">net</span><span class="p">::</span><span class="nn">TcpStream</span><span class="p">::</span><span class="nf">connect</span><span class="p">(</span><span class="n">destination</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
    <span class="k">match</span> <span class="nf">telefork</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">stream</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">()</span> <span class="p">{</span>
        <span class="nn">TeleforkLocation</span><span class="p">::</span><span class="nf">Child</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="p">{</span>
            <span class="nd">println!</span><span class="p">(</span><span class="s">"I teleported to another computer and was passed {}!"</span><span class="p">٫</span> <span class="n">val</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="nn">TeleforkLocation</span><span class="p">::</span><span class="n">Parent</span> <span class="k">=&gt;</span> <span class="nd">println!</span><span class="p">(</span><span class="s">"Done sending!"</span><span class="p">)٫</span>
    <span class="p">};</span>
<span class="p">}</span>
</code></pre></div></div>

<p>I also provide a helper called <code class="language-plaintext highlighter-rouge">yoyo</code> that <code class="language-plaintext highlighter-rouge">telefork</code>s to a server٫ executes a closure you give it٫ then <code class="language-plaintext highlighter-rouge">telefork</code>s back. This provides the illusion that you can easily run a snippet of code on a remote server٫ perhaps one with much more compute power available.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// load the scene locally٫ this might require loading local scene files to memory</span>
<span class="k">let</span> <span class="n">scene</span> <span class="o">=</span> <span class="nf">create_scene</span><span class="p">();</span>
<span class="k">let</span> <span class="k">mut</span> <span class="n">backbuffer</span> <span class="o">=</span> <span class="nd">vec!</span><span class="p">[</span><span class="nn">Vec3</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="mf">0.0</span><span class="p">٫</span> <span class="mf">0.0</span><span class="p">٫</span> <span class="mf">0.0</span><span class="p">);</span> <span class="n">width</span> <span class="o">*</span> <span class="n">height</span><span class="p">];</span>
<span class="nn">telefork</span><span class="p">::</span><span class="nf">yoyo</span><span class="p">(</span><span class="n">destination</span><span class="p">٫</span> <span class="p">||</span> <span class="p">{</span>
  <span class="c">// do a big ray tracing job on the remote server with many cores!</span>
  <span class="nf">render_scene</span><span class="p">(</span><span class="o">&amp;</span><span class="n">scene</span><span class="p">٫</span> <span class="n">width</span><span class="p">٫</span> <span class="n">height</span><span class="p">٫</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">backbuffer</span><span class="p">);</span>
<span class="p">});</span>
<span class="c">// write out the result to the local file system</span>
<span class="nf">save_png_file</span><span class="p">(</span><span class="n">width</span><span class="p">٫</span> <span class="n">height</span><span class="p">٫</span> <span class="o">&amp;</span><span class="n">backbuffer</span><span class="p">);</span>
</code></pre></div></div>

<h2 id="anatomy-of-a-linux-process">Anatomy of a Linux process</h2>

<p>Let’s look at what a process on Linux (the OS <code class="language-plaintext highlighter-rouge">telefork</code> works on) looks like:</p>

<p><img src="/assets/postassets/telefork/process_anatomy.png" alt="Anatomy of a process diagram" /></p>

<ul>
  <li><strong>Memory mappings:</strong> These specify the ranges of bytes from the space of possible memory addresess that our program is using٫ composed of “pages” of 4 kilobytes. You can inspect them for a process using the <code class="language-plaintext highlighter-rouge">/proc/&lt;pid&gt;/maps</code> file. These contain both all the executable code of our program as well as the data it is working with.
    <ul>
      <li>There are a few different types of these but we can treat these as just ranges of bytes that need to be copied and recreated at the same place (with the exception of some special ones).</li>
    </ul>
  </li>
  <li><strong>Threads:</strong> A process can have multiple threads executing simultaneously on the same memory. These have ids and maybe some other state but when they’re paused they’re mainly described by the registers of the processor corresponding to the point of execution. Once we have all the memory copied we can just copy the register contents over into a thread on the destination process and then resume it.</li>
  <li><strong>File descriptors:</strong> The operating system has a table mapping ordinary integers to special kernel resources. You can do things with these resources by passing those integers to <a href="http://man7.org/linux/man-pages/man2/syscalls.2.html">syscalls</a>. There are a whole bunch of different types of resources these file descriptors can point to and some of them like TCP connections can be tricky to clone.
    <ul>
      <li>I just gave up on this part and don’t handle them at all. The only ones that work are stdin/stdout/stderr since those are always mapped to 0٫ 1 and 2 for you.</li>
      <li>That doesn’t mean it’s not possible to handle them٫ it just would take some extra work I’ll talk about later.</li>
    </ul>
  </li>
  <li><strong>Miscellaneous:</strong> There’s some other miscellaneous pieces of process state that vary in difficulty to replicate and most of the time aren’t important. Examples include the <a href="http://man7.org/linux/man-pages/man2/brk.2.html"><code class="language-plaintext highlighter-rouge">brk</code> heap pointer</a>. Some of these are only possible to restore using weird tricks or special syscalls like <a href="https://lore.kernel.org/patchwork/patch/494297/"><code class="language-plaintext highlighter-rouge">PR_SET_MM_MAP</code></a> that were added by other restoration efforts.</li>
</ul>

<p>So we can make a basic <code class="language-plaintext highlighter-rouge">telefork</code> implementation by just figuring out how to recreate the memory mappings and main thread registers. This should handle simple programs that mostly do computation without interacting with OS resources like files (in a way that needs to be teleported٫ opening a file on one system and closing it before calling <code class="language-plaintext highlighter-rouge">telefork</code> is fine).</p>

<h2 id="how-to-telefork-a-process">How to telefork a process</h2>

<p>I wasn’t the first to think of the possibility of recreating a process on another machine. I emailed <a href="https://robert.ocallahan.org/">@rocallahan</a>٫ the author of <a href="https://github.com/mozilla/rr">the rr record and replay debugger</a> to ask some questions since rr does some very similar things to what I wanted to do. He let me know of the existence of <a href="https://criu.org/Main_Page">CRIU</a>٫ which is an existing system that can stream a Linux process to a different system٫ designed for live migrating containers between hosts. CRIU supports restoring all sorts of file descriptors and other state٫ however the code was really complex and used lots of syscalls that required special kernel builds or root permissions. Linked from the CRIU wiki page I found <a href="http://dmtcp.sourceforge.net/">DMTCP</a> which was built for snapshotting distributed supercomputer jobs so they could be restarted later٫ and it had <a href="https://github.com/dmtcp/dmtcp/blob/7d02a2e063a8e70cc4d836d0b658124614666f44/src/mtcp/mtcp_restart.c">easier to follow code</a>.</p>

<p>These didn’t dissuade me from trying to implement my own system since they’re super complex and require special runners and infrastructure٫ and I wanted to show how simple a basic teleport can be and make it just a library call. So I read pieces of source code from <code class="language-plaintext highlighter-rouge">rr</code>٫ CRIU٫ DMTCP٫ and some ptrace examples٫ and put together my own <code class="language-plaintext highlighter-rouge">telefork</code> procedure. My method works in its own way that’s a hodgepodge of different techniques.</p>

<p>In order to teleport a process٫ there’s both work that needs to be done in the source process which calls <code class="language-plaintext highlighter-rouge">telefork</code>٫ and at the call to the function which receives a streamed process on the server and recreates it from the stream (<code class="language-plaintext highlighter-rouge">telepad</code>). These can happen concurrently٫ but it’s also possible to do all the serializing before loading٫ for example by dumping to a file then loading later.</p>

<p>Below is a simplified overview of both processes٫ if you want to know exactly how everything happens I encourage you to read <a href="https://github.com/trishume/telefork/blob/master/src/lib.rs">the source</a>. It’s heavily commented٫ all in one file٫ and ordered so you can read it top to bottom to understand how everything works.</p>

<h2 id="sending-a-process-using-telefork">Sending a process using <code class="language-plaintext highlighter-rouge">telefork</code></h2>

<p>The <code class="language-plaintext highlighter-rouge">telefork</code> function is given a writeable stream over which it sends all the state of its process.</p>

<ol>
  <li><strong>Fork the process</strong> into a frozen child. It can be hard for a process to inspect its own state since as it inspects the state things like the stack and registers change. We can avoid this by using a normal Unix <a href="http://man7.org/linux/man-pages/man2/fork.2.html"><code class="language-plaintext highlighter-rouge">fork</code></a> and then have the child stop itself so we can inspect it.</li>
  <li><strong>Inspect the memory mappings.</strong> This can be done by parsing <code class="language-plaintext highlighter-rouge">/proc/&lt;pid&gt;/maps</code> to find out where all the memory maps are. I used the <a href="https://github.com/rbspy/proc-maps">proc_maps crate</a> for this.</li>
  <li><strong>Send the info for special kernel maps.</strong> Based on what DMTCP does٫ instead of copying the contents of special kernel maps we remap them٫ and this is best done before the rest of the mapping so we stream them first without their contents. These special maps like <code class="language-plaintext highlighter-rouge">[vdso]</code> are used to make certain syscalls like getting the time faster.</li>
  <li><strong>Loop over the other memory maps and stream them</strong> to the provided pipe. I first serialize a structure containing info about the mapping and then I loop over the pages in it and use the <a href="http://man7.org/linux/man-pages/man2/process_vm_readv.2.html"><code class="language-plaintext highlighter-rouge">process_vm_readv</code></a> syscall to copy memory from the child to a buffer٫ then write that buffer to the channel.</li>
  <li><strong>Send the registers.</strong> I use the <code class="language-plaintext highlighter-rouge">PTRACE_GETREGS</code> option for the <a href="http://man7.org/linux/man-pages/man2/ptrace.2.html"><code class="language-plaintext highlighter-rouge">ptrace</code> syscall</a>٫ which allows me to get all register values of the child process. Then I just write them in a message over the pipe.</li>
</ol>

<h2 id="running-syscalls-in-a-child-process">Running syscalls in a child process</h2>

<p>In order to mold a target process into a copy of the incoming process we’ll need to get the process to execute a bunch of syscalls on itself without having access to any code٫ because we’ve deleted it all. Here’s how I do remote syscalls using <a href="http://man7.org/linux/man-pages/man2/ptrace.2.html"><code class="language-plaintext highlighter-rouge">ptrace</code></a>٫ which is a versatile syscall for manipulating and inspecting other processes:</p>

<ol>
  <li><strong>Find a syscall instruction</strong>. You need at least one syscall instruction for the child to execute to be in an executable mapping. Some people patch one in٫ but instead I use <code class="language-plaintext highlighter-rouge">process_vm_readv</code> to read the first page of the kernel <code class="language-plaintext highlighter-rouge">[vdso]</code> mapping٫ which as far as I know contains at least one syscall in all Linux versions so far٫ and then search through the bytes for its offset. I only do this once and update it when I move the <code class="language-plaintext highlighter-rouge">[vdso]</code> mapping.</li>
  <li><strong>Set up the registers</strong> to execute a syscall using <code class="language-plaintext highlighter-rouge">PTRACE_SETREGS</code>. The instruction pointer points to the syscall instruction٫ <code class="language-plaintext highlighter-rouge">rax</code> holds the <a href="https://filippo.io/linux-syscall-table/">Linux syscall number</a>٫ and <code class="language-plaintext highlighter-rouge">rdi٫ rsi٫ rdx٫ r10٫ r8٫ r9</code> hold the arguments.</li>
  <li><strong>Step the process one instruction</strong> using the <code class="language-plaintext highlighter-rouge">PTRACE_SINGLESTEP</code> option to execute the syscall instruction.</li>
  <li><strong>Read the registers</strong> using <code class="language-plaintext highlighter-rouge">PTRACE_GETREGS</code> to retreive the syscall return value and see if it succeeded.</li>
</ol>

<h2 id="receiving-a-process-using-telepad">Receiving a process using <code class="language-plaintext highlighter-rouge">telepad</code></h2>

<p>Using this primitive and ones I’ve already described we can recreate the process:</p>

<ol>
  <li><strong>Fork a frozen child.</strong> Similar to sending except this time we need a child process we can manipulate to turn it into a clone of the process being streamed in.</li>
  <li><strong>Inspect the memory mappings.</strong> This time we need to know all the existing memory maps so we can remove them to make room for the incoming process.</li>
  <li><strong>Unmap the existing mappings.</strong> We loop over each of the mappings and manipulate the child process into calling <code class="language-plaintext highlighter-rouge">munmap</code> on them.</li>
  <li><strong>Remap the special kernel mappings.</strong> Read their destinations from the stream and use <code class="language-plaintext highlighter-rouge">mremap</code> to remap them to their target destination.</li>
  <li><strong>Stream in the new mappings.</strong> Use remote <code class="language-plaintext highlighter-rouge">mmap</code> to create the mappings٫ then <code class="language-plaintext highlighter-rouge">process_vm_writev</code> to stream memory pages into them.</li>
  <li><strong>Restore the registers.</strong> Use <code class="language-plaintext highlighter-rouge">PTRACE_SETREGS</code> to restore the registers for the main thread that were sent over٫ with the exception of <code class="language-plaintext highlighter-rouge">rax</code> which is the return value for the <code class="language-plaintext highlighter-rouge">raise(SIGSTOP)</code> that the snapshotted process stopped on٫ which we overwrite with an arbitrary integer passed to <code class="language-plaintext highlighter-rouge">telepad</code>.
    <ul>
      <li>The arbitrary value is used so the telefork server can pass the file descriptor of the TCP connection the process came in on٫ so that it can send data back٫ or in the case of <code class="language-plaintext highlighter-rouge">yoyo</code> execute a <code class="language-plaintext highlighter-rouge">telefork</code> back over the same connection.</li>
    </ul>
  </li>
  <li><strong>Restart the process</strong> with its brand new contents by using <code class="language-plaintext highlighter-rouge">PTRACE_DETACH</code>.</li>
</ol>

<h2 id="doing-more-things-properly">Doing more things properly</h2>

<p>There’s a few things that are still broken in my implementation of <code class="language-plaintext highlighter-rouge">telefork</code>. I know how to fix them all٫ but I’m satisfied with how much I’ve implemented and sometimes they’re tricky to fix. This describes a few interesting examples of those things:</p>

<ul>
  <li>Handling the vDSO properly. I <code class="language-plaintext highlighter-rouge">mremap</code> the vDSO in the same way that <a href="https://github.com/dmtcp/dmtcp/blob/7d02a2e063a8e70cc4d836d0b658124614666f44/src/mtcp/mtcp_restart.c#L813">DMTCP does</a> but that turns out to work only when restoring on the exact same kernel build. Copying the vDSO contents instead can work accross different builds of the same version٫ which is how I got my path tracing demo to work since getting the number of CPU cores in glibc checks the current time using the vDSO in order to cache the count. However the way to actually do it properly is to either patch all the vDSO functions to just execute syscall instructions like <code class="language-plaintext highlighter-rouge">rr</code> does٫ or to patch each vDSO function to jump to the vDSO function from the donor process.</li>
  <li>Restoring <code class="language-plaintext highlighter-rouge">brk</code> and other miscellaneous state. I tried to use a method from DMTCP to restore the <code class="language-plaintext highlighter-rouge">brk</code> pointer but it only works if the target <code class="language-plaintext highlighter-rouge">brk</code> is greater than the donor’s <code class="language-plaintext highlighter-rouge">brk</code>. The correct way to do it that also restores other things is <code class="language-plaintext highlighter-rouge">PR_SET_MM_MAP</code>٫ but that requires elevated permissions and a kernel build flag.</li>
  <li>Restoring thread local storage. Thread local storage in Rust seems to just work™ presumably because the FS and GS registers are restored٫ but there’s apparently some kind of <code class="language-plaintext highlighter-rouge">glibc</code> cache of the pid and tid that might mess up a different kind of thread local storage. One solution CRIU can do using fancy namespaces is restore the process with the same PID and TIDs.</li>
  <li>Restore some file descriptors. This could be done either using individual strategies for each type of file descriptor٫ like checking if a file with the same name/contents exists on the destination system٫ or forwarding all reads/writes to the process source system using FUSE. However it’s a ton of effort to support all the types of file descriptors٫ like running TCP connections٫ so DMTCP and CRIU just painstakingly implement the most common types and give up on things like <code class="language-plaintext highlighter-rouge">perf_event_open</code> handles.</li>
  <li>Handling multiple threads. Normal Unix <code class="language-plaintext highlighter-rouge">fork()</code> doesn’t do this٫ but it should just involve stopping all threads before the memory streaming٫ then copying their registers and reinstating them in threads in the cloned process.</li>
</ul>

<h2 id="even-crazier-ideas">Even crazier ideas</h2>

<p>I think this shows that some crazy things you might have thought weren’t possible can in fact be done given the right low level interfaces. Here’s some ideas extending on the basic telefork ideas that are totally possible to implement٫ although perhaps only with a very new or patched kernel:</p>

<ul>
  <li><strong>Cluster telefork.</strong> The original inspiration for telefork was the idea of streaming a process onto every machine in a compute cluster. You could maybe even use UDP multicast or peer-to-peer techniques to make the distribution of memory to the whole cluster faster. You probably also want to provide communication primitives.</li>
  <li><strong>Lazy memory streaming.</strong> CRIU submitted patches to the kernel to add something called <code class="language-plaintext highlighter-rouge">userfaultfd</code> that can catch page faults and map in new pages more efficiently than <code class="language-plaintext highlighter-rouge">SIGSEGV</code> handlers and <code class="language-plaintext highlighter-rouge">mmap</code>. This can let you stream in new pages of memory only as they are accessed by the program٫ allowing you to teleport processes with lower latency since they can start running basically right away.</li>
  <li><strong>Remote threads!</strong> You could transparently make a process think it was running on a machine with a thousand cores. You could use <code class="language-plaintext highlighter-rouge">userfaultfd</code> plus a <a href="https://patchwork.kernel.org/cover/11005675/">patch set for userfaultfd write protection</a> <a href="https://github.com/torvalds/linux/commit/63bef48fd6c9d3f1ba4f0e23b4da1e007db6a3c0">which was just merged earlier this month</a> to implement a cache-coherency algorithm like <a href="https://en.wikipedia.org/wiki/MESI_protocol">MESI</a> to replicate the process memory across a cluster of machines efficiently such that memory would only need to be transferred when one machine read a page another wrote to since its last read. Then threads are just sets of registers that are very cheap to distribute across machines by swapping them into the registers of pools of kernel threads٫ and intelligently rearrange so they’re on the same machine as other threads they communicate with. You could even make syscalls work by pausing on syscall instructions٫ transferring the thread to the original host machine٫ executing the syscall٫ then transferring back. This is basically the way your multi-core or multi-socket CPU works except using pages instead of cache lines and the network instead of buses. The same techniques like minimizing sharing between threads that work for multi-core programming would make programs run efficiently here. I think this could actually be very cool٫ although it might need more kernel support to work seamlessly٫ but it could allow you to program a distributed cluster the same way you program a many-core machine and (with a bunch of optimization tricks I haven’t yet written about) have it be competitively efficient with the distributed system you otherwise would have written.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>I think this stuff is really cool because it’s an instance of one of my favourite techniques٫ which is diving in to find a lesser-known layer of abstraction that makes something that seems nigh-impossible actually not that much work. Teleporting a computation may seem impossible٫ or like it would require techniques like serializing all your state٫ copying a binary executable to the remote machine٫ and running it there with special command line flags to reload the state. But underneath your favourite programming language there’s a layer of abstraction where you can choose a fairly simple subset of things that make it possible to teleport at least most pure computations in any language in 500 lines of code and a single weekend. I think this kind of diving down often leads to solutions that are simpler and more universal. Another one of my projects like this is <a href="https://blog.janestreet.com/commas-in-big-numbers-everywhere/">Numderline</a>.</p>

<p>Of course٫ they often seem like extremely cursed hacks and to a large extent they are. They do things in a way nobody expects٫ and when they break they break at a layer of abstraction they aren’t supposed to break at٫ like your file descriptors mysteriously dissapearing. Sometimes though you can hit the layer of abstraction just right and handle all the cases such that everything is seamless and magic٫ I think good examples of this are <a href="https://github.com/mozilla/rr">rr</a> (although telefork manages to be cursed enough to segfault it) and cloud VM live migration (basically telefork at the hypervisor layer).</p>

<p>I also like thinking about these things as inspiration for alternative ways computer systems could work. Why are our cluster computing APIs so much more difficult to use than just running a program that broadcasts functions to the cluster? Why is networked systems programming so much harder than multithreaded programming? Sure you can give all sorts of good reasons٫ but they’re mostly based on how difficult it would be given how other existing systems work. Maybe with the right abstraction or with enough effort a project could seamlessly make it work٫ it seems fundamentally possible.</p>
'),('http://thume.ca/2019/11/02/numderline-grouping-digits-using-opentype-shaping/', 'Numderline: Grouping digits using OpenType shaping', '1572652800000',  13, '
<p>I recently worked on a fun side project to make a font that used font shaping trickery to make it easier to read large numbers by underlining alternating digit groups or inserting fake commas.</p>

<p>I wrote about it on the Jane Street tech blog since I started work there recently and I came up with the idea to help me visually parse tables of latency numbers for my job.</p>

<p>You can read the post here: <a href="https://blog.janestreet.com/commas-in-big-numbers-everywhere/">https://blog.janestreet.com/commas-in-big-numbers-everywhere/</a></p>

<p><img src="/assets/postassets/numderline/numderline.png" alt="Screenshot of the font" /></p>

<p>You can also check out <a href="/numderline">the font demo and download site</a> and the <a href="https://github.com/trishume/numderline">Github repo for the font patcher</a>.</p>

<p>There’s one other large public technical document I’ve written off of my own site that I might as well link here as well٫ which is my documentation of how the Xi text editor’s CRDT works. Although it’s written more as documentation than as a generally accessible blog post٫ you may still find it interesting٫ it has lots of diagrams. You can read it <a href="https://github.com/xi-editor/xi-editor/blob/e8065a3993b80af0aadbca0e50602125d60e4e38/doc/crdt-details.md">here</a></p>
'),('http://thume.ca/2019/07/29/shenanigans-with-hash-tables/', 'Shenanigans With Hash Tables', '1564358400000',  13, '
<p>One reason to know how your data structures work is so that when your problem has unusual constraints you can tweak how they work to fit the problem better or work faster. In this article I’ll talk about four different fun tweaks to the concept of a hash table that I made in the process of using hash tables to implement interface method lookup vtables in <a href="/2019/04/18/writing-a-compiler-in-rust/">my compilers class Java-subset compiler</a>. The fact that I knew the contents and lookups of all the tables at compile time allowed me to heavily optimize the way the hash table worked at run time until the common case was just indexing an array at a constant offset! Even outside the context of compilers٫ I think this is an interesting source of inspiration for the ways you can tweak data structures for your purpose.</p>

<h2 id="background-on-vtables-and-interfaces">Background on vtables and interfaces</h2>

<p>For object-oriented languages٫ compilers usually use “<a href="https://pabloariasal.github.io/2017/06/10/understanding-virtual-tables/">vtables</a>” to implement method dispatch. This is when every object has a pointer to an array of function pointers corresponding to the different methods on that object. Each method has a fixed slot٫ with methods in base classes coming before inherited ones so that an object can be treated as its base class with the same offsets.</p>

<p>The problem is that implementing <a href="http://tutorials.jenkov.com/java/interfaces.html">interfaces</a> is harder since the vtable prefix trick doesn’t work. Java HotSpot implements interface method calls doing a linear search over a list of “itables” for each interface an object implements٫ then using inline caching and fancy JIT specialization to speed that up in the common case.</p>

<p>The simpler alternative is to make a giant table of every method signature present in the program (for Java that’s name and parameter types like <code class="language-plaintext highlighter-rouge">addNums(int٫int)</code>)٫ each class will have an instance of this table with the slots for methods it implements filled in (including ones inherited from superclasses)٫ and most slots empty. Then for interface dispatch you can just use a fixed offset for the interface method signature: easy and fast. The problem is the size of each table scales with the size of the program٫ and so does the number of tables٫ leading to <code class="language-plaintext highlighter-rouge">O(n^2)</code> scaling٫ making this technique non-viable for large programs.</p>

<h2 id="hash-vtables">Hash vtables</h2>

<p><img src="/assets/postassets/hashvtables/basic-hash-table.png" alt="Basic Hash Table Diagram" /></p>

<p>Instead of using a giant fixed table٫ we can use a hash table from method signature to method pointer. Since every table doesn’t need to be large enough to fit all method signatures in the entire program٫ this solves the scaling problem. For simplicity we’ll use <a href="http://www.cs.rmit.edu.au/online/blackboard/chapter/05/documents/contribute/chapter/05/linear-probing.html">linear probing</a> to handle the case when our hash tries to put two methods in the same slot: we put the colliding method in the next available slot.</p>

<p>However this is now much slower than simple tables. A simple hash table lookup with linear probing includes two operations that need to loop over the bytes in the signature as well as a probing loop:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="nc">TableEntry</span> <span class="p">{</span>
  <span class="kt">char</span> <span class="o">*</span><span class="n">signature</span><span class="p">;</span> <span class="c1">// assume signatures are strings for simplicity</span>
  <span class="kt">void</span> <span class="o">*</span><span class="n">fnAddr</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="o">*</span><span class="nf">lookup</span><span class="p">(</span><span class="n">TableEntry</span> <span class="o">*</span><span class="n">table</span><span class="p">٫</span> <span class="kt">size_t</span> <span class="n">tableSize</span><span class="p">٫</span> <span class="kt">char</span> <span class="o">*</span><span class="n">query</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">uint32_t</span> <span class="n">queryHash</span> <span class="o">=</span> <span class="n">hash</span><span class="p">(</span><span class="n">query</span><span class="p">);</span> <span class="c1">// &lt;- O(n) in signature length</span>
  <span class="c1">// look in the next slot if a collision bumped our target from its place</span>
  <span class="k">for</span><span class="p">(;;</span><span class="n">queryHash</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">queryHash</span> <span class="o">%=</span> <span class="n">tableSize</span><span class="p">;</span>
    <span class="n">TableEntry</span> <span class="n">entry</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="n">queryHash</span><span class="p">];</span>
    <span class="k">if</span><span class="p">(</span><span class="n">strcmp</span><span class="p">(</span><span class="n">query</span><span class="p">٫</span> <span class="n">entry</span><span class="p">.</span><span class="n">signature</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// &lt;- O(n) in signature length</span>
      <span class="k">return</span> <span class="n">entry</span><span class="p">.</span><span class="n">fnAddr</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Why use <code class="language-plaintext highlighter-rouge">queryHash %= tableSize</code> instead of just indexing with <code class="language-plaintext highlighter-rouge">queryHash % tableSize</code>? I did that in the initial draft of this post٫ but then I realized it breaks when the initial hash is close to the maximum integer and probing causes <code class="language-plaintext highlighter-rouge">queryHash</code> to overflow to zero. That would have been a very evil bug since it would silently give the wrong result but only exceedingly rarely.</p>

<h2 id="hashing-at-compile-time">Hashing at compile time</h2>

<p><img src="/assets/postassets/hashvtables/comptime-table.png" alt="Compile Time Hash Table Diagram" /></p>

<p>First we’ll take advantage of the fact that we know which signatures are going to be used for each method call lookup at compile time٫ so we can do the hashing at compile time and then just compare the hashes when probing. This way we don’t even need to store the signatures in table for comparison٫ just the hashes.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="nc">TableEntry</span> <span class="p">{</span>
  <span class="kt">uint32_t</span> <span class="n">hash</span><span class="p">;</span>
  <span class="kt">void</span> <span class="o">*</span><span class="n">fnAddr</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="o">*</span><span class="nf">lookup</span><span class="p">(</span><span class="n">TableEntry</span> <span class="o">*</span><span class="n">table</span><span class="p">٫</span> <span class="kt">size_t</span> <span class="n">tableSize</span><span class="p">٫</span> <span class="kt">uint32_t</span> <span class="n">queryHash</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">for</span><span class="p">(;;</span><span class="n">queryHash</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">queryHash</span> <span class="o">%=</span> <span class="n">tableSize</span><span class="p">;</span>
    <span class="n">TableEntry</span> <span class="n">entry</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="n">queryHash</span><span class="p">];</span>
    <span class="k">if</span><span class="p">(</span><span class="n">entry</span><span class="p">.</span><span class="n">hash</span> <span class="o">==</span> <span class="n">queryHash</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">return</span> <span class="n">entry</span><span class="p">.</span><span class="n">fnAddr</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Now our method lookup is simple enough that we can viably translate it to assembly and insert a version of it at every method call site. In the common case of no probing٫ branch prediction and out of order execution in modern processors should even make it so the cost over a normal vtable lookup is minimal!</p>

<h2 id="avoiding-collisions-with-rehashing">Avoiding collisions with rehashing</h2>

<p>The above approach has a problem٫ which is that we stopped handling hash collisions. A method call could resolve incorrectly if two different signatures hash to the same thing. According to <a href="https://en.wikipedia.org/wiki/Birthday_problem">my most frequently referenced Wikipedia page</a>٫ at 32 bits for our hash we’re not safe from collisions in large programs٫ even if we use a strong hash function.</p>

<p>My solution to this is to keep a table at compile time of which hash value I’m using for each signature. When I’m adding a new signature to the table I append an additional integer before hashing٫ and if the resulting value collides with an existing hash٫ then I increment the integer and hash again until I get a value that doesn’t collide. This ensures that comparing signatures only by hash in the lookup is valid because hashes uniquely identify signatures.</p>

<h2 id="sizing-the-table-ahead-of-time">Sizing the table ahead of time</h2>

<p><img src="/assets/postassets/hashvtables/fixed-table.png" alt="Fixed Hash Table Diagram" /></p>

<p>In our above examples we need to pass in the table size to our lookup. If each class can have differently sized tables٫ we also need to store the size somewhere accessible٫ like index <code class="language-plaintext highlighter-rouge">-1</code> from the vtable pointer. However loading the size means probably loading another cache line in serial٫ carrying a performance cost. The solution is to make all our hash vtables the same size.</p>

<p>The other problem is that the modulo operation is relatively expensive٫ having <a href="https://www.agner.org/optimize/instruction_tables.pdf">a latency of 20+ cycles</a>. For the initial lookup we can fix this by also doing the modulo at compile time٫ then moving the modulo to the probing case of the assembly stub. We can improve the probing case as well by making the table size always a power of 2٫ and then using a bitwise AND with a constant mask (which has 1 cycle of latency).</p>

<p>In our compiler I computed a fixed power-of-2 table size ahead of time by figuring out how many method signatures the largest table needed to store٫ multiplying by an arbitrary factor of 4 to avoid collisions (and thus probing)٫ then rounding up to a power of 2. I expect the size of classes follows a power law distribution so the largest class would scale with the log of the size of the program٫ making total table space <code class="language-plaintext highlighter-rouge">O(n log n)</code> in program size.</p>

<h2 id="probing-only-when-necessary">Probing only when necessary</h2>

<p>My final idea was that when I was building the tables I could track which signature hashes ever collide in a table and get placed in a slot other than their home slot٫ and thus may need probing. Then for all the signatures which never got placed outside their home slot٫ I could just not generate the probing code at those call sites! Non-probing sites also don’t need to check that the hash is equal (it always will be) and can do the modulo at compile time٫ making them just indexing a table.</p>

<p>The final probing and non-probing assembly method call stubs look something like this:</p>

<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">; == X86 Assembly for general case with probing٫ call target in eax</span>
<span class="nf">mov</span> <span class="nb">eax</span><span class="p">٫</span> <span class="p">[</span><span class="nb">eax</span><span class="p">]</span> <span class="c1">; eax = address of object -&gt; eax = address of vtable</span>
<span class="nf">mov</span> <span class="nb">ebx</span><span class="p">٫</span> <span class="mi">61</span> <span class="c1">; the initial slot index٫ hash % size</span>
<span class="nl">.callcmp:</span>
<span class="nf">mov</span> <span class="nb">ecx</span><span class="p">٫</span> <span class="p">[</span><span class="nb">eax</span> <span class="o">+</span> <span class="nb">ebx</span><span class="o">*</span><span class="mi">8</span><span class="p">]</span> <span class="c1">; get the hash at the current slot</span>
<span class="nf">cmp</span> <span class="nb">ecx</span><span class="p">٫</span> <span class="mi">1062035773</span> <span class="c1">; check if it matches the expected hash</span>
<span class="nf">je</span> <span class="nv">.docall</span><span class="p">:</span> <span class="c1">; jump if it did match</span>
<span class="nf">add</span> <span class="nb">ebx</span><span class="p">٫</span> <span class="mi">1</span> <span class="c1">; if not probe to the next bucket</span>
<span class="nf">and</span> <span class="nb">ebx</span><span class="p">٫</span> <span class="mi">127</span> <span class="c1">; bit mask for computing i % 128 (the table size)</span>
<span class="nf">jmp</span> <span class="nv">.callcmp</span> <span class="c1">; check the hash again</span>
<span class="nl">.docall:</span>
<span class="nf">call</span> <span class="p">[</span><span class="nb">eax</span> <span class="o">+</span> <span class="nb">ebx</span><span class="o">*</span><span class="mi">8</span> <span class="o">+</span> <span class="mi">4</span><span class="p">]</span> <span class="c1">; indirect call to the function pointer</span>


<span class="c1">; == X86 Assembly for case without probing٫ call target in eax</span>
<span class="nf">mov</span> <span class="nb">eax</span><span class="p">٫</span> <span class="p">[</span><span class="nb">eax</span><span class="p">]</span> <span class="c1">; eax = address of object -&gt; eax = address of vtable</span>
<span class="nf">call</span> <span class="p">[</span><span class="nb">eax</span> <span class="o">+</span> <span class="mi">492</span><span class="p">]</span> <span class="c1">; indirect call to the function at offset (hash%size)*8+4</span>
</code></pre></div></div>

<p>Our arbitrary max table size expansion factor of 4 lead to only 0.13% of method call sites in our test program corpus needing probing٫ although larger programs would be less forgiving. This meant that in almost all cases my hash vtables emitted basically the same code as classic vtables would٫ except that the same vtables also worked for interfaces as well! However the tables being larger than classic vtables in the non-interface case mean they’ll be less efficient with cache space and so would be somewhat slower in practice.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I’ve never heard of anyone implementing interface vtables in this way٫ but I wouldn’t be surprised if there is prior art because these are all just simple insights you can have by thinking about how to specialize a hash table for this problem. I think LuaJit does some similar tricks for its hash tables where its tracing JIT can specialize on the hash value and optimize an index lookup plus bailing from the trace if the key doesn’t match.</p>

<p>According to my compilers class professor there’s a broad literature of optimizing the “giant table with all signatures” approach with heuristics for saving space by rearranging and merging the tables of different classes into the same space or re-using offsets across classes to make tables smaller. But the general problem is NP-complete so can only be solved heuristically. Interestingly I ended up with a kind of similar direction which re-uses offsets effectively randomly٫ but then includes a mechanism for handling the resulting collisions.</p>

<p>I hope you found some of these hash table tricks fun and came away inspired to think about how you might be able to modify a common data structure to fit your application better!</p>
'),('http://thume.ca/2019/07/27/two-performance-aesthetics/', 'Two Performance Aesthetics: Never Miss a Frame and Do Almost Nothing', '1564185600000',  13, '
<p>I’ve noticed when I think about performance nowadays that I think in terms of two different aesthetics. One aesthetic٫ which I’ll call <em>Never Miss a Frame</em>٫ comes from the world of game development and is focused on writing code that has good worst case performance by making good use of the hardware. The other aesthetic٫ which I’ll call <em>Do Almost Nothing</em> comes from a more academic world and is focused on algorithmically minimizing the work that needs to be done to the extent that there’s barely any work left٫ paying attention to the performance at all scales. In this post I’ll describe the two aesthetics٫ look at some case studies of pairs of programs in different domains that follow different aesthetics٫ and talk about the trade-offs involved and how to choose which direction to lean for a project.</p>

<h2 id="never-miss-a-frame">Never Miss a Frame</h2>

<p>In game development the most important performance criteria is that your game doesn’t miss frame deadlines. You have a target frame rate and if you miss the deadline for the screen to draw a new frame your users will notice the jank. This leads to focusing on the worst case scenario and often having fixed maximum limits for various quantities. This property can also be important in areas other than game development٫ like other graphical applications٫ <a href="http://www.rossbencina.com/code/real-time-audio-programming-101-time-waits-for-nothing">real-time audio</a>٫ safety-critical systems and many embedded systems. A similar dynamic occurs in distributed systems where one server needs to query 100 others and combine the results٫ you’ll wait for the slowest of the 100 every time so speeding up some of them doesn’t make the query faster٫ and queries occasionally taking longer (e.g because of garbage collection) will impact almost every request!</p>

<p>A consequence of deadlines is that it’s not worth saving time unless you can save it in all cases. Things like caching often don’t help because if the item isn’t in the cache then you’ll miss your deadline. The easiest way to achieve this is to just do all the work every single frame and don’t keep anything between frames except for persistent state.</p>

<p>In this kind of domain you’ll often run into situations where in the worst case you can’t avoid processing a huge number of things. This means you need to focus your effort on making the best use of the hardware by writing code at a low level and paying attention to properties like cache size and memory bandwidth.</p>

<p>Projects with inviolable deadlines need to adjust different factors than speed if the code runs too slow. For example a game might decrease the size of a level or use a more efficient but less pretty rendering technique.</p>

<p>Aesthetically: Data should be tightly packed٫ fixed size٫ and linear. Transcoding data to and from different formats is wasteful. Strings and their variable lengths and inefficient operations must be avoided. Only use tools that allow you to work at a low level٫ even if they’re annoying٫ because that’s the only way you can avoid piles of fixed costs making everything slow. Understand the machine and what your code does to it.</p>

<p>Personally I identify this aesthetic most with <a href="https://www.youtube.com/user/jblow888">Jonathan Blow</a>. He has a very strong personality and I’ve watched enough of videos of him that I find imagining “What would Jonathan Blow say?” as a good way to tap into this aesthetic. My favourite articles about designs following this aesthetic are on the <a href="https://ourmachinery.com/post/">Our Machinery Blog</a>.</p>

<h2 id="do-almost-nothing">Do Almost Nothing</h2>

<p>Sometimes٫ it’s important to be as fast as you can in all cases and not just orient around one deadline. The most common case is when you simply have to do something that’s going to take an amount of time noticeable to a human٫ and if you can make that time shorter in some situations that’s great. Alternatively each operation could be fast but you may run a server that runs tons of them and you’ll save on server costs if you can decrease the load of some requests. Another important case is when you care about power use٫ for example your text editor not rapidly draining a laptop’s battery٫ in this case you want to do the least work you possibly can.</p>

<p>A key technique for this approach is to never recompute something from scratch when it’s possible to re-use or patch an old result. This often involves caching: keeping a store of recent results in case the same computation is requested again.</p>

<p>The ultimate realization of this aesthetic is for the entire system to deal only in differences between the new state and the previous state٫ updating data structures with only the newly needed data and discarding data that’s no longer needed. This way each part of the system does almost no work because ideally the difference from the previous state is very small.</p>

<p>Aesthetically: Data must be in whatever structure scales best for the way it is accessed٫ lots of trees and hash maps. Computations are graphs of inputs and results so we can use all our favourite graph algorithms to optimize them! Designing optimal systems is hard so you should use whatever tools you can to make it easier٫ any fixed cost they incur will be made negligible when you optimize away all the work they need to do.</p>

<p>Personally I identify this aesthetic most with my friend <a href="https://www.patreon.com/raphlinus">Raph Levien</a> and his <a href="https://xi-editor.io/docs.html">articles about the design of the Xi text editor</a>٫ although Raph also appreciates the other aesthetic and <a href="https://raphlinus.github.io/rust/graphics/gpu/2019/05/08/modern-2d.html">taps into it himself sometimes</a>.</p>

<h2 id="the-tradeoff">The Tradeoff</h2>

<p>Ideally it would be possible to follow both of these ideals simultaneously٫ writing code that does the minimal amount of work as fast as the machine can possibly perform it. In some cases this is possible but in most cases developers have more important things to do٫ or there’s a trade-off like caching slowing down the wost case. I’m conflating the axes of deadline-oriented vs time-oriented and low-level vs algorithmic optimization٫ but part of my point is that while they are different٫ I think these axes are highly correlated.</p>

<p>In practice when I see people set out to make a fast piece of software٫ depending on the project’s goals and their background٫ they tend to lean towards one aesthetic or the other. If every operation in your software never lags٫ then there’s often no reason to save additional work. If you’ve made everything in your system incremental to the point where everything is doing minimal work٫ there’s little reason to optimize the operations at a low level since they take negligible time.</p>

<p>That isn’t to say that people trying to make fast software shouldn’t understand both approaches. You don’t want to ignore either constant factors and the size of N in practice٫ or ignore the overall scaling and the quality of the algorithms you’re using. For each task you may use mostly one approach or the other٫ but choosing the approach based on the task rather than always using only one or the other is a valuable skill.</p>

<h2 id="case-studies">Case Studies</h2>

<h3 id="gui-toolkits">GUI Toolkits</h3>

<p>In the olden days٫ GUIs were rendered with slow CPUs that couldn’t quite render an entire screen’s UI in one frame. This necessitated a <em>Do Almost Nothing</em> approach to GUI toolkits٫ where they kept track of the current state of the UI along with all sorts of saved computations like layout. Events would try to plumb minimal updates through the whole pipeline٫ touching as little as possible and then redrawing only the rectangle on the screen that actually needed to be updated٫ like the single new character you typed. But some updates like opening a new window wouldn’t be able to take advantage of this and might take multiple frames. This design is called “retained mode GUI” and is still around today in most GUI toolkits (with some extensions to use the GPU for scrolling and drawing). It’s still around because it works٫ it’s what people know٫ and it ended up good for battery life once laptops and smartphones arrived.</p>

<p>However٫ at some point computers and GPUs became powerful enough that it was possible to render an entire screen full of UI from scratch ever frame. This spawned an alternative approach called “immediate mode GUI” or “<a href="https://github.com/ocornut/imgui">imgui</a>” where instead of creating persistent widgets that stick around and can cache computations٫ you just call functions that figure out how a widget should look and then write data to buffers for the GPU. This is super fast and will always render in one frame provided you don’t render an absurd amount of UI. However٫ since it’s harder for an imgui to cache things they can’t easily do some things that retained mode UI’s can do٫ like render a long document of internationalized text scrolled to the bottom. All existing internationalized text shaping libraries are too slow to shape a long document in one frame٫ so immediate mode GUI libraries usually just don’t support internationalized text.</p>

<h3 id="text-editors">Text Editors</h3>

<p><a href="https://www.sublimetext.com/">Sublime Text</a> is a text editor that mostly follows the <em>Never Miss a Frame</em> approach. Basically every operation is instant because all the operations have been implemented very efficiently. However٫ some things like syntax highlighting don’t quite run fast enough to be instant at large file sizes so Sublime does have infrastructure for caching highlighting٫ and sometimes throws up progress bars when opening large files. Sublime makes trade-offs to use simple but efficient data structures by sacrificing performance in rare cases like editing extremely long lines. This architecture doesn’t always deal well with external code that isn’t designed to be instant though٫ plugins that communicate with slow compilers can sometimes temporarily hang the editor.</p>

<p>The <a href="https://github.com/xi-editor/xi-editor">Xi Editor</a> is designed to solve this problem by being designed from the ground up to grapple with the fact that some operations٫ especially those interacting with slow compilers written by other people٫ can’t be made instantaneous. It does this using a fancy asynchronous plugin model and lots of fancy data structures. It tries to allow a native frontend for each platform despite the slowness of cross-language communication over JSON by only ever plumbing minimal deltas over the pipe٫ so the slowness doesn’t matter. It uses a fancy tree-based rope data structure to make even editing very long lines efficient. Many parts of this worked great٫ and Xi is extremely fast in many ways. The issue facing the Xi project today is that designing complex data structures and protocols to make every single operation incremental and asynchronous makes progress very slow.</p>

<p>An editor that leans into the <em>Never Miss a Frame</em> aesthetic even harder than Sublime Text is <a href="https://github.com/makepad/makepad">Makepad</a>. It’s a work-in-progress editor that uses an imgui-esque custom UI toolkit to render everything٫ making heavy use of the GPU. Layout and highlighting for the entire file is calculated every single frame by highly optimized code. This will drop frames on rare 10k line files٫ but for all other files allows fancy things other editors couldn’t easily do like pressing <code class="language-plaintext highlighter-rouge">alt</code> to smoothly animate into an overlay of the functions in the whole file.</p>

<h3 id="compilers">Compilers</h3>

<p>Jonathan Blow’s <a href="https://github.com/BSVino/JaiPrimer/blob/master/JaiPrimer.md">Jai</a> compiler is clearly designed with the <em>Never Miss a Frame</em> aesthetic. It’s written to be extremely fast at every level٫ and the language doesn’t have any features that necessarily lead to slow compiles. The LLVM backend wasn’t fast enough to hit his performance goals so he wrote an alternative backend that directly writes x86 code to a buffer without doing any optimizations. Jai compiles something like 100٫000 lines of code per second. Designing both the language and compiler to not do anything slow lead to clean build performance 10-100x faster than other commonly-used compilers. Jai is so fast that its clean builds are faster than most compilers incremental builds on common project sizes٫ due to limitations in how incremental the other compilers are.</p>

<p>However٫ Jai’s compiler is still O(n) in the codebase size where incremental compilers can be O(n) in the size of the change. Some compilers like the work-in-progress <a href="https://github.com/rust-analyzer/rust-analyzer">rust-analyzer</a> and I think also <a href="https://github.com/dotnet/roslyn">Roslyn for C#</a> take a different approach and focus incredibly hard on making everything fully incremental. For small changes (the common case) this can let them beat Jai and respond in milliseconds on arbitrarily large projects٫ even if they’re slower on clean builds.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I find both of these aesthetics appealing٫ but I also think there’s real trade-offs that incentivize leaning one way or the other for a given project. I think people having different performance aesthetics٫ often because one aesthetic really is better suited for their domain٫ is the source of a lot of online arguments about making fast systems. The different aesthetics also require different bases of knowledge to pursue٫ like knowledge of data-oriented programming in C++ vs knowledge of abstractions for incrementality like <a href="http://adapton.org/">Adapton</a>٫ so different people may find that one approach seems way easier and better for them than the other.</p>

<p>I try to choose how to dedicate my effort to pursuing each aesthetics on a per project basis by trying to predict how effort in each direction would help. Some projects I know if I code it efficiently it will always hit the performance deadline٫ others I know a way to drastically cut down on work by investing time in algorithmic design٫ some projects need a mix of both. Personally I find it helpful to think of different programmers where I have a good sense of their aesthetic and ask myself how they’d solve the problem. One reason I like <a href="http://rust-lang.org/">Rust</a> is that it can do both <a href="https://doc.rust-lang.org/1.29.1/std/arch/index.html">low-level optimization</a> and also has a good <a href="https://crates.io/keywords/data-structures">ecosystem</a> and <a href="https://doc.rust-lang.org/beta/rust-by-example/custom_types/enum.html">type system</a> for algorithmic optimization٫ so I can more easily mix approaches in one project. In the end the best approach to follow depends not only on the task٫ but your skills or the skills of the team working on it٫ as well as how much time you have to work towards an ambitious design that may take longer for a better result.</p>
'),('http://thume.ca/2019/07/26/writing-a-beat-saber-patcher/', 'Writing a Beat Saber Patcher for the Oculus Quest', '1564099200000',  13, '
<p>After trying out VR and <a href="https://beatsaber.com/">Beat Saber</a> at <a href="https://www.ctrlv.ca/">Ctrl-V</a> and really enoying it٫ I decided to pre-order an <a href="https://www.oculus.com/quest/">Oculus Quest</a>٫ the first standalone VR headset with <a href="https://en.wikipedia.org/wiki/Six_degrees_of_freedom">6 DOF</a> head and hand tracking. As expected I really enjoyed playing Beat Saber and practicing to play more difficult songs٫ but I also ended up getting wrapped up in the Beat Saber modding community and developing <a href="https://github.com/trishume/QuestSaberPatch">a patcher</a> for adding custom songs which has been downloaded 80٫000 times. I figured out how to read and modify the <a href="https://unity.com/">Unity</a> asset file format used by Beat Saber٫ learned C#٫ and <a href="https://github.com/trishume/QuestSaberPatch">wrote a patcher</a> that could read in the game’s assets٫ modify them to add custom songs٫ and modify the APK in-place with the replaced asset files.</p>

<h2 id="early-discoveries">Early Discoveries</h2>

<p>I started off by joining the <a href="https://discordapp.com/invite/beatsabermods">Beat Saber Modding Group Discord</a> chat while my Quest was still shipping٫ and chatting with the other modders who were eager to figure out how to add custom songs to Beat Saber on the Quest like they have with the PC version. I didn’t have anything to poke at myself yet but I could still chime in with ideas٫ and I created a Google Doc where I collated and documented other people’s discoveries٫ which I encouraged other people to edit and write things in as they experimented.</p>

<p>Over a couple days we figured out that Beat Saber was compiled with <a href="https://docs.unity3d.com/Manual/IL2CPP.html">IL2CPP</a> so modding the C# code would be tricky٫ but while the levels were stored in a different format than the PC game٫ they were stored in the Unity asset bundles present in the APK. Some people who had Unity modding tools installed that could read and modify Unity asset files looked at the assets and found the levels but the beat maps looked like indecipherable compressed or encrypted data٫ then through some digging in disassembly and deduction <a href="https://github.com/emulamer">emulamer</a> figured out that it was the same data types the PC version used for levels٫ just encoded with C#’s <a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.serialization.formatters.binary.binaryformatter?view=netframework-4.8">BinaryFormatter</a> and then run through a <a href="https://docs.microsoft.com/en-us/dotnet/api/system.io.compression.deflatestream?view=netframework-4.8">DeflateStream</a>.</p>

<p>With this information <a href="https://github.com/emulamer">emulamer</a> could convert PC beatmaps (maps of the patterns of blocks to slash along with the song) to the format that went inside the Unity asset. This could then be patched into an APK using a Unity modding tool like <a href="http://www.devxdevelopment.com/">DevX</a>. However٫ we had noticed that levels contained a signature field so we suspected this wouldn’t work on its own and it didn’t٫ but it turned out the demo version didn’t check the signature and this lead to <a href="https://www.youtube.com/watch?v=ikQhUqDh56c">the first successful test</a>. We still needed to patch the signature check in the full version though٫ so I tried poking around in <a href="https://binary.ninja/">Binary Ninja</a> but couldn’t get anywhere because the library with all the code didn’t have symbols for the function names in it. However people on Windows were able to use tools like <a href="https://github.com/Perfare/Il2CppDumper">Il2CppDumper</a> to get symbols٫ and <a href="https://github.com/emulamer">emulamer</a> found the signature check and figured out an ARM machine code patch to replace the call to the verify signature function with a constant true. <a href="https://www.youtube.com/watch?v=o6QDfJ_OHLc">Elliot Tate used DevX and this knowledge to perform the first successful patch of the full game</a>.</p>

<h2 id="figuring-out-the-format">Figuring Out the Format</h2>

<p>So we knew how to patch in custom songs٫ the problem was we only knew how to do it with closed-source Windows GUI applications like DevX٫ which wasn’t going to help us deliver custom songs to lots of people٫ and as a macOS user it wasn’t going to help me. We needed to figure out how to patch Unity assets ourselves. So I did some Googling and while I didn’t find any open source code that could <em>modify</em> Unity assets٫ I did find <a href="https://github.com/Perfare/AssetStudio">code that could read them</a>. Now I just needed to extract an understanding of the asset file format from that code so I could write my own code that could read and modify.</p>

<p>I had heard about <a href="https://kaitai.io/">Kaita Struct</a> which lets you write descriptions of a binary format and it will parse it into a tree in a nice IDE for you٫ but when I tried it I found the IDE really slow٫ cumbersome and kinda broken. The format was also very declarative and verbose and I found it hard to use. So I considered buying <a href="https://www.synalysis.net/">Synalyze It</a>٫ which is a native macOS hex editor with similar capabilities٫ but its specification system seemed just as limited. Then (for some reason I forget) I realized that my version of <a href="https://ridiculousfish.com/hexfiend/">Hex Fiend</a> was many years old٫ and went looking for a newer version٫ which I found on <a href="https://github.com/ridiculousfish/HexFiend/releases">their Github</a>. In the changelog I saw that they had very recently added <a href="https://github.com/ridiculousfish/HexFiend/blob/master/templates/Tutorial.md">support for Binary Templates</a>٫ which used Tcl (a fully featured programming language!)٫ this was exactly what I was looking for!</p>

<p>So I gradually put together <a href="https://gist.github.com/trishume/138ef8f6c66fabd2d76b9fdf8d5c4c67">a Hex Fiend template for Unity assets</a> by figuring out open source asset loading code and adding more fields٫ debugging by reloading the template in Hex Fiend and checking the parse in the tree view to see that the values made sense. Eventually I figured out all the parts of the file necessary to mod in custom levels. The Hex Fiend template was invaluable for making it really easy to write a quick parser and debug my understanding against the real files. It was also valuable later on when I could look at the output of my patcher in a pretty tree view.</p>

<p>I also needed to figure out how the audio files referenced by the audio assets were included. I was originally worried it would be complex because the built-in songs were packed into concatenated resources in the proprietary <a href="http://fileformats.archiveteam.org/wiki/FMOD_Sample_Bank">FSB5</a> format that I thought I might need to reverse-engineer. However upon further testing it turned out we could just drop <code class="language-plaintext highlighter-rouge">.ogg</code> files in the APK and reference them as offset 0 in a resource pack٫ and Unity could load them.</p>

<h2 id="writing-a-patcher">Writing a Patcher</h2>

<p>Now I needed to write a patcher program that could take a Beat Saber APK and some custom songs in the PC JSON format٫ and produce an APK with the custom songs. I decided to use C# even though I had never used it before٫ because then I wouldn’t need to reverse-engineer the <code class="language-plaintext highlighter-rouge">BinaryFormatter</code> format used for the beatmap conversion٫ and it’s a nice enough language that works cross-platform. I also decided to structure my patcher as a library so it could be theoretically used in multiple different front ends٫ possibly including a C#-based GUI٫ as well as a command line tool and unit tests.</p>

<p>I started by writing <a href="https://github.com/trishume/QuestSaberPatch/blob/7a76d4e2e198c42584087281649af7efd2de4da9/LibSaberPatch/SerializedAssets.cs">a parser for the asset file format</a> that parsed it into C# classes٫ but classes with a structure carefully designed so that they preserved all the information necessary to recreate the file exactly٫ while being straightforward to modify. This involved combining the separate directory and contents of the file format into a unified list of assets with no offsets٫ and ensuring that I saved amounts of padding in fields in relevant objects. Then I wrote the functions to write those classes back out to an assets file. I used <a href="https://github.com/trishume/QuestSaberPatch/blob/7a76d4e2e198c42584087281649af7efd2de4da9/tests/SerializedAssetTests.cs#L21">a unit test</a> to check that I could parse and then write out an assets file to a byte-identical one with no errors٫ starting with a small file and fixing bugs until I could round-trip the main assets file with all the levels.</p>

<p>After that worked I implemented loading the JSON level files and modifying my assets file data structure to insert the new levels into the existing “Extras” level pack. I also needed to copy the audio files into the APK and patch the binary to disable the level signature check. I needed to modify the APK file٫ but I didn’t want to use the normal method of unzipping it (APKs are just zip files) into a temporary location and then zipping it back up٫ so I used the standard library <a href="https://docs.microsoft.com/en-us/dotnet/api/system.io.compression.ziparchive?view=netframework-4.8">ZipArchive</a> functionality which allowed me to modify the Zip file in-place.</p>

<p>After I got all this working and tested I just needed to write a small command line tool using the library I had written. This allowed me to patch my own Beat Saber for the first time and play my first custom level on my own Oculus Quest!</p>

<h2 id="the-competition">The Competition</h2>

<p>All this time٫ <a href="https://github.com/emulamer">emulamer</a> had also been working on his own patcher with a similar approach to mine. He was making faster progress than me٫ and patched in his first songs somewhat before I did٫ and by the time I patched in my first songs his patcher had already been packaged into a Windows GUI by someone else and people were using it. It also supported things mine didn’t yet like cover art and a separate “Custom Levels” pack instead of just putting things in the existing “Extras” pack.</p>

<p>I persisted though because I was having fun and my patcher had some differentiating factors that I imagined could make it competitive with more work:</p>

<ul>
  <li>Emulamer’s code was by his own admission very hacky and he was just trying to get it to work as fast as possible and fix it up later.</li>
  <li>Many parts of his patching process were controlled by a batch file and it didn’t work in-place on the APK like mine.</li>
  <li>His patcher wasn’t structured as a library and it would be a bunch of refactoring to make it present anything other than one command-line interface.</li>
  <li>I had been using DotNet Core on macOS from the start so I knew my patcher should work cross-platform٫ whereas his wasn’t designed to work on other platforms.</li>
</ul>

<p>So I set out to add more functionality to my patcher to compete!</p>

<h2 id="catching-up">Catching Up</h2>

<p>The first thing I did is add support for song cover art. I knew that <a href="https://github.com/emulamer">emulamer</a>’s cover art gave the game frame rate issues٫ which he assumed was because he didn’t resize textures and use texture compression. But when I looked at how the covers from the base game were stored٫ I noticed they didn’t use any compression but they did use <a href="https://en.wikipedia.org/wiki/Mipmap">mipmaps</a>٫ and lack of mipmaps definitely seemed like it could explain the lag. Looking at the cover data in my hex editor I noticed a repeating pattern that got higher-frequency further into the cover٫ so I guessed that it was probably raw RGB data for all the mip levels concatenated together. I checked what my guess would predict the file size would be against the actual file size and it matched exactly. So I <a href="https://github.com/trishume/QuestSaberPatch/commit/0c9e8be6279c1ee85e6bb9f9ff50151c2a21a467">added support for covers</a> with concatenated mipmaps of the size from the base game using <a href="https://github.com/SixLabors/ImageSharp">ImageSharp</a>. I let <a href="https://github.com/emulamer">emulamer</a> know about the mipmapping so he could reference the code and fix his frame rate issues.</p>

<p>Then I noticed a developer of <a href="https://sidequestvr.com">SideQuest</a> (a popular Electron GUI for side-loading apps onto the Oculus Quest) mentioning in the Discord that he was working on adding Beat Saber custom song support to SideQuest. I used the power of my patcher being a library to throw together a separate command line binary that used a JSON interface over stdin/stdout to provide an easy programmatic interface with more control. Then I included it in the <a href="https://github.com/trishume/QuestSaberPatch/pull/1">cross-platform CI builds that raftario contributed</a>٫ which used DotNet core’s ability to build a self-contained folder that includes the C# runtime and compiled program IL. I chatted with the SideQuest developer and pitched him on using my patcher because of the convenient cross-platform binaries with a uniform easy interface that could patch in-place.</p>

<p>The last major remaining obstacle to an easy cross-platform patcher was that after patching the APK needed to be signed using a Java-based JAR signer٫ requiring users to have 64-bit Java installed. Emulamer and I chatted about this and decided it seemed feasible to write a signer in C#٫ which he managed to do fairly quickly and let me use his code٫ and in turn I figured out how to speed up the signing by a lot and let him know how to improve the speed in his own patcher.</p>

<p>Soon my patcher was incorporated in a SideQuest release that people could use to (somewhat) easily patch custom songs into their Beat Saber!</p>

<h2 id="finishing-touches">Finishing Touches</h2>

<p>At this point <a href="https://github.com/sc2ad">sc2ad</a> had started working on my codebase and adding support for custom saber colors٫ removing songs٫ and custom packs. His code was still experimental٫ but I worked with him and did a lot of refactoring myself to integrate his code with how I wanted my patcher to work and eventually merged all of his work into <code class="language-plaintext highlighter-rouge">master</code>. As part of this process I wrote a new JSON-based command line with a new interface that allowed creating unlimited custom packs and organizing and ordering songs within them. The new code would then take an APK and synchronize the state with the songs you requested: adding٫ removing and rearranging the minimal amount necessary to update the APK quickly.</p>

<p>I let the SideQuest developer I talked to know these capabilities were coming and the SideQuest team developed an awesome interface for organizing your songs into custom playlists and synchronizing them. Soon the new version of my patcher was integrated into SideQuest and released to the world.</p>

<p>I had been scaling down the amount of time I spent working on Beat Saber patching٫ but as Beat Saber released updated versions I continued to update my patcher to be compatible with the new versions and improve its reliability. One of the Beat Saber updates removed the <code class="language-plaintext highlighter-rouge">BinaryFormatter</code> based beatmaps and switched to just JSON strings in the same format as the PC version with no signatures٫ which means eventually there was no reason my patcher needed to be in C# instead of my preferred Rust but I had already written thousands of lines of code so there was no point in switching.</p>

<p>Eventually things were working smoothly enough and I announced my intent to retire from Beat Saber patching and work on other things. SideQuest continued to be used by tons of people٫ with my patcher (downloaded automatically when people tried to use the SideQuest Beat Saber functionality) racking up 80٫000 downloads.</p>

<h2 id="the-next-chapter">The Next Chapter</h2>

<p>Emulamer hadn’t stopped working on Beat Saber patching though٫ after I retired he continued plugging away and eventually released <a href="https://github.com/emulamer/BeatOn">BeatOn</a>. BeatOn is an on-device patcher than uses a <a href="https://github.com/jakibaki/beatsaber-hook">C hook injection system by jakibaki</a> to redirect asset loading to mutable Android <code class="language-plaintext highlighter-rouge">/sdcard/</code> storage. This means that you can load new songs on your Quest and it doesn’t have to re-sign and re-install the APK so its faster. It also supports installing hook and asset mods for things like custom sabers and better swing score feedback. SideQuest also recently added support for installing BeatOn٫ accessing its UI from your computer٫ and copying your SideQuest song library to BeatOn. It’s basically completely replaced my patcher and is better in many ways٫ I’m glad for the progress and now use it myself.</p>

<h2 id="conclusion">Conclusion</h2>

<p>My Beat Saber patching journey is now over but it was a fun one. I learned a bunch from figuring out how to mod a game in practice٫ as well as some C# programming. I also had fun collaborating with everyone on the BSMG Discord and figuring out how Beat Saber worked with them. Competing with <a href="https://github.com/emulamer">emulamer</a> was also a fun experience since I think we both benefitted from trying to implement cool things the other hadn’t and then letting each other take the ideas or code so that both of our patchers could improve٫ it was a very fun friendly casual competition. I think it was a good use of some of my summer٫ I had fun doing it٫ I’ve been playing Beat Saber nearly every day enjoying my custom songs and now can comfortably play at expert+ level٫ and many people have presumably also had fun with their custom levels through SideQuest and my patcher.</p>

'),('http://thume.ca/2019/07/14/a-tour-of-metaprogramming-models-for-generics/', 'Models of Generics and Metaprogramming: Go٫ Rust٫ Swift٫ D and More', '1563062400000',  13, '
<p>In some domains of programming it’s common to want to write a data structure or algorithm that can work with elements of many different types٫ such as a generic list or a sorting algorithm that only needs a comparison function. Different programming languages have come up with all sorts of solutions to this problem: From just pointing people to existing general features that can be useful for the purpose (e.g C٫ Go) to generics systems so powerful they become Turing-complete (e.g. <a href="https://sdleffler.github.io/RustTypeSystemTuringComplete/">Rust</a>٫ <a href="http://matt.might.net/articles/c++-template-meta-programming-with-lambda-calculus/">C++</a>). In this post I’m going to take you on a tour of the generics systems in many different languages and how they are implemented. I’ll start from how languages without a special generics system like C solve the problem and then I’ll show how gradually adding extensions in different directions leads to the systems found in other languages.</p>

<p>One reason I think generics are an interesting case is that they’re a simple case of the general problem of metaprogramming: writing programs that can generate classes of other programs. As evidence I’ll describe how three different fully general metaprogramming methods can be seen as extensions from different directions in the space of generics systems: dynamic languages like Python٫ procedural macro systems like <a href="https://wiki.haskell.org/A_practical_Template_Haskell_Tutorial">Template Haskell</a>٫ and staged compilation like <a href="https://ziglang.org/#Generic-data-structures-and-functions">Zig</a> and <a href="http://terralang.org/">Terra</a>.</p>

<h2 id="overview">Overview</h2>

<p>I made a flow chart of all the systems I discuss to give you an overview of what this post will contain and how everything fits together:</p>

<p><a href="/assets/postassets/generics/flowchart.pdf"><img src="/assets/postassets/generics/flowchart-2x.png" alt="Timing" /></a></p>

<h2 id="the-basic-ideas">The basic ideas</h2>

<p>Let’s say we’re programming in a language without a generics system and we want to make a generic stack data structure which works for any data type. The problem is that each function and type definition we write only works for data that’s the same size٫ is copied the same way٫ and generally acts the same way.</p>

<p>Two ideas for how to get around this are to find a way to make all data types act the same way in our data structure٫ or to make multiple copies of our data structure with slight tweaks to deal with each data type the correct way. These two ideas form the basis of the two major classes of solutions to generics: “boxing” and “monomorphization”.</p>

<p>Boxing is where we put everything in uniform “boxes” so that they all act the same way. This is usually done by allocating things on the heap and just putting pointers in the data structure. We can make pointers to all different types act the same way so that the same code can deal with all data types! However this can come at the cost of extra memory allocation٫ dynamic lookups and cache misses. In C this corresponds to making your data structure store <code class="language-plaintext highlighter-rouge">void*</code> pointers and just casting your data to and from <code class="language-plaintext highlighter-rouge">void*</code> (allocating on the heap if the data isn’t already on the heap).</p>

<p>Monomorphization is where we copy the code multiple times for the different types of data we want to store. This way each instance of the code can directly use the size and methods of the data it is working with٫ without any dynamic lookups. This produces the fastest possible code٫ but comes at the cost of bloat in code size and compile times as the same code with minor tweaks is compiled many times. In C this corresponds to <a href="https://www.cs.grinnell.edu/~rebelsky/musings/cnix-macros-generics">defining your entire data structure in a macro</a> and calling it for each type you want to use it with.</p>

<p>Overall the tradeoff is basically that boxing leads to better compile times but can hurt runtime performance٫ whereas monomorphization will generate the fastest code but takes extra time to compile and optimize all the different generated instances. They also differ in how they can be extended: Extensions to boxing allow more dynamic behavior at runtime٫ while monomorphization is more flexible with how different instances of generic code can differ. It’s also worth noting that in some larger programs the performance advantage of monomorphization might be canceled out by the additional instruction cache misses from all the extra generated code.</p>

<p>Each of these schools of generics has many directions it can be extended in to add additional power or safety٫ and different languages have taken them in very interesting directions. Some languages like Rust and C# even provide both options!</p>

<h2 id="boxing">Boxing</h2>

<p>Let’s start with an example of the basic boxing approach in Go:</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">type</span> <span class="n">Stack</span> <span class="k">struct</span> <span class="p">{</span>
  <span class="n">values</span> <span class="p">[]</span><span class="k">interface</span><span class="p">{}</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">this</span> <span class="o">*</span><span class="n">Stack</span><span class="p">)</span> <span class="n">Push</span><span class="p">(</span><span class="n">value</span> <span class="k">interface</span><span class="p">{})</span> <span class="p">{</span>
  <span class="n">this</span><span class="o">.</span><span class="n">values</span> <span class="o">=</span> <span class="nb">append</span><span class="p">(</span><span class="n">this</span><span class="o">.</span><span class="n">values</span><span class="p">٫</span> <span class="n">value</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">func</span> <span class="p">(</span><span class="n">this</span> <span class="o">*</span><span class="n">Stack</span><span class="p">)</span> <span class="n">Pop</span><span class="p">()</span> <span class="k">interface</span><span class="p">{}</span> <span class="p">{</span>
  <span class="n">x</span> <span class="o">:=</span> <span class="n">this</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">this</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">-</span><span class="m">1</span><span class="p">]</span>
  <span class="n">this</span><span class="o">.</span><span class="n">values</span> <span class="o">=</span> <span class="n">this</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="o">:</span><span class="nb">len</span><span class="p">(</span><span class="n">this</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">-</span><span class="m">1</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">x</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Example languages that use basic boxing: C (<code class="language-plaintext highlighter-rouge">void*</code>)٫ Go (<code class="language-plaintext highlighter-rouge">interface{}</code>)٫ pre-generics Java (<code class="language-plaintext highlighter-rouge">Object</code>)٫ pre-generics Objective-C (<code class="language-plaintext highlighter-rouge">id</code>)</p>

<h2 id="type-erased-boxed-generics">Type-erased boxed generics</h2>

<p>Here’s some problems with the basic boxing approach:</p>

<ul>
  <li>Depending on the language we often need to cast values to and from the correct type every time we read or write to the data structure.</li>
  <li>Nothing stops us from putting elements of different types into the structure٫ which could allow bugs that manifest as runtime crashes.</li>
</ul>

<p>A solution to both of these problems is to add generics functionality to the type system٫ while still using the basic boxing method exactly as before at runtime. This approach is often called type erasure٫ because the types in the generics system are “erased” and all become the same type (like <code class="language-plaintext highlighter-rouge">Object</code>) under the hood.</p>

<p>Java and Objective-C both started out with basic boxing٫ and later added language features for generics with type erasure٫ even using the exact same collection types as before for compatibility٫ but with optional generic type parameters. See the following example from the <a href="https://en.wikipedia.org/wiki/Generics_in_Java">Wikipedia article on Java Generics</a>:</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">List</span> <span class="n">v</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ArrayList</span><span class="o">();</span>
<span class="n">v</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="s">"test"</span><span class="o">);</span> <span class="c1">// A String that cannot be cast to an Integer</span>
<span class="nc">Integer</span> <span class="n">i</span> <span class="o">=</span> <span class="o">(</span><span class="nc">Integer</span><span class="o">)</span><span class="n">v</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span> <span class="c1">// Run time error</span>

<span class="nc">List</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">v</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">ArrayList</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;();</span>
<span class="n">v</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="s">"test"</span><span class="o">);</span>
<span class="nc">Integer</span> <span class="n">i</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span> <span class="c1">// (type error) compilation-time error</span>
</code></pre></div></div>

<h3 id="inferred-boxed-generics-with-a-uniform-representation">Inferred boxed generics with a uniform representation</h3>

<p>OCaml takes this idea even further with a uniform representation where there are no primitive types that require an additional boxing allocation (like <code class="language-plaintext highlighter-rouge">int</code> needing to be turned into an <code class="language-plaintext highlighter-rouge">Integer</code> to go in an <code class="language-plaintext highlighter-rouge">ArrayList</code> in Java)٫ because everything is either already boxed or represented by a pointer-sized integer٫ so everything is one machine word. However when the garbage collector looks at data stored in generic structures it needs to tell pointers from integers٫ so integers are tagged using a 1 bit in a place where valid aligned pointers never have a 1 bit٫ leaving only 31 or 63 bits of range.</p>

<p>OCaml also has a type inference system so you can write a function and the compiler will infer the most generic type possible if you don’t annotate it٫ which can lead to functions that look like a dynamically typed language:</p>

<div class="language-ocaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">first</span> <span class="p">(</span><span class="n">head</span> <span class="o">::</span> <span class="n">tail</span><span class="p">)</span> <span class="o">=</span> <span class="n">head</span>
<span class="c">(* inferred type: "a list -&gt; "a *)</span>
</code></pre></div></div>

<p>The inferred type is read as “a function from a list of elements of type <code class="language-plaintext highlighter-rouge">"a</code> to something of type <code class="language-plaintext highlighter-rouge">"a</code>”. Which encodes the relation that the return type is the same as the list type but can be any type.</p>

<h2 id="interfaces">Interfaces</h2>

<p>A different limitation in the basic boxing approach is that the boxed types are <em>completely</em> opaque. This is fine for data structures like a stack٫ but things like a generic sorting function need some extra functionality٫ like a type-specific comparison function. There’s a number of different ways of both implementing this at runtime and exposing this in the language٫ which are technically different axes and you can <a href="http://okmij.org/ftp/Computation/typeclass.html">implement the same language using multiple of these approaches</a>. However٫ it seems like different language features mostly lend themselves towards being implemented a certain way٫ and then language extensions take advantage of the strengths of the chosen implementation. This means there’s mostly two families of languages based around the different runtime approaches: vtables and dictionary passing.</p>

<h3 id="interface-vtables">Interface vtables</h3>

<p>If we want to expose type-specific functions while sticking with the boxing strategy of a uniform way of working with everything٫ we can just make sure that there’s a uniform way to find the type-specific function we want from an object. This approach is called using “vtables” (shortened from “virtual method tables” but nobody uses the full name) and how it is implemented is that at offset zero in every object in the generic structure is a pointer to some tables of function pointers with a consistent layout. These tables allow the generic code to look up a pointer to the type-specific functions in the same way for every type by indexing certain pointers at fixed offsets.</p>

<p>This is how <code class="language-plaintext highlighter-rouge">interface</code> types are implemented in Go and <code class="language-plaintext highlighter-rouge">dyn</code> <code class="language-plaintext highlighter-rouge">trait</code> objects are implemented in Rust. When you cast a type to an interface type for something it implements٫ it creates a wrapper that contains a pointer to the original object and a pointer to a vtable of the type-specific functions for that interface. However this requires an extra layer of pointer indirection and a different layout٫ which is why sorting in Go uses <a href="https://golang.org/pkg/sort/#Interface">an interface for the container with a Swap method</a> instead of taking a slice of a <code class="language-plaintext highlighter-rouge">Comparable</code> interface٫ because it would require allocating an entire new slice of the interface types and then it would only sort that and not the original slice!</p>

<h3 id="object-oriented-programming">Object-oriented programming</h3>

<p>Object oriented programming is a language feature that makes good use of the power of vtables. Instead of having separate interface objects that contain the vtables٫ object-oriented languages like Java just have a vtable pointer at the start of every object. Java-like languages have a system of inheritance and interfaces that can be implemented entirely with these object vtables.</p>

<p>As well as providing additional features٫ embedding vtables in every object also solves the earlier problem of needing to construct new interface types with indirection. Unlike <code class="language-plaintext highlighter-rouge">Go</code>٫ in Java <a href="https://docs.oracle.com/javase/7/docs/api/java/util/Arrays.html#sort(java.lang.Object[])">the sorting function</a> can just use the <code class="language-plaintext highlighter-rouge">Comparable</code> interface on types that implement it.</p>

<h3 id="reflection">Reflection</h3>

<p>Once you have vtables٫ it’s not too difficult to have the compiler also generate tables of other type information like field names٫ types and locations. This allows accessing all the data in a type with the same code that can inspect all the data in any other type. This can be used to add a “reflection” feature to your language which can be used to implement things like serialization and pretty printing for arbitrary types. As an extension of the boxing paradigm it has the same tradeoff that it only requires one copy of the code but requires a lot of slow dynamic lookups٫ which can lead to slow serialization performance.</p>

<p>Examples of languages with reflection features they use for serialization and other things include Java٫ C# and Go.</p>

<h3 id="dynamically-typed-languages">Dynamically typed languages</h3>

<p>Reflection is very powerful and can do a lot of different metaprogramming tasks٫ but one thing it can’t do is create new types or edit the type information of existing values. If we add the ability to do this٫ as well as make the default access and modification syntaxes go through reflection٫ we end up with dynamically typed languages! The incredibly flexibility to do metaprogramming in languages like Python and Ruby comes from effectively super-powered reflection systems that are used for everything.</p>

<p>“But Tristan٫ that’s not how dynamic languages work٫ they just implement everything with hash tables!” you may say. Well٫ hash tables are just a good data structure for implementing editable type information tables! Also٫ that’s just how some interpreters like CPython do things. If you look at how a high performance JIT like V8 implements things٫ <a href="https://v8.dev/blog/fast-properties">it looks a lot like vtables and reflection info</a>! V8’s hidden classes (vtables and reflection info) and object layout are similar to what you might see in a Java VM٫ just with the capability for objects to change to a new vtable at runtime. This is not a coincidence because nothing is ever a coincidence: The person <a href="https://en.wikipedia.org/wiki/Chrome_V8">listed on Wikipedia as the creator of V8</a> previously <a href="https://en.wikipedia.org/wiki/Lars_Bak_(computer_programmer)">worked on a high-performance Java VM</a>.</p>

<h3 id="dictionary-passing">Dictionary Passing</h3>

<p>Another way of implementing dynamic interfaces than associating vtables with objects is to pass a table of the required function pointers along to generic functions that need them. This approach is in a way similar to constructing Go-style interface objects at the call site٫ just that the table is passed as a hidden argument instead of packaged into a bundle as one of the existing arguments.</p>

<p>This approach is used by <a href="http://okmij.org/ftp/Computation/typeclass.html">Haskell type classes</a> although GHC has the ability to do a kind of monomorphization as an optimization through inlining and specialization. Dictionary passing is also used by OCaml with an explicit argument in the form of <a href="https://v1.realworldocaml.org/v1/en/html/first-class-modules.html">first class modules</a>٫ but there’s a proposal to <a href="https://tycon.github.io/modular-implicits.html">add a mechanism to make the parameter implicit</a>.</p>

<h3 id="swift-witness-tables">Swift Witness Tables</h3>

<p>Swift makes the interesting realization that by using dictionary passing and also putting the size of types and how to move٫ copy and free them into the tables٫ they can provide all the information required to work with any type in a uniform way without boxing them. This way Swift can implement generics <a href="https://www.reddit.com/r/rust/comments/7gkiie/implementing_swift_generics_video/">without monomorphization and without allocating everything into a uniform representation</a>! They still pay the cost of all the dynamic lookups that all boxing-family implementations pay٫ but they save on the allocation٫ memory and cache-incoherency costs. The Swift compiler also has the ability to specialize (monomorphize) and inline generics within a module and across modules with functions <a href="https://github.com/apple/swift-evolution/blob/master/proposals/0193-cross-module-inlining-and-specialization.md">annotated <code class="language-plaintext highlighter-rouge">@inlinable</code></a> to avoid these costs if it wants to٫ presumably using heuristics about how much it would bloat the code.</p>

<p>This functionality also explains how Swift can <a href="https://github.com/apple/swift-evolution/blob/master/proposals/0260-library-evolution.md">implement ABI stability</a> in a way that allows adding and rearranging fields in <code class="language-plaintext highlighter-rouge">struct</code>s٫ although they provide a <code class="language-plaintext highlighter-rouge">@frozen</code> attribute to opt out of dynamic lookups for performance reasons.</p>

<h3 id="intensional-type-analysis">Intensional Type Analysis</h3>

<p>One more way to implement interfaces for your boxed types is to add a type ID in a fixed part of the object like where a vtable pointer would go٫ then generate functions for each interface method that effectively have a big <code class="language-plaintext highlighter-rouge">switch</code> statement over all the types that implement that interface method and dispatch to the correct type-specific method.</p>

<p>I’m not aware of any languages that use this technique٫ but C++ compilers and Java VMs do something similar to this when they use profile-guided optimization to learn that a certain generic call site mostly acts on objects of certain types. They’ll replace the call site with a check for each common type and then a static dispatch for that common type٫ with the usual dynamic dispatch as a fallback case. This way the branch predictor can predict the common case branch will be taken and continue dispatching instructions through the static call.</p>

<h2 id="monomorphization">Monomorphization</h2>

<p>Now٫ the alternative approach to boxing is monomorphization. In the monomorphization approach we need to find some way to output multiple versions of our code for each type we want to use it with. Compilers have multiple phases of representations that the code passes through as it is compiled٫ and we theoretically can do the copying at any of these stages.</p>

<h3 id="generating-source-code">Generating source code</h3>

<p>The simplest approach to monomorphization is to do the copying at the stage of the first representation: source code! This way the compiler doesn’t even have to have generics support in it٫ and this is what users of languages like C and Go٫ where the compiler doesn’t support generics٫ sometimes do.</p>

<p>In C you can use the preprocessor and define your data structure in a macro or a header that you include multiple times with different <code class="language-plaintext highlighter-rouge">#define</code>s. In Go there are scripts like <a href="https://github.com/cheekybits/genny">genny</a> that make this code generation process easy.</p>

<p>The downside of this is that duplicating source code can have a lot of warts and edge cases to look out for depending on the language٫ and also gives the compiler lots of extra work to do parsing and type checking basically the same code many times. Again depending on language and tools this method’s generics can be ugly to write and use٫ like how if you write one inside a C macro every line has to end with a backslash and all type and function names need to have the type name manually concatenated onto their identifiers to avoid collisions.</p>

<h3 id="d-string-mixins">D string mixins</h3>

<p>Code generation does have something going for it though٫ which is that you can generate the code using a fully powered programming language٫ and also it uses a representation that the user already knows.</p>

<p>Some languages that implement generics in some other way also include a clean way of doing code generation to address more general metaprogramming use cases not covered by their generics system٫ like serialization. The clearest example of this is D’s <a href="https://dlang.org/articles/mixin.html">string mixins</a> which enable generating D code as strings using the full power of D during the middle of a compile.</p>

<h3 id="rust-procedural-macros">Rust procedural macros</h3>

<p>A similar example but with a representation only one step into the compiler is <a href="https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html">Rust’s procedural macros</a>٫ which take token streams as input and output token streams٫ while providing utilities to convert token streams to and from strings. The advantage of this approach is that token streams can preserve source code location information. A macro can directly paste code the user wrote from input to output as tokens٫ then if the user’s code causes a compiler error in the macro output the error message the compiler prints will correctly point to the file٫ line and columns of the broken part of the user’s code٫ but if the macro generates broken code the error message will point to the macro invocation. For example if you use <a href="https://docs.rs/log-derive/">a macro that wraps a function in logging calls</a> and make a mistake in the implementation of the wrapped function٫ the compiler error will point directly to the mistake in your file٫ rather than saying the error occurred in code generated by the macro.</p>

<h3 id="syntax-tree-macros">Syntax tree macros</h3>

<p>Some languages do take the step further and offer facilities for consuming and producing Abstract Syntax Tree (AST) types in macros written in the language. Examples of this include <a href="https://wiki.haskell.org/A_practical_Template_Haskell_Tutorial">Template Haskell</a>٫ <a href="https://nim-lang.org/docs/tut3.html">Nim macros</a>٫ <a href="http://ocamllabs.io/doc/ppx.html">OCaml PPX</a> and nearly all <a href="https://en.wikipedia.org/wiki/Lisp_(programming_language)">Lisp</a>s.</p>

<p>One problem with AST macros is that you don’t want to require users to learn a bunch of functions for constructing AST types as well as the base languages. The Lisp family of languages address this by making the syntax and the AST structure very simple with a very direct correspondence٫ but constructing the structures can still be tedious. Thus٫ all the languages I mention have some form of “quote” primitive where you provide a fragment of code in the language and it returns the syntax tree. These quote primitives also have a way to splice syntax tree values in like string interpolation. Here’s an example in Template Haskell:</p>

<div class="language-haskell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- using AST construction functions</span>
<span class="n">genFn</span> <span class="o">::</span> <span class="kt">Name</span> <span class="o">-&gt;</span> <span class="kt">Q</span> <span class="kt">Exp</span>
<span class="n">genFn</span> <span class="n">f</span> <span class="o">=</span> <span class="kr">do</span>
  <span class="n">x</span> <span class="o">&lt;-</span> <span class="n">newName</span> <span class="s">"x"</span>
  <span class="n">lamE</span> <span class="p">[</span><span class="n">varP</span> <span class="n">x</span><span class="p">]</span> <span class="p">(</span><span class="n">appE</span> <span class="p">(</span><span class="n">varE</span> <span class="n">f</span><span class="p">)</span> <span class="p">(</span><span class="n">varE</span> <span class="n">x</span><span class="p">))</span>

<span class="c1">-- using quotation with $() for splicing</span>
<span class="n">genFn"</span> <span class="o">::</span> <span class="kt">Name</span> <span class="o">-&gt;</span> <span class="kt">Q</span> <span class="kt">Exp</span>
<span class="n">genFn"</span> <span class="n">f</span> <span class="o">=</span> <span class="p">[</span><span class="o">|</span> <span class="nf">\</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="o">$</span><span class="p">(</span><span class="n">varE</span> <span class="n">f</span><span class="p">)</span> <span class="n">x</span> <span class="o">|</span><span class="p">]</span>
</code></pre></div></div>

<p>One disadvantage of doing procedural macros at the syntax tree level instead of token level is that syntax tree types often change with the addition of new language features٫ while token types can remain compatible. For example OCaml’s PPX system needs <a href="https://github.com/ocaml-ppx/ocaml-migrate-parsetree">special infrastructure to migrate parse trees</a> to and from the language version used by a macro. Whereas Rust has libraries that add <a href="https://github.com/dtolnay/syn">parsing</a> and <a href="https://github.com/dtolnay/quote">quotation</a> utilities so you can write procedural macros in a style similar to syntax tree macros. Rust even has <a href="https://github.com/dtolnay/reflect">an experimental library that tries to replicate the interface provided by reflection</a>!</p>

<h3 id="templates">Templates</h3>

<p>The next type of generics is just pushing the code generation a little further in the compiler. Templates as found in C++ and D are a way of implementing generics where you can specify “template parameters” on types and functions and when you instantiate a template with a specific type٫ that type is substituted into the function٫ and then the function is type checked to make sure that the combination is valid.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">template</span> <span class="o">&lt;</span><span class="k">class</span> <span class="nc">T</span><span class="p">&gt;</span> <span class="n">T</span> <span class="nf">myMax</span><span class="p">(</span><span class="n">T</span> <span class="n">a</span><span class="p">٫</span> <span class="n">T</span> <span class="n">b</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">a</span><span class="o">&gt;</span><span class="n">b</span><span class="o">?</span><span class="n">a</span><span class="o">:</span><span class="n">b</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">template</span> <span class="o">&lt;</span><span class="k">class</span> <span class="nc">T</span><span class="p">&gt;</span> <span class="k">struct</span> <span class="nc">Pair</span> <span class="p">{</span>
  <span class="n">T</span> <span class="n">values</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="p">};</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">myMax</span><span class="p">(</span><span class="mi">5</span><span class="p">٫</span> <span class="mi">6</span><span class="p">);</span>
  <span class="n">Pair</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">p</span> <span class="p">{</span> <span class="p">{</span><span class="mi">5</span><span class="p">٫</span><span class="mi">6</span><span class="p">}</span> <span class="p">};</span>
  <span class="c1">// This would give us a compile error inside myMax</span>
  <span class="c1">// about Pair being an invalid operand to `&gt;`:</span>
  <span class="c1">// myMax(p٫ p);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>One problem with the template system is that if you include a template function in your library and a user instantiates it with the wrong type they may get an inscrutable compile error inside your library. This is very similar to what can happen with libraries in dynamically typed languages when a user passes in the wrong type. <a href="http://dlang.org/">D</a> has an interesting solution to this which is similar to what popular libraries in dynamic languages do: just use helper functions to check the types are valid٫ the error messages will clearly point to the helpers if they fail! Here’s the same example in D٫ note the <code class="language-plaintext highlighter-rouge">if</code> in the signature and the generally better syntax (<code class="language-plaintext highlighter-rouge">!</code> is how you provide template parameters):</p>

<div class="language-d highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// We"re going to use the isNumeric function in std.traits</span>
<span class="k">import</span> <span class="n">std</span><span class="p">.</span><span class="n">traits</span><span class="p">;</span>

<span class="c1">// The `if` is optional (without it you"ll get an error inside like C++)</span>
<span class="c1">// The `if` is also included in docs and participates in overloading!</span>
<span class="n">T</span> <span class="n">myMax</span><span class="p">(</span><span class="n">T</span><span class="p">)(</span><span class="n">T</span> <span class="n">a</span><span class="p">٫</span> <span class="n">T</span> <span class="n">b</span><span class="p">)</span> <span class="k">if</span><span class="p">(</span><span class="n">isNumeric</span><span class="p">!</span><span class="n">T</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">a</span><span class="p">&gt;</span><span class="n">b</span><span class="p">?</span><span class="n">a</span><span class="p">:</span><span class="n">b</span><span class="p">);</span>
<span class="p">}</span>

<span class="k">struct</span> <span class="n">Pair</span><span class="p">(</span><span class="n">T</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">T</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="n">values</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">myMax</span><span class="p">(</span><span class="mi">5</span><span class="p">٫</span> <span class="mi">6</span><span class="p">);</span>
  <span class="n">Pair</span><span class="p">!</span><span class="kt">int</span> <span class="n">p</span> <span class="p">=</span> <span class="p">{[</span><span class="mi">5</span><span class="p">٫</span><span class="mi">6</span><span class="p">]};</span>
  <span class="c1">// This would give a compile error saying that `(Pair!int٫ Pair!int)`</span>
  <span class="c1">// doesn"t match the available instance `myMax(T a٫ T b) if(isNumeric!T)`:</span>
  <span class="c1">// myMax(p٫ p);</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://en.cppreference.com/w/cpp/language/constraints">C++20 has a feature called “concepts”</a> that serves the same purpose except with a design more like defining interfaces and type constraints.</p>

<h3 id="compile-time-functions">Compile time functions</h3>

<p>D’s templates have a number of extensions that allow you to use features like compile time function evaluation and <code class="language-plaintext highlighter-rouge">static if</code> to basically make templates act like functions that take a compile time set of parameters and return a non-generic runtime function. This makes D templates into a fully featured metaprogramming system٫ and as far as I understand modern C++ templates have similar power but with less clean mechanisms.</p>

<p>There’s some languages that take the “generics are just compile time functions” concept and run with it even further٫ like Zig:</p>

<pre><code class="language-zig">fn Stack(comptime T: type) type {
    return struct {
        items: []T٫
        len: usize٫

        const Self = @This();
        pub fn push(self: Self٫ item: T) {
            // ...
        }
    };
}
</code></pre>

<p>Zig does this using the same language at both compile time and runtime٫ with functions split up based on parameters marked <code class="language-plaintext highlighter-rouge">comptime</code>. There’s another language that uses a separate but similar language at the meta level called <a href="http://terralang.org/">Terra</a>. Terra is a dialect of Lua that allows you to construct lower level C-like functions inline and then manipulate them at the meta level using Lua APIs as well as quoting and splicing primitives:</p>

<div class="language-lua highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span> <span class="nf">MakeStack</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
    <span class="kd">local</span> <span class="n">struct</span> <span class="n">Stack</span> <span class="p">{</span>
        <span class="n">items</span> <span class="p">:</span> <span class="err">&amp;</span><span class="n">T</span><span class="p">;</span> <span class="c1">-- &amp;T is a pointer to T</span>
        <span class="n">len</span> <span class="p">:</span> <span class="n">int</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">terra</span> <span class="n">Stack</span><span class="p">:</span><span class="n">push</span><span class="p">(</span><span class="n">item</span> <span class="p">:</span> <span class="n">T</span><span class="p">)</span>
        <span class="c1">-- ...</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">Stack</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Terra’s crazy level of metaprogramming power allows it to do things <a href="http://terralang.org/#compiling-a-language">like implement optimizing compilers for domain specific languages as simple functions</a>٫ or implement the interface and object systems of <a href="https://github.com/zdevito/terra/blob/master/tests/lib/javalike.t">Java</a> and <a href="https://github.com/zdevito/terra/blob/master/tests/lib/golike.t">Go</a> in a library with a small amount of code. Then it can save out generated runtime-level code as dependency-free object files.</p>

<h3 id="rust-generics">Rust generics</h3>

<p>The next type of monomorphized generics of course moves the code generation one step further into the compiler٫ after type checking. I mentioned that the type of inside-the-library errors you can get with C++ are like the errors you can get in a dynamically typed language٫ this is of course because there’s basically only one type of type in template parameters٫ like a dynamic language. So that means we can fix the problem by adding a type system to our meta level and having multiple types of types with static checking that they support the operations you use. This is how generics work in Rust٫ and at the language level also how they work in Swift and Haskell.</p>

<p>In Rust you need to declare “trait bounds” on your type parameters٫ where <code class="language-plaintext highlighter-rouge">trait</code>s
are like interfaces in other languages and declare a set of functionality provided by the type. The Rust compiler will check that the body of your generic functions will work with any type conforming to your trait bounds٫ and also not allow you to use functionality of the type not declared by the trait bounds. This way users of generic functions in Rust can <em>never</em> get compile errors inside a library function when they instantiate it. The compiler also only has to type check each generic function once.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">my_max</span><span class="o">&lt;</span><span class="n">T</span><span class="p">:</span> <span class="n">PartialOrd</span><span class="o">&gt;</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">T</span><span class="p">٫</span> <span class="n">b</span><span class="p">:</span> <span class="n">T</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">T</span> <span class="p">{</span>
    <span class="k">if</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="n">b</span> <span class="p">{</span> <span class="n">a</span> <span class="p">}</span> <span class="k">else</span> <span class="p">{</span> <span class="n">b</span> <span class="p">}</span>
<span class="p">}</span>

<span class="k">struct</span> <span class="n">Pair</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="n">values</span><span class="p">:</span> <span class="p">[</span><span class="n">T</span><span class="p">;</span> <span class="mi">2</span><span class="p">]٫</span>
<span class="p">}</span>

<span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="nf">my_max</span><span class="p">(</span><span class="mi">5</span><span class="p">٫</span><span class="mi">6</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">p</span><span class="p">:</span> <span class="n">Pair</span><span class="o">&lt;</span><span class="nb">i32</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">Pair</span> <span class="p">{</span> <span class="n">values</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">٫</span><span class="mi">6</span><span class="p">]</span> <span class="p">};</span>
    <span class="c">// Would give a compile error saying that</span>
    <span class="c">// PartialOrd is not implemented for Pair&lt;i32&gt;:</span>
    <span class="c">// my_max(p٫p);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>At the language level this is very similar to the kind of type system you need to implement generics with interface support using the boxing approach to generics٫ which is why Rust can support both using the same system! Rust 2018 even added a uniform syntax where a <code class="language-plaintext highlighter-rouge">v: &amp;impl SomeTrait</code> parameter gets monomorphized but a <code class="language-plaintext highlighter-rouge">v: &amp;dyn SomeTrait</code> parameter uses boxing. This property also allows compilers like Swift’s and Haskell’s GHC to monomorphize as an optimization even though they default to boxing.</p>

<h3 id="machine-code-monomorphization">Machine code monomorphization</h3>

<p>The logical next step in monomorphized generics models is pushing it further in the compiler٫ after the backend. Just like we can copy source code templates that are annotated with placeholders for the generic type٫ we can generate machine code with placeholders for the type-specific parts. Then we can stamp these templates out very quickly with a <code class="language-plaintext highlighter-rouge">memcpy</code> and a few patches like how a linker works! The downside is that each monomorphized copy couldn’t be specially optimized by the optimizer٫ but because of the lack of duplicate optimization٫ compilation can be way faster. We could even make the code stamper a tiny JIT that gets included in binaries and stamps out the monomorphized copies at runtime to avoid bloating the binaries.</p>

<p>Actually I’m not aware of any language that works this way٫ it’s just an idea that came to me while writing as a natural extension of this taxonomy٫ which is exactly the kind of thing I hoped for from this exercise! I hope this post gives you a clearer picture of the generics systems in different languages and how they can be fit together into a coherent taxonomy٫ and prompts you to think about the directions in concept-space where we might find new cool programming languages.</p>
'),('http://thume.ca/2019/06/19/glitchless-metal-window-resizing/', 'Glitchless Metal Window Resizing', '1560902400000',  13, '
<p>There’s a problem with Apple’s Metal <a href="https://developer.apple.com/documentation/metalkit/mtkview">MTKView</a> on macOS which is that seemingly nobody can figure out how to get smooth window resizing to work properly. I just figured it out٫ more on that later. If you reposition the triangle in Apple’s Hello Triangle program to the left (to make the rescaling more apparent) then you can see it judders horribly when the window is resized:</p>

<p><img src="/assets/postassets/metalresize/wobbly_hello_triangle.gif" alt="Wobbly Hello Triangle" /></p>

<p>What’s happening is often the new Metal frame doesn’t arrive in time and it draws a stretched version of the previous frame instead. There’s a number of places on the internet dating back to 2017 with various people encountering the problem:</p>

<ul>
  <li><a href="https://stackoverflow.com/questions/45375548/resizing-mtkview-scales-old-content-before-redraw">Stack Overflow: Resizing MTKView scales old content before redraw</a></li>
  <li><a href="https://forums.developer.apple.com/thread/77901">Apple Developer Forums: Redraw MTKView when its size changes</a></li>
  <li><a href="https://forums.developer.apple.com/thread/94765">Apple Developer Forums: Unwanted MTKView content stretching when I resize/zoom the window</a></li>
  <li><a href="https://github.com/gnachman/iTerm2/blob/ed8e2544726e686fe81d71fdec25cd8c5884be4d/sources/PTYTab.m#L5215">iTerm2 switches away from Metal to software rendering when resizing the window</a></li>
</ul>

<p>Basically everyone who tries to make something with Metal that’s not a game runs into this problem and it looks horrible. As far as I can tell nobody has figured out how to fix it properly before and posted about it afterwards. Note in the first dev forums thread that an Apple employee claimed they were looking into this problem almost a year ago with no resolution.</p>

<p>I started <a href="https://github.com/trishume/MetalTest">a test project</a> to try out different ways of drawing with Metal during resize to see if I could get any of them to work properly. First I replicated the MTKView problems and tried to fix them by tweaking lots of different things٫ including all three modes of triggering draws listed in the docs and using <code class="language-plaintext highlighter-rouge">presentsWithTransaction</code> in the way the docs suggest but nothing helped. Then I made a version using Core Graphics and an NSView subclass and stacked it below my Metal view so that I could have a reference that worked properly.</p>

<h2 id="the-solution">The Solution</h2>

<p>Then I tried the accepted answer by Max on <a href="https://stackoverflow.com/questions/45375548/resizing-mtkview-scales-old-content-before-redraw">the Stack Overflow post</a> which uses <code class="language-plaintext highlighter-rouge">CAMetalLayer</code> and some resizing-related properties. This reduced the frequency of glitches quite a bit٫ but didn’t eliminate them. So I added in <code class="language-plaintext highlighter-rouge">presentsWithTransaction = true</code>٫ which wasn’t enough on its own٫ but combining that with  <code class="language-plaintext highlighter-rouge">commandBuffer.waitUntilScheduled()</code> then presenting as suggested in the Apple <code class="language-plaintext highlighter-rouge">CAMetalLayer</code> docs fixed all the glitches! I also needed to do some size conversion to make the accepted answer’s recipe draw crisply on high DPI displays.</p>

<p><strong>Edit:</strong> <a href="https://twitter.com/CoreyDotCom/status/1141653060843950081">@CoreyDotCom on Twitter</a> reminded me I forgot to mention something. If you follow the recipe from the Stack Overflow post٫ it will <em>appear to be</em> glitch-free٫ but it actually isn’t. The <code class="language-plaintext highlighter-rouge">layerContentsPlacement = .topLeft</code> makes the glitches manifest as small broken slices near the moving window edge٫ which are very difficult to notice since the edge is moving quickly. When you change the placement policy to <code class="language-plaintext highlighter-rouge">layerContentsPlacement = .scaleAxesIndependently</code> to match the behavior of <code class="language-plaintext highlighter-rouge">MTKView</code> you see that there are still occasional glitches. Corey reports frame rate issues with <code class="language-plaintext highlighter-rouge">presentsWithTransaction</code>٫ and if this is the case for you as well it may be preferable to just mask the occasional remaining glitches with the top left placement policy.</p>

<h2 id="working-code">Working Code</h2>

<p>I now have a Metal triangle test program that resizes smoothly and without judder.</p>

<p>Check out my test project: <a href="https://github.com/trishume/MetalTest">Github repo</a></p>

<p>And the specific code file containing the working recipe: <a href="https://github.com/trishume/MetalTest/blob/master/MetalTest2/MetalLayerView.swift">MetalLayerView</a></p>

<p>In the gif below the top is the broken <code class="language-plaintext highlighter-rouge">MTKView</code>٫ the middle <code class="language-plaintext highlighter-rouge">NSView</code>٫ and the bottom the working <code class="language-plaintext highlighter-rouge">CAMetalLayer</code> recipe. Contrast the shakey left edge of the top triangle with the stable bottom one:</p>

<p><img src="/assets/postassets/metalresize/metal_triangles.gif" alt="Metal Triangles" /></p>

'),('http://thume.ca/2019/04/29/comparing-compilers-in-rust-haskell-c-and-python/', 'Comparing the Same Project in Rust٫ Haskell٫ C++٫ Python٫ Scala and OCaml', '1556496000000',  13, '
<p>During my final term at UWaterloo I took <a href="https://www.student.cs.uwaterloo.ca/~cs444/">the CS444 compilers class</a> with a project to write a compiler from a substantial subset of Java to x86٫ in teams of up to three people with a language of the group’s choice. This was a rare opportunity to compare implementations of large programs that all did the same thing٫ written by friends I knew were highly competent٫ and have a fairly pure opportunity to see what difference design and language choices could make. I gained a lot of useful insights from this. It’s rare to encounter such a controlled comparison of languages٫ it’s not perfect but it’s much better than most anecdotes people use as the basis for their opinions on programming languages.</p>

<p>We did our compiler in Rust and my first comparison was with a team that used Haskell٫ which I expected to be much terser٫ but their compiler used similar amounts or more code for the same task. The same was true for a team that used OCaml. I then compared with a team that used C++٫ and as expected their compiler was around 30% larger largely due to headers and lack of sum types and pattern matching. The next comparison was my friend who did a compiler on her own in Python and used less than half the code we did because of the power of metaprogramming and dynamic types. A friend whose team used Scala also had a smaller compiler than us. The comparison that surprised me most though was with another team that also used Rust٫ but used 3 times the code that we did٫ because of different design decisions. In the end٫ the largest difference in the amount of code required was within the same language!</p>

<p>I’ll go over why I think this is a good comparison٫ some information on each project٫ and I’ll explain some of the sources of the differences in compiler size. I’ll also talk about what I learned from each comparison. Feel free to use these links to skip ahead to what interests you:</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li>Why I think this is insightful</li>
  <li><a href="#rust-baseline">Rust (baseline)</a></li>
  <li><a href="#haskell">Haskell</a>: 1.0-1.6x the size depending on how you count for interesting reasons</li>
  <li><a href="#c">C++</a>: 1.4x the size for mundane reasons</li>
  <li><a href="#python">Python</a>: half the size because of fancy metaprogramming!</li>
  <li><a href="#rust-other-group">Rust (other group)</a>: 3x the size because of different design decisions!</li>
  <li><a href="#scala">Scala</a>: 0.7x the size</li>
  <li><a href="#ocaml">OCaml</a>: 1.0-1.6x the size depending on how you count٫ similar to Haskell</li>
</ul>

<h2 id="why-i-think-this-is-insightful">Why I think this is insightful</h2>

<p>Now before you reply that amount of code (I compared both lines and bytes) is a terrible metric٫ I think that it can provide a good amount of insight in this case for a number of reasons. This is at least subjectively the most well controlled instance of different teams writing the same <em>large</em> program that I’ve ever heard of or read about.</p>

<ul>
  <li>Nobody (including me) knew I would ask this until after we were done٫ so nobody was trying to game the metric٫ everyone was just doing their best to finish the project quickly and correctly.</li>
  <li>Everyone (with the exception of the Python project I’ll discuss later) was implementing a program with the sole goal of passing the same automated test suite by the same deadlines٫ so the results can’t be confounded much by some groups deciding to solve different/harder problems.</li>
  <li>The project was done over a period of months٫ with a team٫ and needed to be gradually extended and pass both known and unknown tests. This means that it was helpful to write clean understandable code and not hack everything together.</li>
  <li>Other than passing the course tests٫ the code wouldn’t be used for anything else٫ nobody would read it and being a compiler for a limited subset of Java to textual assembly it wouldn’t be useful.</li>
  <li>No libraries other than the standard library were allowed٫ and no parsing helpers even if they’re in the standard library. This means the comparison can’t be confounded by powerful compiler libraries not used by all teams.</li>
  <li>There were secret tests which we couldn’t see that were run once after the final submission deadline٫ which meant there was an incentive to write your own test code and make sure that your compiler was robust٫ correct and could handle tricky edge cases.</li>
  <li>While everyone involved was a student٫ the teams I talk about are all composed of people I consider quite competent programmers. Everyone has at least 2 years of full time work experience doing internships٫ mostly at high end tech companies sometimes even working on compilers. Nearly all have been programming for 7-13 years and are enthusiasts who read a lot on the internet beyond their courses.</li>
  <li>Generated code wasn’t counted٫ but grammar files and code that generated code was counted.</li>
</ul>

<p>Thus I think the amount of code provides a decent approximation of how much effort each project took٫ and how much there would be to maintain if it was a longer term project. I think the smaller differences are also large enough to rule out extraordinary claims٫ like the ones I’ve read that say writing a compiler in Haskell takes less than half the code of C++ by virtue of the language.</p>

<h2 id="rust-baseline">Rust (baseline)</h2>

<p>Me and one of my teammates had each written over 10k lines of Rust before٫ and my other teammate had written maybe 500 lines of Rust for some hackathon projects. Our compiler was 6806 lines by <code class="language-plaintext highlighter-rouge">wc -l</code>٫ 5900 source lines of code (not including blanks and comments)٫ and 220kb by <code class="language-plaintext highlighter-rouge">wc -c</code>.</p>

<p>One thing I discovered is that these measures were related by approximately the same factors in the other projects where I checked٫ with minor exceptions that I’ll note. For the rest of the post when I refer to lines or amount I mean by <code class="language-plaintext highlighter-rouge">wc -l</code>٫ but this result means it doesn’t really matter (unless I note a difference) and you can convert with a factor.</p>

<p>I wrote <a href="/2019/04/18/writing-a-compiler-in-rust/">another post describing our design</a>٫ which passed all the public and secret tests. It also included a few extra features that we did for fun and not to pass tests٫ that probably added around 400 extra lines. Also around 500 lines of our total was unit tests and a test harness.</p>

<h2 id="haskell">Haskell</h2>

<p>The Haskell team was composed of two of my friends who’d written maybe a couple thousand lines of Haskell each before plus reading lots of online Haskell content٫ and a bunch more in other similar functional languages like OCaml and Lean. They had one other teammate who I didn’t know well but seems like a strong programmer and had used Haskell before.</p>

<p>Their compiler was 9750 lines by <code class="language-plaintext highlighter-rouge">wc -l</code>٫ 357kb and 7777 SLOC. This team also had the only significant differences between measure ratios٫ with their compiler being 1.4x the lines٫ 1.3x the SLOC٫ and 1.6x the bytes. They didn’t implement any extra features but passed 100% of public and secret tests.</p>

<p>It’s important to note that including the tests is the least fair to this team since they were the most thorough with correctness٫ with 1600 lines of tests٫ they caught a few edge cases that our team did not٫ they just happened to not be edge cases that were tested by the course tests. So not counting tests on both sides (8.1kloc vs 6.3kloc) their compiler was only 1.3x the raw lines.</p>

<p>I also am inclined towards bytes as the more reasonable measure of amount of code here because the Haskell project has longer lines on average since it doesn’t have lots of lines dedicated to just a closing brace٫ and it’s one-liner function chains aren’t split onto a bunch of lines by <code class="language-plaintext highlighter-rouge">rustfmt</code>.</p>

<p>Digging into the difference in size with one of my friends on the team٫ we came up with the following to explain the difference:</p>

<ul>
  <li>We used a hand-written lexer and recursive descent parsing٫ where they used a <a href="https://en.wikipedia.org/wiki/Nondeterministic_finite_automaton">NFA</a> to <a href="https://en.wikipedia.org/wiki/Deterministic_finite_automaton">DFA</a> lexer generator٫ and an <a href="https://en.wikipedia.org/wiki/LR_parser">LR parser</a> and then a pass to turn the parse tree into an AST (<a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract Syntax Tree</a>٫ a more convenient representation of the code). This took them substantially more code٫ 2677 lines compared to our 1705٫ for about an extra 1k lines.</li>
  <li>They used a fancy generic AST type that transitioned to different type parameters as more information was added in each pass. This is and more helper functions for rewriting are probably why their AST code has about 500 lines more than our implementation where we build with struct literals and mutate <code class="language-plaintext highlighter-rouge">Option&lt;_&gt;</code> fields to add information as passes progress.</li>
  <li>They have about 400 more lines of code in their code generation that are mostly attributable to more abstraction necessary to generate and combine code in a purely functional way where we just use mutation and string writing.</li>
</ul>

<p>These differences plus the tests explain all of the difference in lines. In fact our files for middle passes like constant folding and scope resolution are very close to the same size. However that still leaves some difference in bytes because of longer average lines٫ which I’d guess is because they require more code to rewrite their whole tree at every pass where we just use a visitor with mutation.</p>

<p>Bottom line٫ I’d say setting aside design decisions Rust and Haskell are similarly expressive٫ with maybe a slight edge to Rust because of ability to easily use mutation when it’s convenient. It was also interesting to learn that my choice to use a recursive descent parser and hand-written lexer paid off٫ this was a risk since it wasn’t what the professor recommended and taught but I figured it would be easier and was right.</p>

<p>Haskell fans my object that this team probably didn’t use Haskell to its fullest potential and if they were better at Haskell they could have done the project with way less code. I believe that someone like <a href="https://github.com/ekmett">Edward Kmett</a> could write the same compiler in substantially fewer lines of Haskell٫ in that my friend’s team didn’t use a lot of fancy super advanced abstractions٫ and weren’t allowed to use fancy combinator libraries like <a href="http://hackage.haskell.org/package/lens">lens</a>. However٫ this would come at a cost to how difficult it would be to understand the compiler. The people on the team are all experienced programmers٫ they knew that Haskell can do extremely fancy things but chose not to pursue them because they figured it would take more time to figure them out than they would save and make their code harder for the teammates who didn’t write it to understand. This seems like a real tradeoff to me and the claim I’ve seen of Haskell being magical for compilers devolves into something like “Haskell has an extremely high skill cap for writing compilers as long as you don’t care about maintainability by people who aren’t also extremely skilled in Haskell” which is less generally applicable.</p>

<p>Another interesting thing to note is that at the start of every offering of the course the professor says that students can use any language that can run on the school servers٫ but issues a warning that teams using Haskell have the highest variance in mark of any language٫ with many teams using Haskell overestimating their ability and crashing and burning then getting a terrible mark٫ more than any other language٫ while some Haskell teams do quite well and get perfect like my friends.</p>

<h2 id="c">C++</h2>

<p>Next I talked to my friend who was on a team using C++٫ I only knew one person on this team٫ but C++ is used in multiple courses at UWaterloo so presumably everyone on the team had C++ experience.</p>

<p>Their project was 8733 raw lines and 280kb not including test code but including around 500 lines of extra features. Making it 1.4x the size of our non-test code that also had around 500 lines of extra features. They passed 100% of public tests but only passed 90% of secret tests٫ presumably because they didn’t implement the fancy array vtables required by the spec٫ which take maybe 50-100 lines of code.</p>

<p>I didn’t dig very deeply into these differences with my friend. I speculate that it’s mostly explained by:</p>

<ul>
  <li>Them using an LR parser and tree rewriter instead of a recursive descent parser</li>
  <li>The lack of sum types and pattern matching in C++٫ which we used extensively and were very helpful.</li>
  <li>Needing to duplicate all the signatures in header files٫ which Rust doesn’t have.</li>
</ul>

<p>Another thing we compared was compile times. On my laptop our compiler takes 9.7s for a clean debug build٫ 12.5s for clean release٫ and 3.5s for incremental debug. My friend didn’t have timings on hand for their C++ build (using parallel make) but said those sounded quite similar to his experience٫ with the caveat that they put the implementations of a bunch of small functions in header files to save the signature duplication at the cost of longer times (this is also why I can’t measure the pure header file line count overhead).</p>

<h2 id="python">Python</h2>

<p>I have one friend who is an extraordinarily good programmer who chose to do the project alone and in Python. She also implemented more extra features (for fun) than any other team including an SSA intermediate representation with register allocation and other optimizations. On the other hand because she was working alone and implementing a bunch of extra features٫ she dedicated the least effort to code quality٫ for example by throwing an undifferentiated exception for all errors (relying on backtraces for debugging) instead of having error types and messages like we did.</p>

<p>Her compiler was 4581 raw lines and passed all public and secret tests. She also implemented way more extra features than any other team I compare with٫ but it’s hard to determine how extra code that took because many of her extra features were more powerful versions of simple things everyone needed to implement like constant folding and code generation. The extra features probably account for 1000-2000 lines at least though٫ so I’m confident her code was at least twice as expressive as ours.</p>

<p>One large part of this difference is likely dynamic typing. Our <code class="language-plaintext highlighter-rouge">ast.rs</code> alone has 500 lines of type definitions٫ and there are many more types defined throughout our compiler. We also are always constrained in what we do by the type system. For example we need infrastructure for ergonomically adding new info to our AST as it progresses through passes and accessing that later. Whereas in Python you can just set new fields on your AST nodes.</p>

<p>Powerful metaprogramming also explains part of the difference. For example although she used an LR parser instead of a recursive descent parser٫ in her case I think it needed less code٫ because instead of a tree rewriting pass٫ her LR grammar included Python code snippets to construct the AST٫ which the generator could turn into Python functions using <code class="language-plaintext highlighter-rouge">eval</code>. Part of the reason we didn’t use an LR parser is because constructing an AST without a tree rewriting pass would require a lot of ceremony (either generating Rust files or procedural macros) to tie the grammar to snippets of Rust code.</p>

<p>Another example of the power of metaprogramming and dynamic typing is that we have a 400 line file called <code class="language-plaintext highlighter-rouge">visit.rs</code> that is mostly repetitive boilerplate code implementing a visitor on a bunch of AST structures. In Python this could be a short ~10 line function that recursively introspects on the fields of the AST node and visits them (using the <code class="language-plaintext highlighter-rouge">__dict__</code> attribute).</p>

<p>As a fan of Rust and statically typed languages in general I’m inclined to point out that the type system is very helpful for avoiding bugs and for performance. Fancy metaprogramming can also make it more difficult to understand how code works. However٫ this comparison surprised me in that I hadn’t expected the difference in the amount of code to be quite so large. If the difference in general is really close to needing to write twice the amount of code٫ I still think Rust is worth the tradeoff٫ but 2x is nothing to sneeze at and in the future I’ll be more inclined to hack something together in Ruby/Python if I just need to get it done quickly without a team and then throw it away after.</p>

<h2 id="rust-other-group">Rust (other group)</h2>

<p>The last comparison I did and also the most interesting to me was with my friend who did the project in Rust with one teammate (who I didn’t know). My friend had a good amount of Rust experience having contributed to the Rust compiler and done lots of reading٫ I don’t know about his teammate.</p>

<p>Their project was 17٫211 raw lines٫ 15k source lines٫ and 637kb not including test code and generated code. It had no extra features and passed only 4/10 secret tests and 90% of the public code generation tests٫ because they didn’t find the time before the final deadline to implement fancier pieces of the spec. This is 3 times the size of our compiler written in the same language٫ but with strictly less functionality!</p>

<p>This result was really surprising to me and dwarfed all the between-language differences I had investigated thus far. So we compared <code class="language-plaintext highlighter-rouge">wc -l</code> file size listings٫ as well as spot checking how we each implemented some specific things that had very different code sizes.</p>

<p>It seems to come down to consistently making different design decisions. For example٫ their front end (lexing٫ parsing٫ AST building) is 7597 raw lines to our 2164. They used a DFA-based lexer and LALR(1) parser٫ but the other groups did similar things without as much code. Looking at their weeder file٫ I noticed a number of different design decisions:</p>

<ul>
  <li>They chose to use a fully typed parse tree instead of the standard string-based homogeneous parse tree. This presumably required a lot more type definitions and additional transformation code in the parsing stage or a more complex parser generator.</li>
  <li>They used <code class="language-plaintext highlighter-rouge">TryFrom</code> trait implementations for converting between the parse tree types and the AST types while validating their correctness. This lead to tons of 10-20 line <code class="language-plaintext highlighter-rouge">impl</code> blocks. We used functions that returned <code class="language-plaintext highlighter-rouge">Result</code> types to accomplish the same thing٫ which had less line overhead and also freed us from the type structure a bit more٫ making parameters and re-use easier. Some things that for us were single line <code class="language-plaintext highlighter-rouge">match</code> branches were 10 line impl statements for them.</li>
  <li>Our types were structured in a way that required less copy-pasting. For example they used separate <code class="language-plaintext highlighter-rouge">is_abstract</code>٫ <code class="language-plaintext highlighter-rouge">is_native</code> and <code class="language-plaintext highlighter-rouge">is_static</code> fields whose constraint checking code needed to be copy-pasted twice٫ once for their void-typed methods and once for their methods with a return type٫ with slight modifications. Whereas for us <code class="language-plaintext highlighter-rouge">void</code> was just a special type٫ and we came up with a taxonomy of modifiers into <code class="language-plaintext highlighter-rouge">mode</code> and <code class="language-plaintext highlighter-rouge">visibility</code> enums that enforced the constraints at the type level and constraint errors were generated in the default case of the match statement that translated the modifier sets to the mode and visibility.</li>
</ul>

<p>I didn’t look at the code of the analysis passes of their compiler٫ but they are similarly large. I talked to my friend and it seems they didn’t implement anything like the visitor infrastructure that we did. I’m guessing this along with some other smaller design differences account for the size difference of this part. The visitor allowed our analysis passes to only pay attention to the parts of the AST they needed instead of having to pattern match down through the entire AST structure٫ saving a lot of code.</p>

<p>Their code generation is 3594 lines where ours is 1560. I looked at their code for this and it seems that nearly all of the difference is that they chose to have an intermediate data structure for assembly instructions٫ where we just used string formatting to directly output assembly. This required defining types and output functions for all the instructions and operand types they used. It also meant that constructing assembly instructions took way more code٫ where we might have a formatting statement that used terse instructions like <code class="language-plaintext highlighter-rouge">mov ecx٫ [edx]</code>٫ they needed a giant statement <code class="language-plaintext highlighter-rouge">rustfmt</code> split over 6 lines which constructed the instruction with a bunch of intermediate nested types for the operands involving 6 levels of nested parentheses at its deepest. We could also output blocks of related instructions like a function preamble in one formatting statement٫ where they had to do the full construction for each instruction.</p>

<p>Our team considered using such an abstraction. It would make it easier to have the option of either outputting textual assembly or directly emitting machine code٫ however that wasn’t a requirement of the course. The same thing could also be accomplished with less code and better performance using an <code class="language-plaintext highlighter-rouge">X86Writer</code> trait with methods like <code class="language-plaintext highlighter-rouge">push(reg: Register)</code>. Another angle we considered was that it might make debugging and testing easier٫ but we realized that looking at the generated textual assembly would actually be easier to read and test with <a href="https://docs.rs/insta/0.8.1/insta/">snapshot testing</a> as long as we inserted comments liberally. But we (apparently correctly) predicted that it would take a lot of extra code٫ and there wasn’t any real benefit given what we knew we were going to need٫ so we didn’t bother.</p>

<p>A good comparison is with the intermediate representation the C++ group used as an extra feature٫ which only took them closer to 500 extra lines. They used a very simple structure (making for simple type definitions and construction code) that used operations close to what Java required. This meant that their IR was much smaller (and thus required less construction code) than the resulting assembly٫ since many language operations like calls and casts expanded into many assembly instructions. They also say it really helped debugging since it cut out a lot of the cruft and was easy to read. The higher level representation also allowed them to do some simple optimizations on their IR. The C++ team came up with a really nice design which got them much more benefit with much less code.</p>

<p>Overall it seems like the overall 3x size multiplier is due to consistently making different design decisions both large and small in the direction of larger code. They implemented a number of abstractions that we didn’t which added more code٫ and missed out on some of the abstractions we implemented which lead to less code.</p>

<p>This result really surprised me٫ I knew design decisions mattered but I wouldn’t have guessed beforehand that they would lead to any differences this large٫ given that I was only surveying people that I consider strong competent programmers. Of all the results from this comparison٫ this is the one I learned the most from. Something that I think helped was that I had read a lot about how to write compilers before I took the course٫ so I could take advantage of clever designs other people had come up with and found worked well like AST visitors and recursive descent parsing even when they weren’t taught in the course.</p>

<p>One thing this really made me think about is the cost of abstraction. Abstractions may make things easier to extend in the future٫ or guard against certain types of errors٫ but they need to be considered against the fact that you may end up with 3 times the amount of code to understand and refactor٫ 3 times the amount of possible locations for bugs and less time left to spend on testing and further development. Our course was unlike the real world in that we knew exactly what we needed to implement and that we’d never touch the code afterwards٫ which eliminates the benefits of pre-emptive abstraction. However if you were going to challenge me to extend a compiler with an arbitrary feature you’d tell me later٫ and I had to pick which compiler I’d start from٫ I’d choose ours even setting aside familiarity. Because there’d simply be much less code that I’d need to understand how to change٫ and I could potentially choose a better abstraction for the requirements (like the C++ team’s IR) once I knew how I needed to extend things.</p>

<p>It also solidified the taxonomy in my head of abstractions that you expect to remove code given only your current requirements٫ like our visitor pattern٫ and abstractions you expect to add code given only your immediate requirements٫ but that may provide extensibility٫ debuggability or correctness benefits.</p>

<h2 id="scala">Scala</h2>

<p>I also talked to a friend of mine who did the project in a previous term using Scala٫ but the project and tests were the exact same ones. Their compiler was 4141 raw lines and ~160kb of code not counting tests. They passed 8/10 secret tests and 100% of public tests and didn’t implement any extra features. So comparing with our 5906 lines without extra features and tests٫ their compiler is 0.7x the size.</p>

<p>One design factor in their low line count was that they used a different approach to parsing. The course allowed you to use a command line LR table generator tool that the course provided٫ which this team used but no other team I mention did. This saved them having to implement an LR table generator. They also managed to avoid writing the LR grammar using a 150 line Python script which scraped a Java grammar web page they found online and translated it into the input format of the generator tool. They still needed to do some tree building in Scala but overall their parsing stage came in at 1073 lines to our 1443٫ where most other teams use of LR parsing lead to larger parsers than our recursive descent one.</p>

<p>The rest of their compiler was similarly smaller than ours though without any obvious large design differences٫ although I didn’t dig into the code. I suspect this is probably due to differences in expressiveness between Scala and Rust. Scala and Rust have similar functional programming features helpful for compilers٫ like pattern matching٫ but Scala’s managed memory saves on code required to make the Rust borrow checker happy. Scala also has more miscellaneous syntactic sugar than Rust.</p>

<h2 id="ocaml">OCaml</h2>

<p>Since my team had all interned at <a href="https://www.janestreet.com/">Jane Street</a> the other language we considered using was OCaml٫ we decided on Rust but I was curious about how OCaml might have turned out so I talked to someone else I knew had interned at Jane Street and they indeed did their compiler in OCaml with two other former Jane Street interns.</p>

<p>Their compiler was 10914 raw lines and 377kb including a small amount of test code and no extra features. They passed 9/10 secret tests and all public tests.</p>

<p>Like other groups it looks like a lot of the size difference is due to them using an LR parser generator and tree rewriting for parsing٫ as well as a regex-&gt;NFA-&gt;DFA conversion pipeline for lexing. Their front-end (lexing+parsing+AST construction) is 5548 lines where ours is 2164٫ with similar ratios for bytes. They also used <a href="https://blog.janestreet.com/testing-with-expectations/">expect tests</a> for their parser where we used similar snapshot tests that put the expected output outside the code٫ so their parser tests were ~600 lines of that total where ours were ~200.</p>

<p>That leaves 5366 lines (461 lines of which is interface files with just type declarations) for the rest of their compiler and 4642 for ours٫ only 1.15x larger if you count interface files and basically the same size if you don’t count them. So it looks like setting aside our parsing design decisions٫ Rust and OCaml seem similarly expressive except that OCaml needs interface files and Rust doesn’t.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Overall I’m very glad I did this comparison٫ I learned a lot from it and was surprised many times. I think my overall takeaway is that design decisions make a much larger difference than the language٫ but the language matters insofar as it gives you the tools to implement different designs.</p>
'),('http://thume.ca/2019/04/18/writing-a-compiler-in-rust/', 'Writing a Compiler in Rust', '1555545600000',  13, '
<p>During my final term at UWaterloo I took <a href="https://www.student.cs.uwaterloo.ca/~cs444/">the CS444 compilers class</a> with a project to write a compiler from a substantial subset of Java to x86٫ with a language and two teammates of your choice. My group of three chose to write our compiler in Rust and it was a fun experience. We spent time coming to design decisions that worked out really well and used Rust’s strengths. Our compiler ended up being around 6800 lines of Rust and I personally put in around 60 hours of solid coding and more on code review and design. In this post I’ll go over some of the design decisions we made and some thoughts on what it was like using Rust.</p>

<h2 id="lexing-and-parsing">Lexing and Parsing</h2>

<p>The lectures for the course recommended writing an NFA to DFA compiler to implement the lexer٫ and writing an <a href="https://en.wikipedia.org/wiki/Canonical_LR_parser">LR(1)</a> parser generator for the parser٫ then having a separate “weeding” pass to construct a final AST (<a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract Syntax Tree</a>) and validate it in various ways.</p>

<p>I suggested that we should try using a hand-written lexer and recursive descent parser instead٫ and my teammates agreed. A recursive descent parser allowed us to put all the code to parse٫ validate٫ and create the AST node in one place. We figured writing a pass to rewrite and validate the raw parse tree into a strongly typed AST would be about as much code as a recursive descent parser٫ except with the additional work of having to implement an LR(1) parser generator.</p>

<p>The AST we produced made good use of Rust’s type system٫ including extensive use of <code class="language-plaintext highlighter-rouge">enum</code> sum types to handle variants of types٫ expressions and statements. We also used <code class="language-plaintext highlighter-rouge">Option</code> and <code class="language-plaintext highlighter-rouge">Vec</code> extensively٫ as well as <code class="language-plaintext highlighter-rouge">Box</code> to allow type recursion. Our AST types looked like this:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// We preserve source span information using a `Spanned` struct</span>
<span class="k">pub</span> <span class="k">type</span> <span class="n">Type</span> <span class="o">=</span> <span class="n">Spanned</span><span class="o">&lt;</span><span class="n">TypeKind</span><span class="o">&gt;</span><span class="p">;</span>

<span class="nd">#[derive(Clone٫</span> <span class="nd">Debug٫</span> <span class="nd">PartialEq٫</span> <span class="nd">Eq٫</span> <span class="nd">Hash)]</span>
<span class="k">pub</span> <span class="k">enum</span> <span class="n">TypeKind</span> <span class="p">{</span>
    <span class="nf">Array</span><span class="p">(</span><span class="nb">Box</span><span class="o">&lt;</span><span class="n">Type</span><span class="o">&gt;</span><span class="p">)٫</span>
    <span class="nf">Ref</span><span class="p">(</span><span class="n">TypeRef</span><span class="p">)٫</span>
    <span class="n">Int</span><span class="p">٫</span>
    <span class="n">Byte</span><span class="p">٫</span>
    <span class="c">// ...</span>
<span class="p">}</span>

<span class="c">// ...</span>

<span class="nd">#[derive(Clone٫</span> <span class="nd">Debug)]</span>
<span class="k">pub</span> <span class="k">struct</span> <span class="n">InterfaceDecl</span> <span class="p">{</span>
    <span class="k">pub</span> <span class="n">name</span><span class="p">:</span> <span class="nb">String</span><span class="p">٫</span>
    <span class="k">pub</span> <span class="n">extends</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="n">TypeRef</span><span class="o">&gt;</span><span class="p">٫</span>
    <span class="k">pub</span> <span class="n">methods</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="n">Signature</span><span class="o">&gt;</span><span class="p">٫</span>
<span class="p">}</span>
</code></pre></div></div>

<p>We produced this using a <code class="language-plaintext highlighter-rouge">Parser</code> struct with functions for parsing different constructs that could also return parse errors. The <code class="language-plaintext highlighter-rouge">Parser</code> struct had a number of helper functions to easily consume and inspect tokens٫ using the power of abstraction present in a full programming language to get closer to the brevity of a parser generator grammar DSL. Here’s an example of what our parser looked like:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[derive(Clone٫</span> <span class="nd">Debug)]</span>
<span class="k">pub</span> <span class="k">enum</span> <span class="n">ParseError</span> <span class="p">{</span>
    <span class="nf">Unexpected</span><span class="p">(</span><span class="n">SpannedToken</span><span class="p">)٫</span>
    <span class="nf">DuplicateModifier</span><span class="p">(</span><span class="n">SpannedToken</span><span class="p">)٫</span>
    <span class="n">MultipleVisibilities</span><span class="p">٫</span>
    <span class="c">// ...</span>
<span class="p">}</span>

<span class="k">pub</span> <span class="k">struct</span> <span class="n">Parser</span><span class="o">&lt;</span><span class="nv">"a</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="n">tokens</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">"a</span> <span class="p">[</span><span class="n">SpannedToken</span><span class="p">]٫</span>
    <span class="n">pos</span><span class="p">:</span> <span class="nb">usize</span><span class="p">٫</span>
<span class="p">}</span>

<span class="c">// ...</span>

<span class="k">fn</span> <span class="nf">parse_for_statement</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">PResult</span><span class="o">&lt;</span><span class="n">ForStatement</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">self</span><span class="nf">.eat</span><span class="p">(</span><span class="o">&amp;</span><span class="nn">Token</span><span class="p">::</span><span class="n">For</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
    <span class="k">self</span><span class="nf">.eat</span><span class="p">(</span><span class="o">&amp;</span><span class="nn">Token</span><span class="p">::</span><span class="n">LParen</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">init</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.parse_unless_and_eat</span><span class="p">(</span><span class="nn">Token</span><span class="p">::</span><span class="n">Semicolon</span><span class="p">٫</span> <span class="nn">Self</span><span class="p">::</span><span class="n">parse_for_init</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">condition</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.parse_unless_and_eat</span><span class="p">(</span><span class="nn">Token</span><span class="p">::</span><span class="n">Semicolon</span><span class="p">٫</span> <span class="nn">Self</span><span class="p">::</span><span class="n">parse_expr</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">update</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.parse_unless_and_eat</span><span class="p">(</span><span class="nn">Token</span><span class="p">::</span><span class="n">RParen</span><span class="p">٫</span> <span class="nn">Self</span><span class="p">::</span><span class="n">parse_statement_expr</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">body</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.parse_statement</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>
    <span class="nf">Ok</span><span class="p">(</span><span class="n">ForStatement</span> <span class="p">{</span> <span class="n">init</span><span class="p">٫</span> <span class="n">condition</span><span class="p">٫</span> <span class="n">update</span><span class="p">٫</span> <span class="n">body</span> <span class="p">})</span>
<span class="p">}</span>

<span class="c">// ...</span>

</code></pre></div></div>

<h3 id="backtracking">Backtracking</h3>

<p>Mostly our parser takes the form of an <a href="https://en.wikipedia.org/wiki/LL_parser">LL(1) parser</a>٫ which looks ahead one token to decide how it should parse. But some constructs require unlimited lookahead to parse. For example <code class="language-plaintext highlighter-rouge">(java.lang.String)a</code> should parse as a parenthesized field access chain on the ‘java’ variable except for the <code class="language-plaintext highlighter-rouge">a</code> at the end٫ which makes it a cast expression. In fact even <code class="language-plaintext highlighter-rouge">LR(1)</code> parsers can’t parse this specific case properly٫ and the recommended hack is to parse the inside of the parens as an “expression” and then just validate in the weeder that the expression is actually a type.</p>

<p>We solve this problem using backtracking٫ which is where we can save a position in the token stream٫ speculatively parse the following input as one construct٫ and then roll back to that saved position if that parsing fails. This can cause non-linear parse times on pathological input٫ but pathological cases don’t occur non-maliciously in practice٫ especially if backtracking is only used in some situations rather than for the whole parser.</p>

<p>An alternative strategy to backtracking that works in some situations is to parse the common elements of both nonterminals that could follow٫ then once the parser reaches the point where it can decide٫ it calls the specific non-terminal function passing what has been parsed so far as arguments. We use this strategy for deciding between parsing classes and interfaces and between parsing methods and constructors٫ by parsing the modifiers first٫ then looking ahead٫ then parsing the rest passing the parsed modifiers as arguments.</p>

<p>We have Rust helper functions that make backtracking really easy by trying one parse and then trying another if the first parse returns an <code class="language-plaintext highlighter-rouge">Err</code>:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// Unlike the Java spec٫ we can have arguments like `allow_minus` to avoid</span>
<span class="c">// massive duplication in the case of minor special cases.</span>
<span class="c">// `allow_minus` makes sure `(a)-b` parses as `int-int` rather than `(Type)(-int)`</span>
<span class="k">fn</span> <span class="nf">parse_prim_expr</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">٫</span> <span class="n">allow_minus</span><span class="p">:</span> <span class="n">AllowMinus</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">PResult</span><span class="o">&lt;</span><span class="nb">Box</span><span class="o">&lt;</span><span class="n">Expr</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">cur</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">self</span><span class="py">.tokens</span><span class="p">[</span><span class="k">self</span><span class="py">.pos</span><span class="p">];</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">lhs</span> <span class="o">=</span> <span class="k">match</span> <span class="o">&amp;</span><span class="n">cur</span><span class="py">.tok</span> <span class="p">{</span>
        <span class="nn">Token</span><span class="p">::</span><span class="n">LParen</span> <span class="k">=&gt;</span> <span class="k">self</span><span class="nf">.one_of</span><span class="p">(</span><span class="nn">Self</span><span class="p">::</span><span class="n">parse_cast_expr</span><span class="p">٫</span> <span class="nn">Self</span><span class="p">::</span><span class="n">parse_paren_expr</span><span class="p">)٫</span>
        <span class="c">// ...</span>
    <span class="p">};</span>
    <span class="c">// ...</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="pratt-expression-parsing">Pratt expression parsing</h3>

<p>Instead of parsing expressions with precedence using many grammar levels٫ we use a <a href="https://www.oilshell.org/blog/2017/03/31.html">Pratt parsing / precedence climbing</a> system. This algorithm allows specifying the operators as a table with a “binding power” integer٫ with higher binding power for operators with higher precedence. This is both easier and more efficient for parsing expressions with many levels of precedence.</p>

<p>Instead of using data tables like in the canonical Pratt parser implementation٫ we used Rust functions with match statements٫ which fill the same purpose but with more power and no need to keep a data structure around:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">binding_power</span><span class="p">(</span><span class="n">cur</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">SpannedToken</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Option</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">match</span> <span class="o">&amp;</span><span class="n">cur</span><span class="py">.tok</span> <span class="p">{</span>
        <span class="nn">Token</span><span class="p">::</span><span class="nf">Operator</span><span class="p">(</span><span class="n">op</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="k">match</span> <span class="n">op</span> <span class="p">{</span>
            <span class="nn">Op</span><span class="p">::</span><span class="n">Times</span> <span class="p">|</span> <span class="nn">Op</span><span class="p">::</span><span class="n">Divide</span> <span class="p">|</span> <span class="nn">Op</span><span class="p">::</span><span class="nb">Modulo</span> <span class="k">=&gt;</span> <span class="nf">Some</span><span class="p">(</span><span class="mi">12</span><span class="p">)٫</span>
            <span class="nn">Op</span><span class="p">::</span><span class="n">Plus</span> <span class="p">|</span> <span class="nn">Op</span><span class="p">::</span><span class="n">Minus</span> <span class="k">=&gt;</span> <span class="nf">Some</span><span class="p">(</span><span class="mi">11</span><span class="p">)٫</span>
            <span class="nn">Op</span><span class="p">::</span><span class="n">Greater</span> <span class="p">|</span> <span class="nn">Op</span><span class="p">::</span><span class="n">GreaterEqual</span> <span class="p">|</span> <span class="nn">Op</span><span class="p">::</span><span class="n">Less</span> <span class="p">|</span> <span class="nn">Op</span><span class="p">::</span><span class="n">LessEqual</span> <span class="k">=&gt;</span> <span class="nf">Some</span><span class="p">(</span><span class="mi">9</span><span class="p">)٫</span>
            <span class="nn">Op</span><span class="p">::</span><span class="n">Equal</span> <span class="p">|</span> <span class="nn">Op</span><span class="p">::</span><span class="n">NotEqual</span> <span class="k">=&gt;</span> <span class="nf">Some</span><span class="p">(</span><span class="mi">8</span><span class="p">)٫</span>
            <span class="nn">Op</span><span class="p">::</span><span class="n">And</span> <span class="k">=&gt;</span> <span class="nf">Some</span><span class="p">(</span><span class="mi">7</span><span class="p">)٫</span>
            <span class="c">// ...</span>
        <span class="p">}٫</span>
        <span class="nn">Token</span><span class="p">::</span><span class="n">Instanceof</span> <span class="k">=&gt;</span> <span class="nf">Some</span><span class="p">(</span><span class="mi">9</span><span class="p">)٫</span>
        <span class="mi">_</span> <span class="k">=&gt;</span> <span class="nb">None</span><span class="p">٫</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="snapshot-testing">Snapshot testing</h2>

<p>Starting when we did our parser and continuing for the rest of our compiler٫ we made extensive use of snapshot testing with the <a href="https://github.com/mitsuhiko/insta">insta crate</a>. Snapshot testing (similar to <a href="https://blog.janestreet.com/testing-with-expectations/">expect tests</a>) allows you to write tests which just provide the resulting data structure of some process and the testing system will create a “snapshot” of the result of that test in a file٫ and if the result ever changes it will cause a test failure and show you the diff between the snapshot file and the result it got. If the change was expected٫ you can then run a command to update the snapshot files that changed.</p>

<p>This was super useful for writing our parser٫ before we could parse full files and do anything with them٫ we could parse short snippets into AST types implementing the Rust <code class="language-plaintext highlighter-rouge">Debug</code> trait٫ and <code class="language-plaintext highlighter-rouge">insta</code> would create pretty-printed snapshots that we could inspect for correctness٫ and then commit to check for future regressions.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[test]</span>
<span class="k">fn</span> <span class="nf">test_statement</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">lexer</span> <span class="o">=</span> <span class="nf">file_lexer</span><span class="p">(</span><span class="s">"testdata/statements.java"</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">tokens</span> <span class="o">=</span> <span class="n">lexer</span><span class="nf">.lex_all</span><span class="p">()</span><span class="nf">.unwrap</span><span class="p">();</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">parser</span> <span class="o">=</span> <span class="nn">Parser</span><span class="p">::</span><span class="nf">create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tokens</span><span class="p">);</span>

    <span class="k">let</span> <span class="n">statement</span> <span class="o">=</span> <span class="n">parser</span><span class="nf">.parse_statement</span><span class="p">();</span>
    <span class="nd">assert_debug_snapshot_matches!</span><span class="p">(</span><span class="s">"statements"</span><span class="p">٫</span> <span class="n">statement</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Later during the code generation phase we used this extensively to check our assembly output on test programs.</p>

<h2 id="semantic-analysis">Semantic analysis</h2>

<p>About half of our compiler is in the middle-end passes which compute information necessary for code generation and verify various correctness properties. This includes:</p>

<ul>
  <li>Resolving variable and type names.</li>
  <li>Folding constant expressions like <code class="language-plaintext highlighter-rouge">5*3+2</code> into numbers.</li>
  <li>Checking many different constraints of the Java class/interface hierarchy.</li>
  <li>Checking that all statements are reachable and all non-<code class="language-plaintext highlighter-rouge">void</code> functions return.</li>
  <li>Resolving types of all expressions and checking their correctness.</li>
</ul>

<h3 id="visitor-infrastructure">Visitor infrastructure</h3>

<p>Most of the passes in the middle of our compiler only care about certain AST nodes٫ but need to act on those nodes anywhere they might occur in the AST. One way to do this would be to pattern match through the whole AST in every patch٫ but there’s a lot of nodes so that would involve a lot of duplication.</p>

<p>Instead we have a <code class="language-plaintext highlighter-rouge">Visitor</code> trait (like an interface in other languages) which can be implemented by a compiler pass. It has callbacks only for the events we actually need٫ which can run code at various points in the traversal of the AST٫ as well as modify the AST in place. All the callbacks have default implementations that do nothing so that passes only need to implement the methods they need.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">// We use a dynamic error type here so we don"t have to make the visitor generic and</span>
<span class="c">// instantiate it a bunch for every error type</span>
<span class="k">pub</span> <span class="k">type</span> <span class="n">VResult</span> <span class="o">=</span> <span class="n">Result</span><span class="o">&lt;</span><span class="p">()٫</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="nn">std</span><span class="p">::</span><span class="nn">error</span><span class="p">::</span><span class="n">Error</span><span class="o">&gt;&gt;</span><span class="p">;</span>

<span class="k">pub</span> <span class="k">trait</span> <span class="n">Visitor</span> <span class="p">{</span>
    <span class="c">// used for resolving variable references</span>
    <span class="k">fn</span> <span class="nf">visit_var_ref</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">٫</span> <span class="mi">_</span><span class="n">t</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">VarRef</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span> <span class="p">{</span>
        <span class="nf">Ok</span><span class="p">(())</span>
    <span class="p">}</span>

    <span class="k">fn</span> <span class="nf">start_method</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">٫</span> <span class="mi">_</span><span class="n">t</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">Method</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span> <span class="p">{</span>
        <span class="nf">Ok</span><span class="p">(())</span>
    <span class="p">}</span>

    <span class="c">// `finish_` methods get passed the result of traversing their body so that they</span>
    <span class="c">// can wrap errors to provide better location information</span>
    <span class="k">fn</span> <span class="nf">finish_method</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">٫</span> <span class="mi">_</span><span class="n">t</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">Method</span><span class="p">٫</span> <span class="n">res</span><span class="p">:</span> <span class="n">VResult</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span> <span class="p">{</span>
        <span class="n">res</span>
    <span class="p">}</span>

    <span class="c">// like a `finish_` method except it doesn"t need the result</span>
    <span class="k">fn</span> <span class="nf">post_expr</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">٫</span> <span class="mi">_</span><span class="n">t</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">Expr</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span> <span class="p">{</span>
        <span class="nf">Ok</span><span class="p">(())</span>
    <span class="p">}</span>

    <span class="c">// ... a bunch of other methods</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Passes that implement <code class="language-plaintext highlighter-rouge">Visitor</code> are driven by dynamically dispatched calls from the <code class="language-plaintext highlighter-rouge">Visitable</code> trait٫ which is implemented by every AST node and traverses the whole tree in evaluation order. A cool Rust feature we make good use of is “blanket impls” which make the logic for handling AST children that are in containers clean and uniform.</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">trait</span> <span class="n">Visitable</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">visit</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">٫</span> <span class="n">v</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">dyn</span> <span class="n">Visitor</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="p">:</span> <span class="n">Visitable</span><span class="o">&gt;</span> <span class="n">Visitable</span> <span class="k">for</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">visit</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">٫</span> <span class="n">v</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">dyn</span> <span class="n">Visitor</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span> <span class="p">{</span>
        <span class="k">for</span> <span class="n">t</span> <span class="n">in</span> <span class="k">self</span> <span class="p">{</span>
            <span class="n">t</span><span class="nf">.visit</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="nf">Ok</span><span class="p">(())</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c">// ... other blanket impls for Option&lt;T&gt; and Box&lt;T&gt;</span>

<span class="k">impl</span> <span class="n">Visitable</span> <span class="k">for</span> <span class="n">TypeKind</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">visit</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">٫</span> <span class="n">v</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">dyn</span> <span class="n">Visitor</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span> <span class="p">{</span>
        <span class="k">match</span> <span class="k">self</span> <span class="p">{</span>
            <span class="nn">TypeKind</span><span class="p">::</span><span class="nf">Array</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="nf">.visit</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">?</span><span class="p">٫</span>
            <span class="nn">TypeKind</span><span class="p">::</span><span class="nf">Ref</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="nf">.visit</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">?</span><span class="p">٫</span>
            <span class="mi">_</span> <span class="k">=&gt;</span> <span class="p">()٫</span>
        <span class="p">}</span>
        <span class="nf">Ok</span><span class="p">(())</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">impl</span> <span class="n">Visitable</span> <span class="k">for</span> <span class="n">ForStatement</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">visit</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">٫</span> <span class="n">v</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">dyn</span> <span class="n">Visitor</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">VResult</span> <span class="p">{</span>
        <span class="n">v</span><span class="nf">.start_for_statement</span><span class="p">(</span><span class="k">self</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
        <span class="c">// closure allows us to use ? to combine results</span>
        <span class="k">let</span> <span class="n">res</span> <span class="o">=</span> <span class="p">(||</span> <span class="p">{</span>
            <span class="k">self</span><span class="py">.init</span><span class="nf">.visit</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
            <span class="k">self</span><span class="py">.condition</span><span class="nf">.visit</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
            <span class="k">self</span><span class="py">.update</span><span class="nf">.visit</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
            <span class="k">self</span><span class="py">.body</span><span class="nf">.visit</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="p">})();</span>
        <span class="n">v</span><span class="nf">.finish_for_statement</span><span class="p">(</span><span class="k">self</span><span class="p">٫</span> <span class="n">res</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c">// ... many other Visitable implementations</span>
</code></pre></div></div>

<p>This made a lot of our passes much easier. For example constant folding just overrides the <code class="language-plaintext highlighter-rouge">post_expr</code> method٫ checks if the children of an expression are constants and if so uses <code class="language-plaintext highlighter-rouge">mem::replace</code> to replace the node with a constant.</p>

<h3 id="resolving-names">Resolving names</h3>

<p>One discussion we had is how to handle resolving type and variable names. The most obvious way was doing so by mutating the AST using an <code class="language-plaintext highlighter-rouge">Option</code> field that’s initially <code class="language-plaintext highlighter-rouge">None</code>. However our functional programmer instincts felt icky about this so we tried to think of a better way. Using an optional field also had the problem that we knew by the code generation phase that all variables would be resolved but the type system would still think they could be <code class="language-plaintext highlighter-rouge">None</code> so we’d need to <code class="language-plaintext highlighter-rouge">unwrap()</code> them every time we wanted to access them.</p>

<p>We first considered using a side table where we’d give every named reference an ID or hash it٫ then have a map from ID to resolved location that we created during the resolution stage. But we didn’t like how this would make debugging harder since we could no longer just print out our AST types with <code class="language-plaintext highlighter-rouge">Debug</code> to see all their information including resolutions. It also would require passing around quite a few side tables and doing lots of lookups in them by the later stages. It didn’t even solve the need for <code class="language-plaintext highlighter-rouge">unwrap</code> since the table access could theoretically not find the corresponding element.</p>

<p>Next we considered making all of our AST types generic with an annotation type parameter that started out as <code class="language-plaintext highlighter-rouge">()</code> but changed as the AST progressed through stages where it gained more info. The main problem with this is that each pass would need to re-build the entire AST٫ which would make easy visitor infrastructure much harder. Maybe if Rust had something like <a href="https://gitlab.haskell.org/ghc/ghc/wikis/commentary/compiler/derive-functor">an automatically derivable <code class="language-plaintext highlighter-rouge">Functor</code> implementation</a> it wouldn’t have been bad٫ but barring that it would need a lot of boilerplate. There were also multiple things we needed to annotate at various stages necessitating many parameters٫ and a lot of AST types٫ which would require a lot of refactoring our AST and parser to add a multitude of parameters.</p>

<p>So instead we just bit the bullet and used <code class="language-plaintext highlighter-rouge">Option</code> type fields٫ and I think it worked out well. We implemented a nice <code class="language-plaintext highlighter-rouge">Reference&lt;T٫ R&gt;</code> generic that had a <code class="language-plaintext highlighter-rouge">raw</code> and <code class="language-plaintext highlighter-rouge">resolved</code> field. We used it for both variable and type references. It had <code class="language-plaintext highlighter-rouge">Hash</code> and <code class="language-plaintext highlighter-rouge">PartialEq</code> implementations that only looked at the resolved value because that’s what mattered for data structures in later passes. It also had a special <code class="language-plaintext highlighter-rouge">Debug</code> implementation that made the output in snapshot tests nicer:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="p">:</span> <span class="nn">fmt</span><span class="p">::</span><span class="n">Debug</span><span class="p">٫</span> <span class="n">R</span><span class="p">:</span> <span class="nn">fmt</span><span class="p">::</span><span class="n">Debug</span><span class="o">&gt;</span> <span class="nn">fmt</span><span class="p">::</span><span class="n">Debug</span> <span class="k">for</span> <span class="n">Reference</span><span class="o">&lt;</span><span class="n">T</span><span class="p">٫</span> <span class="n">R</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">fmt</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">٫</span> <span class="n">f</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="nn">fmt</span><span class="p">::</span><span class="n">Formatter</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nn">fmt</span><span class="p">::</span><span class="n">Result</span> <span class="p">{</span>
        <span class="k">if</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">self</span><span class="py">.resolved</span> <span class="p">{</span>
            <span class="nd">write!</span><span class="p">(</span><span class="n">f</span><span class="p">٫</span> <span class="s">"{:#?} =&gt; {:#?}"</span><span class="p">٫</span> <span class="k">self</span><span class="py">.raw</span><span class="p">٫</span> <span class="n">r</span><span class="p">)</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="nd">write!</span><span class="p">(</span><span class="n">f</span><span class="p">٫</span> <span class="s">"{:?}"</span><span class="p">٫</span> <span class="k">self</span><span class="py">.raw</span><span class="p">)</span> <span class="c">// only print the raw if not resolved yet</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="reference-counting">Reference counting</h3>

<p>In a number of different places٫ especially the class hierarchy checking and type checking phases٫ a lot of things needed to have the same pieces of information propagated to them. For example types bubbling up an expression or inherited methods bubbling down a tree. In a language like Java we’d just have multiple references to the same object٫ but in Rust for ownership reasons we couldn’t do that straightforwardly. We started out in some places by <code class="language-plaintext highlighter-rouge">clone</code>ing things which worked fine٫ but I realized I could just switch everything to use <code class="language-plaintext highlighter-rouge">Rc</code> to allow sharing.</p>

<p>I had an interesting moment where I thought “man it sucks that this code has to do all this reference count manipulation٫ that’s unnecessarily slow٫ maybe I should refactor this to use an arena or something”. Then I realized that if I had been writing in Swift I wouldn’t have given this a second thought because <em>everything</em> would be ref-counted٫ and even worse than the Rust version٫ <em>atomically</em> ref-counted. Writing code in Rust makes me feel like I have an obligation to make code as fast as possible in a way other languages don’t٫ just by surfacing the costs better. Sometimes I need to remind myself that actually it’s fast enough already.</p>

<h2 id="code-generation">Code Generation</h2>

<p>The course requires that we generate textual NASM x86 assembly files. Given that we only need to output to those٫ we decided we didn’t need an intermediate abstraction for generating assembly٫ and our code generation stage could just use Rust string formatting. This would make our code simpler٫ easier and also allow us to more easily include comments in the generated assembly.</p>

<p>The fact that we preserved source span information through our whole compiler and could generate comments came in handy because we could output comments containing the source expression/statement location for every single generated piece of code. This made it much easier to track down exactly which piece of code was causing a bug.</p>

<p>A somewhat annoying Rust thing we ran into is that we could find two easy ways of formatting to a string٫ both of which had an issue:</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="k">mut</span> <span class="n">s</span> <span class="o">=</span> <span class="nn">String</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>
<span class="c">// Requires a Result return type or unwrap٫ even though it won"t ever fail.</span>
<span class="c">// Generates a bunch of garbage error handling LLVM needs to optimize out.</span>
<span class="nd">writeln!</span><span class="p">(</span><span class="n">s</span><span class="p">٫</span> <span class="s">"mov eax٫ {}"</span><span class="p">٫</span> <span class="n">val</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
<span class="c">// Allocates an intermediate String which it then immediately frees</span>
<span class="n">s</span><span class="nf">.push_str</span><span class="p">(</span><span class="nd">format!</span><span class="p">(</span><span class="s">"mov eax٫ {}"</span><span class="p">٫</span> <span class="n">val</span><span class="p">));</span>
</code></pre></div></div>

<p>My two teammates worked on the initial stages of code generation in parallel and each of them chose a different fork of this tradeoff٫ and by that close to the end of the course our consistency standards had relaxed٫ so our code generation has both.</p>

<h3 id="usercorn">Usercorn</h3>

<p>Our compiler was supposed to output Linux ELF binaries and link to a runtime that made Linux syscalls. However٫ our entire team used macOS. Rewriting the runtime for macOS would have been somewhat annoying since syscalls aren’t always as easy and well documented on macOS as Linux. It also would have added an annoying delay to running our tests and made the harness more complex if we had to <code class="language-plaintext highlighter-rouge">scp</code> the binaries to a Linux server or VM.</p>

<p>I remembered that my internet friend had written a cool tool called <a href="https://github.com/lunixbochs/usercorn">usercorn</a> that used the <a href="https://www.unicorn-engine.org/">Unicorn CPU emulator</a> plus some fanciness to run Linux binaries on macOS as if they were normal macOS binaries (or vice versa and a bunch of other things). It was straightforward to build a self-contained version that I could check into our repository and use in our tests to run our binaries. My teammate then got together a macOS build of <code class="language-plaintext highlighter-rouge">ld</code> that could link Linux ELF binaries and included it.</p>

<p>We could also use <code class="language-plaintext highlighter-rouge">usercorn</code> to output a trace of all the instructions executed and registers modified by our programs٫ and this came in handy quite a few times for debugging our code generation.</p>

<p>I ran into one problem where a test program that did a lot of allocation was 1000x slower under usercorn than on a real Linux server. Luckily I knew the author and I just sent him the offending binary and he quickly figured it was due to an inefficient implementation of the <code class="language-plaintext highlighter-rouge">brk</code> syscall which reasonable programs don’t use for every single memory allocation like the runtime the course provided did. He quickly figured out how to make it more efficient and pushed a fix later that evening which solved my problem. He’s pretty awesome٫ <a href="https://www.patreon.com/lunixbochs/overview">subscribe to his Patreon!</a></p>

<p>I then shared our pre-compiled bundle of <code class="language-plaintext highlighter-rouge">usercorn</code> and <code class="language-plaintext highlighter-rouge">ld</code> (with the bug fix for the assignment tests) with a few other teams I knew who used macOS so they could have an easier time testing as well.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Overall I’m proud of how our compiler turned out. It was a fun project and my teammates were excellent. I also think Rust ended up being a good choice of implementation language٫ especially the powerful <code class="language-plaintext highlighter-rouge">enum</code>s and pattern matching. The main downsides of Rust were the long compile times (although apparently comparable to a group that did their compiler in C++)٫ and the fact that sometimes we had to do somewhat more work to satisfy the borrow checker.</p>

<p>One of the most interesting learning experiences from the project was when afterwards I talked to some other teams and got to compare what it was like to do the same project in different languages and with different design decisions. I’ll talk about that in an upcoming post!</p>
'),('http://thume.ca/2019/03/03/my-tungsten-cube/', 'My Tungsten Cube', '1551571200000',  13, '
<p>A few months ago I bought a featureless cube of tungsten. It’s 1.5 inches across and cost $130٫ but I argue it was one of the best purchases I’ve made recently.</p>

<p>Why would I spend so much money on a cube? Well it’s really dense. Tungsten is one of the densest elements٫ over twice the density of steel. My cube weighs one kilogram despite being pretty small. The first time I held a friend’s tungsten cube I was blown away٫ it felt like some otherworldy force was pulling the cube down into my hand (spoiler: it was gravity). Whenever I show people my cube they consistently find it really cool and it’s fun to be able to so easily share a unique experience like that.</p>

<p>Even after the initial surprise wore off٫ I still find it just really satisfying to hold. Ever hold something with satisfying heft? Well it’s like the platonically purest amplified form of that satisfaction. I keep it on my desk and turn it around in my hands while I’m thinking.</p>

<p>The cool thing about it being a featureless hunk of extremely hard٫ durable metal that doesn’t really oxidize away٫ is that it will last for a long time. I expect I’ll continue getting value out of having this cube on my desk for at least 5 years and probably more. Given how much I fidget with the cube and enjoy owning it٫ I figure I definitely get more than $2/month worth of value out of it.</p>

<p>I struggled a lot with deciding to buy a cube. It felt <em>wrong</em> to spend so much money on a featureless hunk of metal. Money is for buying fancy doo-dads٫ or large things٫ or hotel nights٫ or any number of other things that cost about as much while delivering arguably less value. On the other hand there was something appealing to me about buying an object that was so <em>platonically good</em>. It was just a really dense cube that I could derive a pure and weird form of satisfaction from holding.</p>

<p>Anyhow٫ tungsten cubes٫ 10/10 would recommend. There’s a reason they have <a href="https://www.amazon.com/Tungsten-Cube-1-5-One-Kilo/dp/B00XZBIJLS/">so many 5 star Amazon reviews</a>. Maybe some day I’ll work up the courage to buy a <a href="https://www.amazon.com/dp/B01N23DISF/">$500 one that’s over 10 pounds</a> like my housemate last term did.</p>
'),('http://thume.ca/2018/08/16/def-con-26-ctf-writeups/', 'DEF CON 26 CTF Writeups: reverse٫ doublethink٫ bew٫ reeducation', '1534377600000',  13, '
<p>Recently I flew to Vegas to attend the DEF CON 26 CTF with (<a href="https://ctftime.org/team/1937">Samurai</a>)٫ the team I <a href="/2018/05/13/winning-def-con-quals-writeups/">played with when we won the qualifiers</a>. I had a lot of fun and got very little sleep٫ working two consecutive 20 hour days and finishing off with another 4 hours of contest at the end.</p>

<p>As a programmer entering CTF with only a little bit of reverse engineering experience and no exploit development skills٫ I was happy that the organizers included new King of the Hill format challenges this year٫ which I found I could contribute nicely to since they tended to mix in more programming with the hacking. I also made sure to spend some time poking around other challenge binaries in Binary Ninja to hone my reverse engineering skills٫ although I only managed to make a meaningful contribution doing this with <code class="language-plaintext highlighter-rouge">reeducation</code>.</p>

<h1 id="reverse">reverse</h1>

<p>The first challenge released and the first I worked on was <code class="language-plaintext highlighter-rouge">reverse</code>. It was a service with a client binary and a remote server that presented a curses interface for completing disassembly and assembly puzzles like filling in the line of assembly that matched some bytes of machine code. There were multiple “level”s consisting of a bunch of puzzles٫ solving them got you points and let you move to the next level٫ and each level was a new type of puzzle.</p>

<p>While a few of us in the hotel suite got started on figuring out how we wanted to automate it٫ people on the floor started solving puzzles manually٫ then <a href="https://twitter.com/lunixbochs"><code class="language-plaintext highlighter-rouge">aegis</code></a> gradually built up a UI automation script that copied data from his terminal٫ parsed it٫ ran it through command line (dis)assembler tools and typed the answers.</p>

<p>Back in the hotel٫ a couple of us started on parsing the client output out of the VT100 but a teammate figured out the network protocol the client used so we started using that directly. The first level could actually be solved using an info leak that was present in the protocol but didn’t show up in the client٫ but this didn’t work for level 2 and up.</p>

<p>We then integrated the solvers for levels 1-4 from <code class="language-plaintext highlighter-rouge">aegis</code>’s automation into our script so <code class="language-plaintext highlighter-rouge">aegis</code> could stop having his computer taken over by UI automation every round.</p>

<p>We ran into a problem though٫ we couldn’t get through level 5 since the problems seemed nonsensical and impossible. There just wasn’t enough information in the question to choose the right answer. We realized that there must be some way to cheat to solve it.</p>

<p>Luckily someone else on our team had been reversing the client and fuzzing the network protocol and had discovered a number of helpful tricks like the ability to not spend the limited “coins” we had to attempt challenges٫ and to restart a level as much as we wanted. After <code class="language-plaintext highlighter-rouge">aegis</code> noted that he saw duplicate assembly lines in his logs and that we should try dumping٫ I started on a script. I modified our solver Python code to use the protocol tricks to quickly request level 1 problems in a pipelined way to not have to wait for round trips and dump them to a file. Then <code class="language-plaintext highlighter-rouge">aegis</code> tuned up the script and ran it on the CTF floor dumping thousands of lines of assembly per second٫ eventually converging around 280k unique lines.</p>

<p>I then started on using these dumps to write better versions of our solvers (which previously often failed to determine the correct answer) by cheating with the known lines. This allowed us to resolve the difference between say <code class="language-plaintext highlighter-rouge">call sub_1432</code> and <code class="language-plaintext highlighter-rouge">call sub_2532</code> without knowing where the procedures were and made our solving simpler and more robust. We also incorporated an underflow bug a teammate discovered from poking at the server that gave us an extra 255 points per question. Unfortunately the dump didn’t give us any clues as to how to solve level 5٫ and unfortunately the dumped binary didn’t appear to be the server like we’d hoped. At this point the challenge was close to closing so we gave up and started on other problems.</p>

<p>After the contest we learned from the organizers there was a broken protocol instruction discoverable by fuzzing that allowed you to leak the server binary. You could then find an exploit allowing you to give yourself arbitrarily many points.</p>

<h1 id="doublethink">doublethink</h1>

<p>This was another King of the Hill challenge٫ released just before the contest shut down on the first day٫ it was a fun problem that motivated me to stay up nearly all night.</p>

<p>The gist of the challenge was that you submitted a single 4KB chunk of binary that you could then execute against a number of different architectures using various emulators٫ the more architectures you got to print the flag the higher your score. So the goal was to write a polyglot piece of shellcode that opened a flag file and wrote it out on modern architectures٫ or printed it from a known memory address on older architectures.</p>

<p>We realized we needed to write flag-printing shellcode for a bunch of architectures separately and then put them together in one blob with a sequence of jump instructions at the front for each architecture jumping to that architecture’s payload٫ and where all the other architecture’s jumps before it didn’t stop the emulator or jump somewhere unintended. Another interesting twist is that a lot of the old architectures bytes/words with varying numbers of bits٫ which were just chopped off the file you gave by concatenating all the bytes in binary and chunking.</p>

<p>We decided to start by developing a bunch of payloads in parallel that we would assemble later. I started with PDP-8٫ where after reading the instruction reference I found a <a href="https://bigdanzblog.wordpress.com/2014/05/31/hello-world-program-for-pdp-8-using-pal-assembly-language/">Hello World program</a> and <a href="https://github.com/radekh/palbart">a matching assembler</a>. The first challenge was that the output format of the assembler didn’t match the format the challenge wanted٫ so I had to write a 50 line python script to parse the assembled output and put it together at the bit level (because of the 12 bit bytes). After that I checked it printed Hello World against the provided testing Docker image٫ then modified the program to print the flag٫ and made it much shorter.</p>

<p>I followed a similar process to construct a payload for PDP-10. After a bunch of architecture research and miscellaneous searching I found <a href="https://github.com/aap/tenth">an assembler as part of someone’s FORTH project</a>. I translated a Hello World program I found into that assembler’s syntax and modified the assembler code to print the info I needed٫ and again wrote a Python script to parse the output and munge the bits into the format we needed٫ then again modified the program to print the flag.</p>

<p>By this point other members of my team had written payloads for <code class="language-plaintext highlighter-rouge">clemency</code>٫ <code class="language-plaintext highlighter-rouge">mix</code>٫ <code class="language-plaintext highlighter-rouge">amd64</code> and <code class="language-plaintext highlighter-rouge">riscv</code> which we considered sufficient to start pulling them together. I started by writing a script to print a file as the bytes of varying bit widths including values in octal (which PDP system ISAs matched well with) so we could debug the jump train. Then I wrote a script to assemble jump sequences and payloads for different architectures at bit-level offsets. Then <code class="language-plaintext highlighter-rouge">aegis</code> and I worked together for a while and found a sequence of jumps٫ nops and padding that worked for <code class="language-plaintext highlighter-rouge">amd64</code>٫ <code class="language-plaintext highlighter-rouge">pdp-8</code> and <code class="language-plaintext highlighter-rouge">pdp-10</code> together. After I went to bed a teammate managed to patch in a very short <code class="language-plaintext highlighter-rouge">mix</code> shellcode into ours٫ leaving us with a 4-polyglot for the start the next day.</p>

<p>The next day I spent a bunch of hours with <code class="language-plaintext highlighter-rouge">aegis</code> trying to get a working sequence including <code class="language-plaintext highlighter-rouge">riscv</code> and failing٫ and improving tooling and commenting it so others could try integrating more jumps. We mostly failed because things had too many constraints to fit in our head so by the time we thought we were approaching a solution we forgot an earlier constraint and went down a dead end. Eventually a teammate wrote a <code class="language-plaintext highlighter-rouge">pdp-1</code> payload and that ISA had few constraints and slotted pretty easily into our existing jump train٫ getting us to a 5-polyglot. I then tried and failed to integrate <code class="language-plaintext highlighter-rouge">hexagon</code> and <code class="language-plaintext highlighter-rouge">ibm-1401</code>. By that time the challenge was close to ending and we decided to move on٫ with <code class="language-plaintext highlighter-rouge">clemency</code>٫ <code class="language-plaintext highlighter-rouge">hexagon</code>٫ <code class="language-plaintext highlighter-rouge">ibm-1401</code>٫ and <code class="language-plaintext highlighter-rouge">riscv</code> payloads unused٫ which was sad.</p>

<p>It later turned out that this challenge too was possible to exploit to get an artificially high score٫ according to the organizers and our later investigation. It was possible to use the <code class="language-plaintext highlighter-rouge">amd64</code> shellcode which was run directly (as <code class="language-plaintext highlighter-rouge">nobody</code>) concurrently from multiple submissions to fake a correct flag printing. This allowed two teams to get “fake” scores of 9 and 11٫ although PPP (the 2nd place team) did actually create an 8-polyglot.</p>

<h1 id="bew">bew</h1>

<p>Released just before the end of the second day٫ this was the next challenge I worked on. It was a web app with a text field you could submit to to add text to a file that was printed on another page.</p>

<p>While the contest servers were still up٫ we looked into the source and realized that the <code class="language-plaintext highlighter-rouge">express-validator</code> dependency had been replaced by an entirely different library using a WebAssembly module compiled with <a href="https://github.com/kripken/emscripten">Emscripten</a>. All inputs to the text file were passed through the validator library before being added to the text file.</p>

<p>After some theorizing about possible exploits involving using the Emscripten standard library emulation to use the Node <code class="language-plaintext highlighter-rouge">fs</code> module to get the flag٫ we noticed on the submissions page that people were submitting exploits involving plain JS code and it seemed to work. We were confused but <code class="language-plaintext highlighter-rouge">aegis</code> started putting together our own flag retrieval payload that could get past the pre-filters while other members of our team started scraping flags other teams had retrieved with a script.</p>

<p>Eventually we found that the way the service worked was dumber than we thought. The WebAssembly did some preliminary filtering looking for use of <code class="language-plaintext highlighter-rouge">require</code> or the <code class="language-plaintext highlighter-rouge">fs</code> module٫ then it passed the input to an external handler (below) which just took the input and <code class="language-plaintext highlighter-rouge">eval</code>‘d it in the Node server process٫ and put the input in the text file if it threw an exception. This looked initially like it was rejecting JS and accepting text because most text triggers JS errors. The basic exploits people were using just obscured the <code class="language-plaintext highlighter-rouge">require</code> and <code class="language-plaintext highlighter-rouge">fs</code> use and used that to get the flag and put it in a public place٫ which we were also scraping without even deploying our own exploit!</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// The handler that the WebAssembly called into</span>
<span class="kd">var</span> <span class="nx">ASM_CONSTS</span> <span class="o">=</span> <span class="p">[</span><span class="kd">function</span><span class="p">(</span><span class="nx">$0</span><span class="p">)</span> <span class="p">{</span> <span class="nx">str</span> <span class="o">=</span> <span class="nx">Pointer_stringify</span><span class="p">(</span><span class="nx">$0</span><span class="p">);</span> <span class="k">try</span> <span class="p">{</span> <span class="nb">eval</span><span class="p">(</span><span class="nx">str</span><span class="p">);</span> <span class="k">return</span> <span class="mi">1</span><span class="p">;}</span> <span class="k">catch</span><span class="p">(</span><span class="nx">err</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="mi">0</span><span class="p">;</span> <span class="p">}</span> <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nb">eval</span><span class="p">(</span><span class="dl">"</span><span class="s1">const fs = require("fs");fs.writeFile("/tmp/test.txt"٫ "testwrites")</span><span class="dl">"</span><span class="p">)</span> <span class="o">+</span> <span class="dl">"</span><span class="s1">WEBASS got </span><span class="dl">"</span> <span class="o">+</span> <span class="nx">$0</span><span class="p">);</span> <span class="p">}];</span>
</code></pre></div></div>

<p>After the contest servers closed for the night٫ we did some thinking about the challenge. Based on the large number of bytes you were allowed to patch only in the WebAssembly file٫ it seemed the intended patching solution was to write an actual JS validator٫ compile it to WASM and patch it in٫ with functional tests likely verifying that the web app still accepted text and rejected JS. This sounded like a lot of work٫ so we thought we’d poke around with our full remote code execution some more.</p>

<p>I realized that I could patch the server dynamically by just reassigning the <code class="language-plaintext highlighter-rouge">ASM_CONSTS</code> variable (in scope!) to not <code class="language-plaintext highlighter-rouge">eval</code> the string and either reject or accept all submissions٫ fully closing the <code class="language-plaintext highlighter-rouge">eval</code> hole. This would persist until the server was restarted٫ and based on the persistent text file we knew that the server was kept alive between requests. I eventually refined this into a version that left a back door so that we could still exploit the server if we messed up٫ and also made sure our exploits (containing <code class="language-plaintext highlighter-rouge">/</code> and <code class="language-plaintext highlighter-rouge">_</code>) couldn’t accidentally end up in the public text file:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">ASM_CONSTS</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="kd">function</span><span class="p">(</span><span class="nx">ptr</span><span class="p">)</span> <span class="p">{</span> <span class="nx">str</span> <span class="o">=</span> <span class="nx">Pointer_stringify</span><span class="p">(</span><span class="nx">ptr</span><span class="p">);</span> <span class="k">if</span><span class="p">(</span><span class="nx">str</span><span class="p">.</span><span class="nx">includes</span><span class="p">(</span><span class="dl">"</span><span class="s2">DAT_BEST_BACK_DOOR_SECRET</span><span class="dl">"</span><span class="p">))</span> <span class="nb">eval</span><span class="p">(</span><span class="nx">str</span><span class="p">);</span> <span class="k">return</span> <span class="p">(</span><span class="nx">str</span><span class="p">.</span><span class="nx">includes</span><span class="p">(</span><span class="dl">"</span><span class="s2">_</span><span class="dl">"</span><span class="p">)</span> <span class="o">||</span> <span class="nx">str</span><span class="p">.</span><span class="nx">includes</span><span class="p">(</span><span class="dl">"</span><span class="s2">/</span><span class="dl">"</span><span class="p">))</span> <span class="p">?</span> <span class="mi">1</span> <span class="p">:</span> <span class="mi">0</span><span class="p">;</span> <span class="p">}</span>
</code></pre></div></div>

<p>Meanwhile <code class="language-plaintext highlighter-rouge">aegis</code> figured out that he could modify the <code class="language-plaintext highlighter-rouge">express</code> web server handler chain to do all sorts of fun things. First he figured out how to take down all the pages٫ then how to add a backdoor flag page by mounting root as a public directory.</p>

<p>I talked this with <code class="language-plaintext highlighter-rouge">aegis</code> and we realized this was so absurdly easy and powerful that the organizers couldn’t have thought of it. We realized we could insert a backdoor that let us get the flag and then close the door to all the other teams٫ with the only weakness being if another team realized this and closed the door first. If no other teams figured this out and beat us then we would get all the flags and no other team would get any٫ we could also close our own door without inserting the backdoor.</p>

<p>We realized that if we were lucky and were the only team to figure this out٫ we needed to not leak our exploit publicly so other teams could immediately figure it out themselves. So I started by developing a thrower script for our exploits that could be run automatically and would ensure a team was backdoored and the door was closed without leaking our exploit in case of a patched team that accepted all submissions:</p>

<ol>
  <li>Check our flag backdoor٫ if it’s there we’re done.</li>
  <li>Submit a canary piece of bogus JS code that used all the syntactic constructs our exploits used٫ if it went through then submitting our exploits would leak them٫ so abandon.</li>
  <li>Install the backdoor express chain rewriting code.</li>
  <li>Check that we can retrieve the flag٫ if not bail and log an error.</li>
  <li>Close the door and check that the door was successfully closed and log if not.</li>
</ol>

<p>Next I worked on improving <code class="language-plaintext highlighter-rouge">aegis</code>’s payload to place the flag backdoor at a less obvious place than <code class="language-plaintext highlighter-rouge">/flag</code> which required some URL rewriting. This is the payload I ended up with:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Part 1: exposes the flag at /flagaaa</span>
<span class="nx">s</span> <span class="o">=</span> <span class="nx">process</span><span class="p">.</span><span class="nx">mainModule</span><span class="p">.</span><span class="nx">children</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">children</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nx">exports</span><span class="p">.</span><span class="kd">static</span><span class="p">(</span><span class="dl">"</span><span class="s1">/</span><span class="dl">"</span><span class="p">);</span>
<span class="nx">process</span><span class="p">.</span><span class="nx">mainModule</span><span class="p">.</span><span class="nx">children</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">exports</span><span class="p">.</span><span class="nx">_router</span><span class="p">.</span><span class="nx">stack</span><span class="p">[</span><span class="mi">5</span><span class="p">].</span><span class="nx">handle</span> <span class="o">=</span> <span class="kd">function</span><span class="p">(</span><span class="nx">req</span><span class="p">٫</span> <span class="nx">res</span><span class="p">٫</span> <span class="nx">next</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">if</span><span class="p">(</span><span class="nx">req</span><span class="p">.</span><span class="nx">url</span> <span class="o">&amp;&amp;</span> <span class="nx">req</span><span class="p">.</span><span class="nx">url</span><span class="p">.</span><span class="nx">includes</span><span class="p">(</span><span class="dl">"</span><span class="s1">flag</span><span class="dl">"</span><span class="p">))</span> <span class="p">{</span>
    <span class="nx">req</span><span class="p">.</span><span class="nx">url</span> <span class="o">=</span> <span class="nx">req</span><span class="p">.</span><span class="nx">url</span><span class="p">.</span><span class="nx">substring</span><span class="p">(</span><span class="mi">0</span><span class="p">٫</span> <span class="nx">req</span><span class="p">.</span><span class="nx">url</span><span class="p">.</span><span class="nx">length</span><span class="o">-</span><span class="mi">3</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="k">return</span> <span class="nx">s</span><span class="p">(</span><span class="nx">req</span><span class="p">٫</span> <span class="nx">res</span><span class="p">٫</span> <span class="nx">next</span><span class="p">);</span>
<span class="p">};</span>
</code></pre></div></div>

<p>By this point it was 4am and we were tired after our 2nd consecutive 20 hour day so we went to sleep. We woke up just before the contest opened again٫ and I got ready to throw our door closer at our own server manually since we had only automated the throwing at other teams.</p>

<p>But our worst fears came true and total victory was snatched from our grasp by a faster team! I threw the door closer at our own server shortly after opening and found that our canary went through when it shouldn’t. I checked with some other test payloads and sure enough٫ it seemed that some other team had closed our door on us٫ presumably after backdooring our server and all the others for themselves. It also turns out the exploit payload had errored in our automated thrower at minute 0 so we hadn’t slipped in to any teams first.</p>

<p>Shortly later the contest organizers realized or were informed of their oversight about persistent exploits and they put in a workaround of restarting the servers every couple minutes to give all teams a chance to slip in. After streamlining my thrower to not be cautious and be faster since clearly lots of other teams knew about the problem and were already leaking their exploits٫ we managed to regularly slip into a few teams servers each restart.</p>

<p>It wasn’t the glorious victory of monopolizing the flags that we’d dreamed of٫ but we still got some people and were really proud of our clever plan and exploits.</p>

<h1 id="reeducation">reeducation</h1>

<p>In the last two hours of the contest٫ I took a look at the new <code class="language-plaintext highlighter-rouge">reeducation</code> challenge. This was an attack/defend binary challenge that appeared to have been written in Rust.</p>

<p>My teammates had already run a Rust demangler on the symbols and had identified some interesting functions including one including <code class="language-plaintext highlighter-rouge">interpret</code> and determined that we could submit a payload to the service and it would run it through the interpreter.</p>

<p>While they worked on reverse engineering the stages leading to the interpreter I looked at the interpreter in Binary Ninja and used <code class="language-plaintext highlighter-rouge">gdb</code> to test the binary and figure out which registers contained the payload and length. I figured out that each “instruction” was two 64 bit words where if the instruction was <code class="language-plaintext highlighter-rouge">(a٫b)</code> it seemed to execute <code class="language-plaintext highlighter-rouge">mem[a] -= mem[b]</code> on the same memory array containing the code (allowing self modification).</p>

<p>I also discovered with <code class="language-plaintext highlighter-rouge">gdb</code> that the flag was placed in memory immediately after the submitted code. I also learned from <code class="language-plaintext highlighter-rouge">gdb</code> that the length register contained 1024 which was the length of the payload in bytes٫ but in Binary Ninja I saw the bounds checking code was treating that length as the length in 64 bit words. This allowed the payload to access 8 times the memory it should have been able to without triggering an out of bounds error٫ including the flag! This looked to be the intended vulnerability٫ I’m guessing caused by incorrect use of Rust’s <code class="language-plaintext highlighter-rouge">unsafe</code> <code class="language-plaintext highlighter-rouge">Vec::from_raw_parts</code> or <code class="language-plaintext highlighter-rouge">slice::from_raw_parts_mut</code> passing in the byte length instead of the <code class="language-plaintext highlighter-rouge">u64</code> length٫ an example of how if you use <code class="language-plaintext highlighter-rouge">unsafe</code> functions wrong in Rust٫ it can lead to vulnerabilities!</p>

<p>At this point I went and found some teammates in the hotel also working on the problem and shared all the knowledge I hadn’t already posted on Slack. They had figured out that the payload we submitted had to contain only bytes of below a certain value. We figured out we had all the knowledge we needed to write an exploit٫ but we only had 40 minutes of contest left٫ which was likely not enough.</p>

<p>My teammates started on an exploit script and I helped out occasionally٫ figuring out that we could use self-modifying code to access offsets that wouldn’t otherwise make it through the byte value filter. Unfortunately we didn’t have enough time to get a working exploit together.</p>

<p>However٫ while they were working on that I worked on developing a patch. In Binary Ninja I figured out that just underneath the code that initially retrieved the length there was a right shift that divided by 8 for use by some other part of the code. I used Binary Ninja’s patching functionality to fix that code to replace the <code class="language-plaintext highlighter-rouge">mov٫ shr</code> with a <code class="language-plaintext highlighter-rouge">shr٫ mov</code> sequence of the same length that shifted the main length register and then copied it into the other register. The idea was this would fix the length to be the correct length to not allow out of bounds indexing to reach the flag. I posted my 7 byte patch in the Slack channel and one of the people on the floor submitted a patched binary using their better networking 15 minutes before the end of the contest. Unfortunately٫ the scoreboard was hidden for the final day of the contest so although my patch passed the tests٫ I don’t know if it actually succeeded in getting us a few extra defense points in the final couple ticks.</p>

<h1 id="conclusion">Conclusion</h1>

<p>I had a ton of fun٫ and my team (Samurai) ended up coming 11th٫ which although it isn’t as good as our first place finish in the qualifiers٫ is pretty good considering how high level the competition at the event was. I also learned a bunch more about competing in CTFs from my awesome teammates!</p>
'),('http://thume.ca/2018/05/13/winning-def-con-quals-writeups/', 'Winning the DEF CON Quals CTF! Writeups: Easy Pisy٫ Flagsifier٫ Geckome', '1526169600000',  13, '
<p>A friend invited me to join his CTF team (<a href="https://ctftime.org/team/1937">Samurai</a>) this year for the Plaid CTF and the DEF CON qualifiers and I thought that sounded fun and wanted to learn more security and reverse engineering٫ so I did. For Plaid I just spent a couple hours tinkering with a few problems with my main accomplishment being reverse engineering a complicated APL program. For DEF CON I decided to go all out and dedicate my entire weekend to it. I had a really great time٫ and <a href="https://scoreboard.oooverflow.io/#/scoreboard">we won</a>!</p>

<p>I solved three problems mostly by myself: Easy Pisy٫ Flagsifier and Geckome. The last two were the 6th and 1st least-solved challenges in the game٫ and the less people solved a challenge the more points it was worth. This corresponds a little to how much work was required٫ but also to how many lucky/clever/random insights are required٫ and how much effort other teams decided to put in. I’d say Flagsifier was genuinely tricky but Geckome٫ the least-solved challenge٫ was mostly luck and good tactics and wasn’t much work compared to many other challenges.</p>

<p>I spent the last 4 hours of the CTF working on a solution to “adamtune”٫ and I finished a whole bunch of work that did what I intended٫ it just turned out the results weren’t very good. The way the problem worked it was impossible to tell ahead of time whether my approach would be good enough٫ so I just had to spend the time and it didn’t pan out. Now that <a href="https://github.com/o-o-overflow/chall-adamtune/blob/master/src/adamtune.py">the source</a> has been posted٫ it seems like my basic approach was correct٫ and that if I had used the Watson speech to text API instead of the Google one it may have given me the extra info I needed to make a good solution.</p>

<p>I also contributed a bit to discussion and reverse engineering on a few other problems٫ including “It’s-a me!”٫ “Tech Support” and “exzendtential-crisis”.</p>

<p>Without further ado٫ here’s my writeups for the problems that I solved:</p>

<h2 id="easy-pisy">Easy Pisy</h2>

<p>A web app gave us the ability to sign a PDF and then submit a signed PDF. There was accessible source for the PHP scripts and sample PDFS. The source and examples showed that the PDF’s could contain two possible commands: <code class="language-plaintext highlighter-rouge">ECHO</code> and <code class="language-plaintext highlighter-rouge">EXECUTE</code> (which runs a shell command). The signing script would only sign <code class="language-plaintext highlighter-rouge">ECHO</code> PDFs so you couldn’t trivially execute any command.</p>

<p>Running one of the sample PDFs through showed the commands being run included converting the PDF to a PPM file and then running <code class="language-plaintext highlighter-rouge">ocrad</code> (an OCR tool) to extract the text out of them.</p>

<p>One of the example PDFs ran <code class="language-plaintext highlighter-rouge">EXECUTE ls</code> and came with a signature٫ it showed there was a <code class="language-plaintext highlighter-rouge">flag</code> file in the working directory.</p>

<p>So the problem was how to get a signed PDF that shows the text <code class="language-plaintext highlighter-rouge">EXECUTE cat flag</code>٫ when we could only sign a PDF that had an <code class="language-plaintext highlighter-rouge">ECHO</code> command. This sounded a lot like it could involve the recent-ish PDF SHA1 collision. A quick check of the PHP docs showed that the <code class="language-plaintext highlighter-rouge">openssl_verify</code> function they used defaults to using SHA1 signatures!</p>

<p>My teammate <code class="language-plaintext highlighter-rouge">fstenv</code> found the <a href="https://alf.nu/SHA1">https://alf.nu/SHA1</a> website for generating colliding PDFs٫ and I quickly opened Pixelmator and drew up one JPEG that said <code class="language-plaintext highlighter-rouge">ECHO hi</code> in big Arial font and another that said <code class="language-plaintext highlighter-rouge">EXECUTE cat flag</code>. I ran it through the service and it spit out two PDFs with identical hashes. I then went through signing the echo one and executing the cat one and got the flag!</p>

<h2 id="its-a-me">It’s-a Me</h2>

<p>This challenge involved a binary that presented text-based menus for a pizza restaurant. A bunch of us opened up the binary in Binary Ninja and IDA and used <a href="https://github.com/lunixbochs/revsync">revsync</a> to collaborate on naming symbols.</p>

<p>We found that it looked for emojis like tomato٫ pineapple and chicken as the pizza ingredients. If you ordered the Pineapple emoji as an ingredient٫ it yelled and banned you. We found other pineapple-related code at the cooking stage٫ so we needed to figure out how to get there without getting banned. Soon <code class="language-plaintext highlighter-rouge">aegis</code> figured out the cooking stage concatted the ingredients٫ so we could split the emoji’s UTF-8 over 2 ingredients to get it through.</p>

<p>Then <code class="language-plaintext highlighter-rouge">aegis</code> found a code path that could write to a buffer before and after it being <code class="language-plaintext highlighter-rouge">free</code>‘d٫ which could be the start of a heap corruption exploit. To get to that path we needed to make it think our pineapple pizzas were all an <code class="language-plaintext highlighter-rouge">ApprovedPizza</code> instead of a <code class="language-plaintext highlighter-rouge">CriminalPizza</code>.</p>

<p>So we found some bit field logic and <code class="language-plaintext highlighter-rouge">aegis</code> figured out that you could overflow the 4 bit fields and make it think all the pizzas were approved by cooking 16 pineapple pizzas and 1 tomato pizza. That let us corrupt the heap and get a segfault. Then <code class="language-plaintext highlighter-rouge">kileak</code> developed an exploit which he wrote up <a href="https://kileak.github.io/ctf/2018/defconquals18-itsame/">here</a>.</p>

<h2 id="flagsifier">Flagsifier</h2>

<p>This one was tricky٫ it took me 4 hours of fiddling around in a <a href="https://gist.github.com/trishume/99a161c5c3653c08edfbf9e1cd6d27a5">Juypter Notebook</a>.</p>

<p>We were given a Keras convnet image classifer model٫ some sample images showing 38 MNIST-like letters spelling random words glommed together٫ and the name “Flagsifier”. This suggested that the challenge was to extract an image of the flag from the model trained to recognize the flag.</p>

<p><img src="/assets/postassets/dcquals18/flagsifier_sample.png" alt="Flagsifier Sample Inpuw" /></p>

<p>First I Googled “MNIST letters” and found the EMNIST dataset٫ which I suspected is what the samples and training data was made with. Next٫ I had two possible avenues of extraction:</p>

<ol>
  <li>Use something like Deep Dream to optimize an image for flag-ness: this would take a reasonable amount of effort to implement and might work straightforwardly٫ but ran the risk of outputting blurry or otherwise unreadable images.</li>
  <li>Use the letters in the EMNIST dataset to optimize a flag string for flag-ness character by character. This would definitely give a readable result٫ but I wasn’t sure if just hill-climbing a character at a time would reach the flag properly٫ since the final dense layer could theoretically learn not to activate basically at all until all the characters are right.</li>
</ol>

<p>I figured that the second approach had a better effort to expected reward tradeoff and started work. First I set up the data loading code for the EMNIST dataset and extracted only the capital letters (the samples were all uppercase). Then I extracted the first letter from a sample and searched the dataset for it٫ confirming that the letters were from EMNIST. Later I figured out based on the “L”s in the samples that I needed to use the <code class="language-plaintext highlighter-rouge">ByMerge</code> version rather than the <code class="language-plaintext highlighter-rouge">ByClass</code> version and switched it.</p>

<p>Next I wrote a function that took a 38-character string and generated an image with random instances of each letter so that I could run things through the network. I needed to figure out which of the 40 class outputs was flag-ness٫ without having the flag.</p>

<p>The examples I had run through so far had all output <code class="language-plaintext highlighter-rouge">1.0</code> for one class and <code class="language-plaintext highlighter-rouge">0.0</code> for others٫ I figured first I needed more resolution to pick up on hints of flag-ness. To get this I needed to remove the final softmax layer. Unfortunately Keras compiled the model using settings only available inside the load command٫ so it wasn’t easy to modify it after loading. I took the easy/clever/hacky/fastest way out and opened the model in a hex editor٫ found the JSON model description inside and changed <code class="language-plaintext highlighter-rouge">"softmax"٫</code> to <code class="language-plaintext highlighter-rouge">"linear" ٫</code> with the space to maintain the length. This gave me a much higher resolution signal to look at and optimize.</p>

<p>I knew that all flags started with <code class="language-plaintext highlighter-rouge">OOO</code> so I composed an image with <code class="language-plaintext highlighter-rouge">OOO</code> and then blank space٫ and saw that channel 2 (zero-indexed) had the highest activation.</p>

<p>I started by looping through each character for each position starting from the beginning and filling it with the character that had the highest activation٫ using my same generator that picked random instances. This gave garbage results٫ so I made it average the activations of 20 samples for each character and it correctly picked up the <code class="language-plaintext highlighter-rouge">OOO</code> and then a bunch of random-seeming characters.</p>

<p>I rewrote my generator and optimizer to pick 30 random versions of each letter for each position and choose the best letter instance for each slot. Then I rewrote it again so it could start from a given string instead of an empty blank canvas. Then I re-ran the optimizer again starting with my last result and it tuned in each character with context.</p>

<p>This gave me <code class="language-plaintext highlighter-rouge">OOOSOMGAUTHKNTICIWTTILIGCWCCISRTQUIVCT</code>. That looked like the first part might be <code class="language-plaintext highlighter-rouge">OOOSOMEAUTHENTIC</code>٫ it was getting somewhere! So I posted it to the Samurai Slack channel. I was somewhat tapped out of ideas and my teammate wanted to try Deep Dream٫ so I tried a bit harder to get the best guess of a starting point for Deep Dream to optimize. I noted that the <code class="language-plaintext highlighter-rouge">ByMerge</code> dataset meant <code class="language-plaintext highlighter-rouge">L</code> and <code class="language-plaintext highlighter-rouge">I</code> were nearly indistinguishable٫ and given that and the context of an AI challenge it probably continued <code class="language-plaintext highlighter-rouge">OOOSOMEAUTHENTICINTELLIGENCEIS</code>. I couldn’t decipher the last bit though so I prepared to wait for the deep dream results.</p>

<p>Then I got a Slack ping that the challenge had been solved٫ my teammate <code class="language-plaintext highlighter-rouge">shane</code> figured out that the last bit <code class="language-plaintext highlighter-rouge">RTQUIVCT</code> must be <code class="language-plaintext highlighter-rouge">REQUIRED</code>! We had managed to turn the garbled mess into the full flag.</p>

<h2 id="geckome">Geckome</h2>

<p>In this challenge there was a page with Javascript that collected a bunch of info from the browser٫ put it all in a string٫ hashed it٫ and if it had the correct hash٫ passed it off to a PHP file that would give you the flag given the string.</p>

<p>We started by looking at the various Javascript٫ CSS and HTML features used on the page and tabulating which versions of which browsers could possibly have that combination of features٫ and came up with this table:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Thing           Firefox Chrome  Opera   Safari
onbeforeprint   &lt;6      &lt;63     &lt;50     any
DataView        &gt;=15    &gt;=9     &gt;=12.1  &gt;=5.1
webkit anim     X       &gt;=4     &gt;=15    &gt;=4
SubtleCrypto    &gt;=34    &gt;=37    &gt;=24    &gt;=11
link prerender  X       &gt;=13    &gt;=15    X
video tag       &gt;=20    &gt;=4     &gt;=11.5  &gt;=4
ping attr       X       &gt;=15    &gt;=15    &gt;=6

The version expressions for onbeforeprint are
the browsers that don"t support it٫ as suggested.
</code></pre></div></div>

<p>This didn’t do much except rule out Firefox and Safari. We could also probably rule out Opera because it’s rare٫ and the challenge was named “Geckome” which had “ome” from Chrome٫ but nothing from Opera. But there were still too many Chrome versions.</p>

<p>I modified the script to put all the important values to hash on the screen so that we could easily look at the results in different browsers:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;pre</span> <span class="na">id=</span><span class="s">"log"</span><span class="nt">&gt;&lt;/pre&gt;</span>
<span class="nt">&lt;script&gt;</span>
    <span class="kd">var</span> <span class="nx">logText</span> <span class="o">=</span> <span class="dl">""</span><span class="p">;</span>
    <span class="kd">function</span> <span class="nx">logme</span><span class="p">(</span><span class="nx">thing</span><span class="p">٫</span><span class="nx">s</span><span class="p">)</span> <span class="p">{</span> <span class="nx">logText</span> <span class="o">+=</span> <span class="nx">thing</span><span class="p">;</span> <span class="nx">logText</span> <span class="o">+=</span> <span class="dl">"</span><span class="s2">: </span><span class="dl">"</span><span class="p">;</span> <span class="nx">logText</span> <span class="o">+=</span> <span class="nb">String</span><span class="p">(</span><span class="nx">s</span><span class="p">);</span> <span class="nx">logText</span> <span class="o">+=</span> <span class="dl">"</span><span class="s2">;</span><span class="se">\n</span><span class="dl">"</span><span class="p">;}</span>

    <span class="kd">var</span> <span class="nx">f</span> <span class="o">=</span> <span class="dl">""</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">navigator</span><span class="p">.</span><span class="nx">onLine</span><span class="p">)</span>
        <span class="nx">f</span> <span class="o">+=</span> <span class="dl">"</span><span class="s2">o</span><span class="dl">"</span><span class="p">;</span>
    <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">online</span><span class="dl">"</span><span class="p">٫</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">onLine</span><span class="p">);</span>
    <span class="nx">f</span> <span class="o">+=</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">vendor</span><span class="p">;</span>
    <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">vendor</span><span class="dl">"</span><span class="p">٫</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">vendor</span><span class="p">);</span>
    <span class="kd">function</span> <span class="nx">p</span><span class="p">()</span> <span class="p">{</span>
        <span class="nb">window</span><span class="p">.</span><span class="nx">print</span><span class="p">();</span>
    <span class="p">}</span>

    <span class="nx">f</span> <span class="o">+=</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">mimeTypes</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span>
    <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">mimes</span><span class="dl">"</span><span class="p">٫</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">mimeTypes</span><span class="p">.</span><span class="nx">length</span><span class="p">);</span>
    <span class="nx">x</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="k">for</span> <span class="p">(</span> <span class="nx">i</span> <span class="k">in</span> <span class="nb">navigator</span> <span class="p">)</span> <span class="p">{</span> <span class="nx">x</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span> <span class="p">}</span> <span class="nx">f</span> <span class="o">+=</span> <span class="nx">x</span><span class="p">;</span>
    <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">navlen</span><span class="dl">"</span><span class="p">٫</span> <span class="nx">x</span><span class="p">);</span>
    <span class="nx">x</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="k">for</span> <span class="p">(</span> <span class="nx">i</span> <span class="k">in</span> <span class="nb">window</span> <span class="p">)</span> <span class="p">{</span> <span class="nx">x</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span> <span class="p">}</span> <span class="nx">f</span> <span class="o">+=</span> <span class="nx">x</span><span class="p">;</span>
    <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">winlen</span><span class="dl">"</span><span class="p">٫</span> <span class="nx">x</span><span class="p">);</span>
    <span class="c1">// hash</span>
    <span class="kd">function</span> <span class="nx">str2ab</span><span class="p">(</span><span class="nx">str</span><span class="p">)</span> <span class="p">{</span>
        <span class="kd">var</span> <span class="nx">buf</span> <span class="o">=</span> <span class="k">new</span> <span class="nb">ArrayBuffer</span><span class="p">(</span><span class="nx">str</span><span class="p">.</span><span class="nx">length</span><span class="o">*</span><span class="mi">2</span><span class="p">);</span> <span class="c1">// 2 bytes for each char</span>
        <span class="kd">var</span> <span class="nx">bufView</span> <span class="o">=</span> <span class="k">new</span> <span class="nb">Uint16Array</span><span class="p">(</span><span class="nx">buf</span><span class="p">);</span>
        <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span><span class="o">=</span><span class="mi">0</span><span class="p">٫</span> <span class="nx">strLen</span><span class="o">=</span><span class="nx">str</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span> <span class="nx">i</span><span class="o">&lt;</span><span class="nx">strLen</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
            <span class="nx">bufView</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span> <span class="o">=</span> <span class="nx">str</span><span class="p">.</span><span class="nx">charCodeAt</span><span class="p">(</span><span class="nx">i</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="nx">buf</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="kd">function</span> <span class="nx">sha256</span><span class="p">(</span><span class="nx">str</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// We transform the string into an arraybuffer.</span>
        <span class="kd">var</span> <span class="nx">buffer</span> <span class="o">=</span> <span class="nx">str2ab</span><span class="p">(</span><span class="nx">str</span><span class="p">);</span>
        <span class="k">return</span> <span class="nx">crypto</span><span class="p">.</span><span class="nx">subtle</span><span class="p">.</span><span class="nx">digest</span><span class="p">({</span><span class="na">name</span><span class="p">:</span><span class="dl">"</span><span class="s2">SHA-256</span><span class="dl">"</span><span class="p">}٫</span> <span class="nx">buffer</span><span class="p">).</span><span class="nx">then</span><span class="p">(</span><span class="kd">function</span> <span class="p">(</span><span class="nx">hash</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">return</span> <span class="nx">hex</span><span class="p">(</span><span class="nx">hash</span><span class="p">);</span>
        <span class="p">});</span>
    <span class="p">}</span>

    <span class="kd">function</span> <span class="nx">hex</span><span class="p">(</span><span class="nx">buffer</span><span class="p">)</span> <span class="p">{</span>
        <span class="kd">var</span> <span class="nx">hexCodes</span> <span class="o">=</span> <span class="p">[];</span>
        <span class="kd">var</span> <span class="nx">view</span> <span class="o">=</span> <span class="k">new</span> <span class="nb">DataView</span><span class="p">(</span><span class="nx">buffer</span><span class="p">);</span>
        <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">view</span><span class="p">.</span><span class="nx">byteLength</span><span class="p">;</span> <span class="nx">i</span> <span class="o">+=</span> <span class="mi">4</span><span class="p">)</span> <span class="p">{</span>
            <span class="c1">// Using getUint32 reduces the number of iterations needed (we process 4 bytes each time)</span>
            <span class="kd">var</span> <span class="nx">value</span> <span class="o">=</span> <span class="nx">view</span><span class="p">.</span><span class="nx">getUint32</span><span class="p">(</span><span class="nx">i</span><span class="p">)</span>
            <span class="c1">// toString(16) will give the hex representation of the number without padding</span>
            <span class="kd">var</span> <span class="nx">stringValue</span> <span class="o">=</span> <span class="nx">value</span><span class="p">.</span><span class="nx">toString</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
            <span class="c1">// We use concatenation and slice for padding</span>
            <span class="kd">var</span> <span class="nx">padding</span> <span class="o">=</span> <span class="dl">"</span><span class="s1">00000000</span><span class="dl">"</span>
            <span class="kd">var</span> <span class="nx">paddedValue</span> <span class="o">=</span> <span class="p">(</span><span class="nx">padding</span> <span class="o">+</span> <span class="nx">stringValue</span><span class="p">).</span><span class="nx">slice</span><span class="p">(</span><span class="o">-</span><span class="nx">padding</span><span class="p">.</span><span class="nx">length</span><span class="p">)</span>
            <span class="nx">hexCodes</span><span class="p">.</span><span class="nx">push</span><span class="p">(</span><span class="nx">paddedValue</span><span class="p">);</span>
        <span class="p">}</span>

        <span class="c1">// Join all the hex strings into one</span>
        <span class="k">return</span> <span class="nx">hexCodes</span><span class="p">.</span><span class="nx">join</span><span class="p">(</span><span class="dl">""</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">if</span><span class="p">(</span><span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">.</span><span class="nx">length</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">plugin0name</span><span class="dl">"</span><span class="p">٫</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">filename</span><span class="p">);</span>
        <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">plugin0desc</span><span class="dl">"</span><span class="p">٫</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">description</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">if</span><span class="p">(</span><span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">.</span><span class="nx">length</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">plugin1name</span><span class="dl">"</span><span class="p">٫</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nx">filename</span><span class="p">);</span>
        <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">plugin1desc</span><span class="dl">"</span><span class="p">٫</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nx">description</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="nx">f</span> <span class="o">+=</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">filename</span><span class="p">;</span>
    <span class="nx">f</span> <span class="o">+=</span> <span class="nb">navigator</span><span class="p">.</span><span class="nx">plugins</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nx">description</span><span class="p">;</span>

    <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">f</span><span class="dl">"</span><span class="p">٫</span> <span class="nx">f</span><span class="p">);</span>

    <span class="nx">sha256</span><span class="p">(</span><span class="nx">f</span><span class="p">).</span><span class="nx">then</span><span class="p">(</span><span class="kd">function</span><span class="p">(</span><span class="nx">digest</span><span class="p">)</span> <span class="p">{</span>
        <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">digest</span><span class="dl">"</span><span class="p">٫</span> <span class="nx">digest</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="nx">digest</span> <span class="o">==</span> <span class="dl">"</span><span class="s2">31c6b7c46ff55afc8c5e64f42cc9b48dde6a04b5ca434038cd2af8bd3fd1483a</span><span class="dl">"</span><span class="p">)</span> <span class="p">{</span>
            <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">flag</span><span class="dl">"</span><span class="p">٫</span> <span class="dl">"</span><span class="s2">gotit!</span><span class="dl">"</span><span class="p">);</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
            <span class="nx">logme</span><span class="p">(</span><span class="dl">"</span><span class="s2">flag</span><span class="dl">"</span><span class="p">٫</span> <span class="dl">"</span><span class="s2">fail!</span><span class="dl">"</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="nb">document</span><span class="p">.</span><span class="nx">getElementById</span><span class="p">(</span><span class="dl">"</span><span class="s1">log</span><span class="dl">"</span><span class="p">).</span><span class="nx">innerHTML</span> <span class="o">=</span> <span class="nx">logText</span><span class="p">;</span>
    <span class="p">});</span>
<span class="nt">&lt;/script&gt;</span>
</code></pre></div></div>

<p>I then hosted a version of this and used <a href="http://browsershots.org/">BrowserShots</a> to take screenshots of it in many versions. Most crashed for lack of various APIs/values and none were correct.</p>

<p>My next idea was to brute force the hash by trying all the reasonable combinations of numbers and plugin strings.</p>

<p>I spent an hour writing a Rust program to brute force it that computed the strings and digests in the same way٫ including UTF-16 conversion and converting to hex. Then I checked that it could find the values for my browser’s digest. I entered a lot of possible plugin values and reasonable ranges for numbers based on the browser screenshots٫ but couldn’t find the correct one despite searching millions of combinations.</p>

<p><strong>So٫ I gave up.</strong> Then later got a Slack ping that my teammate <code class="language-plaintext highlighter-rouge">nopple</code> had solved it. He had taken my Rust program and added some extra plugin strings I had missed from the browser screenshots (<code class="language-plaintext highlighter-rouge">libpepflashplayer.so</code> turned out to be the key).</p>

<div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">extern</span> <span class="n">crate</span> <span class="n">byteorder</span><span class="p">;</span>
<span class="k">extern</span> <span class="n">crate</span> <span class="n">sha2</span><span class="p">;</span>

<span class="k">use</span> <span class="nn">sha2</span><span class="p">::{</span><span class="n">Sha256</span><span class="p">٫</span> <span class="n">Digest</span><span class="p">};</span>
<span class="k">use</span> <span class="nn">byteorder</span><span class="p">::{</span><span class="n">LittleEndian</span><span class="p">٫</span> <span class="n">WriteBytesExt</span><span class="p">};</span>
<span class="k">use</span> <span class="nn">std</span><span class="p">::</span><span class="nn">fmt</span><span class="p">::</span><span class="n">Write</span><span class="p">;</span>

<span class="k">fn</span> <span class="nf">to_utf16</span><span class="p">(</span><span class="n">s</span><span class="p">:</span> <span class="o">&amp;</span><span class="nb">str</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">out</span> <span class="o">=</span> <span class="nn">Vec</span><span class="p">::</span><span class="nf">with_capacity</span><span class="p">(</span><span class="n">s</span><span class="nf">.len</span><span class="p">()</span><span class="o">*</span><span class="mi">2</span><span class="p">);</span>
    <span class="k">for</span> <span class="n">point</span> <span class="n">in</span> <span class="n">s</span><span class="nf">.encode_utf16</span><span class="p">()</span> <span class="p">{</span>
        <span class="n">out</span><span class="py">.write_u16</span><span class="p">::</span><span class="o">&lt;</span><span class="n">LittleEndian</span><span class="o">&gt;</span><span class="p">(</span><span class="n">point</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="n">out</span>
<span class="p">}</span>

<span class="k">fn</span> <span class="nf">to_hex</span><span class="p">(</span><span class="n">bytes</span><span class="p">:</span> <span class="o">&amp;</span><span class="p">[</span><span class="nb">u8</span><span class="p">])</span> <span class="k">-&gt;</span> <span class="nb">String</span> <span class="p">{</span>
    <span class="nd">assert_eq!</span><span class="p">(</span><span class="n">bytes</span><span class="nf">.len</span><span class="p">()٫</span> <span class="mi">32</span><span class="p">);</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">s</span> <span class="o">=</span> <span class="nn">String</span><span class="p">::</span><span class="nf">with_capacity</span><span class="p">(</span><span class="mi">64</span><span class="p">);</span>
    <span class="k">for</span> <span class="n">byte</span> <span class="n">in</span> <span class="n">bytes</span> <span class="p">{</span>
        <span class="nd">write!</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">s</span><span class="p">٫</span> <span class="s">"{:02x}"</span><span class="p">٫</span> <span class="n">byte</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="n">s</span>
<span class="p">}</span>

<span class="k">fn</span> <span class="nf">hash</span><span class="p">(</span><span class="n">bytes</span><span class="p">:</span> <span class="o">&amp;</span><span class="p">[</span><span class="nb">u8</span><span class="p">])</span> <span class="k">-&gt;</span> <span class="nb">String</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">hasher</span> <span class="o">=</span> <span class="nn">Sha256</span><span class="p">::</span><span class="nf">default</span><span class="p">();</span>
    <span class="n">hasher</span><span class="nf">.input</span><span class="p">(</span><span class="n">bytes</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">output</span> <span class="o">=</span> <span class="n">hasher</span><span class="nf">.result</span><span class="p">();</span>
    <span class="nf">to_hex</span><span class="p">(</span><span class="n">output</span><span class="nf">.as_slice</span><span class="p">())</span>
<span class="p">}</span>

<span class="nd">#[derive(Debug)]</span>
<span class="k">struct</span> <span class="n">Browser</span> <span class="p">{</span>
    <span class="n">online</span><span class="p">:</span> <span class="nb">bool</span><span class="p">٫</span>
    <span class="n">vendor</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">"static</span> <span class="nb">str</span><span class="p">٫</span>
    <span class="n">mimes</span><span class="p">:</span> <span class="nb">u16</span><span class="p">٫</span>
    <span class="n">navs</span><span class="p">:</span> <span class="nb">u16</span><span class="p">٫</span>
    <span class="n">wins</span><span class="p">:</span> <span class="nb">u16</span><span class="p">٫</span>
    <span class="n">plug_name</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">"static</span> <span class="nb">str</span><span class="p">٫</span>
    <span class="n">plug_desc</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">"static</span> <span class="nb">str</span><span class="p">٫</span>
<span class="p">}</span>

<span class="k">fn</span> <span class="nf">construct_f</span><span class="p">(</span><span class="n">b</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">Browser</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">String</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">s</span> <span class="o">=</span> <span class="nn">String</span><span class="p">::</span><span class="nf">with_capacity</span><span class="p">(</span><span class="mi">64</span><span class="p">);</span>
    <span class="k">if</span> <span class="n">b</span><span class="py">.online</span> <span class="p">{</span> <span class="n">s</span><span class="nf">.push</span><span class="p">(</span><span class="sc">"o"</span><span class="p">);</span> <span class="p">}</span>
    <span class="n">s</span><span class="nf">.push_str</span><span class="p">(</span><span class="n">b</span><span class="py">.vendor</span><span class="p">);</span>
    <span class="nd">write!</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">s</span><span class="p">٫</span> <span class="s">"{}"</span><span class="p">٫</span> <span class="n">b</span><span class="py">.mimes</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
    <span class="nd">write!</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">s</span><span class="p">٫</span> <span class="s">"{}"</span><span class="p">٫</span> <span class="n">b</span><span class="py">.navs</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
    <span class="nd">write!</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">s</span><span class="p">٫</span> <span class="s">"{}"</span><span class="p">٫</span> <span class="n">b</span><span class="py">.wins</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>
    <span class="n">s</span><span class="nf">.push_str</span><span class="p">(</span><span class="n">b</span><span class="py">.plug_name</span><span class="p">);</span>
    <span class="n">s</span><span class="nf">.push_str</span><span class="p">(</span><span class="n">b</span><span class="py">.plug_desc</span><span class="p">);</span>
    <span class="n">s</span>
<span class="p">}</span>

<span class="c">// Test target that"s my browser</span>
<span class="c">// const TARGET: &amp;"static str = "31504a9568837f94e9f0afe8387cf945fb4929b81e53caf16bdf65c417e294e0";</span>
<span class="c">// Real target</span>
<span class="k">const</span> <span class="n">TARGET</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">"static</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">"31c6b7c46ff55afc8c5e64f42cc9b48dde6a04b5ca434038cd2af8bd3fd1483a"</span><span class="p">;</span>

<span class="k">fn</span> <span class="nf">test</span><span class="p">(</span><span class="n">f</span><span class="p">:</span> <span class="o">&amp;</span><span class="nb">str</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">bool</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">utf16</span> <span class="o">=</span> <span class="nf">to_utf16</span><span class="p">(</span><span class="n">f</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">hex_hash</span> <span class="o">=</span> <span class="nf">hash</span><span class="p">(</span><span class="o">&amp;</span><span class="n">utf16</span><span class="p">[</span><span class="o">..</span><span class="p">]);</span>
    <span class="nd">assert_eq!</span><span class="p">(</span><span class="n">hex_hash</span><span class="nf">.len</span><span class="p">()٫</span> <span class="mi">64</span><span class="p">);</span>
    <span class="n">hex_hash</span> <span class="o">==</span> <span class="n">TARGET</span>
<span class="p">}</span>

<span class="k">struct</span> <span class="n">ForceConfig</span> <span class="p">{</span>
    <span class="n">navs_start</span><span class="p">:</span> <span class="nb">u16</span><span class="p">٫</span>
    <span class="n">navs_end</span><span class="p">:</span> <span class="nb">u16</span><span class="p">٫</span>
    <span class="n">wins_start</span><span class="p">:</span> <span class="nb">u16</span><span class="p">٫</span>
    <span class="n">wins_end</span><span class="p">:</span> <span class="nb">u16</span><span class="p">٫</span>
<span class="p">}</span>

<span class="k">const</span> <span class="n">PLUGNAMES</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">"static</span> <span class="p">[</span><span class="o">&amp;</span><span class="nv">"static</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="o">&amp;</span><span class="p">[</span>
    <span class="s">"internal-remoting-viewer"</span><span class="p">٫</span>
    <span class="s">"internal-pdf-viewer"</span><span class="p">٫</span>
    <span class="s">"widevinecdmadapter.plugin"</span><span class="p">٫</span>
    <span class="s">"PepperFlashPlayer.plugin"</span><span class="p">٫</span>
    <span class="s">"internal-nacl-plugin"</span><span class="p">٫</span>
    <span class="s">"libpdf.so"</span><span class="p">٫</span>
    <span class="s">"pepflashplayer.dll"</span><span class="p">٫</span>
    <span class="s">"Flash Player.plugin"</span><span class="p">٫</span>
    <span class="s">"WebEx64.plugin"</span><span class="p">٫</span>
    <span class="s">"CitrixOnlineWebDeploymentPlugin.plugin"</span><span class="p">٫</span>
    <span class="s">"googletalkbrowserplugin.plugin"</span><span class="p">٫</span>
    <span class="s">"AdobePDFViewerNPAPI.plugin"</span><span class="p">٫</span>
    <span class="s">"libpepflashplayer.so"</span><span class="p">٫</span>
<span class="p">];</span>

<span class="k">const</span> <span class="n">PLUGDESCS</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">"static</span> <span class="p">[</span><span class="o">&amp;</span><span class="nv">"static</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="o">&amp;</span><span class="p">[</span>
    <span class="s">""</span><span class="p">٫</span>
    <span class="s">"This plugin allows you to securely access other computers that have been shared with you. To use this plugin you must first install the &lt;a href=</span><span class="se">\"</span><span class="s">https://chrome.google.com/remotedesktop</span><span class="se">\"</span><span class="s">&gt;Chrome Remote Desktop&lt;/a&gt; webapp."</span><span class="p">٫</span>
    <span class="s">"Portable Document Format"</span><span class="p">٫</span>
    <span class="s">"Enables Widevine licenses for playback of HTML audio/video content. (version: 1.4.9.1070)"</span><span class="p">٫</span>
    <span class="s">"Plugin that detects installed Citrix Online products (visit www.citrixonline.com)."</span><span class="p">٫</span>
    <span class="s">"Shockwave Flash 9.0 r0"</span><span class="p">٫</span>
    <span class="c">// SNIPPED: versions 10 through 28. These didn"t end up being necessary.</span>
    <span class="s">"Shockwave Flash 29.0 r0"</span><span class="p">٫</span>
<span class="p">];</span>

<span class="k">fn</span> <span class="nf">force</span><span class="p">(</span><span class="n">c</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">ForceConfig</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">num_navs</span> <span class="o">=</span> <span class="p">(</span><span class="n">c</span><span class="py">.navs_end</span><span class="o">-</span><span class="n">c</span><span class="py">.navs_start</span><span class="p">)</span> <span class="k">as</span> <span class="nb">usize</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">num_wins</span> <span class="o">=</span> <span class="p">(</span><span class="n">c</span><span class="py">.wins_end</span><span class="o">-</span><span class="n">c</span><span class="py">.wins_start</span><span class="p">)</span> <span class="k">as</span> <span class="nb">usize</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">max_mime</span><span class="p">:</span> <span class="nb">u16</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span>

    <span class="k">let</span> <span class="n">total</span> <span class="o">=</span> <span class="n">num_navs</span><span class="o">*</span><span class="n">num_wins</span><span class="o">*</span><span class="p">(</span><span class="n">max_mime</span> <span class="k">as</span> <span class="nb">usize</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">PLUGNAMES</span><span class="nf">.len</span><span class="p">()</span><span class="o">*</span><span class="n">PLUGDESCS</span><span class="nf">.len</span><span class="p">();</span>
    <span class="nd">println!</span><span class="p">(</span><span class="s">"Brute forcing {} combinations"</span><span class="p">٫</span> <span class="n">total</span><span class="p">);</span>

    <span class="k">let</span> <span class="n">one_segment</span> <span class="o">=</span> <span class="n">total</span> <span class="o">/</span> <span class="mi">100</span><span class="p">;</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">tick</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

    <span class="k">for</span> <span class="n">navs</span> <span class="n">in</span> <span class="n">c</span><span class="py">.navs_start</span><span class="o">..</span><span class="n">c</span><span class="py">.navs_end</span> <span class="p">{</span>
        <span class="k">for</span> <span class="n">wins</span> <span class="n">in</span> <span class="n">c</span><span class="py">.wins_start</span><span class="o">..</span><span class="n">c</span><span class="py">.wins_end</span> <span class="p">{</span>
            <span class="k">for</span> <span class="n">mimes</span> <span class="n">in</span> <span class="mi">1</span><span class="o">..</span><span class="n">max_mime</span> <span class="p">{</span>
                <span class="k">for</span> <span class="n">plug_name</span> <span class="n">in</span> <span class="n">PLUGNAMES</span> <span class="p">{</span>
                    <span class="k">for</span> <span class="n">plug_desc</span> <span class="n">in</span> <span class="n">PLUGDESCS</span> <span class="p">{</span>
                        <span class="k">let</span> <span class="n">b</span> <span class="o">=</span> <span class="n">Browser</span> <span class="p">{</span>
                            <span class="n">online</span><span class="p">:</span> <span class="k">true</span><span class="p">٫</span>
                            <span class="c">// vendor: ""٫</span>
                            <span class="n">vendor</span><span class="p">:</span> <span class="s">"Google Inc."</span><span class="p">٫</span>
                            <span class="c">// vendor: "Opera Software ASA"٫</span>
                            <span class="n">mimes</span><span class="p">٫</span> <span class="n">navs</span><span class="p">٫</span> <span class="n">wins</span><span class="p">٫</span> <span class="n">plug_name</span><span class="p">٫</span> <span class="n">plug_desc</span><span class="p">٫</span>
                        <span class="p">};</span>
                        <span class="k">let</span> <span class="n">f</span> <span class="o">=</span> <span class="nf">construct_f</span><span class="p">(</span><span class="o">&amp;</span><span class="n">b</span><span class="p">);</span>
                        <span class="k">let</span> <span class="n">good</span> <span class="o">=</span> <span class="nf">test</span><span class="p">(</span><span class="o">&amp;</span><span class="n">f</span><span class="p">);</span>
                        <span class="k">assert</span><span class="o">!</span><span class="p">(</span><span class="o">!</span><span class="n">good</span><span class="p">٫</span> <span class="s">"{:?}"</span><span class="p">٫</span> <span class="n">b</span><span class="p">);</span>

                        <span class="n">tick</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
                        <span class="k">if</span> <span class="n">tick</span> <span class="o">%</span> <span class="n">one_segment</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
                            <span class="nd">println!</span><span class="p">(</span><span class="s">"Done {}/{}"</span><span class="p">٫</span> <span class="n">tick</span><span class="p">٫</span> <span class="n">total</span><span class="p">);</span>
                        <span class="p">}</span>
                    <span class="p">}</span>
                <span class="p">}</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">conf</span> <span class="o">=</span> <span class="n">ForceConfig</span> <span class="p">{</span>
        <span class="n">navs_start</span><span class="p">:</span> <span class="mi">8</span><span class="p">٫</span>
        <span class="n">navs_end</span><span class="p">:</span> <span class="mi">58</span><span class="p">٫</span>
        <span class="n">wins_start</span><span class="p">:</span> <span class="mi">80</span><span class="p">٫</span>
        <span class="n">wins_end</span><span class="p">:</span> <span class="mi">270</span><span class="p">٫</span>
    <span class="p">};</span>
    <span class="nf">force</span><span class="p">(</span><span class="o">&amp;</span><span class="n">conf</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="adamtune">AdamTune</h2>

<p>This challenge involved passing a “voice print” test where you submitted an MP3 file that was allegedly <a href="https://adamdoupe.com/">Adam Doupé</a> reading a sentence.</p>

<p>My teammates spent some time playing with training a text to speech model on a small hand-labeled dataset but that didn’t produce good enough results and at 4 hours till the end of the contest we agreed there’s no way it could work in time.</p>

<p>By recording challenges from the demo server٫ I discovered that a vocabulary of about 209 words completely covered most challenges. So we decided to try a concatenative approach. My teammates downloaded the audio for a bunch of Adam’s talks and gave me cut up mono wav files. I fed these through the Google Speech To Text API and got word level timing information. I wrote a script that cut out wav files of individual words in the vocabulary from the transcript٫ a script that picked out the best instances of these words based on length and volume٫ and a script that strung together the best instances into sentences.</p>

<p>However٫ the results sounded really bad. A lot of the words were said quickly or muttered or included bits of other words٫ the results ended up being really difficult to understand.</p>

<p>I submitted it anyway and it actually passed the check that it said the right words٫ but failed the classifier that it was Adam. This was the opposite of what I expected٫ since it was Adam but didn’t sound like it was saying the sentence cleanly.</p>

<p>Looking at the source after the contest٫ it seems the approach used in it is very similar except with the Watson speech API٫ which gives word-level confidences Google doesn’t٫ allowing better filtering٫ and also might give better timestamps for less choppy cutouts.</p>

<p>My other guess for why we failed the classifier is that we used clips from Adam’s livestreams doing pwnables instead of from his CS lectures٫ these sound very different because of different microphones and styles of speaking. We chose the pwnables because the audio was higher quality٫ but if the classifier used only lectures then that could easily explain why we failed the classifier.</p>

'),('http://thume.ca/2017/12/29/fixing-my-keyboards-latency/', 'Fixing My Keyboard"s Latency', '1514505600000',  13, '
<p>While discussing <a href="https://danluu.com/keyboard-latency/">Dan Luu’s keyboard latency experiments</a> I realized that I had never tested my keyboard’s latency. I use <a href="http://thume.ca/2014/09/08/creating-a-keyboard-1-hardware/">a custom keyboard I designed and built</a>٫ but when I wrote the firmware I was focused on getting it working and didn’t pay any attention to latency. When I took a look at the source code and immediately saw a 10ms delay that was there for no other reason than paranoia٫ I knew I was in for some fun.</p>

<p>After a bunch of measuring٫ finding and squashing sources of latency٫ I managed to improve the latency of the main loop from 30 <em>milliseconds</em> to 700 <em>microseconds</em>. I then added a feature that changed the colour of the keyboard’s RGB LEDs on every key press so that I could use the <a href="http://isitsnappy.com/">Is It Snappy</a> app with my iPhone’s high speed camera mode to do some latency testing.</p>

<p>The first thing I found was that with my improved firmware the end to end latency of typing a character in Sublime Text and XCode 9 near the top of my Macbook display is around 42ms<sup id="fnref:fps" role="doc-noteref"><a href="#fn:fps" class="footnote">1</a></sup>. This is pretty good٫ but the astonishing thing is that it means that before I fixed the firmware <strong>my keyboard used to account for almost <em>half</em> of my end-to-end typing latency</strong>. This is measuring from the LED colour change so it doesn’t count the around 15ms<sup id="fnref:fps:1" role="doc-noteref"><a href="#fn:fps" class="footnote">1</a></sup> according to my testing from starting to press one of my keys the switch activating.</p>

<center>
  <video width="360" height="640" muted="" loop="" autoplay="">
    <source src="/assets/postassets/keyboardlatency/latency.mov" type="video/mp4" />
  </video>
</center>

<p>I also tested my Macbook keyboard٫ as well as a few older low speed USB Apple keyboards٫ and found that they had around 67ms<sup id="fnref:fps:2" role="doc-noteref"><a href="#fn:fps" class="footnote">1</a></sup> of end-to-end latency٫ measuring from when the switch was fully depressed while hitting the key as fast as I could. I suspect part of the reason for this is that these keyboards only poll at 8ms and 10ms intervals according to USB Prober (an old Apple dev tool)٫ whereas the <a href="https://www.pjrc.com/store/teensy32.html">Teensy</a> in my custom keyboard polls every millisecond. According to Dan’s post newer Apple external keyboards also poll at 1000hz.</p>

<p>Note that the 700us main loop doesn’t translate into 700us switch-to-USB latency٫ since the USB transfer is done asynchronously via DMA by the <a href="https://www.pjrc.com/store/teensy32.html">Teensy</a>’s USB controller when it is polled٫ which happens at 1000hz.</p>

<p>It’s interesting that I used my keyboard for 3 years without noticing that it added 30ms of latency. I have a few guesses why:</p>

<ul>
  <li>Although I can perceive 30ms of latency in a comparison test٫ I have to pay attention٫ my keyboard having 30ms of extra latency just made it feel different٫ but that’s unsurprising since it was different in a bunch of ways.</li>
  <li>My only comparison was other high-latency keyboards٫ like my Macbook’s. 30ms of latency difference is more perceptiple than 5-10ms.</li>
</ul>

<p>Anyhow here’s how I managed to bring the latency down from 30ms to 700us:</p>

<ol>
  <li>I added some measurement code that printed the time spent in the main loop to the Serial console after every key press. This gave me the 30ms figure.</li>
  <li>I removed the 10ms delay in the main loop٫ and everything still worked.</li>
  <li>I searched for other delays and found one 2ms one between enabling a row for scanning and reading it٫ which I removed with no apparent consequences. I added back in a 2 microsecond delay just in case.</li>
  <li>I had tried to make the display on my keyboard only update when it changed٫ but I messed this up somewhere else and it was taking 5ms to update on every key press.</li>
  <li>The right half of my keyboard is scanned using an I/O expander over i2c since I didn’t have enough pins on the Teensy. This is the same way the two halves of the <a href="https://www.ergodox.io/">Ergodox</a> work. Based on some Ergodox firmware I saw٫ I reinitialized the direction registers of the I/O expander before every scan٫ just in case. Unfortunately this added 2ms and wasn’t really necessary since unlike the Ergodox you can’t disconnect the second half of my keyboard with a cable.</li>
  <li>Now my loop was taking 3.8ms which was almost entirely the i2c communication with the I/O expander. A friend recommended I check out <a href="https://github.com/nox771/i2c_t3">nox771’s fast i2c library</a>. Unfortunately٫ it wouldn’t compile on the super old version of the Arduino/Teensyduino software I was using. I decided to upgrade٫ and after several hours in C++ compilation hell and accounting for a few changes٫ it worked. I bumped the i2c frequency up to 1.8 megahertz and now my loops took 700us!</li>
  <li>Now I started running into bouncing problems that lead to the occasionally doubled letter٫ so I needed to implement debouncing. Some ways of implementing debouncing add latency but that’s totally unnecessary. <a href="https://github.com/trishume/PolyType/commit/372c2056d705211fb5554a6975eeca34b59f0bc8">I implemented</a> a simple technique that sends transitions immediately and then doesn’t update a key for 5ms after.</li>
</ol>

<p>The specifics are only relevant to other people building keyboard firmware٫ especially the fast i2c one which I don’t think most ErgoDox firmwares use. But I think it’s interesting to see how easy it was to improve the latency of software that wasn’t designed for it with only a few hours work.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:fps" role="doc-endnote">
      <p>I use an iPhone 5S٫ which can only record at 120fps٫ so while these numbers are consistent over multiple measurements٫ they may be off by as much as 8ms. <a href="#fnref:fps" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:fps:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a> <a href="#fnref:fps:2" class="reversefootnote" role="doc-backlink">&#8617;<sup>3</sup></a></p>
    </li>
  </ol>
</div>
'),('http://thume.ca/2017/12/09/cvdisplaylink-doesnt-link-to-your-display/', 'CVDisplayLink Doesn"t Link To Your Display', '1512777600000',  13, '
<p><strong>Edit 2017/12/10:</strong> So I screwed up٫ I thought I was safe confirming it in two different ways but I was using an external monitor and all of the below is accurate only for the multi-monitor case. Skip to the bottom to read about my new results.</p>

<p><code class="language-plaintext highlighter-rouge">CVDisplayLink</code> is the recommended way to synchronize your drawing/animation with the refresh of the display on macOS. Many people assume it calls your app just after each display vsync event٫ unfortunately this isn’t the case at all. <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> just fetches the refresh rate of your display٫ and sets a high resolution timer to call you every 16.6ms (for a 60hz display).</p>

<p>The major reason this is important is if your app has inconsistent rendering times and you get unlucky with the phase of your events٫ you’ll end up painting twice in some frames and zero times in others٫ leading to visible dropped frames in your animations. <a href="https://twitter.com/jordwalke/status/939064408986103808">As illustrated by @jordwalke on Twitter</a>:</p>

<p><a href="https://twitter.com/jordwalke/status/939064408986103808"><img src="/assets/postassets/displaylink/timing.jpeg" alt="Timing" /></a></p>

<p>This is particularly insidious because depending on how variable your draw times are٫ a lot of the time you’ll end up with consistent drawing٫ but every N runs it will be really bad. Even worse٫ your FPS measurements will still show 60fps because you’re still drawing every 16.6ms.</p>

<p>Also٫ if you’re using this for a game loop where you only process input at the start of every frame٫ you could have close to an entire extra frame of latency if you’re unlucky at startup.</p>

<p>“But it’s a special thing that has ‘display’ and ‘link’ right in the name٫ surely it must link up to the display vsync events!” you might say. That’s what I thought too until I talked to <a href="https://twitter.com/pcwalton">@pcwalton</a> at a Rust meetup and he said he’d disassembled <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> and found it was just a timer. This was astonishing to me and I sat on this information somewhat skeptical for a while. But٫ today I finally got around to doing a bunch of investigation and found that he’s right and <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> does not link to the vsync.</p>

<p>First٫ I disassembled the <code class="language-plaintext highlighter-rouge">CoreVideo</code> framework where <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> resides and found a bunch of code that fetches the display rate٫ calculates how often the timer should be triggered and waits on a timer. I didn’t find any code that looked for vsync events.</p>

<p>Next٫ I did some experiments٫ because I might have missed some hidden synchronization. I used <a href="https://github.com/KrisYu/Water">Kris Yu’s Water</a> Metal sample app since that’s sadly the only macOS Metal sample code I could find that built for me. I then disassembled <code class="language-plaintext highlighter-rouge">MTKView</code> and confirmed that as I suspected it just uses <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> to call your <code class="language-plaintext highlighter-rouge">draw</code> method. Then I added <code class="language-plaintext highlighter-rouge">kdebug_signpost</code> calls in the <code class="language-plaintext highlighter-rouge">draw</code> method so that I could use Instrument’s “Points of Interest” trace combined with the new display vsync information to see how they line up.</p>

<p>What I found is that as one would expect with a timer٫ within each run the <code class="language-plaintext highlighter-rouge">draw</code> call happens at a consistent time within the frame٫ but between different runs the <code class="language-plaintext highlighter-rouge">draw</code> call happens at completely different times depending on the phase the <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> starts up in relation to the display vsync.</p>

<p>Here’s some screenshots of different runs in Instruments. The red boxes on the bottom are the <code class="language-plaintext highlighter-rouge">draw</code> call٫ and the vsync display intervals are clearly visible as lining up very differently each run:</p>

<p><a href="/assets/postassets/displaylink/traces.png"><img src="/assets/postassets/displaylink/traces.png" alt="Display Traces" /></a></p>

<p>Now٫ the real question is٫ what do you do if you want actual vsync alignment? I actually don’t know٫ I haven’t done enough research yet٫ but I have some ideas that may or may not work:</p>

<ul>
  <li>I think Cocoa animation or Core Animation draw callbacks may actually be linked to display vsync٫ in which case you can use those. I’m not sure though.</li>
  <li>OpenGL vsync might synchronize with the real vsync.</li>
  <li>Somehow Instruments gets at the real vsync times٫ they might come from a private API٫ but it also might be something public.</li>
  <li>There may be some other API I don’t know about.</li>
</ul>

<p>Note that I haven’t tested <code class="language-plaintext highlighter-rouge">CADisplayLink</code> on IOS٫ but I’ve heard it works properly. Anyway٫ if you know anything about this issue or how to do things properly٫ email me at <a href="mailto:tristan@thume.ca">tristan@thume.ca</a>! I may update this post if I learn anything new.</p>

<h3 id="edit-20171210-i-was-wrong-sorry">Edit 2017/12/10: I was wrong٫ sorry</h3>

<p><a href="https://twitter.com/ametis_/status/939739328397295617">@ametis_</a> on Twitter noted that the internal <code class="language-plaintext highlighter-rouge">CVCGDisplayLink::getDisplayTimes</code> method actually accesses a pointer to a <a href="https://opensource.apple.com/source/IOGraphics/IOGraphics-517.17/IOGraphicsFamily/IOKit/graphics/IOFramebufferShared.h.auto.html">StdFBShmem_t</a>. I poked around some more and confirmed that the shared memory for this is indeed mapped in in the initializer. I figured I might miss something like this٫ hence why I did the experiments. This shared memory contains real vsync times٫ and is apparently a way to get real vsync information from the Kernel. See <a href="https://stackoverflow.com/questions/2433207/different-cursor-formats-in-ioframebuffershared">this StackOverflow post</a> for an example of code that maps it in. The question is٫ why do my experiments show that it still doesn’t line up with vsync?</p>

<p>The <code class="language-plaintext highlighter-rouge">MTKView</code> I was testing with uses <code class="language-plaintext highlighter-rouge">CVDisplayLinkCreateWithActiveCGDisplays</code> which if you have multiple displays creates a <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> “capable of being used with all active displays”٫ i.e it doesn’t use vsync. I was using an external monitor for my tests٫ there’s nothing on my laptop display but I leave it open because there’s a hardware issue where it messes with my trackpad if I close it. In this case a smarter <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> could handle this case fine by realizing that only one of my displays was updating at the time٫ but it turns out it falls back to a timer.</p>

<p>I re-did my experiments in Instruments on my laptop display and found that it consistently fired the <code class="language-plaintext highlighter-rouge">draw</code> call half-way into the frame٫ about 7ms from the next vsync. I don’t know why it does it in the middle rather than the start٫ but at least it was consistent across 6 runs.</p>

<p>So٫ basically this article is mostly wrong٫ provided you only have one display. You still have to worry about jank due to inconsistent frame times on a single monitor if you don’t have GL/Metal vsync enabled and your frames jitter around 7ms though. And if you want events near the start of vsync you may still have a difficult task ahead of you.</p>

<p>It’s probably even possible to get the correct events in a multi-monitor case٫ but you need some fancy code that watches which screen your monitor is on٫ and constructs a new <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> with just that <code class="language-plaintext highlighter-rouge">CGDisplay</code> when the window moves.</p>

<p>Interestingly٫ <a href="https://twitter.com/ametis_/status/939739328397295617">@ametis_</a>’s account was created just for that tweet٫ and figuring out that it uses <code class="language-plaintext highlighter-rouge">StdFBShmem_t</code> without a hint would have required way way better reversing skills than mine to trace the instance variable back to the init method through a bunch of offsets to a memory mapping of an opaque code٫ which they would have had to figure out is <code class="language-plaintext highlighter-rouge">kIOFBSharedConnectType</code> and look at that struct to find it contains the <code class="language-plaintext highlighter-rouge">vblTime</code> field. Either they’re really good at reverse engineering٫ or they’re an Apple engineer with access to the source code who looked into it after seeing my article. Regardless I’m happy they set me straight!</p>

<p>Thanks to other commenters on Hacker News and Twitter have pointed out a few things that I should add here:</p>

<ul>
  <li>Someone on HN notes that the Apple docs don’t promise that <code class="language-plaintext highlighter-rouge">CVDisplayLink</code> gives you refresh times. I had noticed this but didn’t include it in my article٫ but I treated it as further evidence for my results though. Ooops٫ turns out it does sometimes٫ just not always.</li>
  <li><a href="https://twitter.com/jordwalke">@jordwalke</a> linked me to <a href="http://www.ananseproductions.com/game-loops-on-ios/">this article</a> that explains how <code class="language-plaintext highlighter-rouge">CADisplayLink</code> works on IOS.</li>
</ul>
'),('http://thume.ca/2017/11/10/eye-tracking-mouse-control-ideas/', 'Eye Tracking Mouse Control Ideas', '1510272000000',  13, '
<p>This is a list of ideas for using eye tracking as a mouse replacement٫ specifically solving the problem that eye tracking often isn’t quite accurate enough to use raw. There’s lots of targets on a normal computer that are just too small for even the best fingertip-size eyetracker accuracies٫ like selecting individual characters٫ or small buttons. For some people٫ like me٫ eye trackers tend just not to work too well and only are accurate within maybe a 4 cm diameter٫ much too large to specify most targets.</p>

<p>There’s also reason to suspect that this situation won’t improve. People have been working on eye tracking for years and accuracy is still bad. A few papers I’ve read have said that in fact the muscles that point the eyes may even not be accurate enough to point as precisely as a mouse٫ and even if they can that fixating gaze precisely leads to eye fatigue quite quickly.</p>

<p>Why would you want to replace the mouse with an eye-tracking based solution?</p>

<ul>
  <li>Disabilities</li>
  <li>Repetitive Stress Injuries: There’s lots of approaches to addressing RSIs٫ but it’s also a much larger market.</li>
  <li>People who don’t want to take their hands off the keyboard: Programmers go to crazy lengths to learn shortcuts to avoid reaching for the mouse٫ if there was a fast system of hands-free mousing٫ some may like it.</li>
</ul>

<p>I’m writing this list for two reasons:</p>

<ol>
  <li>So that I can get the WaybackMachine to archive it to have evidence of prior art in case anybody tries to patent these. I try to explore as much of the space of possible ideas people could try patenting as possible. Of course٫ it’s possible one or more of these already falls under some patent٫ because there’s patents on a lot of obvious ideas٫ but I don’t know of any.</li>
  <li>As a survey of the possibilities٫ to look at what’s possible and possibly inspire someone to try something out. Eye tracking has such potential٫ but is sadly rarely used outside of research.</li>
</ol>

<p>Before proceeding I’d like to emphasize that <strong>not all these ideas are good</strong>٫ many wouldn’t be that nice to use or would have other issues٫ I aimed much more for breadth in creating this list than depth.</p>

<p>There’s three broad categories to these ideas:</p>

<h2 id="combining-with-another-input-method">Combining with another input method</h2>

<p>There’s a lot of alternative mousing methods that work but are quite slow. But٫ if you use eye tracking for coarse but fast narrowing of position٫ and then another technique for refinement٫ they can be quite efficient.</p>

<dl>
  <dt><a href="https://github.com/trishume/PolyMouse">Polymouse</a></dt>
  <dd>Using head tracking for refinement and eye tracking for large movements٫ you can achieve speeds equal to a good trackpad and approaching a normal mouse. This is the main technique I’ve put effort into and was the focus of my research at the Waterloo HCI lab. I use a version of the “Animated MAGIC” technique to quickly move the mouse cursor along the path to the target based on eye tracking. I’m currently working towards making this technique available in a low-cost and convenient system for daily use.</dd>
  <dt>Combining with a mouse</dt>
  <dd>This just allows you to use less mouse movement. This is built into Tobii’s consumer software.</dd>
  <dt>Combining with voice</dt>
  <dd>There’s a lot of things on a screen to click٫ and it’s hard to describe them٫ but given a small region from eye tracking٫ you can use OCR or accessibility APIs to find interactible things near the gaze and disambiguate what to do via voice. For example “click find” when looking near the “Find file” button on Github.</dd>
  <dt>Combining with a keyboard</dt>
  <dd>Within a region around the eye٫ you could offer a number of options for things to interact with٫ presented as letters or colours overlayed on the screen٫ and then use different keyboard keys to select which one was the true target. The places to put the markers could be done via a pattern٫ machine learning٫ text recognition or an accessibility API. Similar to <a href="https://github.com/trishume/mjolnir.th.hints">this</a>.</dd>
  <dt>Combining with button timing</dt>
  <dd>When the click button is pressed٫ instead of emitting a click event it could start move the cursor in for example a grid or spiral pattern around the gaze location٫ and when the user releases it clicks in that location. This could also be combined with likely target data٫ see the next section. This would be slow but doesn’t require extra hardware٫ it uses timing information as the additional source.</dd>
  <dt>Face Gestures</dt>
  <dd>Camera data could be fed into a face tracking algorithm and face gestures could be used to refine the cursor position. For example moving the lips around like a joystick٫ or twitching cheeks to nudge left and right. Most eye trackers are actually just IR cameras so this may not even require a separate camera.</dd>
</dl>

<h2 id="predicting-the-target">Predicting the target</h2>

<p>When you have eye tracking data that is fairly good but not perfect٫ the effective accuracy can be improved by guessing good targets within the gaze region.</p>

<p>Good targets can be things like buttons٫ words to select٫ and other UI controls. Even when some place is interactible٫ it may make sense to choose a better target anyway٫ for example preferring selecting entire words rather than characters within a word٫ and the right side of a tab targetting the close button and the left side targetting clicking the tab.</p>

<p>Given a source of information about likely targets٫ there’s various things you can do with the information:</p>

<dl>
  <dt>Snapping</dt>
  <dd>The gaze cursor or clicks snap to the nearest likely target. Possibly with snappiness determined by a measure of likelihood of clicking the target.</dd>
  <dt>Draw the cursor towards it</dt>
  <dd>This is basically a softer form of snapping. It could be like gravity٫ or fancier. For example modelling the gaze data as a probability distribution over true targets٫ and target information as a prior distribution٫ and then using Bayesian calculations to find the maximum likelihood target. I think I prefer the simpler and more consistent idea of snapping though.</dd>
</dl>

<p>There’s a few ways I can think of getting the target information٫ a system could use either one or many of these:</p>

<dl>
  <dt>Use accessibility APIs</dt>
  <dd>Accessibility APIs can tell you the pixel location of buttons٫ text and other likely targets.</dd>
  <dt>Likelihood Neural Net</dt>
  <dd>Use machine learning (probably a CNN) to train a model that given a screenshot٫ predicts a likelihood distribution (think heatmap) of click targets. It could be trained on data from recording a screenshot and the mouse position on every click during normal computer use.</dd>
  <dt>Prediction Neural Net</dt>
  <dd>Similar to the above٫ but using Gaze data. A model would be trained on the gaze location and screen contents to predict the true mouse click target. One way to do this would be to feed the net patches of the screen centered on the gaze target. Training data would be gathered by saving data from every click and training on the true click position.</dd>
  <dt>Classical Computer Vision</dt>
  <dd>There’s a number of possible computer vision techniques that could be used to identify targets without machine learning. For text anything from full OCR to algorithms that detect where text is without recognizing it (like in my <a href="https://github.com/trishume/KeySelect">KeySelect</a> demo). Buttons also often have text٫ but controls could also be recognized using image patches recognized from previous clicks. You could even use heuristics like “coloured things” or “visually complex things”.</dd>
</dl>

<h2 id="disambiguate-with-just-gaze">Disambiguate with just gaze</h2>

<p>It’s also possible to disambiguate targets with gaze alone٫ but this generally requires modifying or overlaying on the screen targets to manipulate the gaze.</p>

<dl>
  <dt>Magnifying</dt>
  <dd>The simplest one is just magnifying the error around the gaze٫ either continuously or on dwell. This allows the user to refine their gaze on larger targets. The magnification can be either a rectangle or something fancier like a fisheye.</dd>
  <dt>Moving Markers</dt>
  <dd>Similar to keyboard disambiguation٫ overlay likely targets with a marker that moves around in some pattern. Check if the gaze data is following one of the patterns. This works because eye trackers are better at detecting direction and timing of motion than absolute position. See the <a href="https://www.youtube.com/watch?v=x6hbicxEFbg">Orbits paper</a> for an example of this kind of system.</dd>
  <dt>Moving Distortion</dt>
  <dd>Similar to the previous except instead of markers٫ distort the screen are around the gaze in a moving pattern where different parts move in different patterns. Then the user just follows what they want to click with their gaze.</dd>
  <dt>Eye Gestures</dt>
  <dd>Extra eye movements could be used to refine the position. For example darting the eyes in a position could nudge the cursor in that direction relative to where it was before the dart. Or winking an eye could move it left or right a small amount.</dd>
</dl>

<h2 id="how-to-click">How to click</h2>

<p>Clicking is a separate issue٫ but there’s also lots of possibilities here:</p>

<ul>
  <li>Using a button: This could be a normal mouse or any other button.</li>
  <li>A foot pedal</li>
  <li>Dwell clicking</li>
  <li>Mouth noises: This is what I tried in my research٫ see <a href="https://github.com/trishume/PopClick">PopClick</a></li>
  <li>Face٫ head or eye gestures</li>
  <li>Voice recognition</li>
  <li>A keyboard</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Like I said٫ this was originally written primarily as prior art for patents. But I hope it was at least somewhat interesting to think about the numerous possibilities for eye tracking as a mouse replacement٫ even if a lot of the ideas have issues.</p>
'),('http://thume.ca/2017/06/17/tree-diffing/', 'Designing a Tree Diff Algorithm Using Dynamic Programming and A*', '1497657600000',  13, '
<p>During my internship at <a href="https://www.janestreet.com/">Jane Street</a><sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>٫ one of my projects was a config editing tool that at first sounded straightforward but culminated in me designing a custom tree diffing algorithm using dynamic programming٫ relentlessly optimizing it and then transforming it into an A* accelerated path finding algorithm. This post is the story of the design and optimization of the algorithm٫ of interest to anyone who needs an algorithm for diffing trees٫ or who just wants an in-depth example of the process of solving a real-world problem with a custom non-trivial dynamic programming algorithm٫ and some tips on optimizing one while maintaining understandability٫ or anyone who just wants to read a cool programming story and maybe learn something.</p>

<!-- Inspired by https://twitter.com/patio11/status/864770640796016641 -->

<h3 id="table-of-contents">Table of Contents</h3>

<ul>
  <li><a href="#background">Background</a>: Description of the problem I was solving.</li>
  <li><a href="#the-heuristic-approach">The Heuristic Approach</a>: My initial attempt at a simple algorithm٫ and why it was insufficient.</li>
  <li><a href="#a-tree-diff-optimizer">A Tree Diff Optimizer</a>: Rethinking the problem as finding the optimal resulting tree diff.</li>
  <li><a href="#dynamic-programming">Dynamic Programming</a>: Background on using the correspondence between memoizing recursion and path finding on a grid to find solutions to problems like Levenshtein distance.</li>
  <li><a href="#the-algorithm">The Algorithm</a>: Extending Levenshtein distance with two grids and recursion.</li>
  <li><a href="#profiling-and-optimization">Profiling and Optimizing</a>: Relentless profiling and optimizations to reduce run time.</li>
  <li><a href="#path-finding">Path Finding</a>: Using A* to make the run time proportional to the difference rather than tree size.</li>
  <li><a href="#example-implementation">Example Implementation</a>: Analysis of the effectiveness and costs of A* on Levenshtein distance٫ sequence alignment and diffing problems٫ with open source example code.</li>
</ul>

<h2 id="background">Background</h2>

<p>Jane Street has a lot of config files for their trade handling systems which use <a href="https://en.wikipedia.org/wiki/S-expression">S-expressions</a> (basically a tree with strings as leaves). They often want to make changes that will only apply on certain days٫ for example days when markets will act differently than normal like elections and option expiry dates. To do this their config processor knows a special construct that is like a switch statement for dates٫ it looks something like this:</p>

<figure class="highlight"><pre><code class="language-scheme" data-lang="scheme"><span class="p">(</span><span class="nf">thing-processor-config</span>
  <span class="p">(</span><span class="nf">:date-switch</span>
   <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span>
    <span class="p">(</span><span class="nf">speed</span> <span class="mi">5</span><span class="p">)</span>
    <span class="p">(</span><span class="nf">power</span> <span class="mi">7</span><span class="p">))</span>
   <span class="p">(</span><span class="k">else</span>
    <span class="p">(</span><span class="nf">speed</span> <span class="mi">3</span><span class="p">)</span>
    <span class="p">(</span><span class="nf">power</span> <span class="mi">9</span><span class="p">))))</span></code></pre></figure>

<p>The semantics are that any <code class="language-plaintext highlighter-rouge">:date-switch</code> block has its branches checked against the current date and the children of the correct branch are used in place of the <code class="language-plaintext highlighter-rouge">:date-switch</code> in the config structure. Note that each branch can contain multiple sub-trees.</p>

<p>Now٫ just that small example took a while for me to type and get the indentation correct. People at Jane Street are frequently making edits where they just want to quickly change some numbers but have to make sure they get the syntax and indentation right and have everything still look nice. This is begging for automation!</p>

<p>So they asked me to write a tool that would allow people to just edit the file and run a command٫ and it would automatically scope their changes to the current day٫ or a date they specify٫ by detecting the differences between the current contents on disk and the committed contents in version control.</p>

<p>When I first heard the problem٫ it sounded pretty easy and I thought I’d be done within a few days٫ but I discovered a number of catches after starting and it ended up taking 5 weeks. This sounds like we maybe should have abandoned it when we discovered how complex it was٫ but given how much time expensive people were spending doing these edits٫ sometimes under time pressure when every extra minute had a high cost٫ it was worth it to get it right.</p>

<p>The first thing I discovered is that they had a library for parsing and serializing s-expressions while preserving indentation and comments٫ but it didn’t cleanly handle making structural modifications to the parse tree. Before even starting the rest of the project I had to write a library that provided a better data model for doing this and having the result be nicely indented.</p>

<p>Next٫ the real syntax for these date switch blocks is more complicated than my description and has a static constraint where the branches must cover every date in the current context and no more٫ including when nested inside other switches. I also didn’t want edits to <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks to themselves be scoped to a date٫ since that would create invalid syntax. This required I parse my earlier style-preserving representation into one that computed date context and represented <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks specially in an <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract Syntax Tree (AST)</a> as well as transform back from my representation to the one I could output.</p>

<p>Now finally I was ready to start on the actual algorithm. The basic task my script had to do was take two trees and wrap differing sub-trees in a <code class="language-plaintext highlighter-rouge">:date-switch</code> block with the old contents in one branch and the new contents in the other branch. The thing is٫ there are many ways to do this. The switch can be placed at many different levels and there may be multiple edits and it’s not specified how to group them. Technically it could just add a <code class="language-plaintext highlighter-rouge">:date-switch</code> at the top level with the old file in one branch and the new file in another٫ but that wouldn’t be very satisfying٫ just like how technically the <code class="language-plaintext highlighter-rouge">diff</code> command could just output the entire old file prefixed with <code class="language-plaintext highlighter-rouge">-</code> and then the new file prefixed with <code class="language-plaintext highlighter-rouge">+</code>٫ but then nobody would use it. I needed an algorithm that gave reasonable-looking and compact changes for real-world edits. It shouldn’t double the file size in an enormous <code class="language-plaintext highlighter-rouge">:date-switch</code> when only a single number changed.</p>

<h2 id="the-heuristic-approach">The Heuristic Approach</h2>

<p>If you just want to read about the optimal algorithm and not why one was necessary you can <a href="#a-tree-diff-optimizer">skip this section</a>.</p>

<p>First٫ I came up with a simple algorithm that I thought would work in almost all real-world cases. I simply recursively walked down the tree until I got to either a leaf that was different or a node that had a different number of children٫ and then it would put a <code class="language-plaintext highlighter-rouge">:date-switch</code> at that level.</p>

<p>This didn’t produce the most satisfying results٫ it was okay for changes to leaves٫ but as soon as you added or removed a child from a list٫ it would duplicate most of the list when it could have taken advantage of the ability to have a different number of children in each branch.</p>

<p>It produced this:</p>

<figure class="highlight"><pre><code class="language-scheme" data-lang="scheme"><span class="p">(</span><span class="nf">:date-switch</span>
 <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span>
  <span class="p">(</span><span class="nf">foo</span>
   <span class="nv">qux</span>
   <span class="c1">; ... 1000 more lines ...</span>
   <span class="nv">baz</span><span class="p">))</span>
 <span class="p">(</span><span class="k">else</span>
  <span class="p">(</span><span class="nf">foo</span>
   <span class="c1">; ... 1000 more lines ...</span>
   <span class="nv">baz</span><span class="p">)))</span></code></pre></figure>

<p>When we really would have preferred:</p>

<figure class="highlight"><pre><code class="language-scheme" data-lang="scheme"><span class="p">(</span><span class="nf">foo</span>
 <span class="p">(</span><span class="nf">:date-switch</span>
  <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span> <span class="nv">qux</span><span class="p">)</span>
  <span class="p">(</span><span class="k">else</span><span class="p">))</span>
 <span class="c1">; ... 1000 more lines ...</span>
 <span class="nv">baz</span><span class="p">)</span></code></pre></figure>

<p>Luckily٫ this was easy enough to solve since Jane Street already had an <a href="https://github.com/janestreet/patience_diff">OCaml library implementing the Patience Diff algorithm</a> for arbitrary lists of comparable OCaml types. When I had two lists of differing length٫ I simply applied the Patience Diff algorithm and placed <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks based on the diff.</p>

<p>This algorithm worked okay for cases of a single edit٫ but we wanted the tool to work with multiple edits٫ and for those it still often produced terrible results.</p>

<p>For example٫ because it stopped recursing and applied a diff as soon as it reached a list of changing length٫ it would do this:</p>

<figure class="highlight"><pre><code class="language-scheme" data-lang="scheme"><span class="p">(</span><span class="nf">this</span>
 <span class="p">(</span><span class="nf">:date-switch</span>
  <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span>
   <span class="p">(</span><span class="nf">bar</span>
    <span class="c1">; ... 1000 more lines ...</span>
    <span class="nv">baz</span><span class="p">))</span>
  <span class="p">(</span><span class="k">else</span>
   <span class="p">(</span><span class="nf">foo</span>
    <span class="c1">; ... 1000 more lines ...</span>
    <span class="nv">baz</span><span class="p">)))</span>
 <span class="nv">tests</span>
 <span class="p">(</span><span class="nf">:date-switch</span>
  <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span> <span class="nv">adding</span> <span class="nv">to</span> <span class="nv">a</span> <span class="nv">list</span> <span class="nv">and</span> <span class="nv">modifying</span> <span class="nv">a</span> <span class="nv">sub-tree</span><span class="p">)</span>
  <span class="p">(</span><span class="k">else</span><span class="p">)))</span></code></pre></figure>

<p>It duplicates the long sub-tree instead of placing the <code class="language-plaintext highlighter-rouge">:date-switch</code> lower down in it٫ just because we made another edit at a higher level of the tree.</p>

<p>There were a number of other cases where it didn’t produce output as nice as a human would٫ but earlier on my mentor and I had sighed and accepted it. This though was the last straw٫ we needed a new approach…</p>

<h2 id="a-tree-diff-optimizer">A Tree Diff Optimizer</h2>

<p>At this point I was fed up with constantly discovering failure modes of algorithms I thought should work on real-world cases٫ so I decided to design an algorithm that found the <em>optimal</em>
solution.</p>

<p>I started by searching the Internet for tree diff algorithms٫ but every algorithm I found was either a different kind of diff than what I needed٫ or was complex enough that I wasn’t willing to spend the time understanding it (probably only to later find out it computed a different kind of diff than I needed).</p>

<p>Specifically٫ what I needed was mostly like a tree diff but I wasn’t optimizing for the same thing as other algorithms٫ what I wanted to optimize for was resulting file size٫ including indentation. This I thought represented what I wanted fairly well٫ and captured why previous results which duplicated large parts of the file were bad. As well as the character cost of the branches٫ each additional <code class="language-plaintext highlighter-rouge">:date-switch</code> block added more characters. Additionally٫ each switch construct could also contain multiple sub-trees in each branch٫ which I needed to model to account for overhead correctly.</p>

<p>Consider the case of <code class="language-plaintext highlighter-rouge">(a b c)</code> becoming <code class="language-plaintext highlighter-rouge">(A b C)</code>. A human would write:</p>

<figure class="highlight"><pre><code class="language-scheme" data-lang="scheme"><span class="p">(</span><span class="nf">:date-switch</span>
 <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span> <span class="p">(</span><span class="nf">A</span> <span class="nv">b</span> <span class="nv">C</span><span class="p">))</span>
 <span class="p">(</span><span class="k">else</span> <span class="p">(</span><span class="nf">a</span> <span class="nv">b</span> <span class="nv">c</span><span class="p">)))</span></code></pre></figure>

<p>Despite the fact that the <code class="language-plaintext highlighter-rouge">b</code> is duplicated٫ this is the smallest number of characters. However if we had something longer we’d want something different٫ so the optimal result even depends on the length of leaf nodes:</p>

<figure class="highlight"><pre><code class="language-scheme" data-lang="scheme"><span class="p">((</span><span class="nf">:date-switch</span> <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span> <span class="nv">A</span><span class="p">)</span> <span class="p">(</span><span class="k">else</span> <span class="nv">a</span><span class="p">))</span>
 <span class="nv">this_is_a_super_long_identifier_we_do_not_want_duplicated_because_it_is_looong</span>
 <span class="p">(</span><span class="nf">:date-switch</span> <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span> <span class="nv">C</span><span class="p">)</span> <span class="p">(</span><span class="k">else</span> <span class="nv">c</span><span class="p">)))</span></code></pre></figure>

<p>A very common real-world example of why it is important for it to be able to batch together differences is when changing multiple values of a data structure. The config files often have lots of key-value pairs and edits often touch many nearby values:</p>

<figure class="highlight"><pre><code class="language-scheme" data-lang="scheme"><span class="p">(</span><span class="nf">thing-processor-config</span>
  <span class="p">(</span><span class="nf">:date-switch</span>
   <span class="p">(</span><span class="k">case</span> <span class="mi">2017-04-07</span>
    <span class="p">(</span><span class="nf">speed</span> <span class="mi">5</span><span class="p">)</span>
    <span class="p">(</span><span class="nf">size</span> <span class="mi">80</span><span class="p">)</span>
    <span class="p">(</span><span class="nf">power</span> <span class="mi">9001</span><span class="p">))</span>
   <span class="p">(</span><span class="k">else</span>
    <span class="p">(</span><span class="nf">speed</span> <span class="mi">3</span><span class="p">)</span>
    <span class="p">(</span><span class="nf">size</span> <span class="mi">80</span><span class="p">)</span>
    <span class="p">(</span><span class="nf">power</span> <span class="mi">7</span><span class="p">))))</span></code></pre></figure>

<p>Even though <code class="language-plaintext highlighter-rouge">size</code> didn’t change٫ we duplicate it because it’s cleaner than having two <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks.</p>

<!-- This kind of case is also where counting indentation comes in handy٫ if we only change one value we want to put the `:date-switch` around the whole pair because the indentation for putting it around the value is ugly:

    (thing-processor-config
      (speed (:date-switch
              (2017-04-07 5)
              (else 3)))
      ; better to do this
      (:date-switch
       (2017-04-07 (power 7))
       (else (power 9)))) -->

<!-- We can model the problem as a recursive decision-making problem where we want to find the optimal set of decisions. At each level we"ll have two lists٫ a "new" list and an "old" list٫ there"s a number of cases:

- If both lists are empty٫ there"s nothing to do
- If the first element of both lists is the same٫ we put it in the output and then make decisions on the remainder of the list.
- If both lists start with a different child list٫ we have two choices:
  - We can start a new `:date-switch` block
  - Or we can recurse and decide how to place `:date-switch` blocks within the child list.
- Otherwise٫ we can only enter a `:date-switch` block.

And then we have a separate set of decisions we can make on lists
 -->

<h2 id="dynamic-programming">Dynamic Programming</h2>

<p>After 2+ days of research٫ discussing ideas with my mentor٫ and sitting down in a chair staring out at the nice view of London while thinking and sketching out cases of the algorithm in a notebook٫ I had something. It was a recursive dynamic programming algorithm that checked every possible way of placing the <code class="language-plaintext highlighter-rouge">:by-date</code> blocks and chose the best٫ but used memoization (that’s the dynamic programming part) so that it re-used sub-problems and had polynomial instead of exponential complexity.</p>

<p>The core of the tree diffing problem is similar to the <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein Distance</a> problem٫ you have two lists that have some number of insertions and deletions between them٫ and you want to find the best way to match them up. You can do this with a number of different cases based on the first elements of the lists with different costs٫ calculating those costs involves some constant plus recursively computing the cost for the rest of the lists. Then you compute the cost for each possible decision and take the minimum one.</p>

<p>For example if you have a function <code class="language-plaintext highlighter-rouge">best_cost(old٫new)</code> to solve the Levenshtein distance problem٫ there’s three cases for the start of the lists: insert٫ delete and same. The simplest case is if the first two elements are the same٫ and characters that are the same cost <code class="language-plaintext highlighter-rouge">0</code>٫ then the cost is just <code class="language-plaintext highlighter-rouge">best_cost(old[1..]٫ new[1..])</code>. If a delete costs <code class="language-plaintext highlighter-rouge">1</code>٫ then if the start of the list is a delete that means the character is in <code class="language-plaintext highlighter-rouge">old</code> but not <code class="language-plaintext highlighter-rouge">new</code> so the total cost is <code class="language-plaintext highlighter-rouge">1 + best_cost(old[1..]٫ new)</code>. Insert is similar but the opposite direction. This recursion terminates with the base case of <code class="language-plaintext highlighter-rouge">best_cost([]٫[]) = 0</code>. The problem is that this leads to an exponential number of recursive calls.</p>

<p>But we can fix this by noticing that a lot of things are being computed redundantly and sharing the results by “memoizing” the function so that it stores the results for arguments it has been called with before. As seen in the diagram below٫ where the numbers on the nodes represent calls to <code class="language-plaintext highlighter-rouge">best_cost(old[i..]٫ new[j..])</code> as <code class="language-plaintext highlighter-rouge">i٫j</code>:</p>

<p><img src="/assets/postassets/treediff/tree.png" alt="Decision tree diagram" /></p>

<p>But in some cases it can be difficult to think about the problem as a recursive memoized decision tree. Luckily there’s a different way of thinking about it that lends itself very well to sketching out algorithms in a notebook or on a whiteboard. We can rotate the tree 45 degrees and notice that we can think about it as a grid:</p>

<p><img src="/assets/postassets/treediff/treegrid.png" alt="Decision tree diagram rotated to be a grid" /></p>

<p>This is useful for memoization since it means we can store our results in an efficient-to-access 2D array٫ but also because we can now think of our problem as finding a path from the top left of a grid to the bottom right using a certain set of moves. Whenever our decisions are constrained we can annotate the grid where the input lists have a property٫ like two items being the same. In the example below٫ we have a diagram of trying to find the Levenshtein distance from “abcd” to “bcad”٫ with the best path bolded٫ and an alternative more costly path our algorithm might explore shown dashed.</p>

<p><img src="/assets/postassets/treediff/simplepaths.png" alt="Levenshtein distance paths" /></p>

<p>We can find the best path by testing all the paths and returning the best one. There are exponentially many paths٫ but we can notice that the best path from a point in the middle of the grid to the bottom right is always the same no matter what moves might have gotten us to that point.</p>

<p>One way to exploit this is to recursively search all paths from the top left٫ memoizing the best path at each point so we don’t compute it again. This corresponds to the memoizing of recursive functions mentioned earlier and is called the “top-down approach” to dynamic programming.</p>

<p>There’s also the “bottom up” approach where you start from the bottom right and fill in each intersection with the best path based on previously computed results or base cases by using an order where everything you need is always available. In this case it would be right to left٫ top to bottom٫ like reading a book from end to start.</p>

<p>Now we know that if we can restate our tree diffing problem as a problem of path-finding on a graph٫ we can turn that into an implementation using dynamic programming.</p>

<h2 id="the-algorithm">The Algorithm</h2>

<p>The key differences between my problem and Levenshtein distances were the fact that it was a tree and not a list٫ and the fact that consecutive sequences of inserts/deletes were cheaper than separate ones (because consecutive edits could be combined in one <code class="language-plaintext highlighter-rouge">:date-switch</code> block). My cost function is also different in that I’m measuring the size of the resulting tree including <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks٫ so my moves will need costs based on that.</p>

<p>I can extend the list algorithm to trees by adding a move I’ll call “recurse” that goes down and right and can be done on any square where both items are sub-trees (not leaves). The cost of the move is the cost of the resulting diff from running the entire tree-diff algorithm recursively on those two sub-trees. I don’t bother recursing if the two sub-trees are the same٫ since the “same” move has identical cost in that case٫ and is faster to compute.</p>

<p>We can handle the cheaper consecutive inserts and deletes by modeling entering and leaving a <code class="language-plaintext highlighter-rouge">:date-switch</code> block as moves. However now we have different move sets based on if we are in or out of a <code class="language-plaintext highlighter-rouge">:date-switch</code> block and different costs to get to the end from a given point. We can rectify this by splitting our problem into path-finding over <em>two</em> grids of the same size. One is our “outside” grid٫ where we can do the “same”٫ “recurse” and now also a “in” move which moves us to the same position on the other grid.</p>

<p>On the “inside” grid we can do “insert”٫ “delete” and “out” moves. But that won’t quite work because if “in” and “out” both don’t make forward progress٫ the graph has a cycle and our search algorithm will endlessly recurse over paths going “in” and “out” at the same point. We can solve this by splitting “out” into “insert out” and “delete out”. The first two are the same as insert and delete except they also move to the “outside” grid٫ we also have to make sure that we don’t use the “insert” and “delete” moves to go to the bottom right of the “inside” grid٫ because then we’d be stuck.</p>

<p>This gives us a set of moves that always make forward progress and share as much as possible٫ with this we can find the best path and that gives us an optimal diff. See the diagram below which also includes the cost of each move and an example path٫ although not necessarily the optimal one:</p>

<p><a href="/assets/postassets/treediff/treediffgrid.pdf" target="_blank">
<img src="/assets/postassets/treediff/treediffgrid.png" alt="Tree diff diagram" />
</a></p>

<p>Even this model is simplified٫ because in reality I had to handle input lists that both might have <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks already in them٫ so there were a bunch more cases and contingencies for handling existing <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks properly. But those aren’t very interesting and the core of the algorithm is the same.</p>

<p>So I implemented this algorithm on top of the AST manipulation framework I’d built by translating it to a memoized recursive algorithm operating on linked lists. Since the outer algorithm also involved recursion٫ this meant I had two kinds of recursion٫ which I structured using OCaml’s ability to define functions inside of other functions. I had an outer <code class="language-plaintext highlighter-rouge">scope_diffs</code> function that took two lists of s-expressions and produced a list of s-expressions with differences scoped by <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks. Inside it٫ I allocated two tables to memoize the results in٫ and defined <code class="language-plaintext highlighter-rouge">scope_suffix_diffs_inside</code> and <code class="language-plaintext highlighter-rouge">scope_suffix_diffs_outside</code> functions that took indices of the start of the suffixes and mutually recursed and memoized into the tables based on the moves above.</p>

<p>Unlike the Levenshtein difference algorithm I wanted more than just the cost٫ so I stored the actual scoped s-expressions up to each point in the table directly٫ because I was using immutable linked lists in OCaml this was memory-efficient since each entry would share structure with the entries it was built from. This way I avoided the back-tracing path reconstruction step that is frequently used with dynamic programming. In order to make the lists share structure I did have to add to the front instead of the back٫ but I just reversed the best resulting list before I returned it.</p>

<p>Once I finished programming it and got it to compile٫ I think I only had to fix one place where I’d copy-pasted a <code class="language-plaintext highlighter-rouge">+1</code> where I shouldn’t have and then it worked beautifully. Finally٫ unlike all my heuristic attempts٫ I couldn’t find a case where this produced a result significantly worse than what a human would do.</p>

<p><em>Side note:</em> I used to expect lots of debugging time whenever I finished a bunch of complex algorithmic code٫ but to my surprise I’ve found that’s rarely the case when using languages with good type systems. The compiler catches almost all small implementation errors٫ and since I’ve usually spent a long time thinking about all the edge cases carefully while designing the algorithm٫ there’s usually no serious bugs left by the time it compiles. My tests usually fail a few times٫ but that’s normally because I wrote the tests wrong.</p>

<p>Unfortunately٫ while my new algorithm worked quite well for small files٫ it was very slow on large files. My mentor timed it on a few example files and fit a polynomial and discovered that it was empirically <code class="language-plaintext highlighter-rouge">O(n^3)</code> (or it might have been <code class="language-plaintext highlighter-rouge">O(n^4)</code> I forget) in the file size. This was unfortunate since some of the files were tens of thousands of lines long. I had to make it faster٫ luckily while I’d been thinking about and implementing the algorithm I’d accumulated quite a list of optimization ideas to try. But first٫ I decided to profile to see what the biggest costs were.</p>

<h2 id="profiling-and-optimizing">Profiling and Optimizing</h2>

<h3 id="incremental-cost-computation">Incremental cost computation</h3>

<p>The first order of business was to discover why the empirical complexity was higher than we thought it should be. My mentor and I tried to come up with a proper analysis of what it should be٫ but given all the cases and the nested nature of trees there were just too many parameters and we couldn’t come up with anything precise. But٫ as far as we could tell the complexity of the underlying algorithm should have been about <code class="language-plaintext highlighter-rouge">O(n^2*log(n))</code> in the length of real files.</p>

<p>I could have looked over the implementation carefully to find all the extra unnecessary work٫ but an easier method was just to use the <a href="https://perf.wiki.kernel.org/index.php/Main_Page">Linux <code class="language-plaintext highlighter-rouge">perf</code> tool</a> to profile it. I knew the work that caused it to be <code class="language-plaintext highlighter-rouge">O(n^3)</code> wasn’t at the outer levels of the algorithm٫ or I would have noticed easily٫ so it had to be an operation within that would show up in the profiles.</p>

<p>Sure enough٫ most of the program’s time was spent in the code that computed the length/cost of an s-expression. I had a function that walked a tree and computed its total length٫ and in the part of the algorithm where I had to choose the lowest-cost move I computed the cost of the entire path from that point٫ which added an extra <code class="language-plaintext highlighter-rouge">O(n)</code> inside the <code class="language-plaintext highlighter-rouge">O(n^2)</code> algorithm yielding <code class="language-plaintext highlighter-rouge">O(n^3)</code>.</p>

<p>In order to fix this٫ I made sure every cost computation was constant time٫ which meant I had to construct the cost of a path incrementally as it was constructed٫ and also not repeatedly walk trees to determine their cost.</p>

<p>I solved this in three steps:</p>

<ol>
  <li>Create a “costed list” type which was a linked list except each item included the cost of the suffix from that point. This had a constant-time prepend operation that just added the cost of the item being prepended to the cost field of the rest of the list.</li>
  <li>Modify the Abstract Syntax Tree (AST) data structure to include a cost field on every node٫ and to use a costed list for children. I also made all the AST builder functions compute the cost of their components by just adding the cost of their overhead with the costs of their child nodes or costed lists. Now both getting the cost of an AST subtree and constructing a node were constant time.</li>
  <li>When building the path/diff/result of my algorithm I used a costed list and constructed new <code class="language-plaintext highlighter-rouge">:date-switch</code> nodes using the constant-time builder API.</li>
</ol>

<p>After I did this٫ our measurements of growth were consistent with the <code class="language-plaintext highlighter-rouge">O(n^2*log(n))</code> we were expecting.</p>

<h3 id="skipping-identical-prefixes-and-suffixes">Skipping identical prefixes and suffixes</h3>

<p>This was an easy but high-impact optimization I had written down earlier. By the properties of the cost of each move٫ if a prefix and/or suffix of the two lists was identical٫ the “same” move would always be the best for those parts of the path. This meant that I could find the longest prefix and suffix of the two lists that was the same and only run the dynamic programming algorithm on the middle part that wasn’t. This made the common case of edits being concentrated at a single point in the file very fast because now the running time was more like <code class="language-plaintext highlighter-rouge">O(d^2*log(d)+n)</code> with <code class="language-plaintext highlighter-rouge">n</code>being file size (large) and <code class="language-plaintext highlighter-rouge">d</code> being the size of the edited region (small).</p>

<p>Now almost all common uses of the tool would return instantly except edits in multiple places spread out through a large file. It was now a pretty useful tool٫ but users having to know which cases to avoid to make the tool not take forever wasn’t great. It would sometimes be used in high-pressure situations and often people did want to make edits in different places٫ manually batching the edits up and running the tool multiple times wasn’t ideal.</p>

<p>There was also only one or two weeks left in my internship٫ not much time to do another project٫ and I think my mentor was having fun challenging me to make the tool perfect and brainstorming how to do so with me. I was also enjoying the process٫ so the optimization would continue until performance improved!</p>

<h3 id="tree-creation-optimization">Tree creation optimization</h3>

<p>Profiling indicated a lot of time was spent creating <code class="language-plaintext highlighter-rouge">:date-switch</code> AST nodes.</p>

<p>First I wrote a fast-path method of creating and computing cost for <code class="language-plaintext highlighter-rouge">:date-switch</code> blocks the algorithm creates since they use a simpler format and a known indentation style than the more general AST construction builder uses.</p>

<p>Additionally٫ when exploring paths in the “inside :date-switch” table٫ I used to create a <code class="language-plaintext highlighter-rouge">:date-switch</code> node whenever I needed to know the cost so far to decide between moves. Instead٫ I switched to just adding the costs of the <code class="language-plaintext highlighter-rouge">insert</code> and <code class="language-plaintext highlighter-rouge">delete</code> branches (which were costed lists)٫ to a known overhead of the <code class="language-plaintext highlighter-rouge">:date-switch</code> block. I only created the full node upon exiting to the “outside :date-switch” table.</p>

<p>But my mentor realized this could extend even further: The search for the best path only ever needs to know the cost of a resulting path/tree٫ we only need the full tree for the best path at the end of the search. So I added a “lazy <code class="language-plaintext highlighter-rouge">:date-switch</code>” AST node that has a stored cost computed by fast addition of the cost of the components plus a known overhead٫ but doesn’t actually create the node immediately and just stores an OCaml <code class="language-plaintext highlighter-rouge">lazy</code> thunk that creates it if we try to serialize the result.</p>

<!-- ### Adaptive memoization tables

My tool was now instant in most common cases and difficult cases were over 100x faster. But٫ on the very largest 10٫000+ line config files it would still take up to 5 minutes in the worst case if you made edits in multiple places. There were no longer any obvious hot spots in the profiles٫ I needed algorithmic improvements that let me search less possible paths.

But before I did that٫ in order for them to be effective I had to enable sparse storage of the memoization tables. I was using 2D arrays٫ but if I wanted to search less than `O(n^2)` states at each level I also wanted to not allocate `O(n^2)` memory.

A common approach when memoizing a recursive function is to store things in a hash table٫ that way you only pay for the storage of the states you actually explore. So I switched my implementation to use a hash table. Unfortunately٫ it was now significantly slower and profiling showed hash table lookups were the cause of the slowdown.

I thought about it and realized that I only needed the memory savings on levels of the tree with large lists٫ if I had two lists of 10٫000 elements٫ a 2d array would have 100 million slots. But if the lists only had
 -->
<!-- ^ It turns out it"s no longer in the implementation٫ I must have done it but realized later it didn"t really help. -->

<h3 id="more">More?</h3>

<p>My tool was now instant in most common cases and difficult cases were over 100x faster. But٫ on the very largest 10٫000+ line config files it would still take up to 5 minutes in the worst case if you made edits in multiple places. There were no longer any obvious hot spots in the profiles٫ I needed algorithmic improvements that let me search less possible paths.</p>

<p>I looked at my list of optimization ideas and there was only one left٫ which I had written down early on in the process when thinking about the correspondence between dynamic programming and path finding on a grid. It was just a few characters in a Markdown note that I had saved for if I was feeling ambitious and really needed it: “A*”.</p>

<h2 id="path-finding">Path Finding</h2>

<p>Back when I was designing the algorithm by thinking about it as a path finding problem٫ I thought “hey wait٫ if this is a path finding problem٫ why not use an actual path finding algorithm?” The first thing I realized is that the memoized recursion approach I was planning on taking was just a <a href="https://en.wikipedia.org/wiki/Depth-first_search">depth first search</a>٫ which can be a path finding algorithm٫ but not a particularly good one.</p>

<!-- As far as I can tell the bottom-up table-filling approach to dynamic programming corresponds most closely to [Dijkstra"s Algorithm](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm)٫ except the acyclic graph and known structure mean you don"t have to manually track the visited and unvi -->

<p>Could I use a better path finding algorithm? Breadth first search wouldn’t help much since the goal was near the maximum distance in bounds. However٫ <a href="https://en.wikipedia.org/wiki/A*_search_algorithm">A*</a>٫ perhaps the most famous path finding algorithm٫ seemed like it might help٫ if only I could come up with a good heuristic. So I wrote it down without thinking too much and came back to it later after I had done all my other optimizations.</p>

<p>The last time I learned A* was when I read <a href="http://shop.oreilly.com/product/9780596516246.do">Algorithms in a Nutshell</a> (good book) years ago and all I remembered was that it needed a priority queue and a good heuristic. I had a <a href="https://github.com/janestreet/core_kernel/blob/2e2bb4caedf0ca49d89735911578709434a780e2/src/heap_intf.ml">Heap</a> for the priority queue٫ but I didn’t remember how to actually implement it or what a good heuristic was٫ so <a href="https://en.wikipedia.org/wiki/A*_search_algorithm">to Wikipedia I went!</a>.</p>

<p>I learned that I needed a heuristic that never overestimated the remaining cost٫ and that ideally never decreased more than the cost of any move taken. One thing that satisfies those properties is the maximum of the costs of the two list suffixes from a location. This corresponds to the notion that a scoped config file that includes the contents of both config files can’t be smaller than either of the input files. This heuristic was easy to compute using the costed list representation I already had٫ which already has the cost of each suffix of the input lists.</p>

<p>With a heuristic and an understanding of A* in hand٫ I refactored the implementation of my algorithm to work by putting successor states in a priority queue based on their cost plus the heuristic remaining cost. This required changing each instance of recursion on my table into the creation of a <code class="language-plaintext highlighter-rouge">State</code> structure that encompassed if I was inside or outside of a <code class="language-plaintext highlighter-rouge">:date-switch</code>٫ and the current position.</p>

<p>I also had to make two changes to my data structures. First٫ since I was no longer using recursion to destructure my linked lists but was now indexing them٫ which is <code class="language-plaintext highlighter-rouge">O(n)</code>٫ I created arrays of the tails of my input costed lists so that random access was fast. Next٫ my solution still used <code class="language-plaintext highlighter-rouge">O(n^2)</code> memory in all cases due to the 2D array memoization table٫ so I switched that to a hash table from position tuples.</p>

<p>Profiling now showed a lot of time was then spent in hash table lookups٫ so I experimented with dynamically using a 2D array for small input lists (like were often found on the lower levels of the tree) and a hash table for larger input lists٫ but further profiling showed it didn’t increase performance much٫ probably because most of the lookups were in the larger lists٫ so I stuck with plain hash tables.</p>

<p>After a little debugging of off-by-one errors٫ I ran the program on my largest test case and it finished instantly. It was so fast I was suspicious it was broken and just skipping all the work٫ but sure enough it worked perfectly in every case I threw at it. The cost was something like <code class="language-plaintext highlighter-rouge">O(n * log(n) * e^2)</code> where <code class="language-plaintext highlighter-rouge">n</code> is the file size and <code class="language-plaintext highlighter-rouge">e</code> is the number of edits. Me and my mentor managed to think of some edge case trees where it might revert to <code class="language-plaintext highlighter-rouge">O(n^2)</code> behavior٫ and it still only scaled to config files of tens of thousands of lines rather than hundreds of thousands٫ but it was nearly instant for all cases that might actually occur٫ so it was good enough™.</p>

<p>I spent the remaining 3 days of my internship polishing up the user interface of the tool٫ cleaning up the code and writing lots of doc comments explaining my algorithm. I also gave a presentation to a bunch of the other engineers telling a shorter version of the story I’ve written here. That marked the end of my internship with Jane Street and one of the most interesting algorithmic problems I’ve ever worked on٫ despite it being part of a tool for editing configuration files.</p>

<h2 id="example-implementation">Example Implementation</h2>

<p>I was curious about how the approach of turning a dynamic programming problem into an A* path finding problem scaled and how applicable it was to other problems. So٫ I developed <a href="https://github.com/trishume/seqalign_pathing">an example implementation</a> of this approach in Rust for the <a href="https://en.wikipedia.org/wiki/Sequence_alignment">sequence alignment problem</a>٫ which <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein distance</a> is a specific instance of. It’s structured for simplicity and I haven’t optimized it at all٫ but it’s good enough to demonstrate the asymptotic improvements.</p>

<p>The <a href="https://github.com/trishume/seqalign_pathing/blob/master/src/lib.rs">core code of the algorithm</a> is fairly simple and is a good demonstration of the logic required to turn a dynamic programming algorithm into an A* path finding instance. It allows you to tune the weights of insertions/deletions٫ mismatches and matches of characters in the two strings٫ so that you can change it to be Levenshtein distance or some other instance of sequence alignment.</p>

<p>The heuristic it uses is based on splitting the remaining distance to the bottom right corner into two components: the minimum number of insertion/deletion moves necessary to get on the diagonal from the goal٫ and the minimum number of match moves necessary to get from that place on the diagonal to the goal. This represents the minimum possible cost required to reach the goal from any position without knowing what the actual best path is.</p>

<figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">fn</span> <span class="nf">diag</span><span class="p">(</span><span class="n">pos</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">Pos</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">i32</span> <span class="p">{</span>
    <span class="p">(</span><span class="n">pos</span><span class="err">.</span><span class="mi">1</span> <span class="k">as</span> <span class="nb">i32</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">pos</span><span class="err">.</span><span class="mi">0</span> <span class="k">as</span> <span class="nb">i32</span><span class="p">)</span>
<span class="p">}</span>

<span class="k">fn</span> <span class="nf">heuristic</span><span class="p">(</span><span class="n">pos</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">Pos</span><span class="p">٫</span> <span class="n">goal</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">Pos</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Score</span> <span class="p">{</span>
    <span class="c">// find the distance to the diagonal the goal is on</span>
    <span class="k">let</span> <span class="n">goal_diag</span> <span class="o">=</span> <span class="nf">diag</span><span class="p">(</span><span class="n">goal</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">our_diag</span> <span class="o">=</span> <span class="nf">diag</span><span class="p">(</span><span class="n">pos</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">indel_dist</span> <span class="o">=</span> <span class="p">(</span><span class="n">our_diag</span> <span class="o">-</span> <span class="n">goal_diag</span><span class="p">)</span><span class="nf">.abs</span><span class="p">();</span>
    <span class="c">// find the distance left after moving to the diagonal</span>
    <span class="k">let</span> <span class="n">total_dist</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">goal</span><span class="err">.</span><span class="mi">0</span> <span class="o">-</span> <span class="n">pos</span><span class="err">.</span><span class="mi">0</span><span class="p">٫</span> <span class="n">goal</span><span class="err">.</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pos</span><span class="err">.</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="nb">i32</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">match_dist</span> <span class="o">=</span> <span class="n">total_dist</span> <span class="o">-</span> <span class="n">indel_dist</span><span class="p">;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">indel_dist</span> <span class="o">*</span> <span class="n">INDEL</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">match_dist</span> <span class="o">*</span> <span class="n">MATCH</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p><img src="/assets/postassets/treediff/heuristic.png" alt="Heuristic diagram" /></p>

<h3 id="discoveries">Discoveries</h3>

<p>Here’s some things I learned by fiddling with the program and timing it:</p>

<ul>
  <li>As expected٫ the algorithm only tends to explore states along the diagonal of the grid٫ with the width of the area explored proportional to the edit distance. This suggests the running time is something like <code class="language-plaintext highlighter-rouge">O((a+b) * e^2)</code> where <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code> are the input lengths and <code class="language-plaintext highlighter-rouge">e</code> is the edit distance.</li>
  <li>Running it on a 10٫000 base pair gene sequence with an edit distance of 107 takes 0.26 seconds.</li>
  <li>Running it on a 10 megabyte random text file with 1 edit near the beginning and 2 near the end takes 20 seconds and evaluates 40 million states. This is a case where with the <code class="language-plaintext highlighter-rouge">O(n^2)</code> algorithm just allocating and zeroing <code class="language-plaintext highlighter-rouge">4*10^14</code> bytes of memory for a table with the naive algorithm would take forever. Demonstrating that this optimization does in fact provide an asymptotic speed up.</li>
  <li>It’s still way slower than specialized sequence alignment implementations like <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5408825/">Edlib</a>٫ probably asymptotically so. These implementations use all sorts of fancy tricks including fancy algorithmic tricks٫ SIMD and bit vectors to eke out maximum performance for bioinformatics applications. My implementation is at least way way simpler.</li>
  <li>Plain <a href="https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm">Dijkstra’s algorithm</a> (A* with a heuristic always returning 0) actually performs almost as well for Levenshtein distance because only edits have cost so it explores along the diagonal towards the goal along the path with less edits just because those have lower cost. However٫ if the problem has a cost for matching portions as well (like my original tree diffing problem) Dijkstra’s algorithm will explore in a blob expanding from the top left and be almost as slow as the naive algorithm.</li>
  <li>With a heuristic٫ Levenshtein-distance like instances where only edits have cost take about the same time to run as instances like my tree-diffing problem where matching segments also have cost.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>A* is an interesting technique that’s an easy way to accelerate a class of dynamic programming problems. It definitely works on any vaguely diff or edit-distance like problem٫ but it might extend to even more. If you want absolute peak performance on a simple algorithm there’s probably better techniques to use٫ I’d start by looking at what bioinformatics people do٫ but if you just want something easy and flexible this seems like a good technique٫ and it’s not one I’ve seen done before٫ and Google doesn’t turn up any results. It might even be novel٫ or it might just be that A* is a hard term to Google for٫ I’m interested to hear from anybody who’s seen something like this before.</p>

<hr />

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>A great place to work٫ highly recommend. I did get Jane Street’s permission before divulging the algorithm I wrote for them in this post. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
'),('http://thume.ca/2017/04/06/learning-through-job-diversity/', 'Things I"ve Learned Doing Internships', '1491436800000',  13, '
<p>I’m a student at the University of Waterloo٫ famous for its co-op program where students do 6 4-month work terms throughout their degree. I’ve now done <a href="http://thume.ca/resume/">7 internships</a> both within the program and outside it. Doing internships before one graduates is a great way of experiencing lots of different teams٫ work environments and even cities. This has allowed me to gain a much better idea of what kind of place I want to work after I graduate. Every job has taught me something genuinely new: my model of what factors are important to my enjoyment of a job has totally changed.</p>

<p>In this post I’ll share some of what I learned at each different company٫ especially the things that surprised me and went against conventional wisdom or practice.</p>

<h2 id="halogen-software">Halogen Software</h2>

<p>This was my first job٫ at a company that makes enterprise Java software for HR departments. Back then I was super enthused to have found a job٫ but nowadays this is the kind of place many of my friends would avoid just on the sound of it. There’s a meme in Waterloo of “Cali or bust” where students try desperately hard to get jobs in California and are very sad if they have to settle for enterprisey boring-sounding jobs.</p>

<p>The thing is٫ I enjoyed this job and had fun! My coworkers were great and despite working on software many would judge to be boring I found the work engaging.</p>

<p>At Halogen I learned that even companies that exemplify all the stereotypes of a boring company (Java٫ B2B٫ CRUD٫ cubicals٫ not in California) can be good enjoyable places to work. Just because your job isn’t at the hottest company in California doesn’t mean it will be miserable.</p>

<h2 id="the-eclipse-foundation">The Eclipse Foundation</h2>

<p>My second job was an unpaid co-op job for credit in high-school where I would spend the second half of every school day working. I worked on fixing bugs in the Eclipse IDE off of the bug tracker.</p>

<!-- I found this place by noticing it within 500m of my house on Google Maps and cold-calling them. I needed a job that was easy to get to for a half-day and it so happened that the organization behind the Eclipse Java IDE was close by. It turned out that they don"t employ anyone working on the IDE٫ but the person I phoned was a former programmer and agreed to supervise me. -->

<p>What I learned is that <em>tooling matters a lot</em>. It’s not that the Java tooling I was using allowed me to figure things out faster٫ it’s what allowed me to do things <em>at all</em>. I could wade in with no experience to a multi-million line code base and fix <a href="https://bugs.eclipse.org/bugs/show_bug.cgi?id=2369">11-year old bugs</a> because the Java and Eclipse tooling was <em>so good</em>. The ability to view references and definitions with total accuracy and to follow things in an excellent debugger was key. An interesting Eclipse-specific feature was that every part of Eclipse was a plugin٫ so instead of spending hours compiling all of Eclipse٫ you could download the source for the relevant plugin٫ load it٫ then immediately press “Run” and it would start a new instance of Eclipse almost immediately that cloned your copy of Eclipse except for that one plugin. To this day it is the largest project I’ve worked on but it had a very fast feedback loop and short setup time٫ it was quite impressive.</p>

<p>Almost all of Java’s faults as a language were made up for by tooling that was leagues better than any other popular language (excepting maybe C#). This job tempered my enthusiasm for how much more productive <code class="language-plaintext highlighter-rouge">$AWESOME_LANGUAGE</code> is than languages like Java and C# despite better design and handy features.</p>

<h2 id="shopify">Shopify</h2>

<p>I worked at Shopify three times: twice during high school summers and once as my first Waterloo co-op job. As such٫ I learned a fair amount there٫ but the lessons were sometimes spread out٫ so I’ve grouped them together.</p>

<h3 id="transparent-and-involved-executives-are-fantastic">Transparent and involved executives are fantastic</h3>

<p>The CEO of Shopify٫ <a href="http://www.theglobeandmail.com/report-on-business/rob-magazine/meet-our-ceo-of-the-year/article21734931/">Tobi Lütke</a>٫ is incredibly awesome. He started as the first developer٫ and he makes sure to stay afloat with the latest developments and will even weigh in on technical strategy if you tag him on Github. As an intern it was pretty awesome to sit down on a couch with the CEO and hack on <a href="https://github.com/Shopify/liquid">Liquid</a> together. He’s also very transparent and makes sure everything about the company is too. For example٫ every couple weeks he does a frank AMA where he addresses questions submitted and voted on by employees and does a good job of giving detailed answers and not dodging.</p>

<p>On other fridays٫ employees give lightning talks about what they are working on. This is where one story that really exemplifies the difference between a great CEO and a stereotypical one happened: I was giving a short talk about flaws in the <a href="https://github.com/Shopify/liquid">Liquid</a> template parser and how it would accept almost anything without a syntax error٫ and <a href="https://github.com/Shopify/liquid/pull/235">my work in replacing it</a>. My next term I learned that while watching my talk he’d joked to the person next to him  “that kid’s got courage”٫ which clued me in that at most other companies٫ trash talking code the CEO wrote that powered an important part of the product٫ in front of the entire company٫ would’ve been a “career limiting move” to put it lightly. I had talked to Tobi about the parser rewrite before the talk and he was in fact the first one to admit that the parser had issues٫ he had even bought a book on parsers hoping to fix it himself someday٫ so I knew I was safe giving the talk. Regardless٫ it still shows the benefits of having a great transparent CEO who does his best to rid the company of stifling corporate politics.</p>

<h3 id="good-managers-make-a-big-difference">Good managers make a big difference</h3>

<p>Up until my last internship at Shopify I’d had good team leads٫ supervisors and managers. I recognized that they were important but they didn’t really affect me or my work that much. This sounds like the lead up to a bad manager story٫ but actually the thing that changed my mind was having a <em>fantastic</em> team lead/manager.</p>

<p>He was dedicated٫ competent٫ funny٫ relentlessly positive٫ an excellent advocate for me and the rest of the team. He was also a developer but he spent most of his time being team lead٫ keeping everything on target٫ prioritizing٫ problem solving and making sure we were on target to ship on time.</p>

<p>He had a moderate impact on my productivity: prioritizing٫ distributing tasks٫ answering questions and pair programming on difficult tasks. However٫ he had a tremendous impact on environment of being on the team and thus my enjoyment of the job. I learned that having a good manager helps things run smoothly٫ but having an excellent manager can make a good job <em>great</em>. I hear that having a bad manager can make a good job terrible٫ but luckily I have yet to experience that (<em>crosses fingers</em>).</p>

<h3 id="if-everything-else-is-done-right-the-task-doesnt-matter">If everything else is done right٫ the task doesn’t matter</h3>

<p>The importance of a good manager ties into my next point٫ which is that on that same team I was working on a CRUD web app٫ a stereotypically boring task. However٫ I really enjoyed that job٫ and through that I learned that when a company gets <em>everything else right</em> it doesn’t matter very much what the actual task is.</p>

<p>When I was working at Shopify the third time٫ my team was great٫ my manager was great٫ the culture was great٫ the office was great٫ the tools were great٫ the language was great٫ the food was great٫ the focus on quality was great٫ the technical decision-making was great. It didn’t matter that I was working on redesigning a web form.</p>

<p>This isn’t to say the task doesn’t matter at all. If the task was actually an unpleasant one and not just a less exciting form of programming٫ I wouldn’t have enjoyed it nearly as much.</p>

<h2 id="the-university-of-waterloo-hci-lab">The University of Waterloo HCI Lab</h2>

<p>My next term٫ following my general strategy of trying out as many different jobs as possible٫ despite enjoying my previous job so much I tried out research. I worked on a system that fused eye tracking٫ head tracking and sound recognition to provide <a href="https://github.com/trishume/PolyMouse">a hands-free mouse alternative that I could use as quickly as I can a trackpad</a>. I also worked on custom computer vision systems for eye tracking and marker tracking٫ as well as developing custom audio recognition algorithms. I basically got free reign to work on a side project I had as a job and do exactly the work I wanted and found interesting.</p>

<h3 id="further-learning-on-project-coolness">Further learning on project coolness</h3>

<p>This switch from working on CRUD web apps to a cool project that I had chose myself furthered my learning from the previous term. Despite working on my choice of the most interesting topic٫ although I definitely enjoyed the job٫ I didn’t enjoy it as much as my previous internship at Shopify.</p>

<p>There were two components to this:</p>

<p>First٫ the magnitude in difference of how interesting a project sounds doesn’t correspond to the magnitude of difference in how interesting working on a project is. Working on cool computer vision systems involves a lot of architecture٫ plumbing٫ refactoring and debugging. Most of these tasks are the same kind of tasks one does when working on a CRUD web app. Even when I was working on redesigning a web form there were times when I had to go sit away from the computer and think really hard with a notepad about architectural issues and how to design the system in a clean and robust way. Despite massive differences in how interesting they sounded٫ the computer vision system only involved moderately more interesting difficult problems and slightly less boring plumbing than the CRUD web app.</p>

<p>Secondly٫ I found that even when I was working on the interesting challenging parts٫ I enjoyed and valued the challenge and learning٫ but not as much as I expected to value them before I started the job. The difference in fun was tangible but not as extreme as I had imagined.</p>

<p>Previous to this term I had systematically overvalued the importance of the challenge and interestingness of the task. I also see this a lot when people I know choose jobs٫ they’ll sacrifice pay٫ company quality٫ location choice٫ team٫ culture٫ perks and pretty much everything else if it means they can work on something cool like compilers for machine learning on big data. I did exactly this as well for my research term.</p>

<p>Interestingness of the work is still a significant positive factor when I’m choosing a job٫ it just no longer overrides all other considerations٫ it’s more of a factor I use to decide between two good options.</p>

<h3 id="teams">Teams</h3>

<p>One part of the difference between working in the lab and working at Shopify was that in the lab I was working alone on my own project. There were other people in the lab that I talked to occasionally but we didn’t really work together or even eat lunch together.</p>

<p>I realized that great coworkers are an important part of why I enjoyed my previous jobs.</p>

<h2 id="jane-street">Jane Street</h2>

<p>For my next internship I worked at <a href="https://www.janestreet.com">Jane Street</a> in London UK. I worked on developer tools٫ low-latency networking code٫ rendering huge tables and tree-diffing algorithms٫ all in OCaml. I had a great time٫ both with the interesting work and all the other parts of working there.</p>

<h3 id="interviewing">Interviewing</h3>

<p>The first thing that impressed me about Jane Street٫ because it was before I even started٫ was how good their interviewing system is. The questions seemed rather good at testing programming ability rather than algorithm knowledge or flashes of inspiration. They were about thinking hard٫ puzzling out all the cases and extracting a clean design. I was allowed to use a whiteboard٫ their laptop٫ or my own laptop٫ with any language I wanted. Each interview had two interviewers in the room٫ I assume for higher judgement reliability for the time spent. There were a reasonable number of interviews packed in to one day٫ and I got an offer a fairly short amount of time after I interviewed.</p>

<p>Later I learned that they have a set of people who specialize in interviewing and do substantially more interviews because they like to and for greater consistency and skill specialization. Each question is well-specified and alpha and beta tested before being used for decision-making. Becoming the lead of the two interviewers for a specific question requires having shadowed someone else who knows it well.</p>

<p>This interview process seems substantially better than any other process that I have heard of (with the possible exception of the Matasano process <a href="https://news.ycombinator.com/user?id=tptacek">tptacek on HN</a> talks about٫ but I haven’t looked into that much). It addresses many of the common criticisms of tech company interviews like algorithm bingo٫ requiring flashes of inspiration٫ requiring coding on a whiteboard٫ poor question design٫ inexperienced interviewers and lack of inter-rater reliability. It seems like it would have a very low false positive rate٫ and a lower (though still significant) false negative rate than other interview processes I’ve seen.</p>

<h3 id="agency">Agency</h3>

<p>Another thing that impressed me is the level of agency afforded to employees. The management structure was extremely flat٫ and everyone’s job was basically either “Do what’s best for the company٫ probably coding” or “Do what’s best for the company٫ probably trading” with some people in between and a few “… with some managing” thrown in.</p>

<p>For certain type of company٫ this seems to work excellently. Competent people know that for decisions with sufficiently high stakes it is a good idea to seek input from others٫ and expend effort to make the right decision proportional to the stakes. This means there’s little need for explicit policies٫ procedures and approval chains. That doesn’t mean the value they provide is absent٫ they just happen whenever they make sense for the task at hand٫ like ops checklists and working with other people to make big decisions correctly. I was surprised by the extent to which “Do what’s best” gets the benefits of standard corporate practices when helpful٫ but avoids the pitfalls. I still don’t believe this is broadly applicable though٫ it needs a certain type of company to work well.</p>

<h2 id="conclusion">Conclusion</h2>

<p>My model of what a good job and an effective company looks like have changed significantly since before I started working. Since starting at Waterloo I’ve even precommitted to not doing repeat internships٫ so as to maximize the variety of jobs٫ locations٫ and companies I experience. It’s tempting to return when I have a great time and a job is the best one I’ve ever had٫ but I remember that the only reason I took <em>that</em> job was that I didn’t return to the <em>previous</em> best job I ever had.</p>

<p>I’m looking forward to further learning at 3 more internships before I graduate٫ including one in San Francisco at Google this summer. After I graduate٫ I’ll look hard at all the different jobs I’ve had and will have a good model with which to decide what I want to do next. This will likely be returning to my favourite past company٫ but I might also use this information to choose a brand new path I’m confident is better.</p>
'),('http://thume.ca/2017/03/04/my-text-editor-journey-vim-spacemacs-atom-and-sublime-text/', 'My Text Editor Journey: Vim٫ Spacemacs٫ Atom and Sublime Text', '1488585600000',  13, '
<p>I currently use a highly customized Sublime Text 3 as my text editor for
almost all programming. However٫ people are often surprised to learn that I’ve
used Vim for 6 months٫ Emacs/Spacemacs for 10 months (including much elisp
hacking) and Atom for a month٫ yet I still prefer Sublime.</p>

<p>This post explains my journey between text editors٫ what I learned٫ what I
like and dislike about each of them٫ and why in the end I’ve chosen Sublime
(for now). Most detailed is <a href="#spacemacs">my reasoning for abandoning Spacemacs</a>٫ despite
being a top contributor and power user٫ although many of
my criticisms of Vim also apply to Spacemacs (and vice versa).</p>

<h2 id="the-early-days-textmate--sublime-text-2">The Early Days: Textmate &amp; Sublime Text 2</h2>

<p>My text editor when I first learned programming was Textmate٫ and I stuck with
it for a few years (I forget how many) before I at some point switched to
Sublime Text 2’s trial٫ and then paid for a license.</p>

<p>Back then I only used the basics: syntax highlighting٫ find/replace٫
autocomplete٫ file tree… I didn’t know any keyboard shortcuts besides
standard OS ones like copy-paste and undo. I used the mouse for all selection
and eventually learned the Sublime command pallete and “open file in project”
pallete.</p>

<p>This setup didn’t cause me any trouble٫ I was productive and nothing was
painful. But٫ I heard tell of the true power one gained upon learning to use a
<em>real</em> editor like Vim or Emacs. I watched screencasts where Vim masters would
perform impressive editing operations in a couple keystrokes.</p>

<h2 id="vim-a-taste-of-power">Vim: A Taste of Power</h2>

<p>In late 2012 I switched to Vim. I learned the keyboard shortcuts with <code class="language-plaintext highlighter-rouge">vimtutor</code>
and printed cheat sheets. I read tons of blog articles (often conflicting) on
learning and using Vim the right way.</p>

<p>I tried using a blank <code class="language-plaintext highlighter-rouge">.vimrc</code> and building pieces from scratch making sure I
understood what each piece did each time. However٫ this was taking far too
long٫ my editor was missing key functionality from Sublime and Textmate like a
file tree٫ good autocomplete٫ open in project٫ and support for languages I
used. It was also ugly.</p>

<p>So I started using the <a href="https://github.com/spf13/spf13-vim">spf13</a> Vim
distribution. It was nice٫ and had most of the features I wanted. You can
still find my modified spf13-based vimrc <a href="https://github.com/trishume/dotfiles/tree/master/vim%2B">here</a>.</p>

<p><img src="/assets/postassets/editors/vim.png" alt="Vim" /></p>

<p>I was reasonably happy with this setup and continued using it for over 6 months.</p>

<p>However٫ there were many pain points. One of these was that things often
didn’t work. For example٫ my tab key was bound to tons of different things
like autocomplete٫ snippet expansion٫ indentation٫ moving between snippet
fields and inserting the literal tab character. Many of those overrode each
other in different contexts٫ but very often it chose the wrong one. I ended up
fixing this somewhat but not completely٫ but I didn’t have this issue in
Sublime because everything was designed to work together so the tab key just
always did what I wanted. Even after I fixed it٫ the hours I spent
diagnosing the issue٫ figuring out how to resolve the conflicts٫ implementing
it٫ then re-learning my muscle memory probably erased weeks of sub-
second Vim speed gains.</p>

<p>Another issue I had was that Vim was mouse-hostile. I was fully aware that the
Vim philosophy is to just never use the mouse. However٫ even with plugins like
<a href="https://github.com/easymotion/vim-easymotion">EasyMotion</a> and ideal vim
shortcut use the keyboard is slower for some selection tasks like selecting a
range of text far from the cursor than the mouse is. Often using Vim shortcuts
felt faster because my brain was engaged figuring out the optimal combination
of motions and looking for EasyMotion hints٫ but whenever I timed myself I was
consistently much slower than I was with the mouse. I’m only talking about
long range selection and cursor movement here٫ I totally concede that keyboard
shortcuts are better for short range movement and selection. Vim wasn’t that
bad for the mouse٫ but lots of plugins didn’t really work well with it and
mouse selection often worked weirdly in some states.</p>

<h2 id="back-to-sublime-with-a-stint-in-atom">Back to Sublime (with a stint in Atom)</h2>

<p>I realized that I didn’t like fighting my editor and loved the ease of use and
mouse support of Sublime. However٫ I also loved the power of Vim’s keyboard
model. Luckily٫ I could use <a href="https://github.com/guillermooo/Vintageous">Vintageous</a>.</p>

<p>This way I could get all the power I liked about Vim with all the niceties of
Sublime.</p>

<p>In fact٫ Vintageous is arguably more powerful than Vim itself because it works
with multiple cursors. Using multiple cursors with Vim bindings is incredible٫
it’s basically the same power as Vim macros give you٫ except you can compose
them on the fly with instant feedback about what commands did at each place
you wanted to use them (see gif below). I found I rarely used macros with Vim because I had to
think hard about which commands I could use that would work on every instance
and make sure I didn’t screw anything up٫ then figure out how I wanted to run
the macro for each location٫ but with Sublime it was so easy I did it all the
time. Yes٫ I know both Vim and Emacs have multiple cursor plugins٫ but they are
hacks and don’t seamlessly work with all commands and together with the mouse.</p>

<p><img src="/assets/postassets/editors/sublime_vim.gif" alt="Sublime Vim" /></p>

<p>I started using Sublime as a power user’s text editor just like I had used Vim.
I learned the keyboard shortcuts٫ read about the functionality and installed plugins.</p>

<p>For a month I also tried out Atom. I pretty much replicated my Sublime Text
setup with the equivalent Atom plugins٫ plus some extras that only Atom offered.
However٫ I preferred Sublime’s speed. It wasn’t just that some editing operations
had a bit of latency٫ but that Sublime could offer features that Atom couldn’t
because of its speed. For example Sublime’s “open in project” panel instantly
previews the files as you type because it can load files in milliseconds٫ and search
is incremental by default.</p>

<p>I used this setup quite happily from mid-2013 to late-2014. However٫ I started
thinking about the possibility of using Emacs with <code class="language-plaintext highlighter-rouge">evil-mode</code>. I’d heard its
Vim emulation was fantastic and the possibility of using Emacs lisp to craft
the perfect text editing experience given time was enticing.</p>

<p>I started looking around at various Emacs starter kits like <a href="https://github.com/bbatsov/prelude">Prelude</a>
and tried out a few. I read Emacs articles٫ documentation and blog posts
about people’s Emacs configs. However٫ everything had really horrible convoluted
hard to remember keyboard shortcuts that didn’t fit well with Vim’s.</p>

<h2 id="spacemacs">Spacemacs</h2>

<p><a name="spacemacs"></a></p>

<p>Then٫ I found Spacemacs. It was exactly what I was looking for. It was pretty٫
integrated Vim and Emacs functionality in an interesting and discoverable way٫
and promised to have everything set up to work out of the box. Somehow this
project only had around 12 stars on Github and no other contributors. It
seemed the creator had poured tons of effort into making a fantastic project٫
but unlike most people’s dotfiles٫ he put effort and thought into making it
adaptable to individual needs and documenting how to do so. I was stunned that
this project only had ~20 stars and no other contributors.</p>

<p>So I downloaded it٫ started working on my own <code class="language-plaintext highlighter-rouge">.spacemacs</code> file and joined the
Gitter chat the creator had set up. A little while later I submitted the <a href="https://github.com/syl20bnr/spacemacs/pull/19">first
contribution</a> to the project.</p>

<p>Little did I know at that point that the reason it only had 20 stars was that
by chance and lots of Googling I had just stumbled upon it earlier than
everyone else. Over the coming weeks I continued tweaking and sending PRs and
other early adopters like <a href="https://github.com/cestdiego">Diego</a> trickled in to
the chat and started contributing.</p>

<p>As I used Spacemacs I often noticed things that worked poorly or not at all.
I kept steadily fixing most problems I found and adding new contribution layers
for the things I wanted. When I was using Spacemacs for something where I had
already fixed most of the bugs٫ it was quite nice and felt efficient.</p>

<p>I continued using Spacemacs for around 6 months and maintained my position
as top contributor for most of that time. I helped newbies out in the Gitter
chat٫ triaged PRs and contributed and maintained a few different layers.</p>

<p>I thouroughly enjoyed contributing to Spacemacs٫ but nearly everything I
contributed was fixing a bug or annoyance I encountered while trying to get
something done٫ often writing the elisp to fix an earlier problem.</p>

<h3 id="brokenness">Brokenness</h3>

<p>These yak-shaving tasks ranged from <a href="https://github.com/syl20bnr/spacemacs/pull/174">fixing annoying keybinding conflicts</a> that Sublime Text had built-in logic for٫
to <a href="https://github.com/syl20bnr/spacemacs/pull/58/files">getting LaTeX support to work</a>. I even <a href="https://github.com/Hammerspoon/hammerspoon/pull/300">wrote a general mechanism for tabbing OSX windows</a> to get around how bad all the Emacs tab/workspace plugins were.
I definitely <a href="https://github.com/syl20bnr/spacemacs/pull/76">noticed my annoyance</a>
but I ignored it since I was having fun and I had hope that things would get better after more work.</p>

<p><img src="/assets/postassets/editors/spacemacs.png" alt="Spacemacs Tabs" /></p>

<p>However٫ after six months of making almost no progress on other projects while
discovering and fixing bugs and implementing things I missed from other
editors٫ I realized that there might not be an end. Part of the problem is
that I love learning new languages and doing different kinds of projects. Other
Spacemacs users might make a few fixes here and there for their primary use case٫
whereas I was stuck adding support for <a href="https://github.com/syl20bnr/spacemacs/pull/1415">D</a>٫
<a href="https://github.com/syl20bnr/spacemacs/pull/937">Racket٫ Nim and Rust</a> and then
fixing the bugs I exposed when changing my workflow.</p>

<p>I think the underlying reason is that everything in Emacs٫ and especially
Spacemacs٫ is a hack. Core Emacs offers almost nothing and everything is
layered on top as ad-hoc Emacs Lisp additions. Different third-party plugins
and to some extent base functionality step on each others toes and make
conflicting assumptions all the time. One particularly bad example I ran into
is my Emacs hanging mysteriously when autocompleting on some two character
suffixes. After much searching it turned out to be a <a href="https://github.com/syl20bnr/spacemacs/issues/2654">known issue</a> where if what I was
completing looked like a domain name Emacs would try to ping it because of an
interaction between autocompletion٫ file finding٫ and remote server support.</p>

<h3 id="lack-of-consistency-and-discoverability">Lack of Consistency and Discoverability</h3>

<p>Another problem with this pile-of-hacks design is that nothing was consistent
or discoverable. Every moment I saved on common operations due to efficient
keyboard shortcuts was cancelled out by a minute spent searching for how to do
a less common operation that I didn’t do often enough to memorize.</p>

<p>An example of an occasional workflow I can do in Sublime is:</p>

<ul>
  <li>Paste my clipboard into the search box.</li>
  <li>Search all files in a project for without regex support (useful when searching for a string with special
characters that you don’t want to escape)٫ case insensitively.</li>
  <li>Narrow it down to a glob of certain files without re-typing my query.</li>
  <li>Edit my query slightly to refine the results٫ again without re-typing it.</li>
  <li>Replace the content of all those occurences once satisfied.</li>
</ul>

<p>I tried to do this in Emacs once٫ and had to spend a ton of Googling and investigating <code class="language-plaintext highlighter-rouge">M-x</code> listings:</p>

<ul>
  <li>Look up how to search in project without regex (I’ve never figured out a way to do this)</li>
  <li>Look up the shortcut for pasting into the minibuffer (I use Evil so I can’t use <code class="language-plaintext highlighter-rouge">p</code> like usual).</li>
  <li>Hope that the command is Helm-based so I can edit my query٫ otherwise re-type everything to narrow it down.</li>
  <li>Look up how to replace in project without regex٫ oops it’s an entirely different command from searching.</li>
  <li>Re-enter everything into the new command and run it.</li>
</ul>

<p><img src="/assets/postassets/editors/sublime_find.png" alt="Sublime"s fancy find dialog" /></p>

<h3 id="navigating-multiple-files">Navigating Multiple Files</h3>

<p>The last major problem I had was how difficult it was to work with code spread
across multiple files compared to Sublime Text.</p>

<p>There’s three main ways for working with files in Emacs: buffers٫ files and windows.</p>

<p>I tried using buffers but the problem is that buffer switching is slow and
difficult. It only takes one keystroke to switch to the most recently opened
other buffer٫ if you remember which that is٫ but switching to other buffers
requires waiting for a list to show٫ reading it٫ then multiple additional keys to select the right one.
Buffers also tend to proliferate like mad and these lists end up enormous taking many keys to filter to the right one.
They are also nearly impossible to navigate with the mouse if I’m reading code and that’s where my hand is.</p>

<p>Navigating using normal <code class="language-plaintext highlighter-rouge">find-file</code> and <code class="language-plaintext highlighter-rouge">helm</code> mechanics has a similar problem:
switching is just slow. It takes a lot of key strokes٫ and those strokes sometimes
involve waiting for a list to appear that you can read.</p>

<p>Having your frame/screen split into a bunch of windows (Emacs reverses the
meaning of window and frame from every other editor) in Spacemacs has the
advantage that each window has a number on it and you can hit <code class="language-plaintext highlighter-rouge">SPC+1</code> to
<code class="language-plaintext highlighter-rouge">SPC+9</code> to switch directly to them. This is great in that it is very fast and
easy to remember٫ find and see where you want to go and how to get there. The
problem is that you sacrifice screen real estate for every new file you work
with. I normally ameliorate this with <a href="https://github.com/roman/golden-ratio.el">golden-ratio</a>
mode٫ which shrinks unfocused windows٫ but they still take up space.</p>

<p>With Sublime Text I use tabs٫ which are amazing. I can switch quickly and directly
between files with <code class="language-plaintext highlighter-rouge">cmd+1</code> to <code class="language-plaintext highlighter-rouge">cmd+9</code>٫ see all the files I’m working with at a glance٫
and navigate with the mouse if I want to. I can also easily rearrange tabs so that the
most frequently used and important files are on lower consistent numbers that I can <a href="https://en.wikipedia.org/wiki/Subitizing">subitize</a>.
I can even use <a href="https://packagecontrol.io/packages/Zen%20Tabs">ZenTabs</a> to ensure that I only
ever have my 9 most recently used files open in tabs٫ eliminating buffer proliferation.
Infrequent but useful actions like moving a file between windows and panes٫ and copying the file
path are all obvious discoverable mouse actions. The file I’m working on always fills the full screen٫
unless I want to reference other code in another pane. When the file I want isn’t a tab
I can open it with “Goto Anything”٫ which is similar in speed to narrowing to a buffer by name.
When I want to navigate based on a project’s directory structure I have access to a fantastic
file tree.</p>

<p>Yes٫ Emacs has plugins to add tabs but they are hacks. They’re ugly٫ slow٫ break when used
with other plugins٫ don’t have good keyboard shortcuts٫ and display tons of useless buffers I don’t care about.</p>

<p>When I watch friends and coworkers use Vim and Emacs this is the thing I
notice most. They look super efficient since they’re furiously typing things
or navigating directories٫ but often the file they are opening is one that
they looked at just a minute ago and would have taken me a single keystroke to
switch to. They however have to type a bunch of characters to narrow to the
buffer name. I even frequently see Vim/Emacs users opening files by
navigating directories when I would have just typed a few characters into
“Goto Anything”. Emacs and Vim also have ways to fuzzy search for a file in a
project٫ but the heuristics and tools are often so bad and slow that they give
up and fall back on manually finding the file. I’ve never seen a Vim or Emacs
users who navigates between files as fast as I do in Sublime.</p>

<h3 id="realization">Realization</h3>

<p>I realized that despite all my work and the work of other contributors using
Emacs was still a pain and I longed for the just-works nature of Sublime Text.
It didn’t help that many operations in Spacemacs had surprisingly high latency
(similar to Atom) and many things were ugly (like the file tree). I said my goodbyes
to the Spacemacs community and headed back to Sublime Text.</p>

<p>I still think Spacemacs is overall quite good though. If you’re someone who
mainly codes in one language٫ especially a popular one٫ then you can get
Spacemacs set up to do exactly what you want٫ and the huge community nowadays
means that either the bugs will have been fixed or you can easily get help
with the ones you encounter. I’ve listed a bunch of disadvantages٫ but Emacs
has powerful features that Sublime doesn’t٫ I just didn’t like what I had to
give up to get them.</p>

<h2 id="sublime-text-3-back-with-vengeance">Sublime Text 3: Back With Vengeance</h2>

<p>So I switched back to Sublime Text 3٫ but just like after Vim٫ I took some of the
things I enjoyed back with me. I updated my plugin and keybinding arsenal to include
many of the handy things I used in Spacemacs.</p>

<p><img src="/assets/postassets/editors/sublime.png" alt="Sublime Text 3" /></p>

<p>One thing I really enjoyed in Emacs was <a href="https://magit.vc">Magit</a>٫ so I installed
<a href="https://github.com/divmain/GitSavvy">GitSavvy</a> in Sublime and found it had almost
everything I liked about Magit. I even like its workflow marginally better and the
Github integration is top notch.</p>

<p>I set up the <a href="https://github.com/deanishe/alfred-repos">Alfred Git Repos</a> workflow
to replicate opening projects with Projectile٫ and used my <a href="https://github.com/Hammerspoon/hammerspoon/pull/300">OSX window tabbing plugin</a>
to manage my Sublime Windows as well.</p>

<p>The fanciest thing I did was create <a href="https://github.com/trishume/SublimeTect">my own set of keybindings</a>
that work like Vim except with the palm keys of <a href="/2014/09/08/creating-a-keyboard-1-hardware/">my custom keyboard</a>
as the mode. That way it is faster to quickly do movement and editing actions in
the middle of writing. It also synergizes way better with the mouse because
I never am in an unexpected mode when I use it and then move back to the keyboard
since they physical state of my hands is the state of the editor. I still drop into
Vintageous mode for fancier editing though.</p>

<p>And all this took me only a few evenings to get to a point where I was happier
with it than the Spacemacs setup that had taken me six months. I’ve been using
this setup happily since mid-2015 with only a couple bugs which were quickly
fixed٫ despite using the dev builds of ST3 and many plugins it’s been orders
of magnitude more reliable than Emacs.</p>

<h2 id="jane-street">Jane Street</h2>

<p>Then I went to work at <a href="https://www.janestreet.com">Jane Street</a> for an internship
and ended up migrating back to Spacemacs for a little while. Jane Street has a bunch
of internal Emacs tooling٫ and even a bunch of custom integration with Spacemacs٫
along with much more mature tooling for OCaml than Sublime Text.</p>

<p>It was mostly pretty good٫ but far from smooth sailing. Various internal
and external Emacs plugins I used conflicted on their idea of where windows
should go and took over other windows٫ almost actively replacing whichever
window I cared about most. I encountered tons of bugs٫ both large and small.
Many of these I ended up patching myself٫ either with dotfile snippets or <a href="https://github.com/ocaml/tuareg/pull/99">pull</a> <a href="https://github.com/ocaml/tuareg/pull/103">requests</a>.</p>

<p>Not only did I encounter over 20 different Emacs٫ Spacemacs and plugin bugs
(some annoying me quite regularly) during my four months٫ but there were other
problems. Jane Street’s massive code base made many plugins slow to a crawl.
Synchronous autocompletion with Merlin occasionally hung Emacs. Using <code class="language-plaintext highlighter-rouge">helm-projectile</code>
was unbearable without caching and slow even with it. Until I disabled a bunch
of hooks saving files took seconds due to <code class="language-plaintext highlighter-rouge">hg</code> commands running slowly on the large repo.</p>

<p>Eventually I talked to the one guy using Sublime Text at Jane Street and got
his set of plugins and settings for working on Jane Street’s OCaml with Sublime.
I modied the <a href="https://github.com/cynddl/sublime-text-merlin">Sublime Merlin</a> plugin
to support <a href="https://github.com/jbrooksuk/Intellitip">tooltips</a> that showed the inferred
type of an expression and clickable links to the file of definition and declaration.</p>

<p>I then started using Sublime Text for sprees of reading code٫ but not for writing it.
Sublime still had far worse support for building and indenting Jane Street code.
But٫ this way I could understand things faster by using quick fuzzy search of files٫
excellent tabs٫ smooth scrolling with the mouse٫ and tooltip links to navigate the codebase.</p>

<p>Eventually I started using Sublime for editing as well٫ after I improved indenting٫
highlighting and autocompletion slightly. I still kept Emacs open to run the source
control٫ <a href="https://github.com/janestreet/iron">code review</a> and <a href="https://github.com/janestreet/jenga">Jenga build</a> plugins٫
but I set up elisp so that it navigated to compile errors in both Sublime Text and Emacs.
This offered an excellent compromise between nice plugins and a good editor that I was happy with.</p>

<p>Despite all the additional functionality and improvements I made to Sublime٫ I actually
think I spent less time on getting Sublime to work than on fixing٫ debugging and setting
up Spacemacs while I was there.</p>

<h2 id="closing-thoughts">Closing Thoughts</h2>

<p>Overall٫ I’m still very satisfied with Sublime Text. I think text editors could
go a lot further than they are now٫ but so could most software. I feel very
productive٫ I never fight my editor٫ and it works for any language I throw at it.</p>

<p>I would love it if Sublime was open source٫ or if there was an open source editor
that was as good. However٫ I realize that many of the reasons I love Sublime
wouldn’t be possible without it making money. The reason the creator(s) can pour
so much effort and care into every detail is that Jon (and now also Will) can work
on it full time for years. No other text editor has a custom cross-platform UI toolkit٫
a custom parallel regex engine٫ and incredibly fast indexing٫ search and editing engines.</p>

<p>I also realize that in some respects Sublime’s rather limited plugin API is an advantage.
Unlike Emacs/Vim/Atom I rarely have to worry about plugins slowing down my experience
by accidentally doing something synchronously on the entire file٫ since the API almost enforces
asynchronous design. No plugin can break core functionality or slow startup times.
Plugins are forced to work only in ways where it is difficult to conflict with each other
since two plugins can’t implement hacks in the internals that interfere with each other.
When Emacs plugins implement “helpful” hacks to basic functionality that conflict and break
things٫ my approach is often to disable them since I rarely want these hacks anyway.</p>

<p>Sublime can also get faster and better every release because they don’t have to worry as much
about piles of hacks restricting how they can change their internals. Like how Atom constantly
has to <a href="http://blog.atom.io/2014/07/02/moving-atom-to-react.html">deprecate old APIs</a> whenever they restructure to improve performance.</p>

<p>Also٫ the recent dev builds have patched what I think was the number one
hole in Sublime’s plugin API: tooltips and inline annotations. Now plugins can
implement <a href="https://github.com/facelessuser/ColorHelper">fancy custom tooltips</a>
with links and colours and formatting using a subset of HTML. This same HTML
subset can also be used to inject “phantoms”: rich text annotations of code
for things like previewing LaTeX formulae٫ colours٫ types٫ lints and errors.
This should allow most of the useful plugins that previously were only
possible in Atom/Emacs to be ported to Sublime٫ but since it is implemented
centrally instead of a bunch of different ways it will work seamlessly and
consistently.</p>

<p>I’m optimistic for the future of Sublime Text. I’d love to see a new editor that’s open source
and as fast٫ nice and powerful as Sublime٫ but I don’t expect to since it would be a ton of work.
Visual Studio Code looks pretty awesome though٫ if I was writing Javascript I’d consider it for the
excellent tooling integration٫ but for less common languages it doesn’t look any better than Sublime.</p>

<p>I wrote this post because I often find myself justifying my use of Sublime Text to
Vim and Emacs users. They often look at Sublime users as people who just haven’t put
in the effort to learn a <em>real power user’s text editor</em>. They’re confused when they learn
that I have tried Vim and Emacs extensively and still choose to use what they see as
a basic newbie editor. I hope this post explains why Sublime is an excellent choice
for a highly customizable power user’s text editor.</p>

<h2 id="edit-faq">Edit: FAQ</h2>

<p>Some responses to questions I’ve seen raised after posting this:</p>

<h3 id="you-just-havent-learned-vim-a-real-vim-user-could-do-long-distance-text-selection-faster">You just haven’t learned Vim. A real Vim user could do long distance text selection faster.</h3>

<p>I think I know vim quite well٫ I’ve been using vim bindings for 5 years now across varying editors. I know almost all Vim bindings.</p>

<p>How about a test? Suppose my cursor is on line 198 of <a href="https://github.com/trishume/syntect/blob/ef3b99b06b72e89b7a0036969897751034422f5a/src/parsing/parser.rs">this file</a> I want to copy <code class="language-plaintext highlighter-rouge">match_pat.has_captures &amp;&amp; cur_level.captures.is_some()</code> on line 172. If you give me an efficient sequence of vim bindings for that movement I can tell you if I know what everything does without looking it up.</p>

<p>I think a more apt criticism would be that I think too slowly to use Vim. I can figure out that “26j4wy10e” does what I want٫ and at my normal english characters/second typing speed that is faster than doing the selection with my mouse. However٫ when I actually try and do that without figuring it out ahead of time I take longer to read٫ count and figure out the right numbers and actions٫ then type the individual characters (which due to muscle memory for english I’m slower at than typing english). I end up being slower than the mouse٫ and with a higher mental load.</p>

<p>You could say I just need to “git gud” and practice٫ but if practicing for hours a day for 5 years doesn’t get me to the point that I’m better than the mouse٫ I think it’s time to say that maybe it isn’t a lack of practice. More likely it’s an innate skill difference٫ processing speed٫ counting٫ typing coordination٫ or a combination of the above. I do actually use Vim bindings a lot of the time٫ I know them well٫ and I know when it is faster for me to use the mouse.</p>

<p>That all presumes that there exists a substantial number of people who are faster in practice at long distance text selection with vim shortcuts than I am with the mouse. I have yet to see someone where I can confidently say that is the case٫ and I’ve watched a reasonable number of vim users. Some are within the margin of error where I would have to do a timed race with a stopwatch٫ but I haven’t seen any that are clearly meaningfully faster. I guess everyone I’ve seen using vim (including many 5+ year users) could be a “vim n00b”٫ but that sounds a bit “no true scotsman”-like.</p>

<h3 id="if-you-used-stock-emacs-without-all-the-bloat-it-would-be-faster-and-stable">If you used stock Emacs without all the bloat it would be faster and stable.</h3>

<p>Yes it would have been faster and more stable٫ however then I would just complain about the lack of a bunch of features from Sublime that I like٫ and the terrible keybindings.</p>

<p>I also have minor RSI issues٫ I’m not keen to turn them into major RSI issues by using Emacs bindings.</p>

<h3 id="you-can-only-switch-directly-to-a-few-tabs-buffer-switching-is-logarithmic-time-for-many-buffers">You can only switch directly to a few tabs٫ buffer switching is logarithmic time for many buffers.</h3>

<p>Yes٫ but tabs are more like a cache. Like I mention٫ when it isn’t easy to hit the numbered shortcut to
jump directly to a tab I use “Goto Anything” to narrow directly to the file٫ which takes the same amount
of time buffer switching would.</p>

<p>Tabs are just an additional speedup in the case that I’m switching to one of my ~6 most recently/frequently
used files. I’d say it’s the case that over 95% of my switches are to one of my tabs٫ but only at most 50%
of my switches are to my most recently used other file٫ there’s gains to be had over Emacs in that extra 45%
of switches that become fast.</p>
'),('http://thume.ca/2016/12/03/disassembling-sublime-text/', 'Disassembling Sublime Text', '1480723200000',  13, '
<p>This afternoon I spent some time with the free trial of the
<a href="https://www.hopperapp.com/">Hopper Disassembler</a> looking through the binary of
Sublime Text 3. I found some interesting things and some undocumented settings.</p>

<h2 id="undocumented-settings">Undocumented Settings</h2>

<p>The most potentially useful and interesting thing I found were some undocumented
settings for Sublime Text. A couple of them could even be useful to some people:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">draw_shadows</code>: A boolean that can disable the shadow effect when any line is longer
that the window. I personally like effect but if you want a cleaner look or your window
is only slightly wider than your text and the shadow effect kicks in early٫ you can use
this setting.</li>
  <li><code class="language-plaintext highlighter-rouge">indent_guide_options</code>:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">solid</code>: This as an undocumented option that makes indent guides solid instead of dashed.
Add this in addition to a <code class="language-plaintext highlighter-rouge">draw_*</code> option.</li>
      <li><code class="language-plaintext highlighter-rouge">draw_active_single</code>: Like <code class="language-plaintext highlighter-rouge">draw_active</code> but only draws the innermost indent guide your
cursor is in instead of guides for every indent level down to it.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">draw_debug</code>: A boolean that if true enables a special debugging text renderer. It seems to
turn sections of the document either blue or red٫ and within the sections it turns tokens
alternating light and dark shades of those colours. Note you have to set the setting to false
to turn it off٫ not just delete it. These change sometimes when scrolling and editing but I
can’t figure out when and why.</li>
  <li><code class="language-plaintext highlighter-rouge">wide_caret</code>: This just acts like adding to <code class="language-plaintext highlighter-rouge">caret_extra_width</code>٫ probably an old setting٫ not useful.</li>
</ul>

<p>There’s also the undocumented command line flags:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">--multiinstance</code>: Starts a new instance of Sublime even if one is already running.</li>
  <li><code class="language-plaintext highlighter-rouge">--debug</code>: Prints debug output to stdout٫ I think this is just the output that goes in the built-in console.</li>
</ul>

<p>I discovered these settings by running <code class="language-plaintext highlighter-rouge">strings</code> on my <code class="language-plaintext highlighter-rouge">Sublime Text.app/Contents/MacOS/Sublime Text</code>
binary and looking near the things I knew where config options for things that looked like config
options٫ then trying them out.</p>

<p><img src="/assets/postassets/sublimesecrets/debug_render.png" alt="Debug rendering mode" />
<img src="/assets/postassets/sublimesecrets/configs.png" alt="Debug rendering mode" /></p>

<h2 id="libraries-used">Libraries Used</h2>

<p>The Sublime Text release binaries don’t have symbol names stripped out٫ probably for debugging
reasons٫ and for that I’m very grateful because it’s really cool. The assembly is still largely
indecipherable to me٫ but there are some cool things I can find out.</p>

<p>From the function names I can also see some of the libraries used in the making of Sublime Text.
Here’s a partial list:</p>

<ul>
  <li>Skia: It’s been mentioned online this is used for rendering everything</li>
  <li>Google densehash: Faster hash map٫ used everywhere</li>
  <li>Oniguruma: Fallback for fancy regexes the custom engine can’t handle</li>
  <li>Boost</li>
  <li>Google breakpad</li>
  <li>CryptoPP/Crypto++ (in old versions٫ now replaced with libtomcrypt)</li>
  <li>leveldb: Used to store symbol indexes I think</li>
  <li>snappy: Fast compression٫ not sure what it is used for</li>
  <li>Hunspell</li>
  <li>YAML (apparently actually yaml-cpp)</li>
  <li>lzma</li>
  <li>Hunzip: Probably what is used to unzip the zipped up package format</li>
  <li>libtomcrypt</li>
</ul>

<h2 id="internal-names">Internal names</h2>

<p>I can also see some general architecture and what things are named. This is just cool trivia.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sregex</code>: The custom super fast regex engine. I think the special feature is that it can search for many different regexes on one piece of text at the same time. Because <a href="http://github.com/trishume/syntect">when I wrote a sublime-syntax highighter</a> that’s what I would have wanted.</li>
  <li><code class="language-plaintext highlighter-rouge">skyline</code>: The name for Sublime’s widgets framework. The centerpiece is <code class="language-plaintext highlighter-rouge">skyline_text_control</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">px</code>: The windowing and platform integration framework used for event handling٫ file management and other OS integration across Windows٫ Linux and OSX.</li>
  <li><code class="language-plaintext highlighter-rouge">TokenStorage</code>: The class that stores and renders highlighted tokens.</li>
</ul>

<p>God how I wish any of these were open source. Each of these would be useful in
many things other than text editors. There’s no app I know of that has its own
custom-rendered UI framework that manages to be as fast and smoothly
integrated with the OS as <code class="language-plaintext highlighter-rouge">skyline</code> and <code class="language-plaintext highlighter-rouge">px</code> are. The custom regex engine
would be a handy library as well. I do understand that these goodies might not
have existed in the first place if Jon couldn’t make money off of Sublime Text
though٫ so I’m grateful that I at least have one beautiful and fast cross-
platform app.</p>

<h2 id="more">More</h2>

<p>I also tried to figure out how some parts of the editor work and why they are so fast٫
but I couldn’t figure out much from the assembly. All the key functions have hundreds of
basic blocks and are enormous with everything inlined. If I spent an entire day I might be
able to reverse engineer one function٫ but that wouldn’t get me very far.</p>

<p>If there’s anything you’re interested in about Sublime Text’s internals٫ leave a
comment and I might take a look. Especially if it’s a tiny behaviour improvement that
isn’t accessible to the plugin API but might be possible to patch in the binary٫
with a debugger٫ or with something like <a href="http://www.frida.re/">Frida</a>.</p>

<h2 id="edit-updates">Edit: Updates</h2>

<p>After this article was posted on <a href="https://news.ycombinator.com/item?id=13100560">Hacker News</a>
and cross-posted to <a href="https://forum.sublimetext.com/t/disassembling-sublime-text/24824">the Sublime forum</a>٫
@wbond٫ the Package Control maintainer and new Sublime developer replied with some corrections and new info.
I’ve updated the library listing above with the new info.</p>
'),('http://thume.ca/2016/07/16/advanced-hackery-with-the-hammerspoon-window-manager/', 'Advanced Hackery With The Hammerspoon Window Manager', '1468627200000',  13, '
<p>Along with <a href="https://kapeli.com/dash">Dash</a>٫ <a href="https://www.sketchapp.com/">Sketch</a> and <a href="http://papersapp.com/">Papers</a>٫ one of the main reasons I haven’t yet switched to Linux is <a href="http://www.hammerspoon.org/">Hammerspoon</a>. Hammerspoon gives me most of the power that a fancy Linux tiling window manager and configurable desktop would give me٫ without having to switch operating systems. It’s fully configurable with Lua٫ has <a href="http://www.hammerspoon.org/docs/index.html">tons of built in modules</a> and it is simple to write your own modules. I think of it more as a general-purpose tool for modifying OSX’s user interface than just a window manager. This post explores some of the ways I’ve used Hammerspoon to greatly enhance my general OSX-using experience.</p>

<p><img src="/assets/postassets/hammerspoon/hammerspoon.png" alt="Hints Screenshot" /></p>

<h2 id="window-hints">Window Hints</h2>

<p>The first Hammerspoon module I wrote was a port of <a href="/howto/2012/11/19/using-slate/#switching-windows">Slate’s window hints</a>٫ which if you’ve ever used Vimium or Vimperator٫ are like link hints for windows. They allow you to switch to any window with only two keystrokes: One shortcut to bring up icons and letters for every window٫ and then simply hitting the key corresponding to the window you want.</p>

<p><a href="https://github.com/trishume/mjolnir.th.hints">The module</a> was written mostly in a single evening as a native Lua module (originally for Mjolnir٫ the precursor to Hammerspoon).
It didn’t take much time٫ and is very enjoyable to use٫ and because the module was added to the core Hammerspoon distribution٫ lots of other people can also benefit from it.</p>

<h2 id="window-tabs">Window Tabs</h2>

<p>The second Hammerspoon module I wrote was one that allows you to add tabs to any OSX Application. The tabs sit in the top right of the title bar and allow you to easily switch between windows of an app with keyboard shortcuts (e.g <code class="language-plaintext highlighter-rouge">ctrl+tab number</code>) and later by clicking. This was originally motivated by my switching to <a href="http://spacemacs.org/">Spacemacs</a> and it not having a good solution for working on many different projects like Vim tabs. This module allowed me to wrangle Emacs windows to more easily switch between different projects. I later repurposed it to switch between Sublime Windows for the same reason when I switched back to Sublime Text.</p>

<p>This module was very different to write since it was pure Lua. It uses Hammerspoon’s various powerful built-in modules including the drawing module٫ the app watcher module٫ and the window listener module.</p>

<p><img src="/assets/postassets/hammerspoon/tabs.png" alt="Tabs Screenshot" /></p>

<h2 id="mouth-noises">Mouth Noises</h2>

<p>Most recently I <a href="https://github.com/Hammerspoon/hammerspoon/pull/936">contributed</a> a <a href="http://github.com/trishume/thume.popclick">module for recognizing mouth noises</a>. It is based off some low-latency high-accuracy mouth noise recognizers I wrote during my research term at the UWaterloo HCI lab. Personally I use this module to scroll pages hands-free while lying down on the couch with my laptop. Previously I had to contort my hand into a cramped position on my chest to scroll with the trackpad while lying on my back. It’s one of my zanier uses of Hammerspoon but it is nice to use nonetheless. Just goes to show the variety of user interface scripting tasks Hammerspoon can do.</p>

<h2 id="custom-window-management-hotkeys">Custom Window Management Hotkeys</h2>

<p>I love being able to customize my window management shortcuts perfectly for the kind of things I normally do. I have a custom modifier key on <a href="/2014/09/08/creating-a-keyboard-1-hardware/">my keyboard</a> that is dedicated to window management I call <code class="language-plaintext highlighter-rouge">hyper</code>. Pressing <code class="language-plaintext highlighter-rouge">hyper</code> in combination with the left home row jumps directly between my most frequently used apps (Chrome٫ Sublime٫ iTerm2٫ Mail٫ Path Finder) and a pair of keys that mark a certain window and focus it٫ for all the other apps I use occasionally like PDF readers when writing LaTeX. Pressing <code class="language-plaintext highlighter-rouge">hyper</code> with the right home row moves a window between full screen٫ halves of the monitor٫ and between screens. Various other hyper shortcuts do things like toggling mouth noise recognition. I also have a hotkey I can hit when I plug in my external monitor that arranges all my apps between monitors in the way I like them instantly.</p>

<h2 id="miscellaneous-hackery">Miscellaneous Hackery</h2>

<p>I’ve used Hammerspoon for some one-off tasks٫ especially when I want to bind things to global keyboard shortcuts. An example of this is a weekend project I did to make a mouse controlled by head movements detected by an accelerometer on a microphone headset. I used Hammerspoon to send serial commands to the microcontroller when I pressed a shortcut to toggle the mousing on and off.</p>

<p><img src="/assets/postassets/hammerspoon/lookmouse.jpg" alt="Lookmouse" /></p>

<h2 id="conclusion">Conclusion</h2>

<p>I hope this has given you some ideas about how you can use Hammerspoon to make your computing experience more pleasant. Check out <a href="https://github.com/trishume/dotfiles/blob/master/hammerspoon/hammerspoon.symlink/init.lua">my Hammerspoon config</a> to see how I configure everything and tie it all together. For more inspiration check out the amazing things <a href="https://github.com/asmagill/hammerspoon-config">asmagill does in his config</a>. He has experimental modules for all sorts of things like drawing calendars٫ custom app menus٫ fonts and speech control.</p>

'),('http://thume.ca/2016/04/03/simple-binary-formats-and-terrible-hacks/', 'Simple Binary Formats and Terrible Hacks', '1459641600000',  13, '
<p>Last weekend me and my friend <a href="http://mlht.ca/">Marc</a> went to <a href="https://medium.com/@tau/terriblehack3-1164c2541c3f">TerribleHack III</a> and made <a href="http://dayder.thume.ca/">Dayder</a>٫ a neat little website for finding <a href="http://tylervigen.com/spurious-correlations">spurious correlations</a> in lots of time series data sets. I did the ingestion of our initial data set of causes of death over time٫ as well as the JS/HTML front end. Marc made the correlation finding web server in Rust and also did the final prettying up of the CSS. I’m quite proud of how well it turned out given that it was made in 12 hours.</p>

<p><img src="/assets/postassets/binary/dayder.png" alt="Dayder" /></p>

<p>The coolest part of Dayder is how fast it is. All the DOM and JS Canvas rendering code is custom built for rendering hundreds of graphs in milliseconds. Marc and I also designed a custom simple binary format for storing time series data in a compact way. We called the format <a href="https://github.com/trishume/dayder/blob/master/format.md">btsf</a> and it is a key reason why our app can quickly send tons of time series data sets to the client as well as store them on the server in a compact way. All 6591 time series fit in less than 1 megabyte of data٫ allowing them all to be sent to the client for instantaneous filtering.</p>

<p>The following week I gave a short talk at a UWaterloo CS Club event about simple binary formats and how they can make your project faster٫ easier and cooler:</p>

<script async="" class="speakerdeck-embed" data-id="56dcaeddea6f466bb08d8ee28694f952" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>

<p>Now that I’ve used simple binary formats for both <a href="http://ratewith.science/">Rate With Science</a> and Dayder٫ I’m a big fan. Although outside a hackathon context where I have time to learn libraries and where I don’t have the incentive to design new formats for fun٫ I think I would probably go with something established like <a href="https://capnproto.org/">Cap’n Proto</a> or <a href="https://thrift.apache.org/">Thrift</a> instead of a custom format.</p>
'),('http://thume.ca/2016/03/24/eye-tracker-reviews-pupil-labs-tobii-eyex-eye-tribe-tobii-x2-30/', 'Eye Tracker Reviews: Pupil Labs٫ Tobii٫ Eye Tribe٫ XLabs', '1458777600000',  13, '
<p>During my time at the <a href="http://hci.cs.uwaterloo.ca/">UWaterloo HCI Lab</a> I’ve had the opportunity to try out 5 different eye trackers and compare them.
These eye trackers span the price range from free to $10٫000+ and use a variety of different tracking methods. These trackers are also not always direct
alternatives٫ they are often meant for very different scenarios.</p>

<p>Disclaimer: These are the results that I got for myself using these eye trackers. Eye tracking performance varies wildly between people so it is likely that
for some of these trackers I got atypically bad or good performance. When my results don’t square with claimed performance or performance I’ve seen in videos
I’ll try and note that.</p>

<p>Also٫ I have not done exact degrees accuracy tests on any of these trackers. I may however give figures in degrees٫ here’s what I mean when I mean by these:
Whenever I test these out٫ the tracked point or the filtered point (if there is jitter) is with high probability within a given distance of my real gaze point.
I then use trigenometry to work out the degree angle corresponding to that distance٫ a handy rule of thumb is that each degree corresponds to about a centimeter of
distance at a typical screen-head distance ( <code class="language-plaintext highlighter-rouge">tan(1.0*(pi/180))*60 = 1.04</code> ).</p>

<p>With that out of the way lets move on to the trackers:</p>

<h1 id="pupil-labs-headset-my-favourite-research-eye-tracker">Pupil Labs Headset: My favourite research eye tracker</h1>

<p>My lab has a <a href="https://pupil-labs.com/store/">Pupil Labs</a> eye tracking headset with a high speed world camera and 120hz binocular eye cameras.
It’s well suited for a variety of research٫ and is the only eye tracker with amazing open source software.</p>

<h4 id="pros">Pros:</h4>
<ul>
  <li>Good tracking: very high precision (i.e low jitter) and fairly high accuracy immediately after calibration (~1.5 degrees)</li>
  <li>Allows free head motion because the eye tracker is fixed to your head.</li>
  <li>Robustly tracks markers in order to map gaze onto surfaces like screens.</li>
  <li>The open source software is amazing. Really good interface٫ easy to use٫ tons of features٫ and unlike <em>every other eye tracker</em> you can add any features you need yourself.</li>
  <li>You don’t need a computer screen and you can do eye tracking experiments in other environments.</li>
  <li>Good price for a research eye tracker (on the order of $1000)٫ especially with academic discount.</li>
  <li>Tolerates other IR devices. Since the tracking doesn’t use glints you can use other IR lights like an IR head tracker at the same time. It is the only eye tracker like this.</li>
  <li>Fully cross platform: Windows٫ OSX and Linux.</li>
</ul>

<h4 id="cons">Cons:</h4>
<ul>
  <li>The headset can easily be jostled if you move your head too much or crinkle your face٫ and when that happens accuracy drops proportional to the change in position.
The technique I’m researching requires head motion and I typically see accuracy of ~3 degrees after some head movements slightly move the headset.</li>
  <li>Doesn’t fit with other glasses very well٫ and if it does fit the reflections make it worthless.</li>
  <li>You have to wear something on your head. It is fine at first but after an hour or two can start to feel quite uncomfortable.</li>
  <li>You have to recalibrate every single time you put it on٫ unlike some remote eye trackers.</li>
</ul>

<h4 id="watch-out-for">Watch out for:</h4>
<ul>
  <li>Eye cameras can’t adjust to get a good view of eyes very near the center of the face٫ I had a participant like this and it still worked but lost tracking at larger gaze angles.</li>
  <li>If your ears move when your face moves٫ it will move the eye tracker out of calibration almost immediately. I had a participant like this.</li>
</ul>

<h1 id="tobii-eyex--steelseries-sentry-best-consumer-eye-tracker">Tobii EyeX / Steelseries Sentry: Best consumer eye tracker</h1>

<p>The <a href="http://www.tobii.com/xperience/">Tobii EyeX</a> (or the identical Steelseries Sentry) is an incredible consumer eye tracker. One downside is it only works on Windows٫ but I’ve gotten around this by running
the EyeX software in a VMWare Fusion VM and <a href="https://gist.github.com/trishume/b25492f25fc8ebe01dd9">piping the data to my mac over UDP</a>. Two caveats are that in order to switch to the mac and have tracking continue you have to <a href="http://dannyman.toldme.com/2014/05/15/vmware-retina-thunderbolt-constant-resolution/">lock the
VM’s screen resolution</a>. Also if the load gets too high on the VM sometimes the tracker will stop
and take a couple seconds before it automatically restarts٫ this is only an issue in VMs and can be mostly avoided by running no other programs on the Windows VM.</p>

<h4 id="pros-1">Pros:</h4>
<ul>
  <li>Extremely robust to head motion: your calibration will last practically forever. You can move your head around as much as you want and still maintain decent (2-3 degrees accuracy) tracking.
This means you don’t have to calibrate every time you sit down٫ just keep your one calibration for an arbitrarily long time. The magnetic mount is extremely repeatable so it doesn’t need to be recalibrated.</li>
  <li>Good accuracy even on large screens: Although the accuracy degrades near corners٫ in general the tracker gives me ~2-3 degrees of accuracy٫ which is quite decent.</li>
  <li>Comes with very nice software. The SDK is nice and the software gives you a nice calibration test screen٫ a very pretty gaze trace٫ and some handy eye tracking desktop enhancements like warping your mouse cursor.</li>
</ul>

<h4 id="cons-1">Cons:</h4>
<ul>
  <li>Low precision. There is quite a bit of jitter٫ but it is bounded (it is almost never more than 2cm from the center of the jitter)٫ so can be mostly eliminated by filtering.</li>
  <li>Windows only.</li>
  <li>You may not record gaze data. This is a developer SDK term meant to make you buy Tobii’s more expensive trackers٫ it is not an issue if you’re developing interaction techniques or just using the tracker.</li>
  <li>Your head needs to be relatively low with respect to the monitor. I prefer my head to be near the top of my monitor but this is outside the non-adjustable view of the tracker from the monitor’s bottom edge.
You can fix this by tilting your monitor upwards٫ I was lucky that my monitor had an adjustable stand.</li>
</ul>

<h1 id="edit-tobii-4c-new-best-consumer-eye-tracker">[Edit] Tobii 4C: New best consumer eye tracker</h1>

<p>I’ve now had a chance to use the <a href="https://tobiigaming.com/eye-tracker-4c/">Tobii 4C</a> for a while and it’s fantastic. Everything I said about the EyeX above applies٫ with the following new notes:</p>

<ul>
  <li>All the processing is now done on the device٫ this means very low CPU and USB loads. It now works flawlessly in VMWare Fusion.</li>
  <li>Accuracy is similar or maybe somewhat better. It’s the most accurate eye tracker I’ve used personally.</li>
  <li>Tobii is now working on a macOS implementation of the Stream Engine SDK (the low level C API). I’ve tried out an alpha and it works quite well. I used it to implement <a href="https://github.com/trishume/FusionMouse">FusionMouse</a>.</li>
  <li>I tried it out in combination with a TrackIR 5 and it didn’t interfere with the tracking much٫ which let me combine eye tracking and head tracking that is higher accuracy than the tracking Tobii provides on Windows. I remember having problems when I tried the TrackIR with the EyeX٫ so either they fixed something or my setup changed enough that it works now.</li>
</ul>

<p>The restrictions on recording data still apply though٫ so it’s still difficult to legally use for research٫ other than research on interactive eye tracking systems.</p>

<p>Another tip I picked up: The adhesive on the magnetic strips for attaching the 4C/EyeX to a monitor have very strong permanent adhesive that’s difficult to remove without breaking or bending anything. If you use double-sided foam tape you can attach the strip to a monitor in a way that’s much easier to remove. The extra distance also enables it to be mounted on some laptops.</p>

<h1 id="the-eye-tribe-tracker-good-but-doesnt-work-well-for-me">The Eye Tribe Tracker: Good but doesn’t work well for me</h1>

<p>The <a href="http://theeyetribe.com/">Eye Tribe tracker</a> (I have the older $100 model) is a great piece of hardware at a great price٫ unfortunately it barely works for me.
I’ve seen it work well for other people in videos so I’m not claiming this is a common problem٫ just one that I invariably experience. I’ve tried it in tons of environments
with different computers٫ positions and eyewear. After <a href="http://thume.ca/2016/02/02/a-reverse-engineering-adventure-eye-tribes-usb-protocol/">reverse engineering</a> it I think I have identified
the problem as due to extra glints on the side of my eyes when looking away from the center of my screen. I can calibrate in the center and get ~4 degrees of accuracy within a 1000 x 1000px area٫ but that isn’t great.</p>

<p>As such٫ I’ve restricted my Pros and cons to discussing other issues than accuracy:</p>

<h4 id="pros-2">Pros:</h4>
<ul>
  <li>Great price٫ only $100.</li>
  <li>Works on OSX. This is better than the Tobii EyeX so if you’re looking for a consumer tracker on OSX try the Eye Tribe.</li>
  <li>A great high speed high resolution infrared camera: I <a href="http://thume.ca/2016/02/02/a-reverse-engineering-adventure-eye-tribes-usb-protocol/">reverse engineered</a> the control codes so you can use it for other purposes like motion tracking or writing your own eye tracking algorithms. This can’t be done easily with the EyeX since it uses a much more locked down custom USB protocol.</li>
</ul>

<h4 id="cons-2">Cons:</h4>
<ul>
  <li>Tripod mount means that if you bump it٫ pull the cable٫ or bump your monitor٫ you’ll have to recalibrate. This is in contrast to the sentry٫ which mounts directly to your monitor.
If you’re ambitious you could improve your own clamping mount for the eye tribe tracker or fix the tripod and monitor in place.</li>
  <li>Limited software: The software does very little compared to Tobii’s and Pupil’s software. It is basically just a calibration and API server.</li>
</ul>

<h1 id="tobii-x2-30-great-but-overpriced">Tobii X2-30: Great but overpriced</h1>

<p>My lab has a <a href="http://www.tobiipro.com/product-listing/tobii-pro-x2-30/">Tobii Pro X2-30</a> which in many ways is similar to the Tobii EyeX. The main hardware difference is that it uses two cameras instead of one٫ but I assume they are
lower resolution since it only needs USB 2.0 bandwidths instead of USB 3.0. The main legal difference is that you are allowed to record the gaze data with the pro models. The main practical difference is that the X2-30 costs over <strong>50 TIMES</strong> as much. The price is not public and I imagine they quote different prices to different people. I’m not sure if my lab signed any agreements with regards to giving away the price so I’ll just say we paid somewhere over 50x the price of an EyeX.</p>

<p>The pros/cons and tracking performance are very similar to the Tobii EyeX. Unless you are doing a study where you need to record gaze data٫ the 50x increase in price is not worth it in my opinion.</p>

<h4 id="pros-3">Pros:</h4>
<ul>
  <li>Extremely robust to head motion: your calibration will last practically forever. You can move your head around as much as you want and still maintain decent (2-3 degrees accuracy) tracking.
This means you don’t have to calibrate every time you sit down٫ just keep your one calibration for an arbitrarily long time. The magnetic mount is extremely repeatable so it doesn’t need to be recalibrated.</li>
  <li>Good accuracy: Although the accuracy degrades near corners٫ in general the tracker gives ~2.0 degrees of accuracy when not using a chin rest٫ which is quite good and slightly better than the EyeX.</li>
  <li>Comes with very nice software. The SDK is nice and the software gives you a nice calibration test screen٫ a very pretty gaze trace٫ and some handy eye tracking desktop enhancements like warping your mouse cursor.</li>
  <li>The new Analytics SDK 3.0 allows use with OSX and Linux.</li>
</ul>

<h4 id="cons-3">Cons:</h4>
<ul>
  <li>The nice EyeX software it works with is Windows-only.</li>
  <li>Only specified to work on relatively small monitors by modern standards (22” diagonal).</li>
  <li>I found that sometimes the tracked gaze would jump for half a second or so to a wildly inaccurate position ~15cm away from where I was looking. This is bad because it is harder to filter out and distinguish from a saccade.</li>
  <li>Crazy expensive. This is not unique to Tobii. Basically every eye tracker intended for research (except the Pupil) is absurdly overpriced. Many research eye trackers cost in the range of $50٫000.</li>
  <li>Your head needs to be relatively low with respect to the monitor. I prefer my head to be near the top of my monitor but this is outside the non-adjustable view of the tracker from the monitor’s bottom edge.
You can fix this by tilting your monitor upwards٫ I was lucky that my monitor had an adjustable stand.</li>
</ul>

<h1 id="xlabs-gaze-chrome-plugin-best-webcam-only-eye-tracker">XLabs Gaze Chrome Plugin: Best webcam only eye tracker</h1>

<p>The <a href="https://xlabsgaze.com/">XLabs</a> chrome plugin allows you to do eye tracking on a web page using only a webcam and no special hardware.
I’ve only ever had good results when trying out their <a href="https://eyesdecide.com/">EyesDecide</a> software٫ although I was also in a different environment when I tried it that way.</p>

<h4 id="pros-4">Pros:</h4>
<ul>
  <li>Basically your only option for eye tracking without special hardware. Allows you to do things like web usability eye tracking studies with only a laptop.</li>
  <li>Free! The SDK is currently free to use٫ although that may change٫ and you don’t have to buy hardware.</li>
  <li>Rather decent tracking. Quite impressive for a webcam tracker٫ can achive 2-4 degree accuracies varying extensively by person٫ environment and calibration.</li>
  <li>Fully cross platform٫ because it is just a Chrome plugin.</li>
</ul>

<h4 id="cons-4">Cons:</h4>
<ul>
  <li>Very long calibration process: If you want good results you need to go through a very long sequence of calibration dots٫ on the order of 30.</li>
  <li>Very short lived calibration. It is not as robust to head motion as other trackers and becomes miscalibrated within a few minutes unless you are constantly calibrating with their dynamic calibration.</li>
  <li>Very sensitive to lighting. You need bright light on your face٫ sitting near a window is best. If the lighting isn’t right it can sometimes barely work at all.</li>
  <li>You can only use it within Chrome. No desktop apps.</li>
</ul>

<h1 id="others">Others</h1>

<p>There are tons of crazy expensive research eye tracking systems that I haven’t tried for exactly that reason: they cost way too much. I’m sure some of them are quite excellent٫ but they cost as much of a car for hardware that certainly
isn’t 1/10th that expensive to manufacture.</p>

<p>There’s two other sub-$1000 eye trackers I have not tried but I have read a bit about:</p>

<h4 id="gazepoint-gp3">Gazepoint GP3</h4>

<p>The <a href="http://www.gazept.com/product/gazepoint-gp3-eye-tracker/">Gazepoint GP3</a> is $500 and internally uses a <a href="https://www.ptgrey.com/case-study/id/10423">Point Grey camera</a> which probably has a 752x480 resolution٫ which is much lower than the Eye Tribe tracker.
The only advantage it might have over the Eye Tribe is that it uses bright pupil tracking (so perhaps more robust) and their software might be better٫ but likely is not. Gazepoint’s software is also Windows only.
I see no reason to consider this tracker over the cheaper and seemingly much better Tobii EyeX.</p>

<h4 id="mygaze">MyGaze</h4>

<p>The <a href="http://www.mygaze.com/">MyGaze</a> seems to be the deluxe consumer eye tracker. I haven’t bought it since it is outside my “just trying it out” budget when I already personally own 2 consumer eye trackers.
However٫ there seems to be some glowing recommendations online from people who have tried other consumer eye trakers calling it the best of everything low cost. It is also made by engineers from SMI which is a
super fancy expensive high quality research eye tracker company. There’s some recommendations and a video (that shows incredible &lt;1 degree accuracy) <a href="http://www.apparelyzed.com/forums/topic/37302-questions-about-smis-500-mygaze-vs-200-eye-tribe-tracker-pro/">on this forum thread</a>. If you have the budget for it I recommend you try this tracker out (and then let me know how you like it).</p>

<p>One downside is that although the hardware only costs $500٫ you have to pay $900 to also get the developer SDK٫ unlike every other consumer eye tracker which gives away the SDK for free with the tracker.</p>

<h4 id="the-eye-tribe-pro">The Eye Tribe Pro</h4>

<p>The Eye Tribe is soon going to release a new tracker with new algorithms and supposedly better tracking on many dimensions for $200. I have no idea how good it will be or how it will compare to other low cost eye trackers.</p>
'),('http://thume.ca/2016/02/02/a-reverse-engineering-adventure-eye-tribes-usb-protocol/', 'A Reverse Engineering Adventure: Eye Tribe"s USB Protocol', '1454371200000',  13, '
<p><strong>Update:</strong> See bottom of the article for recent progress. I’ve managed to get a full 10-bit high def video feed and have released example code.</p>

<p>In 2014 I bought an <a href="http://theeyetribe.com/">Eye Tribe eye tracker</a> hoping to work on some neat eye tracking projects.
Unfortunately I’ve never been able to reach the fingertip level accuracy they claim and that I have seen in videos.
I always get around +/- 5cm (2 inches) or more of jitter. Recently I’ve been working on eye tracking research again
and I thought I would take a crack at debugging my accuracy issues.</p>

<p>There’s just one problem: The Eye Tribe’s tracking software is closed source and doesn’t have a debug view or a raw camera
feed API. I’ve been wanting to try my hand at reverse engineering lately so I set myself the goal of reverse engineering
the tracker’s USB protocol so that I could turn the tracker’s IR lights on and capture the IR video feed.</p>

<p>The Eye Tribe tracker is really just a USB 3.0 <a href="https://en.wikipedia.org/wiki/USB_video_device_class">UVC</a> camera (the standard webcam protocol) that shoots
in monochrome IR. It also has bright IR LEDs that light up the user’s face since there isn’t much ambient IR indoors.
Capturing the video is easy٫ the hard part is that the LEDs are controlled through a proprietary extension to the USB video camera protocol.</p>

<p>Thus I started on my quest to discover the special commands that would turn on those LEDs. In the end I figured out some cool techniques٫
and helped diagnose out my issue (haven’t solved it yet though). What could be useful to others is that the Eye Tribe is effectively
a low cost (<a href="https://www.ptgrey.com/">alternatives</a> are &gt;$500)٫ high resolution٫ high frame rate IR camera with built in illuminators.
This could be used for all sorts of computer vision projects like a cheap <a href="http://www.vicon.com/">Vicon</a> style motion capture system or an
open source eye tracker.</p>

<h2 id="exploration">Exploration</h2>

<p>I started by <a href="http://superuser.com/questions/781982/how-can-i-install-usb-prober-from-the-developer-sdk-on-mac-os-x">installing USB Prober</a>٫ a dev tool that lets you inspect the metadata of devices connected by USB. You can get practically the same
information in the USB section of the built in “System Information” app but I installed USB Prober in case it gave more info.</p>

<p>I started looking through the <a href="https://github.com/trishume/EyeTribeReversing/blob/master/USBProber.txt">USB info dump for the Eye Tribe tracker</a> and
discovered some good clues. First of all that it was a UVC camera٫ and that it was only a UVC camera٫ no other fancy USB control endpoints.
I also noticed that there was a <code class="language-plaintext highlighter-rouge">VDC (Control) Extension Unit</code> interface: this was probably where the custom lights control messages could be sent.</p>

<p>I also figured out some other interesting things like the camera module being manufactured by <a href="https://www.leopardimaging.com/">Leopard Imaging</a>
and that it could capture high resolution 2304x1536 video at 27fps (that’s more than 1080p) and 768x1024 at 60fps. There are also a bunch of intermediate
resolutions it can do at intermediate frame rates.</p>

<h2 id="attempting-to-log">Attempting to Log</h2>

<p>My next step was to try and log the USB traffic between the tracker and the eye tracking data server program The Eye Tribe provides.
Unfortunately٫ Apple hasn’t updated the kernel extensions for USB logging for the latest OSs. Last time I tried installing them I nearly
bricked my laptop because it couldn’t read any USB HID input٫ including the internal USB hub for the laptop’s keyboard and trackpad.
I only rescued it by copying the Kext files from the recovery partition onto my main drive٫ I started backing up my entire disk instead of just
my important files after that incident.</p>

<p>So instead I took the advice in <a href="http://lists.apple.com/archives/usb/2015/Jan/msg00004.html">this mail thread</a> and tried <code class="language-plaintext highlighter-rouge">usbtrace</code> and <code class="language-plaintext highlighter-rouge">dtrace</code>
instead. Unfortunately <code class="language-plaintext highlighter-rouge">usbtrace</code> showed megabytes per minute of all my system’s USB traffic in a not very useful format.
<code class="language-plaintext highlighter-rouge">dtrace</code> showed me that control messages were being sent by the tracking server٫ and from what call stack٫ but not which messages and what they contained.</p>

<h2 id="disassembly">Disassembly</h2>

<p>After logging failed٫ I tried a different approach. I downloaded the trial of <a href="http://www.hopperapp.com/">Hopper 3</a> and loaded up the Eye Tribe server executable.
Most of the method names were just numbered symbols but I managed to find an Objective C method called <code class="language-plaintext highlighter-rouge">setUvcControl:withValue:</code> that belonged to a class called
<code class="language-plaintext highlighter-rouge">UVCCameraControl</code>. I tried tracing the callers to see if I could find any obvious light control code٫ but with no function symbol names٫ no source code٫ and
only vaguely knowing x86_64 assembly٫ I wasn’t able to do it.</p>

<p>Instead I used <a href="http://stevenygard.com/projects/class-dump/">class-dump</a> on the server executable to look at the other methods. I Googled some of the method names
and found <a href="http://phoboslab.org/log/2009/07/uvc-camera-control-for-mac-os-x">it was open source</a> (code on <a href="https://github.com/HBehrens/CamHolderApp/blob/master/CamHolderApp%2FUVCCameraControl.m">Github here</a>). Now I had the source code for the mechanism used to send the messages٫ but I didn’t know what they were called with.</p>

<p>I read through the source of that class and started looking at the <a href="http://www.cajunbot.com/wiki/images/8/85/USB_Video_Class_1.1.pdf">UVC protocol spec</a> to make sense of what I found.
I learned that auxiliary parameters of a camera are controlled and inspected by UVC control requests like <code class="language-plaintext highlighter-rouge">SET_CUR</code> and <code class="language-plaintext highlighter-rouge">GET_CUR</code> on different interfaces and with different control selectors.
I figured out through reading the source code that the bit fields described in the protocol corresponded with the fields of OSX’s <a href="https://developer.apple.com/library/mac/documentation/Kernel/Reference/USB_kernel_header_reference/index.html#//apple_ref/c/tdef/IOUSBDevRequest">IOUSBDevRequest</a>.</p>

<h2 id="debugging">Debugging</h2>

<p>I started on a new approach to try and log the control requests sent by the server through intercepting the method calls made by it.
If I could print out the contents of the <code class="language-plaintext highlighter-rouge">IOUSBDevRequest</code> structs being sent٫ I could probably figure out which ones turned on the lights. So I fired up <a href="http://lldb.llvm.org/">LLDB</a>
and set a breakpoint at the hex address of <a href="https://github.com/HBehrens/CamHolderApp/blob/master/CamHolderApp%2FUVCCameraControl.m#L255">sendControlRequest:</a> from the disassembly.</p>

<p>I started the server with the tracker connected and LLDB hit the breakpoint٫ but since there were no debug symbols٫ all I could look at was registers and assembly.
I had no idea what the calling conventions were for Objective-C code and looking them up and peeking at some memory didn’t seem to find the right things.
So I kept stepping and reached down into <code class="language-plaintext highlighter-rouge">IOUSBInterfaceClass::interfaceControlRequest(void*٫ unsigned char٫ IOUSBDevRequest*)</code> which although it didn’t have debug info٫
at least had an unobfustucated function name. I Googled this and found that Apple <a href="http://www.opensource.apple.com/source/IOUSBFamily/IOUSBFamily-203.4.7/IOUSBLib/Classes/IOUSBInterfaceClass.cpp">published the source code</a>!</p>

<p>The registers and assembly weren’t helping me very much until after an hour or two I figured out how to find where the struct I wanted was located.
The source code for <code class="language-plaintext highlighter-rouge">IOUSBInterfaceClass::interfaceControlRequest(void*٫ unsigned char٫ IOUSBDevRequest*)</code> showed it copying a <code class="language-plaintext highlighter-rouge">IOUSBDevRequest</code> into an <code class="language-plaintext highlighter-rouge">IOUSBDevRequestTO</code> and not much else.
So I looked at the dissassembly for that method in the debugger and saw a bunch of mov instructions copying the fields of the struct. They all looked something like:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0x100ae2fb0 &lt;+14&gt;: movb   %al٫ -0x28(%rbp)
0x100ae2fb3 &lt;+17&gt;: movb   0x1(%rbx)٫ %al
</code></pre></div></div>

<p>Aha! At that point the struct I want must be pointed to by register <code class="language-plaintext highlighter-rouge">%rbp</code>. I stepped to that point٫ and after a figuring out the right casting and pointer indirection I printed out the second byte:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(lldb) e (int)((char*)$rbx)[1]
(int) $22 = 129
</code></pre></div></div>

<p>The second byte of the struct I wanted should be the <code class="language-plaintext highlighter-rouge">UInt8 bRequest</code> field which should correspond to one of the <a href="https://github.com/HBehrens/CamHolderApp/blob/master/CamHolderApp%2FUVCCameraControl.h#L16">constants in the UVCCameraControl</a>. Sure enough after using <code class="language-plaintext highlighter-rouge">irb</code> to convert <code class="language-plaintext highlighter-rouge">129</code> to hex I got <code class="language-plaintext highlighter-rouge">0x81</code> which is the request code for <code class="language-plaintext highlighter-rouge">UVC_GET_CUR</code>٫ I had found it!</p>

<h2 id="logging-for-real-this-time">Logging (for real this time)</h2>

<p>Now I needed to figure out how to print out the other fields and the data pointed to by the <code class="language-plaintext highlighter-rouge">void *pData</code> field. All fast enough so that the tracking server wouldn’t get messed up.
My strategy for this was to try and script LLDB to break at the exact right instruction٫ print out all of the fields٫ and then continue automatically.</p>

<p>I read about LLDB’s Python scripting capabilities٫ but the Python interface was poorly documented and could only really do anything with debug info٫ which I didn’t have.</p>

<p>So instead I figured out all the right casting invocations to print out the fields of the struct٫ which took a while.
Then I figured out the exact offset from the start of the dynamic library I wanted to break at (the absolute address changed every time I started up the tracking server)٫ set a breakpoint there
and added a breakpoint command which printed the fields and then continued:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>breakpoint set -a &lt;address of IOUSBLib I found&gt;+0x7fae
breakpoint command add 1
e ((uint64_t*)$rbx)[0]
e ((uint64_t*)$rbx)[1]
p *(uint32_t(*)[15])(((uint32_t**)$rbx)[1])
e ((uint32_t*)$rbx)[4]
c
DONE
</code></pre></div></div>

<p>Then I ran the code٫ connected the eye tracker٫ started the tracking UI (which turns on the lights)٫ waited a bit٫ and shut down the tracking UI (turning off the lights).
It output a bunch of data which I copy pasted into some <a href="https://github.com/trishume/EyeTribeReversing/blob/master/log2.txt">text</a> <a href="https://github.com/trishume/EyeTribeReversing/blob/master/log3.txt">files</a>.</p>

<h2 id="analysis">Analysis</h2>

<p>Now I had a log of the control requests٫ but as a couple 64 bit decimal integers in a copy-pasted LLDB log. So I had to write a script to parse out the various fields of the <code class="language-plaintext highlighter-rouge">IOUSBDevRequest</code> struct.
I did this in Ruby٫ eventually producing <a href="https://github.com/trishume/EyeTribeReversing/blob/master/parsedump.rb">this script</a>.</p>

<p>First I had to parse the format٫ then I used bitwise operators to extract the various fields of the struct out of the integers and into fields of a Ruby hash.
Now I had the raw data from the struct٫ but all the fields were still opaque numbers: next I had to interpret them.</p>

<p>I started by going back to the <a href="http://www.cajunbot.com/wiki/images/8/85/USB_Video_Class_1.1.pdf">UVC protocol spec</a> and copy-pasted some of the name tables in the appendix into hash literals in my script. I tried using these to map the numbers to names٫ but ended up with weird results. Then came a couple hours of fiddling٫ confusion and reading٫ as well as looking at <a href="https://github.com/HBehrens/CamHolderApp/blob/master/CamHolderApp%2FUVCCameraControl.m#L286">how the records were constructed</a> and correlating that with the spec. After the 5th try at mapping I figured out which fields came from where: I had to use the <code class="language-plaintext highlighter-rouge">Terminal ID</code> from USB Prober to decide which table to look up the control selector (high byte of the <code class="language-plaintext highlighter-rouge">wValue</code> field) in based on the <code class="language-plaintext highlighter-rouge">unitID</code> field (high byte of <code class="language-plaintext highlighter-rouge">wIndex</code>).</p>

<p>Finally I got results that made sense: before the lights turned on the server sent a couple <code class="language-plaintext highlighter-rouge">UVC_SET_CUR</code> requests to the extension unit. It looked like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{:bmRequestType=&gt;33٫ :bRequest=&gt;1٫ :wValue=&gt;768٫ :wIndex=&gt;768٫ :wLength=&gt;2٫ :selector=&gt;3٫ :unitId=&gt;3٫ :req=&gt;"UVC_SET_CUR"٫ :unit=&gt;"VC_EXTENSION_UNIT"}
[15٫ 0]
{:bmRequestType=&gt;33٫ :bRequest=&gt;1٫ :wValue=&gt;1024٫ :wIndex=&gt;512٫ :wLength=&gt;2٫ :selector=&gt;4٫ :unitId=&gt;2٫ :req=&gt;"UVC_SET_CUR"٫ :unit=&gt;"VC_PROCESSING_UNIT"٫ :msg=&gt;"PU_GAIN_CONTROL"}
[63٫ 0]
{:bmRequestType=&gt;33٫ :bRequest=&gt;1٫ :wValue=&gt;1024٫ :wIndex=&gt;768٫ :wLength=&gt;8٫ :selector=&gt;4٫ :unitId=&gt;3٫ :req=&gt;"UVC_SET_CUR"٫ :unit=&gt;"VC_EXTENSION_UNIT"}
[250٫ 0٫ 240٫ 0٫ 250٫ 0٫ 240٫ 0]
{:bmRequestType=&gt;33٫ :bRequest=&gt;1٫ :wValue=&gt;1536٫ :wIndex=&gt;768٫ :wLength=&gt;2٫ :selector=&gt;6٫ :unitId=&gt;3٫ :req=&gt;"UVC_SET_CUR"٫ :unit=&gt;"VC_EXTENSION_UNIT"}
[44٫ 1]
{:bmRequestType=&gt;33٫ :bRequest=&gt;1٫ :wValue=&gt;512٫ :wIndex=&gt;768٫ :wLength=&gt;4٫ :selector=&gt;2٫ :unitId=&gt;3٫ :req=&gt;"UVC_SET_CUR"٫ :unit=&gt;"VC_EXTENSION_UNIT"}
[0٫ 0٫ 0٫ 0]
{:bmRequestType=&gt;33٫ :bRequest=&gt;1٫ :wValue=&gt;1024٫ :wIndex=&gt;512٫ :wLength=&gt;2٫ :selector=&gt;4٫ :unitId=&gt;2٫ :req=&gt;"UVC_SET_CUR"٫ :unit=&gt;"VC_PROCESSING_UNIT"٫ :msg=&gt;"PU_GAIN_CONTROL"}
[51٫ 0]
... more of the same message with small adjustments to the gain around level 51 ...
{:bmRequestType=&gt;33٫ :bRequest=&gt;1٫ :wValue=&gt;1024٫ :wIndex=&gt;512٫ :wLength=&gt;2٫ :selector=&gt;4٫ :unitId=&gt;2٫ :req=&gt;"UVC_SET_CUR"٫ :unit=&gt;"VC_PROCESSING_UNIT"٫ :msg=&gt;"PU_GAIN_CONTROL"}
[51٫ 0]
{:bmRequestType=&gt;33٫ :bRequest=&gt;1٫ :wValue=&gt;768٫ :wIndex=&gt;768٫ :wLength=&gt;2٫ :selector=&gt;3٫ :unitId=&gt;3٫ :req=&gt;"UVC_SET_CUR"٫ :unit=&gt;"VC_EXTENSION_UNIT"}
[0٫ 0]
{:bmRequestType=&gt;33٫ :bRequest=&gt;1٫ :wValue=&gt;1024٫ :wIndex=&gt;512٫ :wLength=&gt;2٫ :selector=&gt;4٫ :unitId=&gt;2٫ :req=&gt;"UVC_SET_CUR"٫ :unit=&gt;"VC_PROCESSING_UNIT"٫ :msg=&gt;"PU_GAIN_CONTROL"}
</code></pre></div></div>

<p>So it looks like there are a couple requests sent to the extension unit٫ but only selector <code class="language-plaintext highlighter-rouge">3</code> is sent with a positive value when the lights are turned on and later a zero when the lights are turned off.</p>

<h2 id="capture">Capture</h2>

<p>Now I just had to test my theory by writing an app that sent the right UVC control requests. I used <a href="http://openframeworks.cc/">OpenFrameworks</a> since it comes with a camera capture example that uses
QtKit (which is deprecated but allegedly <code class="language-plaintext highlighter-rouge">UVCCameraControl</code> doesn’t work with <code class="language-plaintext highlighter-rouge">AVFoundation</code>). I linked in the <a href="https://github.com/atduskgreg/ofxUVC">ofxUVC</a> addon but ended up just calling the Obj-C
class directly. I started by fiddling with the gain setting and managed to even see myself a little bit without the IR illuminators turned on.</p>

<p>Then I tried sending selector <code class="language-plaintext highlighter-rouge">3</code> with a value of <code class="language-plaintext highlighter-rouge">15</code> to turn the lights on٫ and <strong>it worked first try</strong>! The lights didn’t turn off when I shut down my test app٫ but that was an easy fix of adding another control message setting it to <code class="language-plaintext highlighter-rouge">0</code>.</p>

<h2 id="victory">Victory!</h2>

<p><img src="https://camo.githubusercontent.com/3927cebd93eaf9e4c75858a4fad0b10d38cb6ad2/687474703a2f2f692e696d6775722e636f6d2f6733495855646f2e6a7067" alt="Captured frame" /></p>

<p>That picture is captured with a gain level of around <code class="language-plaintext highlighter-rouge">0</code> but I noticed in the logs that the tracking server was setting the gain level around <code class="language-plaintext highlighter-rouge">51</code>. But when I adjusted the gain that high٫
the 8 bit green values used to hold the image started wrapping around leading to a messed up image. This might be the cause of the tracking quality issues I’ve been having٫ but the real server
might do something to mitigate this. <strong>Edit:</strong> I’ve since discovered that lowering the exposure to compensate negates this issue٫ so I assume the real server uses a higher frame rate and lower exposure so they need the high gain setting. Another neat thing about the exposure is if you set it really long it can effectively take still pictures without the LEDs on.</p>

<p>Next I used the feature of the demo app to save a video to my drive٫ which interestingly started replacing some frames with pure green٫ which didn’t happen at all in the live preview.
I later discovered that the 1 minute movie it saved was <em>10 gigabytes</em> because it wasn’t using any compression. It is possible the dropped frames were my SSD bottlenecking the video capture.
Anyhow I compressed it down with Handbrake and uploaded it to Youtube٫ sorry for the annoying green frames.</p>

<p>In the video below you can see me looking at the four corners of my screen٫ and then some things on the screen. I then slowly adjust the gain setting upwards until it reaches <code class="language-plaintext highlighter-rouge">51</code> at which
point I wave my arms around to mark the time. Then I continue adjusting the gain up to maximum.</p>

<iframe width="660" height="495" src="https://www.youtube.com/embed/8CguH2EJqUo" frameborder="0" allowfullscreen=""></iframe>

<h2 id="update">Update</h2>

<p>After I first published this post I emailed The Eye Tribe with my info and story٫ and I got some help and info from them.
It turns out that the eye tracker isn’t working in as large of an area as it should (not sure why) so I can only use a 12” diagonal area of my screen instead of the full 24”.
If I use the small area I get much better accuracy٫ closer to +/- 1cm of jitter and a 0-4cm offset from my true gaze location. This is still not as good accuracy as advertized
and it works on a much smaller area than advertized٫ but it is better than before. It is still entirely useless to me though٫ the accuracy is good enough for my project٫ but the area is too small.
Note that I have seen videos of other people achieving the claimed accuracy٫ it is likely that there is still some special complicating factor with my unit or setup٫ most customers probably have no issues.</p>

<p>This is post is also not ment to bash The Eye Tribe. They’re my second favourite eye tracking company after <a href="https://pupil-labs.com/pupil/">Pupil Labs</a>. Despite their closed source software they are
still significantly more open than most other eye tracking companies with orders of magnitude lower cost.</p>

<h2 id="update-2">Update 2</h2>

<p>I’ve now figured out how to properly retrieve high resolution 60fps video at the full 10 bit depth.
The tracker has a variety of resolutions available٫ higher resolutions only work with lower frame rates.
The highest resolution is 2304x1536 which is available at 27FPS. Some of the resolutions offered are scaled down versions of the full image٫ whereas others are cropped areas of it.
In order to get the full 60FPS you have to lower the exposure time٫ which significantly increases the noiseness of the image.</p>

<p>The pixels are encoded in YUY2 format where the lowest 8 bits of brightness are in the Y component and the highest 2 are in the UV component.</p>

<p>I’ve created a <a href="https://github.com/trishume/SmartGaze">project on Github called SmartGaze</a> where I’ve done a little bit of work on implementing eye tracking algorithms for the Eye Tribe.
So far I’ve retrieved the raw feed using <a href="https://github.com/ktossell/libuvc">libuvc</a>٫ found the eye regions using glints٫ and then used an implementation of the <a href="http://thirtysixthspan.com/openEyes/software.html">Starburst algorithm</a>
to locate the iris ellipse. The repo is released under the GPLv2 but <a href="https://github.com/trishume/SmartGaze/tree/d8cc7a767f6a451d69905a9d67a95e16d14f401a">an earlier commit</a> containing just the code to read the raw 10 bit feed is released under the MIT license. I may or may not decide to finish this given that I recently got a <a href="https://steelseries.com/gaming-controllers/sentry-gaming-eye-tracker">Steelseries Sentry</a> that works well for me when I run it in a Windows VM and <a href="https://gist.github.com/trishume/b25492f25fc8ebe01dd9">pipe the data over UDP</a> to my mac.</p>

<p>Here’s a video of the raw feed. The fact that you can hardly see the pupils in this video is a product of how I reduced the 10 bit image down to 8 bits٫ as well as not setting the PU_GAIN UVC control.
More recent commits of SmartGaze use a much brighter video٫ but one that washes out details of the face.</p>

<iframe width="660" height="495" src="https://www.youtube.com/embed/nfCrLg9DnGc" frameborder="0" allowfullscreen=""></iframe>
'),('http://thume.ca/2015/11/19/amazing-profs-of-waterloo-2015/', 'Amazing Profs of Waterloo 2015', '1447891200000',  13, '
<p>During my three terms at The University of Waterloo so far every single professor I’ve had has been quite good. Some however٫ are amazing. Each of these amazing profs is amazing in very different ways. Some are great lecturers٫ some great teachers and some great people.</p>

<p>In this post I’ll highlight some of the great professors I’ve had so far and what makes them amazing.</p>

<h2 id="prabhakar-ragde-cs-146---the-educator">Prabhakar Ragde (CS 146) - The Educator</h2>

<p>Prabhakar is the most dedicated <em>teacher</em> I have ever had. He spends an incredible amount of time and effort refining his lecture material and designing his courses to be the best they can be. He goes above and beyond to make sure that students learn in the best way possible. He had some trouble finding a good way to teach self-balancing binary trees٫ so he went and did original research and formulated a purely functional self-balancing binary tree data structure that’s main advantage is to being easier to learn. It seems to almost physically pain him to see something not taught well. Every teacher should aspire to be as good at teaching as Prabhakar is.</p>

<h3 id="protip">Protip™</h3>

<p>He teaches the advanced CS courses in first year٫ but he teaches them so well that for many people they are easier than the normal courses. The material is indeed more advanced٫ but the assignments are less work and the tests have bonus marks so it is easier to get high marks. I highly recommend taking CS 145 and 146.</p>

<p>He is also addicted to Twitter٫ follow him if you want to know about all the fancy food he eats.</p>

<h2 id="jan-kycia-mns-101---the-renaissance-man">Jan Kycia (MNS 101) - The Renaissance Man</h2>

<p>Jan’s lectures are good٫ he’s an effective speaker and does very neat physics demos in class. What is really incredible about him is his breadth and depth of knowledge. Never in my life have I met anybody so knowledgeable in so many different fields. He’s a physicist by training٫ but also knows a ton about electronics٫ engineering٫ machining٫ measurement٫ plumbing٫ materials and really cold things. He leads a <a href="http://science.uwaterloo.ca/~jkycia/">low temperature lab</a> (he says “millikelvin” a lot) where he uses all these skills to build some highly impressive things. Have I mentioned he’s also really nice and friendly?</p>

<p>I would say that “Any sufficiently advanced technologist is indistinguishable from a wizard” except that Jan will gladly show you all of his tricks if you ask. I have an incredible amount of respect for Jan and look up to him as a model of a truly formidable human being.</p>

<h3 id="protip-1">Protip™</h3>

<p>After every class for around 40 minutes he answers student questions٫ goes on interesting tangents٫ and sometimes gives lab tours and descriptions of his research. It is very much worth your time to stick around for these٫ I have never once regretted staying after class to learn new and interesting things from him٫ even if they aren’t part of the course. Especially follow him whenever he brings students down to the lab to pick up assignments٫ that place is a technological wonderland and he gives amazing tours and research overviews if you ask.</p>

<p>Also٫ MNS 101 (an introduction to material science) is a great course to take. It is very interesting and is a science that most people haven’t had any exposure to in high school.</p>

<h3 id="things-i-have-seen-in-his-lab">Things I have seen in his lab</h3>

<ul>
  <li>Custom-designed electronic measurement equipment.</li>
  <li>High-precision custom-machined heat pumps.</li>
  <li>Custom-made vibration isolating vacuum pipe flextures.</li>
  <li>Superconducting silicon wafer integrated circuits custom-fabricated in house.</li>
  <li>Decades-old equipment that he has scavenged for pennies on the dollar and then painstakingly fixed up to working condition.</li>
</ul>

<h3 id="examples-of-things-he-has-talked-about-after-class">Examples of things he has talked about after class</h3>

<ul>
  <li>The little-known secrets to creating incredibly pure samples of a material using a plasma arc melter٫ electrical discharge machining٫ acid baths٫ and many other steps.</li>
  <li>How to procure an x-ray crystallography set-up on the cheap by buying used DNA flourescence scanners from hospitals.</li>
  <li>The different types of superconducting and non-superconducting wire to use at temperatures approaching 0 kelvin.</li>
  <li>The design factors to take into account when reducing vibrational heating through pipe flextures that must handle vacuum forces.</li>
  <li>How to create strong non-heat-conductive supports by cutting up carbon fiber hunting arrows.</li>
</ul>

<h2 id="eric-helleiner-psci-150---the-lecturer">Eric Helleiner (PSCI 150) - The Lecturer</h2>

<p>Helleiner’s lectures just make you want to listen. He’s enthusiastic about what he teaches in a very friendly way. I just really like listening to him talk about interesting political science things. He’s also knowledgeable and teaches interesting PSCI classes٫ but the reason he’s on this list is that his lectures are just really enjoyable.</p>

<h3 id="protip-2">Protip™</h3>

<p>Go to his office hours some time٫ maybe bring a friend٫ and just talk to him about interesting politics things. I skipped class to do this once and me and my friend chatted with him for over an hour.</p>
'),('http://thume.ca/2015/03/30/wikipedia-link-graphs-and-terrible-hacks/', 'Wikipedia Link Graphs and Terrible Hacks', '1427673600000',  13, '
<p>A couple months ago <a href="http://davepagurek.com/">Dave Pagurek</a> and I decided on making an <a href="http://ratewithscience.thume.net">arbitrary scale finder</a> for the upcoming UWaterloo <a href="http://terriblehack.website">“stupid shit no one needs” hackathon</a>. I decided that I would do this by finding paths in the links between Wikipedia pages. The thing is to do this I needed a good data set in the right format.</p>

<p>I did some research and found <a href="http://mu.netsoc.ie/wiki/">Six Degrees of Wikipedia</a> which had some information but no data or source files. I then found <a href="https://github.com/mirkonasato/graphipedia">Graphipedia</a> but discovered that Neo4j was not fast enough to do what I wanted. Thus I embarked on the adventure of creating my own Wikipedia link graph data set designed for efficient execution of common graph algorithms. The premise was compressing the whole graph into a small(ish) file that would fit entirely in memory٫ so I called it <a href="https://github.com/trishume/wikicrush">Wikicrush</a>.</p>

<p>I spent the next few weeks occasionally working on a set of Ruby scripts that in multiple stages processed the 10GB compressed <code class="language-plaintext highlighter-rouge">enwiki-20150205-pages-articles.xml.bz2</code> file into two 500mb files: <code class="language-plaintext highlighter-rouge">xindex.db</code> and <code class="language-plaintext highlighter-rouge">indexbi.bin</code>. For each stage in the process I ensured that it worked in O(n) time and reasonable memory. This way I could use crunch through the entire thing over a day on a cheap VPS. During development I would use the smaller Simple English wiki which I could process in a few minutes on my laptop. The advantage of the multi-stage design is that if I needed to tweak something I could just re-run the stages after that point rather than the whole thing. The intermediate files it created were also very useful for debugging and could be useful data sets in their own right.</p>

<p><img src="/assets/postassets/wikicrush/ssh-screenshot.png" alt="VPS Working Away" /></p>

<p>I ended up with two files I’m rather proud of٫ one is a binary link graph in a custom format I designed myself designed to fit in memory and allow very efficient searching and processing. The other is simply an Sqlite index designed to translate article titles into offsets into the binary file and back again. The formats are fairly easy to work with in any imperative language and have many handy features. I documented the formats in detail in the <a href="https://github.com/trishume/wikicrush#primary-data">Wikicrush readme</a>. They work so well that my $10/month VPS can easily breadth first search through millions of articles in less than a second.</p>

<p>I had the initial version working fairly quickly but had to spend a bunch of time fixing small bugs to get it to accurately represent the actual link graph of Wikipedia. I had to fix things like following redirects٫ cutting out broken links٫ ignoring links in comments and proper handling of case in links (I ended up lowercasing everything). Although making your own Wikipedia data set may seem easy at first٫ there’s plenty of ways things can go wrong. Many times I thought I had a good complete data set and only later would I realize something was wrong. One time I thought I had finally worked out the kinks and then discovered weeks later that it thought 70% of links on Wikipedia were invalid٫ which obviously isn’t true. Even just yesterday I found and fixed a little bug that only affected 300 articles٫ but the perfectionist in me sent my VPS to slave away for another 40 hours of rebuilding.</p>

<p><strong>Edit:</strong> I recently found another glitch and overhauled the entire process to be more robust. I now think I’ve shaken out all the bugs so I have put up a download of the final product.
You can find the link on the <a href="https://github.com/trishume/wikicrush">Wikicrush readme</a>. I also no longer need to lowercase everything. This is AFAIK the only Wikipedia link graph dataset available for public download.</p>

<h2 id="the-terrible-hacks-hackathon">The Terrible Hacks Hackathon</h2>

<p>During the hackathon some parts went very smoothly while others did not. Working with the files I had created was very easy٫ working with the Rust language for my first time was not. At some point I could not link my graph search algorithm to the <a href="https://github.com/iron/iron">Iron</a> web framework because my algorithm and Sqlite connection were not thread safe and one can not disable type system based thread safety checks in Iron with Rust. I ended up with a suitably terrible hack which was having the Rust code communicate over stdin/stdout and having a Ruby Sinatra server interface with that. Along with that٫ all the paths were hard coded٫ it required a specific <code class="language-plaintext highlighter-rouge">rustc</code> commit and one had to manually fiddle with the <code class="language-plaintext highlighter-rouge">Cargo.toml</code> and <code class="language-plaintext highlighter-rouge">Cargo.lock</code> files to work around a bug in Cargo just to get it to compile. This made it practically impossible to install and run on anything but my laptop.</p>

<p>I eventually got things hacked together and by that time Dave had put together a fantastic front end with fancy CSS٫ autocomplete and REST loading. All I had to do was serve his static files and expose a JSON API.</p>

<p>Once we did that we had a product٫ and it ended up working great. The paths it generated were amusing and it was fun to use. Not to mention it looked pretty good for something put together in one afternoon:
<img src="/assets/postassets/wikicrush/rws-screenshot.png" alt="The Product" /></p>

<h2 id="the-rewrite">The Rewrite</h2>

<p>A week later I decided to kill two birds with one experimental statically-typed stone and learned the <a href="http://nim-lang.org/">Nim</a> language by rewriting the project in it. I ran into a couple similar problems with the Jester web framework and loading the file into an int32 array but unlike the similar problems in Rust these had easy workarounds. In the end everything worked reasonably well with Nim especially after I got some help on IRC from its creator.</p>

<p>You can now visit and try out <a href="http://ratewithscience.thume.net/">Rate With Science</a> powered purely by Nim and backed by Wikicrush.</p>
'),('http://thume.ca/2015/03/14/idea-a-viral-industrial-charity/', 'Idea: A Viral Industrial Charity', '1426291200000',  13, '
<p>Deviating from the usual programming content of this blog I’d like to talk about an idea I’ve been thinking about recently. This week I went to a talk by <a href="http://lewisdartnell.com/en-gb/">Lewis Dartnell</a> author of the most interesting non-fiction book I’ve ever read called <a href="http://the-knowledge.org/en-gb/the-book/">The Knowledge</a>. It’s a book that explores the essential science and technology necessary to build a modern society from the perspective of bootstrapping civilization after the apocalypse. The apocalypse is merely a convenient thought experiment though٫ its a fantastic read just to learn about all the hidden industrial processes and science that keeps the world working today.</p>

<p>Personally the book got me thinking about how this idea of bootstrapping might help in the modern world. I also learned about the fundamental behind the scenes industrial processes that keep the world running٫ like the Haber-Bosch Process and the production of fundamental chemicals like lime. It gave me huge respect for how incredible difficult it is to create an industrial civilization.</p>

<p>The most interesting idea I’ve thought of٫ and I’m sure this idea isn’t unique٫ is the possibility of a viral industrial charity. Suppose there exists a set of machinery٫ tools and knowledge which a group of people can use to produce a second set of machines in a reasonable time span like one year. The other criterion for these machines are that they can be used to productively ensure a decent standard of living for those working on reproducing them.</p>

<p>If funding could be found to build one set of these machines٫ they could be set up in a third-world country as a kind of employer. A group of 100 or so people would be trained to use the machines and they would work to produce a new set and be compensated with the right to use the machines to provide themselves with good housing٫ food and other useful things. The magic comes once they finish the second set of machines and can use it to establish another village. Now there are two villages producing new sets and exponential growth takes hold٫ with luck the charity could grow to create thousands of new industrialized villages per year. With the only infusion of charity capital being the initial set٫ some management and perhaps a small kit for each new village of very difficult to produce items like machine control computers.</p>

<p>This is by no means a perfect plan٫ there are many potential issues. Chief among them is that this set of machinery does not yet exist. Technology is awesome but it is also hard and highly interdependent. It is difficult to satisfy both of the dual criteria of having no external dependencies and being useful for sustaining an independent village. There is a project called the <a href="http://opensourceecology.org/wiki/Global_Village_Construction_Set">Global Village Construction Set</a> that is trying to do just this but it is slow and difficult. They have some great ideas but designing all these machines is a lot of work and they have not solved the closed dependency problem despite trying very hard. Many of their machines require some external parts such as ball bearings and microcontrollers٫ which need very precise dedicated machinery to produce. It is likely that any set of reproducing machines might need a box of small precision parts like ball bearings and integrated circuits to close the cycle. However٫ if this box is cheap enough a charity could support the exponential growth without too much fund raising.</p>

<p>The other technological challenge is resources. For the village to be self-sufficient it would have to produce its own materials and food. Farming can be done in many locations especially with good tools٫ but natural resources are often very spread out. The solution to this is probably to make everything out of a minimal set of different materials that are produced from very common natural resources. One idea from the Global Village Construction Set is the possibility of electrolyzing aluminum from clay. Clay is very common٫ easy to extract and can be used to make bricks٫ ceramic objects and aluminum metal (with some difficulty). A village built near a clay deposit٫ a river and some fertile land for farming with some natural or planted woodland nearby might be able to produce all the resources it needs. The village may still need to do some trading perhaps of aluminum for scrap steel to produce high stress specialized parts though٫ steel mining and refining is likely beyond the capability of a small village yet steel is necessary for many useful machines.</p>

<p>The other thing to think about is the charity structure itself. It has the virtue of not being very dependent on the external economy and enabling self-sufficiency. However٫ it does require at least some managerial and government structure to ensure that the people living in the village continue producing new sets of machinery instead of just using them to satisfy their own needs. This should be possible in any country with a decent government٫ it could probably be set up legally as an employer٫ albeit an unconventional one. Villagers who stopped producing machinery would be breaking the law in the same way as factory employees would be if they started stealing the output of the factory and taking it home. And I’m sure the occupants/employees would at least feel content with the idea that the purpose of their hard work is to help lift others out of poverty. They would of course also be compensated with a standard of living higher than they were used to.</p>

<p>As long as no one has designed this theoretical village this plan remains just an idea. However٫ the <a href="http://opensourceecology.org/wiki/Global_Village_Construction_Set">Global Village Construction Set</a> is doing a great job and it is possible that years in the future it will be polished enough that with some start up capital and planning this could be a real endeavour. For my part I might even try to help design some of the machines on their to-do list as a fun hobby and way of learning about machinery.</p>

<p>For anyone who found the content of this post interesting٫ I highly recommend you read <a href="http://the-knowledge.org/en-gb/the-book/">The Knowledge</a> and take a look at the wiki for the <a href="http://opensourceecology.org/wiki/Global_Village_Construction_Set">Global Village Construction Set</a>. I just thought I’d put this idea out there to see if anyone else has comments on it٫ I by no means think this is a perfect plan and it likely would have many practical tripping points. However٫ if these problems could be solved its potential impact per dollar invested is amazing.</p>
'),('http://thume.ca/howto/2015/03/07/configuring-spacemacs-a-tutorial/', 'Configuring Spacemacs: A Tutorial', '1425686400000',  13, '
<p><strong>Edit:</strong> Some things in this post are now outdated. I’m currently using Sublime Text with Vim keybindings instead of Spacemacs so I haven’t been keeping up. I’ve fixed some things (Thanks Fabien!) but others may remain. If you want to fix something outdated <a href="https://github.com/trishume/trishume.github.com/blob/master/_posts%2F2015-03-07-configuring-spacemacs-a-tutorial.md">submit a PR to my website</a>.</p>

<p>A few months ago I switched to using <a href="https://github.com/syl20bnr/spacemacs">Spacemacs</a> as my text editor of choice. It has great vim keybindings and extensive default configs for a variety of packages. I’ve become one of the top contributors to Spacemacs and I’ve learned a few things about configuring it in the process. This post will function as a tutorial to get you started with configuring Spacemacs to your liking.</p>

<p>You can get started using Spacemacs by following the installation instructions in the <a href="https://github.com/syl20bnr/spacemacs">readme</a> and perusing the in-depth <a href="https://github.com/syl20bnr/spacemacs/blob/master/doc/DOCUMENTATION.org">documentation</a>.</p>

<h1 id="the-spacemacs-file">The .spacemacs File</h1>

<p>The <code class="language-plaintext highlighter-rouge">~/.spacemacs</code> file is your main starting point for configuring Spacemacs. If you don’t have this file you can install a template pressing <code class="language-plaintext highlighter-rouge">SPC : dotspacemacs/install RET</code> in Spacemacs٫ where <code class="language-plaintext highlighter-rouge">SPC</code> is space and <code class="language-plaintext highlighter-rouge">RET</code> is the enter key. At any time you can press <code class="language-plaintext highlighter-rouge">SPC f e d</code> to edit this file.</p>

<p>The template comes with many variables that you can customize and use to set things like font sizes and window preferences. Once you are done editing٫ save the file and either press <code class="language-plaintext highlighter-rouge">SPC f e R</code> in the file to reload it or just restart Spacemacs.</p>

<p>Some parts of this file are more important than others:</p>

<h2 id="dotspacemacsuser-config">dotspacemacs/user-config</h2>

<p>This function is run after Spacemacs sets itself up٫ in here you can customize variables and activate extra functionality you want. Perhaps the most important thing to know is that this is generally where you can paste random snippets of Emacs Lisp you find on the internet. If a page says to put a snippet into your <code class="language-plaintext highlighter-rouge">init.el</code> file <strong>don’t do that</strong>٫ put it in <code class="language-plaintext highlighter-rouge">dotspacemacs/user-config</code> instead.</p>

<p>Another thing this function is useful for is setting the default state of some toggleable editor preferences. If you press <code class="language-plaintext highlighter-rouge">SPC t</code> you will see some of the things you can toggle٫ these include line numbers٫ line wrapping٫ current line highlight٫ etc…</p>

<p>Most of these toggles actually enable and disable “minor modes”٫ if you want some of these on or off by default you can put things like these in your <code class="language-plaintext highlighter-rouge">dotspacemacs/user-config</code> function:</p>

<figure class="highlight"><pre><code class="language-lisp" data-lang="lisp"><span class="p">(</span><span class="nb">defun</span> <span class="nv">dotspacemacs/user-config</span> <span class="p">()</span>
  <span class="p">(</span><span class="nv">global-hl-line-mode</span> <span class="mi">-1</span><span class="p">)</span> <span class="c1">; Disable current line highlight</span>
  <span class="p">(</span><span class="nv">global-linum-mode</span><span class="p">))</span> <span class="c1">; Show line numbers by default</span></code></pre></figure>

<h2 id="dotspacemacs-configuration-layers">dotspacemacs-configuration-layers</h2>

<p>This brings us to <strong>configuration layers</strong> the most core concept of Spacemacs. Not all parts of Spacemacs are enabled by default٫ there are a large number of user contributed “layers” that add packages and configs for things like programming languages٫ external tools and extra functionality. Layers specify which packages they want Spacemacs to install for them٫ how to load the package and often include some default configs to make the package integrate well with the rest of Spacemacs.</p>

<p>The <code class="language-plaintext highlighter-rouge">dotspacemacs-configuration-layers</code> variable٫ set in the <code class="language-plaintext highlighter-rouge">dotspacemacs/layers</code> function near the top of the template is where you specify which layers you want to include. When you find yourself wondering “does Spacemacs come with support for X?” you can simply type <code class="language-plaintext highlighter-rouge">SPC f e h</code> and search through the built in layers. Once you find one you want to include simply include it in the list in the variable set statement. This is what mine looks like:</p>

<figure class="highlight"><pre><code class="language-lisp" data-lang="lisp"><span class="nv">dotspacemacs-configuration-layers</span> <span class="o">"</span><span class="p">(</span><span class="nv">extra-langs</span> <span class="nv">auctex</span>
  <span class="nv">company-mode</span> <span class="nv">git</span> <span class="nv">c-c++</span> <span class="nv">haskell</span> <span class="nv">html</span> <span class="nv">javascript</span> <span class="nv">ruby</span> <span class="nv">ycmd</span>
  <span class="nv">smex</span> <span class="nv">dash</span> <span class="nv">colors</span> <span class="nv">lua</span> <span class="nv">trishume</span> <span class="nv">markdown</span> <span class="nv">finance</span><span class="p">)</span></code></pre></figure>

<p>Yah٫ I use a lot of layers; you should too٫ they’re pretty important! You can see staples like “html” and “ruby” as well as fancier functionality ones like “company-mode”. Try looking through <a href="https://github.com/syl20bnr/spacemacs/tree/master/layers">the “layers” directory</a> to see all the available contributed layers and their Readme’s and source code.</p>

<h1 id="your-own-layers">Your Own Layers!</h1>

<p>You too could be the author of your very own layer! In fact٫ you’ll likely find you want to after you have used Spacemacs for a while. The most important purpose of layers is adding <a href="http://melpa.org/">MELPA</a> packages and the configuration and keybindings for them. <strong>Don’t</strong> try and just install packages with the default Emacs package manager like the internet might tell you to do!</p>

<p>If you want to install a package you found online٫ like <a href="http://melpa.org/#/2048-game">2048-game</a>٫ you’ll want to create a layer that includes the package and sets it up. Another option for small things is to add the package to the <code class="language-plaintext highlighter-rouge">dotspacemacs-additional-packages</code> list. There are a couple of places you can put this layer٫ which is really just a folder with some emacs lisp files:</p>

<h2 id="the-private-directory">The “private” Directory</h2>

<p>This is a folder in the main Spacemacs directory where you can put configuration layers for your own personal use.
You can create a template layer in this directory using <code class="language-plaintext highlighter-rouge">&lt;SPC&gt; : configuration-layer/create-layer RET</code>.</p>

<p>The descriptive comments in the template <code class="language-plaintext highlighter-rouge">packages.el</code> do a pretty good job of explaining what to do. Basically you add the package you want to include to the <code class="language-plaintext highlighter-rouge">yourlayernamehere-packages</code> list and then create <code class="language-plaintext highlighter-rouge">yourlayernamehere-init-yourpackagenamehere</code> functions where you use <a href="https://github.com/jwiegley/use-package">use-package</a> to load the package and set it up. Take a look at <a href="https://github.com/syl20bnr/spacemacs/tree/master/layers/%2Btools/finance">existing layers</a> for examples of how to set up packages and keybindings.</p>

<p>Once you have written a layer <strong>you have to load it in .spacemacs</strong> just like any other layer. Add your layer’s name to <code class="language-plaintext highlighter-rouge">dotspacemacs-configuration-layers</code>.</p>

<h2 id="dotspacemacs-configuration-layer-path">dotspacemacs-configuration-layer-path</h2>

<p>If you want to keep your layers in a git repository or Dropbox sync or some other folder٫ you can use the <code class="language-plaintext highlighter-rouge">dotspacemacs-configuration-layer-path</code> variable in <code class="language-plaintext highlighter-rouge">.spacemacs</code> to set another folder where you can load layers from. Then you can just copy the layer directory that Spacemacs puts in the private directory into this directory and Spacemacs will be able to load it from there.</p>

<h2 id="the-contrib-directory">The “contrib” Directory</h2>

<p>If you are adding some awesome new functionality to Spacemacs٫ which you probably are٫ you should seriously consider contributing it back. This is how Spacemacs has grown into the awesome distribution that it is. Don’t worry about people finding it hacky or not useful٫ we won’t mind and might even help you make it better.</p>

<p>This is what I do٫ I’m proud to say that I only have 1 private layer٫ <a href="https://github.com/syl20bnr/spacemacs/tree/064a598bff56f7cef1ac2ddf1c43684357dde56a/contrib/company-mode">every</a> <a href="https://github.com/syl20bnr/spacemacs/tree/064a598bff56f7cef1ac2ddf1c43684357dde56a/contrib/lang/extra-langs">other</a> <a href="https://github.com/syl20bnr/spacemacs/tree/064a598bff56f7cef1ac2ddf1c43684357dde56a/contrib/ycmd">layer</a> <a href="https://github.com/syl20bnr/spacemacs/tree/064a598bff56f7cef1ac2ddf1c43684357dde56a/contrib/auctex">I’ve</a> <a href="https://github.com/syl20bnr/spacemacs/tree/064a598bff56f7cef1ac2ddf1c43684357dde56a/contrib/ranger-control">written</a> has been contributed back to Spacemacs. It’s as simple as forking Spacemacs٫ adding your layer to <code class="language-plaintext highlighter-rouge">contrib</code> and submitting a Github pull request.</p>

<h2 id="tips-for-writing-layers">Tips For Writing Layers</h2>

<p>There’s a couple things that are nice to know when writing layers. The most important thing to know is some of the features of <a href="https://github.com/jwiegley/use-package">use-package</a>. You use this in the init functions in <code class="language-plaintext highlighter-rouge">packages.el</code> to load the package and set it up. The function takes a package name and some attributes containing things like functions to run on load. You use use-package <strong>instead of</strong> doing whatever loading step the package readme tells you to do٫ generally you don’t include things like <code class="language-plaintext highlighter-rouge">(require "blah)</code>.</p>

<h3 id="basic-format">Basic Format</h3>

<figure class="highlight"><pre><code class="language-lisp" data-lang="lisp"><span class="p">(</span><span class="nb">defun</span> <span class="nv">finance/init-ledger-mode</span> <span class="p">()</span>
  <span class="p">(</span><span class="nb">use-package</span> <span class="nv">ledger-mode</span>
    <span class="c1">; Use :mode to set language modes to automatically activate on certain extensions</span>
    <span class="ss">:mode</span> <span class="p">(</span><span class="s">"\\.\\(ledger\\|ldg\\)\\""</span> <span class="o">.</span> <span class="nv">ledger-mode</span><span class="p">)</span>
    <span class="c1">; :defer t activates lazy loading which makes startup faster</span>
    <span class="ss">:defer</span> <span class="no">t</span>
    <span class="c1">; The code in :init is always run٫ use it to set up config vars and key bindings</span>
    <span class="ss">:init</span>
    <span class="p">(</span><span class="k">progn</span> <span class="c1">; :init only takes one expression so use "progn" to combine multiple things</span>
      <span class="c1">; You can configure package variables here</span>
      <span class="p">(</span><span class="k">setq</span> <span class="nv">ledger-post-amount-alignment-column</span> <span class="mi">62</span><span class="p">)</span>
      <span class="c1">; Using evil-leader/set-key-for-mode adds bindings under SPC for a certain mode</span>
      <span class="c1">; Use evil-leader/set-key to create global SPC bindings</span>
      <span class="p">(</span><span class="nv">evil-leader/set-key-for-mode</span> <span class="ss">"ledger-mode</span>
        <span class="s">"mhd"</span>   <span class="ss">"ledger-delete-current-transaction</span>
        <span class="s">"m RET"</span> <span class="ss">"ledger-set-month</span><span class="p">))</span>
    <span class="ss">:config</span> <span class="c1">; :config is called after the package is actually loaded with defer</span>
      <span class="c1">; You can put stuff that relies on the package like function calls here</span>
      <span class="p">(</span><span class="nv">message</span> <span class="s">"Ledger mode was actually loaded!"</span><span class="p">)))</span></code></pre></figure>

<h3 id="things-that-arent-packages">Things that aren’t packages</h3>

<p>If you want to bundle up some snippet or config that isn’t related to a package you can use the <code class="language-plaintext highlighter-rouge">config.el</code>
file in the layer. In here you can just put Emacs Lisp code and functions that will be evaluated when a layer is loaded.</p>

<h3 id="dependencies">Dependencies</h3>

<p>Sometimes you want to hook something in your layer into another package. This is most common for making sure your alayer works well with default packages like smartparens. To do this you’ll want to use <code class="language-plaintext highlighter-rouge">eval-after-load</code>. <a href="https://github.com/syl20bnr/spacemacs/blob/064a598bff56f7cef1ac2ddf1c43684357dde56a/contrib/ansible/packages.el#L24">Here’s an example</a> of a package adding extra functionality to <code class="language-plaintext highlighter-rouge">yaml-mode</code>.</p>

<h1 id="other-information">Other Information</h1>

<p>This guide hopefully gave you enough info to get started٫ but there’s so much more to Spacemacs that isn’t here. There’s a bunch of other sources of information that you should look at if you can’t find what you want:</p>

<h2 id="the-gitter-chat">The Gitter Chat</h2>

<p>Please visit the <a href="https://gitter.im/syl20bnr/spacemacs">Gitter chat room</a> if you have any questions about configuring or using Spacemacs that you can’t figure out٫ or just come to chat with other Spacemacs users. There’s always tons of knowledgeable people there٫ including the awesome maintainer @syl20bnr٫ who will help you out.</p>

<h2 id="the-documentation">The Documentation</h2>

<p>Most of these layer concepts and mechanics are explained in depth in the massive <a href="https://github.com/syl20bnr/spacemacs/blob/master/doc/DOCUMENTATION.org">Documentation</a>. It also has information on lots of the functionality available in Spacemacs.</p>

<h2 id="the-source-code">The Source Code!</h2>

<p>If you want deep insight into the workings of Spacemacs you should really take a look at the <a href="https://github.com/syl20bnr/spacemacs">source code</a> on Github. The main difference between me and the average Spacemacs user is that I have read lots of the source and thus I know a lot about how Spacemacs works. I swear it’s really not that complicated٫ you’ll discover that most of Spacemacs is actually just the <code class="language-plaintext highlighter-rouge">spacemacs</code> layer which is just like any other configuration layer except it is included by default. You can also read the code for the contrib layers for ideas٫ although the techniques these use might be less consistent since they were written by lots of differnt people٫ many of them newbies. For a good start I recommend skimming through this <a href="https://github.com/syl20bnr/spacemacs/blob/master/layers/%2Bdistributions/spacemacs-base/packages.el">packages.el</a> file. You can also use <code class="language-plaintext highlighter-rouge">SPC h SPC</code> to search for layers and hit enter to visit their source.</p>

<h1 id="conclusion">Conclusion</h1>

<p>I hope this helped you on your way to become a Spacemacs power-user. This guide was rather specific to configuration but I plan on maybe writing other tutorials on basic use and other tips. Don’t forget to say hi to me and all the other awesome Spacemacs people in the <a href="https://gitter.im/syl20bnr/spacemacs">Gitter chat</a>٫ we always love hearing from other Spacemacs users!</p>
'),('http://thume.ca/howto/2014/12/02/using-mjolnir-an-extensible-osx-window-manager/', 'Using Mjolnir: An Extensible OSX Window Manager', '1417478400000',  13, '
<p><strong>Edit: I am now using <a href="http://www.hammerspoon.org/">Hammerspoon</a> which is a fork of Mjolnir that is basically the same except it comes with the modules (no luarocks)٫ it’s under active development and the naming is slightly different and more consistent. Most of this article still applies.</strong></p>

<p>Recently I started using the amazing and highly configurable window manager called <a href="http://mjolnir.io/">Mjolnir</a>.
But really it isn’t a window manager٫ it’s an OSX wrapper around a Lua configuration file and event loop that
has a constellation of modules that allow you to configure all sorts of computer control tasks. The most common use
for Mjolnir is managing Windows but there are all sorts of modules that allow you to use it for doing things like
<a href="https://github.com/asmagill/mjolnir-config/blob/master/utils/_actions/battery_usbdrives.lua">unmounting your USB drives when you switch to battery power</a>.</p>

<p>Two years ago I wrote a blog post about <a href="/howto/2012/11/19/using-slate/">configuring Slate</a>٫ the configurable window manager
that I had been using until this month. However٫ the maintainer hasn’t worked on Slate in years and there are dozens of pull requests sitting around without merge and comment. There have been <a href="https://github.com/mattr-/slate">attempts</a> to revive it٫
but there were still some rough edges and I decided to try something new.</p>

<p>Here I’ll describe how I use Mjolnir and my experience with it so far.</p>

<h2 id="getting-started">Getting Started</h2>

<p>The instructions on <a href="http://mjolnir.io/">Mjolnir’s homepage</a> are pretty good as far as getting Mjolnir installed goes.
You’ll need to get luarocks working and then create an <code class="language-plaintext highlighter-rouge">init.lua</code> file٫ which isn’t very hard.
The basic install you get can’t do much so you’ll have to use some of the many <a href="https://rocks.moonscript.org/search?q=mjolnir">Mjolnir modules</a>.
Before you use a module you have to install it first٫ to install <code class="language-plaintext highlighter-rouge">mjolnir.hotkey</code> you would run</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>luarocks install mjolnir.hotkey
</code></pre></div></div>

<h2 id="window-management">Window Management</h2>

<p>Mjolnir makes managing windows really easy with great modules to help you with this most of which are built upon the basic
functionality found in <a href="https://rocks.moonscript.org/modules/sdegutis/mjolnir.application">mjolnir.application</a>.
That module provides basic access to running applications and their windows٫ which modules like
<a href="https://github.com/BrianGilbert/mjolnir.bg.grid">mjolnir.bg.grid</a> use to provide things like the ability
to move windows around and resize on a grid. There are even fancier modules like
<a href="https://github.com/nathankot/mjolnir.tiling">mjolnir.tiling</a> which automatically organize your windows
like a fancy Linux tiling window manager would do.</p>

<h3 id="basic-key-bindings">Basic Key Bindings</h3>

<p>Generally the way you want to start is by binding actions (really just Lua functions) to keys using the <code class="language-plaintext highlighter-rouge">mjolnir.hotkey</code>.
Here’s an example from the Mjolnir homepage of binding a key that just nudges a window right:</p>

<figure class="highlight"><pre><code class="language-lua" data-lang="lua"><span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">({</span><span class="s2">"cmd"</span><span class="p">٫</span> <span class="s2">"alt"</span><span class="p">٫</span> <span class="s2">"ctrl"</span><span class="p">}٫</span> <span class="s2">"D"</span><span class="p">٫</span> <span class="k">function</span><span class="p">()</span>
  <span class="kd">local</span> <span class="n">win</span> <span class="o">=</span> <span class="n">window</span><span class="p">.</span><span class="n">focusedwindow</span><span class="p">()</span>
  <span class="kd">local</span> <span class="n">f</span> <span class="o">=</span> <span class="n">win</span><span class="p">:</span><span class="n">frame</span><span class="p">()</span>
  <span class="n">f</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="mi">10</span>
  <span class="n">win</span><span class="p">:</span><span class="n">setframe</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="k">end</span><span class="p">)</span></code></pre></figure>

<p>Since it’s just Lua code you can also just directly pass function names and use variables to refer to common chords:</p>

<figure class="highlight"><pre><code class="language-lua" data-lang="lua"><span class="kd">local</span> <span class="n">mash</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"ctrl"</span><span class="p">٫</span> <span class="s2">"shift"</span><span class="p">}</span>
<span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">mash</span><span class="p">٫</span> <span class="s2">"c"</span><span class="p">٫</span> <span class="n">mjolnir</span><span class="p">.</span><span class="n">openconsole</span><span class="p">)</span></code></pre></figure>

<h3 id="using-a-grid">Using a Grid</h3>

<p>Personally I found the easiest way of doing window management was to use the <a href="https://github.com/BrianGilbert/mjolnir.bg.grid">mjolnir.bg.grid</a> module. It provides functions that allow you to shuffle windows around a grid of a configurable number of rows and
columns (3x3 by default). Here’s an example of some basic bindings inspired by <a href="https://github.com/vpetro/dotfiles/blob/master/.mjolnir/init.lua">this config</a>:</p>

<figure class="highlight"><pre><code class="language-lua" data-lang="lua"><span class="kd">local</span> <span class="n">grid</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.sd.grid"</span>
<span class="kd">local</span> <span class="n">hotkey</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.hotkey"</span>

<span class="n">grid</span><span class="p">.</span><span class="n">MARGINX</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">grid</span><span class="p">.</span><span class="n">MARGINY</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">grid</span><span class="p">.</span><span class="n">GRIDWIDTH</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">grid</span><span class="p">.</span><span class="n">GRIDHEIGHT</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1">-- a helper function that returns another function that resizes the current window</span>
<span class="c1">-- to a certain grid size.</span>
<span class="kd">local</span> <span class="n">gridset</span> <span class="o">=</span> <span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">٫</span> <span class="n">y</span><span class="p">٫</span> <span class="n">w</span><span class="p">٫</span> <span class="n">h</span><span class="p">)</span>
    <span class="k">return</span> <span class="k">function</span><span class="p">()</span>
        <span class="n">cur_window</span> <span class="o">=</span> <span class="n">window</span><span class="p">.</span><span class="n">focusedwindow</span><span class="p">()</span>
        <span class="n">grid</span><span class="p">.</span><span class="n">set</span><span class="p">(</span>
            <span class="n">cur_window</span><span class="p">٫</span>
            <span class="p">{</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">٫</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">٫</span> <span class="n">w</span><span class="o">=</span><span class="n">w</span><span class="p">٫</span> <span class="n">h</span><span class="o">=</span><span class="n">h</span><span class="p">}٫</span>
            <span class="n">cur_window</span><span class="p">:</span><span class="n">screen</span><span class="p">()</span>
        <span class="p">)</span>
    <span class="k">end</span>
<span class="k">end</span>

<span class="kd">local</span> <span class="n">mash</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"ctrl"</span><span class="p">٫</span> <span class="s2">"shift"</span><span class="p">}</span>
<span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">mash</span><span class="p">٫</span> <span class="s1">"n"</span><span class="p">٫</span> <span class="n">grid</span><span class="p">.</span><span class="n">pushwindow_nextscreen</span><span class="p">)</span>
<span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">mash</span><span class="p">٫</span> <span class="s1">"a"</span><span class="p">٫</span> <span class="n">gridset</span><span class="p">(</span><span class="mi">0</span><span class="p">٫</span> <span class="mi">0</span><span class="p">٫</span> <span class="mi">1</span><span class="p">٫</span> <span class="mi">2</span><span class="p">))</span> <span class="c1">-- left half</span>
<span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">mash</span><span class="p">٫</span> <span class="s1">"s"</span><span class="p">٫</span> <span class="n">grid</span><span class="p">.</span><span class="n">maximize_window</span><span class="p">)</span>
<span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">(</span><span class="n">mash</span><span class="p">٫</span> <span class="s1">"d"</span><span class="p">٫</span> <span class="n">gridset</span><span class="p">(</span><span class="mi">1</span><span class="p">٫</span> <span class="mi">0</span><span class="p">٫</span> <span class="mi">1</span><span class="p">٫</span> <span class="mi">2</span><span class="p">))</span> <span class="c1">-- right half</span></code></pre></figure>

<h2 id="window-hints">Window Hints</h2>

<p>One of my favourite parts of Mjolnir is that you can write your own modules in Lua and Objective C to hook into OSX
functionality that Mjolnir doesn’t support by default. The great thing is other people have already written all sorts
of modules to do things like <a href="https://github.com/Linell/mjolnir.lb.spotify">controlling Spotify</a>
and <a href="https://github.com/asmagill/mjolnir_asm.ui/tree/master/sound">playing sounds</a>.</p>

<p>Recently I wrote my own module in 4 hours or so that adds the window hints feature that I missed from Slate:
<a href="https://github.com/trishume/mjolnir.th.hints">mjolnir.th.hints</a>. Except I think I did it even better than Slate did.
It allows you to quickly switch apps and windows using “hints” that pop up when you hit a key that have a letter on them٫
when you press the letter it switches to that app.</p>

<p><img src="https://camo.githubusercontent.com/384052b64aa56146c1efb579b6fbdb60901987ea/687474703a2f2f692e696d6775722e636f6d2f6b744c6742574f2e706e67" alt="Hints Screenshot" /></p>

<p>All you have to do is bind it to a key:</p>

<figure class="highlight"><pre><code class="language-lua" data-lang="lua"><span class="kd">local</span> <span class="n">hints</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.th.hints"</span>
<span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">({</span><span class="s2">"cmd"</span><span class="p">}٫</span><span class="s2">"e"</span><span class="p">٫</span><span class="n">hints</span><span class="p">.</span><span class="n">windowHints</span><span class="p">)</span>
<span class="c1">-- You can also use this with appfinder to switch to windows of a specific app</span>
<span class="kd">local</span> <span class="n">appfinder</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.cmsj.appfinder"</span>
<span class="n">hotkey</span><span class="p">.</span><span class="n">bind</span><span class="p">({</span><span class="s2">"ctrl"</span><span class="p">٫</span><span class="s2">"cmd"</span><span class="p">}٫</span><span class="s2">"k"</span><span class="p">٫</span><span class="k">function</span><span class="p">()</span> <span class="n">hints</span><span class="p">.</span><span class="n">appHints</span><span class="p">(</span><span class="n">appfinder</span><span class="p">.</span><span class="n">app_from_name</span><span class="p">(</span><span class="s2">"Emacs"</span><span class="p">))</span> <span class="k">end</span><span class="p">)</span></code></pre></figure>

<h1 id="my-config">My Config</h1>

<p>My personal config is a bit fancier and more specific to me than you might want to start off with٫ but you might want to get
some ideas from it. You can find the latest version <a href="https://github.com/trishume/dotfiles/blob/master/hammerspoon/hammerspoon.symlink/init.lua">in my dotfiles repo</a>٫
but I’ve included my config at the time of writing later on the page because it will probably be simpler than my
config at the time you read this.</p>

<p>It has fancy features like rebinding the keys on keyboard layout change (which doesn’t always work).
Probably the best feature is a crappy implementation of something that mimics Slate’s support for layouts.</p>

<p><strong>Edit: see <a href="https://github.com/trishume/dotfiles/blob/master/hammerspoon/hammerspoon.symlink/init.lua">my dotfiles repo</a> for the Hammerspoon version.</strong></p>

<figure class="highlight"><pre><code class="language-lua" data-lang="lua"><span class="c1">-- Load Extensions</span>
<span class="kd">local</span> <span class="n">application</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.application"</span>
<span class="kd">local</span> <span class="n">window</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.window"</span>
<span class="kd">local</span> <span class="n">hotkey</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.hotkey"</span>
<span class="kd">local</span> <span class="n">keycodes</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.keycodes"</span>
<span class="kd">local</span> <span class="n">fnutils</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.fnutils"</span>
<span class="kd">local</span> <span class="n">alert</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.alert"</span>
<span class="kd">local</span> <span class="n">screen</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.screen"</span>
<span class="c1">-- User packages</span>
<span class="kd">local</span> <span class="n">grid</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.bg.grid"</span>
<span class="kd">local</span> <span class="n">hints</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.th.hints"</span>
<span class="kd">local</span> <span class="n">appfinder</span> <span class="o">=</span> <span class="nb">require</span> <span class="s2">"mjolnir.cmsj.appfinder"</span>

<span class="kd">local</span> <span class="n">definitions</span> <span class="o">=</span> <span class="kc">nil</span>
<span class="kd">local</span> <span class="n">hyper</span> <span class="o">=</span> <span class="kc">nil</span>

<span class="kd">local</span> <span class="n">gridset</span> <span class="o">=</span> <span class="k">function</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
	<span class="k">return</span> <span class="k">function</span><span class="p">()</span>
		<span class="kd">local</span> <span class="n">win</span> <span class="o">=</span> <span class="n">window</span><span class="p">.</span><span class="n">focusedwindow</span><span class="p">()</span>
		<span class="k">if</span> <span class="n">win</span> <span class="k">then</span>
			<span class="n">grid</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="n">win</span><span class="p">٫</span> <span class="n">frame</span><span class="p">٫</span> <span class="n">win</span><span class="p">:</span><span class="n">screen</span><span class="p">())</span>
		<span class="k">else</span>
			<span class="n">alert</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="s2">"No focused window."</span><span class="p">)</span>
		<span class="k">end</span>
	<span class="k">end</span>
<span class="k">end</span>

<span class="n">auxWin</span> <span class="o">=</span> <span class="kc">nil</span>
<span class="k">function</span> <span class="nf">saveFocus</span><span class="p">()</span>
  <span class="n">auxWin</span> <span class="o">=</span> <span class="n">window</span><span class="p">.</span><span class="n">focusedwindow</span><span class="p">()</span>
  <span class="n">alert</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="s2">"Window ""</span> <span class="o">..</span> <span class="n">auxWin</span><span class="p">:</span><span class="n">title</span><span class="p">()</span> <span class="o">..</span> <span class="s2">"" saved."</span><span class="p">)</span>
<span class="k">end</span>
<span class="k">function</span> <span class="nf">focusSaved</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">auxWin</span> <span class="k">then</span>
    <span class="n">auxWin</span><span class="p">:</span><span class="n">focus</span><span class="p">()</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="kd">local</span> <span class="n">hotkeys</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">function</span> <span class="nf">createHotkeys</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">key</span><span class="p">٫</span> <span class="n">fun</span> <span class="k">in</span> <span class="nb">pairs</span><span class="p">(</span><span class="n">definitions</span><span class="p">)</span> <span class="k">do</span>
    <span class="kd">local</span> <span class="n">mod</span> <span class="o">=</span> <span class="n">hyper</span>
    <span class="k">if</span> <span class="nb">string.len</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="nb">string.sub</span><span class="p">(</span><span class="n">key</span><span class="p">٫</span><span class="mi">2</span><span class="p">٫</span><span class="mi">2</span><span class="p">)</span> <span class="o">==</span> <span class="s2">"c"</span> <span class="k">then</span>
      <span class="n">mod</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"cmd"</span><span class="p">}</span>
    <span class="k">end</span>

    <span class="kd">local</span> <span class="n">hk</span> <span class="o">=</span> <span class="n">hotkey</span><span class="p">.</span><span class="n">new</span><span class="p">(</span><span class="n">mod</span><span class="p">٫</span> <span class="nb">string.sub</span><span class="p">(</span><span class="n">key</span><span class="p">٫</span><span class="mi">1</span><span class="p">٫</span><span class="mi">1</span><span class="p">)٫</span> <span class="n">fun</span><span class="p">)</span>
    <span class="nb">table.insert</span><span class="p">(</span><span class="n">hotkeys</span><span class="p">٫</span> <span class="n">hk</span><span class="p">)</span>
    <span class="n">hk</span><span class="p">:</span><span class="n">enable</span><span class="p">()</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="k">function</span> <span class="nf">rebindHotkeys</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">٫</span> <span class="n">hk</span> <span class="k">in</span> <span class="nb">ipairs</span><span class="p">(</span><span class="n">hotkeys</span><span class="p">)</span> <span class="k">do</span>
    <span class="n">hk</span><span class="p">:</span><span class="n">disable</span><span class="p">()</span>
  <span class="k">end</span>
  <span class="n">hotkeys</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="n">createHotkeys</span><span class="p">()</span>
  <span class="n">alert</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="s2">"Rebound Hotkeys"</span><span class="p">)</span>
<span class="k">end</span>

<span class="k">function</span> <span class="nf">applyPlace</span><span class="p">(</span><span class="n">win</span><span class="p">٫</span> <span class="n">place</span><span class="p">)</span>
  <span class="kd">local</span> <span class="n">scrs</span> <span class="o">=</span> <span class="n">screen</span><span class="p">:</span><span class="n">allscreens</span><span class="p">()</span>
  <span class="kd">local</span> <span class="n">scr</span> <span class="o">=</span> <span class="n">scrs</span><span class="p">[</span><span class="n">place</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
  <span class="n">grid</span><span class="p">.</span><span class="n">set</span><span class="p">(</span><span class="n">win</span><span class="p">٫</span> <span class="n">place</span><span class="p">[</span><span class="mi">2</span><span class="p">]٫</span> <span class="n">scr</span><span class="p">)</span>
<span class="k">end</span>

<span class="k">function</span> <span class="nf">applyLayout</span><span class="p">(</span><span class="n">layout</span><span class="p">)</span>
  <span class="k">return</span> <span class="k">function</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">appName</span><span class="p">٫</span> <span class="n">place</span> <span class="k">in</span> <span class="nb">pairs</span><span class="p">(</span><span class="n">layout</span><span class="p">)</span> <span class="k">do</span>
      <span class="kd">local</span> <span class="n">app</span> <span class="o">=</span> <span class="n">appfinder</span><span class="p">.</span><span class="n">app_from_name</span><span class="p">(</span><span class="n">appName</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">app</span> <span class="k">then</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">٫</span> <span class="n">win</span> <span class="k">in</span> <span class="nb">ipairs</span><span class="p">(</span><span class="n">app</span><span class="p">:</span><span class="n">allwindows</span><span class="p">())</span> <span class="k">do</span>
          <span class="n">applyPlace</span><span class="p">(</span><span class="n">win</span><span class="p">٫</span> <span class="n">place</span><span class="p">)</span>
        <span class="k">end</span>
      <span class="k">end</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="k">function</span> <span class="nf">init</span><span class="p">()</span>
  <span class="n">createHotkeys</span><span class="p">()</span>
  <span class="n">keycodes</span><span class="p">.</span><span class="n">inputsourcechanged</span><span class="p">(</span><span class="n">rebindHotkeys</span><span class="p">)</span>
  <span class="n">alert</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="s2">"Mjolnir٫ at your service."</span><span class="p">)</span>
<span class="k">end</span>

<span class="c1">-- Actual config =================================</span>

<span class="n">hyper</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"cmd"</span><span class="p">٫</span> <span class="s2">"alt"</span><span class="p">٫</span> <span class="s2">"ctrl"</span><span class="p">٫</span><span class="s2">"shift"</span><span class="p">}</span>
<span class="c1">-- Set grid size.</span>
<span class="n">grid</span><span class="p">.</span><span class="n">GRIDWIDTH</span>  <span class="o">=</span> <span class="mi">6</span>
<span class="n">grid</span><span class="p">.</span><span class="n">GRIDHEIGHT</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">grid</span><span class="p">.</span><span class="n">MARGINX</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">grid</span><span class="p">.</span><span class="n">MARGINY</span> <span class="o">=</span> <span class="mi">0</span>
<span class="kd">local</span> <span class="n">gw</span> <span class="o">=</span> <span class="n">grid</span><span class="p">.</span><span class="n">GRIDWIDTH</span>
<span class="kd">local</span> <span class="n">gh</span> <span class="o">=</span> <span class="n">grid</span><span class="p">.</span><span class="n">GRIDHEIGHT</span>

<span class="kd">local</span> <span class="n">gomiddle</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span> <span class="o">=</span> <span class="mi">1</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span><span class="p">٫</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">4</span><span class="p">٫</span> <span class="n">h</span> <span class="o">=</span> <span class="mi">6</span><span class="p">}</span>
<span class="kd">local</span> <span class="n">goleft</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span> <span class="o">=</span> <span class="mi">0</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">0</span><span class="p">٫</span> <span class="n">w</span> <span class="o">=</span> <span class="n">gw</span><span class="o">/</span><span class="mi">2</span><span class="p">٫</span> <span class="n">h</span> <span class="o">=</span> <span class="n">gh</span><span class="p">}</span>
<span class="kd">local</span> <span class="n">goright</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span> <span class="o">=</span> <span class="n">gw</span><span class="o">/</span><span class="mi">2</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">0</span><span class="p">٫</span> <span class="n">w</span> <span class="o">=</span> <span class="n">gw</span><span class="o">/</span><span class="mi">2</span><span class="p">٫</span> <span class="n">h</span> <span class="o">=</span> <span class="n">gh</span><span class="p">}</span>
<span class="kd">local</span> <span class="n">gobig</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span> <span class="o">=</span> <span class="mi">0</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">0</span><span class="p">٫</span> <span class="n">w</span> <span class="o">=</span> <span class="n">gw</span><span class="p">٫</span> <span class="n">h</span> <span class="o">=</span> <span class="n">gh</span><span class="p">}</span>

<span class="kd">local</span> <span class="n">fullApps</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s2">"Safari"</span><span class="p">٫</span><span class="s2">"Aurora"</span><span class="p">٫</span><span class="s2">"Nightly"</span><span class="p">٫</span><span class="s2">"Xcode"</span><span class="p">٫</span><span class="s2">"Qt Creator"</span><span class="p">٫</span><span class="s2">"Google Chrome"</span><span class="p">٫</span>
  <span class="s2">"Google Chrome Canary"</span><span class="p">٫</span> <span class="s2">"Eclipse"</span><span class="p">٫</span> <span class="s2">"Coda 2"</span><span class="p">٫</span> <span class="s2">"iTunes"</span><span class="p">٫</span> <span class="s2">"Emacs"</span><span class="p">٫</span> <span class="s2">"Firefox"</span>
<span class="p">}</span>
<span class="kd">local</span> <span class="n">layout2</span> <span class="o">=</span> <span class="p">{</span>
  <span class="n">Airmail</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">٫</span> <span class="n">gomiddle</span><span class="p">}٫</span>
  <span class="n">Spotify</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">٫</span> <span class="n">gomiddle</span><span class="p">}٫</span>
  <span class="n">Calendar</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">٫</span> <span class="n">gomiddle</span><span class="p">}٫</span>
  <span class="n">Dash</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">٫</span> <span class="n">gomiddle</span><span class="p">}٫</span>
  <span class="n">iTerm</span> <span class="o">=</span> <span class="p">{</span><span class="mi">2</span><span class="p">٫</span> <span class="n">goright</span><span class="p">}٫</span>
  <span class="n">MacRanger</span> <span class="o">=</span> <span class="p">{</span><span class="mi">2</span><span class="p">٫</span> <span class="n">goleft</span><span class="p">}٫</span>
<span class="p">}</span>
<span class="n">fnutils</span><span class="p">.</span><span class="n">each</span><span class="p">(</span><span class="n">fullApps</span><span class="p">٫</span> <span class="k">function</span><span class="p">(</span><span class="n">app</span><span class="p">)</span> <span class="n">layout2</span><span class="p">[</span><span class="n">app</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">٫</span> <span class="n">gobig</span><span class="p">}</span> <span class="k">end</span><span class="p">)</span>

<span class="n">definitions</span> <span class="o">=</span> <span class="p">{</span>
  <span class="p">[</span><span class="s2">";"</span><span class="p">]</span> <span class="o">=</span> <span class="n">saveFocus</span><span class="p">٫</span>
  <span class="n">a</span> <span class="o">=</span> <span class="n">focusSaved</span><span class="p">٫</span>

  <span class="n">h</span> <span class="o">=</span> <span class="n">gridset</span><span class="p">(</span><span class="n">gomiddle</span><span class="p">)٫</span>
  <span class="n">t</span> <span class="o">=</span> <span class="n">gridset</span><span class="p">(</span><span class="n">goleft</span><span class="p">)٫</span>
  <span class="n">n</span> <span class="o">=</span> <span class="n">grid</span><span class="p">.</span><span class="n">maximize_window</span><span class="p">٫</span>
  <span class="n">s</span> <span class="o">=</span> <span class="n">gridset</span><span class="p">(</span><span class="n">goright</span><span class="p">)٫</span>

  <span class="n">g</span> <span class="o">=</span> <span class="n">applyLayout</span><span class="p">(</span><span class="n">layout2</span><span class="p">)٫</span>

  <span class="n">d</span> <span class="o">=</span> <span class="n">grid</span><span class="p">.</span><span class="n">pushwindow_nextscreen</span><span class="p">٫</span>
  <span class="n">r</span> <span class="o">=</span> <span class="n">mjolnir</span><span class="p">.</span><span class="n">reload</span><span class="p">٫</span>
  <span class="n">q</span> <span class="o">=</span> <span class="k">function</span><span class="p">()</span> <span class="n">appfinder</span><span class="p">.</span><span class="n">app_from_name</span><span class="p">(</span><span class="s2">"Mjolnir"</span><span class="p">):</span><span class="n">kill</span><span class="p">()</span> <span class="k">end</span><span class="p">٫</span>

  <span class="n">k</span> <span class="o">=</span> <span class="k">function</span><span class="p">()</span> <span class="n">hints</span><span class="p">.</span><span class="n">appHints</span><span class="p">(</span><span class="n">appfinder</span><span class="p">.</span><span class="n">app_from_name</span><span class="p">(</span><span class="s2">"Emacs"</span><span class="p">))</span> <span class="k">end</span><span class="p">٫</span>
  <span class="n">j</span> <span class="o">=</span> <span class="k">function</span><span class="p">()</span> <span class="n">hints</span><span class="p">.</span><span class="n">appHints</span><span class="p">(</span><span class="n">window</span><span class="p">.</span><span class="n">focusedwindow</span><span class="p">():</span><span class="n">application</span><span class="p">())</span> <span class="k">end</span><span class="p">٫</span>
  <span class="n">ec</span> <span class="o">=</span> <span class="n">hints</span><span class="p">.</span><span class="n">windowHints</span>
<span class="p">}</span>

<span class="c1">-- launch and focus applications</span>
<span class="n">fnutils</span><span class="p">.</span><span class="n">each</span><span class="p">({</span>
  <span class="p">{</span> <span class="n">key</span> <span class="o">=</span> <span class="s2">"o"</span><span class="p">٫</span> <span class="n">app</span> <span class="o">=</span> <span class="s2">"MacRanger"</span> <span class="p">}٫</span>
  <span class="p">{</span> <span class="n">key</span> <span class="o">=</span> <span class="s2">"e"</span><span class="p">٫</span> <span class="n">app</span> <span class="o">=</span> <span class="s2">"Google Chrome"</span> <span class="p">}٫</span>
  <span class="p">{</span> <span class="n">key</span> <span class="o">=</span> <span class="s2">"u"</span><span class="p">٫</span> <span class="n">app</span> <span class="o">=</span> <span class="s2">"Emacs"</span> <span class="p">}٫</span>
  <span class="p">{</span> <span class="n">key</span> <span class="o">=</span> <span class="s2">"i"</span><span class="p">٫</span> <span class="n">app</span> <span class="o">=</span> <span class="s2">"iTerm"</span> <span class="p">}٫</span>
  <span class="p">{</span> <span class="n">key</span> <span class="o">=</span> <span class="s2">"m"</span><span class="p">٫</span> <span class="n">app</span> <span class="o">=</span> <span class="s2">"Airmail"</span> <span class="p">}</span>
<span class="p">}٫</span> <span class="k">function</span><span class="p">(</span><span class="n">object</span><span class="p">)</span>
    <span class="n">definitions</span><span class="p">[</span><span class="n">object</span><span class="p">.</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="k">function</span><span class="p">()</span> <span class="n">application</span><span class="p">.</span><span class="n">launchorfocus</span><span class="p">(</span><span class="n">object</span><span class="p">.</span><span class="n">app</span><span class="p">)</span> <span class="k">end</span>
<span class="k">end</span><span class="p">)</span>

<span class="n">init</span><span class="p">()</span></code></pre></figure>

'),('http://thume.ca/2014/09/08/creating-a-keyboard-1-hardware/', 'Designing and Building a Keyboard: The Body', '1410134400000',  13, '
<p>This summer I set myself the task of designing and building a chording keyboard from scratch. Chording keyboards use a different system of typing where you type entire syllables or words in a single stroke by pressing multiple keys at a time. My keyboard is designed to use a system similar to <a href="http://velotype.com/en/">Velotype</a>. This should theoretically let me type at up to 200WPM.</p>

<p>To spoil the ending I managed to build a pretty sweet keyboard that I am using to type this very article. However٫ I haven’t written the chording software yet so I’m currently using it as a Dvorak keyboard.</p>

<p><strong>Update 10/10/2016:</strong> I’ve been using the keyboard for 2 years now. I wrote the <a href="https://github.com/trishume/PolyType">chording firmware</a> and tried learning it but after a month I was still typing at 3wpm. But I did end up really liking the keyboard layout used normally so it’s still my primary keyboard. I’ve also upgraded the hardware with <a href="https://twitter.com/trishume/status/774977727342444544">cool RGB LEDs</a>. I use the palm keys with a <a href="https://github.com/trishume/SublimeTect">set of Sublime Text shortcuts</a> that is like VIM but the mode is set by the physical state of my palms. This integrates better with the mouse٫ I never type in the wrong mode٫ and it’s better for quickly doing something in another mode.</p>

<p><img src="/assets/postassets/keyboardhw/finished-3.jpg" alt="Finished Keyboard" /></p>

<p>When I started the project I thought it might take 2 weeks to finish the hardware and then I would spend the rest of the summer on software. Boy was I wrong! It took me a month to finish the case and another month of evenings spent soldering after work. I managed to complete the hardware before heading off to Waterloo but only barely.</p>

<p>This post will be mostly about the case and key switches٫ next I’ll write about the electronics٫ then the layout (once I design it)٫ and then the software (once I write it).</p>

<p><img src="/assets/postassets/keyboardhw/finished-4.jpg" alt="Case" /></p>

<h1 id="overview">Overview</h1>

<h2 id="the-keys">The Keys</h2>

<p>One thing about chording keyboards is that since you have to press many keys at the same time٫ it is nice to have very low activation force key switches so that your hands don’t have to work as hard to press more switches.</p>

<p>The Velotype uses custom rubber dome switches with a 15g activation force but those require custom molded silicone sheets and a PCB. Instead I modified Cherry MX Red key switches٫ which are already some of the lowest force switches out there٫ and I cut the springs down from 1.5cm to 1.0cm. This gave them an activation force of around 20g instead of 45g.</p>

<p>For the key caps I pulled the black blank ones off my Das Keyboard since I figured that buying and shipping a new set of key caps would cost more than the resale value of my (now redundant) Das.</p>

<p><img src="/assets/postassets/keyboardhw/stripped_das.jpg" alt="Case" /></p>

<h2 id="the-case">The Case</h2>

<p>The case was made with layered acrylic sheets cut on <a href="http://biblioottawalibrary.ca/en/ImagineSpace">the laser cutter at my local library</a>. The layers are bolted together with machine screws with rubber feet at the bottom. The layout is my own design inspired by the Velotype Pro and the Erogdox. The top and bottom layers are thin black acrylic to give the keyboard a nice look and hide the internals. Features include a carrying handle٫ palm keys and a space for a LCD screen.</p>

<p><img src="/assets/postassets/keyboardhw/case.jpg" alt="Case" /></p>

<h2 id="the-design">The Design</h2>

<p>I did all the design in the (free!) student edition of AutoCad. I used cherry switch hole specs posted on the <a href="http://geekhack.org/">GeekHack</a> forum that I fine tuned by laser cutting small test plates. Before doing the final cut in acrylic I cut one prototype in cheap MDF and also a one-button test keyboard in acrylic. This let me catch a couple design flaws and fine tune my CAD model before the final cut.</p>

<p><img src="/assets/postassets/keyboardhw/model-screen.png" alt="Case" /></p>

<p>My original plan was to draw up the CAD files in two days and then cut them the next day٫ then spend the next couple days soldering. Turns out I dramatically underestimated the difficulty of designing quality hardware. It took me a week to do the CAD models alone. I had to design the layout٫ print multiple tests on paper to test ergonomics٫ then draw up the key cutouts٫ layout٫ case and internal pockets in AutoCad. Then I spent days tweaking the kerf٫ screw placement and PCB pocket size so that everything would fit together well.</p>

<h1 id="the-full-story---detailed-build-log">The Full Story - Detailed Build Log</h1>

<h2 id="the-original-plan-backstory-skip-if-you-want">The Original Plan (Backstory٫ skip if you want)</h2>

<p>This whole crazy quest started when I got the idea of trying to build a mag-lev hall effect keyboard. The switches would levitate on magnets inside shafts above a hall effect sensor٫ this would allow very smooth low force switches that gave back analogue signals. This would allow cool things like variable-speed WASD gaming and detection of different typing styles.</p>

<p>I made some crappy prototypes with fridge magnets and paper and it seemed promising so I ordered some hall effect sensors off Digikey and used OpenSCAD to design some 3D models for key switches. I 3D printed them at my library٫ the first time didn’t turn out well but I tweaked the model and got a decent print. However٫ the switches didn’t feel very good since smooth shaft sliding requires very tight tolerances that even the very nice SLA 3D printer I was using couldn’t make switches that didn’t wobble and scrape.</p>

<p>I ended up abandoning the project because after further testing I discovered that the magnets in adjacent switches would repel each other causing very weird responses and things like keys being twice as hard to press down when the adjacent one was down. This problem could only be solved by using springs to keep the key up and then switching to weaker magnets٫ or by shielding each key with something like mu-metal. This is a purely mechanical problem٫ the hall effect sensors actually weren’t interfered with much by adjacent magnets because they only measure the field strength in one axis.</p>

<p><img src="/assets/postassets/keyboardhw/maglevs.jpg" alt="Case" /></p>

<h2 id="the-real-quest-begins">The Real Quest Begins</h2>

<p>After giving up on mag-lev I tried cutting the springs on a cherry brown switch and ended up with a decent low force key switch. Thus started the quest to build a custom chording keyboard. Goals included low force٫ low cost٫ ergonomic design٫ full programmability٫ and the ability to use it as a normal keyboard.</p>

<p>I started out by doing a bunch of research on other people’s custom keyboards and reading Geekhack threads and blog posts. I used some ideas from the <a href="https://www.ergodox.io/">Ergodox</a>٫ <a href="https://github.com/technomancy/atreus">the Atreus</a>٫ and of course the Velotype Pro.</p>

<h2 id="drawing-up-the-cad-file">Drawing up the CAD File</h2>

<h3 id="the-layout">The Layout</h3>

<p>I started my layout off by just setting up a massive rectangular grid of keys in AutoCad٫ I then printed it off at actual size and used my own hand to stagger the columns to match my fingers. One major difference from normal keyboards is that the home row position of the pinky finger is actually on physical row down from the middle٫ an idea I took from the Velotype. This position is much nicer ergonomically given how short the pinky fingers are٫ it is just unconventional.</p>

<p><img src="/assets/postassets/keyboardhw/homerow.png" alt="Case" /></p>

<p>I then used the same print٫ measure٫ adjust model٫ repeat technique to place the thumb cluster and palm keys. The final step was tweaking the layout so that it could use a standard key cap set٫ this meant doing things like using 1.25U keys for the thumbs instead of 1.5 because there are more of them. While doing this I also kept in mind that each row of key caps has a different profile.</p>

<p>The final step was to mirror the one sided layout to the other side and then measure the natural distance between my hands in order to determine the separation.</p>

<h3 id="the-rest-of-the-case">The Rest of The Case</h3>

<p>After drawing up the layout I had to design the rest of the case. I drew a box around the outside and then some interior pockets for the wiring. I measured the piece of perfboard and the LCD I had decided on and then put in pockets for those and added channels to the wiring pockets. Then I rounded all the corners to reduce the number of pointy edges as well as the risk of the acrylic cracking.</p>

<p><img src="/assets/postassets/keyboardhw/spacer.png" alt="Case" /></p>

<p>Finally I placed the bolt holes in locations that were structurally important and also were solid on all layers. I then measured where the screw holes were on the circuit boards and put those in on the bottom for mounting.</p>

<p>I had drawn the various pockets on different layers in AutoCad so I created a viewport for each physical layer of acrylic and then just set which layers I wanted drawn on each viewport. Bolt holes on all layers٫ switch holes on the plate layer٫ etc…</p>

<h2 id="acquiring-materials">Acquiring Materials</h2>

<p>Now that I had my CAD files it was time to acquire the acrylic I needed to cut them in. I called up the <a href="http://www.lairdplastics.ca/">Laird Plastics</a> in Ottawa and they had the acrylic I needed but only in $100 4 foot x 8 foot sheets. This was a great price per square foot but it was way more than I needed. So I checked out <a href="http://canusplastics.com/">Canus Plastics</a> and they had the exact acrylic thickness and colours I needed and they even cut me sheets of the size I wanted while I waited. I also went around the back to their dumpster and found some nice off-cuts for practice material.</p>

<p>I got 2 sheets of 43cmx24cm eighth inch black acrylic and 3 sheets of quarter inch 43cmx24cm clear acrylic for $50.</p>

<p><img src="/assets/postassets/keyboardhw/canus-loot.jpg" alt="Case" /></p>

<p>I also went to Home Depot and bought the right size of machine screws as well as some $3 sheets of MDF in the same thicknesses as my acrylic.</p>

<h2 id="stop-prototype">Stop٫ Prototype!</h2>

<h3 id="switch-cutout-kerf">Switch Cutout Kerf</h3>

<p>The first thing I wanted to tune was the tightness of my switch cutouts. My acrylic plate was quarter inch thick clear acrylic which is to thick for the switches to snap in so they are friction fit. This meant I had to get the fit very close because I had no PCB to hold the switches in and I didn’t want them popping out if I tried to take off the key caps or turned the keyboard upside down.</p>

<p>I ended up printing 6 different small acrylic test sheets including various insets and resizings of different cherry switch cutout shapes. I measured the results that came off the laser cutter with calipers and found that the laser had 0.2mm kerf in the material I was using.</p>

<p>After adjusting for the kerf I had to figure out how tight I wanted the switch holes. Here are the results of my testing٫ measured against the Cherry width spec of 19.05mm with calipers:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-0.15mm : Very loose fit٫ some play٫ can"t pull keycap without pulling out switch.
Keyboard made like this would fall apart easily if it didn"t have a PCB.
-0.10mm : Same as -0.15mm maybe imperceptibly tighter
0.00mm : Cherry Spec. Holds switches to be very robust without a PCB. Almost zero play.
Still not tight enough to pull a keycap without pulling out switch.
+0.05mm : Very nice solid fit. Can pull a keycap off without pulling switch.
+0.10mm : Quite tight without stressing switch.
Can easily pull keycap off without feeling switch move.
Takes effort to pop out.
I"m going to use this for my board since it won"t have a PCB.
</code></pre></div></div>

<p>For my final version I decided on the +0.1mm inset (0.3mm including accounting for the laser kerf.).</p>

<p>I also printed some plates to test friction mounting the stabilizers. Turns out you can’t friction mount them and you have to make the slots wider and hot glue them. My CAD models include large stabilizer slots but I didn’t end up installing the stabilizers since they turned out to be unnecessary.</p>

<p><img src="/assets/postassets/keyboardhw/test-plates.jpg" alt="Case" /></p>

<h3 id="cute-lil-mini-keyboard">Cute Lil’ Mini Keyboard</h3>

<p>To test the acrylic layering٫ the bolt holes and the border width٫ and cutting the acrylic I drew up a one key test keyboard that I printed and bolted together. It helped me discover that my bolt holes were too close to the edges for my rubber feet to fit. It also looks super cute. I left a hole for cable so that I can eventually hook it up in case I come up with a good idea for it.</p>

<p><img src="/assets/postassets/keyboardhw/mini-board.jpg" alt="Case" /></p>

<h3 id="mdf-prototype">MDF Prototype</h3>

<p>So that I didn’t mess up my $50 acrylic sheets I did a test cut in $4 dollars worth of crappy MDF/hardboard and I’m glad I did. This prototype helped me discover that the USB cable didn’t really fit into the case cutout and that I had forgotten to turn some switch cutouts sideways. It also helped me be confident that the final cuts would turn out as I wanted them to.</p>

<h2 id="modifying-switches">Modifying Switches</h2>

<p>After I cut the MDF prototype I spent 2 one hour sessions in the basement modifying key switches. For each switch I opened it using toothpicks٫ took out the spring and put it up against a ruler٫ grabbed it with my wire snippers at the correct point and moved it over a dish and snipped it. Then I put the switch back together and tested the feel. If a switch felt too light I tested it with a multimeter to make sure it didn’t stay down when I pressed it٫ if it did I tossed it into a rejects pile.</p>

<p>I only modified 46 switches٫ which was enough for all the keys used in chording٫ the extra keys which are only used for normal typing and special characters are unmodified. I did all 46 at around 1.5 minutes per switch median time with only 5 rejects (it took significantly longer for some switches because of additional testing).</p>

<p>The source switches were <a href="http://mechanicalkeyboards.com/shop/index.php?l=product_detail&amp;p=806">a bag of 110 Cherry MX Reds</a> I bought for $50. I chose Cherry Reds because they work better for low force modification since they don’t have a tactile bump. When I tried modifying Browns sometimes the switch would get stuck on the bump on the way up.</p>

<p>After modifying the switches I mounted them in my MDF prototype with the low force switches in the right places and normal switches everywhere else. Afterwards I put my Das Keyboard key caps on making sure to use the correct rows. I then had a feel-complete version of my keyboard that I could try typing on٫ it was pretty nice!</p>

<p><img src="/assets/postassets/keyboardhw/mdf-proto.jpg" alt="Case" /></p>

<h2 id="final-cutting">Final Cutting</h2>

<p>With all my prototyping done I biked to the library with my CAD files and acrylic sheets and spent an hour sitting next to a laser cutter while reading Hacker News and occasionally switching plates and printing a new file and sometimes watching the laser cutter slowly turn a featureless sheet into the keyboard I had been working on for a month.</p>

<p>Everything went excellently and I took my sheets home٫ bolted them together and tested that things fit. I then started transferring switches and keycaps from their respective positions on the MDF prototype to the final acrylic plate.</p>

<p><img src="/assets/postassets/keyboardhw/transfer.jpg" alt="Case" /></p>

<p>One interesting thing I discovered was how susceptible to fingerprints٫
hair and dust the layered acrylic design is. It doesn’t affect the functionality but it sure looks ugly. When assembling the layers I had to wear rubber gloves and wipe each layer down with a microfiber cloth before bolting them together.</p>

<p>After a while I had a look and feel complete version of my keyboard٫ now I just had the soldering to do٫ but that could wait. At this point I was halfway through the summer and I went on vacation from working during my vacation. I took my keyboard shell with me and occasionally practiced typing on the low force switches٫ just with the keyboard on my lap sitting by a lake with nothing connected to it.</p>

<h2 id="electronics">Electronics</h2>

<p>For the second month of the summer I worked at Shopify and every day when I got home I worked on designing the electronics and soldering up the key matrix and controller. There’s a lot more to tell about this process but this post is already 2٫500 words.</p>

<p><em><strong>Coming eventually</strong>٫ Part 2 “Designing and Building a Keyboard: The Mind”٫ in which I will detail the wiring٫ controller and basic firmware that make bring it to the functional state it is in now.</em></p>

<p><strong>Update 10/10/2016:</strong> Sorry I still haven’t written the other parts. The firmware is <a href="https://github.com/trishume/PolyType">on Github</a> though. The electronics is a key matrix connected to a Teensy 3.1 and a MCP23017 multiplexer for more outputs.</p>

<p><img src="/assets/postassets/keyboardhw/electronics.jpg" alt="Case" /></p>

<h2 id="conclusion">Conclusion</h2>

<p>With everything included٫ including prototyping materials٫ extra backup parts and shipping costs the total price came to $233. This figure does not include the dozens of hours of my own labor I put in.</p>

<p>I posted all the CAD files on <a href="https://github.com/trishume/KeyboardCAD">Github</a> including the AutoCAD files for the case٫ the Fritzing file for the controller board and the ruby scripts that generate OpenSCAD scripts that generate mag-lev key models.</p>

<p>For fun٫ here’s the checked off items of my To-Do list including most of the building and debugging steps (after a certain point when I started th e list). Don’t expect to understand it٫ it was written for my own reference.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- Design small one switch test layers
- Design PolyType logo plate (didn"t turn out well)
- Go to Home Depot and buy 6-32 machine screws&amp;nuts and 2"x2" MDF
- Laser cut switch test layers and logo plate in offcut acrylic
- Design circuit (to size perfboards properly)
- Test stabilizers on small acrylic test plate
- Disassemble Das Keyboard
- Finish full plate designs
- Use correct switch holes on plate design
- Modify 46 red switch springs.
- Add PCB holes to CAD file
- Cut MDF into 3 keyboard plate
- Order diodes٫ memory٫ IO expander on digikey
- Fix layout to not use stabilized velo keys
- Laser cut new plate for test cake
- Laser cut finished plate design in MDF
- Test sizing of PCB in MDF
- Mount cherry switches in MDF plate and put das caps on them
- Test feel of entire layout٫ is last chance to change it.
- USB slot on clear top layer
- turn long thumb key slots sideways
- make display screw holes bigger
- move ring finger column down
- shorter USB slot
- Laser cut finished plate in Acrylic
- Test fit of all plates together
- Test fit of components in pockets
- Mount all switches
- Wire up key matrix rows
- Install stabilizers
- Buy female headers and PCB screws
- Wire up matrix columns
- Solder controller board
- Wire matrix to controller board
</code></pre></div></div>

<p>Stay tuned for further parts of this saga!</p>
'),('http://thume.ca/2014/06/25/a-tour-of-the-ruby-standard-library/', 'A Tour of the Ruby Standard Library', '1403654400000',  13, '
<p>Recently I gave a full length talk at <a href="http://ottawaruby.ca/">Ottawa Ruby</a> on highlights of the Ruby standard library. It has elements suited to both beginner and advanced Rubyists.</p>

<p>The Ruby standard library is huge and awesome and this talk was designed to show off some of the cool parts of it that are helpful in everyday Ruby programming٫ and some that are mostly just useful for trivia.</p>

<iframe allowfullscreen="" mozallowfullscreen="" webkitallowfullscreen="" src="/rubytour/embedder.html#index.html" width="660" height="370" style="border:3px solid black;">
</iframe>

<p>I gave the talk on June 24٫ 2014.</p>
'),('http://thume.ca/2013/12/09/math-summative-program/', 'Hacking Math Homework', '1386547200000',  13, '
<p>Many high school students complain about boring and repetitive homework٫ but I’ve found a fun way of dealing with this that I find actually helps me understand concepts even better.
When faced with large rote assignments I write programs to complete the homework like no human can: instantly٫ perfectly and on a large scale.
In the past I have written written <a href="/2013/01/24/hacking-english-class/">Literary Analysis Visualizations</a>٫ Punnet Square generators and <a href="http://github.com/trishume/handyGraph">Graphing Programs</a>.</p>

<p>Most of the time it takes way more time to write the program than it would take to do the homework but I end up learning a lot more and having more fun.
Recently I wrote my wrote my most outrageous program yet٫ it took 10 times longer than it should have and blew away my teacher and class.</p>

<p>Part of my Advanced Functions class summative this year was to create a series of piecewise functions that when graphed produce
a picture. Some examples given were line drawings of a smiley face and the Batman symbol. But I had an idea that would go beyond the intended simple line drawings so I spent my weekend implementing it.</p>

<p>I wrote a program that takes an image and composes equations of varying densities into hundreds of massive piecewise functions
so that when you graph them on a very large canvas and zoom out they replicate the image in greyscale. The output looks like this:</p>

<p><img src="/assets/postassets/mathSummative/obama_small.png" alt="Obama" />
<a href="/assets/postassets/mathSummative/collage_small.png"><img src="/assets/postassets/mathSummative/collage_small.png" alt="Function Collage" /></a></p>

<h2 id="additional-resources">Additional Resources</h2>

<p>Another part of the program outputs a massive Latex document with all the large piecewise functions that produces a huge PDF.
You can <a href="/assets/postassets/mathSummative/summative.pdf">download a PDF</a> that explains all the parts and has some more examples.</p>

<h2 id="the-program">The Program</h2>

<p>The program is written in Python and uses matplotlib٫ Numpy and Pillow.
Excuse the terrible code with the manual constants٫ global variables and terrible logic structure.
Not only was I learning Python while writing this but I had to finish the program by the next day and then
never use the program again.</p>

<script src="https://gist.github.com/7881306.js">
</script>

'),('http://thume.ca/2013/09/30/learning-dvorak/', 'Typing Faster', '1380499200000',  13, '
<p>What if you improved your typing speed from
<span class="TKAdjustableNumber" data-var="curWpm" data-min="5" data-max="100" data-step="5"> wpm</span>
to <span class="TKAdjustableNumber" data-var="newWpm" data-min="5" data-max="200" data-step="5"> wpm</span>?</p>

<p>Over <span class="TKAdjustableNumber" data-var="career" data-min="1" data-max="40"> years</span> typing <span class="TKAdjustableNumber" data-var="dailyTyping" data-min="5" data-max="500"> minutes</span> per work day you could:</p>

<ul>
  <li>Spend <b data-var="ratio2" data-format="%.2f"> times</b> as much time typing saving <b data-var="savedHours" data-format="%.0f"> hours</b>.</li>
  <li>Or type <b data-var="ratio1" data-format="%.1f"> times</b> as many words jumping from <b data-var="totalWords" data-format="%.2f"> million words</b> typing to <b data-var="newWords" data-format="%.2f"> million words</b>.</li>
</ul>

<p>If you earn <span class="TKAdjustableNumber" data-var="pay" data-min="1" data-max="400" data-format="$%.0f">​</span> per hour the extra productivity is worth <b data-var="worth" data-format="$%.0f">​</b>.</p>

<h2 id="learning-to-type-efficiently-in-3-weeks">Learning to Type Efficiently in 3 Weeks</h2>

<p>Are you satisfied with your current typing speed? Do you even know what speed you type at?
If you don’t know go test yourself on <a href="http://www.keyhero.com/">KeyHero</a>٫ I’ll wait.
Typing faster and in the correct way has many advantages including productivity gains٫
ergonomics and ability to look at the screen while typing. However٫ not everyone can simply
practice typing and improve their speed٫ sometimes more drastic action is required.
With the right method you can improve your speed from 25 wpm to 60 wpm in 3 weeks of casual effort like I did.
Two years later I now type properly at 80 wpm with no dedicated practice since those 3 weeks.</p>

<p>Most people improve their typing speed through practice on sites like <a href="http://www.keyhero.com/">KeyHero</a>.
This approach works in some cases but there are some cases where this approach is ineffective.
In order for your practice to be effective you have to continue typing faster and correctly afterwards during normal computer use.
For many years I typed at a dismal speed of 25 wpm with incorrect fingering and my eyes firmly focused on my keyboard.
I tried to practice typing correctly and would get up to 20 wpm without looking at the keyboard but as soon as I was done
and I wanted to program or chat with friends I would go back to my slightly faster but incorrect method of typing and lose my progress.
No matter how hard you practice if you immediately go back to looking at your keyboard or typing improperly afterwards you won’t get any faster.</p>

<p>Salvation came a couple years ago when I discovered a method of kicking out my typing crutches: learning <a href="http://en.wikipedia.org/wiki/Dvorak_Simplified_Keyboard">Dvorak</a>.
Dvorak is a keyboard layout with a much more efficient design with the most common letters on the home row.
It is supposedly more efficient but I couldn’t care less about that٫ what mattered to me is that all the keys were in different positions and the labels on the keys were wrong.
I basically threw away everything I knew about typing and started afresh typing properly and efficiently٫ at 0 wpm.
After a weekend of studying I had learned the layout. In only a week I beat my previous speed. In 2 weeks I doubled it and in 3 weeks I was typing at 60 wpm.
Interestingly٫ I was only practicing about one hour per day. The important thing was that I never switched my computer off of Dvorak and did everything in the new layout.</p>

<p><img src="/assets/postassets/typing/Progress.png" alt="Progress Graph Sketch" /></p>

<p>By starting from the beginning on a keyboard layout where you can’t cheat and look at keys٫ you can eliminate
the bad habits that prevent you from becoming a fast typist.
If you look at your keyboard while you type you miss helpful auto-complete popups and typos you have made٫ leading to drastically lower effective wpm.
Not only this but if you truly need to look you are limiting your typing speed to how fast you can target the next letter.</p>

<p>Unlike Colemak٫ the Dvorak layout is available by default on most versions of OSX٫ Windows and Linux so even if you have to use someone else’s computer you can switch the layout.
You don’t have to buy a special keyboard and you might even get ergonomic benefits from using a more efficient layout and not having to contort your fingers so much.
After a few years of using Dvorak I haven’t had any problems with using other people’s computers or keyboards.
You can always fall back on hunt and peck if you can’t be bothered to change the layout setting.</p>

<p>If your typing speed is below 40wpm or you have to look at the keyboard I highly recommend you learn Dvorak to get rid of your bad habits and improve your speed.
This trick helped me immensely and if you have trouble typing quickly because of bad habits٫ it can help you too.</p>

<h2 id="specifics">Specifics</h2>

<p>To initially learn the basic layout so that I could type every letter٫ albeit slowly٫ I used two methods.
I practiced with lessons on <a href="http://learn.dvorak.nl/">dvorak.nl</a> and printed off a sheet with the layout so that I could
memorize it away from the computer. I did this all in 2 days of focus so that I wouldn’t have to switch back to QWERTY between
practices to get things done.</p>

<p>Once I could type everything I needed to I started using KeyHero٫ which is a nicer platform for both practicing and tracking your progress.
I also used Dvorak for everyday things like programming and writing. I was slow to begin with but very soon I could type faster than before.</p>

<script>
var tangle = new Tangle(document٫ {
    initialize: function () {
        this.curWpm = 30;
        this.newWpm = 80;
        this.career = 10;
        this.dailyTyping = 30;
        this.pay = 40;
    }٫
    update: function () {
        this.ratio1 = this.newWpm / this.curWpm;
        this.ratio2 = 1.0 / this.ratio1;

        this.totalMins = this.career * 220 * this.dailyTyping;
        this.totalHours = this.totalMins / 60;
        this.newHours = this.totalHours * this.ratio2;
        this.savedHours = this.totalHours - this.newHours;

        this.totalWords = this.totalMins * this.curWpm / 1000000;
        this.newWords = this.totalWords * this.ratio1;

        this.worth = this.savedHours * this.pay;
    }
});
</script>

'),('http://thume.ca/2013/05/17/best-search-engine/', 'The Best Search Engine For Programmers', '1368748800000',  13, '
<p>There are many different comparisons of
search engine results out there but I thought I would do one specifically geared
towards the audience I identify with: programmers.</p>

<p>Do note that these tests are not rigorous and are based on my
observations of which search engine delivers the best results from a
programmer’s perspective for a number of programming related searches.</p>

<p>The tests were conducted using Google Chrome in Incognito mode while signed out
of any accounts I had with the site in question.</p>

<p>I will be comparing the following search engines:</p>

<ul>
  <li><a href="http://google.com/">Google</a></li>
  <li><a href="http://bing.com/">Bing</a></li>
  <li><a href="http://duckduckgo.com/">DuckDuckGo</a>: This will be particularly interesting since DDG has a number of
features geared towards geeks and programmers.</li>
  <li><a href="http://samuru.com/">Samuru</a>: A cool new search engine based on natural language processing.</li>
</ul>

<h2 id="1-slate">1. Slate</h2>

<p>Slate is a window management tool for OSX which I have <a href="/howto/2012/11/19/using-slate/">written about before</a>. The correct first result should probably be Slate magazine but the geeky result I am looking for is the window manager. Since Slate is not as popular as my other search terms I threw this one in as a tough start to the comparison.</p>

<h3 id="results">Results</h3>
<p>Google actually got it as the second result! I was so stunned by this that I
thought Google was tracking me even with incognito. But I got one of my non-geeky
friends to Google it and he got it as a result as well.
<img src="/assets/postassets/search/3-google.png" alt="Google" /></p>

<p>All the other search engines returned the magazine first and then the rock.</p>

<h3 id="winner">Winner</h3>
<p>Google by a long shot! I only tried this one because I thought none of them
would get it.</p>

<h2 id="2-chef">2. Chef</h2>

<p>If a programmer searches for “Chef” they are probably referring to the
automation platform by Opscode. What I am looking for is results that talk about
Chef٫ preferably from OpsCode.</p>

<h3 id="results-1">Results</h3>
<p>All search engines had OpsCode Chef on the first page but only some had it in
the top 3.
<img src="/assets/postassets/search/1-google.png" alt="Google" />
<img src="/assets/postassets/search/1-bing.png" alt="Bing  " />
<img src="/assets/postassets/search/1-ddg.png" alt="DDG   " />
<img src="/assets/postassets/search/1-samuru.png" alt="Samuru" /></p>

<h3 id="winner-1">Winner</h3>
<p>Google was the only search engine that returned Chef in the top 3 results and it
put it as the first result.</p>

<h2 id="3-node">3. Node</h2>

<p>This is an interesting one since even as a programmer it is tough to figure out
if the correct result is a networking node or Node.js.</p>

<h3 id="results-2">Results</h3>
<p><img src="/assets/postassets/search/2-google.png" alt="Google" />
<img src="/assets/postassets/search/2-bing.png" alt="Bing  " />
<img src="/assets/postassets/search/2-ddg.png" alt="DDG   " />
<img src="/assets/postassets/search/2-samuru.png" alt="Samuru" /></p>

<h3 id="winner-2">Winner</h3>
<p>Depends on your personal preferences. Google and Samuru put nodejs.org first and
Bing and DDG put networking nodes first. Bing is the only one that does not
mention both.</p>

<h2 id="4-underscore">4. Underscore</h2>

<p>Should refer to underscore.js. No screenshots for this one because I have
already made you scroll too much.</p>

<p><strong>Google</strong>: 2/3 including top result are underscore.js
<strong>DuckDuckGo</strong>: 1/3
<strong>Bing</strong>: 0/3
<strong>Samuru</strong>: Samuru gave underscore.js as third result on first search but
because of the way the engine works it gave 3 articles about the character 30s
later after it had done more processing.</p>

<h2 id="5-ruby">5. Ruby</h2>

<p>Interestingly٫ every search engine got the Ruby language as the top result
except for Bing٫ which gave the gem as the top result.</p>

<h2 id="overall-winner">Overall Winner</h2>

<p>Google is the only search engine that returned the results that a programmer
would be looking for every time. It seems the worst of the 4 search engines was
Bing٫ which got many things and even something as simple as Ruby wrong.</p>

'),('http://thume.ca/2013/05/01/too-many-projects-not-enough-pro/', 'Too Many Projects٫ Not Enough pro', '1367366400000',  13, '
<p>I have too many projects٫ so I started a new project to solve my problems.
This project is a <a href="http://github.com/trishume/pro">little tool called pro</a> which allows you to easily deal with all
your git repositories.</p>

<p>It has a handful of very useful features٫ each of which solves a problem that I
have experienced. I imagine they will be useful to others as well. You can get
<code class="language-plaintext highlighter-rouge">pro</code> by running <code class="language-plaintext highlighter-rouge">gem install pro</code>.</p>

<p>Do note that a Unix system is required to use this٫ so it won’t work on Windows
without Cygwin.</p>

<h2 id="cding-to-a-projects-repository">CD’ing to a project’s repository</h2>

<p>Cd’ing to your projects is harder than it should be.
There are <a href="https://github.com/rupa/z">many tools</a> that try and solve this
problem using frequency and recency.
Pro solves the problem by fuzzy searching only git repositories.</p>

<p>The <code class="language-plaintext highlighter-rouge">pd</code> command allows you to instantly CD to any git repo by fuzzy matching
its name.
You can install the <code class="language-plaintext highlighter-rouge">pd</code> tool (name configurable) by running <code class="language-plaintext highlighter-rouge">pro install</code>.
Once you have it you can do some pretty intense cd’ing:</p>

<p><img src="/assets/postassets/pro/pd_screen.png" alt="pd demo" /></p>

<h2 id="state-of-the-repos-address">State of the Repos Address</h2>

<p>Oftentimes I find myself wondering which git repositories of mine still have
uncommitted changes or unpushed commits. I could find them all and run git
status but it would be nice to get a quick overview. <code class="language-plaintext highlighter-rouge">pro status</code> does this.</p>

<p><img src="/assets/postassets/pro/pro_status.png" alt="pro status" /></p>

<p>You can also run <code class="language-plaintext highlighter-rouge">pro status &lt;repo&gt;</code> to show the output of <code class="language-plaintext highlighter-rouge">git status</code> for a
certain repo.</p>

<h2 id="run-all-the-commands">Run all the commands!</h2>

<p>Wouldn’t it be cool if you could run a command on all your repos and see a
summary of the output? Now you can!</p>

<p>You can do this with <code class="language-plaintext highlighter-rouge">pro run &lt;command&gt;</code>. If you don’t pass a command it will
prompt you for one.</p>

<p>For example٫ searching all your repos for ruby files:</p>

<p><img src="/assets/postassets/pro/pro_run.png" alt="pro run" /></p>

<p>Notice that it double checks before running so you don’t accidentally run <code class="language-plaintext highlighter-rouge">rm -rf *</code> on all
your projects.</p>

<h2 id="the-pro-base">The Pro Base</h2>

<p>Pro can use a base directory to speed up its search for git repos. By default it
uses your home folder.</p>

<p>To set the base directory either create a file at <code class="language-plaintext highlighter-rouge">~/.proBase</code> containing the
base path or set the environment variable <code class="language-plaintext highlighter-rouge">PRO_BASE</code> to the path.</p>

<h2 id="conclusion">Conclusion</h2>

<p><code class="language-plaintext highlighter-rouge">pro</code> is a handy tool that makes working with lots of git repos much easier. If
you want to get it run <code class="language-plaintext highlighter-rouge">gem install pro</code>. You can also <a href="http://github.com/trishume/pro">check it out on Github</a>.</p>
'),('http://thume.ca/2013/04/10/the-best-programming-videogame/', 'The Best Programming Game', '1365552000000',  13, '
<p>Ever since I was in grade 4 I have been playing the world’s best programming
game. The game is highly rewarding٫ an excellent way to learn programming
and it’s even free!</p>

<p>This game has many advantages over other programming video games:</p>

<ul>
  <li>Like Minecraft٫ it is open-ended and allows players to set their own
goals.</li>
  <li>It allows players to use any library and programming language they want to.</li>
  <li>The game can lead to real world rewards and recognition. It has MLG
players and top gamers can earn hundreds of thousands of dollars per year.</li>
  <li>It can run on any computer regardless of how recently it was made or what OS
it runs.</li>
  <li><strong>It even has multiplayer support!</strong> You can play with friends and even post your
solutions to the puzzles online.</li>
</ul>

<p>Have you guessed what game it is yet? Does it sound interesting?</p>

<p>The game is called “Just Friggin Program” and it works like this:</p>

<ol>
  <li>Think of a program you would like to write.</li>
  <li>Use the internet to learn things.</li>
  <li>Write the program!</li>
  <li><strong>You beat the level!</strong> Repeat for the next level.</li>
</ol>

<p>I am now 17 and I have gotten a lot of fun out of playing this game for the last
8 years. I have learned everything I know about programming through playing and I’m sure many other programmers have too.
The best part is I have ended up with a <a href="http://github.com/trishume">portfolio of cool projects</a> while players
of other games just have their “levels completed” screen to show for it.</p>

<p><em>Instead of introducing children to brand new 3D “learn-to-program” games I suggest
the oldest game of them all as the best way to teach kids to programming.</em></p>
'),('http://thume.ca/2013/03/29/contributing-to-eclipse/', 'Contributing to Eclipse', '1364515200000',  13, '
<h2 id="background">Background</h2>

<p>When most programmers think of Eclipse they think of the Java IDE but Eclipse is
actually a huge group of projects with very little relation to each other except
that they are all managed by The Eclipse Foundation.</p>

<p>I had the privilege of working for <a href="http://eclipse.org/org/foundation">The Eclipse
Foundation</a> this past semester at school as a
High School
co-op job. The Foundation does not actually employ developers but since I was
working for free I was able to actually work on the code base with expert
guidance from my supervisor Wayne Beaton at the Foundation.</p>

<p>This was an interesting experience. I worked on fixing bugs in various Eclipse
projects including one that had been around for 11 years and likely affected
thousands of developers. In this article I hope to share some of the knowledge I
gathered about contributing to Eclipse projects.</p>

<p><strong>Edit:</strong> To clarify٫ I am not ranting about how bad my job was. I thoroughly
enjoyed my time at The Eclipse Foundation. I also enjoy using Eclipse as an IDE.
Yes it is slow and RAM-intensive but it’s amazing auto complete and content
assist make it invaluable for Java programming. I use VIM for every other language.</p>

<h2 id="one-does-not-simply-compile-eclipse">One Does Not Simply Compile Eclipse</h2>

<p>For my first week my supervisor had the idea of using me to figure out how difficult
it is to be a new contributor to Eclipse. I was given a bug to fix and no other
instruction.</p>

<p>I started off with the assumption that I would have to compile Eclipse. Which
seemed reasonable enough given my experience with other open source projects.</p>

<p>Unfortunately٫ I was <strong>dead wrong</strong>. I spent many hours reading through outdated
wiki pages and filling up my hard drive with build files until my supervisor
eventually told me what I had only seen briefly mentioned in a paragraph full of
adjectives: <strong>you do not need to compile Eclipse to develop it</strong>.</p>

<h2 id="the-one-true-path">The One True Path</h2>

<p>Eclipse is actually developed within Eclipse using a plugin called the Plugin
Development Toolkit (PDT). This sounds like it is only useful for developing
plugins٫ and it is.</p>

<p>The thing is Eclipse is actually almost entirely made up of Eclipse plugins.
This is an excellent architecture once you start developing for it but it is not
necessarily easy for new contributors.</p>

<h2 id="working-on-an-eclipse-project">Working on an Eclipse Project</h2>

<p>Before following this procedure make sure you have the PDT plugin and the EGit
plugin installed.</p>

<p>This procedure only applies to plugins that are plugins to the Eclipse IDE.</p>

<ol>
  <li>Clone the right repository in EGit.
    <ul>
      <li>You can find all the repositories at <a href="http://git.eclipse.org/c/">http://git.eclipse.org/c/</a></li>
      <li>You only need the repository you will be working on directly٫ it will use
 the binary plugins in your Eclipse installation for dependencies.</li>
      <li>Make sure to select the import projects box in the clone dialog.</li>
    </ul>
  </li>
  <li>Create a new ‘Eclipse Application’ run configuration.</li>
  <li>Make changes to the code and run or debug your configuration.</li>
</ol>

<p>This will launch another copy of Eclipse with the changes that you have made.
You can even set breakpoints and run it in the debugger.</p>

<h2 id="bugzilla">Bugzilla</h2>

<p>All Eclipse bugs are tracked on <a href="http://bugs.eclipse.org/">http://bugs.eclipse.org/</a>. They use the loose
definition of the term ‘bug’ that includes feature requests and things that
should be made better.</p>

<p>Any code contribution you make as a non-commiter (which you probably are if you
are reading this article) must be made through Bugzilla. If you write a new feature
and want to contribute it you should create a new bug saying the feature should
be added and immediately submit a patch file.</p>

<p>You can either submit a patch by attaching a patch file to the bug or on some
projects by submitting a pull request with the bug id in the title to the Github
mirror of the project. Keep in mind that not all projects have active committers
on Github to see your pull request so you may want to link to it from the bug.</p>

<h3 id="next-steps">Next Steps</h3>

<p>With any luck a committer will see your patch and write a comment about it.
This could take anywhere from a day to many months depending on how active the
project is.</p>

<p>On some of my patches I got a helpful response within hours٫ on others I only
got a reply weeks later and some of my patches are still sitting there to this
day…</p>

<p>The committer may recommend some changes to your patch to fix bugs or make it better.
Once your patch is good enough the developer will commit it. They may ask you
some questions about originality or have you fill out a form as part of the
intellectual property process. I think my supervisor said they should have had me fill out a form but they never did.</p>

<p>Congratulations! You may now enjoy the warm fuzzy feeling that comes from
contributing to an Eclipse project!</p>

<h2 id="my-own-journey">My Own Journey</h2>

<p>I submitted patches for many bugs during my time at The Foundation.
I fixed many small bugs like having the Javadoc for a function show up in the
Javadoc view when you select it with autoComplete.</p>

<p>Some of my larger achievements:</p>

<ul>
  <li>Helping fix bugs related to Retina displays so that Eclipse displays crisply
on new Retina MacBook Pros.</li>
  <li>Updating the Eclipse Ruby DLTK project to support debugging ruby 1.9+ using
the ‘debugger’ gem instead of the outdated ‘ruby-debug’ gem on 1.8.</li>
</ul>

<p>My biggest achievement was fixing an 11 year old bug that affects any Eclipse
user who has ever had to forcefully stop Eclipse and then lost their place in
what they were working on. <a href="https://bugs.eclipse.org/bugs/show_bug.cgi?id=2369">Bug 2369</a>.</p>

<p>Eclipse is very good at auto-saving state when it is shut down properly but many
users like myself keep Eclipse open constantly and only ever start it up again
when it crashes or our computer crashes.</p>

<p>The reason nobody experienced had taken it on was probably because it was very
difficult. I toiled for weeks chasing through layer upon layer of abstraction trying to
untie the workbench save code from the shutdown code.</p>

<p>I eventually settled upon copying the entire workbench model and then cleaning
up the parts that were not supposed to be persisted in the copy. I gradually
found what parts had to be removed from the model by chasing the causes of
various duplicate menu items and toolbars.</p>

<p>I managed to fix the bug just one week before my coop term ended. And I got to
feel that warm fuzzy open source contribution feeling knowing that I made a
difference people would notice. And they did:</p>

<div>
<blockquote class="twitter-tweet"><p>@<a href="https://twitter.com/mmmandel">mmmandel</a> wow٫ a 4 digit bug number. You can almost see the evolution of the platform UI team by reading through the comments.</p>&mdash; Ian Bull (@irbull) <a href="https://twitter.com/irbull/status/312241966857482240">March 14٫ 2013</a></blockquote>
<script src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>

'),('http://thume.ca/2013/02/06/ottawa-ruby-lightning-talks/', 'Ottawa Ruby Lightning Talks', '1360108800000',  13, '
<p>I have attended the Ottawa Group of Ruby Enthusiasts (<a href="http://ottawaruby.ca/">http://ottawaruby.ca/</a>) for
about a year now. It has been a great place to meet other Ruby developers and
learn interesting things.</p>

<p>The group normally has a main speaker who gives a long talk and one or two 10 minute
lightning talks punctuated by breaks to eat pizza and talk. The main talk is
normally over Skype and the lightning talks are done by volunteers from the group.</p>

<p>I have given two lightning talks on topics which I believed I might know more
than other members. Both talks went well and I’ve decided to post the slides.
Be aware that I did do a significant amount of talking so you can’t get the
whole message from just the slides٫ but they are better than nothing.</p>

<h2 id="edit-the-ruby-standard-library">Edit: The Ruby Standard Library</h2>

<p>I recently did a full length talk on the Ruby standard library.
You can find the slides at <a href="http://thume.ca/rubytour">http://thume.ca/rubytour</a>.</p>

<h2 id="ruby--programming-contests">Ruby + Programming Contests</h2>

<p>The first talk I did was on writing programming contests in Ruby. I write lots
of programming contests and have tried using a couple different languages for
them but keep coming back to Ruby.</p>

<script async="1" class="speakerdeck-embed" data-id="e41bf2e052d60130a4381231380e9e6b" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js">
</script>

<h2 id="ruby--shell-scripts">Ruby &gt; Shell Scripts</h2>

<p>My most recent talk which I gave last meeting was on using Ruby as a scripting
language to automate repetetive tasks.</p>

<script async="1" class="speakerdeck-embed" data-id="926bb4f052d60130870722000a1c41cd" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js">
</script>

<h2 id="developing-a-gem-in-20-minutes">Developing a Gem in 20 Minutes</h2>

<p>I live coded a simple Ruby gem using Bundler in 20 minutes and explained
some tricks and how easy it was to write Ruby Gems.</p>

<p><a href="https://gist.github.com/trishume/5d1ea89862e031a48434">Here’s a Transcript</a></p>

<h2 id="improv-lighting-talk">Improv lighting Talk</h2>

<p>I recently gave an improvised lightning talk prompted by the lack of other
lighting talks called “How to do a lightning talk.” I talked about choosing a
topic that you feel you have unique knowledge of to give you more confidence and
how all that was really important was the confidence to go up there. Everything
else would work itself out.</p>
'),('http://thume.ca/2013/01/24/hacking-english-class/', 'Hacking English Class', '1358985600000',  13, '
<p>I was sitting in English class last year and thinking about how English was
about as far away from programming as you can get. We were discussing the
significance of characters in the novel <em>Lord of the Flies</em> and I thought “I
wonder if I could write a program to analyze this book٫ that would be ironic.”</p>

<p>So that evening I wrote a Ruby script that analyzed the occurences of characters
names in <em>Lord of the Flies</em> and graphed it over time. It was a fun graph٫
especially the most noticable feature being references to “Piggy” suddenly dropping.</p>

<p>I went on to write another script to analyze <em>Lord of the Flies</em> as well as
other scripts during English class this year. Here are some of the ones I have
come up with٫ starting with the most recent.</p>

<p>Most recently I wrote a program that reads entire stories and generates passages that
capture the texture of the story using Markov Trees.</p>

<p><img src="/assets/postassets/hackEnglish/markov-poster.png" alt="Markov Stories" /></p>

<p>In grade 11 my project was analyzing the most common colours in <em>The Great Gatsby</em>.
My teacher thought that yellow would be the most common but it turns out to be
white.</p>

<p><img src="/assets/postassets/hackEnglish/Colours-of-Gatsby.png" alt="Gatsby Colours" /></p>

<p>My other work this year was highlighting important words in the poem <em>Beowulf</em>.</p>

<p><a href="/assets/postassets/hackEnglish/Beowulf.png"><img src="/assets/postassets/hackEnglish/Beowulf.png" alt="Charged Words in Beowulf" /></a></p>

<p>As well as my two <em>Lord of the Flies</em> graphs.</p>

<p><img src="/assets/postassets/hackEnglish/lotf-1.png" alt="Lotf timeline" /></p>

<p>The second one shows words that appear close together٫ the saturation indicates
how often they occur close together.</p>

<p><a href="/assets/postassets/hackEnglish/lotf-2.png"><img src="/assets/postassets/hackEnglish/lotf-2.png" alt="Lotf co-occurence" /></a></p>
'),('http://thume.ca/howto/2012/11/19/using-slate/', 'Using Slate: A Hacker"s Window Manager for Macs', '1353283200000',  13, '
<p><strong>Edit: I’ve recently switched to using <a href="http://mjolnir.io">Mjolnir</a> and have posted <a href="/howto/2014/12/02/using-mjolnir-an-extensible-osx-window-manager/">a new tutorial</a> on that.</strong></p>

<p>Switching windows with the keyboard on Mac OSX is hilariously inefficient: it
involves repeatedly pressing command+tab through millions of programs until you
get to the right one when you could have just clicked the window and been done
with it. Moving windows is no better so people have resorted to paying for tools
like SizeUp and Divvy. I used to have these problems too until I <s>switched to
Linux</s> discovered a program called Slate.</p>

<p>Fancy window management is no longer just for Linux users and their XMonad.</p>

<h2 id="enter-slate">Enter Slate</h2>

<p><a href="https://github.com/jigish/slate">Slate</a> is a keyboard-driven window management
program for Mac OSX. It is highly configurable and has tons of features. It has
permanently changed the way I use my Mac. Not only is it better than other
popular programs like Divvy٫ SizeUp and Moom٫ it beats their prices at being
<strong>free</strong>. Slate is the VIM/Emacs of window managers: it is less of a window
manager than a workflow changing tool you will never give up.</p>

<p>Slate has so much functionality that I think of it more as a shortcut-based
productivity tool than a window manager. Here is a sample of what it can do:</p>

<ul>
  <li><strong>Move/Resize/Shift windows:</strong> this can be done based on different screen size
fractions and even mathematical formulae. There are commands for practically
every window operation you can think of. It also supports the Divvy style
sizing grid.</li>
  <li><strong>Switch Windows:</strong> Slate can act as a complete replacement for command+tab in
many ways. I will talk about this more in the “Window Switching” section.</li>
  <li><strong>Manage multiple monitors:</strong> Slate can move windows between monitors as well as
detecting your monitor configuration and automatically moving windows around
when you plug in an external monitor.</li>
  <li><strong>Save window layouts:</strong> Slate has a feature called “snapshots” that allows you to
save your current window layout and restore it at any time. This is handy for
having different layouts for different projects/tasks.</li>
</ul>

<p>In this article I will describe the kind of things you can do with Slate and how
to configure it to do these things.</p>

<h2 id="switching-windows">Switching Windows</h2>

<p>Slate allows me to switch to any window I want in one shortcut and a single key
press. I can do this using a feature called “Window Hints”. If you have ever
used easyMotion for Vim or Vimperator/Vimium you will be familiar with this
concept.</p>

<p>When you press a shortcut (I use <code class="language-plaintext highlighter-rouge">cmd+e</code>)٫ every window is instantly overlain with
a letter٫ starting with those on the home row of your keyboard. By pressing the
letter over a window your focus is transfered to that window. For windows that
are hidden behind others the application icon is displayed in the overlay.</p>

<h3 id="as-usual-a-picture-is-worth-a-thousand-words">As usual٫ a picture is worth a thousand words:</h3>
<p><a href="/assets/postassets/slate/windowhints.jpg"><img src="/assets/postassets/slate/windowhints.jpg" alt="Window Hints" /></a>
Notes: There is an option to overlay the icons with a dark background so that it
is easier to read the letters. Also note the fancy Slate managed window layout.</p>

<h3 id="switching-windows-even-faster">Switching Windows Even Faster</h3>

<p>Even though window hints are super fast there are some applications I switch to
and from so often that I wanted to be able to do it in one shortcut. Luckily٫
Slate had my back. Using Slate’s focus command I was able to give my most commonly used programs
their own switching shortcuts.</p>

<p>Inspired by <a href="http://stevelosh.com/blog/2012/10/a-modern-space-cadet/">this article</a>٫ I use a
program called “PCKeyboard Hack” (ironically mac only) to bind my caps lock key
to <code class="language-plaintext highlighter-rouge">command+option+shift+control</code> which I call “hyper”.  I use this binding to
manage all my custom shortcuts. For example٫ <code class="language-plaintext highlighter-rouge">hyper+e</code> focuses on my browser٫
<code class="language-plaintext highlighter-rouge">hyper+u</code> focuses on my editor٫ <code class="language-plaintext highlighter-rouge">hyper+i</code> focuses on iTerm٫ <code class="language-plaintext highlighter-rouge">hyper+m</code> focuses Mail٫
etc…</p>

<h2 id="moving-windows">Moving Windows</h2>

<p>Slate has numerous commands for moving and resizing windows. I personally only
use a small portion of them. The most common ones are the classic “resize to
left half”٫ “resize to right half” and “fill the screen”; however٫ I also have
ones like “move this to my other monitor” and “layout my applications across
both monitors just the way I like them”. All of these are bound to keyboard
shortcuts.</p>

<p>I started off with Slate by rebinding my numpad to window movement commands.
Whenever I need to type a number I use the ones along the top of the keyboard so
before Slate the numpad was just useless buttons. I bound the numpad keys like
to resize windows in the direction they pointed. For example٫ 5 was fullscreen٫
4 was left half and 6 was right half. The other buttons were quarters٫ top and
bottom. Special numpad keys like * and + did things like display a window
resizing grid or arrange my windows in a certain layout.</p>

<p>I soon grew tired of reaching for my numpad so I added bindings to the home row
of my keyboard using the hyper key. This is more convenient for when I don’t
have a numpad and it makes it so I don’t have to reach over.</p>

<p>I have just scratched the surface of what Slate can do in terms of window
movement and resizing٫ Slate has commands for resizing windows incrementally٫
nudging windows around٫ resizing to any fraction of the screen you want and even
moving windows to specific pixel positions.</p>

<p><a name="configuration">
</a></p>
<h1 id="configuring-slate">Configuring Slate</h1>
<h3 id="aka-how-do-i-do-all-this-cool-stuff">A.K.A How do I do all this cool stuff?</h3>

<p>Like many amazing tools such as VIM and ZSH٫ Slate is configured through a
dotfile in the home directory called <code class="language-plaintext highlighter-rouge">.slate</code>. The <a href="https://github.com/jigish/slate">Slate
Readme</a> file has very detailed information on
configuring Slate so I am just going to show some tricks that let you do
specific things.</p>

<p>The <code class="language-plaintext highlighter-rouge">~/.slate</code> file is made up of different commands. The top level commands are:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">config</code>: for global configurations.</li>
  <li><code class="language-plaintext highlighter-rouge">alias</code>: to create alias variables.</li>
  <li><code class="language-plaintext highlighter-rouge">layout</code>: to configure layouts.</li>
  <li><code class="language-plaintext highlighter-rouge">default</code> :to default certain screen configurations to layouts</li>
  <li><code class="language-plaintext highlighter-rouge">bind</code>: binds a key to an action.</li>
  <li><code class="language-plaintext highlighter-rouge">source</code>: to load configs from another file.</li>
</ul>

<p>The <code class="language-plaintext highlighter-rouge">#</code> character is used for comment lines and <code class="language-plaintext highlighter-rouge">"</code> is used to delimit
strings.</p>

<h3 id="general-configuration">General Configuration</h3>

<p>Using the <code class="language-plaintext highlighter-rouge">config</code> command٫ you can set a variety of options that change how
slate works. Here are some you options that I like to set:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>config defaultToCurrentScreen true
# Shows app icons and background apps٫ spreads icons in the same place.
config windowHintsShowIcons true
config windowHintsIgnoreHiddenWindows false
config windowHintsSpread true
</code></pre></div></div>

<h3 id="window-hints">Window Hints</h3>

<p>Along with the general configuration from the previous section٫ all you have to
do to use window hints is bind the hint operation to a key. I like to use
<code class="language-plaintext highlighter-rouge">command+e</code> as it is easy to type and not used in many mac applications.</p>

<p>To do this put the following in your <code class="language-plaintext highlighter-rouge">.slate</code> file:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bind e:cmd hint ASDFGHJKLQWERTYUIOPCVBN # use whatever keys you want
</code></pre></div></div>

<p>You can choose which letters you want window hints to use. The letters will be
assigned to windows in the order specified by the <code class="language-plaintext highlighter-rouge">windowHintsOrder</code> config
option. If you have more windows than there are letters specified٫ some hints
will not be shown. I suggest you start with either the home row of your keyboard
or all the keys on one side of the keyboard so you only need one hand.</p>

<h3 id="window-grid">Window Grid</h3>

<p>If you are a fan of the Divvy style window positioning grid Slate can do
that too. To bind the window grid to a key use a command like:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bind g:cmd grid padding:5 0:6٫2 1:8٫3
</code></pre></div></div>

<p>This particular command binds <code class="language-plaintext highlighter-rouge">command+g</code> to show a 6x2 grid on the first
monitor (monitor <code class="language-plaintext highlighter-rouge">0</code>) and a 8x3 grid on the second monitor (monitor <code class="language-plaintext highlighter-rouge">1</code>).</p>

<p><a href="/assets/postassets/slate/grid.png"><img src="/assets/postassets/slate/grid.png" alt="Window Grid" /></a></p>

<h3 id="normal-window-management">Normal Window Management</h3>

<p>Slate is so configurable that it allows you to specify any fraction of the
screen you want to move windows; however٫ this can be annoying if you just want
to use halves and fullscreen. To remedy this٫ Slate allows you to create aliases
that you can use for common commands.</p>

<p>Here are some aliases I use for common positions:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Abstract positions
alias full move screenOriginX;screenOriginY screenSizeX;screenSizeY
alias lefthalf move screenOriginX;screenOriginY screenSizeX/2;screenSizeY
alias righthalf move screenOriginX+screenSizeX/2;screenOriginY screenSizeX/2;screenSizeY
alias topleft corner top-left resize:screenSizeX/2;screenSizeY/2
alias topright corner top-right resize:screenSizeX/2;screenSizeY/2
alias bottomleft corner bottom-left resize:screenSizeX/2;screenSizeY/2
alias bottomright corner bottom-right resize:screenSizeX/2;screenSizeY/2
</code></pre></div></div>

<p>You can then bind these commands to any keys you want. For example٫ you can use
the numpad to move windows around:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Numpad location Bindings
bind pad1 ${bottomleft}
bind pad2 push bottom bar-resize:screenSizeY/2
bind pad3 ${bottomright}
bind pad4 ${lefthalf}
bind pad5 ${full}
bind pad6 ${righthalf}
bind pad7 ${topleft}
bind pad8 push top bar-resize:screenSizeY/2
bind pad9 ${topright}
</code></pre></div></div>

<h3 id="layouts">Layouts</h3>

<p>Layouts allow you to tell Slate how you like your windows arranged so it can
arrange them for you. To create a layout you have to specify how you like your
applications arranged and then you bind the layout to a keyboard shortcut.</p>

<p>We can re-use the aliases from the last section in our layout definitions like
this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>layout 1monitor "iTerm":REPEAT ${bottomright}
layout 1monitor "Sublime Text 2":REPEAT ${lefthalf}
layout 1monitor "MacVim":REPEAT ${lefthalf}
layout 1monitor "Safari":REPEAT ${righthalf}
layout 1monitor "Mail":REPEAT ${righthalf}
layout 1monitor "Path Finder":REPEAT ${topright}
layout 1monitor "Xcode":REPEAT ${full}
layout 1monitor "Eclipse":REPEAT ${full}
layout 1monitor "iTunes":REPEAT ${full}
</code></pre></div></div>

<p>Then we can bind the layout to a key like this:</p>

<p>bind l:cmd layout 1monitor</p>

<p>Now whenever we press <code class="language-plaintext highlighter-rouge">command+l</code> our apps will arrange themselves the way we
like. In this example I named my layout <code class="language-plaintext highlighter-rouge">1monitor1</code> but you can give it a
meaningful name and even have multiple layouts with different names.</p>

<h3 id="ultra-fast-app-switching">Ultra-Fast App Switching</h3>

<p>To bind shortcuts directly to focusing an app you can use the focus command.
For example٫ we can bind <code class="language-plaintext highlighter-rouge">command+option+b</code> to focus our browser:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bind b:cmd;alt focus "Google Chrome"
</code></pre></div></div>

<h3 id="my-slate">My .slate</h3>

<p>Here is my <code class="language-plaintext highlighter-rouge">.slate</code> file in its entirety٫ do note that it is optimized for the
Dvorak keyboard layout٫ so some of the shortcuts may seem weird and the hint
keys are the Dvorak home row rather than qwerty.</p>

<script src="https://gist.github.com/4121655.js?file=.slate">
</script>

'),('http://thume.ca/projects/2012/11/14/magic-png-files/', 'Magic PNG Thumbnails', '1352851200000',  13, '
<p>I was shown trick by a friend where an image was posted on a website
that displayed one thing in the thumbnail and another in the lightbox.
<a href="http://funnyjunk.com/channel/ponytime/rainbow+dash/llhuDyy/15#15">http://funnyjunk.com/channel/ponytime/rainbow+dash/llhuDyy/15#15</a></p>

<p>This post contains an explanation of how these images work and how I was able
to replicate their behaviour.</p>

<h2 id="the-behaviour">The Behaviour</h2>

<p>Certain renderers of the png files would display one image and other renderers
would display a completely different one. One image is always dark and one is
light.</p>

<h3 id="example">Example:</h3>
<p><img src="/assets/postassets/doubleVision/difference.png" alt="Difference example" /></p>

<h3 id="things-that-display-the-light-image">Things that display the light image:</h3>

<ul>
  <li>Thumbnail renderers (Facebook٫ etc…)</li>
  <li>Apple png rendering</li>
  <li>Windows png rendering</li>
</ul>

<h3 id="things-that-display-the-dark-image">Things that display the dark image:</h3>

<ul>
  <li>Firefox (and by extension anything that uses libpng)</li>
  <li>Google Chrome</li>
</ul>

<h3 id="this-can-lead-to-interesting-combos">This can lead to interesting combos:</h3>

<ul>
  <li>linking the image on facebook can show one image as a thumbnail but a completely different one when the link is clicked.</li>
  <li>A picture that detects the user’s browser. (Chrome/Firefox or Safari)</li>
  <li>A picture that displays one thing in the browser and a different thing when downloaded to the user’s (victim’s) computer.</li>
  <li>The classic image board thumbnail.</li>
</ul>

<h2 id="the-challenge-and-victory">The Challenge and Victory</h2>

<p>I started on a long journey to figure out how this effect works so that I
could replicate it. The path to enlightenment involved many wrong turns
including believing that the image was being interpreted as a GIF but I
eventually discovered the truth.</p>

<p>After I discovered the secret I wrote a command line tool in Ruby called
doubleVision so that anybody could generate magic thumbnail images.</p>

<p><a href="http://github.com/trishume/doubleVision">doubleVision is available on Github</a>
and as an executable Ruby gem.</p>

<p>The output images look like this:</p>

<p><img src="/assets/postassets/doubleVision/out.png" alt="Sample Image" /></p>

<p>Try downloading it to your computer and then viewing it. Cool eh?</p>

<h2 id="how-it-works">How it works</h2>

<p>The PNG specification contains a metadata attribute that allows you
to specify the gamma to render the image with. This attribute is intended to
be used to ensure that images look identical on all computers. This is a very
normal image processing process called <a href="http://en.wikipedia.org/wiki/Gamma_correction">Gamma Correction</a></p>

<p>The PNG specification defines the gAMA chunk (the chunk that stores the gamma
value) to change the image output like so:</p>

<p>light_out = image_sample^(1 / gamma)</p>

<p>This scales the image values exponentially based on the reciprocal of the
gamma value. If the gamma value is around 1 like it normally is this function
has little noticeable effect. During this process٫ the lowest brightness value
for a pixel is 0 and the highest is 1.</p>

<p>If we set the PNG gamma attribute to a very low value٫ making the exponent
value very high (since it is the reciprocal)٫ all darker pixels will be made
black and all lighter pixels will be mapped to the normal spectrum.</p>

<h3 id="exponential-gamma-mapping">Exponential Gamma Mapping</h3>
<p><img src="/assets/postassets/doubleVision/PNG_Gamma_mapping.png" alt="Gamma mapping" /></p>

<p>We can reverse this mapping for a very low value of the gamma attribute (I use 0.023)
to get a PNG image where all the pixels of the image are mapped to very light
colors. If we then set the gamma value of the PNG to 0.023 the image will look
somewhat normal٫ except for the rounding errors introduced by crunching the
image into high values.</p>

<p>The thing is٫ not all renderers support the gamma attribute. If we try and
view this image in a renderer that does not support the gamma attribute it
will show too bright to make out.</p>

<p>We can abuse this to create a magic thumbnail by taking two images of the same
size and creating a new image twice their dimensions. One image is run through
the previously mentioned reverse gamma filter that makes all pixels very bright and
the other is darkened so that it has no very bright pixels. The images are
then spaced out in grids around each other (see image). The resulting image is
saved as a PNG file with a gAMA of 0.023.</p>

<h3 id="pixel-grid-pattern">Pixel Grid Pattern</h3>
<p><img src="/assets/postassets/doubleVision/pixelgrid.png" alt="Grid Pattern" /></p>

<p>When the image is displayed in a renderer that supports gamma (Like Firefox/Chrome) the light pixels
become fairly dark but visible colors and the normal pixels become a grid of dark pixels.
When the image is displayed in a renderer that does not support gamma (like Apple/Microsoft rendering)
The untransformed image is shown surrounded by a grid of seemingly white pixels.</p>

<h2 id="installation-and-usage">Installation and Usage</h2>

<p>You can install the doubleVision gem and command using:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ gem install doubleVision
</code></pre></div></div>

<p>Next٫ run the program like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>doubleVision withgamma.png withoutgamma.png out.png
</code></pre></div></div>

<p>obviously replacing the filenames with your own.</p>

<p>It will combine the images into one image (<code class="language-plaintext highlighter-rouge">out.png</code>) that will display
<code class="language-plaintext highlighter-rouge">withgamma.png</code> when viewed with gamma support (e.g. in Firefox)
and <code class="language-plaintext highlighter-rouge">withoutgamma.png</code> when displayed without gamma support (e.g. As a thumbnail)</p>

<h3 id="for-more-detailed-instructions-read-the-readme-on-github">For more detailed instructions read the <a href="http://github.com/trishume/doubleVision">README on Github</a></h3>

<h2 id="other-example">Other Example</h2>

<p><img src="/assets/postassets/doubleVision/DayNight.png" alt="Day and Night" /></p>

<p>Was generated from:
<img src="/assets/postassets/doubleVision/Night.png" alt="Night" />
and
<img src="/assets/postassets/doubleVision/Day.png" alt="Day" /></p>

'),('http://thume.ca/projects/2012/11/04/simple-accurate-eye-center-tracking-in-opencv/', 'Simple٫ accurate eye center tracking in OpenCV', '1351987200000',  13, '
<p>I am currently working on writing <a href="http://github.com/trishume/eyeLike">an open source gaze tracker</a> in OpenCV that requires only a webcam.
One of the things necessary for any gaze tracker<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup> is accurate tracking of the eye center.</p>

<p>For my gaze tracker I had the following constraints:</p>
<ul>
  <li>Must work on low resolution images.</li>
  <li>Must be able to run in real time.</li>
  <li>I must be able to implement it with only high school level math knowledge.</li>
  <li>Must be accurate enough to be used for gaze tracking.</li>
</ul>

<p>I came across a paper<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup> by Fabian Timm that details an algorithm that fit all of my criteria.
It uses image gradients and dot products to create a function that theoretically is at a maximum at the center of the image’s most prominent circle.</p>

<p>Here is a video he made of his algorithm in action:</p>

<iframe width="560" height="315" src="http://www.youtube.com/embed/aGmGyFLQAFM" frameborder="0" allowfullscreen="">
</iframe>

<p><strong>Before continuing I recommend that you read <a href="https://www.inb.uni-luebeck.de/fileadmin/files/PUBPDFS/TiBa11b.pdf">his paper</a>.</strong></p>

<h1 id="implementing-the-algorithm">Implementing the algorithm</h1>

<p>After implementing the algorithm detailed in the paper using OpenCV functions my implementation had horrendous accuracy and many problems. These were partially caused by the paper not specifying some important numbers.</p>

<p>These numbers include:</p>
<ul>
  <li>The eye region fractions.</li>
  <li>The gradient magnitude threshold.</li>
  <li>The size of the eye regions used.</li>
</ul>

<p>I contacted Dr. Timm and he helped me with some of my problems.
Below are some problems that I resolved with Dr. Timm’s help.</p>

<h2 id="things-that-are-not-in-the-paper">Things That Are Not in the Paper</h2>

<p>The first thing I fixed was the eye region fractions as portions of the face. From Dr. Timm:</p>

<blockquote>
  <p>Let (x٫ y) be the upper left corner and W٫ H the width and height of the detected face.
Then٫ the mean of the right eye centre is located at (x + 0.3٫ y + 0) and the mean of the left centre is at position (x + 0.7٫ y + 0.4).</p>
</blockquote>

<p>On his recommendation I also applied a gaussian blur to the face before processing it to smooth noise. I use the sigma of <code class="language-plaintext highlighter-rouge">0.005 * sideLengthOfFace</code>.</p>

<h3 id="the-gradient-algorithm">The Gradient Algorithm</h3>

<p>One important thing that is not explained very clearly in the paper is the gradient algorithm. In his implementation he uses the MatLab <code class="language-plaintext highlighter-rouge">gradient</code> function. In my original implementation I used a Sobel operator but by imitating MatLab’s gradient function I achieved much better results.</p>

<p>The way MatLab’s gradient algorithm works (in Matlab code) is <code class="language-plaintext highlighter-rouge">[x(2)-x(1) (x(3:end)-x(1:end-2))/2 x(end)-x(end-1)]</code> with x being the input. Translated into C++ and OpenCV this comes out as:</p>

<figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="nf">computeMatXGradient</span><span class="p">(</span><span class="k">const</span> <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="o">&amp;</span><span class="n">mat</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">cv</span><span class="o">::</span><span class="n">Mat</span> <span class="n">out</span><span class="p">(</span><span class="n">mat</span><span class="p">.</span><span class="n">rows</span><span class="p">٫</span><span class="n">mat</span><span class="p">.</span><span class="n">cols</span><span class="p">٫</span><span class="n">CV_64F</span><span class="p">);</span>

  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="n">mat</span><span class="p">.</span><span class="n">rows</span><span class="p">;</span> <span class="o">++</span><span class="n">y</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">const</span> <span class="n">uchar</span> <span class="o">*</span><span class="n">Mr</span> <span class="o">=</span> <span class="n">mat</span><span class="p">.</span><span class="n">ptr</span><span class="o">&lt;</span><span class="n">uchar</span><span class="o">&gt;</span><span class="p">(</span><span class="n">y</span><span class="p">);</span>
    <span class="kt">double</span> <span class="o">*</span><span class="n">Or</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="n">ptr</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="p">(</span><span class="n">y</span><span class="p">);</span>

    <span class="n">Or</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">Mr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Mr</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">mat</span><span class="p">.</span><span class="n">cols</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span> <span class="o">++</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">Or</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">Mr</span><span class="p">[</span><span class="n">x</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Mr</span><span class="p">[</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mf">2.0</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">Or</span><span class="p">[</span><span class="n">mat</span><span class="p">.</span><span class="n">cols</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">Mr</span><span class="p">[</span><span class="n">mat</span><span class="p">.</span><span class="n">cols</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Mr</span><span class="p">[</span><span class="n">mat</span><span class="p">.</span><span class="n">cols</span><span class="o">-</span><span class="mi">2</span><span class="p">];</span>
  <span class="p">}</span>

  <span class="k">return</span> <span class="n">out</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure>

<p>to get the Y gradient I simply take the X gradient of the transpose matrix and transpose it again(<code class="language-plaintext highlighter-rouge">computeMatXGradient(eyeROI.t()).t()</code>)</p>

<p>By replicating his gradient algorithm I was also able to use the same gradient threshold as him. From Dr. Timm:</p>

<blockquote>
  <p>I remove all gradients that are below this threshold:</p>

  <p><code class="language-plaintext highlighter-rouge">0.3 * stdMagnGrad + meanMagnGrad</code></p>

  <p>where “stdMagnGrad” and “meanMagnGrad” are the standard deviation and the mean of all gradient magnitudes٫ i.e. the length of the gradients.;</p>
</blockquote>

<h3 id="the-little-thing-that-he-didnt-mention">The “Little Thing” that he didn’t mention</h3>

<p>Because his algorithm in the form he gives in the paper is generalized to all circles he left out one tiny important thing. For me this one line of code made the difference between it working and being terribly innacurate.</p>

<p>In the equation he gives the dot product of the <code class="language-plaintext highlighter-rouge">d</code> vector and the gradient is taken and then squared. The thing is this makes negative dot products positive.</p>

<p>Dot products are negative if the vectors are pointing in opposite directions. The gradient function used creates vectors that always point towards the lighter region. Since the iris is darker than the sclera (white part) the vectors of the iris edge always point out. This means that at the center they will be facing in the same direction as the <code class="language-plaintext highlighter-rouge">d</code> vector. <strong>Anything pointing in the opposite direction is irrelevant</strong></p>

<p>To fix this I added a line of code that turns negative values into zero so they have no effect on the result:
<code class="language-plaintext highlighter-rouge">dotProduct = std::max(0.0٫dotProduct);</code></p>

<p>After adding this line of code my implementation tracked my eyes excellently and worked exactly as it should.</p>

<p>#Conclusion</p>

<p>Dr. Timm’s eye center location algorithm is an excellent simple way to track the pupil٫ but only if you add a few extra things that he does not talk about in his paper.</p>

<p>In terms of my eye tracker at the moment this is all I have implemented. I am
still looking into methods of tracking a reference point like eye corner to
accurately judge where the user is looking.</p>

<p>I am also looking into using deformation of the eye into an oval to
determine the orientation of the iris.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>An eye tracker gives the pixel position of the center of the pupil in an image whereas a gaze tracker determines where the person is looking on the screen. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Timm and Barth. Accurate eye centre localisation by means of gradients. In Proceedings of the Int. Conference on Computer Theory and Applications (VISAPP)٫ volume 1٫ pages 125-130٫ Algarve٫ Portugal٫ 2011. INSTICC. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/web/HandlingExtraQueryParameters', 'What you should do about extra query parameters on your URLs', '1599622919000',  14, '<div class="wikitext"><p>My entry on <a href="https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters">how web server laxness created a de facto requirement
to accept arbitrary query parameters on your URLs</a>
got a number of good comments٫ so I want to agree with and magnify
the suggestion about what to do about these parameters. First off٫
<a href="https://utcc.utoronto.ca/~cks/space/blog/web/CautionIsAMistakeToday">you shouldn"t reject web page requests with extra query parameters</a>. I also believe that you shouldn"t just
ignore them and serve the regular version of your web page. Instead٫
as said by several commentators٫ <strong>you should answer with a HTTP
redirect to the canonical URL of the web page</strong>٫ which will be
stripped of at least the extra query parameters.</p>

<p>(I think that this should be a permanent HTTP redirect instead of
a temporary one for reasons that don"t fit within the margins of
this entry. Also٫ this assumes that you"re dealing with a <code>GET</code> or
a <code>HEAD</code> request.)</p>

<p>Answering with a HTTP redirect instead of the page has two useful
or important effects٫ as pointed out by commentators on <a href="https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters">that entry</a>. First٫ any web search engines that are
following those altered links won"t index duplicate versions of
your pages and get confused about which is the canonical one (or
downrate you in results for having duplicate content). Second٫
people who copy and reshare the URL from their browser will be
sharing the canonical URL٫ not the messed up version with tracking
identifiers and other gunk. This assumes that you don"t care about
those tracking identifiers٫ but I think this is true for most of my
readers.</p>

<p>(In addition٫ you can"t count on other people"s tracking identifiers
to be preserved by third parties when your URLs get re-shared. If
you want to track that sort of stuff٫ you probably need to add your
own tracking identifier. You might care about this if٫ for example٫
you wanted to see how widely a link posted on Facebook spread.)</p>

<p>However٫ this only applies to web pages٫ not to API endpoints. Your
API endpoints (even <code>GET</code> ones) should probably error out on extra
query parameters unless there is some plausible reason they would
ever be usefully shared through social media. If your API endpoints
never respond with useful HTML to bare <code>GET</code>s٫ this probably doesn"t
apply. If you see a lot of this happening with your endpoints٫ you
might make them answer with HTTP redirects to your API documentation
or something like that instead of some 4xx error status.</p>

<p>(But you probably should also try to figure out why people are
sharing the URLs of your API endpoints on social media٫ and other
people are copying them. You may have a documentation issue.)</p>

<p>PS: As you might suspect٫ this is what <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a> does٫ at least for the
extra query parameters that it specifically recognizes.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpgradeDrag', 'Why Fedora version upgrades are complicated and painful for me', '1599537037000',  14, '<div class="wikitext"><p>It"s September and I still haven"t upgraded any of my machines to
Fedora 32 (which came out at the end of April). If I delay too much
longer٫ I might run into Fedora 33 coming out and Fedora 31 dropping
out of my upgrade path٫ so I really need to start getting moving
on this. But٫ <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/MyKernelUpdateSteps">much like why updating my Fedora kernels is complicated</a>٫ my Fedora version updates are a drag; complex٫
time consuming٫ and periodically painful. So I keep not getting
around to it.</p>

<p>(In a normal year٫ I would have spent a slow afternoon at work to
upgrade the work machine٫ in an environment where having it not
work is not completely disruptive٫ then upgraded the home machine.
That"s not <a href="https://en.wikipedia.org/wiki/COVID-19_pandemic">today"s environment</a>; now I"m at home٫
and my home desktop is also my DSL gateway.)</p>

<p>Normal people have sensible straightforward Fedora upgrade processes.
They start the upgrade in one of the official methods٫ go away for
a an hour or three٫ and it all works. Because my machines run such
an unusual and custom set of environments٫ I don"t trust this process
and I also don"t want to be without either my home desktop or my
work desktop for several hours. So the first complication of my
upgrades is that I do <a href="https://fedoraproject.org/wiki/Upgrading_Fedora_using_package_manager">live upgrades using <code>dnf</code></a> and
during them٫ I watch <code>dnf</code>"s output to see if there are signs of
problems with package updates. I can do other things during this٫
but that"s more than an hour where I am basically babysitting the
machine while distracting myself every so often. This is a time
sink and not a terribly pleasant way to spend my time٫ but it"s
probably the least of the upgrade"s pain.  Doing upgrades in an
unofficial way on an unusual system configuration also raises the
risks that something will break during them٫ and I can never
completely test this in advance (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/Fedora30GrubBLSGotcha">for example</a>).</p>

<p>(I capture all the <code>dnf</code> output by using <code>script</code> so that I can
also look at it later٫ but there"s no good way that I know of to
scan through the result the way I could with a more straightforward
log file.  Something like <code>less</code> will show me the raw output٫
complete with progress bars being rendered and so on. And my terminal
windows only have so much backscroll.)</p>

<p>The next big complication is that I use <a href="https://zfsonlinux.org/">ZFS on Linux</a> for my home directory and other critical
things٫ and it"s of course not integrated with Fedora. This means
there"s always a risk of something going wrong with my ZFS setup
during a Fedora version upgrade. To deal with this٫ I "preflight"
my Fedora version upgrades extensively on virtual machines (which
helps deal with the "will they work in general" issue). This takes
its own set of time and preparation work٫ and is its own kind of
little slog.</p>

<p>Finally٫ upgrading Fedora sometimes creates problems in my custom
desktop environment (or <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/MyDesktopTour">non-environment</a>)
that I"ll have to then sort out (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/Fedora29XIssues">for example</a>).
These range from somewhat modest٫ such as font rendering issues٫
to significant٫ such as sound not working any more. In extreme
cases٫ my desktop environment won"t start at all and I get to spend
some time sorting things out. This means that I can only start the
upgrade on a day when I feel that I have that kind of time left in
the day٫ and I have to be up to dealing with various kinds of
irritation about my environment exploding.</p>

<p>There really isn"t anything that can be done about all of this٫ and
it"s really all a pain that I"ve set myself up for through my own
machine setup choices. So some time٫ I just have to say that I"m
spending this afternoon (or this day) on the work٫ and get it done
(and I"m hoping that writing this entry will help push me forward
on it).</p>

<p>(Sometimes I wonder if tracking Fedora Rawhide would make my life
easier by spreading this time and effort out over a longer time٫
instead of concentrating it all in a few days. But Rawhide"s potential
for serious bugs discourages me. What I really want is a rolling
release of "stable" Fedora٫ with no big bangs of major releases٫
but this will probably never exist. There are sensible reasons for
distributions to like the idea of major releases٫ but that"s for
another entry.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpgradeDrag?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters', 'URL query parameters and how laxness creates de facto requirements on the web', '1599452238000',  14, '<div class="wikitext"><p>One of the ways that <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a> (the code behind <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>) is unusual is that it strictly validates the query parameters
it receives on URLs٫ including on HTTP <code>GET</code> requests for ordinary
pages. If a HTTP request has unexpected and unsupported query
parameters٫ such a <code>GET</code> request will normally fail. When I made
this decision it seemed the cautious and conservative approach٫ but
<a href="https://utcc.utoronto.ca/~cks/space/blog/web/CautionIsAMistakeToday">this caution has turned out to be a mistake on the modern web</a>. In practice٫ all sorts of sites will
generate versions of your URLs with all sorts of extra query
parameters tacked on٫ give them to people٫ and expect them to work.
If your website refuses to play along٫ (some) people won"t get to
see your content. <strong>On today"s web٫ you need to accept (and then
ignore) arbitrary query parameters on your URLs</strong>.</p>

<p>(Today"s new query parameter is "s=NN"٫ for various values of NN
like "04" and "09". I"m not sure what"s generating these URLs٫ but
it may be Slack.)</p>

<p>You might wonder how we got here٫ and that is a story of lax behavior
(or٫ if you prefer٫ being liberal in what you accept). In the
beginning٫ both Apache (for static web pages) and early web
applications often ignored extra query parameters on URLs٫ at least
on <code>GET</code> requests. I suspect that other early web servers also
imitated Apache here٫ but I have less exposure to their behavior
than Apache"s. My guess is that this behavior wasn"t deliberate٫
it was just the simplest way to implement both Apache and early
web applications; you paid attention to what you cared about and
didn"t bother to explicitly check that nothing else was supplied.</p>

<p>When people noticed that this behavior was commonplace and widespread٫
they began using it. I believe that one of the early uses was for
embedding "where this link was shared" information for your own web
analytics (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/AnalyticsVsSecurity">cf</a>)٫ either based on your logs
or using JavaScript embedded in the page. In the way of things٫
once this was common enough other people began helpfully tagging
the links that were shared through them for you٫ which is why I
began to see various "utm_*" query parameters on inbound
requests to <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a> even though I never
published such URLs.
Web developers don"t leave attractive nuisances alone for long٫ so
soon enough people were sticking on extra query parameters to your
URLs that were mostly for them and not so much for you. Facebook
may have been one of the early pioneers here with their "fbclid"
parameter٫ but other websites have hopped on this particular train
since then (as I saw recently with these "s=NN" parameters).</p>

<p>At this point٫ the practice of other websites and services adding
random query parameters to your URLs that pass through them is so
wide spread and common that accepting random query parameters is
pretty much a practical requirement for any web content serving
software that wants to see wide use and not be irritating to the
people operating it. If٫ like <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a>٫ you stick to your guns and
refuse to accept some or all of them٫ you will drop some amount of
your incoming requests from real people٫ disappointing would be
readers.</p>

<p>This practical requirement for URL handling is not documented in
any specification٫ and it"s probably not in most "best practices"
documentation. People writing new web serving systems that are
tempted to be strict and safe and cautious get to learn about it
the hard way.</p>

<p>In general٫ any laxness in actual implementations of a system can
create a similar spiral of de facto requirements. Something that
is permitted and is useful to people will be used٫ and then supporting
that becomes a requirement. This is especially the case in a
distributed system like the web٫ where any attempt to tighten the
rules would only be initially supported by a minority of websites.
These websites would be "outvoted" by the vast majority of websites
that allow the lax behavior and support it٫ because that"s what
happens when the vast majority work and the minority don"t.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters?showcomments#comments">7 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/tech/IM2000NotGoodIdea', 'Daniel J. Bernstein"s IM2000 email proposal is not a good idea', '1599367141000',  14, '<div class="wikitext"><p>A long time ago٫ Daniel J. Bernstein wrote a proposal for a new
generation of Internet email he called <a href="https://cr.yp.to/im2000.html">IM2000</a>٫ although it never went anywhere.
Ever since then٫ a significant number of people have idealized it
as the great white "if only" hope of email (especially as the
solution to spam)٫ in much the same way that people idealized Sun"s
<a href="https://en.wikipedia.org/wiki/NeWS">NeWS</a> as the great "if only"
alternative to X11. Unfortunately٫ IM2000 is not actually a good
idea.</p>

<p>The core of <a href="https://cr.yp.to/im2000.html">IM2000</a> is summarized by Bernstein as follows:</p>

<blockquote><p>IM2000 is a project to design a new Internet mail infrastructure
around the following concept: Mail storage is the sender"s
responsibility.</p>
</blockquote>

<p>The first problem with this is that it doesn"t remove the fundamental
problem of email٫ which is (depending on how you phrase it) that
email is an <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/EmailVsModernProtocols"><em>anonymous push</em> protocol</a>
or that it lacks <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SignedEmailWrongProblem"><em>revocable authorization</em> to send you things</a>. In IM2000٫ random strangers on the
Internet are still allowed to push to you٫ they just push less data
than they currently do with (E)SMTP mail.</p>

<p>The idea that IM2000 will deal with spam rests on the idea that
forcing senders to store mail is difficult for spammers. Even a
decade ago this was a questionable assumption٫ but today it is
clearly false. A great deal of serving capacity is yours for the
asking (and someone"s credit card) in AWS٫ <a href="https://en.wikipedia.org/wiki/Google_Cloud_Platform">GCP</a>٫ Azure٫ OVH٫
and any number of other VPS and serverless computing places.  In
addition many spammers will have a relatively easy time with
"storing" their email٫ because their spam is already generated from
templates and so in IM2000 could be generated on the fly whenever
you asked for it from them. We now have a great deal of experience
with web servers that generate dynamic content on demand and it"s
clear that they can run very efficiently and scale very well٫
provided that they"re designed competently.</p>

<p>(I wrote about this a long time ago <a href="https://utcc.utoronto.ca/~cks/space/blog/spam/SenderStorageHelpsSpammers">here</a>٫ and things have gotten much
easier for spammers since then.)</p>

<p>At the same time٫ IM2000 is catastrophic for your email privacy.
People complain vociferously about "tracking pixels" in HTML email
that betray when you open and read the email from someone; well٫
IM2000 is one giant tracking pixel that reliably reports when and
where you read that email message. IM2000 would also be a terrible
email reading experience٫ because it"s like a version of IMAP where
message retrieval has random delays and sometimes fails entirely.</p>

<p>(As far as spam filtering your incoming IM2000 messages goes٫ IM2000
gives you far less up front information than you currently get with
SMTP email. I wrote up this and other issues a long time ago in an
entry about <a href="https://utcc.utoronto.ca/~cks/space/blog/spam/SenderStorageProblems">the technical problems of such schemes</a>. Some of those problems are no longer
really an issue more than a decade later٫ but some continue to be.)</p>

<p>At a broader "technical choices have social impacts" level٫ IM2000
would create a very different experience than today"s email systems
if implemented faithfully٫ one where "your" email was actually not
yours but was mostly other people"s because other people are storing
it. Those other people can mostly retract individual messages by
deleting them from their servers (you would still have the basic
headers that are pushed to you)٫ and they can wipe out large sections
of your email by deleting entire accounts (and the sent messages
associated with them)٫ or even by going out of business or having
a data loss incident. Imagine a world where an ISP getting out of
the mail business means that all email that its customers have sent
from their ISP email accounts over the years just goes away٫ from
everyone"s mailbox.</p>

<p>(If "ISP" sounds abstract here٫ substitute "Yahoo". Or "GMail".)</p>

<p>In addition٫ in some potential realizations of IM2000٫ email would
become mutable in practice (even if you weren"t supposed to in
theory)٫ because once again the sender is storing the message and
is in a position to alter that stored copy. Expect that capability
to be used sooner or later٫ just as people silently revise things
posted on the web (including official statements٫ perhaps especially
including them).</p>

<p>Some of these social effects can be partially avoided by storing
your own local copies of IM2000 messages when you read them٫ but
there are two issues. The first is pragmatic; the more you store
your own copies and the earlier you make them٫ the more IM2000 is
SMTP in a bad disguise. The second is social; in the IM2000 world
the server holds the authoritative copy of the message٫ not you٫
so if you say the message says one thing (based on your local copy)
and the server operator says it says something else (or doesn"t
exist)٫ the server operator likely wins unless you have very strong
evidence.</p>

<p>In general٫ I think that IM2000 or anything like it would create
an "email" experience that was far more like the web٫ complete with
the experience of <a href="https://en.wikipedia.org/wiki/Link_rot">link rot</a>
and <a href="https://utcc.utoronto.ca/~cks/space/blog/web/CoolUrlsChange">cool messages changing</a>٫ than today"s
email (where for better or worse you keep your own full record of
what you received٫ read and reread it at your leisure٫ and know
that it"s as immutable as you want it to be). And it would still
have the problem that people can push stuff in front of you٫ unlike
the web where you usually at least have to go looking for things.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/CyberPowerPowerpanelNotes', 'Some notes on what the CyberPower UPS "Powerpanel" software reports to you', '1599282594000',  14, '<div class="wikitext"><p>For reasons beyond the scope of this entry٫ I recently bought a
reasonably nice UPS for home usage. Me being me٫ I then found a
Prometheus metrics exporter for it٫ <a href="https://gitlab.com/shouptech/cyberpower_exporter">cyberpower_exporter</a> (and see also
<a href="https://shoup.io/posts/2020-03-19-cyberpower-p8s/">Mike Shoup"s blog post about it</a>)٫ and then
tinkered with it. This exporter works by talking to the daemon
provided by <a href="https://www.cyberpowersystems.com/product/software/power-panel-personal/powerpanel-for-linux/">CyberPower"s Powerpanel software</a>٫
instead of talking directly to the UPS٫ so my first port of call
was to dump the raw information the daemon was providing for my
UPS.</p>

<p>(The Powerpanel software is available as a Fedora RPM that"s not
too obnoxious. Per <a href="https://wiki.archlinux.org/index.php/CyberPower_UPS">the Arch Wiki page on CyberPower UPS</a>٫ you can also
use <a href="http://networkupstools.org/">Network UPS Tools (NUT)</a>. I opted
to take the simpler path that theoretically should just work.)</p>

<p>You get status information from Powerpanel by connecting to the
Unix socket <code>/var/pwrstatd.ipc</code> (yes I know٫ it should be in <code>/run</code>)
and sending ASCII "STATUS" followed by two newlines. You can do this
by hand with <code>nc</code> if you feel like it:</p>

<blockquote><pre style="white-space: pre-wrap;">
printf "STATUS\n\n" | nc -U /var/pwrstatd.ipc
</pre>
</blockquote>

<p>What you get back is something like this (this is my particular UPS
model٫ yours may vary):</p>

<blockquote><pre style="white-space: pre-wrap;">
STATUS
state=0
model_name=CP1500PFCLCD
firmware_num=000000000000
battery_volt=24000
input_rating_volt=120000
output_rating_watt=900000
avr_supported=yes
online_type=no
diagnostic_result=1
diagnostic_date=2020/07/31 12:34:53
power_event_result=1
power_event_date=2020/07/31 12:33:59
power_event_during=21 sec.
battery_remainingtime=5160
battery_charging=no
battery_discharging=no
ac_present=yes
boost=no
utility_volt=121000
output_volt=121000
load=8000
battery_capacity=100
</pre>
</blockquote>

<p>The "volt" and "watt" numbers need to be divided by 1000 to get the
units you expect from their name. The "load" is divided by 1000 to
get a percentage (or by 100000 to get it in 0.0 to 1.0 form)٫ and
is as a percentage of the output rating watts. The daemon doesn"t
report the current load in watts; instead you have to compute it
for yourself. The battery remaining time is in seconds. The battery
capacity is a percentage٫ but unlike <code>load</code>٫ it"s expressed as a
straight 0-100 number. The times are in your local timezone٫ not
UTC٫ and I don"t know how the UPS reports longer durations of power
events (in the minutes or even more than an hour).</p>

<p>I suspect that the <code>state</code>٫ <code>power_event_result</code>٫ and
<code>diagnostic_result</code> fields can take on multiple values.  Based
on what the CyberPower <code>pwrstat</code> command reports for my UPS right
now٫ these mean a normal state٫ that the last power event was a
blackout (a total power loss)٫ and that the last self-test passed.</p>

<p>(The blackout was because I unplugged the UPS from the wall
socket to make sure everything worked٫ which is why it was
so short.)</p>

<p>The reported <code>load</code> number is somewhat untrustworthy and definitely
seems to be quantized by the UPS. It"s possible to observe reported
loads of "0" if my home machine environment is idle enough (with
the display blanked). This isn"t just an artifact of the Powerpanel
software٫ either; when I looked at the UPS"s actual front panel٫
it reported 0 load and 0 watts being used. The front panel also
reports "VA" figures٫ and they didn"t go to zero at these "0 load"
times. However٫ as far as I can tell VA figures aren"t reported by
the Powerpanel software٫ and may or may not be provided to the
outside world by the UPS itself.</p>

<p>(The NUT page for <a href="https://networkupstools.org/ddl/Cyber_Power_Systems/CP1000PFCLCD.html">a very similar model</a>
doesn"t list any VA data.)</p>

<p>As a consequence٫ you can"t really use the reported <code>load</code> value
to see how much power your overall UPS-based setup is using over
time; the UPS <code>load</code> will under-report at times of low usage and
perhaps at other times. This was a bit disappointing٫ but then I
didn"t buy the UPS to (also) be a watt-meter with a USB readout
that I could grab from the computer.</p>

<p>(The UPS connects to my desktop via USB and is visible as a USB
device٫ but I haven"t tried to dump its USB traffic to see the truly
raw data. That"s a little bit too much work for my current level of
curiosity.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/web/CoolUrlsChange', 'In practice٫ cool URLs change (eventually)', '1599194516000',  14, '<div class="wikitext"><p>The idea that "cool URLs don"t change" has been an article of faith
for <a href="https://www.w3.org/Provider/Style/URI">a very long time</a>.
However٫ at this point we have more than 20 years of experience
with the web٫ and anyone who"s been around for a significant length
of time can tell you that <strong>in practice٫ cool URLs change all of
the time</strong> (and I don"t mean just minor changes like preferring
HTTPS over HTTP). Over a sufficient length of time٫ internal site
page layouts change (sometimes because <a href="https://utcc.utoronto.ca/~cks/space/blog/web/CoolUrlProblem">URL design is hard</a>)٫ people move domains or hosts within a domain٫
and sometimes cool URLs even go away and must be resurrected٫
sometimes by hand (through people re-publishing and re-hosting
things) and sometimes through the <a href="https://web.archive.org/">Wayback Machine</a>. This decay in cool URLs is so pervasive
and well recognized that we have a term for it٫ <a href="https://en.wikipedia.org/wiki/Link_rot">link rot</a>.</p>

<p>(Of course٫ you"re a good person٫ and your cool URLs don"t change.
But this is the web and we all link to each other٫ so it"s inevitable
that some other people"s cool URLs that you link to will suffer
from link rot.)</p>

<p>Despite link rot being widely recognized as very real٫ I think that
in many way"s we"re in denial about it. We keep pretending (both
culturally and technically) that if we wish hard enough and try
hard enough (and yell at people hard enough)٫ all important URLs
will be cool URLs that are unchanging forever. But this is not the
case and is never going to be the case٫ and it"s long past time
that we admitted it and started dealing with it. Whether we like
it or not٫ it is better to deal with the world of the web as it is.</p>

<p>Culturally٫ we recite "cool URLs don"t change" a lot٫ which makes
it hard to talk about how best to evolve URLs over time٫ how to
preserve content that you no longer want to host٫ and other issues
like that. I don"t think anyone"s written a best practices document
for "so you want to stop having a web site (but people have linked
to it)"٫ never mind what a company can do to be friendly for archiving
when it goes out of business or shuts down a service. And that"s
just scratching the surface; there"s a huge conversation to be had
about the web over the long term once we admit out loud that nothing
is forever around here.</p>

<p>(The <a href="https://archiveteam.org/">Archive Team</a> has opinions. But
there are some hard issues here; there are people who have published
words on the Internet٫ not under CC licenses٫ and then decided for
their own reasons that they no longer want those words on the
Internet despite the fact that other people like them٫ linked to
them a lot٫ and so on.)</p>

<p>Technically٫ how we design our web systems and web environments
often mostly ignores the possibility of future changes in either
our own cool URLs or other people"s. What this means in more tangible
terms is really a matter for other entries٫ but if you look around
you can probably come up with some ideas of your own. Just look for
the pain points in your own web publishing environment if either
your URLs or other people"s URLs changed.</p>

<p>(One pain point and sign of problems is that it"s a thing to spider
your own site to find all of the external URLs so you can check if
they"re still alive. Another pain point is that it can be so hard
to automatically tell if a link is still there٫ since not all dead
links either fail entirely or result in HTTP error codes. Just ask
people who have links pointing to what are now parked domains.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/WhyMailFilteringLanguage', 'Why I want something like Procmail with a dedicated mail filtering language', '1599104784000',  14, '<div class="wikitext"><p>A couple of years ago I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ProcmailWhatNext">discovering that procmail
development is basically dead</a> and wondering
out loud what I might switch to. In some comments on that entry٫
<a href="http://plasmasturm.org/">Aristotle Pagaltzis</a> suggested that
in an environment (such as MH) with one message per file٫ well٫
let me quote:</p>

<blockquote><p>[...]٫ then you can write yourself one or more programs in your
favourite language that kick the mail from there to wherever you want
it to end up. The entirety of the job of such code is opening and
reading files and then moving them٫ for which any language whatsoever
will do٫ so the only concern is how far you want to library up your
mail parsing.</p>
</blockquote>

<p>My reply (in another comment on that entry) was that I wanted a
system where I directly wrote mail filtering rules٫ as is the case
in procmail٫ not a system where I wrote filtering rules in some
general purpose programming language. But I never explained why I
wanted a special purpose language for this.</p>

<p>My reason for this is that writing mail filtering in a special
purpose language removes (or rather hides) all of the plumbing that
is otherwise necessary. The result may have obscure syntax (procmail
certainly does)٫ but almost everything it says is about what mail
filtering is happening٫ not the structure of getting it to happen
(both at the large scale level of opening files٫ parsing them٫
moving them around٫ and at the small scale level of executing or
otherwise matching rules). This makes it much easier to come back
later to pull out "what is this filtering" from the system; the
configuration file you read is all about that. With a general purpose
programming language٫ coming back in six months or a year requires
essentially reverse engineering your entire program٫ because you
have to find the filtering rules in the rest of the code (and
understand how they"re executed).</p>

<p>(In theory you can avoid some of this if you write good enough
documentation for your personal filtering setup. In practice it"s
pretty unlikely that you will٫ or that this documentation will be
well tested enough (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DocumentationNeedsTesting">because you need to test documentation</a>). An open source mail filtering system
with a dedicated filtering language is much more likely to have
good documentation that lets you drop right into understanding your
filtering rules again.)</p>

<p>This is a subtle advantage of DSLs (Domain Specific Languages) in
general. In a good DSL٫ <a href="https://utcc.utoronto.ca/~cks/space/blog/web/WhySimpleMarkup">much like with wikitext</a>٫
almost everything you write is real "content" (here٫ real filtering
rules)٫ and very little of it is scaffolding. A general purpose
language necessarily isn"t that focused on your specific problem
area٫ and so making it focus that way requires a bunch of scaffolding.
At the extreme٫ you wind up building your own language that"s
implemented in the general purpose language.</p>

<p>(This may be literal٫ with a parser and everything٫ or it may be
in the form of a set of stylized and standard function calls or
method calls you make to embody your real work.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/WhyMailFilteringLanguage?showcomments#comments">5 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoConcurrencyStillNotEasy', 'Even in Go٫ concurrency is still not easy (with an example)', '1599019066000',  14, '<div class="wikitext"><p>Go is famous for making concurrency easy٫ through good language
support for <a href="https://golangbot.com/goroutines/">goroutines</a>. Except
what Go makes easy is only one level of concurrency٫ the nuts and
bolts level of making your code do things concurrently and communicating
back and forth through channels. Making it do the right things
concurrently is still up to you٫ and unfortunately Go doesn"t
currently provide a lot of standard library support for correctly
implemented standard concurrency patterns.</p>

<p>For example٫ one common need is for a limited amount of concurrency;
you want to do several things at once٫ but only so many of them.
At the moment this is up to you to implement on top of goroutines٫
channels٫ and things like the <a href="https://golang.org/pkg/sync/"><code>sync</code></a>
package. This is not as easy as it looks٫ and quite competent people
can make mistakes here. As it happens٫ I have an example ready to
hand today.</p>

<p><a href="https://github.com/google/gops">Gops</a> is a convenient command to
list (and diagnose) Go processes that are currently running on your
system. Among other things٫ it"ll tell you which version of Go they
were compiled with٫ which is handy if you want to see if you have out
of date binaries that should be rebuilt and redeployed. One of the
things <code>gops</code> needs to do is look at all of the Go processes on your
system٫ which it does concurrently. However٫ it doesn"t want to look
at too many processes at once٫ because <a href="https://github.com/google/gops/pull/118">that can cause problems with
file descriptor limits</a>. This
is a classic case of <em>limited concurrency</em>.</p>

<p>Gops implements this at the moment with code in <a href="https://github.com/google/gops/blob/6fb0d860e5fa50629405d9e77e255cd32795967e/goprocess/gp.go#L29">goprocess.FindAll()</a>
that looks like this٫ in somewhat sketched and reduced form:</p>

<blockquote><pre style="white-space: pre-wrap;">
func FindAll() []P {
   pss٫ err := ps.Processes()
   [...]
   found := make(chan P)
   limitCh := make(chan struct{}٫ concurrencyProcesses)

   for _٫ pr := range pss {
      limitCh &lt;- struct{}{}
      pr := pr
      go func() {
         defer func() { &lt;-limitCh }()
         [... get a P with some error checking ...]
         found &lt;- P
      }()
   }
   [...]

   var results []P
   for p := range found {
      results = append(results٫ p)
   }
   return results
}
</pre>
</blockquote>

<p>(In the real code there"s a WaitGroup for coordination٫ and the
<code>found</code> channel gets closed appropriately.)</p>

<p>How this works is clear٫ and is a standard pattern (covered in eg
Go 101"s <a href="https://go101.org/article/channel-use-cases.html">Channel Use Cases</a>). We use a
buffered channel to provide a limited number of tokens; sending a
value into the channel implicitly takes a token (and blocks if the
token supply is exhausted)٫ while receiving a value from it puts a
token back in. We take a token before we start a new goroutine٫ and
the goroutine releases the token when it"s done.</p>

<p>Except that <a href="https://github.com/google/gops/issues/123">this code has a bug if there are too many processes
to examine</a>. Even knowing
that there is a bug in this code٫ it may not be obvious.</p>

<p>The bug is that the goroutines only receive from <code>limitCh</code> to release
their token after sending their result to the unbuffered <code>found</code>
channel٫ while the main code only starts receiving from <code>found</code>
after running through the entire loop٫ and <strong>the main code takes
the token in the loop and blocks if no tokens are available</strong>. So
if you have too many processes to go through٫ you start N goroutines٫
they all block trying to write to <code>found</code> and don"t receive from
<code>limitCh</code>٫ and the main <code>for</code> loop blocks trying to send to <code>limitCh</code>
and never reaches the point where it starts receiving from <code>found</code>.</p>

<p>At one level٫ this bug is a very fragile bug; it only exists because
of multiple circumstances. If the goroutines took the token by
sending to <code>limitCh</code> instead of the main <code>for</code> loop doing it٫ the
bug would not exist; the main <code>for</code> loop would start them all٫ many
would stop٫ and then it would go on to receive from <code>found</code> so that
they could receive from <code>limitCh</code> and release their token so other
goroutines would run. If the goroutines received from <code>limitCh</code> to
release their token before sending to <code>found</code>٫ it wouldn"t exist
(but because of error handling٫ it"s simpler and more reliable to
do the receive in a <code>defer</code>). And if the entire <code>for</code> loop was in
an additional goroutine٫ the main code would go on to receive from
<code>found</code> and unblock completed goroutines to release their tokens٫
so the fact that the <code>for</code> loop was blocked waiting to send to
<code>limitCh</code> wouldn"t matter.</p>

<p>At another level٫ this shows how concurrency is not easy as easy
as it looks in Go. All you need is one mistake and things skid to
a halt٫ and all of the code involved can look good to a casual
examination. Getting concurrency correct is simply hard for people
(we can debate about why٫ but I think that it is is very clear).</p>

<p>(I"m sure that the people who wrote and approved the change that
added this concurrency limiting code to gops were good programmers.
A tricky case still tripped them up٫ passing all of their scrutiny.
Even when I knew that there was a concurrency problem in the code
and where it was (because my <code>gops</code> was hanging all of a sudden٫
and <a href="https://github.com/go-delve/delve">Delve</a> told me where
everything was stuck)٫ it still took me some time to see what the
exact problem was.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/SignedEmailSolutionImpact', 'Why we won"t like it if signing email is the solution to various email problems', '1598926733000',  14, '<div class="wikitext"><p>Yesterday I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SignedEmailWrongProblem">my thesis that all forms of signing email
are generally solving the wrong problem</a>
and said in passing that if signing email was actually a solution٫
we wouldn"t like it in the long run. Today٫ let"s talk about that.</p>

<p>As I sort of discussed yesterday٫ the issue with signing email as
a solution is that on the Internet٫ identities normally can"t be
used to exclude people because people can always get a new one (eg٫
a new domain and new DKIM keys for it and so on). If signed email
is going to solve problems٫ the requirement is that such new
identities stop being useful. In other words٫ email providers would
stop accepting email from new identities (or at least do something
akin to that). If new identities don"t get your email accepted٫
existing identities are suddenly important and can be used to revoke
access.</p>

<p>(This revocation might be general or specific٫ where a user could
say "I don"t want to see this place"s email any more" and then the
system uses the identity information to make that reliable.)</p>

<p>Let"s be blunt: big email providers would love this. Google would
be quite happy in a world where almost everyone used one of a few
sources of email and Google could make deals or strongarm most or
all of them. Such a world would significantly strengthen the current
large incumbents and drive more business to their paid offerings.
Even the current world where it"s rather easier in practice to get
your email delivered reliably if you"re a Google Mail or Microsoft
Office365 customer does that; a world where only a few identities
had their email reliably accepted would make that far worse.</p>

<p>For the rest of us٫ that would be a pretty disastrous change. I
won"t say that the cure would be worse than the disease (people"s
opinions here vary)٫ but it would likely create two relatively
separate email worlds٫ with the remaining decentralized email network
not really connected to the centralized one of "only known identities
accepted here" email. If running your own mail server infrastructure
meant not talking to GMail٫ a lot of people and organizations would
drop out of doing it and the remaining ones would likely have
ideological reasons for continuing to do so.</p>

<p>(A far out version of this would be for it to lead to multiple
federated email networks٫ as clusters of email systems that interact
with each other but don"t accept much email from the outside world
effectively close their borders much as the big providers did. If
this sounds strange٫ well٫ there are multiple IRC networks and even
the <a href="https://en.wikipedia.org/wiki/Fediverse">Fediverse</a> is
splintering in practice as not everyone talks to everyone else. And
there are plenty of messaging systems that don"t interconnect with
each other at all.)</p>

<p>PS: There are lesser versions of this٫ where large email providers
don"t outright stop showing "outside" email to people but they do
downgrade and segregate it. And of course that happens to some
degree today through opaque anti-spam and anti-junk systems; if
Hotmail dislikes your email but not enough to reject it outright٫
probably a lot of people there aren"t going to see it.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/SignedEmailWrongProblem', 'All forms of signing email are generally solving the wrong problem (a thesis)', '1598842533000',  14, '<div class="wikitext"><p>Modern email is full of forms of signed email. Personally signed
email is the old fashioned approach (and wrong)٫ but modern email
on the Internet is laced with things like <a href="https://en.wikipedia.org/wiki/DomainKeys_Identified_Mail">DKIM</a>٫ which
have the sending system sign it to identify at least who sent it.
Unfortunately٫ the more I think about it٫ the more I feel that
signed email is generally solving the wrong problem (and if it"s
solving the right one٫ we won"t like that solution in the long run).</p>

<p>A while ago I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/EmailVsModernProtocols">why email often isn"t as good as modern
protocols</a>٫ which is because it"s what I
described as an <em>anonymous push</em> protocol. An anonymous push protocol
necessarily enables spam since it allows anyone to send you things.
Describing email as "anonymous push" makes it sound like the anonymity
is the problem٫ which would make various forms of signing the
solution (including DKIM). But this isn"t really what you care about
with email and requiring email to carry some strong identification
doesn"t solve the problem٫ as we"ve found out with all of the spam
email that has perfectly good DKIM signatures for some random new
domain.</p>

<p>(This is a version of <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TwoSidesOfIdentity">the two sides of identity</a>.
On the Internet people can trivially have multiple identities٫ so
while an identity is useful to only let selected people in٫ it"s
not useful to keep someone out.)</p>

<p>I think that what you really care about with modern communication
protocols is <em>revocable authorization</em>. With a pull protocol٫ you
have this directly; you tacitly revoke authorization by stopping
pulling from the place you no longer like. With a push protocol٫
you can still require authorization that you grant٫ which lets you
revoke that granted authorization if you wish. The closest email
comes to this is having lots of customized email addresses and
carefully using a different one for each service (which Apple has
recently automated for iOS people).</p>

<p>Obviously٫ requiring authorization to push things to you has a
fundamental conflict with any system that"s designed to let arbitrary
strangers contact you without prearrangement (which is <a href="https://utcc.utoronto.ca/~cks/space/blog/spam/FundamentalSpamProblem">the
fundamental problem of spam</a>).
Modern protocols seem to deal with this in two ways (even with
revocable authorization); they have some form of gatekeeping (in
the form of accounts or access)٫ and then they evolve to provide
settings that let you stop or minimize the ability of arbitrary
strangers to contact you (for example٫ Twitter"s settings around
who can send you Direct Messages).</p>

<p>(The modern user experience of things like Twitter has also evolved
to somewhat minimize the impact of strangers trying to contact you;
for example٫ the Twitter website separates new DMs from strangers
from DMs from people you"ve already interacted with. It"s possible
that email clients could learn some lessons from this٫ for example
by splitting your inbox into "people and places you"ve interacted
with before" and "new contacts from strange people". This would
make DKIM signatures and other email source identification useful٫
apart from the bit where senders today feel free to keep changing
where they"re sending from.)</p>

<p>PS: In this view٫ actions like blocking or muting people on Twitter
(or the social network of your choice) is a form of revoking their
tacit authorization to push things to you.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SignedEmailWrongProblem?showcomments#comments">9 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoContextValueMistake', 'An interesting mistake with Go"s <code>context</code> package that I (sort of) made', '1598757854000',  14, '<div class="wikitext"><p>Today٫ <a href="https://dave.cheney.net/">Dave Cheney</a> did another Go pop quiz
<a href="https://twitter.com/davecheney/status/1299846267850223616">on Twitter</a>٫
where he asked whether the following code printed -6٫ 0٫ "&lt;nil>"٫ or
paniced:</p>

<blockquote><pre style="white-space: pre-wrap;">
package main
</pre>

<pre style="white-space: pre-wrap;">
import (
    "context"
    "fmt"
)

func f(ctx context.Context) {
    context.WithValue(ctx٫ "foo"٫ -6)
}

func main() {
    ctx := context.TODO()
    f(ctx)
    fmt.Println(ctx.Value("foo"))
}
</pre>
</blockquote>

<p>I didn"t answer this correctly because I focused my attention on the
wrong thing.</p>

<p>What I focused on was the use of the <code>"foo"</code> string as the context
key٫ partly because of my experience with languages like Python.
To start with٫ the <a href="https://golang.org/pkg/context/"><code>context</code></a>
package"s documentation says:</p>

<blockquote><p>The provided key must be comparable and should not be of type string
or any other built-in type to avoid collisions between packages using
context. Users of WithValue should define their own types for keys.
[...]</p>
</blockquote>

<p>A traditional problem in languages like Python is that two strings
may compare the same without actually being the same thing٫ and
some code really wants you to present it with the exact same thing.
However٫ the <code>context</code> package doesn"t require that you present it
with the exact same key٫ just a key where the <em>interface value</em> of
the key will compare the same.</p>

<p>(Because <code>context</code> compares interface values٫ both the value and
the type must match; it"s not enough for both values to have the
same underlying concrete type٫ say string٫ and to compare identical.
This is why defining your own string type is a reliable away around
collisions between packages.)</p>

<p>So after I worked through all of this٫ I confidently answered that
this code printed -6. The <code>"foo"</code> string that the value is set
with is not necessarily the same <code>"foo"</code> string that it"s retrieved
with٫ but that doesn"t matter. However٫ this is not the problem
with the code. The actual problem is that <strong>context.WithValue()
returns a new context with the value set٫ it doesn"t change the
context it"s called on</strong>. Dave Cheney"s code is written as if
<code>.WithValue()</code> mutates the current context٫ as <code>f()</code> ignores that
new context that <code>.WithValue()</code> provides and returns nothing to
<code>main()</code>. Since the original <code>context</code> in <code>main()</code> is what <code>.Value()</code>
is called on٫ it has no <code>"foo"</code> key and the result is actually
"&lt;nil>".</p>

<p>This problem with the code is actually a quite interesting mistake٫
because as far as I can tell right now none of the usual Go style
checkers detect it. This code passes "<code>go vet</code>"٫ it produces no
complaints from <a href="https://github.com/kisielk/errcheck"><code>errcheck</code></a>
because we"re not ignoring an error return value٫ and tools like
<a href="https://github.com/golangci/golangci-lint">golangci-lint</a> only
complain about the use of the built-in type string as the key in
<code>.WithValue()</code>. Nothing seems to notice that we"re ignoring the
critical return value from <code>.WithValue()</code>٫ which turns it into more
or less a no-op.</p>

<p>(Now that Dave Cheney has brought this to the surface٫ I suspect
that someone will contribute a check for it to <a href="https://staticcheck.io/">staticcheck</a>٫ which already detects the "using a
built-in type as a key" issue.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoContextValueMistake?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/unix/VimNotUsingFeatures', 'My divergence from "proper" Vim by not using and exploring features', '1598673577000',  14, '<div class="wikitext"><p>I"ve read a reasonable number of Vim tutorials and introductions
by now٫ and one of the things that stands out is how some of what
I do differs from what seems to be considered "proper" Vim. The
simple way to put it is that I use less of Vim"s features than the
tutorials often introduce. One of the best examples is something
that I do all of the time٫ which is reflowing paragraphs.</p>

<p>The official proper Vim way to reflow paragraphs (based on tutorials
I"ve read) is <code>gq{motion}</code>. Often the most flexible version is
<code>gqip</code> or <code>gqap</code> (where "ip" or "ap" select the paragraph you"re
in). Assuming that various things are set correctly٫ this will
magically reflow your paragraph٫ much as M-q does in Emacs (a command
I"m accustomed to using there).</p>

<p>However٫ for various reasons I don"t use this; instead I rely on
the general purpose hammer of "<code>!</code>" and the (relatively) standard
Unix <code>fmt</code> command. My conditioned reflex sequence of commands for
formatting the paragraph I"m writing is "ESC { !}fmt }"٫ and in
general I"ll use "!}fmt" more or less reflexively.</p>

<p>At one level this is somewhere between a curiosity and a deliberate
choice not to learn all of Vim and try to Vim golf everything in
sight (a choice that <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/ViInefficientMovement">I"ve written about before</a>).
At another level this is kind of a weakness. As an example٫ in
writing this entry I discovered not just that the <code>gq</code> command could
be made to use <code>fmt</code>٫ but also discovered or re-discovered the <code>ip</code>
and <code>ap</code> motion modifiers٫ which might be useful periodically٫
including in my usual paragraph reflowing.</p>

<p>Or perhaps not٫ because now that I experiment with it٫ using <code>ip</code>
instead of moving to the start of the paragraph causes the cursor
to jump up to the start after the paragraph is reflowed. Using an
explicit { command means that I"m (relatively) conscious that I"m
actively moving before I reflow٫ instead of having the cursor jump.
If Vim was Emacs٫ I probably wouldn"t mind٫ but since Vim is Vim I
think I may prefer the explicitness of my current approach.</p>

<p>(And on character golfing٫ using <code>ip</code> or <code>ap</code> saves no characters
in this situation. To really golf٫ I would need to switch to <code>gq</code>.)</p>

<p><a href="https://utcc.utoronto.ca/~cks/space/blog/unix/ViInefficientMovement">As before</a>٫ I probably shouldn"t be
surprised. Vim"s sets of commands and motions are now really quite
large٫ and people generally pick and choose what they use out of
large sets like that. I suspect that plenty of Vim users use only
various subsets of them٫ subsets that would strike other Vim users
as annoyingly inefficient or old-fashioned.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/VimNotUsingFeatures?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/web/Firefox80VideoAccelConfusion', 'Firefox 80 and my confusion over its hardware accelerated video on Linux', '1598591821000',  14, '<div class="wikitext"><p>The news of the time interval is that Firefox 80 is out and in
theory it can support hardware video acceleration on X11٫ not just
Wayland (<a href="https://www.omgubuntu.co.uk/2020/08/firefox-80-release-linux-gpu-acceleration">source</a>٫
<a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=Firefox-80-Released">also</a>).
The master Mozilla tracking bug for hardware accelerated video on
X11 is <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1619523">bug #1619523</a>٫ with all
sorts of information. So I downloaded the official release (one of
my Firefox setups uses the official builds these days for reasons
beyond the scope of this entry) and tried to get it to do accelerated
video playback. The short version is that I think I"ve failed٫ but I"m
not sure why.</p>

<p>Even in Firefox 80٫ getting VA-API accelerated video playback
requires a whole series of magic incantations in <code>about:config</code>
preferences and perhaps environment variables when you start Firefox
(this may change in the next release). Assuming that all of those
are set right٫ Firefox can apparently still decide that it doesn"t
like your Linux video driver (or its version)٫ your specific hardware٫
or perhaps either or both of the resolution of the source video and
the resolution of your display. Some or many of these can be forced
with Firefox settings٫ but at the same time the bug reports I"ve
read say that sometimes Firefox ignores hardware acceleration because
it"s slower for the specific circumstances٫ or because it has known
bugs. If Firefox is making a sensible decision for <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2018">my specific
hardware</a>٫ that"s one thing and I want
it to do what will work best. But if I"ve missed a setting or if
Firefox is just being twitchy about something٫ I also want to
override it. In general I know my hardware is capable of hardware
accelerated playback of videos at far lower CPU usage than Firefox
manages (on the same videos).</p>

<p>Unfortunately٫ Firefox won"t tell me what it"s doing or why٫ at
least not in a way that I can understand. I"ve peered into the
depths of <code>about:support</code>٫ which tells me some of the "what" but
not the "why"٫ and I"ve tried some of the things from <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1619523">bug #1619523</a>
without success. If Firefox is or isn"t going to do hardware
accelerated video playback٫ I wish it would tell me both what it was
doing and why. Otherwise I"m probably going to go on being confused
and annoyed with it.</p>

<p>(I care about hardware acceleration not just because of CPU load
but because my perception is that hardware acceleration is necessary
to play back a full sized video smoothly without dropping frames
every so often. This may be wrong on modern hardware٫ even on my 4k
display.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/Firefox80VideoAccelConfusion?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSSSDActivitySlowsScrubs', 'Even on SSDs٫ ongoing activity can slow down ZFS scrubs drastically', '1598496494000',  14, '<div class="wikitext"><p>Back in the days of <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetupII">our OmniOS fileservers</a>٫
which used HDs (spinning rust) across iSCSI٫ we wound up <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSScrubsOurSpeedup">changing
kernel tunables to speed up ZFS scrubs</a> and
saw a significant improvement. When we migrated to <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">our current
Linux fileservers with SSDs</a>٫ I
didn"t bother including these tunables (or the Linux equivalent)٫
because I expected that SSDs were fast enough that it didn"t matter.
Indeed٫ our SSD pools generally scrub like lightning.</p>

<p>(Our Linux fileservers use a ZFS version before <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSSequentialScrubIsComing">sequential scrubs</a> (<a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSScrubScannedVsIssued">also</a>).
It"s possible that sequential scrub support would change this story.)</p>

<p>Then٫ this weekend٫ a ZFS pool with 1.68 TB of space used took two
days to scrub (48:15٫ to be precise). This is not something that
happens normally; this size of pool usually scrubs much faster٫ on
the order of a few hours. When I poked at it a bit none of the disks
seemed unusually slow and there were no signs of other problems٫
it was just that the scrub was running slowly. However٫ looking at
NFS client metrics in <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">our metrics system</a> suggested that there was
continuous ongoing NFS activity to some of the filesystems in that
pool.</p>

<p>Although I don"t know for sure٫ this looks like a classical case
of even a modest level of regular ZFS activity causing the ZFS scrub
code to back off significantly on IO. Since this is on SSDs٫ this
isn"t really necessary (at least for us); we could almost certainly
sustain both a more or less full speed scrub and our regular read
IO (significant write IO might be another story٫ but that"s because
it has some potential performance effects on SSDs in general). However٫
with no tuning our current version of ZFS is sticking to conservative
defaults.</p>

<p>In one sense٫ this isn"t surprising٫ since it"s how ZFS has
traditionally reacted to IO during scrubs. In another sense٫ it is٫
because it"s not something I expected to see affect us on SSDs; if
I had expected to see it٫ I"d have carried forward our ZFS tunables
to speed up scrubs.</p>

<p>(Now that I look at our logged data٫ it appears that ZFS scrubs on
this pool have been slow for some time٫ although not "two days" slow.
They used to complete in a couple of hours٫ then suddenly jumped to
over 24 hours. More investigation may be needed.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/ColdLockupMachineMysteryII', 'My home desktop is still locking up when it gets too cold (and what next)', '1598413897000',  14, '<div class="wikitext"><p>In early 2019 I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/ColdLockupMachineMystery">the mystery of my home desktop that
was locking up when it got too cold</a>.  At
that point the machine was about a year old (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2018">I built it in March
or so of 2018</a>) and the winter of 2018-2019
was its first winter and thus my first chance to see this. I regret
to report that I haven"t really done anything since then٫ and the
machine will still lock up when it gets too cold. For last winter
(the 2019-2020 winter)٫ my workaround was to raise the heat here;
in combination with a generally mild winter that was enough to have
only a couple of lockups during especially cold overnight times.</p>

<p><a href="https://en.wikipedia.org/wiki/COVID-19_pandemic">Current world and local events</a> suggest strongly
that daytime interior temperatures will not be an issue this coming
winter٫ because I will almost certainly be working from home almost
all of the time and so will want it warm enough to be comfortable
(which is well above the temperature the machine locks up at).
However that still leaves me with the direct issue of overnight
temperatures and the indirect issue that I have a machine with some
sort of flaw that"s now my primary machine for doing work.</p>

<p>The path of least resistance is to do nothing and assume that nothing
really bad will happen. My machine will probably lock up a few times
overnight when I"m not using it over the winter٫ but that"s no big
deal. The path of more effort and some risk is to reseat at least
the memory٫ loosen and re-tighten the motherboard screws٫ and perhaps
experiment with canned air to selectively cool spots on the motherboard
to see if I can identify something that triggers the problem. This
risks a slightly flaky component into a very flaky or even a dead
component٫ which would leave me with a dead machine٫ and also has
no guarantee of fixing or even identifying the problem.</p>

<p>(But re-seating things should be very low risk so I should really
try it٫ however much I don"t like working with hardware.)</p>

<p>The sure but more expensive path would be to replace at least the
motherboard and (probably) the power supply. Buying a new motherboard
or PSU would be necessary in practice even if I identify a fault
in my current one and get it replaced under warranty٫ because I"m
not going to be without a home desktop for so much as a day if I
can help it. This feels wasteful (the current hardware is only about
two and a half years old) and expensive٫ but if I put a reasonable
value on my time and annoyance it"s probably the second cheapest
option after doing nothing. It also means I would have to figure
out at least a new motherboard٫ which is where I started thinking
about <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/MissingPCType">how I want a type of PC and motherboard that"s generally
skipped</a>. However٫ it would give me an emergency
spare motherboard and PSU that would be comparable to my current
machine٫ which is something I might decide I care about in the
current conditions.</p>

<p>(Having a reliable motherboard with two M.2 slots and a backup
emergency spare would also make it less scary to upgrade to M.2
NVMe drives. Right now I"ve been holding back on that partly because
my emergency machine is <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2011">my old home PC</a>٫
which has no M.2 slots and <a href="https://twitter.com/thatcks/status/975884414021496832">I lost full trust in</a>.)</p>

<p>(This entry is one of the ones that I write in part to convince myself
to do something sensible. Whether I actually will is an open question;
knowing myself٫ the most likely option is to do nothing until the
weather starts getting cold enough that the issue"s more imminent.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/ColdLockupMachineMysteryII?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/tech/MissingPCType', 'I want a type of desktop PC (and motherboard) that"s generally skipped', '1598326141000',  14, '<div class="wikitext"><p>By now٫ the desktop x86 PC market has segmented itself into a number
of categories. There are machines٫ CPUs٫ and motherboards that are
basic machines with limited features and made to be quite inexpensive٫
"business" machines that don"t need very much but are more than the
very basics٫ machines for gaming enthusiasts٫ and HEDT ("High End
Desktop") workstations that are aimed at people building high powered
machines. Typical examples of what are in these categories are in
Anandtech"s <a href="https://www.anandtech.com/show/11891/best-cpus-for-workstations">Best CPUs for Workstations</a>
and <a href="https://www.anandtech.com/show/9793/best-cpus">Best CPUs for Gaming</a>;
in Intel motherboard chipsets there is the H series٫ the B series٫
and the Z series (sometimes among others). Unfortunately for me٫
my interests in machines fall into an intermediate category that
doesn"t generally exist٫ which I will call a <em>sysadmin workstation</em>.</p>

<p>Every system administrator probably has a somewhat different view
of what they want in their desktop. My image of a sysadmin workstation
is exemplified by <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2018">my current home machine</a>;
it has a fast (Intel) CPU٫ it takes a fair amount of RAM that can
run at faster than completely stock speeds٫ it has at least M.2
slots (both of which run at x4) and four SATA ports٫ and it can
drive at least one 4K display through onboard graphics. Unlike a
gaming machine٫ I want to use integrated graphics (they"re quieter٫
less clutter٫ cheaper٫ and generally better supported on Linux)
instead of a GPU. Unlike a HEDT workstation٫ I don"t want a
fire-breathing CPU with its increased cost and cooling requirements
(and I also don"t want one or more GPUs for GPU computation). And
I want more storage (especially M.2) than basic home or business
desktops usually provide.</p>

<p>(I might change my views on GPUs if Intel starts making discreet
GPUs that are well supported under Linux٫ drive two 4K displays
at 60 Hz or better٫ and don"t require lots of cooling.)</p>

<p>It"s possible to put together a sysadmin workstation٫ of course; I
did it for <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2018">my current home machine</a> and
<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/WorkMachine2017">my current (AMD based) work machine</a>٫
although the latter has to use a GPU. But it generally involves
buying more than you need and picking through specifications to
narrow in on the bits you care about٫ and the motherboard support
for integrated graphics is often somewhat limited. People who buy
motherboards with lots of features and high specification generally
use GPUs٫ so there are a fair number of otherwise suitable motherboards
that just don"t support onboard graphics. I"m also lucky in that
Intel still provides versions of their higher end desktop CPUs with
onboard graphics. AMD has historically restricted onboard graphics
to lower end models; if you wanted a reasonably powerful Ryzen٫ you
were stuck getting a GPU.</p>

<p>(As far as Intel versus Ryzen goes٫ <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/MyIntelVsAMDView-2018">I still don"t trust AMD</a>. My Intel home machine still has its problem
of <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/ColdLockupMachineMystery">hanging when the temperature drops too low</a>٫
but that"s a narrow issue that"s probably a motherboard fault. The
coming of winter with another go-around of this issue is one reason
I"m thinking about motherboards and desktops and so on again.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/MissingPCType?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/spam/BugzillasGetSpam', 'The Linux kernel bugzilla (and others) get spammed (of course)', '1598238947000',  14, '<div class="wikitext"><p>The general rule of the Internet is that everything gets spammed٫
so at one level it should be no surprise to me that bug reporting
systems for open source projects do. As it happens٫ I sort of have
personal experience with this٫ especially through <a href="https://bugzilla.kernel.org/show_bug.cgi?id=196683">this old bug
for AMD Ryzens hanging on Linux</a>٫ which I"m
subscribed to because <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/RyzenApparentlyStable">it sort of affects me</a>. Actually reading the bug will
generally not show you any spam٫ but that"s because people go through
and remove it quite promptly when it"s submitted. I know about the
spam because I get the standard Bugzilla email when someone submits
an update to it٫ including a new spam comment.</p>

<p>(I"m pretty sure the Fedora Bugzilla instance gets spammed too٫
although perhaps less than the kernel"s.)</p>

<p>Since you have to register to leave new comments in the Linux kernel
bugzilla and the spam persists٫ the spammers are either doing this
at least partially by hand or have automated the process of registering
for Bugzillas. This isn"t just the usual automated form stuffing
that goes on everywhere.</p>

<p>(When I say "the spammers"٫ it could be people that they"ve hired
to do it in low-wage areas.)</p>

<p>That this happens doesn"t so much make me sad as make me angry
(again) at the spammers٫ not just because of the spam but because
of the way they progressively ruin everything on the Internet.
Behind the clean looking Linux kernel bugzilla bug entry is some
number of people who have to shovel out the stables and worry about
how to try to stop the inflow٫ and the same is true for lots of
other things. Everything on the Internet today that allows people
to send in content has to deal with spam٫ which means that spam
is a tax on all of those things (and one that wears away at people).
I"m sure that there are things that aren"t being built because of
spam٫ or that are being built differently.</p>

<p>PS: I believe that the Linux kernel bugzilla spam I"ve seen has
generally been attempts to plant links to various sites. Sometimes
it"s just a big spew of URLs٫ but sometimes it has some text (even
sometimes text that"s plugging its links instead of just filling up
space).</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/python/ArgparseSomeUnixNotes', 'Some bits on making Python"s argparse module work like Unix usually does', '1598155179000',  14, '<div class="wikitext"><p>I recently discovered that <a href="https://utcc.utoronto.ca/~cks/space/blog/python/ArgparseAbbreviatedOptions">argparse allows you to abbreviate long
options</a>٫ and then Chris Wellons wrote
about <a href="https://nullprogram.com/blog/2020/08/01/">Conventions for (Unix) Command Line Options</a>٫ which included a criticism
of <a href="https://docs.python.org/3/library/argparse.html"><code>argparse</code></a>. I"m
not going to write about how to make argparse behave today٫ because I
haven"t explored that in full; instead٫ this is some quick notes from
the documentation and my past experiences.</p>

<p>First٫ both Wellons and I had a bad reaction to argparse accepting
abbreviated options. However٫ based on <a href="https://docs.python.org/3/library/argparse.html#argumentparser-objects">the documentation</a>
you probably have to accept it٫ because of an important postscript
note:</p>

<blockquote><p><em>Changed in version 3.8</em>: In previous versions٫ <code>allow_abbrev</code>
[being <code>False</code>] also disabled grouping of short flags such as <code>-vv</code>
to mean <code>-v -v</code>.</p>
</blockquote>

<p>Almost no one has Python 3.8٫ which means that the cure here is
worse than the disease. Not accepting grouped short flags is much
worse than accepting abbreviated long flags٫ so until Python 3.8+
is pervasive we"re stuck with the latter.</p>

<p>As it implicitly documents (in the form of its example)٫ argparse
allows the non-traditional style of options being intermixed with
non-option arguments on the command line٫ instead of requiring all
options to be before non-options. There is no way to control this.
Argparse does accept "<code>--</code>" to terminate the option list (with some
caveats)٫ after which things that look like options are non-option
arguments.</p>

<p>In general٫ using the <a href="https://docs.python.org/3/library/argparse.html#nargs"><code>nargs</code></a> argument
for <a href="https://docs.python.org/3/library/argparse.html#the-add-argument-method"><code>add_argument()</code></a>
is neither necessary nor useful for options (and <a href="https://utcc.utoronto.ca/~cks/space/blog/python/ArgparseNargsChoicesLimitation">has issues when
used with non-options</a>). Setting
things like "<code>type=str</code>" or "<code>action="append"</code> causes the argument
parser to do the right thing; similarly٫ it does the right thing
when the action doesn"t consume any argument value (this behavior
is documented in a postscript of the <code>nargs</code> section). As Wellons
noted٫ argparse can fall down badly if you attempt to create an
option that takes an optional value. Fortunately٫ <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/MyOptionsConventions">I don"t think
you should do that</a> and should stick
to options either always taking a value or never doing so. Argparse"s
own examples use "<code>nargs="?"</code>" for non-options arguments that are
in fact optional.</p>

<p>Argparse makes a weird attempt to handle command line arguments that
are negative numbers٫ as documented in <a href="https://docs.python.org/3/library/argparse.html#arguments-containing">Arguments containing -</a>.
This isn"t how traditional Unix commands behave with such arguments٫
where a leading "-" is a leading "-" no matter what٫ with no attempts to
guess at what should happen. This behavior is not currently optional
and I don"t think there"s a really good way to trick argparse into not
doing it.</p>

<p>(Actually reading much of the <a href="https://docs.python.org/3/library/argparse.html"><code>argparse</code></a> documentation has
already taught me useful things I didn"t know٫ such as how the
<a href="https://docs.python.org/3/library/argparse.html#dest"><code>dest</code></a>
argument is optional. I"m not sure I"d want to ever leave it out٫
though; explicit is better than implicit٫ and using "<code>dest</code>" leaves
a visible reminder in the code of what attribute holds the result.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/links/MozillaWhyNoXULAddons', 'Link: Why Did Mozilla Remove XUL Add-ons?', '1598063581000',  14, '<div class="wikitext"><p>David Teller"s <a href="https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/">Why Did Mozilla Remove XUL Add-ons?</a>
is the answer to this question٫ from someone who works on Firefox.
Firefox XUL Add-ons are the old and more powerful form of addons٫
which have now been replaced by WebExtensions as of Firefox Quantum.</p>

<p>I knew a certain amount about this area (and it"s an interest of
mine٫ since Firefox WebExtensions still aren"t quite as good for
<a href="https://utcc.utoronto.ca/~cks/space/blog/web/Firefox74Addons">my addons</a>)٫ but I didn"t know all of the
details and the article taught me things. I had never quite wondered
what happened to Firefox"s Electrolysis stuff٫ for example; the
article answers the question.</p>

<p>(<a href="https://hackers.town/@lmorchard/104723322435253992">Via</a>٫
itself via <a href="https://mastodon.social/@mhoye">@mhoye</a>.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/GoogleWhenEvilRealized', 'When I stopped believing in Google"s fundamental good nature', '1598062069000',  14, '<div class="wikitext"><p>Once upon a time I might have believed in Google"s fundamental
goodness and well intentioned nature (probably with qualifications).
Google themselves eventually taught me better٫ perhaps later than
it took for other people to realize that they were an amoral
corporation. For me٫ the moment of realization٫ the point where I
knew for sure that Google"s "don"t be evil" slogan was inoperative٫
was the great <a href="https://en.wikipedia.org/wiki/Google%2B">Google+</a>
"nymwars"٫ where Google (for Google+) declared that everyone on
Google+ must use their real name and then attempted to enforce that
(<a href="https://en.wikipedia.org/wiki/Nymwars#Google">it went wrong pretty fast</a>).</p>

<p>There were a large number of problems with Google+"s "real name"
policies. It didn"t match how actual users referred to each other
and were known online٫ including for people who actually worked at
Google. Forcing people to reveal their real name does real harm and
has real risks (something appreciated even back then in 2011٫ but
which is more pointed today). And in practice٫ a "real name" policy
is actually a "it looks like a real name to underpaid support people
or some automated system" policy٫ where "John Smith" is far more
likely to be accepted than a non-Western name or an unusual one٫
even if one is not your real name and the other is.</p>

<p>Google knew all of this. People٫ including internal people٫ pointed
this out to them at great length. A decent number of technical people
who worked at Google protested. There were demonstrated problems with
the actual enforcement and actions involved. And Google٫ in both their
senior leadership and their ongoing policies٫ simply didn"t care. All
of the harms and the wrongs did not matter to them. They were going to
do evil because they could٫ and because they thought it served their
corporate goals for Google+.</p>

<p>(We all know how that one went; Google+ died٫ for all that it had
some good ideas.)</p>

<p>Watching all of this happen٫ watching all of the protesting and
good arguments and everything go exactly nowhere٫ is when I knew
that my image of Google was wrong (and gone). Now I extend no more
trust to Google than I think supported by their corporate and
commercial interests. Google employees may care about "don"t be
evil" and doing the right thing and so on٫ but Google as a whole
does not٫ and the employees do what Google tells them to.</p>

<p>(This elaborates something I said in an aside long ago٫ in an entry
about <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SmartphoneWhyIPhone">why my smartphone is an iPhone</a>.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/GoogleWhenEvilRealized?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DashboardsWhatForAndSettings', 'What you"re looking for with a Grafana dashboard affects its settings', '1597982248000',  14, '<div class="wikitext"><p>Recently I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/GrafanaOurIntervalSettings">how we chose our time intervals in dashboards</a>٫ where the answer is that we mostly
use <a href="http://docs.grafana.org/reference/templating/#the-interval-variable"><code>$__interval</code></a>
because for our purposes this is the best option. But this raises
the question of what is our purpose with our dashboards. Put another
way٫ why do we not care about seeing brief spikes in our dashboards?</p>

<p>Broadly speaking٫ I think that dashboards can be there to look for
signs of obvious issues٫ to look for signs of subtle issues٫ or to
diagnose problems in detail (when you already know there"s an issue
and you"re trying to understand what"s going on). Pretty much all
of our dashboards are for some combination of the first or the last٫
and we don"t normally go looking for subtle issues.</p>

<p>(The flipside of looking for signs of obvious issues is reassuring
you that there are no obvious issues right now. From a cynical
perspective٫ this may be the purpose of a lot of overview dashboards.)</p>

<p>When you"re looking for obvious issues٫ broad overviews are generally
fine. If you have periodic very short usage spikes but nothing else
notices on a larger scale٫ you almost certainly don"t have an
<em>obvious</em> issue. Similarly٫ showing very short usage spikes on a
broad overview graph isn"t necessarily useful unless you believe
that these spikes are the sign of a larger issue. As a result٫ you
might as well use <code>$__interval</code> even though it makes short term
spikes disappear when you"re looking at longer time periods.</p>

<p>When you"re trying to diagnose problems in detail you already know
something is going on and you"re probably looking at fine time
scales around specific times of interest. At fine time scales٫ a
properly set up Grafana dashboard will show you all of the information
available٫ including fine grained spikes٫ because it"s using a very
short <code>$__interval</code> since it covers only a small time range. This
is certainly my experience with our dashboards٫ where I often wind
up looking at only five or ten minute time windows in order to try
to really understand what was going on at some point.</p>

<p>Looking for subtle issues is an interesting challenge in dashboard
design. I suspect it"s hard to do without knowing a fair bit about
how your environment is supposed to behave (or at least believing
that you do). At this point it"s not something that I"m doing very
much of in our dashboard design (although I"ve sort of done some
of it).</p>

<p>(See also <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DashboardAttentionProblem">the problem of paying too much attention to our
dashboards</a>.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/web/LinuxBrowserSupportPains', 'Potential problem points for Chrome (or any browser) to support Linux', '1597890426000',  14, '<div class="wikitext"><p>Suppose٫ not entirely hypothetically٫ that you"re worried about the
possibility of browsers no longer supporting Linux (and Unix in
general). Since Chrome and Firefox are already cross-platform٫ a
sensible question is what might make supporting Linux (or Unix in
general) difficult in a cross-platform browser٫ especially one that
already supports Android. From my somewhat ignorant perspective٫ I
see two general issues.</p>

<p>One big thing that a browser needs to do is interact with the
platform"s "graphics" system for drawing٫ video٫ audio٫ input events٫
and other similar things (extending to eg clipboard support). Unix
currently has two graphics systems (X11 and Wayland) that are used
by no one else٫ and they"re at least somewhat different from other
platforms (especially X11٫ which is very old fashioned). If the X11
and Wayland APIs diverge too far away from what Android and Windows
support (and possibly Mac OS)٫ then continuing to support the lowest
common denominator between all of these platforms might be considered
too limiting (or too much work to basically emulate what other
platforms can do).</p>

<p>(We"ve already seen some degree of this in video٫ where both Chrome
and Firefox have been very slow to support hardware accelerated
video playback on Unix systems.)</p>

<p>The other large area٫ especially for Chrome٫ is platform security
features for process isolation and process security. To the best
of my understanding٫ Chrome is much more secure on Windows than it
is on Unix because Windows allows it to do much more to lock down
various processes. Unix (Linux especially) is trying to move forward
on this٫ but it"s generally been happening slowly and it may not
match the APIs that Chrome is organized around on Windows. On
Android٫ Google has a lot of freedom to advance the platform security
features in any way that they want٫ so they could move towards
features and APIs that are more convenient for them (ie٫ probably
more Windows like). This would leave Unix as the odd one out٫
requiring an increasing amount of code (and effort) just for it٫
for less security.</p>

<p>(Firefox is not as far along toward separated and securely confined
processes٫ so I expect that this affects it less.)</p>

<p>PS: With all of that said٫ <a href="https://old.reddit.com/r/linux/comments/ic1afz/firefox_and_web_browsers_for_linux/">the Reddit comments</a>
for <a href="https://utcc.utoronto.ca/~cks/space/blog/web/FirefoxAndLinuxBrowsers">my entry worrying about Firefox"s future on Linux</a> raised a good point (<a href="https://old.reddit.com/r/linux/comments/ic1afz/firefox_and_web_browsers_for_linux/g21onzz/">here</a>)
for Chrome continuing to support Linux٫ which is that a lot of
Google developers use Linux internally and they need a browser٫ and
probably ideally a Chrome that at least renders the same as Chrome
on Windows and Android.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/LinuxBrowserSupportPains?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/PrometheusVsCPUFrequency', 'The Prometheus host agent can disturb Linux CPU frequency measurements', '1597807604000',  14, '<div class="wikitext"><p>Recently I read <a href="https://www.robustperception.io/cpu-frequency-scaling-metrics-from-the-node-exporter">CPU frequency scaling metrics from the node
exporter</a>٫
which talks about how to look at the <a href="https://prometheus.io/">Prometheus</a>
metrics that the <a href="https://github.com/prometheus/node_exporter">Prometheus host agent</a> gathers and exposes
to Prometheus. Naturally this got me to to look at the frequencies
that my own little Prometheus setup on <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2018">my home machine</a>
had gathered٫ which gave me a surprise.</p>

<p>Like a lot of desktops٫ my home machine is idle almost all of the
time٫ and I can see that reflected in a lot of the statistics that
the Prometheus host agent gathers. But Prometheus reported that my
my CPU frequency was hovering up at very high values٫ often around
4 GHz (and checking confirmed that these were what the host agent
was reporting). Since this didn"t match my expectations٫ I looked
at the direct information in <code>/sys</code>:</p>


<pre style="white-space: pre-wrap;">
: hawklords.cs ; cd /sys/devices/system/cpu/cpufreq
: hawklords.cs ; cat policy?/scaling_cur_freq policy??/scaling_cur_freq
800079
800210
800106
800045
800091
800032
800162
800644
801214
800175
800060
800026
</pre>

<p>That is٫ my CPUs are sitting at around 800 Mhz٫ which is actually
the minimum frequency (scaling_min_freq is 800000). That"s what
I see almost all of the time when my desktop is idle٫ with brief
exceptions.</p>

<p>My only theory for what"s going on with the Prometheus host agent
is that this is happening because the host agent is a <a href="https://golang.org/">Go</a> program and is quite parallelized and concurrent.
When Prometheus or you ask the host agent for metrics٫ it immediately
goes out to gather them from all of its <a href="https://github.com/prometheus/node_exporter#collectors"><em>collectors</em></a> in parallel٫
which is likely to make many or all of your CPUs busy and thus push
up their frequencies. Apparently my overall system (Linux٫ the CPU٫
and whatever BIOS magic is going on) is so good at this that the
speed rises fast enough for the host agent to observe it٫ and then
drops again almost immediately once the host agent is done. I suspect
that the Prometheus daemon itself also contributes to the CPU usage
(since it"s receiving the data from the host agent)٫ but I expect
that the host agent"s multi-CPU usage is the big factor.</p>

<p>(The choice of CPU frequency governor likely affects this; my home
machine is currently on "powersave"٫ which is what my Fedora 31
environment defaults to. The CPU frequency driver is intel_pstate.)</p>

<p>This unfortunately rather reduces the usefulness of the host agent"s
CPU frequency information on Linux. You can probably use it to look
at big exceptions (such as CPUs٫ cores٫ or sockets that are
persistently out of step with what they should be)٫ but it"s clearly
not a reliable guide to the normal state of your systems.</p>

<p>PS: I see similar but less drastic effects on <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/WorkMachine2017">my office machine</a>٫ which has an AMD Ryzen instead of an Intel CPU.
Direct examination in <code>/sys</code> suggests that it idles around 1.8 Ghz٫
but the host agent sees it around 2.7 to 2.9 Ghz when idle٫ with
spikes to higher.</p>

<p>PPS: The host agent does sometimes observe low frequencies; it"s
reported 800 Mhz frequencies on each core on my home machine at
some point over the past week. It even appears to have seen 800 Mhz
on all cores at some point.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/web/FirefoxAndLinuxBrowsers', 'Firefox and web browsers for Linux', '1597718045000',  14, '<div class="wikitext"><p>The (web) news of the time interval is that <a href="https://arstechnica.com/information-technology/2020/08/firefox-maker-mozilla-lays-off-250-workers-says-covid-19-lowered-revenue/">Mozilla is laying off
a significant number of people</a>٫
including people working on <a href="https://developer.mozilla.org/en-US/docs/Tools#:~:text=You%20can%20open%20the%20Firefox٫%2B%20Opt%20%2B%20I%20on%20macOS.">Firefox"s web developer tools</a>
and <a href="https://developer.mozilla.org/en-US/">MDN</a>. Naturally this
has led to people worrying about the future of Firefox (well٫ more
than usual٫ since it"s had declining web browser share for some
time). As a user of Firefox on Linux I have some extra worries٫
because Firefox is kind of special on Linux.</p>

<p>People on Windows٫ Mac OS٫ iOS٫ and Android can be confident that
there will pretty much always be a competent browser on their
platform. Each of these platforms is backed by a big company and
having a competent browser is too important to their success for
the company to neglect it. Linux (or Unix in general) is the odd
platform out٫ since there"s no large company behind it to fund
browser development. Competent Unix web browsers are kind of a side
effect of browser development for other platforms.</p>

<p>Out of the main browsers remaining٫ only Mozilla has felt genuinely
committed to keeping their browser going on Unix. Apple and Microsoft
are obviously indifferent٫ and Google"s corporate goals for Chrome
only require it to work on major platforms such as Windows and
Android (Android is not Unix here٫ because Android doesn"t use X11
or Wayland and has increasingly divergent APIs and capabilities).
It"s fairly easy to imagine a future where Firefox fading out leaves
Unix people with essentially no modern browsers and a growing set
of sites that we couldn"t really use.</p>

<p>(I believe that the Chrome developers generally care about Chrome
working on Unix٫ but they"re at the mercy of what Google is willing
to spend money on. If the spur of competition from Firefox goes
away٫ Google might decide that Unix no longer qualifies. They might
even decide that supporting Chromium on Unix is getting in the way
of internal changes that make it better on Android and Windows.)</p>

<p>This might sound theoretical٫ but in a way Unix users have been
here before. Back in the days before Netscape open-sourced its
browser to create Mozilla٫ Netscape"s browser was pretty much the
only good option for Unix users٫ and Netscape had a solid period
of relative stagnation in the late 90s and early 00s. I used Netscape
back then and it was not really a great experience. I"m not looking
forward to the possibility of a rerun of that.</p>

<p>(In the pre-Mozilla days٫ Unix users were also at the mercy of what
Unixes Netscape bothered to provide browser binaries for. I"m pretty
sure that there were some Unix workstation users who lost out due
to that٫ which didn"t help the fortunes of their Unix vendors in
an era where the web was becoming more and more important.)</p>

<p>PS: It"s possible that Canonical٫ Red Hat٫ and perhaps SuSE would
get together to fund enough ongoing Firefox development to keep
things viable on Linux (and hopefully other Unixes). Perhaps there
are even people in these organizations considering this issue right
now.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/FirefoxAndLinuxBrowsers?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/unix/TimeBeforeReadline', 'Important parts of Unix"s history happened before readline support was common', '1597637326000',  14, '<div class="wikitext"><p>Unix and things that run on Unix have been around for a long time
now. In particular٫ <a href="https://en.wikipedia.org/wiki/GNU_Readline">GNU Readline</a> was first released in
1989 (as was <a href="https://en.wikipedia.org/wiki/Bash_(Unix_shell)">Bash</a>)٫
which is long enough ago for it (or lookalikes) to become pretty
much pervasive٫ especially in Unix shells. Today it"s easy to think
of readline support as something that"s always been there.  But of
course this isn"t the case. Unix in its modern form dates from <a href="https://en.wikipedia.org/wiki/Version_7_Unix">V7</a> in 1979 and <a href="https://en.wikipedia.org/wiki/History_of_the_Berkeley_Software_Distribution#4.2BSD">4.2
BSD</a>
in 1983٫ so a lot of Unix was developed before readline and was
to some degree shaped by the lack of it.</p>

<p>(This isn"t to say that GNU Readline and Bash were the first sources
of readline style editing٫ command completion٫ and so on; on Unix
they go back at least as far as 1983٫ with <a href="https://en.wikipedia.org/wiki/Tcsh">tcsh</a>. But tcsh wasn"t pervasive for
various reasons.)</p>

<p>One obvious thing that was shaped by the lack of readline was csh.
Csh has a sophisticated set of operations on your command history
that are involved through special strings embedded in your command
line. To quote <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=4.2BSD/usr/man/man1/csh.1">the 4.2 BSD csh manpage</a>:</p>

<blockquote><p>History substitutions place words from previous command input as
portions of new commands٫ making it easy to repeat commands٫ repeat
arguments of a previous command in the current command٫ or fix
spelling mistakes in the previous command with little typing and a
high degree of confidence.  History substitutions begin with the
character `!" and may begin anywhere in the input stream (with the
proviso that they do not nest).</p>
</blockquote>

<p>The most well known history substitution for tcsh users is probably
"<code>!!</code>"٫ which repeats the previous command. Bash has a similar
facility٫ <a href="https://www.gnu.org/software/bash/manual/html_node/History-Interaction.html">cf</a>٫
and even today the Bash manual calls out its similarity to csh"s
version. These days I suspect most people using Bash don"t use Bash"s
history substitutions and just stick to readline stuff; it"s generally
more fluid and easy to deal with.</p>

<p>(This is an obvious observation٫ but at times it"s easy to blur the
old days of Unix together and lose track of how comparatively old
some parts of it are. Or at least it is for me.)</p>

<p>PS: My impression is that the widespread availability of command
and filename completion subtly shapes the kind of command names and
file names that people use. When you don"t have completion٫ it makes
a lot of sense for names to be short and it doesn"t matter if they"re
all jumbled together so that completion can"t tell them apart.
Famously٫ Unix loves short command names because they"re short to
type٫ which makes a lot of sense in a V7 environment.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/TimeBeforeReadline?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/BlameAndWorksOnMyLaptop', '"It works on my laptop" is a blame game', '1597550442000',  14, '<div class="wikitext"><p>There is an infamous dialog between developers and operations teams
(<a href="https://markosrendell.wordpress.com/2014/02/20/it-works-on-my-laptop-win/">eg</a>)
where the core of the exchange is the developer saying "it works
on my laptop" and then the operations team saying "well٫ pack up
your laptop٫ it"s going into production". Sometimes this is reframed
as the developer saying "it works on my laptop٫ deploy it to
production". One of many ways to understand this exchange is as a
game of who is to blame for production issues.</p>

<p>When the developer says "well it works on my laptop"٫ they"re
implicitly saying "you operations people screwed up when deploying
it". When the operations people say "well pack up your laptop"٫
they"re implicitly saying in return "no we didn"t٫ you screwed it
up one way or another; either it didn"t work or you didn"t prepare
it for deployment". The developer is trying to push blame to
operations and operations is trying to push blame back.</p>

<p>(This exchange is perpetually darkly funny to system administrators
because we often feel that we"re taking the fall for what are
actually other people"s problems٫ and in this exchange the operations
people get to push back.)</p>

<p>But the important thing here is that this is a social problem٫ just like
any blame game. Sometimes this is because higher up people will punish
someone (implicitly or explicitly) for the issue٫ and sometimes this is
because incentives aren"t aligned (which can lead to <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DevopsBlameProblem">DevOps as a way
to deal with the blame problem</a>).</p>

<p>(<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DevopsProblemLevels">This isn"t the only thing that DevOps can be for</a>.)</p>

<p>Playing the blame game in real life instead of in funny Internet
jokes isn"t productive٫ it"s a problem. If your organization is
having this dialog for real٫ it has multiple issues and you"re
probably going to get caught in the fallout.</p>

<p>(I almost wrote "you have multiple issues"٫ but it"s not your
problem٫ it"s the organization"s. Unless you"re very highly placed٫
you can"t fix these organizational problems٫ because they point to
deep cultural issues on how developers and system administrators
view each other٫ interact with each other٫ and probably are rewarded.)</p>

<p>Realizing this makes the "it works on my laptop" thing a little
less funny and amusing to me٫ and a bit sadder and darker than it
was before.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/BlameAndWorksOnMyLaptop?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoInlinesAcrossPackages', 'Go will inline functions across packages (under the right circumstances)', '1597467487000',  14, '<div class="wikitext"><p>Like many languages٫ or more exactly many compilers for many
languages٫ Go will <a href="https://en.wikipedia.org/wiki/Inline_expansion"><em>inline</em></a> one function into
another under the right circumstances.  For more on this in general
(and examples)٫ see Dave Cheney"s <a href="https://dave.cheney.net/2020/04/25/inlining-optimisations-in-go">Inlining optimisations in Go</a>.</p>

<p>In many languages٫ only functions within the same source code file
or compilation unit are candidates for inlining. Functions that are
further away than that (and compiled separately)٫ especially in
completely separate packages or libraries٫ are not available for
inlining for various reasons. As I found out recently٫ modern
versions of Go don"t work this way٫ especially with <a href="https://dave.cheney.net/2020/05/02/mid-stack-inlining-in-go">mid-stack
inlining</a>.
If a function in a different package that you use is simple enough٫
the Go compiler will quietly inline it into your function.</p>

<p>With Go"s <a href="https://dave.cheney.net/2020/05/02/mid-stack-inlining-in-go">mid-stack inlining</a>٫ there are some very common functions
from standard packages that are inlined (probably) in many people"s
code. One prominent example is <a href="https://golang.org/pkg/fmt/#Printf"><code>fmt.Printf</code></a>. The actual implementation of
<code>fmt.Printf</code> is:</p>


<blockquote><pre style="white-space: pre-wrap;">
func Printf(format string٫ a ...interface{}) (n int٫ err error) {
   return Fprintf(os.Stdout٫ format٫ a...)
}
</pre>
</blockquote>

<p>(You can see it in <a href="https://github.com/golang/go/blob/master/src/fmt/print.go#L210">fmt/print.go</a>.)</p>

<p>This is simple enough to be inlined٫ and so it generally is. If you
write a little test program and build it with the necessary compiler
flags (from Dave Cheney"s <a href="https://dave.cheney.net/2020/05/02/mid-stack-inlining-in-go">Mid-stack inlining in Go</a>)٫ you
can get a report on this:</p>

<blockquote><pre style="white-space: pre-wrap;">
$ go build -gcflags=-m=2 fred.go
[...]
./fred.go:4:14: inlining call to fmt.Printf [...]
</pre>
</blockquote>

<p>(And if you check on <a href="https://godbolt.org/">Compiler Explorer</a>
(aka "godbolt")٫ you can verify that the generated assembly matches
this.)</p>

<p>PS: I don"t know if this inlining extends to internal runtime
functions that the compiler generates call to for you٫ such as
<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts">converting small integer values to interfaces</a>٫
or if it only happens for calls that are in your source as you wrote
it.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallIntsII', 'Go 1.15"s interface optimization for small integers is invisible to Go programs', '1597382145000',  14, '<div class="wikitext"><p>When I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts">how Go 1.15 improved converting small integer
values to interfaces</a>٫ I said that Go
pointing small integer interface values to its special static array
of the first 256 integers was similar to what some dynamic languages
do. For example٫ Python effectively <a href="https://en.wikipedia.org/wiki/String_interning"><em>interns</em></a> a bunch of small
integers. However٫ in one important respect what Go is doing is
different from what Python and other languages are doing. In Go٫
this optimization is invisible to normal٫ proper Go programs٫ while
the equivalent in other languages <a href="https://utcc.utoronto.ca/~cks/space/blog/python/ObjectIdentityGotcha">often is visible in some
situations</a>.</p>

<p>The reason this optimization is visible to programs in Python is
that Python exposes the actual unique interned objects for small
numbers to you. Since you get access to these objects٫ you can tell
when two numbers from two completely different sources are actually
the same object٫ and sometimes this matters. (And since the unique
objects are directly exposed to you٫ they have to be made immutable.)</p>

<p>Go doesn"t do this. Go works in values and values are always copied٫
including when you create interface values from concrete values
(even if the concrete value is a pointer). <strong>How an interface value
holds its copy of the concrete value is invisible to Go programs</strong>.
When you create an interface value from a concrete value٫ the
interface value takes a copy of the concrete value and stores it
somehow. When you get the concrete value back using a <a href="https://tour.golang.org/methods/15">type assertion</a> or call a method on the concrete
type through the interface value٫ Go makes a copy of the concrete
value held by the interface value and gives it to you (or the
method). You never get a reference to the interface value"s copy
of the concrete value.</p>

<p>Mechanically٫ Go implements interface values using a pair of pointers
(<a href="https://research.swtch.com/interfaces">cf</a>)٫ which means that
an interface value normally needs to allocate a place to put its
copy of the concrete value (which it will then have a pointer to).
But you never get access to the "pointer to the concrete value"
part of the interface value in normal Go and so you can never observe
that for a small integer٫ it"s pointing into a static array instead
of into the heap.  Since you can"t see these pointers٫ you also
can"t see that two different interface values have pointers to the
same entry in the static array.</p>

<p>(You can use <a href="https://golang.org/pkg/unsafe/">the <code>unsafe</code> package</a>
to crack open the otherwise opaque interface value and pull out the
pair of pointers. But then you"re not using normal Go.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/ManyRealLifeIdentities', 'People often have multiple social identities even in the physical realm', '1597285468000',  14, '<div class="wikitext"><p>Somewhat recently٫ I read <a href="https://yarmo.eu/post/future-online-identity-decentralized">The Future of Online Identity is
Decentralized</a>
(<a href="https://lobste.rs/s/ckalve/future_online_identity_is_decentralized">via</a>)٫
and it said one thing in passing that made me twitch. I"ll quote rather
than paraphrase:</p>

<blockquote><p>Authenticity and anonymity aren"t mutually exclusive and that is
the beauty of the internet. In the physical realm٫ you are (mostly)
limited to a single social identity. In the digital space٫ there are
no such restrictions. While you can"t embody multiple persons in the
offline world٫ you can have several identities online. [...]</p>
</blockquote>

<p>This is٫ in practice٫ not the case. Many people have what are in effect
multiple social identities in the real world٫ and you can even argue
that the lack of support for this in common platforms on the Internet
has created some real problems (especially for how people interact with
them).</p>

<p>The way you naturally create multiple social identities in the real
world is simple; you don"t tell everyone you interact with about
everything you do٫ especially in detail. You are in practice one
person at work٫ another person at home٫ a third person at <a href="https://tbn.ca/">your
bike club</a>٫ a fourth person on the photowalks you
do (<a href="https://en.wikipedia.org/wiki/COVID-19_pandemic">or did</a>)
with the group of regulars٫ and so on and so forth. These disjoint
groups of people may have some idea that you have other identities
(you may mention to your co-workers that you"re a keen bicyclist
and are in a bike club)٫ but they probably don"t know the details
(and often they don"t want to). In practice these are different
social identities and you"re a different person to all of these
groups; each one may well know some things about you that would
surprise others who know you.</p>

<p>(My impression is that this separation is especially strong between work
and everything else. People like to draw a line here and not share back
and forth.)</p>

<p>By now٫ we"ve all heard stories of these separate social identities
breaking down (or being exposed) on the Internet in social media٫
in the familiar story of "I had no idea they were &lt;X>" (or "believed
in &lt;X>")٫ where &lt;X> is often something uncomfortable to you. Before
Facebook٫ Twitter٫ and the like٫ this sort of thing required different
groups of people to talk to each other or have an unexpected
connection (say٫ one of your co-workers takes up bicycling and joins
your bicycle club). Now٫ social media often slams all of that
together; if you see anything of someone٫ you may see everything.
Social media generally tacitly encourages this by making it easiest
to share everything with everyone٫ instead of providing good support
for multiple social identities on a single platform (leading to the
perennial "I followed you to read about &lt;X>٫ not &lt;Y>" complaints
on Twitter and elsewhere).</p>

<p>(You can also argue that the Internet makes it easier for people
who want to cross connect your (online) identities to do so٫ because
it made broad searches much easier. On the Internet٫ you have to
be deliberately anonymous or simple web searches may well turn up
multiple social identities.)</p>

<p>Relatively strong Internet anonymity is probably easier than strong
physical anonymity٫ at least today (where you can take someone"s
name you learned from one connection to them and start trying to
find other signs of them on the Internet). Physical social identities
necessarily leak what you look like and often your name٫ and you
can readily skip both on most of the Internet.</p>

<p>(Some portions of the Internet are very intent on knowing your real
name٫ but there"s still a broad norm that people can be anonymous
and pseudonymous. And if you have a relatively common name٫ even
your name is relatively pseudonymous by itself٫ because there
will be many people on the Internet with that name.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/programming/Go115InterfaceSmallInts', 'How Go 1.15 improved converting small integer values to interfaces', '1597207160000',  14, '<div class="wikitext"><p>In Go٫ <a href="https://golang.org/ref/spec#Interface_types">interface values</a>
are famously implemented as a pair of pointers (see Russ Cox"s <a href="https://research.swtch.com/interfaces">Go
Data Structures: Interfaces</a>);
a pointer to information about the type and a pointer to the value
itself. This generally means that the value must be dynamically
allocated in the <em>heap</em>٫ which means that it will contribute to the
work that Go"s garbage collection does.</p>

<p>The <a href="https://golang.org/doc/go1.15">Go 1.15 release notes</a> mention
an intriguing improvement in <a href="https://golang.org/doc/go1.15#runtime">the runtime section</a>:</p>

<blockquote><p>Converting a small integer value into an interface value no longer
causes allocation.</p>
</blockquote>

<p>When I saw that٫ I immediately wondered how it works٫ and especially
if Go"s runtime was now sometimes using the value pointer field in
interface values to directly store the value.
(There are a number of languages that do this٫ using various approaches
like <a href="https://wiki.c2.com/?TagBit">tag bits</a> to tell values from real
pointers.)</p>

<p>The answer turns out to be pretty straightforward٫ and is in <a href="https://go-review.googlesource.com/c/go/+/216401">Go
CL 216401</a> (merged
in <a href="https://github.com/golang/go/commit/9828c43288a53d3df75b1f73edad0d037a91dff8">this commit</a>٫
which may be easier to read). The Go runtime has a special static
array of the first 256 integers (0 to 255)٫ and when it would
normally have to allocate memory to store an integer on the heap
as part of converting it to an interface٫ it first checks to see
if it can just return a pointer to the appropriate element in the
array instead. This kind of static allocation of frequently used
values is common in languages with lots of dynamic allocation;
Python does something similar for small integers٫ for example
(<a href="https://utcc.utoronto.ca/~cks/space/blog/python/ObjectIdentityGotcha">which can sometimes surprise you</a>).</p>

<p>(It turns out that Go previously had an optimization where if you were
converting 0 to an interface value٫ it would return a pointer to a
special static zero value. This new optimization for 0-255 replaces
that.)</p>

<p>There is one special trick that Go plays here. The actual array is
an array of <code>uint64</code>٫ but it reuses the same array for smaller sized
values as well. On <a href="https://en.wikipedia.org/wiki/Endianness">little endian</a> systems like x86٫ this
is fine as it stands because a pointer to a 64-bit value is also a
valid pointer to that value interpreted as 32 or 16 bits (or 8
bits). But on big endian systems this isn"t the case٫ so if Go is
running on a big endian machine it bumps up the pointer so that it
works properly (making it point to either the last two bytes or the
last four bytes of the 8-byte value).</p>

<p>(On a little endian machine٫ the pointer is to the low byte of the
value and the remaining bytes are all zero so it doesn"t matter how
many more of them you look at. On a big endian machine٫ the pointer
is to the high byte٫ but the low byte is the thing that matters.)</p>

<p>As bonus trivia for this change٫ this new array of 0-255 <code>uint64</code>
values was then reused for avoiding allocating anything for one-byte
strings in another change (<a href="https://github.com/golang/go/commit/bda42a7a782dbcf4b123d617c5b60f3c848cbb82">this commit</a>٫
<a href="https://go-review.googlesource.com/c/go/+/221979">CL 221979</a>).
Go previously had an array of bytes for this purpose٫ but why have
two arrays. Big endian machines need the same sort of pointer bumping
they did for small integers being converted to interface values٫
but little endian machines can once again use the pointers as is.</p>

<p>PS: There are runtime functions for converting 16٫ 32٫ and 64 bit
values to interface values٫ in <a href="https://github.com/golang/go/blob/master/src/runtime/iface.go">runtime/iface.go</a>
(they can be inlined in actual code)٫ but I was puzzled because
there is no runtime function for converting 8 bit values. It turns
out that 8-bit values are directly handled by the compiler in
<a href="https://github.com/golang/go/blob/master/src/cmd/compile/internal/gc/walk.go#L837">walk.go</a>٫
where it generates inline code that uses the <code>staticuint64s</code> array.
This may be done directly in the compiler partly because it needs
no fallback path for larger values٫ unlike the 16٫ 32٫ and 64 bit
cases٫ since an 8 bit value will always be in <code>staticuint64s</code>.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraAvoidingModules', 'Disabling DNF modules on Fedora 31 so they don"t mess up package updates', '1597113409000',  14, '<div class="wikitext"><p>Fedora 31 DNF modules (and probably Fedora 32 ones as well) are
currently broken٫ as covered <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailure">here</a>
and <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailureII">here</a>. Fedora is not insuring
that DNF modules that claim to be the "latest" (for example ripgrep)
have versions of their packages that are as recent as the non-modular
packages (the ripgrep module has 11.0.2; Fedora 31 has 12.0.1)٫ and
the mere existence of a DNF module for something will block updates٫
even if you have not enabled the module. The only way out is to
disable (or ignore) DNF modules.</p>

<p>If you want to temporarily ignore DNF modules to update your system
to the latest versions of packages available in the main Fedora 31
repository٫ the following (from <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailure">my first entry</a>) appears to work:</p>

<blockquote><pre style="white-space: pre-wrap;">
dnf --setopt=updates.module_hotfixes=true --setopt=fedora.module_hotfixes=true update
</pre>
</blockquote>

<p>In <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailureII">my second entry</a> I thought that
removing everything from <code>/etc/dnf/modules.d</code> would prevent problems.
This turns out to not be the case. If you want to completely disable
DNF modules٫ you need to either edit /etc/yum.repos.d/fedora-modular.repo
to change "enabled=1" to "enabled=0"٫ or remove the file entirely.
I would edit the file٫ as that probably has a higher chance to
survive package updates of the fedora-repos package. I believe
that you can also do this with "<code>dnf config-manager --set-disabled
fedora-modular</code>"٫ but I"m the kind of person who uses an editor
here.</p>

<p>(Fedora has repo files in <code>/etc/yum.repos.d</code> for reasons of historical
compatibility and avoiding flag days where all repo files have to
move٫ one way or another.  It amuses me sometimes.)</p>

<p>I don"t yet know if upgrading Fedora with DNF keeps modules disabled.
I suspect not and that I"ll have to go back in to clean things out
after I upgrade to Fedora 32 one of these days. After my experiences
with modules to date٫ I have no intentions of ever having them doing
anything on any of my Fedora machines until and unless Fedora gives
me no choice in the matter.</p>

<p>I hope that this is the last entry I have to write about DNF modules.
There"s more that I could say about this mess but I"d rather not spend
more time on it.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraAvoidingModules?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/unix/UnixOptionsConventions', 'Unix options conventions are just that٫ which makes them products of culture', '1597027795000',  14, '<div class="wikitext"><p>Recently I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/MyOptionsConventions">my views on some conventions for Unix
command line options</a>٫ where I disagreed in
part with what Chris Wellons considered <a href="https://nullprogram.com/blog/2020/08/01/">Conventions for Command
Line Options</a>. Both Wellons
and I have a lot of Unix experience٫ and that we disagreed on parts
of what rightfully should be a well established core of Unix in
practice shows some things about them.</p>

<p>The first thing to note about Unix"s conventions on options is that
they"ve always been ad hoc and imperfectly adhered to٫ to the extent
that they even existed in the first place. To start with٫ V7 Unix
did not have <code>getopt(3)</code>٫ so every V7 program did its own parsing
of options and I"m certain that some of them had somewhat different
behavior. Several V7 programs completely broke these conventions;
famously <code>dd</code> doesn"t even use conventional options that start with
a "-"٫ and while <code>find</code> has options that start with "-" they"re
actually more like GNU style long options.</p>

<p>(<a href="https://en.wikipedia.org/wiki/Getopt">Wikipedia</a> implies that
<code>getopt(3)</code> first appeared in System III٫ and indeed <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=SysIII/usr/src/man/man3/getopt.3c">here"s the
System III <code>getopt(3)</code> manpage</a>٫
dating from 1980 (<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=SysIII/usr/src/man/man3">cf</a>٫
<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=SysIII">also</a>).)</p>

<p>The second thing is that both Wellons and I can go on about conventions
all we want (and what they should be)٫ but the reality is that the
"conventions" that exist are defined by what programs actually do.
If a lot of programs (or a popular option parsing library) behave
in a particular way٫ in practice that is the convention regardless
what I think of it (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/MyOptionsConventions">or write</a>). The corollary
of this is that what people consider convention is in large part
defined by how the programs they use behave. By its mere existence
and popularity٫ GNU Getopt has defined a lot of the modern conventions
for options handling; if you deviate from it٫ you will surprise
people who expect your programs to behave like the other programs
they use every day.  Before GNU Getopt was what most programs used٫
<code>getopt(3)</code> did the same thing and had the same effect for the
conventions it enforced.</p>

<p>(New options parsing libraries tend not to break too much with the
current convention when they were initially written٫ but they can
selectively change some of them٫ especially what are considered more
obscure ones.)</p>

<p>Finally٫ I suspect that part of the difference between Wellons" view
of these conventions and mine is because of when we came into Unix. I
started using Unix long enough ago that it was in the era of classic
<code>getopt(3)</code> instead of GNU Getopt (and long options)٫ so the rules that
<code>getopt(3)</code> enforced were the ones that I wound up internalizing as the
correct conventions. Someone who came into Unix later would have been
primarily exposed to GNU Getopt"s somewhat different behavior٫ with it
supporting intermixed options and non option arguments٫ long options
being routine٫ and so on.</p>

<p>The corollary of this is that people who come into Unix today
are learning the conventions as they stand now٫ including any
inconsistencies between Unix programs that are increasingly written in
different languages٫ with different argument parsing libraries٫ and so
on.  Some languages are sufficiently divergent that no one is going to
mistake them for "how Unix commands should behave" (I"m looking at you٫
Go)٫ but others are close enough that people are likely to internalize
parts of their behavior٫ even if only as expected divergences and
differences٫ just as people remember <code>find</code> and its unusual behavior.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/UnixOptionsConventions?showcomments#comments">9 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailureII', 'More problems with Fedora 31 DNF modules and package updates', '1596944499000',  14, '<div class="wikitext"><p>A while back I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailure">how Fedora 31 had fumbled DNF modules
and package updates</a>٫ which ended with
me believing that I had fixed the problem so that I would get updates
to packages I cared about despite the DNF module versions not being
updated. Then recently <a href="https://twitter.com/thatcks/status/1291373423655084034">I tweeted</a>:</p>

<blockquote><p>It turns out that Fedora 31 DNF modules٫ even reset ones that aren"t
active٫ are apparently still both out of date and blocking package
updates. Modular ripgrep is 11.x٫ current main repo ripgrep is 12.1.0٫
but good luck getting that.</p>

<p>Dear Fedora: If I have to resort to bodhi to get the latest
stable main repository version of packages٫ DNF has failed
*spectacularly*. If these packages had security updates٫ there
would be real issues here.</p>
</blockquote>

<p><a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailure">As before</a>٫ for a while "<code>dnf updateinfo
info</code>" has been telling me that there was an update to ripgrep
available٫ to 12.1.0 (I had 12.0.0). However I couldn"t get <code>dnf</code>
to actually apply the update٫ and the latest version that the
"ripgrep" module has is 11.0.2. Similar problems were reported for
meson and a couple of other packages. This is despite the fact that
I had no DNF modules enabled; I had reset all of them in <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailure">my first
go around</a>.</p>

<p>To actually get the current packages٫ I resorted to the brute force
approach of <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraBodhiGetPackages">downloading them through <code>bodhi</code></a>.
This is not an approach that most people can do (most people aren"t even
aware of <a href="https://fedoraproject.org/wiki/Bodhi">Bodhi</a>).  Looking back٫
it"s possible that I could have succeeded by using the set of command
line options from <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailure">my first entry</a>. I
didn"t think of trying it at the time٫ and anyway I knew that Bodhi
would work for sure and I had already wasted enough time (and
accumulated enough frustration on Fedora DNF"s broken modularity).</p>

<p>Allow me to emphasize that: <strong>as it currently stands٫ Fedora DNF modules
are broken</strong>. Module packages are not being kept up to date (even when
the module claims to be the "latest" version of a program) and the mere
existence of modules blocks you from getting up to date packages from
the main repository. If I could completely remove or turn off DNF
modules٫ I would٫ but as far as I know they"re deeply integrated into
DNF and aren"t optional in that way.</p>

<p>After I went through the Bodhi approach I hunted around and found
an assortment of files in <code>/etc/dnf/modules.d</code>٫ which appears to
be where DNF records modules you"ve done anything at all with. There
were files lingering here for every DNF module I"d ever had enabled٫
even if I"d done "<code>dnf module reset ..</code>" on them. I removed all of
these files٫ so maybe the next time there"s a new ripgrep update
I"ll get it without any hassles.</p>

<p>(I know٫ I have to update to Fedora 32 sometime٫ which is going to
re-enable various modules that I"ll have to clean out again. I
haven"t gotten around to it the way I usually do because all of my
usual processes for this have been thrown off by working from home
all of the time due to <a href="https://en.wikipedia.org/wiki/COVID-19_pandemic">ongoing world and local events</a>.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraUpdatesModuleFailureII?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/GrafanaOurIntervalSettings', 'How we choose our time intervals in our Grafana dashboards', '1596852370000',  14, '<div class="wikitext"><p>In a comment on <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">my entry on our Prometheus and Grafana setup</a>٫ trallnag asked a good question:</p>

<blockquote><p>Would you mind sharing your concrete approach to setting the time
intervals for functions like rate() and increase()?</p>
</blockquote>

<p>This is a good question٫ because trallnag goes on to cover why this
is an issue you may want to think about:</p>

<blockquote><p>I tend to switch between using $__interval٫ completely fixed
values like 5m or a Grafana interval variable with multiple
interval to choose from. None are perfect and all fail in certain
circumstances٫ ranging from missing spikes with $__interval to
under or oversampling with custom intervals.</p>
</blockquote>

<p>The very simple answer is that so far I"ve universally used
$__interval٫ which is <a href="http://docs.grafana.org/reference/templating/#the-interval-variable">Grafana"s templating variable for
"whatever the step is on this graph given the time scale you"re
currently covering"</a>.
Using $__interval means that your graph is (theoretically)
continuous but without oversampling; every moment in time is used
for one and only one graph point.</p>

<p>The more complete answer is that we use $__interval but often
tell Grafana that there is a minimum interval for the query that
is usually slightly larger than how often we generate the metric.
When you use <code>rate()</code>٫ <code>increase()</code>٫ and their kin٫ you need to
make sure that your interval always has at least two metric points٫
otherwise they give you no value and your graphs look funny. Since
we"re using variable intervals٫ we have to set the minimum interval.</p>

<p>In a few graphs I"ve experimented with combining <code>rate()</code> and <code>irate()</code>
with an <code>or</code> clause:</p>


<blockquote><pre style="white-space: pre-wrap;">
rate( ...[$__interval] ) or
   irate( ...[4m] )
</pre>
</blockquote>

<p>The idea here is that if the interval is too short to get two metric
points٫ the <code>rate()</code> will generate nothing and we fall through to
<code>irate()</code>٫ which will give us the rate across the two most recent
metric points (see <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusRateVsIrate"><code>rate()</code> versus <code>irate()</code></a>).
Unfortunately٫ this is both annoying to write (since you have to
repeat your metric condition) and inefficient (since Prometheus
will always evaluate both the <code>rate()</code> and the <code>irate()</code>)٫ so I"ve
mostly abandoned it.</p>

<p>The high level answer is that we use $__interval because I don"t
have a reason to make things more complicated. Our Grafana dashboards
are for overviews (even detailed overviews)٫ not narrow troubleshooting٫
and I feel that for this a continuous graph is generally the most
useful. It"s certainly the easiest to make work at both small and large
timescales (including ones like "the last week"). We"re also in the
position where we don"t care specifically about the rate of anything
over a fixed interval (eg٫ "error rate in the last 5 minute should be
under ...")٫ and probably don"t care about momentary spikes٫ especially
when we"re using a large time range with a dashboard.</p>

<p>(Over a small time range٫ a continuous graph of <code>rate()</code> will show you
all of the spikes and dips. Or you can go into Grafana"s "Explore" and
switch to <code>irate()</code> over a fixed٫ large enough interval.)</p>

<p>If we wanted to always see short spikes (or dips) even on dashboards
covering larger time ranges٫ we"d have to use the more complicated
approach I covered in <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusSubqueriesForSpikes">using Prometheus subqueries to look for spikes
in rates</a>. There"s no clever choice of
interval in Grafana that will get you out of this for all time ranges
and situations٫ and Prometheus currently has no way to find these spikes
or dips short of writing out the subquery. Going down this road also
requires figuring out if you care about spikes٫ dips٫ or both٫ and if
it"s both how to represent them on a dashboard graph without overloading
it (and yourself).</p>

<p>(Also٫ the metrics we generally graph with <code>rate()</code> are things that we
expect to periodically have short term spikes (often to saturation٫ for
things like CPU usage and network bandwidth). A dashboard calling out
that these spikes happened would likely be too noisy to be useful.)</p>

<p>PS: This issue starts exposing a broader issue of what your Grafana
dashboards are for٫ but that"s another entry.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/UbuntuOldPackageProblem', 'Our problem installing an old Ubuntu kernel set of packages', '1596772803000',  14, '<div class="wikitext"><p>On Twitter٫ <a href="https://twitter.com/thatcks/status/1291453564527824897">I said</a>:</p>

<blockquote><p>It has been "0" days since I"ve wound up hating Debian"s choice to
sign package metadata instead of packages (or perhaps "in addition to"
these days). Why? Because it makes it much more difficult to support
"install a package٫ satisfying dependencies from this directory of
debs".</p>
</blockquote>

<p>Naturally there is a story here.</p>

<p>We have some <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">Linux fileservers</a> running
Ubuntu٫ and we are very controlled about upgrading their kernel
versions (partly because of <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu1804OddKernelPanic">mysterious crashes</a>). We have a new kernel version that"s
proven on our test fileserver and our most recently build fileserver
(which is itself a story)٫ and we"re looking at upgrading the other
fileservers to that kernel. However٫ this kernel is not the most
recent Ubuntu kernel; it"s sufficiently old that it"s no longer in
the official Ubuntu package repositories.</p>

<p>We have our own local Ubuntu mirror٫ where we never delete packages٫
and it has all of the many linux-* packages and meta-packages
required. However٫ we can"t just do "<code>apt-get install
linux-generic=...</code>" and get all of those packages. Because these
older Linux kernels aren"t in the Ubuntu official package repositories٫
they"re not in the official repository index files. Because these
index files are signed٫ our mirror can"t just rebuild them to reflect
the full set of packages we have available. Although we have these
files available on our mirror٫ we can"t use them٫ at least not
easily.</p>

<p>Similarly٫ I suspect this fundamental assumption of signed index files
(or at least the existence of index files) is part of why I don"t think
any <code>dpkg</code> frontend has an option to just get packages and dependencies
from a directory you supply. You can "<code>dpkg -i *.deb</code>" for everything in
a directory٫ but that requires you to carefully curate the directory to
have absolutely everything required٫ and Ubuntu kernels come in a rather
large number of packages.</p>

<p>(If there is a command line frontend that supports this٫ I would like to
know about it. I don"t count dropping .debs into /var/cache/apt/archives
for apt٫ although I"ve read that it actually works.)</p>

<p>You don"t really have this problem on RPM based systems like
CentOS. Since all RPM packages themselves are signed٫ signed metadata
isn"t as important and tools like <code>yum</code> and <code>dnf</code> are generally happy to
work with a pool of RPMs in a directory.</p>

<p>(Note that <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/UnsignedMetadataExploits">unsigned repository metadata opens you up to some attacks</a>٫ so you definitely want to sign it if
possible. It"s also safe to generate your own local unsigned repository
metadata٫ since you generally trust yourself.)</p>

<p>(See also <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/UbuntuISOPackageUpdate">my wish to be able to easily update the packages on an
Ubuntu ISO image</a>٫ which also runs into
this issue.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/UbuntuOldPackageProblem?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/unix/MyOptionsConventions', 'My views on some conventions for Unix command line options', '1596684851000',  14, '<div class="wikitext"><p>Recently I read Chris Wellons" <a href="https://nullprogram.com/blog/2020/08/01/">Conventions for Command Line Options</a>٫ which reviews these
conventions. As it happens٫ I learned and have internalized a
somewhat different version of how these conventions should be and
how I expect programs to behave. I"m not going to mention things
where my expectations agree with Wellons" presentation of the
conventions٫ just where I differ.</p>

<p>On short options that accept an argument٫ Wellons says:</p>

<blockquote><p>This technique is used to create another category٫ <em>optional option
arguments</em>. The option’s argument can be optional [...]</p>
</blockquote>

<p>There are no optional option arguments; an option either always
takes an argument or it never does. This is how the traditional
<code>getopt(3)</code> behaves٫ at least as far as I remember٫ and appears to
be how <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=4.3BSD/usr/man/man3/getopt.3">the 4.3 BSD <code>getopt(3)</code> manpage</a>
documents it.</p>

<p>(It"s also how <a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/getopt.html">POSIX <code>getopt()</code></a>
is required to behave; see the discussion of how <code>optarg</code> is set.)</p>

<blockquote><p>Options can typically appear in any order — something parsers
often achieve via <em>permutation</em> — but non-options typically follow
options.</p>
</blockquote>

<p>Non-options always follow options. By extension٫ the first non-option
argument terminates scanning for options; any remaining "-..."
things become arguments. Again this is how the 4.3 BSD <code>getopt(3)</code>
is documented٫ and in fact that options and non-options can"t be
intermixed is mostly required by the <code>getopt(3)</code> API.</p>

<p>(How <code>getopt(3)</code> returns non-option arguments to you is that it
gives you the index of the first argument in <code>argv</code>. To support
intermixed options and non-options٫ it would have to permute the
order of entries in <code>argv</code> to move all options up to before all
non-options. In modern C definitions of <code>getopt(3)</code>٫ including <a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/getopt.html">the
POSIX one</a>٫ I
believe this is forbidden because <code>argv</code> is declared <code>const</code>.)</p>

<p>My strong cultural expectations for option handling only cover short
options; while I have opinions about how long options should act٫
they"re not as visceral as for short options. Just as with short options
and for much the same pragmatic reasons٫ I don"t believe in long options
with optional option arguments; long options should either always take
an argument or never do so. Behaving otherwise breaks my expectation
that long options are just the same as short options except longer
(and they can"t be grouped٫ and there"s that optional "=" thing for
arguments).</p>

<p>(This difference between my views and Chris Wellons" views points out
some general issues here٫ but that"s for another entry.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/MyOptionsConventions?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu2004MaybeMostlySkipping', 'We may wind up significantly delaying or mostly skipping Ubuntu 20.04', '1596603243000',  14, '<div class="wikitext"><p>Back at the start of April٫ I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu2004TimingIssues">how we might face some
issues with the timing of Ubuntu 20.04</a>٫ given
<a href="https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic">ongoing world and local events</a>٫
because we generally need to be in the office to deploy 20.04
machines and upgrade machines to 20.04. Back then٫ I optimistically
hoped for a return to normality and the office perhaps by July٫ and
in any case not lots and lots later. That is not the situation we"ve
wound up in. Instead٫ it seems most likely that we won"t be in the
office on regular basis until next spring at the earliest.</p>

<p>The highest priority machines to upgrade are our remaining Ubuntu
16.04 machines٫ which will be going out of support in April of next
year. Fortunately we don"t have very many of them compared to our
18.04 machines٫ so there is not a huge amount of work to do.
Unfortunately٫ most of our Exim based mail machines are 16.04 and
<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/EximTaintingPain">the 20.04 version of Exim is a significantly disruptive upgrade</a>٫ plus a number of the remaining machines
are delicate to upgrade (our Samba server٫ for example).</p>

<p>This opens up the issue of what Ubuntu version to upgrade these
16.04 machines to. Normally we"d upgrade them to Ubuntu 20.04٫ but
normally we"d already be running less critical machines on 20.04
and getting experience with it; this time they"d be among our first
20.04 machines. On the other side٫ we"re already running Ubuntu
18.04 in general and in some cases running the same services on
18.04 as we currently do on 16.04 (we have a couple of 18.04 Exim
machines٫ for example). This makes upgrading most or all of our
16.04 machines to 18.04 instead of 20.04 a reasonably attractive
proposition٫ especially for Exim based machines. We"d have to upgrade
them again in two years when 22.04 comes out and 18.04 starts going
out of support٫ but hopefully in two years the situation will be a
lot different.</p>

<p>(If we"re not back in the office in two years٫ it seems likely that
a fair number of things will have changed in our operations. And
in any case we"ll have a lot more experience with remote operation٫
and possibly hardware that better supports it.)</p>

<p>If we only have limited time in the office to work on machines٫
going out of our way to upgrade 18.04 machines to 20.04 seems like
a bad use of time٫ even if they"re machines that we normally try
to keep on the latest version of Ubuntu (such as our user login
servers). There will be new machines and there are some machines
where we want to rework them anyway for various reasons٫ and both
of these may sensibly wind up on 20.04٫ but otherwise I suspect
we"re going to leave more machines than usual at 18.04 until
we"re back in the office.</p>

<p>(New services can go on Ubuntu 20.04 without causing any extra problems٫
because we"d have to develop and explore them no matter what Ubuntu
version we used for them.)</p>

<p>If we get back in the office on an ongoing basis next summer٫ we could
start upgrading machines to Ubuntu 20.04 then٫ but Ubuntu 22.04 will
be only a year away. We may well decide to stick with 18.04 for most
machines and move them to 22.04 when it comes out.</p>

<p>Overall this seems likely to leave us with relatively modest use
of Ubuntu 20.04٫ although we"re definitely planning to use it for
some things. To the extent that we do use Ubuntu 20.04٫ our use is
going to be slow and delayed (and has already been delayed from our
usual timeline).</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu2004MaybeMostlySkipping?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/EximTaintingPain', 'Exim"s change to "taint" some Exim variables is going to cause us pain', '1596511189000',  14, '<div class="wikitext"><p><a href="https://www.exim.org/">Exim</a> is a very flexible mail system (aka
a MTA٫ Mail Transfer agent)٫ to the extent that in its raw state
<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/EximMailerKit">Exim is a mailer construction kit</a> more than a
mailer (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PostfixVsExim">if you want a simple mailer٫ consider Postfix</a>).
You can use this power for a lot of things٫ like <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/SimpleEximMailingLists">building simple
mailing lists</a>٫ where a mailing list is
created by putting a file of addresses in a specific directory (the
name of the file being the name of the mailing list).</p>

<p>This flexibility and power can create security issues٫ for example
when you directly use information from the incoming mail message
(information that"s under the control of the sender) to open a file
in a directory. If not carefully controlled٫ an attacker who knows
enough about your Exim configuration could possibly make you open
files you don"t intend to٫ like "../../../etc/passwd".</p>

<p>(This is a standard risk when using information that"s ultimately
provided by an attacker.)</p>

<p>For a long time٫ Exim left it up to whoever wrote your Exim
configuration file to worry about this. It was on them to do input
validation to make sure that /cs/lists/<a href="https://www.exim.org/exim-html-current/doc/html/spec_html/ch-string_expansions.html#SECTexpvar">$local_part</a>
would never have anything dangerous in it. Recently the Exim developers
decided that this was not sufficient and introduced the idea of
"tainted data"٫ which isn"t allowed to be used in various places
(especially٫ as part of a filename that will be opened or accessed).
Things that are under the control of a potential attacker٫ such as
the local part or the domain of an address٫ are tainted.</p>

<p>Unfortunately٫ there are a lot of places where it"s traditionally
been natural to use the Exim <code>$local_part</code> string variable as
part of file access٫ which is now tainted and forbidden. Specifically٫
we have various places in the Exim configurations for several mail
machines that use it. These uses are safe in our environment because
we only make use of <code>$local_part</code> after it"s been verified to
exist in our generated list of valid local addresses٫ but Exim isn"t
smart enough to know that they"re safe. Instead there are a collection
of ways to de-taint strings (<a href="https://www.mail-archive.com/exim-users@exim.org/msg54831.html">eg</a>٫
<a href="https://www.mail-archive.com/exim-users@exim.org/msg54904.html">also</a>٫
<a href="https://www.mail-archive.com/exim-users@exim.org/msg54739.html">also</a>٫
<a href="https://mox.sh/sysadmin/tainted-filename-errors-in-exim-4.94/">also</a>)٫
which from one perspective are a set of artificial hoops you now
have to jump through to pacify Exim. Some of these options for
de-tainting are backward compatible to versions of Exim before
tainting was introduced٫ but generally the compatible ways are more
awkward than the modern best ways.</p>

<p>People٫ us included٫ who upgrade to a version of Exim that includes
tainting will have to go through their Exim configuration files and
revise them to de-taint various things the configuration needs to
use. For us٫ this has to happen for any upgrade of our mail machines
to Ubuntu 20.04; 20.04 has a version of Exim with tainting٫ while the
Exim versions in 18.04 and 16.04 are pre-tainting ones. This means that
upgrading any of our mail machines to Ubuntu 20.04 needs configuration
changes٫ and some of these configuration changes may not be backward
compatible.  I think I can find all of the places where our Exim
configurations might use tainted data٫ but I"m not completely confident
of that; if I miss one٫ we"re going to experience Exim errors and
failures to properly process some email in production.</p>

<p>This is going to be a little bit painful. I"m not looking forward to
it٫ especially as it is yet another case of "do more work to wind up
in exactly the same place".</p>

<p>(There"s an obvious better way for the Exim people to have done this
transition to tainted data٫ but it would have been slower and meant that
Exim remained insecure by default for longer.)</p>

<p>PS: We"re at least better off than the people on CentOS using EPEL٫
who apparently got a "tainted data" version of Exim just dropped
on them as a regular package update (<a href="https://bugzilla.redhat.com/show_bug.cgi?id=1848283">cf</a>).</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/python/DjangoErrorPropagationIssue', 'The issue of how to propagate some errors in our Django web app', '1596428190000',  14, '<div class="wikitext"><p>Much of what <a href="https://utcc.utoronto.ca/~cks/space/blog/python/DjangoORMDesignPuzzleII">our Django application to handle (Unix) account
requests</a> does is only available to special
people such as professors٫ who can actually approve account requests
instead of just making them. Following our usual٫ we protect the
management section of the web app with <a href="https://utcc.utoronto.ca/~cks/space/blog/web/ApacheBasicAuthWhy">Apache HTTP Basic
Authentication</a>٫ where only people in
designated Unix groups (such as the "sponsors" group) have access.
However٫ the Django application also has a "users" table٫ and in
order to have access to the application you have to be in it (as
well as be in a Unix group that"s allowed access). Normally we
maintain these two things in sync; when we add someone to the
relevant Unix group٫ we also add them as a user (and set the type
of user they are٫ and set up other necessary data for people who
can sponsor accounts). But sometimes we overlook this extra step
so people wind up permitted by Apache but not in the "users" table.
If they actually try to use our web application٫ this causes it to
stop with an error.</p>

<p>(This "users" table is part of the application"s own set of tables
and models٫ not <a href="https://docs.djangoproject.com/en/3.0/topics/auth/default/">the normal Django authentication system"s User
table</a>.
Possibly I should have handled this differently so that it"s more
integrated with normal Django stuff٫ but when I started this web
application I was new to Django and keeping things completely
separate was much easier.)</p>

<p>Right now٫ a bunch of our views look like this at the start:</p>


<blockquote><pre style="white-space: pre-wrap;">
def approve(request):
  urec = get_user(request)
  if urec.is_staff():
    ...
  ...
</pre>
</blockquote>

<p>You"ll note that there"s no error handling. This is because
<code>get_user()</code> does the brute force simple thing (with some error
checks removed):</p>

<blockquote><pre style="white-space: pre-wrap;">
def get_user(request):
  user = request.META["REMOTE_USER"]
  try:
    return models.User.objects.get(login=user)
  except models.User.DoesNotExist:
    ... log a message ...
    raise django.http.Http404
</pre>
</blockquote>

<p>This is simple and reliable٫ but it has a downside٫ which is that
people who run into this mistake of ours get the same HTTP 404 error
page that they"d get if they were trying to go to a URL that genuinely
didn"t exist in our application. This is at best uninformative and
at worst confusing٫ and I"d like to do better. Unfortunately I"m
not sure what the best way to do it is.</p>

<p>My first attempt was to raise Django"s Http404 error with a specific
message string and then try to make our template for the application"s
404 error page check for that string and generate a different set of
messages. That failed٫ because as far as I can see either Django drops
the message string at some point in its processing or doesn"t pass it to
your custom template as a template variable.</p>

<p>I can see three alternate approaches٫ none of which I"m persuaded
by. The simple but unappealing option is to change <code>get_user()</code>
to return an error in this situation. This would require a boilerplate
change at every place it"s called to check the error and handle it
by generating a standard "we screwed up" response page٫ which makes
the code feel like Go instead of Python. But at least how things
worked would be obvious (and if I returned <code>None</code>٫ I could make
failures to handle this case relatively obvious).</p>

<p>The more complicated but less code approach is to raise a custom
error and wrap every function that calls <code>get_user()</code> with a
decorator that catches the error to generate and return the standard
explanation page. I would have to decorate every view function that
directly or indirectly calls <code>get_user()</code> (and remember to add
this if I added new functions)٫ and decorators are sort of advanced
Python magic that aren"t necessarily either clear or straightforward
for people to follow.</p>

<p>I suspect that the way I"m supposed to do this in Django is with
some form of middleware. If I kept to much of the current approach٫
I could do this with a middleware that just used
<a href="https://docs.djangoproject.com/en/3.0/topics/http/middleware/#process-exception"><code>process_exception()</code></a>٫
but that doesn"t seem the most idiomatic way. Since this is a common
processing step for anything protected behind HTTP Basic Authentication٫
it feels like the middleware should do the user lookup itself and
attach it to the request somehow٫ with the actual views not even
calling <code>get_user()</code>. But I don"t know how to attach arbitrary
data to Django"s request objects٫ and anyway that involves even
more Django magic than middleware that catches a custom exception
(and the magic is less clear٫ since the view functions would just
access data without any obvious reason for it to be there).</p>

<p>(I care about the amount of magic involved in any solution because
my co-workers aren"t particularly familiar with Django and even I
only touch the code every once in a while. Possibly this means I
should just use the explicit error checking version٫ even if it
makes me twitch.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/python/DjangoErrorPropagationIssue?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/TickersVersusSleeping', 'Getting my head around the choice between sleeping and "tickers"', '1596338681000',  14, '<div class="wikitext"><p>If you have a program that wants to do something periodically٫ say
once every ten seconds٫ the obvious and simplest way is to just
sleep for ten seconds after each time you do the thing. For example:</p>


<blockquote><pre style="white-space: pre-wrap;">
while True:
  collect_device_stats()
  publish_device_stats()
  time.sleep(10)
</pre>
</blockquote>

<p>Some languages and libraries also offer an API that I"ve seen called
a "ticker"; Go٫ for example٫ has <a href="https://golang.org/pkg/time/#Ticker"><code>time.Ticker</code></a>. A ticker signals or invokes
you somehow every time interval٫ such as every ten seconds. With
a ticker٫ you could write the above (in Go) as something like:</p>

<blockquote><pre style="white-space: pre-wrap;">
ticker := time.NewTicker(10*time.Second)
for {
  t := &lt;- ticker.C
  collect_device_stats(t)
  publish_device_stats(t)
}
</pre>
</blockquote>

<p>The big difference between the two is that <strong>a ticker is indifferent
to how long it took you to do your work</strong>. If collecting and
publishing device stats takes two seconds٫ the sleep approach means
that you will do this once every twelve seconds (two seconds for
the work followed by ten seconds of sleeping). The ticker approach
will collect and publish once every ten seconds٫ because it signals
you every ten seconds even if it took you two seconds to collect
and publish device stats.</p>

<p>While this may make tickers sound great٫ this behavior has potential
downsides. Which one you want depends partly on what your reasons are
for sleeping or delaying. In particular٫ if you"re sleeping to limit
the load your actions create٫ then a ticker may not be what you want٫
precisely because it"s indifferent to how long your work took. If your
work takes nine seconds and you sleep afterward for ten٫ you"re keeping
things less than 50% busy. If your work takes nine seconds and you have
a ten second ticker٫ you"re keeping things 90% busy; one second after
you finish your work the ticker will go off again and start it all over.</p>

<p>Tickers are great for things you want to happen every N seconds٫
even if they take a bunch of time (or a variable amount of time).
Sleeping is great for things you want to happen no more often than
once every N seconds. However٫ the difference between the two only
matters if what you"re doing does (or may) take an appreciable
amount of time compared to the tick (or sleep) interval; if it isn"t
going to٫ you might as well use whichever API is more idiomatic and
convenient٫ although tickers will probably make things more regular
and precise.</p>

<p>(This set of thoughts was sparked by poking around in <a href="https://gitlab.com/shouptech/cyberpower_exporter">some Python
code</a> that used
the <code>sleep()</code> idiom and then thinking about how it would probably
use a ticker in Go. (Well٫ in Go it would have a better API for what
it"s doing٫ but apart from that.))</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/TickersVersusSleeping?showcomments#comments">5 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/AlertsIncludeObvious', 'Putting some extra "obvious" information into our temperature alerts', '1596252195000',  14, '<div class="wikitext"><p>As part of <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">our Prometheus system</a>٫
we monitor the temperature in our machine rooms and wiring areas
and send out alerts if the temperature gets what we consider to be
"too high". The alert email generated for high temperatures is a
slight variation of our general alert message; it has some generic
framing٫ a specific message generated in Prometheus to describe the
situation٫ and a convenient link to the Grafana dashboard for that
temperature sensor.</p>

<p>We don"t fix the AC systems in our machine rooms ourselves; for the
most part٫ they"re considered part of the building"s infrastructure
and are managed by <a href="https://www.fs.utoronto.ca/">the university people who look after the
buildings</a>. When there"s an AC problem٫
part of what we do is to call those people to notify them of the
problem٫ and there"s a standard set of contacts. Probably this is
all pretty normal for handling machine room AC.</p>

<p>Last week٫ we got a temperature alert (fortunately for a transient
condition). As I started to deal with the issue٫ I once again had
to remind myself of who we called and what their phone number was.
We"ve had to deal with machine room AC issues often enough recently
that I could trace through the logic of who it was٫ but not so much
that I had the phone numbers memorized٫ so there was a certain
amount of going through <a href="https://www.fs.utoronto.ca/">university websites</a>
and scanning some old email from past incidents and so on. As I was
doing this٫ I slapped myself on the forehead٫ because <em>the AC contact
information should have been in the alert email</em>.</p>

<p>This contact information is obvious in one sense٫ and it doesn"t
vary from sensor to sensor and alert to alert in the way that the
specifics of the situation and even the link to the temperature
sensor"s dashboard do. But it"s completely predictable that we"re
going to want the information when we get a temperature alert٫ and
for all that it"s obvious and standard٫ I don"t generally deal with
AC issues often enough to actually remember all of it (my co-workers
may have better memories). This makes it a good thing to put in
temperature alerts٫ so once I"d looked up everything (and the
temperature had gone down again on its own)٫ I updated the alerts
to have a short footer that tells us who to call.</p>

<p>I"ve read various things on alerting that said alerts should ideally
include links to <a href="https://en.wikipedia.org/wiki/Runbook">runbooks</a>.
However I always interpreted it as "runbooks for specific alerts"
and the runbooks being for big things٫ not a little snippet of
general information for a whole class of alerts. Of course in
retrospect this is a bit silly.</p>

<p>My moral from this is that I should always try to think through
what people getting the alert will immediately want٫ then consider
putting it into the alert (either directly or perhaps on a web
page). This is worth thinking about even if it feels like standard
and obvious information٫ because what"s obvious now may not be
obvious when the alert goes off for the first time in six months.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/AlertsIncludeObvious?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/IPMIPortIsolatedNetwork', 'Putting IPMIs on a port isolated network to deal with shared network interfaces', '1596167069000',  14, '<div class="wikitext"><p>Yesterday I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/IPMISharedInterfaceProblem">the problem of "shared" IPMI network
interfaces</a>٫ which is that when the
host and the IPMI both have access to the same physical network
port٫ you"re exposed to a compromised host putting itself on your
<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/KVMOverIPSecurity">secure IPMI network</a> and compromising other
IPMIs (and then hosts) over it. There was a discussion about this
<a href="https://lobste.rs/s/5dknzm/problem_shared_ipmi_network_interfaces">on lobste.rs</a>٫
where <a href="https://lobste.rs/s/5dknzm/problem_shared_ipmi_network_interfaces#c_jaarka">lobste.rs user sn made an excellent suggestion</a>:</p>

<blockquote><p>The L2 feature you are looking for is called a protected port. This
should be available on any managed switch٫ but I’ll link to the
cisco documentation: <a href="https://www.cisco.com/en/US/docs/switches/lan/catalyst3850/software/release/3.2_0_se/multibook/configuration_guide/b_consolidated_config_guide_3850_chapter_011101.html">[link]</a></p>
</blockquote>

<p>("Protected ports" are what I know as <a href="https://en.wikipedia.org/wiki/Private_VLAN">port isolation</a>٫ where hosts connected
to these isolated ports can only talk to designated "uplink" ports٫
not with each other.)</p>

<p>This is a great suggestion and a great idea. Generally your IPMIs don"t
need to communicate with each other٫ they only need to communicate with
upstream machines that monitor them٫ collect syslog messages٫ connect
to them to manage servers٫ and so on. If you put all of the ports used
for IPMIs on a port isolated network (or on a port isolated subset of
switches)٫ a compromised server can"t bring up the host side of a shared
IPMI network interface to talk to the other IPMIs; it can only talk to
the upstream servers٫ which are hopefully a lot more secure than the
IPMIs (which often aren"t).</p>

<p>If we were to design a new IPMI network from scratch٫ I would at
least suggest this and see if my co-workers could spot a reason
it"s a bad idea in our setup. Our current IPMI network drifted into
that role (which is a story all in its own right)٫ so it"s <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/CSLabNetworkLayout">an
ordinary "sandbox" private network</a> without
port isolation; we probably don"t want to go back to revise it to
be port isolated٫ especially <a href="https://en.wikipedia.org/wiki/COVID-19_pandemic">these days</a>.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/IPMISharedInterfaceProblem', 'The problem of "shared" IPMI network interfaces', '1596077289000',  14, '<div class="wikitext"><p>These days٫ most of our servers have some form of <a href="https://en.wikipedia.org/wiki/Intelligent_Platform_Management_Interface">IPMI</a>
support٫ including a network connection for their IPMI and any
associated services (like KVM over IP). However٫ there is a significant
variation in how this network connection is provided in hardware٫ and
that causes some problems for actually using IPMI with less expensive
servers in environments where you care about security.</p>

<p>The best servers have a separate physical network port that"s only
accessible to and used by the IPMI. The physical machine may have
three network ports on the back٫ but the host machine (the server)
is only connected to two; the third is connected only to the IPMI.
This is typical for our Supermicro servers as used in٫ for example٫
<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">our Linux ZFS fileservers</a>.</p>

<p>On other servers of ours٫ there is no network port that"s connected only
to the IPMI; instead٫ at some level٫ the available network ports are
shared between the IPMI and the host system. Often٫ the BIOS and the
IPMI can operate these ports in two modes٫ "dedicated" and "shared". In
dedicated mode٫ the host server is entirely locked out of one port and
NIC٫ and only has one network interface available. In shared mode٫ the
host and the IPMI magically share a network port; traffic for the IPMI
goes to it (and is theoretically invisible to the host)٫ while traffic
for the host goes to it so that the port looks like a normal network
port.</p>

<p>(There are variations on this depending on the server.)</p>

<p>I don"t like this "shared" mode. The problem with it is simple;
<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/KVMOverIPSecurity">any IPMI system needs to be on a secure network</a>
and with a shared network port٫ the host has potential access to
your theoretically secure IPMI network٫ with all of the other crunchy
and probably dangerously insecure IPMIs on it. Sure٫ traffic to the
server"s own IPMI will be fenced away from the host٫ but other
traffic probably won"t be (partly because there are some people who
put their IPMIs on the same network as their hosts).</p>

<p>Even the existence of a shared mode is probably dangerous to the
security of your IPMI network٫ because on some systems this setting
can be changed through IPMI itself from the host (for example٫ see
the various "set-nic-mode" commands in FreeIPMI"s <a href="https://www.gnu.org/software/freeipmi/manpages/man8/ipmi-oem.8.html"><code>ipmi-oem</code></a>).
An attacker who"s compromised one such server can probably switch its
IPMI mode from dedicated to shared٫ then put the host on the IPMI
network and get to work.</p>

<p>Only a completely dedicated IPMI network port is safe from this٫
because only then does the host have no access to it no matter
what the BIOS and IPMI are set to or can be changed to. So I
wish everything had dedicated IPMI network ports٫ not ones that
are potentially accessible by the host. Sadly٫ extra network
ports and NICs cost more٫ so they don"t appear on most of the
inexpensive servers we tend to buy.</p>

<p>(Since the host can talk to the IPMI and IPMIs can have security
bugs٫ a fully dedicated IPMI network port doesn"t make you completely
safe. In theory the host can compromise the IPMI and get the IPMI
to proxy network traffic for it. In practice this is not something
that"s likely to be a risk for most people; it rises to the level
of <a href="https://www.usenix.org/system/files/1401_08-12_mickens.pdf">"the intelligence agency is going to intelligence agency"</a> [PDF٫
but it"s James Mickens٫ you should read it].)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSOurSparesSystemV', 'Our ZFS spares handling system for ZFS on Linux', '1595992624000',  14, '<div class="wikitext"><p>When we ran <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetup">Solaris fileservers</a>
and then <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetupII">OmniOS fileservers</a> we
ended up building our own system for handling replacing failed disks
with spares٫ which I wrote about years ago in <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemI">part 1</a>٫ <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemII">2</a>٫
<a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemIII">3</a>٫ and <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/OurSparesSystemIV">4</a>. When we migrated to our current
generation of <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">Linux based ZFS fileservers</a>٫
many of our local software for OmniOS migrated over almost completely
unchanged. This included (and includes) our ZFS spares system٫ which
remains mostly unchanged from the Solaris and OmniOS era (both in how
it operates and in the actual code involved).</p>

<p>The first important aspect of our spares system is that it is still
state driven٫ not event driven. Rather than trying to hook into
<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise">ZED</a> to catch and handle events٫ our spares driver
program operates by inspecting the state of all of our pools and
attempting to start any disk replacement that"s necessary (and
possible). We do use ZED to immediately run the spares driver in
response to both ZED vdev state change events (which can be a disk
failing) and pool resilvers finishing (because a resilver finishing
can let us start more disk replacements). We also run the spares
driver periodically from cron as a backup to ZED; even if ZED isn"t
running or misses events for some reason٫ we will eventually notice
problems.</p>

<p>Our Solaris and OmniOS fileservers used iSCSI٫ so we had to carefully
maintain a list of what iSCSI disks were potential spares for each
fileserver (a fileserver couldn"t necessarily use any iSCSI disk
visible to it). Since our Linux fileservers only have local disks٫
we could get rid of these lists; the spares driver can now use any
free disks it sees and its knowledge of available spares is always
up to date.</p>

<p>(As before٫ these "disks" are actually fixed size partitions on our
SSDs٫ with four partitions per SSD. We are so immersed in our world
that we habitually call these "disks" even though they aren"t.)</p>

<p>As in the iSCSI world٫ we don"t pick replacement disks randomly;
instead there is a preference system. Our fileservers have half
their disks on SATA and half on SAS٫ and our regular mirrored pairs
use the same partition from matching disks (so the first partition
on the first SATA disk is in a mirror vdev with the first partition
on the first SAS disk). Spare replacement tries to pick a replacement
disk partition on the same type of disk (SATA or SAS) as the dead
disk; if it can"t find one٫ it falls back to "any free partition"
(which can happen if we use up almost all of the available space
on a fileserver٫ which has already happened on one).</p>

<p>In the past٫ with HDs over iSCSI٫ we had to carefully limit the
number of resilvers that we did at once in order to not overwhelm
the system; our normal limit was replacing only one "disk" (a
partition) at a time. Our experience with local SSDs is that this
is no longer really a problem٫ so now we will replace up to four
failed partitions at once٫ which normally means that if a SSD fails
we immediately start resilvers for everything that was on it. This
has made a certain amount of old load limiting code in the spares
driver basically pointless٫ but we haven"t bothered to remove it.</p>

<p>For inspecting the state of ZFS pools٫ we continue to rely on <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemII">our
local C program to read out ZFS pool state</a>. It ported from OmniOS to ZFS on
Linux with almost no changes٫ although getting it to compile on
Ubuntu 18.04 was a bit of a pain because of how Ubuntu packages ZFS
there. It"s possible that ZFS on Linux now has official APIs that
would provide this information٫ but our existing code works now so
I haven"t had any interest in investigating the current state of
any official API for ZFS pool information.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/MicrowaveGoodUIBehavior', 'Digital microwaves show an example of good UI doing what you wanted', '1595908922000',  14, '<div class="wikitext"><p>Every so often٫ you encounter a bit of UI that does what you mean
to do so transparently that you don"t even notice that the UI is
breaking its own "how it works" rules to do so. You could say that
this is the complete reverse of <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/UnixAnnoyance">robot logic</a>٫
as seen yesterday in <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/PamPasswdErrorFail">trying to change your password on Linux</a>. Recently I realized that I"d run
into such a "do what I mean even though it doesn"t fit" UI in plain
ordinary microwaves٫ of all places.</p>

<p>Your typical microwave has a 0-9 digital pad for entering the cooking
time and its cook time is set in MM:SS. If you want one minute and
twenty seconds٫ you punch in "1 2 0" and the microwave displays "1:20"
and counts down from there. This is all perfectly logical and sensible٫
and forms a clear model of how the microwave behaves.</p>

<p>So what happens if you enter "9 0"? The microwave doesn"t reject
this as an error because you can"t have 90 seconds in the seconds
portion of a minutes and seconds time (you can have at most 59).
Instead it breaks the model and gives you 90 seconds of cook time.
This creates some inconsistencies٫ of course; if you enter "9 9"
you get 99 seconds٫ but if you enter "1 0 0"٫ you get 60 seconds
(because now it"s 1:00 cook time). On at least some microwaves
this still works even if you enter more than two digits; "1 9 9"
is 199 seconds٫ not an error (or one minute plus 99 seconds).</p>

<p>This behavior was so natural and so obviously correct and what I meant
that I spent years not realizing there was anything unusual about
it. Only one day as I was keying in "9 0" yet again and congratulating
myself on pressing one less digit than "1 3 0" did I stop to ask myself
why it even worked. And the answer is that the microwave makers went out
of their way to figure out what this input should mean so that it should
match user expectations٫ and make it so.</p>

<p>(I suspect or at least hope that there were user studies by some early
microwave company on what people expected to happen when they keyed in
various number sequences that weren"t proper MM:SS setups.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/MicrowaveGoodUIBehavior?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/PamPasswdErrorFail', 'Linux PAM leads to terrible error messages from things like <code>passwd</code>', '1595817652000',  14, '<div class="wikitext"><p>Here is a puzzle for you. Suppose that you"re trying to change your
password on a typical Linux system٫ as happens periodically (and as
we make new logins on our systems do immediately)٫ and you get the
following:</p>

<pre style="white-space: pre-wrap;">
; passwd
Changing password for user cks.
Current password: 
passwd: Authentication token manipulation error
</pre>

<p>What has gone wrong here? What should you do to fix it? Should you
try again٫ or instead send email to your system administrators to
get them to fix it?</p>

<p>Well٫ you don"t know٫ because <code>passwd</code> and <a href="https://en.wikipedia.org/wiki/Linux_PAM">Linux"s implementation
of PAM</a> have combined to
create a terrible error message through <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/UnixAnnoyance">robot logic</a>٫ where the error message is completely technically
logical and correct but useless in practice. <strong>The most likely cause
of this message is that you"ve mis-typed your current password</strong>٫
but there are other possible causes if things have gone wrong in
the depths of PAM. The only people who can start to disentangle
this is your system administrators٫ or in general anyone who can
look at PAM"s logs (normally in syslog)٫ because only there will
you find extremely valuable and much more precise messages like:</p>

<blockquote><pre style="white-space: pre-wrap;">
passwd[487312]: pam_unix(passwd:chauthtok): authentication failure; logname= uid=19 euid=0 tty=pts/6 ruser= rhost=  user=cks
</pre>
</blockquote>

<p>Even this isn"t really clear٫ but with sufficient painful experience
you can decode this to that the passwd command was verifying your
password through traditional Unix <code>/etc/shadow</code> encrypted passwords٫
and the password you typed didn"t "authenticate"٫ ie didn"t match
the encrypted password.</p>

<p>One of the reasons this is a terrible error message is because normal
people have essentially no chance at all of understanding it (as I can
assure you from our experience of supporting the people who use <a href="https://support.cs.toronto.edu/">our</a> systems). The best you can do is use
a wrapper script that puts a big explanatory message around the whole
thing٫ and even then people get confused.</p>

<p>(And if other things go wrong and the same message gets printed
out٫ you"re really confusing people; you"ve claimed that the problem
is that they"re using the wrong password٫ except they know that
they"re not. At least they"ll probably email the system administrators
at that point.)</p>

<p>I"m not sure if the PAM API provides any way for PAM modules such
as pam_unix to provide a more specific error message. This
particular error message is the generic PAM error string for
<code>PAM_AUTHTOK_ERR</code>٫ which is the equally generic PAM error code
that pam_unix is forced to return in this situation. You can
see the full list in the <a href="https://man7.org/linux/man-pages/man3/pam.3.html">pam(3)</a> manpage.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSOnLinuxModuleBackups', 'Keeping backup ZFS on Linux kernel modules around', '1595737330000',  14, '<div class="wikitext"><p>I"m a long term user of <a href="https://zfsonlinux.org/">ZFS on Linux</a>
and over pretty much all of the time I"ve used it٫ I"ve built it
from the latest development version. Generally this means I update
my ZoL build at the same time as <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/MyKernelUpdateSteps">I update my Fedora kernel</a>٫ since a ZoL update requires a kernel reboot
anyway. This is a little bit daring٫ of course٫ although the ZoL
development version has generally been quite solid (and this way I
get the latest features and improvements long before I otherwise
would).</p>

<p>One of the things I do to make it less alarming is that <strong>I always
keep backup copies of previous versions of ZFS on Linux</strong>٫ in the
form of copies of the RPMs I install and update. Naturally I keep
these backup copies in a non-ZFS filesystem٫ because I need to be
able to get at them even if the new version of ZFS isn"t working
(possibly just with the new kernel٫ possibly in general). I haven"t
needed these backup copies very often٫ but on the rare occasions
when I"ve had to revert٫ I was very glad that they were there.</p>

<p>(You don"t always run into immediate failures to bring ZFS up;
sometimes there are merely stability or other issues in a new
development change٫ and you want to roll back to a previous one.
In those cases it"s okay to have the previous versions on a ZFS
filesystem٫ because you can probably use ZFS enough to grab them.)</p>

<p>Not everyone uses development versions of ZFS on Linux٫ but I suggest
that you keep backup copies of older versions even if you only use
released ZoL versions. You never know when you may run into an issue
and be glad that you have options.</p>

<p>(That I keep backup copies of previous versions and want to have them
accessible outside of ZFS is one reason that I doubt I"ll ever use ZFS
on Linux on my root filesystem. System recovery is much easier in many
scenarios if ZFS isn"t required to at least boot the system٫ get it on
the network٫ or access the root filesystem from a live CD.)</p>

<p>One obvious requirement here is that you should never update ZFS
pool or filesystem features until you"re absolutely sure that you"ll
never want to revert to a ZoL version that"s too old to support those
features. This generally makes me quite conservative about updating pool
features; I want them to be in a ZoL release that"s been out long enough
to be considered fully stable.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSOnLinuxModuleBackups?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/web/FirefoxMyVariedWindows', 'My varied types of Firefox windows', '1595646281000',  14, '<div class="wikitext"><p>When I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/WindowManagerWants">what I want out of my window manager</a>٫ I mentioned that I have a plethora
of Firefox windows٫ generally iconified to <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/MyDesktopTour">my desktop</a>. This may sound like things are out of
control (and in a way they are)٫ but there is some method to my
madness. I actually have a number of different sorts of Firefox
windows.</p>

<p>In no particular order٫ I have Firefox windows for:</p>

<ul><li>things that I"m actively working on or using. These are the
windows that are most likely to be open٫ instead of iconified; I
tend to iconify them only if I"m running out of space.<p>
</li>
<li>things that I"m relatively actively reading. I"m one of those
people who gets distracted or just doesn"t want to read one thing
for too long (and sometimes I get interrupted)٫ so I tend to have
several things that I"m reading through at any given time.<p>
</li>
<li>things that I refresh and look at on a regular basis٫ either
temporarily or on a regular basis. Now that I"m writing this٫
I"ve realized that I should shift some of these to <a href="https://utcc.utoronto.ca/~cks/space/blog/web/BookmarksAlternative">my browser
start page</a>٫ because that"s part of what
it"s there for.<p>
</li>
<li>things that I"m holding around as references for other things I"m
doing. In theory these aren"t permanent; in practice٫ sometimes
the other thing falls down my priority list and its reference
windows wind up sitting around for a long time.<p>
A related category is web pages I"m going to mention in email٫ a
<a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a> entry٫ or something like that; here
I have the web page still around as a way of both keeping its URL
and reminding me of it.<p>
</li>
<li>things that I have aspirations of reading (or getting to) but
in practice I"m not going to get to any time soon٫ or perhaps
ever. This includes things that I"ve stopped being that interested
in (but I can"t admit it to myself and close the window)٫ and
things that I feel I should be interested in but٫ well٫ I"ll read
them later٫ someday.</li>
</ul>

<p>Sometimes these windows have multiple tabs; this is especially
common for references and things I"m actively working on.</p>

<p>I can"t pile all of these different types of windows together in
one clump (such as a bunch of tabs in a single window)٫ even sorted
by title٫ because I need to keep what type of window they are
straight. Right now I keep track of that primarily based on where each
window is iconified on my screen; some areas and some arrangements are
for one purpose٫ other arrangements and areas are for others.</p>

<p>Some of these (the "aspirations of reading" windows) could be dealt with
better if I had a good way to archive a window and list and track my
archived windows. This would probably take a Firefox addon; the ideal
one would archive the entire window state (what Firefox currently saves
in its session store٫ that"s used to restore all your windows when
restarting Firefox) and be able to completely return it to life٫ as if
I"d never closed that window and all its tabs.</p>

<p>(Right now I have a little local HTML file where I sort of do this by
hand. You can guess how often this happens٫ and it just has URLs and
titles (and the date when I put them there)٫ so it"s less convenient
than "just give me the window back".)</p>

<p>Some method to group and then de-group specific Firefox windows on
demand would also help٫ because then I could have a group for each
sort of thing and put windows into it that I"m not actively looking
at right now. I"m not sure if I"d want this to be the same "archive"
mechanism as for things I don"t expect to look at for some time٫
because that would probably put these other web pages a bit too far
out of my mind. That probably means it"s not something that should
be done by Firefox but instead by my window manager somehow.</p>

<p>(It"s quite possible that there are some good Firefox addons for dealing
with this sort of thing. I haven"t looked into the area very much٫ or
even really thought about what might be possible to do inside Firefox.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/FirefoxMyVariedWindows?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/solaris/OverlookingSyseventadm', 'Some thoughts on us overlooking Illumos"s <code>syseventadm</code>', '1595564462000',  14, '<div class="wikitext"><p>In a comment on <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise">my praise of ZFS on Linux"s ZFS event daemon</a>٫ <a href="https://sysmgr.org/blog">Joshua M. Clulow</a>
noted that Illumos (and thus OmniOS) has an equivalent in <a href="https://illumos.org/man/1M/syseventadm"><code>syseventadm</code></a>٫ which dates back to
Solaris. I hadn"t previously known about <code>syseventadm</code>٫ despite
having run <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetup">Solaris fileservers</a> and <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetupII">OmniOS
fileservers</a> for the better part of a decade٫
and that gives me some tangled feelings.</p>

<p>I definitely wish I"d known about <code>syseventadm</code> while we were still
using OmniOS (and even Solaris)٫ because it would probably have
simplified our life. Specifically٫ it probably would have simplified
the life of <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemI">our spares handling system</a> (<a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemII">2</a>٫ <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemIII">3</a>). At the least٫
running immediately when some sort of pool state change happened
would have sped up its reaction to devices failing (instead٫ it ran
every fifteen minutes or so from cron٫ creating a bit of time lag).</p>

<p>(On the whole it was probably good to be forced to make our spares
system be state based instead of event based. State based systems are
easier to make robust in the face of various sorts of issues٫ like
dropped events.)</p>

<p>At the same time٫ that we didn"t realize <code>syseventadm</code> existed is٫
in my mind٫ a sign of problems in how Illumos is organized and
documented (which is something it largely inherited from Solaris).
For instance٫ <code>syseventadm</code> is not cross referenced in any of the
Fault Manager related manpages ( <a href="https://illumos.org/man/1M/fmd"><code>fmd</code></a>٫
<a href="https://illumos.org/man/1M/fmdump"><code>fmdump</code></a>٫ <a href="https://illumos.org/man/1M/fmadm"><code>fmadm</code></a>٫ and so on). The fault management
system is the obvious entry point for a sysadmin exploring this
area on Illumos (<a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/FaultManagerIrritation">partly because it dumps out messages on you</a>)٫ so some sort of cross reference would
have led me to <code>syseventadm</code>. Nor does it come up much in discussions
on the Internet٫ although if I"d asked specifically back in the
days I might have had someone mention it to me.</p>

<p>(It got mentioned in <a href="https://serverfault.com/questions/538978/how-to-run-a-command-once-a-zfs-scrub-completes">this Serverfault question</a>٫
for example.)</p>

<p>A related issue is that in order to understand what you can do with
<code>syseventadm</code>٫ you have to read Illumos header files (<a href="https://serverfault.com/a/752050">cf</a>). This isn"t even mentioned in
the <a href="https://illumos.org/man/1M/syseventadm"><code>syseventadm</code></a> manpage٫ and the examples in the manpage are
all for custom events generated by things from a hypothetical third
party vendor <code>MYCO</code> instead of actual system events. Without a lot
of context٫ there are not many clues that ZFS events show up in
<code>syseventadm</code> in the first place for you to write a handler for
them. It also seems clear that writing handlers is going to involve
a lot of experimentation or reading the source to determine what
data you get and how it"s passed to you and so on.</p>

<p>(In general and speaking as a sysadmin٫ the documentation for
syseventadm doesn"t present itself as something that"s for end
sysadmins to use. If you have to read kernel headers to understand
even part of what you can do٫ this is aimed at <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/OperatorsAndSystemProgrammers">system programmers</a>.)</p>

<p>On the whole I"m not terribly surprised that we and apparently other
people missed the existence and usefulness of syseventadm٫ even if
clearly there was some knowledge of it in the Illumos community. That we
did miss it while ZFS on Linux"s equivalent practically shoved itself in
our face is an example of practical field usability (or lack thereof) in
action.</p>

<p>At this point interested parties are probably best off writing
articles about how to do things with syseventadm (especially ZFS
things)٫ and perhaps putting it in Illumos ZFS FAQs. Changing the
structure of the Illumos documentation or rewriting the manpages
probably has too little chance of good returns for the time invested;
for the most part٫ the system documentation for Illumos is what it
is.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/unix/MainKernelAndUserAPI', 'C"s <code>main()</code> is one of the places where Unix"s user and kernel APIs differ', '1595477926000',  14, '<div class="wikitext"><p>Modern Unixes often like to draw a legalistic distinction between
the API provided to user space by the kernel and the Unix API
provided to programs by the "standard library"٫ by which they mean
the standard C library. Some people٫ me included٫ don"t entirely
like this (I"ve written about <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/UnixAPIAndCRuntime">whether the C runtime and library
is a legitimate part of the Unix API</a>). However٫
regardless of what I might think about it٫ Unix has long had at
least one place where there was a real difference between the normal
API that everyone used and the API that the kernel actually
implemented. I"m talking about the traditional C style <code>main()</code>
entry point that starts your program.</p>

<p>Everyone knows the basic form of <code>main()</code>٫ with <code>argc</code> and <code>argv</code>;
you"re called with a count of the arguments and an array of strings.
In slightly more advanced usage there is a third argument٫ <code>envp</code>٫
an array of environment variables. This format is very old in Unix.
The two argument version of <code>main()</code> goes back to at least Research
Unix <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V4/man/man2/exec.2">V4"s <code>exec(2)</code></a>٫ while
the three argument form with environment variables seems to appear
in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/man/man2/exec.2">V7"s <code>exec(2)</code></a>.</p>

<p>However٫ this is not the actual <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/ProgramStartTwoApproaches">program entry point</a> that the V7 Unix kernel used when
starting your program٫ and the actual entry point had a somewhat
different API than <code>main()</code>. Conventionally٫ V7 C programs actually
started at an assembly symbol called <code>start</code>; the simplest version
of the assembly code involved is in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/src/libc/csu/crt0.s"><code>crt0.s</code></a>
and it clearly does a certain amount of setup work. There are other
versions of this startup in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/src/libc/csu">/usr/src/libc/csu</a> that
do various amounts of more work٫ such as arranging to profile your
program.</p>

<p>(Research Unix V6 also had a <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V6/usr/source/s4/crt0.s"><code>crt0.s</code></a>٫
but it"s rather different; I think there are no loops٫ for example.
If I understood PDP-11 assembly language I might have a better idea of
what it was actually doing.)</p>

<p>In V7٫ the differences between the user API for <code>main()</code> and the
kernel API are not huge. In current Unixes٫ there"s often rather
more going on٫ especially once you include dynamic loaders and
things like the <a href="https://lwn.net/Articles/519085/">"auxiliary vector"</a>
present in some Unixes. I suspect that the simplest version of a
modern one to look at is <a href="https://musl.libc.org/">musl libc</a> for
Linux٫ where <a href="https://git.musl-libc.org/cgit/musl/tree/crt/crt1.c">crt1.c</a>
and <a href="https://git.musl-libc.org/cgit/musl/tree/src/env/__libc_start_main.c">the main libc bootstrap functions</a> are
relatively straightforward.</p>

<p>(Some of the code is because the C runtime environment needs to be
set up (and yes٫ modern C has a runtime)٫ but a certain amount of
it is converting between how the kernel involves programs and how
<code>main()</code> wants to be invoked.  For example٫ notice how musl libc"s
main start function isn"t called with <code>argc</code> as an explicit argument;
instead it retrieves <code>argc</code> from memory.)</p>

<h3>Sidebar: The interesting V7 trick with data address 0</h3>

<p>At the end of every version of V7"s crt0.s is a little bit that
initially puzzled me:</p>


<blockquote><pre style="white-space: pre-wrap;">
.data
   .=.+2   / loc 0 for I/D; null ptr points here.
</pre>
</blockquote>

<p>What this is doing is that it"s reserving two bytes of space at the
start of the data section. V7 Unix ran on PDP-11"s that supported
<a href="https://gunkies.org/wiki/PDP-11_Memory_Management">split instruction and data address space</a>٫ so the data
section starts at (data) address 0. Reserving two bytes at the start
insures that no variable or other thing in the data section can be
located at address 0 and so C NULL is always distinct from valid
pointers.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/MainKernelAndUserAPI?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/tech/ProgramStartTwoApproaches', 'Contrasting the two common approaches to where programs start running', '1595389001000',  14, '<div class="wikitext"><p>When a program (in a broad sense) is executed٫ it must start running
somewhere. There are two common approaches for choosing what code is
the first code executed٫ each with different tradeoffs that make some
languages and system environments pick one over the other.</p>

<p>The simplest approach is to say that the first code in the program
starts running. This is what Python٫ Perl٫ many versions of BASIC٫
and shell scripts all do; execution starts from the top of your
file and marches down. This is also something that"s done at the
machine code level; a simple execution environment might load your
code into memory (often at a fixed address) and then simply transfer
control to the start of that block of memory. This is٫ for example٫
how PC BIOSes load and execute the Master Boot Record (MBR) from
hard drives; the first 512 byte sectors is loaded into memory and
they jump to it.</p>

<p>The other common approach is to say that execution starts at a user
defined entry point٫ at some address or identifier that is set by
the program. Sometimes this entry point is specified by you as you
build or execute the program; sometimes it is set by convention٫
such as C"s <code>main()</code>. Your <code>main()</code> function doesn"t have to be at
the start of your program"s code or at any specific address in
memory; the system will arrange to find it and begin execution
there (at least at a conceptual level٫ with some handwaving). This
approach is common in compiled languages٫ especially ones that
support building a single entity from multiple source files.</p>

<p>The tradeoff of the "start at the start" approach is that you have
to care about the order of your code٫ both for code within a file
and also the order of files (if your program is made up of multiple
files). For "start at the start"٫ layout matters. Many "start at
the start" languages are most naturally used with programs that
live in a single file; among other things٫ this means that you don"t
need to worry about the order of multiple files. This is commonly
the case for interpreted languages٫ so "start at the start" is
common for them.</p>

<p>(It"s not universal in interpreted languages٫ even on Unix. For
example٫ awk is only sometimes ordered; you can put a "<code>BEGIN</code>"
rule anywhere٫ but code order matters if multiple rules act on a
single line.)</p>

<p>The tradeoff of the entry point approach is that you have to define
the entry point٫ either by hand or through convention. If defined
by hand (at build or run time)٫ you have to do some extra work and
you have an extra thing to keep track of; if defined by convention٫
it"s a bit harder to add some code to run at the start of your
program (you have to add it to the front of the code at the defined
entry point٫ respecting any ordering requirements٫ and can"t just
add a block at the very start of the file). The advantage of the
entry point approach is that the order of code and files no longer
matters.</p>

<p>(Also٫ conventions are arbitrary choices and are essentially magic.
The reason your C programs start at <code>main()</code> is "because"٫ which
is unsatisfying to some people and something you just have to
memorize.)</p>

<p>It"s common for compiled languages to support building programs
from multiple source files that have no specific order among
themselves٫ because this is the easiest approach for humans to deal
with; we can name our source files whatever makes sense and don"t
have to maintain them in some careful order. This pretty much forces
the entry point model. Supporting the "start at the start" model
would require people to maintain an order that the source files
were specified in during compilation٫ and not just use "cc -o barney
*.o" or the equivalent.</p>

<p>(This entry was sparked by <a href="https://news.ycombinator.com/item?id=23904313">the Hacker News discussion</a> of <a href="https://utcc.utoronto.ca/~cks/space/blog/python/WhyNoMainFunction">my exploration
of why Python doesn"t require a "main" function</a>. As mentioned٫ Python is a "start
at the start" language and it has an execution model to support
that.)</p>

<p>PS: On modern Unixes that use ELF format executables٫ you can see
the entry address of executables with "<code>readelf -h &lt;program></code>" and
then looking at the "Entry point address". Programs generally have
a wide variety of entry point addresses.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/ProgramStartTwoApproaches?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/python/WhyNoMainFunction', 'An exploration of why Python doesn"t require a "main" function', '1595302075000',  14, '<div class="wikitext"><p>Many languages start running your program by calling a function of
yours that must have a specific name. In C (and many C derived
languages)٫ this is just called <code>main()</code>; in Go٫ it"s <code>main.main()</code>
(the <code>main()</code> function in the <code>main</code> package). Python famously
doesn"t require any such function٫ and won"t automatically call a
function called <code>main()</code> even if you create it. Recently I read
<a href="https://towardsdatascience.com/why-doesnt-python-have-a-main-function-3afe6a8d093">Why doesn’t Python have a main function?</a>
(<a href="https://lobste.rs/s/fumh1r/why_doesn_t_python_have_main_function">via</a>)٫
which puts forward one discussion for why this is so. However٫ I have
a somewhat different way of explaining this situation.</p>

<p>The core reason that Python doesn"t require a <code>main()</code> function is a
combination of its execution model (specifically for what happens when
you import something) and that under normal circumstances you start
Python programs by (implicitly) importing a single file of Python code.
So let"s look at each of these parts.</p>

<p>In many languages things like functions٫ classes٫ and so on are
created (defined) by the interpreter or compiler as it parses the
source file. In Python٫ this is not quite the case; instead٫ <a href="https://utcc.utoronto.ca/~cks/space/blog/python/FunctionDefinitionOrder"><code>def</code>
and <code>class</code> are executable statements</a>٫
and they define classes and functions when they execute (among other
things٫ this is part of <a href="https://utcc.utoronto.ca/~cks/space/blog/python/WhyMetaclassesWork">why metaclasses work</a>).
When Python imports something٫ it simply executes everything in the
file (or the import more generally). When what"s executed is <code>def</code>
and <code>class</code> statements٫ you get functions and classes. When what"s
executed is regular code٫ you get more complicated things happening٫
including conditional imports or calling functions on the fly under
the right conditions. Or you can write an entire program that just
runs inline٫ as the file is imported.</p>

<p>(This has some interesting consequences٫ including <a href="https://utcc.utoronto.ca/~cks/space/blog/python/ReloadRealBehavior">what reloading
a Python module really does</a>.)</p>

<p>However٫ Python is not quite as unique here as it might look. Many
languages have some facility to run arbitrary code early on as the
program is "loading"٫ before the program starts normal execution
(Go has <code>init()</code> functions٫ for example). Where Python is different
from these languages is that Python normally starts a program by
loading and executing a specific single file. Because Python is
only executing a single file٫ it"s unambiguous what code is run in
what order and it"s straightforward for the code in that file to
control what happens. In a sense٫ rather than picking an arbitrarily
named function for where execution (nominally) starts٫ Python is
able to sneakily pick an arbitrarily named file by having you provide
it.</p>

<p>(Compiled languages traditionally have a model where code from a bunch
of separate files is all sort of piled up together. In Python٫ you can"t
really aggregate multiple files together into a shared namespace this
way; one way or another٫ you have to <code>import</code> them and everything starts
from some initial file.)</p>

<p>Where this nice model breaks down and needs a workaround is if you
run a package with "<code>python -m ...</code>"٫ where Python doesn"t really
have a single file that you"re executing (or it"d have to make
<code>__init__.py</code> serve double duty). As covered in the official
documentation"s <a href="https://docs.python.org/3/library/__main__.html"><code>__main__</code> — Top-level script environment</a> (<a href="https://lobste.rs/s/fumh1r/why_doesn_t_python_have_main_function#c_jmer2v">via</a>)٫
Python adopts the arbitrary convention of loading a <code>__main__.py</code>
file from your package and declaring it more or less the point where
execution starts.</p>

<p>(Under at least some situations٫ your package"s <code>__init__.py</code> may
also be executed.)</p>

<p>PS: contrary to <a href="https://towardsdatascience.com/why-doesnt-python-have-a-main-function-3afe6a8d093">the original article"s views</a>٫
<strong>I strongly suggest that you have a <code>main()</code> function</strong>٫ because
<a href="https://utcc.utoronto.ca/~cks/space/blog/python/ImportableMain">there are significant benefits to keeping your program importable</a>.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/python/WhyNoMainFunction?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise', 'In praise of ZFS On Linux"s ZED "ZFS Event Daemon"', '1595210334000',  14, '<div class="wikitext"><p>I"ve written before (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSameness">here</a>) about how <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">our
current Linux ZFS fileservers</a> work much
like <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetupII">our old OmniOS fileservers</a>.
However٫ not everything is quite the same between ZFS on Linux and
traditional Solaris/OmniOS ZFS. One of the most welcome differences
for us is <a href="https://zfsonlinux.org/manpages/0.8.4/man8/zed.8.html">ZED</a>٫
the ZFS Event Daemon. What ZED does that is so great is that it provides
a very simple way to take action when <a href="https://zfsonlinux.org/manpages/0.8.4/man5/zfs-events.5.html">ZFS events</a> happen.</p>

<p>When a ZFS event happens٫ ZED looks through a directory (generally
<code>/etc/zfs/zed.d</code>) to find scripts (or programs) that should be run
in response to the event. Each script is run with a bunch of
environment variables set to describe what"s going on٫ and it can
use those environment variables to figure out what the event is.
ZED decides what things to run based on their names; generally you
wind up with script names like <code>all-cslab.sh</code> (which is run on
all events) and <code>resilver_finish-cslab.sh</code> (which is run when a
resilver finishes).</p>

<p>Because these are just a collection of individual files٫ you"re
free to add your own without colliding with or having to alter the
standard "ZEDLETs" provided by ZFS on Linux. Your additions can do
anything you want them to٫ ranging from the simple to the complex.
For instance٫ our simplest ZEDLET simply syslogs all of the ZED
environment variables:</p>


<blockquote><pre style="white-space: pre-wrap;">
PATH=/usr/bin:/usr/sbin:/bin:/sbin:$PATH
export PATH
if [ "$ZEVENT_SUBCLASS" = "history_event" ]; then
        exit 0
fi
unset ZEVENT_TIME
unset ZEVENT_TIME_STRING
printenv | fgrep "ZEVENT_" | sort | fmt -999 |
    logger -p daemon.info -t "cslab-zevents"
exit 0
</pre>
</blockquote>

<p>(There"s a standard "all-syslog.sh" ZEDLET٫ but it doesn"t syslog
all of the information in the zevents. Capturing all of the information
is especially useful if you want to write additional ZEDLETs and
aren"t quite sure what they should look for or what environment
variables have useful information.)</p>

<p>It can take a bit of time and experimentation to sort out what ZFS
events are generated (and with what information available) in
response to various things happening to adn in your ZFS pools. But
once you have figured it out٫ ZED gives you a way to trigger and
drive all sorts of system management activities. These can be active
(like taking action if devices fail) or passive (like adding markers
in your metrics system or performance dashboards for when ZFS scrubs
or resilvers start and end٫ so you can correlate this with other
things happening).</p>

<p>Coming from Solaris and OmniOS٫ where there was no such simple
system for reacting to things happening in your ZFS pools٫ ZED was
a breath of fresh air for us. More than anything else٫ it feels
like how ZFS events should have been handled from the start٫ so
that system administrators could flexibly meet their own local needs
rather than having to accept whatever the Solaris Fault Management
system wanted to give them.</p>

<p>PS: Because ZFS on Linux is now OpenZFS٫ I believe that ZED will
probably eventually show up in FreeBSD (if it isn"t already there).
Perhaps it will even some day be ported back to Illumos.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoBuildUsingNewAPIs', 'Using Go build directives to optionally use new APIs in the standard library', '1595130013000',  14, '<div class="wikitext"><p>I mentioned recently that new APIs in the Go standard library were
relatively easy to optionally support٫ because such new APIs only
appear in new Go releases and you can conditionally build files
based on the Go release that"s building your program. But that"s a
pretty abstract description٫ so let"s make it concrete.</p>

<p>One of the long time limitations of the <a href="https://golang.org/pkg/crypto/tls/"><code>crypto/tls</code></a> package was that it only gave
you numbers for <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SSLCipherNames">TLS cipher suites</a>٫ not
any sort of names٫ and for logging and reporting things to users
you often wanted a name. Go"s lack of names for its cipher suite
numbers left you to roll your own conversion٫ generally with <a href="https://github.com/siebenmann/call/blob/master/tlsnames.go">a
big table of mappings</a>٫ as I
do (or did) in my <a href="https://github.com/siebenmann/call"><code>call</code></a>
program.  In Go 1.14٫ the Go authors fixed this by adding
<a href="https://golang.org/pkg/crypto/tls/#CipherSuiteName"><code>tls.CipherSuiteName()</code></a>. If I was
content to have the latest version of <a href="https://github.com/siebenmann/call"><code>call</code></a> only build on Go
1.14 or later٫ I could simply convert it to directly using
<a href="https://golang.org/pkg/crypto/tls/#CipherSuiteName"><code>tls.CipherSuiteName()</code></a> in place of my current hand done solution.
However٫ for various reasons I would like to keep <a href="https://github.com/siebenmann/call"><code>call</code></a> building
on previous Go versions as well٫ which means that I need to use my old
solution if the new API isn"t available.</p>

<p>The first step is to pull out the small function that needs to
access the API into a separate file٫ or create a function to do
this if you don"t have one already. In my case I might as well call
my (new) function <code>cipherSuiteName()</code>. Then we create two versions
of this function in two files٫ let"s call them <code>ciphername.go</code> and
<code>ciphername_old.go</code>. The second file has the current implementation٫
for older versions of Go٫ while the first version has the new
implementation that calls <code>tls.CipherSuiteName()</code>.</p>

<p>The first file can very simple if all you want to do is directly
call the new API and accept its result. It needs a Go build directive
to only build on Go 1.14 and later٫ and can look like this:</p>

<blockquote><pre>
// There must be a blank line between the
// build directive and "package main".
//
// +build go1.14

package main

import "crypto/tls"

func cipherSuiteName(id uint16) string {
    return tls.CipherSuiteName(id)
}
</pre>
</blockquote>

<p>The second file will have a more complicated implementation٫ which
I"m leaving out here٫ and a Go build directive to not build on Go
1.14 (and later):</p>

<blockquote><pre>
// For pre 1.14 Go versions without
// tls.CipherSuiteName().
//
// +build !go1.14

package main

import "fmt"

func cipherSuiteName(id uint16) string {
   ....
}
</pre>
</blockquote>

<p>My view is that you should use the longer file name for the old
implementation٫ because in the long run you"re probably going to
delete it (when you stop supporting old Go versions). Depending
on what your function in <code>ciphername.go</code> does٫ you might want to
keep it or simply switch over to a direct call to
<a href="https://golang.org/pkg/crypto/tls/#CipherSuiteName"><code>tls.CipherSuiteName()</code></a>.</p>

<p>Useful references for Go build directives are <a href="https://golang.org/pkg/go/build/">the go/build package
documentation</a> and Dave Cheney"s
<a href="https://dave.cheney.net/2013/10/12/how-to-use-conditional-compilation-with-the-go-build-tool">How to use conditional compilation with the go build tool</a>.</p>

<p>(This is the kind of entry that I write partly for my later use٫
because I"m sure I"m going to want to do this for other APIs in the
future.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ToolsNotAlwaysSilent', 'Not all sysadmin tools should be silent by default', '1595037614000',  14, '<div class="wikitext"><p>As a long term Unix person٫ I have wound up with a reflexive
assumption that all of the programs and tools I write should be
silent by default. This is the traditional Unix approach; Unix
programs are supposed to be silent if all goes well and only print
things if asked to or if something goes wrong٫ for good reasons.
However٫ lately I"ve began thinking that this is not necessarily
always correct and that under some circumstances my programs and
tools should be somewhat verbose by default (with an option to
make them Unix style silent).</p>

<p>A certain amount of the tools I write are normally run through
automation (such as crontabs and scripts)٫ where they can be supplied
with whatever command line options we want٫ and they may or may not do
something when run depending on the state of the system (or what they
perceive that to be). If I"m running such a program interactively٫
it"s generally an exceptional situation and I want and expect it to do
something. If the program follows the Unix philosophy and is silent both
when there is no work to be done and when there"s work to do but it goes
well٫ I"m at a loss for which one actually happened.</p>

<p>For this sort of program٫ I"ve come to believe that some verbosity
by default is more helpful in practice. When I run the program
interactively with no command line options٫ it will actually tell me
what it did (or didn"t do) and I won"t be left wondering. When we run it
through automation٫ we can give it the command line option that makes
it more silent٫ so we don"t get a barrage of emails from crontab or the
like.</p>

<p>All of that sounds abstract٫ so let me make it concrete. One part
of <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurSparesSystemI">our ZFS spares system</a> is a
program called "<code>sanspares</code>". The primary job of <code>sanspares</code> is to
either actually perform sparing or report on what sparing it would
like to do٫ but it can run into various reasons it might not actually
do any sparing despite wanting to. Right now٫ sanspares is a silent
by default program٫ so if I run it interactively and it produces
no output it could be for one of several reasons. If I"m checking
what sanspares thinks about the health of a fileserver٫ the different
reasons for not doing anything matter and I would like to know which
one it was. I actually recently had to run <code>sanspares</code> interactively٫
and I had to do a bunch of fiddling with "<code>-vv</code>" flags until I was
confident that I understood why it was doing what it was doing.</p>

<p>(Silence is especially not golden if there"s a possibility that your
program is actually broken. This was part of why I was running sanspares
interactively٫ as I needed to fix an issue we"d found with it recently as
well as understand the health of the fileserver.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ToolsNotAlwaysSilent?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/spam/ExesInEverything', 'Malware spammers put .exe Windows executables in everything', '1594950703000',  14, '<div class="wikitext"><p>Recently٫ for <a href="https://twitter.com/thatcks/status/1276163223960551427">reasons beyond the scope of this entry</a>٫ I"ve been
expanding <a href="https://github.com/siebenmann/exim-attachment-logger">our system for recording email attachment type information</a> to be able
to look inside more archive formats to get the file extensions of
files inside them. The most significant format I wanted to be able
to peer inside was <a href="https://en.wikipedia.org/wiki/7z">7zip archives</a>٫
because 7zip archives are one of the big areas where <a href="https://utcc.utoronto.ca/~cks/space/blog/spam/MalwareMatchingDifference">ClamAV differs
from our current commercial solution</a>
by recognizing fewer things٫ but I added support for ISO 9660 images
and CAB files while I was there.</p>

<p>In completely unsurprising news٫ once I had this interior file extension
logging working٫ it started lighting up with 7zip archives٫ ISO 9660
images٫ and even a CAB archive here and there that all contained <code>.exe</code>
files٫ generally with nothing else. This matches malware behavior I"ve
seen before for <a href="https://utcc.utoronto.ca/~cks/space/blog/spam/MalwareBeingClear">7zip attachments</a> and <a href="https://utcc.utoronto.ca/~cks/space/blog/spam/SpamCapturingCanBeUseful">ISO images</a>٫ but it"s always useful to have this stuff
confirmed (especially since malware behavior changes over time).</p>

<p>(We"re already rejecting email that contains .cab files or ISO
images as attachments٫ but now I can have more confidence that these
truly are bad and we can make more fine grained filtering decisions
if we need to. Since we now can٫ we"re rejecting email with 7zip
archives that have .exes in them.)</p>

<p>My assumption is that malware spammers are putting .exes in all
sorts of archive formats in an attempt to shield them from content
scanners. Some of this will be for content scanners that can"t look
inside the archive format at all٫ and probably some is for things
where a different archive format messes up simple signature recognition
or executable scanning. I can"t say that this is a silly idea٫
because until recently this content smuggling mostly worked against
us.</p>

<p>It is somewhat amusing to get confirmation that all of those very
bad looking things really are bad٫ such as the people who put several
extensions on their filenames:</p>

<blockquote><p>attachment application/x-7z-compressed; MIME file ext: .pdf.z; 7zip exts: .exe</p>
</blockquote>

<p>Of course٫ in the grand traditional of malware٫ sometimes the extension
is sort of a lie:</p>

<blockquote><p>attachment application/octet-stream; MIME file ext: .pdf.z; file magic: application/x-rar; rar exts: .exe</p>
</blockquote>

<p>Perhaps it"s simpler in the software to just use a fixed set of extensions
regardless of what archive type you"re packing it up as. (We have a number
of these .pdf.z RAR archives logged recently.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/spam/CleverURLObfuscation', 'A piece of phish spam with some clever URL obfuscation', '1594867187000',  14, '<div class="wikitext"><p>We were the target of a phish spam run today. In many respects it
was a standard modern phish; it was specifically targeted to us٫
with a message and claimed sender tuned to here٫ it was in HTML٫
and the inducement to click was a claim of "go here to retrieve a
voicemail message". However٫ it had one interesting trick that I
haven"t seen before٫ and that was how it obfuscated its target URL.</p>

<p>The first level of obfuscation was that the target in the &lt;a
href="..."> was entirely encoded in HTML hex entities٫ which probably
only stops very basic spam recognizer engines (and serves as a big
warning sign for others). However٫ even when decoded the direct
URL came out to be "/blah/?of=&lt;email address>"٫ with no host in
evidence. At first I stared at this in puzzlement٫ and then the
penny dropped and I looked at the full HTML. Up at the top was
a little thing:</p>

<blockquote><p>&lt;html> &lt;base href="&amp;#x68;&amp;#x74; &amp;#x74;&amp;#x70; &amp;#x73;&amp;#x3A; &amp;#x5C;&amp;#x2F;[...]</p>
</blockquote>

<p>(For a bit of extra obfuscation٫ that decodes to "https:\/". I"ve
removed the hostname٫ and added strategic spaces between some hex
entities so that this entry doesn"t get an extra-wide line.)</p>

<p>The phish spammers had split their URL in two by using <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/base">a base URL
element</a>.
The base URL element had the hostname (and the https://٫ sort of);
the &lt;a href> had the path on the host. Given this٫ it seems likely
that a decent number of anti-spam engines that parse HTML don"t
handle it to the extent of base URL elements (and anything that
just does basic text matching is out in the cold).</p>

<p>(I have a personal little program that extracts URLs from email
messages for my own uses. It didn"t understand the base URL element٫
but I"m not sure I should bother fixing that.)</p>

<p>I expect that IMAP mail clients properly reconstruct the full URL
as part of properly rendering modern HTML٫ although I haven"t tested
that. I don"t know if web based things like GMail do٫ although it"s
possible that document base URLs are used frequently enough in real
HTML email that they have to.</p>

<p>(The phish spammer targeting us may have assumed that anyone using
GMail or the like was a lost cause anyway٫ and have aimed at people
using desktop or mobile IMAP clients.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/python/ArgparseAbbreviatedOptions', 'Today I learned that Python"s argparse module allows you to abbreviate long command line options', '1594782494000',  14, '<div class="wikitext"><p><a href="https://docs.python.org/3/library/argparse.html">Argparse</a> is the
standard Python library for Unix style command line argument handling;
I use it in all of my Python programs these days.  As part of this
it supports the now standard long options٫ so you can have options
like "<code>--dead-disks</code>" instead of just "<code>-D</code>" (there are only so
many single characters to go around٫ and they can be hard to
remember). Today I learned that <a href="https://docs.python.org/3/library/argparse.html">argparse</a> accepts abbreviations
for these long options٫ provided that they"re unambiguous. If you
have a long option "<code>--dead-disks</code>" and no other long option that
starts with "d"٫ argparse will accept all of "--dead-disk"٫ "--dead"٫
and even "--d" as meaning "--dead-disks".</p>

<p>This is clearly documented in the argparse documentation if you
bother to read it all (I never did)٫ in <a href="https://docs.python.org/3/library/argparse.html#prefix-matching">Argument abbreviations
(prefix matching)</a>. You
can turn it off when constructing your <a href="https://docs.python.org/3/library/argparse.html#argparse.ArgumentParser">ArgumentParser</a>
by setting the <a href="https://docs.python.org/3/library/argparse.html#allow-abbrev"><code>allow_abbrev</code></a>
keyword argument to "<code>false</code>". Unfortunately I don"t think there"s
anything visible in a program"s --help that will tell you whether
or not it accepts abbreviated options; you have to either read
the Python code or just try it with something harmless.</p>

<p>(It appears that <a href="https://docs.python.org/3/library/optparse.html">optparse</a>٫ argparse"s
predecessor٫ always allowed abbreviations٫ with no way to turn it
off I"m basing this on a little mention of abbreviated long options
in <a href="https://docs.python.org/3/library/optparse.html#how-callbacks-are-called">this section</a>.
This makes argparse a clear improvement here٫ since at least you can turn
abbreviated options off if you want to.)</p>

<p>With my user hat on٫ I think this is a fine little feature. Long
options are often٫ well٫ long٫ and if you can abbreviate them you
might as well so people don"t have to type as much (at least the
people who don"t have command line completion for options for your
programs).</p>

<p>With my sysadmin hat on٫ I"m worried about the implications of
abbreviated options accidentally getting embedded into other scripts٫
crontab entries٫ and so on. For instance٫ if the real option is
"--dead-disks" but it"s usually used with a single disk name٫ it
would be easy to accidentally forget that it wasn"t "--dead-disk"
and embed that mistake in a script. Although this works today٫ it
risks confusion in people who later read the script (including your
future self). With heavily abbreviated options٫ evolving the program
to add more options risks now making a previously unambiguous and
working abbreviation now ambiguous and not working. If you add a
new "--deadline" argument and scripts were using "--dead" as an
abbreviation for "--dead-disks"٫ suddenly they"re going to start
getting errors.</p>

<p>(You can think of this as a version of <a href="https://en.wikipedia.org/wiki/Robustness_principle">Postel"s law</a>٫ in which
case <a href="https://tools.ietf.org/id/draft-thomson-postel-was-wrong-03.html">The Harmful Consequences of the Robustness Principle</a>
sort of applies.)</p>

<p>Given this concern٫ it"s tempting to update at least some of our
sysadmin tools to disable abbreviated command line options and
perhaps to make it my default argparse setting in future tools.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/python/ArgparseAbbreviatedOptions?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/links/PrometheusQueryAnatomy', 'Link: The Anatomy of a PromQL Query', '1594777403000',  14, '<div class="wikitext"><p><a href="https://promlabs.com/blog/2020/06/18/the-anatomy-of-a-promql-query/">The Anatomy of a PromQL Query</a>
(<a href="https://old.reddit.com/r/PrometheusMonitoring/comments/hjuele/the_anatomy_of_a_promql_query_promlabs_blog/">via</a>)
is a very clear and nice explanation of what goes into a <a href="https://promlabs.com/blog/2020/06/18/the-anatomy-of-a-promql-query/">PromQL</a>
query. It covers both the elements (metrics٫ functions٫ and so on)
and the Prometheus data types you use (such instant vectors and
range vectors). This is a very useful article because while PromQL
is solidly documented٫ it doesn"t have a concept overview that"s
as clear and straightforward as this.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow', 'How major and minor device numbers worked in V7 Unix', '1594695193000',  14, '<div class="wikitext"><p>Unix people who"ve been around for a while know that Unix devices
have <em>device numbers</em>٫ and that device numbers are divided into
<em>major</em> and <em>minor</em> device numbers. When you do "<code>ls -l /dev/null</code>"
and one of the fields that <code>ls</code> prints is two comma separated
numbers٫ those are the major and minor numbers (on Linux٫ they are
"1٫ 3"; this varies by Unix). Device numbers and their split into
major and minor parts go back a long way٫ to before Research Unix
V7٫ but V7 makes a convenient point to look at what they meant and
how they worked in the original Unixes.</p>

<p>As various sources will tell you٫ the major number tells you (and
the Unix kernel) what sort of device it is and thus what device
driver to use to talk to it٫ while the minor number tells the device
driver what specific bit of hardware it"s responsible for that you
want to talk to.  Sometimes the minor number also determines some
bit of functionality. Because V7 was a deliberately simple and
brute force system and kernel٫ major device numbers had a very
simple implementation. We can see it in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf/c.c">the generated V7 kernel
configuration file <code>c.c</code></a>:</p>


<pre style="white-space: pre-wrap;">
 struct bdevsw bdevsw[] =
 {
   nulldev٫ nulldev٫ rkstrategy٫ &amp;rktab٫ /* rk = 0 */
   nodev٫ nodev٫ nodev٫ 0٫ /* rp = 1 */
   [...]
   nodev٫ nodev٫ nodev٫ 0٫ /* hp = 6 */
   htopen٫ htclose٫ htstrategy٫ &amp;httab٫ /* ht = 7 */
   nodev٫ nodev٫ nodev٫ 0٫ /* rl = 8 */
   0
 };
</pre>

<p>What we"re seeing here is that V7 literally had an array of <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/h/conf.h"><code>bdevsw</code>
structures</a> indexed
by the major (block) device number٫ with various function that were
called when you did things like open a device (in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/sys/fio.c"><code>fio.c</code></a>).
There was a similar array for character devices٫ the <code>cdevsw</code> array.
In both of them٫ what driver functions were listed here instead of
stubbed out were determined by simple configuration files (<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf">here</a>)
that said what devices you had (among other things).</p>

<p>(The <code>c.c</code> file was generated by <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf/mkconf.c">a program</a>.
The particular <code>c.c</code> file in the TUHS V7 tree was built with only
two block devices configured٫ the <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/rk.c">RK disk driver</a> and
<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/ht.c">TJU16 tape driver "ht"</a>.)</p>

<p>In V7 the minor device number was only interpreted by the device
driver٫ as far as I can see. Device drivers used this for a variety
of purposes. For instance٫ <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/mem.c">the <code>mem</code> character driver</a>
implemented <code>/dev/null</code> as minor device 2٫ to go along with access
to physical memory and kernel memory. The <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/rl.c"><code>rl</code> disk driver</a> used
the minor device number to decide what physical disk it was talking
to (it supported up to four of them). Once V7 started getting out
in the world٫ other people wrote drivers for it (such as <a href="http://clara.comm.sfu.ca/pups/PDP-11/Trees/V7/usr/sys/dev/rx2.c">the RX02
floppy disk driver</a>) that
used minor device numbers both to select what to talk to and control
what features to use.</p>

<p>(There"s also <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/kl.c">the <code>kl</code> KL/DL-11 serial and console driver</a>٫ which
seems to deal with three different sets of hardware control registers
based on the minor number.)</p>

<p>The <code>/dev/tty</code> character device was implemented in a clever and
very short way in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/sys.c"><code>sys.c</code></a>. In
V7٫ there were no pseudo-ttys and no hot-plugged devices٫ so your
underlying physical terminal device always existed and was recorded
in your <code>u</code> area (see <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/h/user.h"><code>user.h</code></a>) The
general tty driver simply used this recorded device number of your
controlling tty to call its open٫ read٫ write٫ and ioctl functions
through the <code>cdevsw</code> array. As far as I can tell٫ this driver paid
no attention at all to the minor device number; as long as <code>/dev/tty</code>
had major number 7٫ the minor number was irrelevant.</p>

<p>PS: Note that V7 device drivers tended to be a little relaxed about
error checking for their minor device numbers (and other things).
For instance٫ as far as I can tell the <code>mem</code> driver actually only
distinguishes between minor number 2٫ minor number 1٫ and "everything
else"٫ which is treated as minor number 0٫ giving access to physical
memory.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/RunningServersFredBrooks', 'Running servers and Fred Brooks on transforming programs to products', '1594610131000',  14, '<div class="wikitext"><p>One of the seminal books on software engineering and project
management is Fred Brooks" justly famous <a href="https://en.wikipedia.org/wiki/The_Mythical_Man-Month">The Mythical Man-Month</a>. One of the
things that Brooks discusses in the book is the additional effort
it takes to transform a program (that has been written) into a
product (that can be sold). The modern open source world has its
own equivalent of this transformation that many people experience;
to make your program useful for other people it needs documentation٫
build instructions٫ and often generalization and more testing than
you gave it in your own personal use.</p>

<p>A while back I wrote an entry about how <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/RunningServersNotTrivial">running servers and
services well is not trivial</a>٫ which is
about exactly that. It has recently occurred to me that one part
of this difficulty٫ and also how setting up and running servers
often appears easy for non specialists٫ is another version of Fred
Brooks" transformation from programs to products and the extra
effort it takes. Just as it"s easy to write a one off program for
your own use٫ it"s easy these days to set up a one off special
server. But that"s not the server equivalent of a <em>product</em>; it"s
the server equivalent of a program before it"s been transformed
into a product. To become a product (a production server)٫ you need
a whole raft of additional things (many of which I outlined in <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/RunningServersNotTrivial">my
entry</a>).</p>

<p>Many programs can be transformed into products through incremental
improvements and developments (writing documentation٫ for example).
Unfortunately servers are often less malleable this way٫ and it may
not be very easy (or even possible) to transform a casually set up
server into a production grade server. Often you"ll wind up rebuilding
the server from scratch. The good news is that it"s usually much
easier (and faster) to build new versions of servers than it is to
rewrite programs from scratch.</p>

<p>I think that this can also provide a guide and a caution for when
you should set up a casual server yourself. If all you need is the
server equivalent of a one-off program٫ you can spin it up just as you
would write that program. But watch out; just as one off programs not
infrequently get drawn into (or pressed into) long term use٫ your "one
off" server may not be so temporary or unimportant after all. If it
becomes a load bearing component of your environment٫ the initial quick
approach will likely have left you with lingering problems.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/DesktopAppAutostartSystemd', 'Linux desktop application autostarting is different from systemd user units', '1594527634000',  14, '<div class="wikitext"><p>When I wrote about <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/DesktopAppAutostart">how applications autostart on modern Linux
desktops</a>٫ there was <a href="https://old.reddit.com/r/linux/comments/hbek8n/how_applications_autostart_on_modern_linux/">a Reddit discussion</a>٫
and one of the people there noted that things could also be autostarted
through systemd user units. As covered in <a href="https://wiki.archlinux.org/index.php/Systemd/User">the Arch Wiki page on
this</a>٫ Linuxes
that are systemd based generally automatically start a "<code>systemd
--user</code>" user systemd instance for you٫ and one of the things this
will do is it will start things in <code>~/.local/share/systemd/user</code>
and <code>~/.config/systemd/user</code>٫ which you can manipulate.</p>

<p>However٫ there are some significant differences between the two
that help explain why Linux desktops don"t use systemd user units.
The big one is that <strong>systemd user units are per-user٫ not
per-session</strong>. By their nature٫ desktop applications are a per
session thing and so not a great fit for a per-user system.  In
fact even getting systemd user units to be able to talk to your
desktop session takes what is basically a hack٫ as covered in <a href="https://wiki.archlinux.org/index.php/Systemd/User#DISPLAY_and_XAUTHORITY">the
Arch wiki section on DISPLAY and XAUTHORITY</a>٫
and this hack must be carefully timed so that it works correctly
(it has to happen before units that need to talk to your desktop
are started٫ and that means they have to be terminated when you log
out).</p>

<p>Desktops also have a lot more fine control over what gets started
with <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/DesktopAppAutostart">their current mechanisms</a>. Obviously
these things only get started for desktop sessions٫ not things like
SSH logins٫ and they can be specific to certain desktops or not
start in some desktops. I don"t believe there is a native systemd
unit option for "run only if this environment variable is defined"٫
so you can"t readily make a systemd unit that only runs in desktop
sessions٫ never mind only a particular sort of desktop.</p>

<p>(Relying to any significant degree on user units would also more
strongly tie desktops to systemd٫ although I don"t know if that"s
something they worry about these days or if it"s full steam ahead
on systemd in general.)</p>

<p>My general impression is that systemd user .service units are not
a good fit for what most users want and do with autostarting things
today٫ whether or not they"re using a desktop. Systemd user units
are probably a better fit for socket and dbus units٫ because those
are more naturally activated on the fly as needed٫ but I don"t know
if people are doing this very much (especially for desktop related
things).</p>

<p>(As a practical matter٫ I"d consider it pretty obnoxious if a program
decided to set itself to autostart as a systemd user unit. I suspect
I"m not alone in this.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/DesktopAppAutostartSystemd?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoMiddlewareVsInterfaceSmuggling', 'The impact on middleware of expanding APIs with Go"s interface smuggling', '1594434134000',  14, '<div class="wikitext"><p>Recently٫ the Go blog had <a href="https://blog.golang.org/module-compatibility">Keeping your Modules Compatible</a> which is about
doing exactly that as you add features and want to expand your
module"s API. When the module"s API involves interfaces٫ one of
the approaches they suggested is what I"ve called <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoInterfaceSmuggling">interface
smuggling</a> and what other people have
called <em>interface upgrades</em>. Let me quote the article:</p>

<blockquote><p>When you run into a case where you want to add a method to an existing
interface٫ you may be able to follow this strategy. Start by creating
a new interface with your new method٫ or identify an existing
interface with the new method. Next٫ identify the relevant functions
that need to support it٫ type check for the second interface٫ and add
code that uses it.</p>
</blockquote>

<p>This is a quite popular approach٫ one used by many packages in Go"s
standard library and third party packages. However٫ it has a dark
side٫ and that is its unfortunate effects on middleware.</p>

<p>The problem for middleware is best illustrated by the most common
sort of middleware٫ which is things that interpose in the chain of
HTTP handlers to modify the results. Much middleware wants to look
at or act on some aspect of the HTTP reply٫ for example <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoPrometheusMetricLabels">to gather
metrics based on the result code</a>٫ which
means that it must modify and proxy the <a href="https://golang.org/pkg/net/http/#ResponseWriter"><code>http.ResponseWriter</code></a> passed to child
<a href="https://golang.org/pkg/net/http/#Handler"><code>http.Handler</code></a>s. Over
time the <a href="https://golang.org/pkg/net/http/"><code>http</code> package</a> has
acquired a whole collection of smuggled interfaces on ResponseWriters٫
such as <a href="https://golang.org/pkg/net/http/#CloseNotifier"><code>http.CloseNotifier</code></a> (which is deprecated)٫
<a href="https://golang.org/pkg/net/http/#Flusher"><code>http.Flusher</code></a>٫
<a href="https://golang.org/pkg/net/http/#Hijacker"><code>http.Hijacker</code></a>٫ and
<a href="https://golang.org/pkg/net/http/#Pusher"><code>http.Pusher</code></a>. In the
future there will probably be more.</p>

<p>(In addition٫ the ResponseWriter may or may not support
<a href="https://golang.org/pkg/io/#ReaderFrom"><code>io.ReaderFrom</code></a>.)</p>

<p>If you"re a piece of middleware٫ the ResponseWriter you"re passed
may support some٫ many٫ or all of these additional APIs. However٫
Go provides you no good way to pass this support through your proxy
ResponseWriter that you"re going to pass to children Handlers. The
Prometheus people try hard to do it anyway٫ and <a href="https://github.com/prometheus/client_golang/blob/master/prometheus/promhttp/delegator.go">the result is
rather messy</a>
and involves a combinatorial explosion of the possible combinations
of APIs. As the case of io.ReaderFrom shows٫ these additional APIs
don"t even necessarily come from the <a href="https://golang.org/pkg/net/http/"><code>http</code> package</a>. A smuggled
interface from anywhere may need to be supported.</p>

<p>One answer to this is that you just don"t support these additional
APIs in your middleware٫ or you only support a few of them. The
problem with this is that the ResponseWriter and the client code
that people are trying to use your middleware with well have been
developed٫ tested٫ and normally used in an environment where these
expanded APIs are used٫ not cut off. As we all know٫ if you don"t
test it it doesn"t work. Your middleware may be the first code to
try to pass the next hop a ResponseWriter with a genuinely narrow
API٫ because such narrow APIs may mostly come from middleware. And
of course if there are any bugs in the result٫ people will blame
your middleware.</p>

<p>None of this is insurmountable. But beyond the problems and the
hassles٫ it means that expanding your API with interface smuggling
is decidedly not transparent if people use middleware with it. And
as a practical matter٫ some amount of the time your new API will
not be usable until middleware is expanded to cope with it (if it
ever is).</p>

<p>Another problem is that this expansion of middleware to cope with
your new API can"t happen until your new API itself is pervasive.
Go currently provides no support for conditional building based on
the version of other packages or the state of their API٫ so middleware
can"t include any use of your new API interfaces until it doesn"t
have to build against versions of your package that predate them.</p>

<p>(People can work around this for HTTP middleware because they can
make files build only on specific minimum versions of Go. Your
package doesn"t have this magical power; it"s something available
only for new APIs in the Go standard library.)</p>

<p>Because nothing is new under the sun٫ this problem was noticed back
in 2014"s <a href="https://avtok.com/2014/11/05/interface-upgrades.html">Interface Upgrades in Go</a>٫ which is
one of the earliest places to call this pattern an "interface
upgrade". The article notes the proxy problem and ends with a call
to use interface upgrades sparingly. This is good advice in my
opinion٫ but is very much at odds with the idea of routinely using
interface upgrades to expand your API.</p>

<p>(<a href="https://old.reddit.com/r/golang/comments/hoehhv/interface_smuggling_a_go_design_pattern_for/">Via</a>.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/UbuntuBuildingFirefox', 'Ubuntu٫ building current versions of Firefox٫ and snaps', '1594354085000',  14, '<div class="wikitext"><p>Today on Twitter٫ <a href="https://twitter.com/thatcks/status/1281331375912767489">I said</a>:</p>

<blockquote><p>Given that Ubuntu"s ostensible logic for putting Chrome in a snap is
"it makes maintaining it easier"٫ my cynical side expects Ubuntu to
also do this with Firefox before too long (due to Firefox"s need for
steadily increasing versions of Rust).</p>
</blockquote>

<p>(The context here is LWN"s <a href="https://lwn.net/Articles/825005/">Linux Mint drops Ubuntu Snap packages</a>٫ <a href="https://lobste.rs/s/9q0kta/linux_mint_drops_ubuntu_snap_packages">via</a>.
For "Ubuntu"٫ you can read "Canonical"٫ since Canonical is driving
this.)</p>

<p>Ubuntu ships current versions of Firefox (at the moment Firefox 78)
in Ubuntu LTS releases٫ which means that they must build current
versions of Firefox on all supported Ubuntu LTS versions. Firefox
is built partly with Rust (among other things)٫ and new releases
of Firefox often require relatively recent versions of Rust; for
instance٫ right now Firefox Nightly (which will become Firefox 80
or 81) requires Rust 1.43.0 or better. Nor is Rust the only thing
that Firefox has minimum version requirements for. Firefox 78٫ the
current release٫ requires nasm 2.14 or better if you want to build
the AV1 codecs٫ and I"m sure there are others I just haven"t tripped
over yet.</p>

<p>This is a problem for Ubuntu because Ubuntu famously doesn"t like
updating packages on Ubuntu LTS (or probably any Ubuntu release٫
but I only have experience with LTS releases). Today٫ the need to
build current Firefox versions on old Ubuntu LTS releases means
that Ubuntu 16.04 has been dragged up to Rust 1.41.0 (the same Rust
version that"s on 18.04 and 20.04). If current versions of Rust
weren"t required to build Firefox٫ Rust on 16.04 would probably be
a lot like Go٫ where the default is version 1.6 (that"s the <code>golang</code>
package version) and the most recent available one is Go 1.10 (which
actually dates from 2018٫ which is modern for an LTS release from
2016). When Firefox 80 or so is released and requires Rust 1.43.0
or better٫ Ubuntu will have to update Rust again on all of the still
supported LTS versions٫ which will probably still include 16.04 at
that point.</p>

<p>Canonical can"t like this. At the same time٫ they have to ship
Firefox and they have to keep it current٫ for security reasons.
Shipping Firefox as a Snap would deal with both problems٫ because
Canonical would no longer need to be able to build the current
Firefox from source on every supported Ubuntu release (LTS and
otherwise٫ but the oldest ones are generally LTS releases). Given
that Canonical wants to shove everyone into Snaps in general٫ I
rather expect that they"re going to do this to Firefox sooner or
later.</p>

<p>PS: I"m not looking forward to this٫ because <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu2004SnapsHomeIssue">Snaps don"t work
with NFS mounted home directories or in our environment in general</a>. Ubuntu moving Firefox to a Snap would
probably cause us to use the official Mozilla precompiled binaries
in the short term٫ and push us more toward another Linux release
in the longer term (probably Debian).</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/UbuntuBuildingFirefox?showcomments#comments">5 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/links/MimeTypeAssociations', 'Link: Mime type associations (on Linux)', '1594310077000',  14, '<div class="wikitext"><p>Enrico Zini"s <a href="https://www.enricozini.org/blog/2020/debian/mime-type-associations/">Mime type associations</a>
(via <a href="https://planet.debian.org/">Planet Debian</a>) is
about the practical side of fixing MIME type associations so that
various types of files open in the right program on your Debian
system.  This is an area of interest to me٫ but I"ve never pulled
everything together into one spot (and compactly) the way this
article does.</p>

<p>(For my entries٫ there"s <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/XdgMimeTypeSearching">how <code>xdg-mime</code> searches for MIME type
handlers</a>٫ <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/XdgOpenWhichBrowser">how <code>xdg-open</code> picks
which web browser to use</a>٫ <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/UbuntuMailcapBasics">the
basics of <code>/etc/mailcap</code></a>٫ and <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/MailcapDocx2txtTangle">a
cautionary story of mailcap handling</a>.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/links/MimeTypeAssociations?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoInterfaceSmuggling', '"Interface smuggling"٫ a Go design pattern for expanding APIs', '1594265867000',  14, '<div class="wikitext"><p>Interfaces are one of the big ways of creating and defining APIs
in <a href="https://golang.org/">Go</a>. Go famously encourages these
interfaces to be very minimal; the widely used and implemented
<a href="https://golang.org/pkg/io/#Reader"><code>io.Reader</code></a> and <a href="https://golang.org/pkg/io/#Writer"><code>io.Writer</code></a> are each one method. Minimal APIs
such as this have the advantage that almost anything can implement them٫
which means that Go code that accepts an <code>io.Reader</code> or <code>io.Writer</code> can
work transparently with a huge range of data sources and destinations.</p>

<p>However٫ this very simplicity and generality means that these APIs
are not necessarily the most efficient way to perform operations.
For example٫ if you want to copy from an io.Reader to an io.Writer٫
such as <a href="https://golang.org/pkg/io/#Copy"><code>io.Copy()</code></a> does٫ using
only the basic API means that you have to perform intermediate data
shuffling when in many cases either the source could directly write
to the destination or the destination could directly read from the
source. Go"s solution to this is what I will call <em>interface
smuggling</em>.</p>

<p>In interface smuggling٫ the actual implementation is augmented with
additional well known APIs٫ such as <a href="https://golang.org/pkg/io/#ReaderFrom"><code>io.ReaderFrom</code></a> and <a href="https://golang.org/pkg/io/#WriterTo"><code>io.WriterTo</code></a>. Functions that want to
work more efficiently when possible٫ such as <a href="https://golang.org/pkg/io/#Copy"><code>io.Copy()</code></a>٫
attempt to convert the io.Reader or io.Writer they obtained to
the relevant API and then use it if the conversion succeeded:</p>

<blockquote><pre style="white-space: pre-wrap;">
if wt٫ ok := src.(WriterTo); ok {
   return wt.WriteTo(dst)
}
if rt٫ ok := dst.(ReaderFrom); ok {
   return rt.ReadFrom(src)
}
[... do copy ourselves ...]
</pre>
</blockquote>

<p>I call this <em>interface smuggling</em> because we are effectively smuggling
a different٫ more powerful٫ and broader API through a limited one.
In the case of types supporting io.WriterTo and io.ReaderFrom٫
io.Copy completely bypasses the nominal API; the .Read() and .Write()
methods are never actually used٫ at least directly by io.Copy (they may
be used by the specific implementations of .WriteTo() or .ReadFrom()٫ or
more interface smuggling may take place).</p>

<p>(Go code also sometimes peeks at the concrete types of interface
API arguments. This is how under the right circumstances٫ io.Copy
will wind up using the Linux <a href="https://man7.org/linux/man-pages/man2/splice.2.html"><code>splice(2)</code></a> or <a href="https://man7.org/linux/man-pages/man2/sendfile.2.html"><code>sendfile(2)</code></a> system
calls.)</p>

<p>There is also interface smuggling that expands the API٫ as seen in
things like <a href="https://golang.org/pkg/io/#ReadCloser"><code>io.ReadCloser</code></a>
and <a href="https://golang.org/pkg/io/#ReadWriteSeeker"><code>io.ReadWriteSeeker</code></a>.
If you have a basic <code>io.Reader</code>٫ you can try to convert it to see if it
actually supports these expanded APIs٫ and then use them if it does.</p>

<p>PS: There"s probably a canonical Go term for doing this as part
of your API design٫ either to begin with or <a href="https://blog.golang.org/module-compatibility">as part of expanding
it while retaining backward compatibility</a>. If so٫ feel free
to let me know in the comments.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoInterfaceSmuggling?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraBtrfsDefaultView', 'Some thoughts on Fedora moving to btrfs as the default desktop file system', '1594180024000',  14, '<div class="wikitext"><p>The news of the time interval for me is that there is a Fedora
change proposal to <a href="https://fedoraproject.org/wiki/Changes/BtrfsByDefault">make btrfs the default file system for Fedora
desktop</a>
(<a href="https://communityblog.fedoraproject.org/fedora-33-btrfs-by-default-test-day-2020-07-08/">via</a>٫
itself <a href="https://lobste.rs/s/skkr5x/fedora_33_btrfs_by_default_test_day_2020_07">via</a>;
see also <a href="https://lists.fedoraproject.org/archives/list/devel@lists.fedoraproject.org/thread/IOPR2R3SCKOFUCKPLMS4MDD5664SGQFR/">the mailing list post</a>).
Given that in the past I"ve been a btrfs sceptic (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSOnLinuxvsBtrfsToday">eg</a>٫ from 2015)٫ long time readers might expect
me to have some views here. However٫ this time around my views are
cautiously optimistic for btrfs (and Fedora)٫ although I will only
be watching from a safe distance.</p>

<p>The first two things to note are that 2015 is a long time ago (in
computer time) and I"m too out of touch with btrfs to have an
informed opinion on its current state. I"m confident that people
in Fedora wouldn"t have proposed this change if there weren"t good
reasons to believe that btrfs is up to the task. The <a href="https://btrfs.wiki.kernel.org/index.php/Status">current btrfs
status</a> looks pretty
good on a skim٫ although the section on <a href="https://btrfs.wiki.kernel.org/index.php/Status#Device_replace">device replacement</a>
makes me a little alarmed. The Fedora proposal also covers who else
is using btrfs and has been for some time٫ and it"s a solid list
that suggest btrfs is not going to explode for Fedora users.</p>

<p>I"m a big proponent of <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/NextGenerationFilesystem">modern filesystems with data and metadata
checksums</a>٫ so I like that aspect
of btrfs. As far as performance goes٫ most people on desktops are
unlikely to notice the difference٫ and as a long term user of <a href="https://zfsonlinux.org/">ZFS
on Linux</a> I can testify how nice it is to
not have to preallocate space to specific filesystems (even if with
LVM you can grow them later).</p>

<p>However٫ I do feel that this is Fedora being a bit adventurous.
This is in line with Fedora"s goals and general stance of being a
relatively fearless leading edge distribution٫ but at the same time
sometimes the leading edge is also the bleeding edge. I would not
personally install a new Fedora machine with btrfs in the first few
releases of Fedora that defaulted to it٫ because I expect that there
will be teething problems. Some of these may be in btrfs٫ but others
will be in system management programs and practices that don"t cope
with btrfs or conflict with it.</p>

<p>In the long run I think that this change to btrfs will be good for
Fedora and for Linux as a whole. Ext4 is a perfectly decent filesystem
(and software RAID works fine)٫ but it"s possible to do much better٫
as ZFS has demonstrated for a long time.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraBtrfsDefaultView?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/web/BlogDroppingPerDayPages', 'I now think that blog "per day" pages with articles are a mistake', '1594094965000',  14, '<div class="wikitext"><p>Back in 2005 when I wrote <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a>٫ the engine that is used for
<a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>٫ there was an accepted standard structure
for blogs that people followed٫ me included. For instance٫ it was
accepted convention that the front page of your blog showed a number
of the most recent articles٫ and you could page backward to older
ones. Part of this structure was the idea that you would have a
page for each day and that page would show the article or articles
written that day (if any). When I put together <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a>"s URL structure
for blog-like areas٫ I followed this٫ and to this day <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering
Thoughts</a> has these per-day pages.</p>

<p>I now think that these per day pages are not the right thing to do
on the modern web (for most blogs)٫ for three reasons. The first
reason is that they don"t particularly help <a href="https://utcc.utoronto.ca/~cks/space/blog/web/RealBlogUsability">real blog usability</a>٫ especially getting people to explore your blog
after they land on a page. Most people make at most one post a day٫
so exploring day by day doesn"t really get you anything more than
links in a blog entry to the next entry and the previous entry will
(and if the links have the destination"s title٫ they will probably
be giving you more information than a day).</p>

<p>The second reason is that because they duplicate content from your
actual articles٫ they confuse search engine based navigation. Perhaps
the search engine will know that the actual entry is the canonical
version and present that in preference to the per-day page where
the entry is also present٫ but perhaps not. And if you do have two
entries in one day٫ putting both of their texts on one page risks
disappointment in someone who is searching for a combination of
terms where one term is only in one entry and the other term is in
a second.</p>

<p>The third and weakest reason is a consequence of how <a href="https://utcc.utoronto.ca/~cks/space/blog/web/EverythingGetsVisited">on the modern
web٫ everything gets visited</a>. Per-day pages
are additional pages in your blog and web crawlers will visit them٫
driving up your blog"s resource consumption in the process. These
days my feelings are that you generally want to minimize the number
of pages in your blog٫ not maximize them٫ something I"ve written
about more in <a href="https://utcc.utoronto.ca/~cks/space/blog/web/ManyURLsModernDrawback">The drawback of having a dynamic site with lots of
URLs on today"s web</a>. But this is not a
very strong reason٫ if you have a reasonably efficient blog and
you serve per-day pages that don"t have the full article text.</p>

<p>I can"t drop per-day pages here on <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>٫ because
I know that people have links to them and I want those links to
keep working as much as possible. The simple thing to do is to stop
putting full entries on per-day pages٫ and instead just put in their
title and a link to them (just as I already do on per-month and
per-year pages); this at least gets rid of the duplication of entry
text and makes it far more likely that search engine based navigation
will deliver people to the actual entry.  The more elaborate thing
would be to automatically serve a HTTP redirect to the entry for
any per-day page that had only a single entry.</p>

<p>(For relatively obvious reasons you"d want to make this a temporary
redirect.)</p>

<p>There"s a bit of me that"s sad about this shift in blog design and
web usage; the per-day٫ per-month٫ and per-year organization had a
pleasant regularity and intuitive appeal. But I think its time has
passed. More and more٫ we"re all tending toward <a href="https://utcc.utoronto.ca/~cks/space/blog/web/StaticVsDynamicSiteLayout">the kind of minimal
URL structure typical of static sites</a>٫
even when we have dynamic sites and so could have all the different
URL structures and ways of accessing our pages that we could ask for.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/BlogDroppingPerDayPages?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoWhenNotManyGoroutines', 'A Go lesson learned: sometimes I don"t want to use goroutines if possible', '1594007545000',  14, '<div class="wikitext"><p>We have a heavily NFS based server environment <a href="https://support.cs.toronto.edu/">here</a>٫ with <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">multiple NFS servers</a> and an IMAP server that accesses
all mailboxes over NFS. That IMAP server has had <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/LoadAverageIMAPImpactQuestion">ongoing issues
with elevated load averages</a>٫
and what at least seems to be IMAP slowness. However٫ our current
metrics leave a lot of uncertainties about the effects of all of
this٫ because we basically only have a little bit of performance
data for a few IMAP operations. One thing I"d like to do is gather
some very basic Unix level NFS performance data from our IMAP server
and from some other machines٫ to see if I can see anything.</p>

<p>One very simple metric is how long it takes to read a little file
from every NFS filesystem we have mounted on a machine. As it
happens٫ we already have the little files (they"re used for another
system management purpose)٫ so all I need is a program to open and
read each one while timing how long it takes. There"s an obvious
issue with doing this sequentially٫ which is that if there"s a
single slow filesystem٫ it could delay everything else.</p>

<p>The obvious answer here was Go٫ goroutines٫ and some form of goroutine
pool. Because the goroutines just do IO (and they"re only being
used to avoid one bit of IO delaying another separate bit)٫ the
natural size of the goroutine pool is fairly large٫ say 50 to 100
goroutines (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ManyNFSFilesystemsWhy">we have a lot of NFS filesystems</a>).  This is quite easy and obvious
to implement in Go٫ so I put together a little Go program for it
and watched the numbers it generated as they jumped around.</p>

<p>Then٫ out of reflexive caution٫ I tried running the same program
with a goroutine pool size of 1٫ which more or less forced serial
execution (the pool goroutine infrastructure was still active but
there was only one worker goroutine doing all the reading). To my
surprise the "time to read a file" number for all filesystems was
visibly and decidedly lower. I could run the program side by side
with the two different goroutine pool sizes and see this clearly.</p>

<p>Some thinking gave me a possible reason why this is so. My core
code does essentially the following (minus error checking):</p>

<blockquote><pre style="white-space: pre-wrap;">
start := time.Now()
file٫ err := os.Open(target)
n٫ err := file.Read(buffer)
duration := time.Now().Sub(start)
</pre>
</blockquote>

<p>This sequence makes two system calls and <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoSchedulerAndSyscalls">each system call is a
potential goroutine preemption point</a>. If
a goroutine gets preempted during either system call٫ it can only
record the finishing time once it"s scheduled again (and finishes
the read٫ if it was preempted in the open). If there are 50 or more
goroutines all doing this٫ some of them could well be preempted and
then not scheduled for some time٫ and that scheduling delay will
show up in the final duration. When there aren"t multiple goroutines
active٫ there should be very little scheduling delay and the recorded
durations (especially the longest durations) will be lower. And the
ideal situation for essentially no goroutine contention is of course
one goroutine.</p>

<p>(Technically this makes two more system calls to get the time at
the start and the end of the sequence٫ but on modern systems٫
especially Linux٫ these don"t take long enough to trigger <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoSchedulerAndSyscalls">Go"s
system call preemption</a> and probably don"t
even enter the kernel itself.)</p>

<p>Because I still worry about individual slow filesystems slowing
everything down (or stalls on some filesystems)٫ my solution was a
more complicated work pool approach that starts additional worker
goroutines only when all of the current ones seem to have stalled
for too long.  If all goes well (and it generally does in my testing)٫
this runs with only one goroutine.</p>

<p>(My current code has the drawback that once the goroutine worker
pool expands٫ all of them stay active٫ which means that enough
slow filesystems early on in the checks could get me back to the
thundering herd problem. I"m still thinking about that issue.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoWhenNotManyGoroutines?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/tech/TLSHowMultipleChains', 'How you get multiple TLS certificate chains from a server certificate', '1593892980000',  14, '<div class="wikitext"><p>I"ve known and read for some time that a single server certificate
can have more than one chain to a root certificate that you trust٫
but I never really thought about the details of how this worked.
Then <a href="https://www.agwa.name/blog/post/fixing_the_addtrust_root_expiration">the AddTrust thing</a>
happened٫ I started writing about <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusBlackboxVsAddTrust">how Prometheus"s TLS checks
would have reacted to it</a>٫
and Guus left a comment on <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusBlackboxVsAddTrust">that entry</a> that got me thinking
about what else Prometheus could sensibly look at here. So now
I want to walk through the mechanics of multiple TLS chains to
get this straight in my head.</p>

<p>Your server certificate and the other TLS certificates in a chain
are each signed by an <em>issuer</em>; in a verified chain٫ this chain of
issuers eventually reaches a Certificate Authority root certificate
that people have some inherent trust in. However٫ a signed certificate
doesn"t specifically name and identify the issuer"s certificate by٫
say٫ its serial number or hash; instead <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateIdentity">issuers are identified
by their X.509 Subject Name</a> and also at
least implicitly by their keypair (and sometimes explicitly).  By
extension٫ your signed certificate also identifies the key type of
the issuer"s certificate; if your server certificate is signed by
RSA٫ an intermediate certificate with an ECDSA keypair is clearly
not the correct parent certificate.</p>

<p>(Your server certificate implicitly identifies the issuer by keypair
because they signed your certificate with it; an intermediate
certificate with a different keypair can never validate the signature
on your certificate.)</p>

<p>However٫ several certificates can have the same keypair and <a href="https://en.wikipedia.org/wiki/X.509">X.509
Subject Name</a>٫ provided that
other attributes differ. One such attribute is the issuer that
signed them (including whether this is <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSWhatIsSelfSignedCert">a self-signed CA root
certificate</a>). So the first thing is that
<strong>having more than one certificate for an issuer is generally
required to get multiple chains</strong>. If you only have one certificate
for each issuer٫ you can pretty much only build a single chain.</p>

<p>There are three places that these additional certificates for an
issuer can come from; they can be sent by the server٫ they can be
built into your certificate store in advance٫ or they can be cached
because you saw them in some other context. The last is especially
common with browsers٫ which often cache intermediate certificates
that they see and may use them in preference to the intermediate
certificate that a TLS server sends. Other software is generally
more static about what it will use. My guess is that we"re unlikely
to have multiple certificates for a single CA root issuer٫ at least
for modern CAs and modern root certificate sets as used by browsers
and so on.  This implies that the most likely place to get additional
issuer certificates is from intermediate certificates sent by a
server.</p>

<p>(In any case٫ it"s fairly difficult to know what root certificate
sets clients are using when they talk to your server. If your server
sends the CA root certificate you think should be used as part of
the certificate chain٫ a monitoring client (such as Prometheus"s
checks) can at most detect when it"s got an additional certificate
for that CA root issuer in its own local trust store.)</p>

<p>One cause of additional issuer certificates is what"s called
<em>cross-signing</em> a CA"s intermediate certificate٫ as is currently
the case with <a href="https://letsencrypt.org/certificates/">Let"s Encrypt"s certificates</a>. In cross-signing٫ a CA
generate two versions of its intermediate certificate٫ using the
same X.509 Subject Name and keypair; one is signed by its own CA
root certificate and one is signed by another CA root certificate.
A CA can also cross-sign its own new root certificate (well٫ the
keypair and issuer) directly٫ as is the case with <a href="https://ssl-tools.net/subjects/6ff4684d4312d24862819cc02b3d472c1d8a2fa6">the DST Root
CA X3 certificate that Let"s Encrypt is currently cross-signed with</a>;
one certificate for "DST Root CA X3" is self-signed and likely in
your root certificate set٫ but two others existed that were
cross-signed by an older DST CA root certificate.</p>

<p>(As covered in the certificate chain illustrations in <a href="https://www.agwa.name/blog/post/fixing_the_addtrust_root_expiration">Fixing the
Breakage from the AddTrust External CA Root Expiration</a>٫ this
was also the case with the expiring AddTrust root CA certificate.
The "<a href="https://ssl-tools.net/subjects/cd30d24c343a82ab1f0570158ad7a107762992e9">USERTrust RSA Certification Authority</a>"
issuer was also cross-signed to "<a href="https://ssl-tools.net/subjects/7cb166549cabdb44ee622616adf4657bf77ad594">AddTrust External CA Root</a>"٫
a CA root certificate that expired along with that cross-signed
intermediate certificate. And this USERTrust root issuer is still
cross signed to another valid root certificate٫ "<a href="https://ssl-tools.net/subjects/53b54f6e16a815187849c176725823579954799e">AAA Certificate
Services</a>".)</p>

<p>This gives us some cases for additional issuer certificates:</p>

<ul><li>your server"s provided chain includes multiple intermediate certificates
for the same issuer٫ for example both Let"s Encrypt intermediate
certificates.  A client can build one certificate chain through
each.<p>
</li>
<li>your server provides an additional cross-signed CA certificate٫ such
as the USERTrust certificate signed by AddTrust. A client can build
one certificate chain that stops at the issuer certificate that"s in
its root CA set٫ or it can build another chain that"s longer٫ using
your extra cross-signed intermediate certificate.<p>
</li>
<li>the user"s browser knows about additional intermediate certificates
and will build additional chains using them٫ even though your server
doesn"t provide them in its set of certificates. This definitely
happens٫ but browsers are also good about handling multiple chains.</li>
</ul>

<p>In a good world٫ all intermediate certificates will have an expiration
time no later than the best certificate for the issuer that signed
them. This was the case with the AddTrust expiration; the cross-signed
USERTrust certificate expired at the same time as the AddTrust root
certificate. In this case you can detect the problem by noticing
that a server provided intermediate certificate is expiring soon.
If only a CA root certificate at the end of an older chain is
expiring soon and the intermediate certificate signed by it has a
later expiration date٫ you need to check the expiration time of the
entire chain.</p>

<p>As a practical matter٫ monitoring the expiry time of all certificates
provided by a TLS server seems very likely to be enough to detect
multiple chain problems such as the AddTrust issue. Competent
Certificate Authorities shouldn"t issue server or intermediate
certificates with expiry times later than their root (or intermediate)
certificates٫ so we don"t need to try to find and explicitly check
those root certificates. This will also alert on expiring certificates
that were provided but that can"t be used to construct any chain٫
but you probably want to get rid of those anyway.</p>

<h3>Sidebar: Let"s Encrypt certificate chains in practice</h3>

<p>Because browsers do their own thing٫ a browser may construct multiple
certificate chains for Let"s Encrypt certificates today even if
your server only provides the LE intermediate certificate that is
signed by DST Root CA X3 (the current Let"s Encrypt default for the
intermediate certificate). For example٫ if you visit <a href="https://valid-isrgrootx1.letsencrypt.org/">Let"s Encrypt"s
test site for their own CA root</a>٫ your browser will
probably cache the LE intermediate certificate that chains to the
LE CA root certificate٫ and then visiting other sites using Let"s
Encrypt may cause your browser to ignore their intermediate certificate
and chain through the "better" one it already has cached. This is
what currently happens for me on Firefox.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/TLSWhatIsSelfSignedCert', 'What a TLS self signed certificate is at a mechanical level', '1593836710000',  14, '<div class="wikitext"><p>People routinely talk about self signed TLS certificates. You use
them in situations where you just need TLS but don"t want to set
up an internal Certificate Authority and can"t get an official TLS
certificate٫ and many CA root certificates are self signed. But
until recently I hadn"t thought about what a self signed certificate
is٫ mechanically. So here is my best answer.</p>

<p>To simplify a lot٫ a TLS certificate is a bundle of attributes wrapped
around a public key. All TLS certificates are signed by someone; we
call this the <em>issuer</em>. <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateIdentity">The issuer for a certificate is identified
by their X.509 Subject Name</a>٫ and also at least
implicitly by the keypair used to sign the certificate (since only
an issuer TLS certificate with the right public key can validate the
signature).</p>

<p>So this gives us the answer for what a self signed TLS certificate
is. It"s a certificate that lists its own Subject Name as the issuer
and is signed with its own keypair (using some appropriate key
signature algorithm٫ such as SHA256-RSA for RSA keys). It still has
all of the usual TLS certificate attributes٫ especially "not before"
and "not after" dates٫ and in many cases they"ll be processed
normally.</p>

<p>Self signed certificates are not automatically CA certificates for a
little private CA. Among other things٫ the self-signed certificate can
explicitly set an "I am not a CA" marker in itself. Whether software
respects this if someone explicitly tells it to trust the self-signed
certificate as a CA root certificate is another matter٫ but at least you
tried.</p>

<p>Self-signed certificates do have a serial number (which should be
unique)٫ and a unique cryptographic hash. Browsers that have been told
to trust a self-signed certificate are probably using either these or
a direct comparison of the entire certificate to determine if you"re
giving them the same self-signed certificate٫ instead of following the
process used for identifying issuers (of checking the issuer Subject
Name and so on). This likely means that if you re-issue a self-signed
certificate using the same keypair and Subject Name٫ browsers may not
automatically accept it in place of your first one.</p>

<p>(As far as other software goes٫ who knows. There are dragons all
over those hills٫ and I suspect that there is at least some code
that accepts a matching Subject Name and keypair as good enough.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/WorkNotDoneFromHome', 'The work that"s not being done from home is slowly accumulating for us', '1593745597000',  14, '<div class="wikitext"><p>At the moment٫ the most recent things I"ve seen have talked about
<a href="https://support.cs.toronto.edu/">us</a> not returning to the office
before September٫ and then not all of us at one time. This gives
me complicated feelings٫ including about what work we are doing.
From the outside٫ our current work from home situation probably
looks like everything is going pretty well. We"ve kept the computing
lights on٫ things are being done٫ and so far all of the ordinary
things that people ask of us get done as promptly as usual. A few
hardware issues have come up and have been dealt with by people
making brief trips into the office. So it all looks healthy; you
might even wonder why we need offices.</p>

<p>When I look at the situation from inside٫ things are a bit different.
We may be keeping the normal lights on٫ but at the same time there"s a
steadily growing amount of work that is not being done because of our
working from home. The most obvious thing is that ordering new servers
and other hardware has basically been shut down; not only are we not in
the office to work on any hardware٫ it mostly can"t even be delivered to
the university right now.</p>

<p>The next obvious thing is the timing of any roll out of Ubuntu 20.04
on our machines. Under normal circumstances٫ we"d have all of the
infrastructure for installing 20.04 machines ready and probably
some test machines out there for people to poke at٫ and we"d be
hoping to migrate a number of user-visible machines in August before
the fall semester starts. That"s looking unlikely٫ since at this
point all we have is an ISO install image that"s been tested only
in temporary virtual machines. Since we haven"t been in the office٫
we haven"t set up any real servers running 20.04 on an ongoing
basis. We"re in basically <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/Ubuntu2004TimingIssues">the bad case situation I imagined back
in early April</a>.</p>

<p>(And of course many of the people we"d like to have poke at 20.04
test machines are busy with their own work from home problems٫ so
even if we had test machines٫ they would probably get less testing
than usual.)</p>

<p>Another sign is that many of our Ubuntu servers have been up without
a reboot for what is now an awfully long time for us. Under normal
circumstances we might have scheduled a kernel update and reboot
by now٫ but under work from home conditions we only want to take
the risk of doing kernel updates and rebooting important servers
if there is something critical. If something goes wrong٫ it"s not
a walk down to the machine room٫ it"s a trip into the office (and
a rather longer downtime).</p>

<p>There"s also a slowly accumulating amount of pending physical
networking work٫ where we"re asked to change what networks particular
rooms or network ports are on because people are moving around.
This work traditionally grows as the fall semester approaches and
space starts getting sorted out for new graduate students and so
on٫ although that could change drastically this year depending on
the university"s overall plans for what graduate students will do
and where they will work.</p>

<p>(To put it one way٫ a great deal of graduate student space is not
set up for appropriate physical distancing. Nor is a fair amount
of other office and lab space.)</p>

<p>One level up from this is that there"s a number of projects that
need to use some physical servers. We have a bunch of OpenBSD
machines on old OpenBSD versions that could do with updates (and
refreshes on to new hardware)٫ for example٫ but we need to build
them out in test setups first. Another example is that we have plans
to significantly change <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/SlurmHasCreatedCattle">how we currently use SLURM</a>٫ but that needs a few machines to set up a
little new cluster (on our server network٫ as part of our full
environment).</p>

<p>(A number of these projects need custom network connectivity٫ such
as new test firewalls needing little test networks. Traditionally
we build this in some of our "lab space"٫ with servers just sitting
on a table wired together.)</p>

<p>Much of this is inherent in us having and using physical servers. Having
physical servers in a machine room means receiving new hardware٫ racking
it٫ cabling it up٫ and installing it٫ all of which we have to do in
person (plus at least pulling the cables out of any old hardware that
it"s replacing). Some of it (such as our reluctance to reboot servers)
is because we don"t have full remote KVM over IP capabilities on our
servers.</p>

<p>PS: We"re also lucky that <a href="https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic">all of this</a> didn"t
happen in a year when we"d planned to get and deploy a major set
of hardware٫ such as the year when we got the hardware for <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">our
current generation of fileservers</a>.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/links/CodeOnlySaysWhatItDoes', 'Link: Code Only Says What it Does', '1593733785000',  14, '<div class="wikitext"><p>Marc Booker"s <a href="https://brooker.co.za/blog/2020/06/23/code.html">Code Only Says What it Does</a> (<a href="https://lobste.rs/s/efrg4x/code_only_says_what_it_does">via</a>) is about
what code doesn"t say and why all of those things matter. Because
I want you to read the article٫ I"m going to quote all of the first
paragraph:</p>

<blockquote><p>Code says what it does. That"s important for the computer٫ because
code is the way that we ask the computer to do something. It"s OK for
humans٫ as long as we never have to modify or debug the code. As soon
as we do٫ we have a problem. Fundamentally٫ debugging is an exercise
in changing what a program does to match what it should do. It
requires us to know what a program should do٫ which isn"t captured in
the code. Sometimes that"s easy: What it does is crash٫ what it should
do is <em>not crash</em>. Outside those trivial cases٫ discovering intent is
harder.</p>
</blockquote>

<p>This is not an issue that"s exclusive to programming٫ as I"ve written
about in <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ConfigMgmtIsNotDocumentation">Configuration management is not documentation٫ at least
not of intentions</a>
(<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ProceduresAreNotDocumentation">procedures and checklists and runbooks aren"t documentation
either</a>). In computing
we love to not write documentation٫ but not writing down our
intentions in some form is just piling up future problems.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSAdminVsFilesystemLayout', 'In ZFS٫ your filesystem layout needs to reflect some of your administrative structure', '1593658735000',  14, '<div class="wikitext"><p>One of the issues we sometimes run into with ZFS is that ZFS
essentially requires you to reflect your administrative structure
for allocating and reserving space in how you lay out ZFS filesystems
and filesystem hierarchies. This is because <strong>in ZFS٫ all space
management is handled through the hierarchy of filesystems</strong> (and
perhaps in having multiple pools). If you want to make two separate
amounts of space available to two separate sets of filesystems (or
collectively reserved by them)٫ either they must be in different
pools or they must be under different dataset hierarchies within
the pool.</p>

<p>(These hierarchies don"t have to be visible to users٫ because you can
mount ZFS filesystems under whatever names you want٫ but they exist in
the dataset hierarchy in the pool itself and you"ll periodically need to
know them٫ because some commands require the full dataset name and don"t
work when given the mount point.)</p>

<p>That sounds abstract٫ so let me make it concrete. Simplifying only
slightly٫ our filesystems <a href="https://support.cs.toronto.edu/">here</a>
are visible to people as <code>/h/NNN</code> (for home directories) and <code>/w/NNN</code>
(<em>workdirs</em>٫ for everything else). They come from some NFS server
and live in some ZFS pool there (inside <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSOurContainerFilesystems">little container filesystems</a>)٫ but the NFS server and to some extent
the pool is an implementation detail. Each research group has its
own ZFS pool (or for big ones٫ more than one pool because one pool
can only be so big)٫ as do some individual professors. However٫
there are not infrequently cases where a professor in a group pool
would like to <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/HowWeSellStorage">buy extra space</a> that
is only for their students٫ and also this professor has several
different filesystems in the pool (often a mixture of /h/NNN homedir
filesystems and /w/NNN workdir ones).</p>

<p>This is theoretically possible in ZFS٫ but in order to implement
it ZFS would force us to put all of a professor"s filesystems under
a sub-hierarchy in the pool. Instead of the current tank/h/100 and
tank/w/200٫ they would have to be something like tank/prof/h/100
and tank/prof/w/200. The ZFS dataset structure is required to reflect
the administrative structure of how people buy space. One of the
corollaries of this is that you can basically only have a single
administrative structure for how you allocate space٫ because a
dataset can only be in one place in the ZFS hierarchy.</p>

<p>(So if two professors want to buy space separately for their filesystems
but there"s a filesystem shared between them (and they each want it to
share in their space increase)٫ you have a problem.)</p>

<p>If there were sub-groups of people who wanted to buy space collectively٫
we"d need an even more complicated dataset structure. Such sub-groups
are not necessarily decided in advance٫ so we can"t set up such a
hierarchy when the filesystems are created; we"d likely wind up
having to periodically modify the dataset hierarchy.  Fortunately
the manpages suggest that "<code>zfs rename</code>" can be done without
disrupting service to the filesystem٫ provided that the mountpoint
doesn"t change (which it wouldn"t٫ since we force those to the
/h/NNN and /w/NNN forms).</p>

<p>While our situation is relatively specific to <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/HowWeSellStorage">how we sell space</a>٫ people operating ZFS can run into
the same sort of situation any time they want to allocate or control
collective space usage among a group of filesystems. There are
plenty of places where you might have projects that get so much
space but want multiple filesystems٫ or groups (and subgroups) that
should be given specific allocations or reservations.</p>

<p>PS: One reason not to expose these administrative groupings to users
is that they can change. If you expose the administrative grouping in
the user visible filesystem name and where a filesystem belongs shifts٫
everyone gets to change the name they use for it.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSHierarchyQuotaLack', 'The unfortunate limitation in ZFS filesystem quotas and refquota', '1593569847000',  14, '<div class="wikitext"><p>When ZFS was new٫ the only option it had for filesystems quotas was
the <code>quota</code> property٫ which <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSSnapshotQuota">I had an issue with</a>
and which caused us practical problems in <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetup">our first generation
of ZFS fileservers</a> because it covered the space
used by snapshots as well as the regular user accessible filesystem.
Later ZFS introduced the <code>refquota</code> property٫ which did not have
that problem but in exchange doesn"t apply to any descendant datasets
(regardless of whether they"re snapshots or regular filesystems).
At one level this issue with <code>refquota</code> is fine٫ because we put
quotas on filesystems to limit their maximum size to what our backup
system can comfortably handle. At another level٫ this issue impacts
how we operate.</p>

<p>All of this stems from a fundamental lack in ZFS quotas٫ which is
ZFS"s general quota system doesn"t let you limit space used only
by unprivileged operations. Writing into a filesystem is a normal
everyday thing that doesn"t require any special administrative
privileges٫ while making ZFS snapshots (and clones) requires special
administrative privileges (either from being <code>root</code> or from having
had them specifically delegated to you). But you can"t tell them
apart in a hierarchy٫ because ZFS only you offers the binary choice
of ignoring all space used by descendants (regardless of how it
occurs) or ignoring none of it٫ sweeping up specially privileged
operations like creating snapshots with ordinary activities like
writing files.</p>

<p>This limitation affects our pool space limits٫ because we use them
for two different purposes; <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/HowWeSellStorage">restricting people to only the space
that they"ve purchased</a> and <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSGuaranteeFreeSpace">insuring
that pools always have a safety margin of space</a>.
Since pools contain <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ManyNFSFilesystemsWhy">many filesystems</a>٫
we must limit their total space usage using the <code>quota</code> property.
But that means that any snapshots we make for administrative purposes
consume space that"s been purchased٫ and if we make too many of
them we"ll run the pool out of space for completely artificial
reasons. It would be better to be able to have two quotas٫ one for
the space that the group has purchased (which would limit only
regular filesystem activity) and one for our pool safety margin
(which would limit snapshots too).</p>

<p>(This wouldn"t completely solve the problem٫ though٫ since snapshots
still consume space and if we made too many of them we"d run a pool
that should have free space out of even its safety margin. But it would
sometimes make things easier.)</p>

<p>PS: I thought this had more of an impact on our operations and the
features we can reasonable offer to people٫ but the more I think
about it the more it doesn"t. Partly this is because we don"t make
much use of snapshots٫ though٫ for various reasons that sort of
boil down to "the natural state of disks is usually full". But
that"s for another entry.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSHierarchyQuotaLack?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusBlackboxVsAddTrust', 'How Prometheus Blackbox"s TLS certificate metrics would have reacted to AddTrust"s root expiry', '1593485594000',  14, '<div class="wikitext"><p>The last time around I talked about <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusBlackboxTLSExpiry">what Blackbox"s TLS certificate
expiry metrics are checking</a>٫ but it
was all somewhat abstract. <a href="https://www.agwa.name/blog/post/fixing_the_addtrust_root_expiration">The recent AddTrust root expiry</a>
provides a great example to make it concrete. As a quick summary٫
the <a href="https://github.com/prometheus/blackbox_exporter">Blackbox exporter</a>
provides two metrics٫ probe_ssl_earliest_cert_expiry for the
earliest expiring certificate and
probe_ssl_last_chain_expiry_timestamp_seconds for the latest
expiring verified chain of certificates.</p>

<p>If your TLS server included the expiring AddTrust root certificate
as one of the chain certificates it was providing to clients٫ the
probe_ssl_earliest_cert_expiry metric would have counted down
and your alarms would have gone off٫ despite the fact that your
server certificate itself wasn"t necessarily expiring. This would
have happened even if the AddTrust certificate wasn"t used any more
and its inclusion was just a vestige of past practices (for example
if you had a "standard certificate chain set" that everything
served). In this case this would have raised a useful alarm٫ because
the mere presence of the AddTrust certificate in your server"s
provided chain caused problems in some (or many) TLS libraries
and clients.</p>

<p>(Browsers were fine٫ though.)</p>

<p>Even if your TLS server included the AddTrust certificate in its
chain and your server certificate could use it for some verified
chains٫ the probe_ssl_last_chain_expiry_timestamp_seconds would
not normally have counted down. Most or perhaps all current server
certificates could normally be verified through another chain that
expired later٫ which is what matters here. If
probe_ssl_last_chain_expiry_timestamp_seconds had counted down
too٫ it would mean that your server certificate could only be
verified through the AddTrust certificate for some reason.</p>

<p>Neither metric would have told you if the AddTrust certificate was
actually being used by your server certificate through some verified
chain of certificates٫ or if it was now completely unnecessary.
Blackbox"s TLS metrics don"t currently provide any way of knowing
that٫ so if you need to monitor the state of your server certificate
chains you"ll need another tool.</p>

<p>(There"s a third party <a href="https://github.com/ribbybibby/ssl_exporter">SSL exporter</a>٫ but I don"t think it
does much assessment of chain health٫ or give you enough metrics
to know if a server provided chain certificate is unnecessary.)</p>

<p>If you weren"t serving the AddTrust root certificate and had a
verified chain that didn"t use it٫ but some clients required it to
verify your server certificate٫ neither Blackbox metric would have
warned you about this. Because you weren"t serving the certificate٫
probe_ssl_earliest_cert_expiry would not have counted down; it
includes only TLS certificates you actually serve٫ not all of the
TLS certificates required to verify all of your currently valid
certificate chains. And probe_ssl_last_chain_expiry_timestamp_seconds
wouldn"t have counted down because there was an additional verified
chain besides the one that used the AddTrust root certificate.</p>

<p>(In general it"s very difficult to know if some client is going to
have a problem with your certificate chains٫ because there are many
variables. Including outright programming bugs٫ which were part of
the problem with AddTrust. If you want to be worried٫ read Ryan
Sleevi"s <a href="https://medium.com/@sleevi_/path-building-vs-path-verifying-implementation-showdown-39a9272b2820">Path Building vs Path Verifying: Implementation Showdown</a>.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusBlackboxVsAddTrust?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/python/DjangoAppAdaptations', 'Adapting our Django web app to changing requirements by not doing much', '1593407387000',  14, '<div class="wikitext"><p>We have <a href="https://utcc.utoronto.ca/~cks/space/blog/python/DjangoORMDesignPuzzleII">a Django web application to handle (Unix) account requests</a>٫ which is now nine years old. I"ve called
this <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/ProductAndUtilityCode">utility code</a>٫ but I
<a href="https://utcc.utoronto.ca/~cks/space/blog/python/DjangoIsProductCode">mentioned recently</a> that over that time there
have been some changes in how graduate students were handled that
needed some changes in the application. Except not very much change
was necessary٫ in some ways٫ and in other ways the changes are
hacks. So here are some stories of those changes.</p>

<p>When we (I) initially wrote the web application٫ our model of how
new graduate students got Unix accounts was straightforward. All
graduate students were doing a thesis (either a Masters or a PhD)
and so all of them have a supervising professor. As a long standing
matter of policy٫ that supervisor was their <em>account sponsor</em>٫ and
so approved their account request. Professors can also sponsor
accounts for other people associated with them٫ such as postdocs.</p>

<p>(This model already has a little glitch; some students are co-supervised
by more than one professor. Our system requires one to be picked as the
account sponsor٫ instead of somehow recording them as co-sponsored٫
which has various consequences that no one has complained about so far.)</p>

<p>The first change that showed up was that <a href="https://www.cs.toronto.edu/">the department</a> developed a new graduate program٫ the
<a href="https://mscac.utoronto.ca/">Master of Science in Applied Computing</a>.
Graduate students in the MScAC program don"t write a thesis and as
a result they don"t have a supervising professor. As it happened٫
we already had a model for solving this٫ because Unix accounts for
administrative and technical staff are not sponsored by professors
either; they have special non-professor sponsors. So we added another
such special sponsor for MScAC students. This was not sufficient by
itself٫ because the account request system sometimes emails new
graduate students and the way those messages were written assumed
that the student"s sponsor was supervising them.</p>

<p>Rather than develop a general solution to this٫ we took the brute
force solution of an "{% if ...}" condition in the relevant Django
template. Because of how our data is set up٫ this condition both
has to reach through several foreign keys and uses a fixed text
match against a magic name٫ instead of checking any sort of flag
or status marker (because no such status marker was in the original
data model). Fortunately the name it matches against is not exposed
to people٫ because the official name for the program has actually
changed over time but our internal name has never been updated
(partly because it was burned into the text template). This is a
hack٫ but it works.</p>

<p>The second change is that while all graduate students must eventually
get a specific supervisor٫ not all of them have one initially when they
arrive. In particular٫ there is one research group that accepts most
new graduate students collectively and then sorts out who they will be
supervised later٫ once the graduate students know more about the group
and their own interests. In the past٫ this had been solved artificially
by assigning nominal sponsors immediately even if they weren"t going to
be the student"s supervisor٫ but eventually the group got tired of this
and asked us to do better. The solution here was similar to the
MScAC program (and staff accounts); we invented a synthetic "supervisor"
for them٫ with a suitable generic name. Unlike with the MScAC program٫
we didn"t customize the Django templates for this new situation٫ and
unfortunately the result does look a little ugly and awkward.</p>

<p>(This is where a general solution would have been useful. If we
were templating this from a database table or the like٫ we could
have just added a new entry for this general research group case.
Adding another Django "{% if ...}" to the template would have made
it too tangled٫ so we didn"t.)</p>

<p>I don"t think we did anything clever in our Django application"s
code or its data model. A lot of the changes we were able to make
were inherent in having a system that was driven by database tables
and being able to add relatively arbitrary things to those tables
(with some hacks involved). Where our changes start breaking down
is exactly where the limitations of that start appearing٫ such as
multiple cases in templates when we didn"t design that into the
database.</p>

<p>(Could we have added it later? Perhaps. But I"ve always been too
nervous about database migrations to modify our original database
tables٫ partly because I"ve never done one with Django. This is a
silly fear and in some ways it"s holding back the evolution of our
web application.)</p>

<p>PS: You might think that properly dealing with the co-supervision
situation would make the research group situation easy to deal with٫
by just having new graduate students "co-sponsored" by the entire
research group. It"s actually not clear if this is the right answer٫
because the situations are somewhat different on the Unix side.
When you actively work with a supervisor٫ you normally get added
to their Unix group so you can access group-specific things (if
there are any)٫ so for co-supervisors you should really get added
to the Unix groups for both supervisors. However٫ it"s not clear
if people collectively sponsored by a research group should be added
to every professor"s Unix group in the same way. This implies that
the Django application should know the difference between the two
cases so that it can signal our Unix account creation process to
treat them differently.</p>

<h3>Sidebar: Our name hack for account sponsors</h3>

<p>When someone goes to our web page to request an account٫ they have
to choose their sponsor from a big &lt;select> list of them. The list
is sorted on the sponsor"s last name٫ to make it easier to find.
The idea of "first name" and "last name" is somewhat tricky (as is
their order)٫ and automatically picking them out from a text string
is even harder. So we deal with the problem the other way around.
Our Django data model has a "first name" and a "last name" field٫
but what they really mean is "optional first part of the name" and
"last part of the name (that will determine the sort order)".</p>

<p>As part of this٫ the synthetic account sponsors generally don"t
have a "first name"٫ because we want them to sort in order based
on the full description (such as "MScAC Graduate Student"٫ which
sorts in M not G or S).</p>

<p>(Sorting on "last name" is somewhat arbitrary٫ but part of it is that we
expect people requesting accounts to be more familiar with the last name
of their sponsor than the first name.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/python/DjangoIsProductCode', 'Understanding why Django"s goals are not our goals for our web application', '1593317145000',  14, '<div class="wikitext"><p>A while back I wrote about how <a href="https://utcc.utoronto.ca/~cks/space/blog/python/DjangoGoalsNotOurGoals">Django"s goals are probably not
our goals for our web application</a>٫ but at
the time٫ I didn"t have a succinct way of talking about why this was
the case.  Recently I wrote about a realization I"d come to about
<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/ProductAndUtilityCode">product code and utility code</a>٫
where product code is used as part of delivering your business but
utility code sits in the background doing other things. That
realization gives me a better way to talk about Django and us.</p>

<p>Right from its beginning as a newspaper"s publishing platform٫
<a href="https://www.djangoproject.com/">Django</a> has been product code and
been used for product code. Probably most large sized Python projects
(such as <a href="https://twistedmatrix.com/">Twisted</a>) see themselves
this way and are often used this way٫ with people building big
projects that support the business on top of them (after all٫ you
rarely build big projects if you don"t need them). As direct and
indirect product code٫ Django is constantly evolving as the needs
of people"s businesses pull it in various directions. Django mostly
has good API stability٫ but this stability is to enable people with
product code that use Django to move faster.</p>

<p><a href="https://utcc.utoronto.ca/~cks/space/blog/python/DjangoORMDesignPuzzleII">Our Django based Unix account request handling system</a> is not product code٫ it"s utility code.
The business rules and processes for authorizing new accounts are
set by policies that are extremely stable٫ and <a href="https://www.cs.toronto.edu/">the department</a> doesn"t operate in a way where we
suddenly change the sort of accounts that we set up. How the
department teaches and what sort of programs it offers have changed
(although slowly)٫ but that"s as far as it goes.</p>

<p>(Looking back٫ there actually have been some modest policy changes
about some aspects of incoming graduate students. We"ve patched
around these in the account request system in some simple ways٫
which is actually an interesting story of flexibility and adaptation.
But the fundamental ideas of who can have an account here and who
decides that haven"t changed. University departments are like that٫
and unlike businesses.)</p>

<p>As we"ve found out٫ basing utility code on top of product code is
not a great path to happiness. This isn"t really surprising since
the two are pulling in different directions; utility code wants to
be static٫ while product code needs to evolve as business activities
do. Django has done a good job of being stable (in its API) despite
that٫ but there is still work to keep up with it (beyond the shift
to Python 3)٫ and that work is not what utility code wants.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/NetworkManagerConnectionConflict', 'NetworkManager and (not) dealing with conflicting network connections', '1593225734000',  14, '<div class="wikitext"><p>I recently tweeted <a href="https://twitter.com/thatcks/status/1275799821199249409">a wish for NetworkManager</a>:</p>

<blockquote><p>I wish there was some straightforward way to tell NetworkManager to
not automatically connect to any wifi networks if my laptop has a
wired network connection٫ while still auto-connecting if there is no
wired Ethernet.</p>
</blockquote>

<p>In NetworkManager you can set a priority for network connections٫
but as far as I can tell you can"t tell it that two connections
conflict with each other and should never be brought up at the same
time. You can write scripts that run when connections change and
that take down connections (on Twitter <a href="https://twitter.com/zigford_org/status/1276070144930766848">@zigford</a> pointed
me to a script for this <a href="https://zigford.org/precision-5510---gentoo-gnulinux.html">here</a>)٫ but I
don"t consider this straightforward. So let me give you the story of
how I have wound up wanting this.</p>

<p>I have <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/DellXPS13FedoraReview">a work laptop</a>٫ which I"ve brought
home periodically for short periods of light use in the past (for
example over our Christmas vacations). At that point I set it up
for wireless networking and to automatically connect to my home
wireless for convenience. Then٫ thanks to <a href="https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic">current world and local
events</a>٫ I
took my work laptop home for extended use over a longer period٫ and
soon discovered that my home wireless network has surprisingly high
and variable latency. Fortunately I"d also taken the laptop"s USB
Ethernet adapter and I have a little home switch٫ so I could change
over to having my laptop use a wired connection (although <a href="https://twitter.com/thatcks/status/1247567034596147201">not
without fun discoveries</a>).</p>

<p>As it happens٫ I don"t have two home subnets٫ one wired and one
wireless; I have one that everything is on (and the AP just extends
it out from wired to wireless). When I initially set up my laptop
at home on the wireless٫ I gave it a fixed IP address and name so
that I could easily SSH to it (and because I give everything here
a fixed IP address). When I "switched" my laptop to using a wired
connection٫ I gave that wired Ethernet address the same fixed IP
address٫ because I had no desire to have to SSH to "laptop-wired"
versus "laptop-wifi" (I just want to SSH to "laptop"). Unfortunately
this means that if both the wired and the wireless connections are
active at once٫ both get the same IP and then fun things happen.
Especially٫ some of my traffic to my laptop goes over the wireless٫
with increased and variable latencies٫ which is what I set up a
wired connection to avoid.</p>

<p>(I"m honestly surprised that my DHCP server didn"t object to handing
out the same IP at once to two different things٫ but then I did
tell it that both the wired and the wireless Ethernet addresses
could have the same IP. I"m also surprised at how long it took me
to notice this; I only did because I was running "ifconfig -a" for
another reason and noticed that my wifi adapter had an IP assigned.)</p>

<p>My current solution is to tell NetworkManager to not automatically
connect to my home wireless network. This is less convenient if I
want to use my work laptop from somewhere else٫ but in practice I
almost never do (my work laptop is mostly used for video conferencing٫
since it has a camera and a microphone; actual work happens from
my home desktop).</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/NetworkManagerConnectionConflict?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusBlackboxTLSExpiry', 'What Prometheus Blackbox"s TLS certificate expiry metrics are checking', '1593143536000',  14, '<div class="wikitext"><p>One of the things that the <a href="https://github.com/prometheus/blackbox_exporter">Prometheus Blackbox exporter</a> can do is connect
to services that use TLS and harvest enough certificate information
from them to let you monitor and alert on soon to expire TLS
certificates. Traditionally٫ this was a single metric٫
probe_ssl_earliest_cert_expiry٫ but in <a href="https://github.com/prometheus/blackbox_exporter/releases/tag/v0.17.0">the 0.17.0 release</a> a
second one was added٫ probe_ssl_last_chain_expiry_timestamp_seconds.
TLS certificate expiry issues have been on my mind because of <a href="https://www.agwa.name/blog/post/fixing_the_addtrust_root_expiration">the
mess from the AddTrust root expiry</a>٫ and
recently I read a pair of articles by Ryan Sleevi on <a href="https://medium.com/@sleevi_/path-building-vs-path-verifying-the-chain-of-pain-9fbab861d7d6">TLS certificate
path building and verifying</a>
(<a href="https://medium.com/@sleevi_/path-building-vs-path-verifying-the-chain-of-pain-9fbab861d7d6">part 2</a>)٫
which taught me that this issue isn"t at all simple. After all this٫
I wound up wondering exactly what these two Blackbox exporter metrics
were checking.</p>

<p>When you connect to a TLS server٫ it sends one or more certificates
to you٫ generally at least two٫ in what is commonly called a
<em>certificate chain</em>. These server sent certificates don"t include
the Certificate Authority"s root certificate٫ because you need to
already have that٫ and they don"t actually have to form a single
chain or even be related to each other. Normally they should be a
chain (and <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SSLChainOrder">be in a specific order</a>)٫ but
people make all sorts of configuration errors and decisions in the
certificates that they send. The Blackbox exporter"s
probe_ssl_earliest_cert_expiry metric is the earliest expiry
of any of these server sent certificates. I"m not certain if it"s
filtered of invalid certificates٫ but it definitely doesn"t exclude
self-signed certificates.</p>

<p>(Specifically٫ it is the earliest expiry of a certificate in the
Go <a href="https://golang.org/pkg/crypto/tls/#ConnectionState">crypto.tls.ConnectionState</a>"s <code>PeerCertificates</code>.)</p>

<p>When you actually verify a TLS certificate (if you do it correctly) you
wind up with one or more valid paths between the server certificate and
some roots of trust; we can call these the <em>verified chains</em>. These
chains will use the server certificate that the server sent you٫ but
they may not use all or even any of the other certificates. To work
out the probe_ssl_last_chain_expiry_timestamp_seconds metric٫ the
Blackbox exporter first goes over every verified chain to find out the
earliest expiry time of any certificate in it and the picks the latest
such chain expiry time. These verified chains do include the CA root
certificates٫ which don"t necessarily expire regardless of their nominal
expiry time. If there are no verified chains at all٫ such as if you"re
dealing with a self-signed certificate٫ the Blackbox exporter currently
makes this metric be an extremely large and useless negative number.</p>

<p>(The verified chains come from the Go <a href="https://golang.org/pkg/crypto/tls/#ConnectionState">crypto.tls.ConnectionState</a>"s
<code>VerifiedChains</code>. If there are no verified chains٫ the metric is
the zero value of Go"s <a href="https://golang.org/pkg/time/#Time">time.Time</a>
turned into a time in the Unix epoch. Since this zero value is more
than a thousand years before January 1st 1970 UTC٫ it winds up very
negative. This is potentially a bug and may change someday.)</p>

<p>Normally there will always be a verified chain٫ because otherwise
the Blackbox TLS probe would fail entirely. You have to specifically
set insecure_skip_verify to true in the Blackbox configuration
in order to accept self-signed certificates or other chain problems.</p>

<p>So what do these metrics mean٫ beyond their technical details? If the
earliest certificate expiry is soon٫ it doesn"t necessarily mean that
your TLS server certificate itself is about to expire٫ but it does mean
that some TLS certificate your server is providing to people is about
to. Either you"re serving an unnecessary intermediate TLS certificate٫
or some number of your users are about to have a problem. Either is
an issue that you should fix٫ especially since an expired certificate
that"s not necessary may still make many TLS libraries fail to verify
your server certificate.</p>

<p>(This is part of <a href="https://www.agwa.name/blog/post/fixing_the_addtrust_root_expiration">what happened with the AddTrust expiry</a>.
A surprisingly large number of TLS libraries had to be patched
to just skip it.)</p>

<p>The last chain expiry is the point at which you definitely will
have problems٫ because no one at all will be able to build a verified
chain for your server certificate. A last chain expiry that"s well
into the future is not a guarantee that you"ll be free of problems
until then٫ unless you know that there"s only one valid chain that
can be formed from your server certificate. If there are multiple
chains٫ not all clients may able to use all chains so some of them
could be stuck on chains that might expire earlier. The Blackbox
exporter doesn"t currently have a metric for the earliest expiring
verified chain٫ but perhaps it should.</p>

<p>(Normally all verified certificate chains will have the same expiry
time٫ because the shortest lifetime certificate on them should be
the server"s certificate itself. If there are multiple chains and
there"s a difference between the latest and the earliest chain
expiry time٫ you may be about to have an exciting time (although
it"s not your fault).)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/unix/FilesystemStatDeviceProblem', 'Unix"s design issue of device numbers being in stat() results for files', '1593050647000',  14, '<div class="wikitext"><p>Sometimes٫ you will hear the view that Unix"s design is without
significant issues٫ especially the "pure" design of Research Unix
(before people who didn"t really understand Unix like Berkeley and
corporate AT&amp;T got their hands on it). Unfortunately that is not
the case٫ and there are some areas where Research Unix made decisions
that still haunt us to this day. For reasons beyond the scope of
this entry٫ today"s example is that part of the file attributes
that you get from <a href="https://man.openbsd.org/stat.2"><code>stat()</code></a> system
call and its friends is the "device number" of the filesystem the
file is on.</p>

<p>(To be specific٫ this is the <code>st_dev</code> field of the <code>struct stat</code>
that <code>stat()</code> returns٫ which has been since <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/include/sys/stat.h">V7"s stat.h</a>.
The <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V6/usr/man/man2/stat.2">V6 stat()</a> was
even more explicit about what it was returning.)</p>

<p>In Unix٫ the user level file attributes you get back need some kind
of locally unique identifier for the filesystem that the file is
on٫ so the presence of some identifier is not a mistake. The
identifier being different between two files is how you detect
things like that you"re at a filesystem mount point٫ that you can"t
use <a href="https://man.openbsd.org/link.2"><code>link()</code></a>٫ or that two otherwise
identical looking files are not actually hardlinked together because
they"re on different filesystems. It"s also useful to have an
identifier that can be matched up with things like a list of mounted
filesystems.</p>

<p>However٫ early Unixes didn"t make this merely some identifier٫ they
made this specifically the device number of the underlying disk
device that the filesystem was mounted from (hence its name as
"<code>st_dev</code>"). This had the unfortunate consequence of permanently
joining two logically separate identifier namespaces٫ the namespace
of (mounted) filesystems and the namespace of block devices.</p>

<p>Now٫ 40 odd years later٫ we have plenty of Unix filesystems that
don"t have underlying block devices (especially singular ones).
Anything mounted using one of these filesystems needs to somehow
make up a "device number" for itself٫ and this device number can"t
be the same as any real block device. This generally requires Unixes
to carve out a section of their overall block device numbers that"s
reserved for filesystems to do this with٫ in other words things
that aren"t actually block devices. Fortunately modern Unixes have
generally made the namespace of device numbers be much larger than
it used to be.</p>

<p>(Then because device numbers for block devices are generally stable٫
a certain amount of software expects the "device number" returned as
part of file attributes to also be stable٫ for any arbitrary filesystem.
When the kernel and a filesystem has to make this number up on the fly٫
this is not always the case.)</p>

<p>At the same time٫ this is a good design for V7 itself٫ in the time and
the context. V7 and its kernel were intended to be a small system٫ and
in a small system you don"t want to go doing extra work unless you
absolutely have to٫ especially in the kernel. V7 could reuse the device
number to be the filesystem identifier essentially for free٫ so that"s
what it did.</p>

<p>(V7"s kernel took any number of shortcuts in the interests of having
a simple implementation. For instance٫ a lot of things were stored
in small fixed-sized arrays٫ because you would never have more than
a modest number of processes٫ open files٫ or so on.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/web/PeopleShowYouSiteFlaws', 'Sometimes it takes other people to show you some of your site"s design flaws', '1592969714000',  14, '<div class="wikitext"><p>Recently٫ I wrote an entry about <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/Go2GenericsExpectedEfficiency">people"s efficiency expectations
for generics in Go</a>٫
and also wound up having a little discussion in the comments of
that entry. The r/golang reddit <a href="https://old.reddit.com/r/golang/comments/hcce4e/peoples_efficiency_expectations_for_generics_in/">linked to my entry</a>٫
so I read it٫ and one thing I noticed was that one of the people
commenting probably didn"t realize that the entry and my comment
on it had been written by the same person.</p>

<p>My first reaction was uncharitable٫ but then I put myself in that
commentator"s shoes and had a rather more humbling reaction. Looking
at it from the outside٫ right now there"s no particularly obvious
sign in how I display comments here that the "cks" who left a comment
is in fact the author of the entry. There are contextual clues (for
example "cks" appears in several places around <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>٫ including the URL and <a href="https://mastodon.social/@cks">my Fediverse link</a>)٫ but there"s nothing that says it
clearly. Even my name is not directly visible on the comment; I
hide it behind an &lt;abbr> element with a title٫ which is not obvious
at the best of times and is <a href="https://utcc.utoronto.ca/~cks/space/blog/web/HTMLAbbrAndMobileBrowsers">probably completely invisible on
mobile browsers</a>٫ something I didn"t
know until yesterday.</p>

<p>(Because I"m likely to change how comments are displayed٫ right now
the comment authorship for me looks like "By <abbr title="Chris Siebenmann">cks</abbr> at ...". The "cks" is the &lt;abbr>٫ if it doesn"t show
in your browser.)</p>

<p>Obviously I should do something about this specific flaw in how
<a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a> (the wiki engine underlying <a href="https://utcc.utoronto.ca/~cks/space/blog/">this blog</a>) displays
comments written by myself٫ although I haven"t decided exactly how
it should look. But this is also a useful general lesson in how
flaws in our own designs can linger until someone points them out٫
and also on how the flaws may not be pointed out in an obvious and
explicit way. Any time you wind up thinking "how could someone not
see that?" about some aspect of your website٫ you should probably
step back and take a serious attempt at figuring out why. There
may be a good reason.</p>

<p>(This can be extended to more than websites. Over time٫ I"ve learned
that when people miss something or misunderstand what I"ve written
here٫ often I haven"t quite written what I thought I did. I"ve
assumed too much background٫ or I haven"t written out what was
obvious in my head٫ or I"ve cut some corners.  It all looked good
to me in reading it over before posting٫ because I knew what I was
talking about٫ but other people don"t. I"ve seen similar issues
come up when I put together <a href="https://grafana.com/">Grafana</a>
dashboards for <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">our monitoring setup</a>; I knew what they were
saying and how to read them٫ but my co-workers didn"t and so couldn"t
follow the morass.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/web/HTMLAbbrAndMobileBrowsers', 'Today I learned that HTML &lt;abbr> may not do much on mobile browsers', '1592882210000',  14, '<div class="wikitext"><p>For some time٫ I"ve been using HTML &lt;abbr> elements with <code>title</code>
attributes in my writing here on <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>.
Sometimes I use it purely to provide a friendly expansion of
abbreviations٫ like a TLS <abbr title="Certificate Authority">CA</abbr> or
<abbr title="Man In The Middle (attack)">MITM</abbr>; sometimes the expansion
acquires some additional commentary٫ such as the mention of &lt;abbr>
itself in <a href="https://utcc.utoronto.ca/~cks/space/blog/web/HTMLDetailsWikiProblem">this entry</a>٫ and sometimes I
use it for little asides. In a couple of contexts I use it to provide
additional information; for example٫ any of my comments here
(currently) say that they are "by <abbr title="Chris Siebenmann">cks</abbr>"٫
where the &lt;abbr> is used to add my name.</p>

<p>Today I had a reason to look at some of my pages that are using
&lt;abbr> in a mobile browser٫ specifically the iOS mobile browser.
That was when I learned that iOS Safari doesn"t render &lt;abbr> in
any visible way٫ which is fairly reasonable because there"s no real
way to interact with it; on desktops٫ an &lt;abbr>"s title is shown
when you hover the mouse over it٫ but on mobile there"s no hover.
This is a bit surprising because both <a href="https://developer.mozilla.org/en/docs/Web/HTML/Element/abbr">MDN"s &lt;abbr> page</a> and
<a href="https://caniuse.com/#feat=mdn-html_elements_abbr">CanIUse</a> currently
say that it"s fully supported on mobile browsers.</p>

<p>Once I started doing Internet searches it appears that this is a
long standing issue and unlikely to change (because of the hover
problem). There are various workarounds with both CSS and JavaScript٫
but I"m not certain I like any of them٫ especially with how I"ve
historically used &lt;abbr> here; some of my &lt;abbr> usage would look
very out of place if displayed inline in some way. Given that a
decent amount of browsing comes from mobile these days٫ this is
likely going to cause me to rethink how I use &lt;abbr> here on
<a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a> and likely use it a lot less٫ if at
all. Probably a lot more terms will wind up as actual links to
explanations of them٫ which is not necessarily a bad change overall.</p>

<p>This is a useful lesson to me that the web٫ and especially the
mobile web٫ is an ongoing learning experience. Things that I think
I know should be tested every so often٫ and I should look at my own
sites in a mobile browser more often.</p>

<p>(As part of this٫ I should find out if there"s a not too annoying
and difficult way to look at and interact with my sites from an
Android browser٫ despite not having any Android devices myself.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/HTMLAbbrAndMobileBrowsers?showcomments#comments">5 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoValueCopyIsTyped', 'In Go٫ the compiler needs to know the types of things when copying values', '1592791194000',  14, '<div class="wikitext"><p>If Go implements generics (which seems likely to happen someday)٫
there will be a lot of interesting generic functions that don"t
need to do much more with the specific types they"re instantiated
with other than copy values around (and often allocate slices and their
backing arrays). The classical map٫ filter٫ and reduce trio all
don"t need to do anything more themselves than copy values٫ and the
same is true for things like making a slice of the keys of a map.
If the compiler is interested in generating only a single set of
code for these generic functions (similar to <a href="https://dave.cheney.net/2018/05/29/how-the-go-runtime-implements-maps-efficiently-without-generics">how maps are implemented</a>)٫
one interesting question is how much it needs to know about the
values being copied around here. In particular٫ does the Go runtime
need to know their type٫ or is it enough to know how big they are
and then just copy the relevant number of bytes with a memory move?</p>

<p>Unfortunately for us٫ the answer is that <strong>the Go runtime needs to
know the types of the values it"s copying</strong>٫ even if it"s only
copying them to already allocated memory. We can discover why by
looking at the source for <a href="https://go.googlesource.com/go/+/refs/heads/master/src/runtime/mbarrier.go#149"><code>runtime.typedmemmove</code></a>.
The short version of why is that if the runtime is currently doing
a garbage collection٫ all Go code needs to take special precautions
when updating pointers. This includes when copying values that are
either pointers or composite types that include pointers. When doing
a bulk memory move٫ the runtime needs to know where the pointers
are in the destination٫ and that requires knowing the type of the
destination.</p>

<p>(For more٫ see <a href="https://go.googlesource.com/go/+/refs/heads/master/src/runtime/mbitmap.go#581"><code>runtime.bulkBarrierPreWrite</code></a>.)</p>

<p>The Go runtime also needs to know the type of things when allocating
memory for them (such as when creating or expanding a slice). This
is because all newly allocated objects must have runtime information
set up so that the Go garbage collector knows where any pointers
in them are (among other things٫ this is <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoUnsafeTypeConvGCSafety">why unsafe type conversions
are still garbage collection safe</a>).
Setting up this information requires knowing the type of what is
being allocated٫ because this information on pointers is in the
type information.</p>

<p>The exception for both copying values and allocating new memory for
them is that if the type contains no pointers٫ I believe that all
the Go runtime needs to know is that and what alignment is required
for values. A generic function could thus potentially be compiled
into a general version for pointer containing types and a narrower
version that only worked for non-pointer types. In practice you
would probably just compile a version that was passed a pointer to
the type information٫ because the type information gives you size٫
alignment٫ and pointer information all in one place with only a
single argument.</p>

<p>(You"ll notice that <a href="https://go.googlesource.com/go/+/refs/heads/master/src/runtime/mbarrier.go#149"><code>runtime.typedmemmove</code></a> is just a <code>memmove()</code>
if the type doesn"t contain any pointers٫ although some of this is
hidden in <a href="https://go.googlesource.com/go/+/refs/heads/master/src/runtime/cgocheck.go#59"><code>runtime.cgoCheckMemmove</code></a>.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DNSUpdatesAndSecondaries', 'The additional complications in DNS updates that secondary DNS servers add', '1592695145000',  14, '<div class="wikitext"><p>I was recently reading Julia Evans" <a href="https://jvns.ca/blog/how-updating-dns-works/">What happens when you update
your DNS? </a> (which
is a great clear explanation of what it says)٫ and it brought back
some painful memories of the old days (which are still the current
days for some people)٫ which I might as well share.</p>

<p>Today٫ most DNS services that people deal with are managed DNS
providers. When you enter a DNS update into your DNS provider"s API
or website for this٫ magical things happen behind the scenes in the
DNS provider"s infrastructure and your update normally goes live
more or less immediately on all of the authoritative DNS servers
involved in answering queries for your domain. In this environment٫
where your changes appear on your authoritative DNS servers effectively
instantly٫ the only thing that matters for how fast your changes
are visible is how long the various recursive DNS servers on the
Internet have cached your existing information٫ as Julia Evans
covers.</p>

<p>However٫ authoritative DNS servers didn"t originally work that way
and even today things don"t necessarily quite work out that way if
you run your own DNS service using straightforward DNS servers like
<a href="https://nlnetlabs.nl/projects/nsd/about/">NSD</a> or the venerable
Bind. The original DNS server environment had the idea of <em>primary</em>
and <em>secondary</em> authoritative DNS servers. The primary DNS servers
got all of the data for your zone from files on their disk (or more
recently perhaps from a database or some network data source)٫ and
the secondary DNS servers got the data for your zone by copying it
from a primary DNS server (possibly one that wasn"t advertised
publicly٫ which is often called a "stealth master")٫ generally with
an <a href="https://en.wikipedia.org/wiki/DNS_zone_transfer">AXFR</a>.
Effectively your secondary authoritative DNS servers were (and are)
a cache.</p>

<p>(You could have multiple primary servers٫ at which point it was up
to you to make sure they were all using the same DNS zone data. The
very simple way to do this was to <code>rsync</code> the data files around to
everyone before having the DNS servers reload zones.)</p>

<p>Any time that you have what is effectively a cache٫ you should be
asking about cache invalidation and refreshing; DNS servers are no
exception. The original answer to this is in the specifications of
<a href="https://en.wikipedia.org/wiki/SOA_record">the DNS SOA record</a>٫
which has (zone) <em>refresh</em>٫ <em>retry</em> (of a failed refresh)٫ and
<em>expire</em> times٫ and a zone serial number so that secondaries could
tell when their copy of the zone was out of date compared to the
DNS primary.  Every refresh interval٫ a secondary would check the
SOA serial number on its primary and fetch an update if necessary.
If it couldn"t talk to the primary for long enough٫ it would declare
the zone stale and stop answering queries from its cached data.</p>

<p>This meant that DNS updates had two timers on their propagation
around٫ once you made them. First they had to propagate from the
primary to all of the secondaries٫ which was based on the SOA refresh
time.  Once all secondaries were answering queries using the new
DNS data٫ recursive DNS servers could still have old queries cached
for up to the query TTL. In the worst case٫ where you make a change
just after a refresh and a recursive DNS server queried your last
secondary just before its refresh timer went off٫ your update might
not reach everyone until the sum of the entry"s TTL and the zone"s
SOA refresh.</p>

<p>(Adding a new DNS record could have a similar delay but here the
first time was the SOA <em>minimum</em> value٫ which in theory set the TTL
for negative replies. More or less.)</p>

<p>Having to wait for secondary DNS servers to hit their refresh timers
to update has various issues. Obviously it slows down DNS updates٫
but it also means that there"s a potentially significant amount of
time when your various authoritative DNS servers are giving different
answers to queries. All of this was recognized relatively early on
and led to <a href="https://tools.ietf.org/html/rfc1996">RFC 1996</a>٫ which
created the DNS NOTIFY mechanism٫ which lets primary servers send
a special DNS NOTIFY message to secondaries.</p>

<p>When you update your primary servers٫ they signal the secondary
servers that a zone change has (probably) happened. Generally the
secondaries will then immediately try to transfer the updated zone
over so they can use it to answer queries. A DNS NOTIFY doesn"t
guarantee that the secondaries are promptly up to date٫ but it makes
it much more likely٫ and there is some protection against the NOTIFY
being dropped in transit between the primary and the secondaries.
In practice this seems to work fairly well٫ especially in network
environments where the primaries and secondaries are close to each
other (in network terms).  However it"s still not guaranteed٫ so
if you have <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">a monitoring system</a>٫
it"s worth having a check for the SOAs on your zones not being out
of sync for too long between your primaries and secondaries.</p>

<p>(DNS providers hopefully have similar internal monitoring.)</p>

<p>Normally your primary DNS server software will automatically send
out DNS NOTIFY messages to appropriate secondary servers if you
tell it to reload things. You can generally manually trigger sending
them even without a zone change or reload; one use of this is making
sure that a particular secondary (or all of them) gets a little
prod to try doing an update.</p>

<p>PS: Since we run our DNS ourselves <a href="https://support.cs.toronto.edu/">here</a>٫ this whole area remains an
issue that we have to think about and remember some aspects of.
But that"s another entry.</p>

<p>PPS: Usually secondary servers have restrictions on who they"ll accept
DNS NOTIFY messages from٫ and I believe the messages can optionally be
authenticated in some way these days.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DNSUpdatesAndSecondaries?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraRemovingMustBeOptIn', 'Removing unmaintained packages from your Fedora machine should require explicitly opting in', '1592621064000',  14, '<div class="wikitext"><p>Ben Cotton recently wrote an entry on <a href="https://funnelfiasco.com/blog/2020/06/18/removing-unmaintained-packages-from-an-installed-system/">Fedora potentially removing
unmaintained packages from your system under some circumstances</a>٫
because there is <a href="https://fedoraproject.org/wiki/Changes/Fedora-Retired-Packages">a Fedora change proposing to remove "retired"
packages</a>.
The change proposal contains the following remarks:</p>

<blockquote><h4>Upgrade/compatibility impact</h4>
<p>During an upgrade٫ all retired packages will be automatically removed.</p>

<p>[...]</p>

<h4>How To Test</h4>
<p>1. Upgrade to next version of Fedora. 2. Check all retired packages
are removed.</p>
</blockquote>

<p>In the ending of Ben Cotton"s article٫ he says in passing "[B]ut
we have to make sure we’re clearly communicating what is happening
to the user" if package removal happens. I will go further than that.</p>

<blockquote><p><strong>Removing packages from your system on Fedora upgrades should require
an explicit opt-in</strong>٫ and this opt-in should be able to show you the
list of packages being removed.</p>
</blockquote>

<p>Going beyond that٫ Fedora should never remove unmaintained packages
from your system without this opt in٫ for example they should never
push out an updated <code>fedora-retired-packages</code> RPM in Fedora updates.</p>

<p>Removing unmaintained packages from people"s systems is removing
functionality with no replacement or equivalent. This can break what
people are doing with their Fedora machines٫ and doing so is both
morally wrong and dangerous in practice. It doesn"t take too many cases
of Fedora upgrades or Fedora package updates breaking things without
warning for people to stop doing either of them.</p>

<p>Because this requires explicit user opt-in and a UI and so on٫ and
additional unmaintained packages should not be removed during the
lifetime of a Fedora release٫ I think that removing retired packages
during upgrades should live in the upgrader٫ not be implemented as
an RPM package (or at least not as an RPM package that"s installed
by default). The upgrade system is the only place that is in a
position to actively prompt the user in a meaningful way to obtain
explicit٫ informed opt-in consent to this.</p>

<p>(The lightweight version of this would be to require people to opt in in
advance by installing the special <code>fedora-retired-packages</code> RPM. People
who know enough to manually select and install the package can be
presumed to know what they"re doing and be making an informed choice to
accept whatever package retirements Fedora wants to push.)</p>

<p>PS: I was going to consider this different from the existing situation
with fedora-obsolete-packages for various hand-waving reasons٫ but
the more I look at what packages Fedora has removed through the
fedora-obsolete-packages RPM٫ the more I think that the two should be
mostly merged together and treated very similarly (ie٫ require explicit
opt-in). The current fedora-obsolete-packages goes well beyond merely
removing packages that cause upgrade problems (unless you take a rather
expansive view of "upgrade problems").</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/FedoraRemovingMustBeOptIn?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/Go2GenericsExpectedEfficiency', 'People"s efficiency expectations for generics in "Go 2" and patterns of use', '1592540727000',  14, '<div class="wikitext"><p>The Go authors have recently come out with <a href="https://blog.golang.org/generics-next-step">a blog entry on the
next steps for generics</a>
and a new <a href="https://go.googlesource.com/proposal/+/refs/heads/master/design/go2draft-type-parameters.md">draft design based on interfaces instead of contracts</a>.
As it always is٫ one of the concerns raised in the draft is about
<a href="https://go.googlesource.com/proposal/+/refs/heads/master/design/go2draft-type-parameters.md#efficiency">the efficiency tradeoffs of any implementation</a>.</p>

<p>Roughly speaking٫ there are two ways to implement generics. One is
to generate fully specialized implementations every time a generic
function or type is specialized to a concrete set of types; another
is to compile only a single implementation and quietly pass hidden
parameters to the implementation so that it can do its work٫ similar
to how interfaces are implemented in Go (and also maps; most of the
code of Go maps is generic٫ not specialized for each type of map).
Fully specialized implementations are as fast as the compiler can
make them with full knowledge of the types and functions involved٫
but they take longer to compile and result in more code in the final
binary.</p>

<p>In thinking about this٫ it strikes me that there are two usage
patterns (or at least extremes of usage patterns) for generics٫
based on what code people often write in Go today. I will call these
<em>type safe interfaces</em> and <em>single implementations</em> respectively.
The type safe interfaces usage pattern would use generics to implement
a type safe version of what code is already doing with <code>interface{}</code>
or somewhat more restrictive interfaces today. The proposal itself
talks about Go using generics to implement type safe versions of
things like <a href="https://golang.org/pkg/container/list/">container/list</a>
and <a href="https://golang.org/pkg/sync/#Map">sync.Map</a> (<a href="https://go.googlesource.com/proposal/+/refs/heads/master/design/go2draft-type-parameters.md#pervasiveness">here</a>).</p>

<p>The single implementations usage pattern would use generics to condense
what today is multiple copies of essentially the same code٫ specialized
to various types٫ into a single block of code using generic types. These
are the people who are tired of writing yet another copy of the function
to generate a slice of all of the keys of a map of some new type. Their
existing code could in theory be written once using <code>interface{}</code> and a
lot of typecasts٫ but in practice repetition is better than all of the
typecasts required (and the resulting possibility of runtime panics)٫
especially since the underlying code is often reasonably simple and
short.</p>

<p>People in the type safe interfaces usage pattern probably don"t
mind the potential speed overheads of a single unspecialized
implementation٫ because they are already paying that penalty today.
This does imply that such a generics implementation shouldn"t perform
worse than the interface based equivalent. People in the single
implementations usage pattern are replacing hand specialized Go
code with a generics implementation so they can write it only once.
Some of them won"t be willing to do this if there"s a significant
performance penalty as a result of such a conversion٫ and in general
these people are willing to pay the compile time and space penalty
for specialized implementations because they"re already doing so
today with their hand specialized code.</p>

<p>(Hopefully the Go compiler can find clever ways to often make the
extra cost of unspecialized code very low٫ similar to <a href="https://dave.cheney.net/2018/05/29/how-the-go-runtime-implements-maps-efficiently-without-generics">how it
implements maps efficiently</a>.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/Go2GenericsExpectedEfficiency?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/DesktopAppAutostart', 'How applications autostart on modern Linux desktops', '1592446308000',  14, '<div class="wikitext"><p>A while back I mentioned that <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/MicrosoftTeamsBadArrogance">part of Microsoft Teams" misbehavior
was autostarting when you logged in</a>;
recently٫ because I was testing <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/XInputGtkScrollPuzzle">some things</a>
on my laptop with alternate desktops٫ <a href="https://twitter.com/thatcks/status/1273261622933557249">that behavior led to me
uninstalling Teams</a>. So all
in all٫ it seemed like a good time to read up on how applications
get automatically started when you log in (if they do) on modern
Linux desktops like Gnome and Cinnamon.</p>

<p>(This is not normally an issue for me in <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/MyDesktopTour">my desktop environment</a>٫ because everything in it is explicitly
started by hand in a shell script.)</p>

<p>Unsurprisingly٫ there"s a <a href="https://freedesktop.org/">freedesktop.org</a>
standard on this٫ the <a href="https://specifications.freedesktop.org/autostart-spec/latest/">Desktop Application Autostart Specification</a>٫
which builds on the <a href="https://specifications.freedesktop.org/desktop-entry-spec/latest/"><code>.desktop</code> file specification</a>.
The simple version is that you set applications to autostart by
installing an appropriate .desktop file for them into either
<code>/etc/xdg/autostart</code> (for a system-wide autostart on login) or
<code>~/.config/autostart</code> (for an autostart for an individual user).</p>

<p>There are a number of special settings keys that can be in these
.desktop files. First٫ you can have a <code>OnlyShowIn</code> or <code>NotShowIn</code>
key that controls which desktops should autostart this or not
autostart it (the specification misspells these keys in some mentions
of them). Second٫ you can have a <code>Hidden=true</code> key٫ in which case
the application should not autostart (in any desktop). For obvious
reasons٫ the latter key is most useful in your personal autostart
directory.</p>

<p>Some desktops have custom keys of their own٫ and even custom locations
for additional .desktop files to autostart; for example KDE before
KDE 5 apparently also used ~/.kde/Autostart (see <a href="https://docs.kde.org/trunk5/en/kde-workspace/kcontrol/autostart/index.html">here</a>).
An important and common property is X-GNOME-Autostart-enabled٫ which
is (still) in wide use despite <a href="https://gist.github.com/najamelan/b44e943145b03e018229">apparently being deprecated</a>.  In
particular٫ Cinnamon appears to implement disabling of standard
autostart things by copying their .desktop file to your ~/.config/autostart
directory and adding a line to the end with
"X-GNOME-Autostart-enabled=false".</p>

<p>(GNOME .desktop files can also have a phase of GNOME"s startup that
they happen in; see <a href="https://gist.github.com/najamelan/b44e943145b03e018229">here</a> and <a href="https://github.com/GNOME/gnome-session/blob/master/gnome-session/README">here</a>.
KDE .desktop files apparently have somewhat similar properties too.)</p>

<p>Some desktops have their own custom locations for various special
things٫ or have had in the past (<a href="https://askubuntu.com/questions/971105/what-is-the-difference-between-config-autostart-and-config-autostart-scrip">eg</a>٫
<a href="https://wiki.archlinux.org/index.php/KDE#Autostart">also</a>٫ and
for <a href="https://wiki.lxde.org/en/Autostart">LXDE</a>). However٫ desktops
don"t necessarily use custom locations and settings. I know that
with Cinnamon٫ if you add a new thing to be done on startup٫ Cinnamon
puts a new .desktop file in your ~/.config/autostart.</p>

<p>More minimal "desktops" may or may not automatically support .desktop
autostarts. However٫ according to the Arch wiki"s page on <a href="https://wiki.archlinux.org/index.php/XDG_Autostart">XDG
Autostart</a>٫
there are standalone programs that will do this for you if you want
them to. On my normal machines٫ my own window manager environment
is so divergent that I don"t think autostarting .desktop files is
of any use to me٫ so I"m not planning to try any of them.</p>

<p>(<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/DellXPS13FedoraReview">My work laptop</a> runs a more or less
standard Cinnamon environment٫ which automatically handles autostarting
things. I believe that Cinnamon considers itself a form of GNOME
for <code>OnlyShowIn</code> and <code>NotShowIn</code> and so on .desktop keys. Cinnamon
certainly disables autostarted things using a GNOME specific key.)</p>

<p>Applications can arrange to autostart in at least two ways٫ the
honest way and the sneaky way. The honest way is to put a copy of
their .desktop file into <code>/etc/xdg/autostart</code>. The sneaky way is
to wait until you run them once٫ then copy their .desktop file into
your ~/.config/autostart directory (re-copying this file every time
they"re run is optional). Based on poking through the RPM package
for Microsoft Teams (and also <a href="https://twitter.com/jrcresawn/status/1273293329774505984">how they apparently have a preferences
setting about this</a>)٫ Teams
appears to do this the sneaky way.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/linux/XInputGtkScrollPuzzle', 'A scrolling puzzle involving GTK+٫ XInput٫ and alternate desktops (on Fedora)', '1592368628000',  14, '<div class="wikitext"><p>Recently I discovered that <a href="https://github.com/IBBoard/cawbird">cawbird</a>
wasn"t recognizing certain "scroll up" events in parts of its
interface. This wasn"t a new issue٫ although I originally thought
it was; instead for years I"d been missing some of cawbird"s
functionality without noticing (and before it٫ corebird). I don"t
know exactly what the core problem is٫ but part of it appears to
be some sort of interaction between desktop environments (or the
lack of them) and <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/XInputOldAndNew">the new approach to handling input devices using
the X Input Extension</a>.</p>

<p><a href="https://github.com/IBBoard/cawbird/issues/164">The actual Cawbird issue</a>
is somewhat complicated and tangled٫ but fortunately it can be
boiled down to a simpler situation through <a href="https://bugzilla.gnome.org/show_bug.cgi?id=675959">a test program that
prints GTK mouse scroll event information</a> (a copy of my
version is <a href="https://utcc.utoronto.ca/~cks/programs/gtk-events/gtk-scroll-events.c">here</a>).
For background٫ when vertical scrolling happens in GDK٫ you can see
either or both of specific smooth scrolling events٫ with a Y delta
of some value٫ and "scroll up" and "scroll down" events٫ which
appear to always have a Y delta of 0.</p>

<p>On <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/MyDesktopTour">my desktop</a> running <a href="http://www.fvwm.org/">fvwm</a> outside of a desktop environment like Gnome٫
what I see from the test program when I use my mouse scroll wheel
is just a stream of scroll up and scroll down events from a source
device of "Core Pointer". On <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/DellXPS13FedoraReview">my work laptop</a>
running Cinnamon٫ scrolling on the touchpad generates smooth scrolling
events with various Y deltas depending on how fast I"m moving my
fingers٫ while using the scroll wheel on an external mouse generates
both a smooth scrolling event (with a Y delta of -1 or +1 depending
on the direction) and a "scroll up" (or "scroll down") event; these
events have a source device of either the touchpad or the USB mouse٫
although <code>xinput</code> says that there is an overall "Core Pointer"
device.</p>

<p>As far as I can tell٫ <code>xinput</code> and the X servers are reporting that
the mice involved are set up the same way; the physical mouse (and
the touchpad) are extended input devices handled by XINPUT. But
something about my fvwm environment or how I start X on my desktop
is causing these GTK smooth scroll events to not be generated٫ to
the confusion of at least some programs (and there will probably
be more in the future). Unfortunately I have no ideas about what
it might be or how to track it down.</p>

<p>(After some further testing٫ I can say that OpenBox on my laptop
and Cinnamon inside a VMWare virtual machine both cause GTK to
generate smooth scroll events. The VMWare virtual machine is using
my desktop"s mouse٫ but the xinput mouse configuration is different
because of VMWware stuff.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/unix/XInputOldAndNew', 'Input events on X have an old world and a new world', '1592277422000',  14, '<div class="wikitext"><p>The <a href="https://en.wikipedia.org/wiki/X_Window_System_protocols_and_architecture">X Window System</a>
is now very old٫ and it never had what you could call "protocol
agility" in the core X protocol. As a result٫ over the years X has
been extended through both conventions (such as <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/XFontTypes">modern X fonts</a>) and X server extensions. In theory both forms of
extension are optional and servers and clients may not support any
specific one; in practice٫ various common things are now mandatory
for any X server or client that wants to work right in the modern
world.</p>

<p>(For instance٫ X servers increasingly don"t have many old style X
fonts available for you to use and they"re often not very good
looking.)</p>

<p>As part of X"s evolution over time٫ input event handling has gone
through a practical change٫ although one that is what you could
call unevenly distributed. The original X protocol has input events٫
of course٫ which are sometimes now called <a href="https://en.wikipedia.org/wiki/X_Window_System_protocols_and_architecture#Events">core input events</a>.
You can see what core events are generated from various activities
through the venerable <a href="https://linux.die.net/man/1/xev"><code>xev</code></a>
program٫ and many straightforward X programs continue to interact
only with core events.</p>

<p>However٫ core input events have limitations that date from X"s
origins.  Core input events are only really designed to deal with
straightforward keyboards and mice with buttons. Even mouse scroll
wheels have an awkward representation in core X events; moving the
scroll wheel actually generates mouse button events for pressing
and releasing button 4 or 5 (for normal٫ implicitly vertical scroll
wheels). I don"t think there"s anything in the X protocol that
reserves these buttons for scroll wheels٫ it"s just a convention
that people came up with when they started needing to handle scroll
wheels in X.</p>

<p>I suspect that what pushed people over the edge on X input handling
was laptop touchpads and trackpads. You can pretend that a touchpad is
a mouse and manufacture appropriate X events from finger touches and
presses٫ but this isn"t really a good representation of what is actually
going on. More sophisticated programs might want to know all sorts of
additional information that a touchpad can deliver٫ and then there"s
additional input devices like pens.</p>

<p>The solution to this is <a href="https://www.x.org/releases/X11R7.7/doc/libXi/inputlib.html">the X Input (Device) Extension</a>. This
extension understands that you may have multiple input devices
connected٫ not just one (for example you may have both a touchpad
and an external mouse) and it delivers a much richer event stream
to programs that want to use it. It also generates core input events
from this richer٫ more sophisticated input event stream. You can
more or less see what XIE events are generated when you do things
with "<a href="https://linux.die.net/man/1/xinput"><code>xinput test-xi2</code></a>"٫
although you probably need to know more than you do to interpret
<code>xev</code> output.</p>

<p>Programs using a modern toolkit like GTK+ will often attempt to use
XIE (and may in practice require it). On Linux (and perhaps other
Unixes)٫ one sign of such programs is that they use the <a href="https://gitlab.freedesktop.org/xorg/lib/libxi">libXi</a> shared library٫
which is the X client library for dealing with the X Input Extension.
A C program that isn"t using this shared library is very unlikely
to be using XIE; a C program that has loaded it very likely is using
XIE in preference to core input events٫ especially if it"s using a
toolkit like GTK+.</p>

<p>One of the important consequences of this split between core input
events and XIE events is that events that look identical at the
core input event level (for example٫ as shown by <code>xev</code>) may be
different at the XIE level (as interpreted by libXi and then toolkit
libraries٫ and perhaps as shown by <code>xinput</code>). This means that some
programs will treat them exactly the same because they"re
indistinguishable and some programs may react to them differently.
This can cause rather odd issues٫ but that"s a story for <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/XInputGtkScrollPuzzle">another
entry</a>.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/XInputOldAndNew?showcomments#comments">4 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/ProductAndUtilityCode', 'Product code and utility code', '1592185003000',  14, '<div class="wikitext"><p>Over time٫ I"ve noticed that I seem to have a relatively different
experience of programming than many people do (or at least the
people who write articles that show up in my Internet reading). I
think that part of this difference can be attributed to me working
on a different sort of code than most people. To explain that٫ let"s
talk about a split (that is really a continuum) between two sorts
of code٫ <em>product code</em> and <em>utility code</em>.</p>

<p>Product code is what you use to deliver your business. Sometimes
the product code is your business (either selling the software or
directly providing an online service)٫ and sometimes it directly
supports your business activities. Product code almost always needs
to keep changing and evolving because what you deliver in your
business inevitably keeps changing and evolving itself. If you try
to freeze product code in the face of a changing business٫ eventually
you get a wider and wider gap between what the code does and what
your people need. Your people will bridge this gap as best they
can٫ through new code that connects to your code٫ awkward procedures٫
and eventually bypassing the old code and doing the business with
spreadsheets and so on.</p>

<p>Utility code supports what you do٫ but it"s not tied to business
requirements (or at least not very tightly; it"s connected in that
you shouldn"t be doing things unless the business needs them for
some reason). This is the code that works quietly in the background
keeping the wheels on and turning٫ supporting both the environment
that product code exists in and the generally stable internal
processes of the organization. Because it"s not tied very strongly
to the business٫ utility code doesn"t necessarily need very many
changes; the further from business operations it is generally the
fewer changes it needs over time. Utility code for stable and well
established internal processes like expense reports or onboarding
new people into some aspects of the organization can be essentially
static.</p>

<p>If you work on product code٫ your code is constantly changing anyway
and you don"t necessarily see the appeal of being able to stabilize
it and walk away. Unchanging product code is almost always dead and
abandoned; either it"s out ot step with the business or the part
of the business it"s associated with has been frozen and is probably
dying. If you work on utility code٫ you frequently stabilize it and
walk away٫ because what it needs to do is often pretty fixed; if
you can"t stabilize the code despite fixed requirements٫ something
is wrong and you"re unhappy about it.</p>

<p>(A corollary of this is that you almost always have people who are
familiar with how your product code works٫ because there"s generally
someone working on it٫ but you may not have anyone who remembers how
some bit of utility code works.)</p>

<p>This makes a difference when code needs to change for reasons other
than business requirements changing. Product code is always changing
anyway٫ so you can often naturally roll in those other changes as
part of your ongoing regular changes. Utility code is often frozen٫
so now you have to thaw it out٫ make changes٫ stabilize things٫ and
freeze it again٫ all to stay in the same place as far as organizational
needs and functionality go.</p>

<p>(As you might guess from all of this٫ I feel that I mostly work on
utility code. <a href="https://support.cs.toronto.edu/">We</a> don"t really
have any product code we"re responsible for٫ although it does exist
within <a href="https://www.cs.toronto.edu/">the department</a>.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/ProductAndUtilityCode?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/MailcapDocx2txtTangle', 'An interesting combination of flaws in some <code>/etc/mailcap</code> handling', '1592105488000',  14, '<div class="wikitext"><p>Somewhat recently we ran into an interestingly tangled issue around
<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/UbuntuMailcapBasics"><code>/etc/mailcap</code></a> and MIME handlers on our
Ubuntu 18.04 user login machines٫ one of those situations where
there seem to be multiple problems that when combined together lead
to an undesirable result.  What happened is that we installed the
<a href="http://docx2txt.sourceforge.net/">docx2txt</a> Ubuntu package after
it was requested by someone٫ but then found that this broke at least
<a href="http://exmh.sourceforge.net/">exmh</a>"s ability to display MS Office
"docx" file attachments. However٫ the interesting story is why.</p>

<p>As part of its package٫ docx2txt includes a <code>/usr/lib/mime/packages</code>
file to describe what it can be used to display٫ which then causes
<a href="https://manpages.ubuntu.com/manpages/xenial/man8/update-mime.8.html"><code>update-mime</code></a> to
update the MIME handling information in <code>/etc/mailcap</code>. Because
docx2txt prints what it converts to standard output٫ its mailcap
entry has the "<code>copiousoutput</code>" tag٫ and also appears to set its
priority to 2٫ which is relatively low (5 is the default). The first
thing that goes wrong is that docx2txt has an uncaught typo in this;
it actually sets "<code>prority</code>" to 2٫ leaving it at the default priority
of 5.  Also installed on our Ubuntu machines is <a href="https://www.libreoffice.org/">LibreOffice</a>٫ and LibreOffice Writer also has
<code>/usr/lib/mime/packages</code> file. LibreOffice"s entry for docx files
has priority 3٫ theoretically higher than docx2txt"s (and a standard
condition to say "I need to be in a GUI session to work")٫ but
docx2txt"s typo means that docx2txt"s mailcap entry should actually
be preferred over LibreOffice"s.</p>

<p>The second thing that happens٫ which is at least unclear٫ is that
<a href="https://manpages.ubuntu.com/manpages/xenial/man8/update-mime.8.html"><code>update-mime</code></a> doesn"t pass the <code>priority</code> field through to
<code>/etc/mailcap</code>. I think update-mime orders the generated <code>/etc/mailcap</code>
from highest priority to lowest٫ and assumes that programs that use
mailcap will pick the first matching entry. If this is what you"re
supposed to do to handle priorities in mailcap entries٫ I couldn"t
find anything that explicitly said it. Since this ordering doesn"t
seem to be explicitly written up٫ it"s at most folk knowledge and
you have to hope that the mailcap parser used by any particular
program follows this. Update-mime also doesn"t reject docx2txt"s
partially malformed mailcap line; instead it accepts it as an
entry with the default priority (and puts the "prority" field
in the generated <code>/etc/mailcap</code>٫ where it may mislead you if
you"re reading fast).</p>

<p>The third thing going wrong is that <a href="http://exmh.sourceforge.net/">exmh</a> turns out to have bad
handling of mailcap entries that write their results to standard
output٫ so that you can theoretically display it inline. What you
would expect to happen is that <a href="http://exmh.sourceforge.net/">exmh</a> would run the handler (either
automatically or on request) and then display the result inline.
Instead٫ it has a little display for that attachment that looks
like you can"t do anything (normally it will say "you can view this
with ..."٫ so you know the section can be handled)٫ and if you
actually ask exmh to run the mailcap handler to generate the output٫
it writes the generated output to its standard error (which almost
certainly isn"t connected to anything useful). Given that this is
spectacularly useless٫ exmh clearly hasn"t been used very much with
mailcap entries that want to do this instead of running an external
program that will display things on its own.</p>

<p>Exmh"s bad handling of "<code>copiousoutput</code>" mailcap entries wouldn"t
be an issue except for the mangled priority field of docx2txt;
without that٫ exmh picks LibreOffice instead (which works fine).
Docx2txt"s bad "prority" field wouldn"t have persisted if update-mime
(or some other tool) checked for and rejected improperly formed
mailcap entries; instead update-mime covered up the problem and
increased docx2txt"s priority over what it had been intended. It
took a cascade of flaws to expose this issue.</p>

<p>(Our solution was to uninstall docx2txt again. It"s not important
enough to break exmh for people using it٫ and anything else that
may also have problems with such an entry. Now that I understand
the issue٫ I will see if I have enough energy to file a Debian bug
report against docx2txt٫ which still has the bug in <a href="https://salsa.debian.org/debian/docx2txt">the current
package source</a>. Of course
it will be years before any bug fix is available in Ubuntu.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/tech/GMailPopTLSVerificationII', 'The safety of GMail"s POP server TLS certificate verification (or lack of it)', '1592018043000',  14, '<div class="wikitext"><p>A while back I wrote an entry on <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/GMailPopTLSVerification">how GMail hadn"t been doing full
TLS server certificate verification when fetching mail from remote
POP servers</a>. GMail may have verified that
the POP server"s TLS certificate was properly signed by a CA٫ but
<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertVerifyTwoParts">it didn"t check the server name٫ which is the second part of
server verification</a>. This is not safe in
general (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSVerifyByIPNotSafe">even if you verify the IP address</a>)٫
but Google (and GMail) aren"t everyone and they sit in a very special
position in several ways.</p>

<p>I don"t know if GMail"s lack of verification was truly safe٫ and
certainly it skips <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertHostVerifyReasons">part of the purpose of verifying the TLS server
hostname</a>٫ but Google skipping this check
can be safer than it is for almost anyone else. The basic reason
why is that Google is in a position to be very confident that it"s
not talking to an impostor٫ if it wants to go to the effort. First٫
Google can check what it sees for DNS lookups٫ network routing٫ and
TLS certificates from multiple vantage points around the Internet.
This means that any tampering and MITM attacks must be global٫ not
local٫ which generally means very close to the final network
connection to the target.</p>

<p>(Of course٫ doing this sort of global check can run into issues
with services that give you localized DNS results٫ with anycast
routing٫ and so on. Nothing is perfect here.)</p>

<p>Second٫ Google can keep a history of all of this. If everything is
consistent over time (and your previous connections worked and gave
sensible results)٫ you can be relatively confident that you"re still
connecting to the same thing. If you accepted the thing before٫ you
can keep accepting it now. We weren"t presenting the same TLS server
key every time (as far as I know٫ <a href="https://certbot.eff.org/">Certbot</a>
generates a new keypair every time it renews your TLS certificate٫
which is about every 60 days)٫ but we were presenting a valid TLS
certificate for the same set of TLS names (that were valid DNS names
for our IMAP and POP server).</p>

<p>None of this could make GMail"s lack of full checking completely
safe. But it at least could make it a lot safer than an isolated
program or service trying to do the same thing. Google"s in a
position to have a lot of information that let it "authenticate"
(in some sense) your server٫ which is <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertHostVerifyReasons">part of the reasons for
verifying the server name</a>.</p>

<p>(At the same time٫ I expect that GMail"s behavior was ultimately
for pragmatic reasons. It seems likely that they found that too
many people had POP servers with TLS certificates that didn"t include
the right name. I can"t throw stones about this٫ since we accidentally
did this٫ as covered in <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/GMailPopTLSVerification">my first entry</a>.)</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DualDisplayVsMultiDesktop', 'Dual displays contrasting with virtual screens (aka multiple desktops)', '1591935072000',  14, '<div class="wikitext"><p>At work٫ I have dual displays on <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/WorkMachine2017">my office desktop</a>٫ specifically two Dell U2412M monitors
(which are 24" diagonal with 1920 x 1200 resolution). This gives
me a lot of space to work in٫ and lets me do things like have a
full sized <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">Grafana dashboard</a> on the
left one while carpeting the right one with windows that are
investigating the problems shown on the dashboard. Of course٫ given
<a href="https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic">world and local events</a> I"m
not at work٫ I"m working from home. At home I have <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/4KHiDPIIsVisible">a nice HiDPI
display</a>٫ but it"s a Dell P2715Q which
means it"s only 27" diagonal (and a 16:9 display compared to the
16:10 of the dual monitors). This is not anywhere near as much space
as two displays٫ and <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/DualDisplaysNaturalSplit">the space doesn"t split naturally or as nicely</a>.</p>

<p>One of the things that <a href="http://www.fvwm.org/">my window manager</a>
supports is what is variously called virtual screens or multiple
desktops. I have multiple virtual screens set up on <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/MyDesktopTour">my desktop</a> at work as well as at home٫ but at work I"ve generally
not used them very often or for much. Generally I would switch virtual
screens only if I was interrupted in the middle of something and so
needed a whole new set of windows on top of the set that I already
had. Otherwise٫ I did everything on my primary virtual screen٫
because it had enough room.</p>

<p>This isn"t really the case with working from home. Now I"m routinely
out of what I consider enough space٫ and so my work sprawls across
multiple virtual screens. Sometimes this is different parts of my
work; I might be <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/HomeInternetAcceptableX">running virtual machines</a> on one virtual screen and looking
at a Grafana dashboard on another. This sort of split across virtual
screens is okay٫ and some people would find it an improvement over
putting everything on the primary screen٫ although I"m not sure I
do (having everything iconified in one spot is convenient). However٫
sometimes my single screen and lack of as much space forces me to
split one thing between two virtual screens. The most common case
is looking at Grafana dashboards٫ which really want to be full
screen on my display. A full screen dashboard leaves me no room for
other windows to investigate things٫ so I often wind up flipping
back and forth between a virtual screen with a Grafana dashboard
and a virtual screen where I"m doing something about what the
dashboard is telling me. This is٫ naturally٫ not the best experience;
I can"t see both things at once and I lose some context and flow
as I flip back and forth.</p>

<p>Even with different parts of my work٫ it"s not infrequently a bit
more annoying to switch virtual screens than to have one set of
things on one display and another set of things on the other. One
area this especially comes up in is reading email as it comes in.
At work٫ my email client de-iconifies on the left side of my right
display (more or less in the center of where I look)٫ and I tend
to first use the left display for things like terminal windows and
work٫ which means that there"s space left for the email client to
open up٫ for me to write replies to email٫ and so on. At home٫ the
de-iconified email client is competing for space with all sorts of
other things٫ so if email comes in while I"m working I"ll often
switch to another clean virtual screen to read it. This is more of
an interruption than it is on my work dual display.</p>

<p>At the same time٫ the clean virtual screen that I get at home is
in its own way a nicer thing. I can"t deny that there"s clutter and
a bunch of distractions on my primary virtual screen at work٫ both
passive ones (things I could do) and active ones (things I"m currently
doing). A forced switch to a different virtual screen at home wipes
away all of that and gives me a clean٫ low distraction slate (at
least until I start cluttering up the second virtual screen). The
very lack of space that I don"t like pushes me to switch virtual
screens more often and thus to get that new٫ uncluttered٫ lower
distraction experience more often.</p>

<p>My current feelings are that virtual screens at home don"t make up
for not having dual displays. I can get my work done٫ but it"s not
as nice an experience as it is at work٫ and not as flowing (for
lack of a better term). I"m cramming too much into too little space٫
and my virtual screens are mostly a method of trying to get more
space (as opposed to٫ say٫ trying to keep things organized).</p>

<p>(Some people like using virtual screens to separate various things
from each other٫ but my current view is that I don"t want to do
that for various reasons beyond the scope of this entry.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/DualDisplayVsMultiDesktop?showcomments#comments">One comment</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/tech/DualDisplaysNaturalSplit', 'A dual display setup creates a natural split between things', '1591847091000',  14, '<div class="wikitext"><p>Sometimes you notice things only when you don"t have them. At work
I have a dual display setup on my work desktop (arranged horizontally)٫
but I only have a single display at home (mostly for space reasons).
One of the differences I"ve noticed in how I use my screen space
is that <strong>dual displays provide a natural division and split between
things</strong>٫ because of the literal physical split between the two
displays.</p>

<p>(I"ve been noticing this lately because I"m working from home٫ so
for once I"m spending a lot of time doing the same sort of things
at home that I normally do at work.)</p>

<p>This split tends to manifest in two ways٫ which I can call active
and passive. The active type split is how I often wind up dynamically
using windows as I work on something. On a dual display system٫
it"s natural to open up a full "screen" (really display) view of a
<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">Grafana dashboard</a> on
one display while using the second display to look into the specifics
of what the dashboard is showing me٫ through terminal windows and
other things. Similarly it feels natural to park documentation on
one screen while actively working on the other٫ or use one display
to monitor logs while I"m making a change on the other one. The
passive type split is how I organize iconified or idle windows;
rather than sprawl across both displays٫ they tend to wind up
entirely on one or the other.</p>

<p>In theory I could split my display at home in the same way (it"d
take some window manager support to make it convenient٫ but I use
a very flexible window manager). In practice such a split would
feel artificial. I"d be drawing an arbitrary line down my screen
somewhere٫ with no particularly good reason for it except that I
wanted it. The split in a dual display setup is anything but
arbitrary٫ because there"s a clear discontinuity and visual gap
(one created by the bezels of the two displays). You can"t have
something straddle the gap and look normal.</p>

<p>I suspect that I"d still feel this way even if I had a single display
at home that was the size of my dual displays at work. I would probably
start splitting up the layout so that some things consistently went to
the left٫ some to the right٫ and some in the center٫ and I definitely
would have a "maximize to one half (or one third) horizontally" option
in my window manager (because a true full screen window would be far too
big). But I suspect that things would wind up passively sprawled out
all over٫ instead of grouped into areas. It would just be too tempting
to expand things into some of that empty space with no obvious division
between it and the occupied space.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/DualDisplaysNaturalSplit?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/tech/FediverseDiversityChallenge', 'The practical people problem with instance diversity in the Fediverse', '1591760728000',  14, '<div class="wikitext"><p>Recently I was reading Kev Quirk"s <a href="https://kevq.uk/centralisation-and-mastodon/">Centralisation and Mastodon</a> (<a href="https://lobste.rs/s/d4t4ex/centralisation_mastodon">via</a>)٫ which
notes how central <a href="https://mastodon.social/">Mastodon.social</a>
and a few other big instances are to the overall Fediverse٫ making
it hardly a decentralized network in practice. The article concludes
with a call to action:</p>

<blockquote><p>If you’re thinking about joining Mastodon٫ don’t just join the
first instance you come across. Take a look at the sign up section of
<a href="https://joinmastodon.org/">the Mastodon homepage</a>. There is a list
[of] alternative instances that you can join٫ all arranged by topic.</p>
</blockquote>

<p>I think that more genuine decentralization in the Fediverse isn"t
a bad thing٫ but I also think that there are practical considerations
pushing against it. To put it one way٫ if you"re joining the Fediverse
your choice of instance is a risky decision that you"re mostly not
interested in and are generally not well equipped to make.</p>

<p>Your choice of instance is risky in that if you pick badly٫ you"ll
wind up having to go through various sorts of annoyance and pain.
Picking what is clearly a big and popular instance has an intuitive
appeal to reduce those risks; a popular instance is probably not a
bad choice. As far as actively choosing an instance goes٫ this is
usually not what you"re interested in. Most people are interested
in joining the Fediverse as a whole٫ and one of the points of it
being a decentralized network is that it isn"t supposed to matter
where you join. So you might as well take a low risk choice.</p>

<p>Finally٫ if you"re trying to actively pick a good instance٫ most
people have the twin problems that they don"t know what they care
about (or should care about) in instances٫ and even if they do know
they have things they care about they don"t know enough to how to
evaluate instances. Oh٫ you can read an instance"s policies and
poke around a bit٫ but that may not give you clear and honest
answers٫ and on top of that a lot of things in the Fediverse are
only clear to people who are immersed in the Fediverse already.  To
put it one way٫ there are a lot of problems with instances (and
problem instances) that aren"t obvious and clear to outsiders.</p>

<p>All of this should be unsurprising٫ because it"s all a version of
<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SecurityChoiceProblem">the problem of forcing users to make choices in security</a>. People mostly don"t care٫ and even if they
do care they mostly don"t know enough to make good choices. This is
especially the case if they"re new to the Fediverse.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/FediverseDiversityChallenge?showcomments#comments">3 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/linux/SwapOnZramMixedFeelings', 'My mixed feelings about "swap on zram" for Linux', '1591675356000',  14, '<div class="wikitext"><p>Recently I read about how <a href="https://fedoraproject.org/wiki/Changes/SwapOnZRAM">Fedora will be enabling "swap on zram"</a>٫ including for
upgraded machines٫ in a future version of Fedora. I suspect that a
similar change may some day come to Ubuntu as well٫ because it"s
an attractive feature from some perspectives. My feelings are a bit
more mixed.</p>

<p><a href="https://en.wikipedia.org/wiki/Zram">Zram</a> is a dynamically sized
compressed block device in RAM (ie a compressed ramdisk); "swap on
zram" is using a zram device as a swap device (or as your sole swap
device). This effectively turns inactive RAM pages into compressed
RAM in an indirect way while pacifying the kernel"s traditional
desire to have some swap space. The pitch for swap on zram is very
nicely summarized on <a href="https://fedoraproject.org/wiki/Changes/SwapOnZRAM">the Fedora page</a> as "swap is
useful٫ except when it"s slow". Being in RAM٫ swap on zram is very
fast; it"s the fastest swap device you can have٫ faster than SSD
or even NVMe.</p>

<p>(This implies that how much of an advantage swap on zram is for
your system depends partly on how fast your existing swap storage
is. But RAM is still much faster than even NVMe.)</p>

<p>The drawback of swap on zram is that it is not really freeing up
all of your memory to "swap things out"; instead the estimate is
that it will generally compress to about half the previous size.
This drawback is the source of my mixed feelings about swap on zram
for my Fedora desktops and our Ubuntu servers.</p>

<p>On my Fedora desktops٫ I generally barely use any swap space٫ which
means that swap on zram would be harmless. If I do temporarily use
a surge of swap space٫ being able to get the contents back fast
is probably good; Linux has generally had an irritating tendency
to swap out things I wanted٫ like bits of my window manager"s
processes. Both <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/HomeMachine2018">my home machine</a> and <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/WorkMachine2017">my work
machine</a> have 32 GB of RAM٫ and peak swap usage over
the past 120 days has been under a gigabyte٫ so I"m barely going to
notice the memory effects. As a result I"m likely to leave swap on
zram in its default enabled state when Fedora gives it to me.</p>

<p>Unfortunately this is not the case for our Ubuntu LTS servers. Those
of our Ubuntu servers that use much swap at all tend to eventually
end up with their swap space full or mostly full of completely idle
data that just sits there. Keeping even a compressed version of
this data in RAM is not what we want; we really want it to be swapped
out of memory entirely. Swap on zram would be a loss of RAM for us
on our Ubuntu servers. As a result٫ if and when Ubuntu enables this
by default٫ I expect us to turn it off again.</p>

<p>One way to put this is that swap on zram is faster than conventional
swap but not as useful and effective for clearing RAM. Which of
these is more important is not absolute but depends on your situation.
If you"re actively swapping٫ then speed matters (fast swap lowers
the chances of <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/SwapSizingII">swapping yourself to death</a>).
If you"re instead pushing out idle or outright dormant memory in
order to make room for more productive uses of that RAM٫ then
clearing RAM matters most.</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/SwapOnZramMixedFeelings?showcomments#comments">5 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/programming/GoTimeParsingTZIssue', 'A Go time package gotcha with parsing time strings that use named time zones', '1591582568000',  14, '<div class="wikitext"><p>Go has a generally well regarded <a href="https://golang.org/pkg/time/"><code>time</code></a>
package. One of the things it can do is parse a string representation
of a time based on a specification of the time format٫ using
<a href="https://golang.org/pkg/time/#Parse"><code>time.Parse()</code></a>; for example٫
to parse times like "Sat Mar 7 11:06:39 PST 2015" or "Sat٫ 07 Mar
2015 11:06:39 -0800" (which are in Unix date format and "RFC 1123 Z"
format respectively). As usual٫ <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoTimeHasLocation">these parsed <code>time.Time</code> values have
a location</a>٫ ie a time zone.  However٫ if you"re
dealing with time strings with named time zones٫ like "PST"٫ this
parsing has a very large catch.  This catch is sort of spelled out in
the official documentation٫ but not quite completely clearly:</p>

<blockquote><p>When parsing a time with a zone abbreviation like MST٫ if the zone
abbreviation has a defined offset in the current location٫ then that
offset is used. The zone abbreviation "UTC" is recognized as UTC
regardless of location. <strong>If the zone abbreviation is unknown٫ Parse
records the time as being in a fabricated location with the given zone
abbreviation and a zero offset</strong>.</p>
</blockquote>

<p>MST is a widely known zone abbreviation٫ so you might think that
it will always have "a defined offset in the current location".
This is not so. If your current location doesn"t ever use "MST"
as a zone abbreviation٫ then it"s not considered "a defined offset"
and you get a time that claims it is in "MST" but that has a 0
offset from UTC. <strong>This is not a correctly parsed time as any
human being would understand it</strong>. Go is making up an offset
in order to not report an error.</p>

<p>What Go means by "a defined offset in the current location" is that
you can use "EST" and "EDT" if you"re in Eastern time. This means that
<strong>Go will parse a time string containing a named time zone differently
depending on your local time zone</strong>. If you parse a string that uses
"MST" as its time zone and you are in Mountain time٫ you will get one
<code>time.Time</code> value; if you are in Eastern time (or <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ServerUTCTimeViews">this server is in
UTC time</a>)٫ you will get a completely
different <code>time.Time</code> value.</p>

<p>(This implies that if you write out a time string using a named
time zone٫ change your time zone (either personally or server wide)٫
and then parse the time string again٫ you will get a different
time. One way to change your personal time zone is to move a file
containing time strings from one server to another.)</p>

<p>This also means that it very much matters whether the source of the
time string is using named time zones or numeric time zone offsets.
The choice between "<a href="https://tools.ietf.org/html/rfc1123">RFC 1123</a>"
time format (using named time zones) and "RFC 1123 Z" format (using
numeric values) will give you what is theoretically the same time
that Go will not infrequently parse as very different time zones.
<strong>Only time formats using numeric time zone offsets are safe to use
with Go</strong> (and even then <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoTimeHasLocation">there is a catch when later formatting
them</a>).</p>

<p>My personal opinion is that this is a serious bug in Go"s time
parsing. If a named time zone offset is given and Go cannot safely
determine its actual zone offset٫ the parse should fail with an
error. Turning "Sat Mar 7 11:06:39 PST 2015" into March 7 11:06:39
UTC 2015 is not correct behavior; instead it is actively dangerous.
If this means that too many time strings fail to parse٫ then Go
time parsing needs to get smarter about looking up popular named
time zone offsets٫ or it should provide a "parse liberally" function
with the current behavior of <code>time.Parse()</code>.</p>

<p>Another consequence of this behavior is that a <code>time.Time</code> time
zone that is printed as "EST" is not always "EST" (and the same for
any named time offset). Sometimes it is "EST (-0500)" and sometimes
it is "EST (+0000)"٫ ie "UTC but we are claiming that it is called
EST". In my opinion٫ Go should also stop doing this. If it is going
to accept "EST" but treat it as UTC٫ it should actually set the
location to UTC so that people are not fooled by how the same two
times٫ apparently equal because they format with the same output٫
are in fact not equal.</p>

<p>(To Go"s credit٫ the default string format for <code>time.Time</code> values٫ as
shown in <a href="https://golang.org/pkg/fmt/"><code>fmt</code></a>"s <code>%v</code> format٫ does show
both the time zone name and the numerical offset. This gives you odd but
honest output like "2015-03-07 11:06:39 +0000 MST". But if you format
with just the named time zone٫ you can have two times that format the
same but don"t compare equal.)</p>

<p>(This entire issue was brought to my attention by James Antill"s
comments on <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoTimeHasLocation">my entry about how <code>time.Time</code> values have locations</a>.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoTimeParsingTZIssue?showcomments#comments">2 comments</a>.) </div>'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ChangeSubtleDangerExample', 'Why sysadmins don"t like changing things٫ illustrated', '1591501616000',  14, '<div class="wikitext"><p>System administrators are famously reluctant to change anything
unless they have to; once a system works٫ they like to freeze it
that way and not touch it. This is sometimes written off as irrational
over-concern٫ and to be honest sometimes it is; <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/AvoidingRebootFetish">you can make a
fetish out of anything</a>. However٫ it isn"t
just superstition and fetish. We can say general things like <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/StabilityViaChangeControl">on
good systems٫ you control stability by controlling changes</a> and note that <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/CheckForChangeEffects">harmless changes aren"t
always actually harmless</a>٫ but surely if you
take appropriate care you can monitor your systems while applying
controlled changes٫ promptly detect and understand any problems٫
and either fix them or roll back.</p>

<p>Well٫ let me tell you a story about that٫ and about spooky subtle
action at a distance. (A story that I mentioned in passing <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusAlertTimeFormatting">recently</a>.)</p>

<p>We have <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusGrafanaSetup-2019">a Prometheus based monitoring and alerting system</a>٫ that among other things sends out
alert notifications٫ which come from a Prometheus component called
<a href="https://prometheus.io/docs/alerting/alertmanager/">the Alertmanager</a>.
Those alert notifications include the start and end times of the
alerts (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusAlertsWhyTimes">for good reasons</a>)٫ and <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ServerUTCTimeViews">since
we generally deal in local time</a>٫ these are in
local time. Or at least they"re supposed to be. Quite recently a
co-worker noticed that these times were wrong; after a short
investigation٫ it was obvious that they were in UTC. Further
investigation showed that they hadn"t always been in UTC time; ever
since we started with Prometheus in late 2018 they"d been in local
time٫ as we expected٫ and then early in May they"d changed to UTC.</p>

<p>We have <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ChecklistEvolution">reasonably good records of what we"ve changed on our
systems</a>٫ so I could go back to what we"d changed
on the day when the alert times switched from local time to UTC٫
and I could also look at the current state of the system. What I
expected to find was one of four changes; the system switching
timezones for some reason٫ an Ubuntu package update of a time related
package٫ an update to <a href="https://prometheus.io/docs/alerting/alertmanager/">Alertmanager</a> itself (with a
change related to this behavior)٫ or that the systemd service for
Alertmanager was putting it into UTC time. I found none of them.
Instead the cause of the timezone shift in our alert messages was
an update to the Prometheus daemon٫ and the actual change in
Prometheus was not even in its release notes (I found it only by
searching Git commit logs٫ which led me to <a href="https://github.com/prometheus/prometheus/commit/7646cbca328278585be15fa615e22f2a50b47d06">here</a>).</p>

<p>Here is an undesirable change in overall system behavior that we
didn"t notice for some time and that was ultimately caused by us
upgrading something that wasn"t obviously related to the issue.
The actual cause of the behavior change was considered so minor
that it didn"t appear in the release notes٫ so even reading them
(both before and after the upgrade) didn"t give us any sign of
problems.</p>

<p>This shows us٫ once again٫ that you can"t notice all changes in
behavior immediately٫ not in practice٫ you can"t predict them in
advance from due diligence like reading release notes and trying
things out on test systems٫ and they aren"t always from things that
you expect; a change in one place can cause spooky action at a
distance. Our alert time stamps are formatted in Alertmanager when
it generates alerts٫ but it turned out through a long chain of
actions that a minor detail of how they were created inside Prometheus
made a difference in our setup.</p>
</div>
'),('https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusAlertsWhyTimes', 'Why we put alert start and end times in our Prometheus alert messages', '1591411029000',  14, '<div class="wikitext"><p>As I mentioned in <a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusAlertTimeFormatting">Formatting alert start and end times in
Alertmanager messages</a>٫ we put the
alert start times and if applicable the alert end times in the
(email) alert messages that we send out. Generally these look
like one of these two:</p>

<blockquote><ul><li>for a current alert <br>
(alert started at 15:16:02 EDT 2020-06-05٫ likely detected ~90s earlier)<p>
</li>
<li>for an alert that has ended <br>
(alert active from 15:16:02 EDT 2020-06-05 to 15:22:02 EDT 2020-06-05)</li>
</ul>
</blockquote>

<p>(The "likely detected .." bit is there because most of our Prometheus
alert rules have a "<code>for:</code>" clause٫ so the alert condition becomes
true somewhat before the alert itself starts.)</p>

<p>At the beginning of life with Prometheus and Alertmanager٫ it may not be
obvious why this is useful and sometimes even necessary; after all٫ the
alert message itself already has a time when it was emailed٫ posted to
your communication channel٫ or whatever.</p>

<p>The lesser reason we do this٫ especially for alert end times٫ is
that it"s convenient to have this information in one place when
we"re going back through email. If we have a "this alert is resolved"
email٫ we don"t have to search back to see when it started; the
information is right there in the final message. There"s a similar
but smaller convenience with email about the start of single alerts٫
since you can just directly read off the start time from the text
of the message without looking back to however your mail client is
displaying the email"s sending time.</p>

<p>The larger reason is how <a href="https://prometheus.io/docs/alerting/alertmanager/">Alertmanager</a> works with
grouped alerts (which is almost all of our alerts). Alertmanager"s
core model is that rather than sending you new alerts or resolved
alerts (or both)٫ it will send you the entire current state of the
group"s alerts any time that stage changes. What this means is that
if at first alert A is raised٫ then somewhat later alert B٫ then
finally alert C٫ you will get an email listing "alert A is active"٫
then one saying "alert A and B are active"٫ then a third saying
"alerts A٫ B٫ and C are active".</p>

<p>When you get these emails٫ you generally want to know what alerts
are new and what alerts are existing older alerts. You"re probably
already looking at the existing alerts٫ but the new alerts may be
for new extra problems that you also need to look at٫ and they may
be a sign that things are getting worse. And this is why you want
the alert start times٫ because they let you tell which alerts are
more recent (and more likely to be new ones you haven"t seen before)
and which ones are older. It"s not as good as being clearly told
which alerts are new in this message٫ but it"s as good as we can
get in the Alertmanager model of the world.</p>

<p>(I don"t know if Alertmanager puts the alerts in these messages
in any particular order. Even if it does so today٫ there"s no
documentation about it so it"s not an official feature and may
change in the future. It would be nice if Alertmanager used a
documented and useful order٫ or let you sort the alerts based
on start and end times.)</p>
</div>
<div> (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusAlertsWhyTimes?showcomments#comments">One comment</a>.) </div>'),('https://kieranhealy.org/blog/archives/2020/08/25/some-data-packages/', 'Some Data Packages', '1598360503000',  15, '<p>If you&rsquo;re teaching statistics٫ data analysis٫ or data visualization with R this semester٫ especially in the social sciences٫ I&rsquo;ve pulled together various bits of data into packages that I use in my own teaching. You might find them useful once you&rsquo;re sick of Gapminder. They cover a variety of topics and range from single tables of data to whole longitudinal and panel surveys.</p>
<p class = "clearfix"><a href="http://kjhealy.github.io/uscenpops"><img src = "/files/misc/hex-cavax.png" width = "140" align = "left"></a> The <a href="http://kjhealy.github.io/cavax">cavax package</a> contains a school-level table of rates of Personal Belief Exemptions (PBEs) in California kindergartens for the 2014-15 school year. At that time (the rules have since changed)٫ a PBE allowed a child to enter kindergarten without having received the usual complement of vaccinations. Information on the school"s name٫ district٫ city٫ county٫ and type is included٫ along with the size of the kindergarten class.</p>
<p class = "clearfix"><a href="http://kjhealy.github.io/ukelection2019"><img src = "/files/misc/hex-uk2019.png" width = "140" align = "left"></a> The <a href="http://kjhealy.github.io/ukelection2019">ukelection2019 package</a> contains candidate-level vote data by constituency on the UK general election of 2019٫ scraped from the BBC"s election website.</p>
<p class = "clearfix"><a href="http://kjhealy.github.io/uscenpops"><img src = "/files/misc/hex-uscenpops.png" width = "140" align = "left"></a> The <a href="http://kjhealy.github.io/uscenpops">uscenpops package</a> contains a table of birth counts for the United States by year-of-age and sex for every year from 1900 to 2018.</p>
<p class = "clearfix"><a href="http://kjhealy.github.io/nycdogs"><img src = "/files/misc/hex-nycdogs.png" width = "140" align = "left"></a> The <a href="http://kjhealy.github.io/nycdogs">nycdogs package</a> is a fun dataset (actually three separate tibbles: licenses٫ bites٫ and zip codes) taken from New York City"s Open Data initiative٫ cleaned up and packaged for R. It"s useful for teaching <a href ="http://dplyr.tidyverse.org">dplyr</a>٫ for drawing maps٫ and for seeing where dogs with particular names live. </p>
<p class = "clearfix"><a href="http://kjhealy.github.io/covdata"><img src = "/files/misc/hex-covdata.png" width = "140" align = "left"></a> The <a href="http://kjhealy.github.io/covdata">covdata package</a> contains data on reported cases of and deaths from COVID-19 from from a variety of sources. Amongst other things٫ the package provides (1) National-level case and mortality data from the ECDC٫ U.S. state-level case and morality data from the CDC and the New York Times٫ patient-level data from the CDC"s public use dataset. (2) All-cause mortality and excess mortality data from the Human Mortality Database. (3) Mobility and activity data from Apple and Google. (4) Policy data from the <a href = "https://coronanet-project.org">CoronaNet Project</a>.
<p class = "clearfix"><a href="http://kjhealy.github.io/gssr"><img src = "/files/misc/hex-gssr.png" width = "140" align = "left"></a> The <a href="http://kjhealy.github.io/gssr">gssr package</a> provides the complete General Social Survey cumulative data file (1972-2018) and Three Wave Panel data files in an R-friendly format٫ together with their codebooks. </p>
<p class = "clearfix"><a href="http://kjhealy.github.io/socviz"><img src = "/files/misc/hex-socviz.png" width = "140" align = "left"></a> All of these packages work well with  the <a href="http://kjhealy.github.io/socviz">socviz package</a> which supports my <a href="https://www.amazon.com/Data-Visualization-Introduction-Kieran-Healy/dp/0691181624"><em>Data Visualization</em></a> book with a collection of datasets and utility functions to help you draw good graphs in R and ggplot. </p>
'),('https://kieranhealy.org/blog/archives/2020/06/03/the-politics-of-disorder/', 'The Politics of Disorder', '1591182337000',  15, '<p>The wave of protest and unrest in the wake of George Floyd&rsquo;s killing by the police shows little sign of abating just yet. Unrest nationwide is٫ if anything٫ increasing as protesters are met with repression by the police. Civil unrest of this scope is unusual. The conjunction of mass protest and widespread disorder should be worrying to those in authority.</p>
<p>When property damage and theft happens as a side-effect of real mass protest٫ authorities in a democracy cannot baton٫ tear gas٫ or shoot their way to legitimacy. People want social order٫ but this isn&rsquo;t like quelling a riot after a sports game. The key issue—as the Governor of Minnesota put it the other day—is that &ldquo;there are more of them than us&rdquo;. All the tactical gear in the world isn&rsquo;t worth a damn٫ ultimately٫ if enough of the population ends up in open revolt against civil authority. There are just too many people.</p>
<p>That’s one reason the Army are on the scene already in DC. If the mobilization is large enough and it’s met with police repression and brutality—rather than some more accommodating strategy—then it will only take a few days before things seem to spin right out of control. The desire to present a &ldquo;show of force&rdquo; to protesters is understandable. It can be strategically sensible٫ too٫ insofar as it is aimed both at dealing with those in the streets and at securing the support of an approving audience who just want things to calm down. This calculus can change rapidly٫ however٫ as larger and larger numbers of people become directly and indirectly supportive of the protests.</p>
<p>Those actually running cities٫ and city police forces٫ are usually aware of this. Practical experience and decades of research makes it clear what&rsquo;s at stake when &ldquo;ordinary criminal behavior&rdquo; is happening in the context of mass protest rather than as mere disorderly conduct. This is one of the reasons that authorities tend to blame “outside agitators” or “the media” or “protesters from out of state” as being the real cause of unrest. Protest organizers will do this too٫ often enough٫ blaming disorder on fringe groups or provocateurs who have illegitimately attached themselves to an otherwise peaceful protest. But if the bulk of a city&rsquo;s population really is directly engaged in mass protest or indirectly supportive of it٫ and these protests are met with force by the authorities٫ then violent disorder will start to look less like pockets of disruption disapproved of by all and more like the loss of legitimacy.</p>
<p>In the United States٫ these pressures are exacerbated by racial stratification. The deep-seated racism of almost all aspects of U.S. life٫ and the residential racial segregation of many cities٫ makes it easier to mobilize the support of whites for the use of force in the name of social order. Even here٫ crises have been accommodated by efforts to redirect unrest towards an ordinary political process. The demand for social order without repression٫ after all٫ is not restricted to whites.</p>
<p>President Trump has no interest in routine politics. His instincts are authoritarian٫ his interest in the mechanics of governance is nil٫ and his attention span is minimal. He has been happy to cultivate the political support of the police and to egg on its paramilitary elements. Trump&rsquo;s temperament intersects badly with long-term trends. The increasingly paramilitary culture (and equipment) of U.S. police forces has been noted by observers over the past twenty five years. The police were already aware that٫ thanks to astonishingly strong union contracts٫ weak internal oversight٫ and the doctrine of qualified immunity٫ individual officers would face no or minimal consequences for the use of excessive force٫ up to and including force that resulted in someone&rsquo;s death.</p>
<p>Trump&rsquo;s personal attitudes merely catalyzed what was already there. But it did so on both sides. Trump started out as a very unpopular leader and the scale of the economic crisis accompanying the COVID-19 pandemic has made everything much worse. Structurally٫ lockdown has put millions of people out of work. Contingently٫ the relatively small but highly visible wave of reopening protests threw the current unrest into sharp relief. In the former case٫ white protesters were allowed to vent their anger directly in the faces of police in ordinary uniform. Masked men with armalite rifles were permitted to walk onto the floor of state legislatures in the name of liberty. Such things are of course simply inconceivable in the context of black-led protest.</p>
<p>Thus were created the conditions for the fusion of mass protest and violent unrest. In the absence of mass mobilization for protest٫ imposing &ldquo;Law and Order&rdquo; by force is usually a politically successful tactic٫ at least in the short-run. The demand for order is the most basic demand of political life. But attempting to impose order by force when people are protesting in the streets en masse is much riskier٫ both for the leader wanting to &ldquo;dominate&rdquo; and for political institutions generally. A competent democratic leader may effectively de-escalate conflict and return it to the sphere of ordinary political struggle. Alternatively٫ a competent authoritarian may secure control of the police and military and get the backing of enough people to leave democracy behind. What you generally can’t do in a democracy٫ though٫ is “crush” or “dominate” real mass dissent purely by force without also causing political institutions to come crashing down around your head.</p>
'),('https://kieranhealy.org/blog/archives/2020/05/23/get-apples-mobility-data/', 'Get Apple"s Mobility Data', '1590253874000',  15, '<p>I&rsquo;ve been maintaining <a href="https://kjhealy.github.io/covdata/">covdata</a>٫ an R package with a variety of COVID-related datasets in it. That means I&rsquo;ve been pulling down updated files from various sources every couple of days. Most of these files are at static locations. While their internal structure may change occasionally٫ and maybe they&rsquo;ve moved once or twice at most since I started looking at them٫ they&rsquo;re generally at a stable location. <a href="https://www.apple.com/covid19/mobility">Apple&rsquo;s Mobility Data</a> is an exception. The URL for the CSV file changes daily٫ and not just by incrementing the date or something like that. Instead the file path is a function of whatever version the web CMS is on٫ and its versioning moves around. Worse٫ the webpage is dynamically generated in Javascript when it&rsquo;s requested٫ which means we can&rsquo;t easily scrape it and just look for the URL embedded in the &ldquo;Download the Data&rdquo; button.</p>
<p>I resigned myself to doing the update manually for a bit٫ and then I got stuck in the weeds of using a headless browser from within R that could execute the Javascript and thus find the URL. But this was a huge pain. When I lamented my situation on Twitter٫ David Cabo pointed out to me that there&rsquo;s an <code>index.json</code> file that&rsquo;s stably-located and contains the information I needed to generate the URL of the day. Here&rsquo;s how to do just that٫ and then pull in the data to a tibble.</p>
<p>The <code>index.json</code> file is just a string of metadata. It looks like this:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-json" data-lang="json">

<span class="p">{</span><span class="nt">&#34;basePath&#34;</span><span class="p">:</span><span class="s2">&#34;/covid19-mobility-data/2008HotfixDev38/v3&#34;</span><span class="p">٫</span>
 <span class="nt">&#34;mobilityDataVersion&#34;</span><span class="p">:</span><span class="s2">&#34;2008HotfixDev38:2020-05-21&#34;</span><span class="p">٫</span>
 <span class="nt">&#34;regions&#34;</span><span class="p">:{</span><span class="nt">&#34;en-us&#34;</span><span class="p">:{</span><span class="nt">&#34;jsonPath&#34;</span><span class="p">:</span><span class="s2">&#34;/en-us/applemobilitytrends.json&#34;</span><span class="p">٫</span>
                     <span class="nt">&#34;localeNamesPath&#34;</span><span class="p">:</span><span class="s2">&#34;/en-us/locale-names.json&#34;</span><span class="p">٫</span>
                     <span class="nt">&#34;csvPath&#34;</span><span class="p">:</span><span class="s2">&#34;/en-us/applemobilitytrends-2020-05-21.csv&#34;</span><span class="p">٫</span>
                     <span class="nt">&#34;initialPath&#34;</span><span class="p">:</span><span class="s2">&#34;/en-us/initial-data.json&#34;</span><span class="p">٫</span>
                     <span class="nt">&#34;shards&#34;</span><span class="p">:{</span><span class="nt">&#34;defaults&#34;</span><span class="p">:</span><span class="s2">&#34;/en-us/shards/defaults.json&#34;</span><span class="p">}}}}</span>

</code></pre></td></tr></table>
</div>
</div>

<p>So٫ we grab this file (whose URL we know) and extract the information we want about the <code>basePath</code> and <code>csvPath</code> that point to the data:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">get_apple_target</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">cdn_url</span> <span class="o">=</span> <span class="s">&#34;https://covid19-static.cdn-apple.com&#34;</span><span class="p">٫</span>
                             <span class="n">json_file</span> <span class="o">=</span> <span class="s">&#34;covid19-mobility-data/current/v3/index.json&#34;</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">tf</span> <span class="o">&lt;-</span> <span class="nf">tempfile</span><span class="p">(</span><span class="n">fileext</span> <span class="o">=</span> <span class="s">&#34;.json&#34;</span><span class="p">)</span>
  <span class="n">curl</span><span class="o">::</span><span class="nf">curl_download</span><span class="p">(</span><span class="nf">paste0</span><span class="p">(</span><span class="n">cdn_url</span><span class="p">٫</span> <span class="s">&#34;/&#34;</span><span class="p">٫</span> <span class="n">json_file</span><span class="p">)٫</span> <span class="n">tf</span><span class="p">)</span>
  <span class="n">json_data</span> <span class="o">&lt;-</span> <span class="n">jsonlite</span><span class="o">::</span><span class="nf">fromJSON</span><span class="p">(</span><span class="n">tf</span><span class="p">)</span>
  <span class="nf">paste0</span><span class="p">(</span><span class="n">cdn_url</span><span class="p">٫</span> <span class="n">json_data</span><span class="o">$</span><span class="n">basePath</span><span class="p">٫</span> <span class="n">json_data</span><span class="o">$</span><span class="n">regions</span><span class="o">$</span><span class="n">`en-us`</span><span class="o">$</span><span class="n">csvPath</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1">## &gt; get_apple_target()</span>
<span class="c1">## [1] &#34;https://covid19-static.cdn-apple.com/covid19-mobility-data/2008HotfixDev38/v3/en-us/applemobilitytrends-2020-05-21.csv&#34;</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Then we can grab the data itself٫ with this function:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">get_apple_data</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">url</span> <span class="o">=</span> <span class="nf">get_apple_target</span><span class="p">()٫</span>
                             <span class="n">fname</span> <span class="o">=</span> <span class="s">&#34;applemobilitytrends-&#34;</span><span class="p">٫</span>
                             <span class="n">date</span> <span class="o">=</span> <span class="n">stringr</span><span class="o">::</span><span class="nf">str_extract</span><span class="p">(</span><span class="nf">get_apple_target</span><span class="p">()٫</span> <span class="s">&#34;\\d{4}-\\d{2}-\\d{2}&#34;</span><span class="p">)٫</span>
                             <span class="n">ext</span> <span class="o">=</span> <span class="s">&#34;csv&#34;</span><span class="p">٫</span>
                             <span class="n">dest</span> <span class="o">=</span> <span class="s">&#34;data-raw/data&#34;</span><span class="p">٫</span>
                             <span class="n">save_file</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;n&#34;</span><span class="p">٫</span> <span class="s">&#34;y&#34;</span><span class="p">))</span> <span class="p">{</span>

  <span class="n">save_file</span> <span class="o">&lt;-</span> <span class="nf">match.arg</span><span class="p">(</span><span class="n">save_file</span><span class="p">)</span>
  <span class="nf">message</span><span class="p">(</span><span class="s">&#34;target: &#34;</span><span class="p">٫</span> <span class="n">url</span><span class="p">)</span>

  <span class="n">destination</span> <span class="o">&lt;-</span> <span class="n">fs</span><span class="o">::</span><span class="nf">path</span><span class="p">(</span><span class="n">here</span><span class="o">::</span><span class="nf">here</span><span class="p">(</span><span class="s">&#34;data-raw/data&#34;</span><span class="p">)٫</span>
                          <span class="nf">paste0</span><span class="p">(</span><span class="s">&#34;apple_mobility&#34;</span><span class="p">٫</span> <span class="s">&#34;_daily_&#34;</span><span class="p">٫</span> <span class="n">date</span><span class="p">)٫</span> <span class="n">ext</span> <span class="o">=</span> <span class="n">ext</span><span class="p">)</span>

  <span class="n">tf</span> <span class="o">&lt;-</span> <span class="nf">tempfile</span><span class="p">(</span><span class="n">fileext</span> <span class="o">=</span> <span class="n">ext</span><span class="p">)</span>
  <span class="n">curl</span><span class="o">::</span><span class="nf">curl_download</span><span class="p">(</span><span class="n">url</span><span class="p">٫</span> <span class="n">tf</span><span class="p">)</span>

  <span class="c1">## We don&#39;t save the file by default</span>
  <span class="nf">switch</span><span class="p">(</span><span class="n">save_file</span><span class="p">٫</span>
         <span class="n">y</span> <span class="o">=</span> <span class="n">fs</span><span class="o">::</span><span class="nf">file_copy</span><span class="p">(</span><span class="n">tf</span><span class="p">٫</span> <span class="n">destination</span><span class="p">)٫</span>
         <span class="n">n</span> <span class="o">=</span> <span class="kc">NULL</span><span class="p">)</span>

  <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">(</span><span class="n">readr</span><span class="o">::</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">tf</span><span class="p">))</span>
<span class="p">}</span>

</code></pre></td></tr></table>
</div>
</div>

<p>This will pull the data into a tibble٫ which you can then clean further (e.g.٫ put into long format) as desired.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">apple</span> <span class="o">&lt;-</span> <span class="nf">get_apple_data</span><span class="p">()</span>

<span class="c1">## target: https://covid19-static.cdn-apple.com/covid19-mobility-data/2008HotfixDev38/v3/en-us/applemobilitytrends-2020-05-21.csv</span>
<span class="c1">## Parsed with column specification:</span>
<span class="c1">## cols(</span>
<span class="c1">##   .default = col_double()٫</span>
<span class="c1">##   geo_type = col_character()٫</span>
<span class="c1">##   region = col_character()٫</span>
<span class="c1">##   transportation_type = col_character()٫</span>
<span class="c1">##   alternative_name = col_character()٫</span>
<span class="c1">##   `sub-region` = col_character()٫</span>
<span class="c1">##   country = col_character()٫</span>
<span class="c1">##   `2020-05-11` = col_logical()٫</span>
<span class="c1">##   `2020-05-12` = col_logical()</span>
<span class="c1">## )</span>
<span class="c1">## See spec(...) for full column specifications.</span>

<span class="n">apple</span>

<span class="c1">### A tibble: 3٫625 x 136</span>
<span class="c1">##   geo_type region transportation_… alternative_name sub_region country x2020_01_13 x2020_01_14 x2020_01_15</span>
<span class="c1">##   &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;            &lt;chr&gt;            &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;</span>
<span class="c1">## 1 country… Alban… driving          NA               NA         NA              100        95.3       101. </span>
<span class="c1">## 2 country… Alban… walking          NA               NA         NA              100       101.         98.9</span>
<span class="c1">## 3 country… Argen… driving          NA               NA         NA              100        97.1       102. </span>
<span class="c1">## 4 country… Argen… walking          NA               NA         NA              100        95.1       101. </span>
<span class="c1">## 5 country… Austr… driving          AU               NA         NA              100       103.        104. </span>
<span class="c1">## 6 country… Austr… transit          AU               NA         NA              100       102.        101. </span>
<span class="c1">## 7 country… Austr… walking          AU               NA         NA              100       101.        102. </span>
<span class="c1">## 8 country… Austr… driving          Österreich       NA         NA              100       101.        104. </span>
<span class="c1">## 9 country… Austr… walking          Österreich       NA         NA              100       102.        106. </span>
<span class="c1">##10 country… Belgi… driving          België|Belgique  NA         NA              100       101.        107. </span>
<span class="c1">### … with 3٫615 more rows٫ and 127 more variables: x2020_01_16 &lt;dbl&gt;٫ x2020_01_17 &lt;dbl&gt;٫ x2020_01_18 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_01_19 &lt;dbl&gt;٫ x2020_01_20 &lt;dbl&gt;٫ x2020_01_21 &lt;dbl&gt;٫ x2020_01_22 &lt;dbl&gt;٫ x2020_01_23 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_01_24 &lt;dbl&gt;٫ x2020_01_25 &lt;dbl&gt;٫ x2020_01_26 &lt;dbl&gt;٫ x2020_01_27 &lt;dbl&gt;٫ x2020_01_28 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_01_29 &lt;dbl&gt;٫ x2020_01_30 &lt;dbl&gt;٫ x2020_01_31 &lt;dbl&gt;٫ x2020_02_01 &lt;dbl&gt;٫ x2020_02_02 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_02_03 &lt;dbl&gt;٫ x2020_02_04 &lt;dbl&gt;٫ x2020_02_05 &lt;dbl&gt;٫ x2020_02_06 &lt;dbl&gt;٫ x2020_02_07 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_02_08 &lt;dbl&gt;٫ x2020_02_09 &lt;dbl&gt;٫ x2020_02_10 &lt;dbl&gt;٫ x2020_02_11 &lt;dbl&gt;٫ x2020_02_12 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_02_13 &lt;dbl&gt;٫ x2020_02_14 &lt;dbl&gt;٫ x2020_02_15 &lt;dbl&gt;٫ x2020_02_16 &lt;dbl&gt;٫ x2020_02_17 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_02_18 &lt;dbl&gt;٫ x2020_02_19 &lt;dbl&gt;٫ x2020_02_20 &lt;dbl&gt;٫ x2020_02_21 &lt;dbl&gt;٫ x2020_02_22 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_02_23 &lt;dbl&gt;٫ x2020_02_24 &lt;dbl&gt;٫ x2020_02_25 &lt;dbl&gt;٫ x2020_02_26 &lt;dbl&gt;٫ x2020_02_27 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_02_28 &lt;dbl&gt;٫ x2020_02_29 &lt;dbl&gt;٫ x2020_03_01 &lt;dbl&gt;٫ x2020_03_02 &lt;dbl&gt;٫ x2020_03_03 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_03_04 &lt;dbl&gt;٫ x2020_03_05 &lt;dbl&gt;٫ x2020_03_06 &lt;dbl&gt;٫ x2020_03_07 &lt;dbl&gt;٫ x2020_03_08 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_03_09 &lt;dbl&gt;٫ x2020_03_10 &lt;dbl&gt;٫ x2020_03_11 &lt;dbl&gt;٫ x2020_03_12 &lt;dbl&gt;٫ x2020_03_13 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_03_14 &lt;dbl&gt;٫ x2020_03_15 &lt;dbl&gt;٫ x2020_03_16 &lt;dbl&gt;٫ x2020_03_17 &lt;dbl&gt;٫ x2020_03_18 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_03_19 &lt;dbl&gt;٫ x2020_03_20 &lt;dbl&gt;٫ x2020_03_21 &lt;dbl&gt;٫ x2020_03_22 &lt;dbl&gt;٫ x2020_03_23 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_03_24 &lt;dbl&gt;٫ x2020_03_25 &lt;dbl&gt;٫ x2020_03_26 &lt;dbl&gt;٫ x2020_03_27 &lt;dbl&gt;٫ x2020_03_28 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_03_29 &lt;dbl&gt;٫ x2020_03_30 &lt;dbl&gt;٫ x2020_03_31 &lt;dbl&gt;٫ x2020_04_01 &lt;dbl&gt;٫ x2020_04_02 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_04_03 &lt;dbl&gt;٫ x2020_04_04 &lt;dbl&gt;٫ x2020_04_05 &lt;dbl&gt;٫ x2020_04_06 &lt;dbl&gt;٫ x2020_04_07 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_04_08 &lt;dbl&gt;٫ x2020_04_09 &lt;dbl&gt;٫ x2020_04_10 &lt;dbl&gt;٫ x2020_04_11 &lt;dbl&gt;٫ x2020_04_12 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_04_13 &lt;dbl&gt;٫ x2020_04_14 &lt;dbl&gt;٫ x2020_04_15 &lt;dbl&gt;٫ x2020_04_16 &lt;dbl&gt;٫ x2020_04_17 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_04_18 &lt;dbl&gt;٫ x2020_04_19 &lt;dbl&gt;٫ x2020_04_20 &lt;dbl&gt;٫ x2020_04_21 &lt;dbl&gt;٫ x2020_04_22 &lt;dbl&gt;٫</span>
<span class="c1">###   x2020_04_23 &lt;dbl&gt;٫ x2020_04_24 &lt;dbl&gt;٫ …</span>
<span class="c1">##</span>
</code></pre></td></tr></table>
</div>
</div>

'),('https://kieranhealy.org/blog/archives/2020/05/21/the-kitchen-counter-observatory/', 'The Kitchen Counter Observatory', '1590096352000',  15, '<p>Every day begins in the same way. I get up. I make my coffee. I look at the data. Everything about this is absurd. To begin with٫ there’s the absurdity that everyone with a job like mine faces each day. Locked down at home with the kids٫ trying to get things done٫ unable to properly teach٫ write٫ or think. The household is like a little spacecraft٫ drifting in the void. Occasionally you venture outside to get supplies٫ or to check the shields. I find the days are speeding up now٫ because even though things drag from moment to moment٫ each twenty-four hour period is essentially identical. It reminds me of when my children were newborns. It’s a daily slog that٫ in retrospect٫ fuses into a gray blob almost impossible to recall in any sort of differentiated way.</p>
<p>Far better٫ of course٫ to have a mild case of lockdown <em>ennui</em> than to be in the situation of those directly fighting the pandemic٫ those whose health or livelihood has been devastated by it٫ or those who carry on out in the world٫ working to fulfil essential roles. I see some of them individually٫ at my door or in my social media. I see them in the aggregate in the data. There’s <em>so much</em> data. People working at international agencies٫ universities٫ newspapers٫ magazines٫ and state and local governments put out more each day٫ trying to capture the scale and scope of the pandemic. And it’s not just official agencies and businesses٫ either. One of the best sources of daily information on the pandemic in the United States is being run by a rapidly-assembled team of freelance journalists and volunteers. The <a href="https://covidtracking.com">COVID Tracking Project</a> was brought into existence by the realization that the Centers for Disease Control were failing to provide the sort of daily updates on case counts and deaths that was part of their reason for existing.</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/us-cities-kitchen-counter.png"
         alt="City Driving Data from Apple"/> <figcaption>
            <p>Driving activity over the past three months.</p>
        </figcaption>
</figure>
<p>With a laptop٫ some free software٫ and a cup of coffee٫ I can examine what <em>ought</em> to seem like a staggering amount of information. Here٫ for example٫ is a picture showing what driving patterns have looked like every day in one hundred American cities over the past four months. As if that were a reasonable thing to be able to know while confined to your house! I drew it using information that Apple has been releasing to help researchers quantify the scope of the lockdown around the world. At this point٫ the full dataset has about half a million observations in it. Google is putting out a similar resource٫ about four times as large٫ that lets you see how busy different kinds of places are around the world over the same time period. This sort of thing doesn’t count as “big data” anymore. Back when I was a graduate student٫ I spent three days in a library manually copying down a few hundred numbers from a long-shelved report about blood donors. Now I sit here at home٫ surveying the scope of what’s being inflicted on people across the country and around the world as this disease spreads.</p>
<p>People sometimes think (or complain) that working with quantitative data like this inures you to the reality of the human lives that lie behind the numbers. Numbers and measures are crude; they pick up the wrong things; they strip out the meaning of what’s happening to real people; they make it easy to ignore what can’t be counted. There’s something to those complaints. But it’s mostly a lazy critique. In practice٫ I find that far from distancing you from questions of meaning٫ quantitative data forces you to confront them. The numbers draw you in. Working with data like this is an unending exercise in humility٫ a constant compulsion to think through what you can and cannot see٫ and a standing invitation to understand what the measures really capture—what they mean٫ and for whom. Those regular spikes in the driving data are the pulse of everyday life as people go out to have a good time at the weekend. That peak there is the Mardi Gras parade in New Orleans. That bump in Detroit was a Garth Brooks concert. Right across the country٫ that is the sudden shock of the shutdown the second weekend in March. It was a huge collective effort to buy time that٫ as it turns out٫ the federal government has more or less entirely wasted. And now through May here comes the gradual return to something like the baseline level of activity from January٫ proceeding much more quickly in some cities than in others.</p>
<p>I sit at my kitchen-counter observatory and look at the numbers. Before my coffee is ready٫ I can quickly pull down a few million rows of data courtesy of a national computer network originally designed by the government to be disaggregated and robust٫ because they were convinced that was what it would take for communication to survive a nuclear war. I can process it using software originally written by academics in their spare time٫ because they were convinced that sophisticated tools should be available to everyone for free. Through this observatory I can look out without even looking up٫ surveying the scale and scope of the country’s ongoing٫ huge٫ avoidable failure. Everything about this is absurd.</p>
'),('https://kieranhealy.org/blog/archives/2020/05/09/covid-concept-generator/', 'Covid Concept Generator', '1589029416000',  15, '<p>To save everyone some time٫ here&rsquo;s a generator for the next five years of conceptual advances in social theory. Choose once at random from each column to secure your contribution.</p>
<table>
<thead>
<tr>
<th>Column 1</th>
<th>Column 2</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sequenced</td>
<td>Stratification</td>
</tr>
<tr>
<td>Algorithmic</td>
<td>Differences</td>
</tr>
<tr>
<td>Automated</td>
<td>Capital</td>
</tr>
<tr>
<td>Robust</td>
<td>Contagion</td>
</tr>
<tr>
<td>COVID</td>
<td>Masking</td>
</tr>
<tr>
<td>Epidemiologic</td>
<td>Others</td>
</tr>
<tr>
<td>Viral</td>
<td>Politics</td>
</tr>
<tr>
<td>Rhizomatic</td>
<td>Inequality</td>
</tr>
<tr>
<td>Infectious</td>
<td>Sexualities</td>
</tr>
<tr>
<td>Compartmentalized</td>
<td>Classification</td>
</tr>
<tr>
<td>Pandemic</td>
<td>Causality</td>
</tr>
<tr>
<td>Epizootic</td>
<td>Discrimination</td>
</tr>
<tr>
<td>Transmissible</td>
<td>Polarization</td>
</tr>
<tr>
<td>Leucocyte</td>
<td>Paradox</td>
</tr>
<tr>
<td>Intersectional</td>
<td>Bodies</td>
</tr>
<tr>
<td>Corona</td>
<td>Disparities</td>
</tr>
<tr>
<td>Liquid</td>
<td>Isomorphism</td>
</tr>
<tr>
<td>Genomic</td>
<td>Populism</td>
</tr>
<tr>
<td>Nucleotide</td>
<td>Interdependence</td>
</tr>
<tr>
<td>Masked</td>
<td>Colorism</td>
</tr>
</tbody>
</table>
'),('https://kieranhealy.org/blog/archives/2020/04/28/new-orleans-and-normalization/', 'New Orleans and Normalization', '1588117010000',  15, '<p>My post about <a href="https://kieranhealy.org/blog/archives/2020/04/23/apples-covid-mobility-data/">Apple&rsquo;s mobility data</a> from a few days ago has been doing the rounds. (People have been <a href="https://sixcolors.com/link/2020/04/parsing-through-apples-covid-mobility-data/">very</a> <a href="https://daringfireball.net/linked/2020/04/26/healy-covid-mobility-data">kind</a>.) Unsurprisingly٫ one of the most thoughtful responses came from Dr. Drang٫ who wrote up a great discussion about the importance of choosing the right baseline if you&rsquo;re going to be indexing change with respect to some time. His discussion of <a href="https://leancrew.com/all-this/2020/04/small-multiples-and-normalization/">Small Multiples and Normalization</a> is really worth your while.</p>
<p>Dr. Drang&rsquo;s eye was caught by the case of Seattle٫ where the transit series was odd in a way that was related to Apple&rsquo;s arbitrary choice of January 13th as the baseline for its series:</p>
<blockquote>
<p>One effect of this normalization choice is to make the recent walking and driving requests in Seattle look higher than they should. Apple’s scores suggest that they are currently averaging 50–65% of what they were pre-COVID٫ but those are artificially high numbers because the norm was set artificially low.</p>
<p>A better way to normalize the data would be to take a week’s average٫ or a few weeks’ average٫ before social distancing and scale all the data with that set to 100.</p>
</blockquote>
<p>I&rsquo;ve been continuing to update my <a href="https://kjhealy.github.io/covdata">covdata package for R</a> as Apple٫ Google٫ and other sources release more data. This week٫ Apple substantially expanded the number of cities and regions it is providing data for. The number of cities in the dataset went up from about 90 to about 150٫ for example. As I was looking at that data this afternoon٫ I saw that one of the new cities was New Orleans. Like Seattle٫ it&rsquo;s an important city in the story of COVID-19 transmission within its region. And٫ as it turns out٫ even more so than Seattle٫ its series in this particular dataset is warped by the choice of start date. Here are three views of the New Orleans data: the raw series for each mode٫ the trend component of an STL time series decomposition٫ and the remainder component of the decomposition. (The methods and code are the same as <a href="https://kieranhealy.org/blog/archives/2020/04/23/apples-covid-mobility-data/">previously shown</a>.)</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/nolac_raw.png"
         alt="Raw New Orleans series"/> <figcaption>
            <p>The New Orleans series as provided by Apple. Click or touch to zoom in.</p>
        </figcaption>
</figure>
<figure>
    <img src="https://kieranhealy.org/files/misc/nolac_trend.png"
         alt="New Orleans trend component"/> <figcaption>
            <p>The trend component of the New Orleans series. Click or touch to zoom in.</p>
        </figcaption>
</figure>
<figure>
    <img src="https://kieranhealy.org/files/misc/nolac_remainders.png"
         alt="New Orleans remainder component"/> <figcaption>
            <p>The remainder component of the New Orleans series. Click or touch to zoom in.</p>
        </figcaption>
</figure>
<p>Two things are evident right away. First٫ New Orleans has a huge spike in foot-traffic (and other movement around town) the weekend before Mardi Gras٫ and on Shrove Tuesday itself. The spike is likely accentuated by the tourist traffic. As I noted before٫ because Apple&rsquo;s data is derived from the use of Maps for directions٫ the movements of people who know their way around town aren&rsquo;t going to show up.</p>
<p>The second thing that jumps out about the series is that for most of January and February٫ the city is way٫ way below its notional baseline. How can weekday foot traffic٫ in particular٫ routinely be 75 percentage points below the January starting point?</p>
<p>The answer is that on January 13th٫ <a href="https://www.ncaa.com/game/3959666">Clemson played LSU in the NCAA National Football Championship</a> at the New Orleans Superdome. (LSU won 42-25.) This presumably brought a big influx of visitors to town٫ many of whom were using their iPhones to direct themselves around the city. Because Apple chose January 13th as its baseline day٫ this unusually busy Monday was marked as the &ldquo;100&rdquo; mark against which subsequent activity was indexed. Again٫ as with <a href="https://kieranhealy.org/blog/archives/2020/04/23/apples-covid-mobility-data/">the strange case of European urban transit</a>٫ a naive analysis٫ or even a &ldquo;sophisticated&rdquo; one where the researcher did not bother to <a href="https://www.amazon.com/Data-Visualization-Introduction-Kieran-Healy/dp/0691181624">look at the data first</a>٫ might easily lead up the garden path.</p>
<p>Dr. Drang has <a href="https://leancrew.com/all-this/2020/04/small-multiples-and-normalization/">already said</a> most of what I&rsquo;d say at this point about the value of checking the sanity of one&rsquo;s starting point (and unlike me٫ he says it in Python) so I won&rsquo;t belabor the point. You can see٫ though٫ just how huge Mardi Gras is in New Orleans. Were the data properly normalized٫ the Fat Tuesday spike would be far٫ far higher than most of the rest of the dataset.</p>
'),('https://kieranhealy.org/blog/archives/2020/04/23/apples-covid-mobility-data/', 'Apple"s COVID Mobility Data', '1587644168000',  15, '<div class="admonition info"><p class="admonition-title">Update</p>
<p>I&rsquo;ve added a <a href="https://github.com/kjhealy/apple_covid_post">GitHub repository</a> containing the code needed to reproduce the graphs in this post٫ as what&rsquo;s shown here isn&rsquo;t self-contained.</p>
</div>
<p>Apple recently released <a href="https://www.apple.com/covid19/mobility">a batch of mobility data</a> in connection with the COVID-19 pandemic. The data is aggregated from requests for directions in Apple Maps and is provided at the level of whole countries and also for a selection of large cities around the world. I folded the dataset into the <a href="https://kjhealy.github.io/covdata/">covdata package for R</a> that I&rsquo;ve been updating٫ as I plan to use it this Fall in a course I&rsquo;ll be teaching. Here I&rsquo;ll take a quick look at some of the data. Along the way&mdash;as it turns out&mdash;I end up reminding myself of a lesson I&rsquo;ve learned before about making sure you understand your measure before you think you understand what it is showing.</p>
<p>Apple released time series data for countries and cities for each of three modes of getting around: driving٫ public transit٫ and walking. The series begins on January 13th and٫ at the time of writing٫ continues down to April 20th. The mobility measures for every country or city are indexed to 100 at the beginning of the series٫ so trends are relative to that baseline. We don&rsquo;t know anything about the absolute volume of usage of the Maps service.</p>
<p>Here&rsquo;s what the data look like:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="o">&gt;</span> <span class="n">apple_mobility</span>
<span class="c1"># A tibble: 39٫500 x 5</span>
   <span class="n">geo_type</span>       <span class="n">region</span>  <span class="n">transportation_type</span> <span class="n">date</span>       <span class="n">index</span>
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>          <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>               <span class="o">&lt;</span><span class="n">date</span><span class="o">&gt;</span>     <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>
 <span class="m">1</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-13</span> <span class="m">100</span>  
 <span class="m">2</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-14</span>  <span class="m">95.3</span>
 <span class="m">3</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-15</span> <span class="m">101</span><span class="n">. </span>
 <span class="m">4</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-16</span>  <span class="m">97.2</span>
 <span class="m">5</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-17</span> <span class="m">104</span><span class="n">. </span>
 <span class="m">6</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-18</span> <span class="m">113</span><span class="n">. </span>
 <span class="m">7</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-19</span> <span class="m">105</span><span class="n">. </span>
 <span class="m">8</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-20</span>  <span class="m">94.4</span>
 <span class="m">9</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-21</span>  <span class="m">94.1</span>
<span class="m">10</span> <span class="n">country</span><span class="o">/</span><span class="n">region</span> <span class="n">Albania</span> <span class="n">driving</span>             <span class="m">2020-01-22</span>  <span class="m">93.5</span>
<span class="c1"># … with 39٫490 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>The <code>index</code> is the measured outcome٫ tracking relative usage of directions for each mode of transportation. Let&rsquo;s take a look at the data for New York.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">raw_ny</span> <span class="o">&lt;-</span> <span class="n">apple_mobility</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">region</span> <span class="o">==</span> <span class="s">&#34;New York City&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">region</span><span class="o">:</span><span class="n">index</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">rename</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">transportation_type</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">tools</span><span class="o">::</span><span class="nf">toTitleCase</span><span class="p">(</span><span class="n">mode</span><span class="p">)٫</span>
         <span class="n">weekend</span> <span class="o">=</span> <span class="nf">isWeekend</span><span class="p">(</span><span class="n">date</span><span class="p">)٫</span>
         <span class="n">holiday</span> <span class="o">=</span> <span class="nf">isHoliday</span><span class="p">(</span><span class="nf">as.timeDate</span><span class="p">(</span><span class="n">date</span><span class="p">)٫</span> <span class="nf">listHolidays</span><span class="p">()))</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">max_day</span> <span class="o">=</span> <span class="nf">ifelse</span><span class="p">(</span><span class="nf">is_max</span><span class="p">(</span><span class="n">index</span><span class="p">)٫</span> <span class="n">date</span><span class="p">٫</span> <span class="kc">NA</span><span class="p">)٫</span>
         <span class="n">max_day</span> <span class="o">=</span> <span class="nf">as_date</span><span class="p">(</span><span class="n">max_day</span><span class="p">))</span>

<span class="n">p_raw_ny</span> <span class="o">&lt;-</span> <span class="nf">ggplot</span><span class="p">(</span><span class="n">raw_ny</span><span class="p">٫</span> <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">date</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="n">index</span><span class="p">٫</span>
                                      <span class="n">group</span> <span class="o">=</span> <span class="n">mode</span><span class="p">٫</span> <span class="n">color</span> <span class="o">=</span> <span class="n">mode</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">geom_vline</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">subset</span><span class="p">(</span><span class="n">raw_ny</span><span class="p">٫</span> <span class="n">holiday</span> <span class="o">==</span> <span class="kc">TRUE</span><span class="p">)٫</span>
             <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">xintercept</span> <span class="o">=</span> <span class="n">date</span><span class="p">)٫</span>
             <span class="n">color</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">)</span><span class="n">[5]</span><span class="p">٫</span> <span class="n">size</span> <span class="o">=</span> <span class="m">2.9</span><span class="p">٫</span> <span class="n">alpha</span> <span class="o">=</span> <span class="m">0.1</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_hline</span><span class="p">(</span><span class="n">yintercept</span> <span class="o">=</span> <span class="m">100</span><span class="p">٫</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;gray40&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_line</span><span class="p">()</span> <span class="o">+</span>
  <span class="nf">geom_text_repel</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">label</span> <span class="o">=</span> <span class="nf">format</span><span class="p">(</span><span class="n">max_day</span><span class="p">٫</span> <span class="n">format</span> <span class="o">=</span> <span class="s">&#34;%a %b %d&#34;</span><span class="p">))٫</span>
                  <span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">)٫</span> <span class="n">nudge_x</span> <span class="o">=</span> <span class="m">1</span><span class="p">٫</span> <span class="n">show.legend</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Date&#34;</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Relative Mobility&#34;</span><span class="p">٫</span>
       <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;Mode&#34;</span><span class="p">٫</span>
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;New York City&#39;s relative trends in activity. Baseline data with no correction for weekly seasonality&#34;</span><span class="p">٫</span>
       <span class="n">subtitle</span> <span class="o">=</span> <span class="s">&#34;Data are indexed to 100 for usage on January 13th 2020. Weekends shown as vertical bars. Date with highest relative activity index labeled.\nNote that in Apple&#39;s data &#39;Days&#39; are defined as Midnight to Midnight PST.&#34;</span><span class="p">٫</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Data: Apple. Graph: @kjhealy&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;top&#34;</span><span class="p">)</span>

<span class="n">p_raw_ny</span>
</code></pre></td></tr></table>
</div>
</div>

<figure>
    <img src="https://kieranhealy.org/files/misc/apple_nyc_raw.png"
         alt="Relative Mobility in New York City. Touch or click to zoom."/> <figcaption>
            <p>Relative Mobility in New York City. Touch or click to zoom.</p>
        </figcaption>
</figure>
<p>As you can see٫ we have three series. The weekly pulse of activity is immediately visible as people do more or less walking٫ driving٫ and taking the subway depending on what day it is. Remember that the data is based on requests for directions. So on the one hand٫ taxis and Ubers might be making that sort of request every trip. But people living in New York do not require turn-by-turn or step-by-step directions in order to get to work. They already know how to get to work. Even if overall activity is down at the weekends٫ requests for directions go up as people figure out how to get to restaurants٫ social events٫ or other destinations. On the graph here I&rsquo;ve marked the highest relative value of requests for directions٫ which is for foot-traffic on February 22nd. I&rsquo;m not interested in that particular date for New York٫ but when we look at more than one city it might be useful to see how the maximum values vary.</p>
<p>The big COVID-related drop-off in mobility clearly comes in mid-March. We might want to see just that trend٫ removing the &ldquo;noise&rdquo; of daily variation. When looking at time series٫ we often want to decompose the series into components٫ in order to see some underlying trend. There are many ways to do this٫ and many decisions to be made if we&rsquo;re going to be making any strong inferences from the data. Here I&rsquo;ll just keep it straightforward and use some of the very handy tools provided by the <a href="https://tidyverts.org">tidyverts</a> (sic) packages for time-series analysis. We&rsquo;ll use an <a href="https://feasts.tidyverts.org/reference/STL.html">STL decomposition</a> to decompose the series into <em>trend</em>٫ <em>seasonal</em>٫ and <em>remainder</em> components. In this case the &ldquo;season&rdquo; is a week rather than a month or a calendar quarter. The trend is a locally-weighted regression fitted to the data٫ net of seasonality. The remainder is the residual left over on any given day once the underlying trend and &ldquo;normal&rdquo; daily fluctuations have been accounted for. Here&rsquo;s the trend for New York.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">resids_ny</span> <span class="o">&lt;-</span> <span class="n">apple_mobility</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">region</span> <span class="o">==</span> <span class="s">&#34;New York City&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">region</span><span class="o">:</span><span class="n">index</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">rename</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">transportation_type</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">tools</span><span class="o">::</span><span class="nf">toTitleCase</span><span class="p">(</span><span class="n">mode</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">as_tsibble</span><span class="p">(</span><span class="n">key</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">region</span><span class="p">٫</span> <span class="n">mode</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">model</span><span class="p">(</span><span class="nf">STL</span><span class="p">(</span><span class="n">index</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">components</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">weekend</span> <span class="o">=</span> <span class="nf">isWeekend</span><span class="p">(</span><span class="n">date</span><span class="p">)٫</span>
         <span class="n">holiday</span> <span class="o">=</span> <span class="nf">isHoliday</span><span class="p">(</span><span class="nf">as.timeDate</span><span class="p">(</span><span class="n">date</span><span class="p">)٫</span> <span class="nf">listHolidays</span><span class="p">()))</span> <span class="o">%&gt;%</span>
  <span class="nf">as_tibble</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">max_day</span> <span class="o">=</span> <span class="nf">ifelse</span><span class="p">(</span><span class="nf">is_max</span><span class="p">(</span><span class="n">remainder</span><span class="p">)٫</span> <span class="n">date</span><span class="p">٫</span> <span class="kc">NA</span><span class="p">)٫</span>
         <span class="n">max_day</span> <span class="o">=</span> <span class="nf">as_date</span><span class="p">(</span><span class="n">max_day</span><span class="p">))</span>

<span class="n">p_resid_ny</span> <span class="o">&lt;-</span> <span class="nf">ggplot</span><span class="p">(</span><span class="n">resids_ny</span><span class="p">٫</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">date</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="n">remainder</span><span class="p">٫</span> <span class="n">group</span> <span class="o">=</span> <span class="n">mode</span><span class="p">٫</span> <span class="n">color</span> <span class="o">=</span> <span class="n">mode</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">geom_vline</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">subset</span><span class="p">(</span><span class="n">resids</span><span class="p">٫</span> <span class="n">holiday</span> <span class="o">==</span> <span class="kc">TRUE</span><span class="p">)٫</span>
             <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">xintercept</span> <span class="o">=</span> <span class="n">date</span><span class="p">)٫</span>
             <span class="n">color</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">)</span><span class="n">[5]</span><span class="p">٫</span> <span class="n">size</span> <span class="o">=</span> <span class="m">2.9</span><span class="p">٫</span> <span class="n">alpha</span> <span class="o">=</span> <span class="m">0.1</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_line</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="m">0.5</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_text_repel</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">label</span> <span class="o">=</span> <span class="nf">format</span><span class="p">(</span><span class="n">max_day</span><span class="p">٫</span> <span class="n">format</span> <span class="o">=</span> <span class="s">&#34;%a %b %d&#34;</span><span class="p">))٫</span>
                  <span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">)٫</span> <span class="n">nudge_x</span> <span class="o">=</span> <span class="m">1</span><span class="p">٫</span> <span class="n">show.legend</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Date&#34;</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Remainder&#34;</span><span class="p">٫</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;Mode&#34;</span><span class="p">٫</span>
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;New York City٫ Remainder component for activity data&#34;</span><span class="p">٫</span>
       <span class="n">subtitle</span> <span class="o">=</span> <span class="s">&#34;Weekends shown as vertical bars. Date with highest remainder component labeled.\nNote that in Apple&#39;s data &#39;Days&#39; are defined as Midnight to Midnight PST.&#34;</span><span class="p">٫</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Data: Apple. Graph: @kjhealy&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;top&#34;</span><span class="p">)</span>
  
 <span class="n">p_resid_ny</span> 
</code></pre></td></tr></table>
</div>
</div>

<figure>
    <img src="https://kieranhealy.org/files/misc/apple_nyc_trend.png"
         alt="Trend component of the New York series. Touch or click to zoom."/> <figcaption>
            <p>Trend component of the New York series. Touch or click to zoom.</p>
        </figcaption>
</figure>
<p>We can make a small multiple graph showing the raw data (or the components٫ as we please) for all the cities in the dataset if we like:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">p_base_all</span> <span class="o">&lt;-</span> <span class="n">apple_mobility</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">geo_type</span> <span class="o">==</span> <span class="s">&#34;city&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">region</span><span class="o">:</span><span class="n">index</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">rename</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">transportation_type</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">ggplot</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">date</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="n">index</span><span class="p">٫</span> <span class="n">group</span> <span class="o">=</span> <span class="n">mode</span><span class="p">٫</span> <span class="n">color</span> <span class="o">=</span> <span class="n">mode</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">geom_line</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="m">0.5</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">facet_wrap</span><span class="p">(</span><span class="o">~</span> <span class="n">region</span><span class="p">٫</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">8</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Date&#34;</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Trend&#34;</span><span class="p">٫</span>
       <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;Mode&#34;</span><span class="p">٫</span>
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;All Modes٫ All Cities٫ Base Data&#34;</span><span class="p">٫</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Data: Apple. Graph: @kjhealy&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;top&#34;</span><span class="p">)</span>

<span class="n">p_base_all</span>
</code></pre></td></tr></table>
</div>
</div>

<figure>
    <img src="https://kieranhealy.org/files/misc/apple_all_cities_raw.png"
         alt="Data for all cities. Touch or click to zoom."/> <figcaption>
            <p>Data for all cities. Touch or click to zoom.</p>
        </figcaption>
</figure>
<p>This isn&rsquo;t the sort of graph that&rsquo;s going to look great on your phone٫ but it&rsquo;s useful for getting some overall sense of the trends. Beyond the sharp declines everywhere&mdash;with slightly different timings٫ something that&rsquo;d be worth looking at separately&mdash;a few other things pop out. There&rsquo;s a fair amount of variation across cities by mode of transport and also by the intensity of the seasonal component. Some sharp spikes are evident٫ too٫ not always on the same day or by the same mode of transport. We can take a closer look at some of the cities of interest on this front.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">focus_on</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;Rio de Janeiro&#34;</span><span class="p">٫</span> <span class="s">&#34;Lyon&#34;</span><span class="p">٫</span> <span class="s">&#34;Bochum - Dortmund&#34;</span><span class="p">٫</span> <span class="s">&#34;Dusseldorf&#34;</span><span class="p">٫</span>
              <span class="s">&#34;Barcelona&#34;</span><span class="p">٫</span> <span class="s">&#34;Detroit&#34;</span><span class="p">٫</span> <span class="s">&#34;Toulouse&#34;</span><span class="p">٫</span> <span class="s">&#34;Stuttgart&#34;</span><span class="p">٫</span>
              <span class="s">&#34;Cologne&#34;</span><span class="p">٫</span> <span class="s">&#34;Hamburg&#34;</span><span class="p">٫</span> <span class="s">&#34;Cairo&#34;</span><span class="p">٫</span> <span class="s">&#34;Lille&#34;</span><span class="p">)</span>

<span class="n">raw_ts</span> <span class="o">&lt;-</span> <span class="n">apple_mobility</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">geo_type</span> <span class="o">==</span> <span class="s">&#34;city&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">region</span><span class="o">:</span><span class="n">index</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">rename</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">transportation_type</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">tools</span><span class="o">::</span><span class="nf">toTitleCase</span><span class="p">(</span><span class="n">mode</span><span class="p">)٫</span>
         <span class="n">weekend</span> <span class="o">=</span> <span class="nf">isWeekend</span><span class="p">(</span><span class="n">date</span><span class="p">)٫</span>
         <span class="n">holiday</span> <span class="o">=</span> <span class="nf">isHoliday</span><span class="p">(</span><span class="nf">as.timeDate</span><span class="p">(</span><span class="n">date</span><span class="p">)٫</span> <span class="nf">listHolidays</span><span class="p">()))</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">region</span> <span class="o">%in%</span> <span class="n">focus_on</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">region</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">max_day</span> <span class="o">=</span> <span class="nf">ifelse</span><span class="p">(</span><span class="nf">is_max</span><span class="p">(</span><span class="n">index</span><span class="p">)٫</span> <span class="n">date</span><span class="p">٫</span> <span class="kc">NA</span><span class="p">)٫</span>
         <span class="n">max_day</span> <span class="o">=</span> <span class="nf">as_date</span><span class="p">(</span><span class="n">max_day</span><span class="p">))</span>
         
<span class="nf">ggplot</span><span class="p">(</span><span class="n">raw_ts</span><span class="p">٫</span> <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">date</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="n">index</span><span class="p">٫</span>
                                      <span class="n">group</span> <span class="o">=</span> <span class="n">mode</span><span class="p">٫</span> <span class="n">color</span> <span class="o">=</span> <span class="n">mode</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">geom_vline</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">subset</span><span class="p">(</span><span class="n">raw_ts</span><span class="p">٫</span> <span class="n">holiday</span> <span class="o">==</span> <span class="kc">TRUE</span><span class="p">)٫</span>
             <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">xintercept</span> <span class="o">=</span> <span class="n">date</span><span class="p">)٫</span>
             <span class="n">color</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">)</span><span class="n">[5]</span><span class="p">٫</span> <span class="n">size</span> <span class="o">=</span> <span class="m">1.5</span><span class="p">٫</span> <span class="n">alpha</span> <span class="o">=</span> <span class="m">0.1</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_hline</span><span class="p">(</span><span class="n">yintercept</span> <span class="o">=</span> <span class="m">100</span><span class="p">٫</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;gray40&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_line</span><span class="p">()</span> <span class="o">+</span>
  <span class="nf">geom_text_repel</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">label</span> <span class="o">=</span> <span class="nf">format</span><span class="p">(</span><span class="n">max_day</span><span class="p">٫</span> <span class="n">format</span> <span class="o">=</span> <span class="s">&#34;%a %b %d&#34;</span><span class="p">))٫</span>
                  <span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">)٫</span> <span class="n">nudge_x</span> <span class="o">=</span> <span class="m">1</span><span class="p">٫</span> <span class="n">show.legend</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">facet_wrap</span><span class="p">(</span><span class="o">~</span> <span class="n">region</span><span class="p">٫</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">2</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Date&#34;</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Relative Mobility&#34;</span><span class="p">٫</span>
       <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;Mode&#34;</span><span class="p">٫</span>
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Relative trends in activity٫ selected cities. No seasonal correction.&#34;</span><span class="p">٫</span>
       <span class="n">subtitle</span> <span class="o">=</span> <span class="s">&#34;Data are indexed to 100 for each city&#39;s usage on January 13th 2020. Weekends shown as vertical bars.\nDate with highest relative activity index labeled.\nNote that in Apple&#39;s data &#39;Days&#39; are defined as Midnight to Midnight PST.&#34;</span><span class="p">٫</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Data: Apple. Graph: @kjhealy&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;top&#34;</span><span class="p">)</span>         

</code></pre></td></tr></table>
</div>
</div>

<figure>
    <img src="https://kieranhealy.org/files/misc/apple_raw_tall.png"
         alt="Selected cities only. Touch or click to zoom."/> <figcaption>
            <p>Selected cities only. Touch or click to zoom.</p>
        </figcaption>
</figure>
<p>Look at all those transit peaks on February 17th. What&rsquo;s going on here? At this point٫ we could take a look at the residual or remainder component of the series rather than looking at the raw data٫ so we can see if something interesting is happening.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">resids</span> <span class="o">&lt;-</span> <span class="n">apple_mobility</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">geo_type</span> <span class="o">==</span> <span class="s">&#34;city&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">region</span><span class="o">:</span><span class="n">index</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">rename</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">transportation_type</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="n">tools</span><span class="o">::</span><span class="nf">toTitleCase</span><span class="p">(</span><span class="n">mode</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">region</span> <span class="o">%in%</span> <span class="n">focus_on</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">as_tsibble</span><span class="p">(</span><span class="n">key</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">region</span><span class="p">٫</span> <span class="n">mode</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">model</span><span class="p">(</span><span class="nf">STL</span><span class="p">(</span><span class="n">index</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">components</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">weekend</span> <span class="o">=</span> <span class="nf">isWeekend</span><span class="p">(</span><span class="n">date</span><span class="p">)٫</span>
         <span class="n">holiday</span> <span class="o">=</span> <span class="nf">isHoliday</span><span class="p">(</span><span class="nf">as.timeDate</span><span class="p">(</span><span class="n">date</span><span class="p">)٫</span> <span class="nf">listHolidays</span><span class="p">()))</span> <span class="o">%&gt;%</span>
  <span class="nf">as_tibble</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">region</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">max_day</span> <span class="o">=</span> <span class="nf">ifelse</span><span class="p">(</span><span class="nf">is_max</span><span class="p">(</span><span class="n">remainder</span><span class="p">)٫</span> <span class="n">date</span><span class="p">٫</span> <span class="kc">NA</span><span class="p">)٫</span>
         <span class="n">max_day</span> <span class="o">=</span> <span class="nf">as_date</span><span class="p">(</span><span class="n">max_day</span><span class="p">))</span>
         
<span class="nf">ggplot</span><span class="p">(</span><span class="n">resids</span><span class="p">٫</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">date</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="n">remainder</span><span class="p">٫</span> <span class="n">group</span> <span class="o">=</span> <span class="n">mode</span><span class="p">٫</span> <span class="n">color</span> <span class="o">=</span> <span class="n">mode</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">geom_vline</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">subset</span><span class="p">(</span><span class="n">resids</span><span class="p">٫</span> <span class="n">holiday</span> <span class="o">==</span> <span class="kc">TRUE</span><span class="p">)٫</span>
             <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">xintercept</span> <span class="o">=</span> <span class="n">date</span><span class="p">)٫</span>
             <span class="n">color</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">)</span><span class="n">[5]</span><span class="p">٫</span> <span class="n">size</span> <span class="o">=</span> <span class="m">1.5</span><span class="p">٫</span> <span class="n">alpha</span> <span class="o">=</span> <span class="m">0.1</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_line</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="m">0.5</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_text_repel</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">label</span> <span class="o">=</span> <span class="nf">format</span><span class="p">(</span><span class="n">max_day</span><span class="p">٫</span> <span class="n">format</span> <span class="o">=</span> <span class="s">&#34;%a %b %d&#34;</span><span class="p">))٫</span>
                  <span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">)٫</span> <span class="n">nudge_x</span> <span class="o">=</span> <span class="m">1</span><span class="p">٫</span> <span class="n">show.legend</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">facet_wrap</span><span class="p">(</span><span class="o">~</span> <span class="n">region</span><span class="p">٫</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">2</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Date&#34;</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Remainder&#34;</span><span class="p">٫</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;Mode&#34;</span><span class="p">٫</span>
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Remainder component for activity data (after trend and weekly components removed)&#34;</span><span class="p">٫</span>
       <span class="n">subtitle</span> <span class="o">=</span> <span class="s">&#34;Weekends shown as vertical bars. Date with highest remainder component labeled.\nNote that in Apple&#39;s data &#39;Days&#39; are defined as Midnight to Midnight PST.&#34;</span><span class="p">٫</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Data: Apple. Graph: @kjhealy&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;top&#34;</span><span class="p">)</span>         
</code></pre></td></tr></table>
</div>
</div>

<figure>
    <img src="https://kieranhealy.org/files/misc/apple_remainders_tall.png"
         alt="Remainder components only. Touch or click to zoom."/> <figcaption>
            <p>Remainder components only. Touch or click to zoom.</p>
        </figcaption>
</figure>
<p>We can see that there&rsquo;s a fair amount of correspondence between the spikes in activity٫ but it&rsquo;s not clear what the explanation is. For some cities things seem straightforward. Rio de Janiero&rsquo;s huge spike in foot traffic corresponds to the Carnival parade around the week of Mardi Gras. As it turns out&mdash;<a href="https://twitter.com/FOchsenfeld/status/1253047574392684546?s=20">thanks</a> to some <a href="https://twitter.com/RenseC/status/1253035699999211526?s=20">local</a> <a href="https://twitter.com/Andre_Serious/status/1253035880568193030?s=20">informants</a> for <a href="https://twitter.com/Eule_Geheule/status/1253036239445536768?s=20">this</a>&mdash;the same is true of Cologne٫ where Carnival season (<a href="https://en.wikipedia.org/wiki/Carnival_in_Germany٫_Switzerland_and_Austria">Fasching</a>) is also a big thing. But that doesn&rsquo;t explain the spikes that repeatedly show up for February 17th in a number of German and French provincial cities. It&rsquo;s a week too early. And why specifically in <em>transit</em> requests? What&rsquo;s going on there? Initially I speculated that it might be connected to events like football matches or something like that٫ but that didn&rsquo;t seem very convincing٫ because those happen week-in week-out٫ and if it were an unusual event (like a final) we wouldn&rsquo;t see it across so many cities. A second possibility was some widely-shared calendar event that would cause a lot of people to start riding public transit. The beginning or end of school holidays٫ for example٫ seemed like a plausible candidate. But if that were the case why didn&rsquo;t we see it in other٫ larger cities in these countries? And are France and Germany on the same school calendars? This isn&rsquo;t around Easter٫ so it seems unlikely.</p>
<p>After wondering aloud about this on Twitter٫ the best candidate for an explanation came from <a href="https://twitter.com/SebastianGeukes/status/1253074673123897357?s=20">Sebastian Geukes</a>. He pointed out that the February 17th spikes coincide with <a href="https://www.cultofmac.com/685221/apple-maps-transit-directions-expand-europe/">Apple rolling out expanded coverage of many European cities in the Maps app</a>. That Monday marks the beginning of public transit directions becoming available to iPhone users in these cities. And so٫ unsurprisingly٫ the result is a surge in people using Maps for that purpose٫ in comparison to when it wasn&rsquo;t a feature. I say &ldquo;unsurprisingly&rdquo;٫ but of course it took a little while to figure this out! And I didn&rsquo;t figure it out myself٫ either. It&rsquo;s an excellent illustration of a rule of thumb I wrote about <a href="https://kieranhealy.org/blog/archives/2018/08/01/i-cant-believe-its-not-butter/">a while ago</a> in a similar context.</p>
<blockquote>
<p>As a rule٫ when you see a sharp change in a long-running time-series٫ you should always check to see if some aspect of the data-generating process changed—such as the measurement device or the criteria for inclusion in the dataset—before coming up with any substantive stories about what happened and why. This is especially the case for something susceptible to change over time٫ but not to extremely rapid fluctuations. &hellip;  As Tom Smith٫ the director of the General Social Survey٫ likes to say٫ if you want to measure change٫ you can’t change the measure.</p>
</blockquote>
<p>In this case٫ there&rsquo;s a further wrinkle. I probably would have been quicker to twig what was going on had I looked a little harder at the raw data rather than moving to the remainder component of the time series decomposition. Having had my eye caught by Rio&rsquo;s big Carnival spike I went to look at the remainder component for all these cities and so ended up focusing on that. But if you look again at the raw city trends you can see that the transit data series (the blue line) spikes up on February 17th but then <em>sticks around</em> afterwards٫ settling in to a regular presence٫ at quite a high relative level in comparison to its previous non-existence. And this of course is because people have begun to use this new feature regularly. If we&rsquo;d had raw data on the absolute levels of usage in transit directions this would likely have been clear more quickly.</p>
<p>The tendency to launch right into what social scientists call the &ldquo;Storytime!&rdquo; phase of data analysis when looking at some graph or table of results is really strong. We already know from other COVID-related analysis how tricky and indeed dangerous it can be to mistakenly infer too much from what you think you see in the data. (<a href="https://statmodeling.stat.columbia.edu/2020/04/19/fatal-flaws-in-stanford-study-of-coronavirus-prevalence/">Here&rsquo;s a recent example.</a>) Taking care to understand what your measurement instrument is doing really does matter. In this case٫ I think٫ it&rsquo;s all the more important because with data of the sort that Apple (and also <a href="https://www.google.com/covid19/mobility/index.html?hl=en">Google</a>) have released٫ it&rsquo;s fun to just jump into it and start speculating. That&rsquo;s because we don&rsquo;t often get to play with even highly aggregated data from sources like this. I wonder if٫ in the next year or so٫ someone doing an ecological٫ city-level  analysis of social response to COVID-19 will inadvertently get caught out by the change in the measure lurking in this dataset.</p>
'),('https://kieranhealy.org/blog/archives/2020/04/16/upset-plots/', 'Upset Plots', '1587065371000',  15, '<p>The other day <a href="https://www.nature.com/articles/d41586-020-01023-2">Nature</a> reported some preliminary results from a study of COVID-19 symptoms that&rsquo;s being carried out via a phone app. The report noted that loss of sense of smell (or &ldquo;Anosmia&rdquo;) seemed to be a common symptom. The report was accompanied by this graphic٫ showing the co-occurrence of symptoms in about 1٫700 self-reports via the app.</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/covid-symptoms-venn.jpg"
         alt="COVID Symptoms Venn Diagram"/> <figcaption>
            <p>A species of Venn Diagram showing the co-occurrence of reported COVID-19 symptoms.</p>
        </figcaption>
</figure>
<p>(Again٫ please bear in mind that these are preliminary results from the users of a single smartphone app.)</p>
<p>I think it&rsquo;s fair to say that this way of representing the data is pushing the Venn Diagram approach to its limits. It&rsquo;s hard to get a sense of what&rsquo;s going on. That said٫ representing what are in effect tables of cross-classified counts or frequencies is one of those aspects of data visualization that is surprisingly hard to do effectively. If you have a large number of categories and cross-classifications of discrete measures٫ things get messy very fast. Continuous data are much easier to display٫ by comparison.</p>
<p>Still٫ we can do better. One familiar option would be a heatmap of some sort٫ showing a matrix of symptoms&mdash;perhaps clustered how often they occur together&mdash;with the cells shaded by the counts or frequencies. More recently٫ the <em>upset plot</em>٫ developed by <a href="https://ieeexplore.ieee.org/document/6876017">Lex et al</a> (2014)٫ has emerged as a useful alternative. An upset plot arranges your co-occurring variables into sets and shows you a bar chart of their frequency. The trick is that it tries to make it easy to see the elements that make up the set.</p>
<p>There are several implementations of upset plots in R. I&rsquo;m going to use the <a href="https://github.com/krassowski/complex-upset">Complex UpSet</a> package٫ but they&rsquo;re all good. Check out <a href="https://github.com/hms-dbmi/UpSetR">UpSetR</a>٫ and <a href="https://github.com/const-ae/ggupset">ggupset</a> as well.</p>
<p>I used a spreadsheet to copy out the data from the <em>Nature</em> report٫ and then loaded it in to R.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">symptoms</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;Anosmia&#34;</span><span class="p">٫</span> <span class="s">&#34;Cough&#34;</span><span class="p">٫</span> <span class="s">&#34;Fatigue&#34;</span><span class="p">٫</span> <span class="s">&#34;Diarrhea&#34;</span><span class="p">٫</span> <span class="s">&#34;Breath&#34;</span><span class="p">٫</span> <span class="s">&#34;Fever&#34;</span><span class="p">)</span>
<span class="nf">names</span><span class="p">(</span><span class="n">symptoms</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="n">symptoms</span>


<span class="n">dat</span> <span class="o">&lt;-</span> <span class="n">readxl</span><span class="o">::</span><span class="nf">read_xlsx</span><span class="p">(</span><span class="s">&#34;data/symptoms.xlsx&#34;</span><span class="p">)</span> 
<span class="n">dat</span> <span class="o">%&gt;%</span> <span class="nf">print</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">dat</span><span class="p">))</span>

<span class="c1">## # A tibble: 32 x 2</span>
<span class="c1">##    combination                                 count</span>
<span class="c1">##    &lt;chr&gt;                                       &lt;dbl&gt;</span>
<span class="c1">##  1 Anosmia                                       140</span>
<span class="c1">##  2 Cough                                          57</span>
<span class="c1">##  3 Fatigue                                       198</span>
<span class="c1">##  4 Diarrhea                                       12</span>
<span class="c1">##  5 Breath                                          5</span>
<span class="c1">##  6 Fever                                          11</span>
<span class="c1">##  7 Cough&amp;Fatigue                                 179</span>
<span class="c1">##  8 Fatigue&amp;Fever                                  28</span>
<span class="c1">##  9 Breath&amp;Fatigue                                 10</span>
<span class="c1">## 10 Diarrhea&amp;Fatigue                               43</span>
<span class="c1">## 11 Anosmia&amp;Fatigue                               281</span>
<span class="c1">## 12 Breath&amp;Cough                                    1</span>
<span class="c1">## 13 Anosmia&amp;Diarrhea&amp;Fatigue                       64</span>
<span class="c1">## 14 Breath&amp;Cough&amp;Fatigue                           22</span>
<span class="c1">## 15 Anosmia&amp;Cough&amp;Fatigue                         259</span>
<span class="c1">## 16 Anosmia&amp;Fever&amp;Fatigue                          46</span>
<span class="c1">## 17 Cough&amp;Fever&amp;Fatigue                            54</span>
<span class="c1">## 18 Cough&amp;Diarrhea                                  7</span>
<span class="c1">## 19 Cough&amp;Diarrhea&amp;Fatigue                         31</span>
<span class="c1">## 20 Anosmia&amp;Breath&amp;Cough&amp;Fatigue                   26</span>
<span class="c1">## 21 Anosmia&amp;Cough&amp;Fatigue&amp;Fever                    69</span>
<span class="c1">## 22 Anosmia&amp;Breath&amp;Cough&amp;Diarrhea&amp;Fatigue          18</span>
<span class="c1">## 23 Anosmia&amp;Breath&amp;Cough&amp;Fatigue&amp;Fever             17</span>
<span class="c1">## 24 Breath&amp;Cough&amp;Fatigue&amp;Fever                     11</span>
<span class="c1">## 25 Breath&amp;Cough&amp;Diarrhea&amp;Fatigue                   7</span>
<span class="c1">## 26 Breath&amp;Cough&amp;Diarrhea&amp;Fatigue&amp;Fever             8</span>
<span class="c1">## 27 Diarrhea&amp;Fatigue&amp;Fever                         12</span>
<span class="c1">## 28 Cough&amp;Diarrhea&amp;Fatigue&amp;Fever                   17</span>
<span class="c1">## 29 Anosmia&amp;Diarrhea&amp;Fatigue&amp;Fever                 17</span>
<span class="c1">## 30 Anosmia&amp;Diarrhea&amp;Cough&amp;Fatigue                 41</span>
<span class="c1">## 31 Anosmia&amp;Breath&amp;Cough&amp;Diarrhea&amp;Fatigue&amp;Fever    23</span>
<span class="c1">## 32 Anosmia&amp;Cough&amp;Diarrhea&amp;Fatigue&amp;Fever           50</span>

</code></pre></td></tr></table>
</div>
</div>

<p>We have six basic symptoms (&ldquo;Breath&rdquo; means &ldquo;Shortness of Breath&rdquo;). They occur in various combinations. We need to get this data into a shape we can work with. We have two tasks. First٫ it will be convenient to convert this summary back into an observation-level table. The <code>tidyr</code> package has a <a href="https://tidyr.tidyverse.org/reference/uncount.html">handy function</a> called <code>uncount</code> that will do this for us. However٫ we can&rsquo;t do that directly. Think of the table as showing counts of where various combinations of symptoms are <code>TRUE</code>. Implicitly٫ where we don&rsquo;t see a symptom٫ it&rsquo;s implicitly <code>FALSE</code> in those cases where it isn&rsquo;t there. For example٫ in the first row٫ the 140 patients reporting Anosmia are implicitly also reporting they don&rsquo;t have any of the other five symptoms. If we don&rsquo;t get those implicit negatives back٫ we won&rsquo;t get a proper picture of the clustering.</p>
<p>So٫ we&rsquo;re going to generate table of <code>TRUE</code> and <code>FALSE</code> values for our symptom combinations. There&rsquo;s probably a substantially more elegant way to do this than shown here٫ but let&rsquo;s press on regardless.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">subsets</span> <span class="o">&lt;-</span> <span class="n">dat</span><span class="o">$</span><span class="n">combination</span>

<span class="c1">## Check if each subset mentions each symptom or not</span>
<span class="n">symptom_mat</span> <span class="o">&lt;-</span> <span class="nf">map_dfc</span><span class="p">(</span><span class="n">subsets</span><span class="p">٫</span> <span class="n">str_detect</span><span class="p">٫</span> <span class="n">symptoms</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="nf">data.frame</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">t</span><span class="p">()</span> <span class="o">%&gt;%</span> <span class="c1"># transpose the result٫ ugh</span>
    <span class="nf">as_tibble</span><span class="p">()</span>

<span class="nf">colnames</span><span class="p">(</span><span class="n">symptom_mat</span><span class="p">)</span>  <span class="o">&lt;-</span> <span class="n">symptoms</span>

<span class="n">symptom_mat</span><span class="o">$</span><span class="n">count</span> <span class="o">&lt;-</span> <span class="n">dat</span><span class="o">$</span><span class="n">count</span>

<span class="n">symptom_mat</span> <span class="o">%&gt;%</span> <span class="nf">print</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">symptom_mat</span><span class="p">))</span>

<span class="c1">## # A tibble: 32 x 7</span>
<span class="c1">##    Anosmia Cough Fatigue Diarrhea Breath Fever count</span>
<span class="c1">##    &lt;lgl&gt;   &lt;lgl&gt; &lt;lgl&gt;   &lt;lgl&gt;    &lt;lgl&gt;  &lt;lgl&gt; &lt;dbl&gt;</span>
<span class="c1">##  1 TRUE    FALSE FALSE   FALSE    FALSE  FALSE   140</span>
<span class="c1">##  2 FALSE   TRUE  FALSE   FALSE    FALSE  FALSE    57</span>
<span class="c1">##  3 FALSE   FALSE TRUE    FALSE    FALSE  FALSE   198</span>
<span class="c1">##  4 FALSE   FALSE FALSE   TRUE     FALSE  FALSE    12</span>
<span class="c1">##  5 FALSE   FALSE FALSE   FALSE    TRUE   FALSE     5</span>
<span class="c1">##  6 FALSE   FALSE FALSE   FALSE    FALSE  TRUE     11</span>
<span class="c1">##  7 FALSE   TRUE  TRUE    FALSE    FALSE  FALSE   179</span>
<span class="c1">##  8 FALSE   FALSE TRUE    FALSE    FALSE  TRUE     28</span>
<span class="c1">##  9 FALSE   FALSE TRUE    FALSE    TRUE   FALSE    10</span>
<span class="c1">## 10 FALSE   FALSE TRUE    TRUE     FALSE  FALSE    43</span>
<span class="c1">## 11 TRUE    FALSE TRUE    FALSE    FALSE  FALSE   281</span>
<span class="c1">## 12 FALSE   TRUE  FALSE   FALSE    TRUE   FALSE     1</span>
<span class="c1">## 13 TRUE    FALSE TRUE    TRUE     FALSE  FALSE    64</span>
<span class="c1">## 14 FALSE   TRUE  TRUE    FALSE    TRUE   FALSE    22</span>
<span class="c1">## 15 TRUE    TRUE  TRUE    FALSE    FALSE  FALSE   259</span>
<span class="c1">## 16 TRUE    FALSE TRUE    FALSE    FALSE  TRUE     46</span>
<span class="c1">## 17 FALSE   TRUE  TRUE    FALSE    FALSE  TRUE     54</span>
<span class="c1">## 18 FALSE   TRUE  FALSE   TRUE     FALSE  FALSE     7</span>
<span class="c1">## 19 FALSE   TRUE  TRUE    TRUE     FALSE  FALSE    31</span>
<span class="c1">## 20 TRUE    TRUE  TRUE    FALSE    TRUE   FALSE    26</span>
<span class="c1">## 21 TRUE    TRUE  TRUE    FALSE    FALSE  TRUE     69</span>
<span class="c1">## 22 TRUE    TRUE  TRUE    TRUE     TRUE   FALSE    18</span>
<span class="c1">## 23 TRUE    TRUE  TRUE    FALSE    TRUE   TRUE     17</span>
<span class="c1">## 24 FALSE   TRUE  TRUE    FALSE    TRUE   TRUE     11</span>
<span class="c1">## 25 FALSE   TRUE  TRUE    TRUE     TRUE   FALSE     7</span>
<span class="c1">## 26 FALSE   TRUE  TRUE    TRUE     TRUE   TRUE      8</span>
<span class="c1">## 27 FALSE   FALSE TRUE    TRUE     FALSE  TRUE     12</span>
<span class="c1">## 28 FALSE   TRUE  TRUE    TRUE     FALSE  TRUE     17</span>
<span class="c1">## 29 TRUE    FALSE TRUE    TRUE     FALSE  TRUE     17</span>
<span class="c1">## 30 TRUE    TRUE  TRUE    TRUE     FALSE  FALSE    41</span>
<span class="c1">## 31 TRUE    TRUE  TRUE    TRUE     TRUE   TRUE     23</span>
<span class="c1">## 32 TRUE    TRUE  TRUE    TRUE     FALSE  TRUE     50</span>

</code></pre></td></tr></table>
</div>
</div>

<p>OK٫ so with that table in place٫ we can use the <code>uncount()</code> function to turn our summary back into quasi-individual-level data:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">indvs</span> <span class="o">&lt;-</span> <span class="n">symptom_mat</span> <span class="o">%&gt;%</span>
    <span class="nf">uncount</span><span class="p">(</span><span class="n">count</span><span class="p">)</span> 

<span class="n">indvs</span>

<span class="c1">## # A tibble: 1٫764 x 6</span>
<span class="c1">##    Anosmia Cough Fatigue Diarrhea Breath Fever</span>
<span class="c1">##    &lt;lgl&gt;   &lt;lgl&gt; &lt;lgl&gt;   &lt;lgl&gt;    &lt;lgl&gt;  &lt;lgl&gt;</span>
<span class="c1">##  1 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  2 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  3 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  4 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  5 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  6 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  7 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  8 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">##  9 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">## 10 TRUE    FALSE FALSE   FALSE    FALSE  FALSE</span>
<span class="c1">## # … with 1٫754 more rows</span>
</code></pre></td></tr></table>
</div>
</div>

<p>If we hadn&rsquo;t done that tabulation٫ <code>uncount</code> would have given us the wrong answers. Ask me how I know!</p>
<p>Now that we&rsquo;ve reconstituted the data٫ we can draw our graph.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="nf">library</span><span class="p">(</span><span class="n">ComplexUpset</span><span class="p">)</span>

<span class="nf">upset</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">indvs</span><span class="p">٫</span> <span class="n">intersect</span> <span class="o">=</span> <span class="n">symptoms</span><span class="p">٫</span> 
      <span class="n">name</span><span class="o">=</span><span class="s">&#34;Symptom Groupings by Frequency. Total pool is 1٫764 individuals.&#34;</span><span class="p">٫</span> 
      <span class="n">min_size</span> <span class="o">=</span> <span class="m">0</span><span class="p">٫</span>
      <span class="n">width_ratio</span> <span class="o">=</span> <span class="m">0.125</span><span class="p">)</span> <span class="o">+</span>
    <span class="nf">labs</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Co-Occurence of COVID-19 Symptoms&#34;</span><span class="p">٫</span>
         <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Data: covid.joinzoe.com/us | Graph: @kjhealy&#34;</span><span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div>

<figure>
    <img src="https://kieranhealy.org/files/misc/covid-upset-plot-1.png"
         alt="COVID Symptoms Upset Plot"/> <figcaption>
            <p>An UpSet plot showing the co-occurrence of reported COVID-19 symptoms. Click or touch to zoom.</p>
        </figcaption>
</figure>
<p>The plot has three pieces. The bar chart shows the number of people in the data who reported some particular combination of symptoms. Each bar is a different combination. Underneath it is a graphical table showing what those combinations are. Each row is one of our six symptoms: Fatigue٫ Anosmia٫ Cough٫ Fever٫ Diarrhea٫ and (shortness of) Breath. The black dots and lines show the combination of symptoms that make up each cluster or subset of symptoms. Reading from left to right٫ we can see that the most common subset of symptoms is the combination of Fatigue and Anosmia٫ and nothing else. A total of 281 respondents reported this combination. Next is Fatigue٫ Anosmia٫ and Cough٫ with 259 reports٫ followed by Fatigue alone with 198. And so on across the table. You can see٫ for example٫ that there are 23 reports of all six symptoms٫ and only one report of <em>just</em> the combination of Cough and shortness of Breath.</p>
<p>The third component of the plot is the smaller bar chart to the left of the graphical table. This shows the unconditional frequency count of each symptom across all subsets. You can see that almost everyone reported suffering from Fatigue٫ for instance٫ and that Shortness of Breath was the least commonly-reported symptom in absolute terms.</p>
<p>I think upset plots are very useful٫ on the whole. They clearly outperform Venn diagrams when there&rsquo;s more than a few overlapping sets٫ and they avoid some of the problems associated with heatmaps٫ too. Nicholas Tierney puts them to very good use in <a href="https://github.com/njtierney/naniar">naniar</a>٫ his package for visualizing missing data. The technique doesn&rsquo;t make the problems with visualizing cross-classified counts magically disappear٫ of course. If you have a large number of intersecting groups it will become unwieldy as well. But then of course you&rsquo;d start to look for ways to focus on the intersections that matter most٫ or on alternative ways of ordering the combinations٫ and so on. (The upset packages have some of these methods built in.) In the meantime٫ it&rsquo;s often your best option for this kind of task.</p>
<p>The code and data used in this post are <a href="https://github.com/kjhealy/covid_symptoms">available on GitHub</a>.</p>
'),('https://kieranhealy.org/blog/archives/2020/04/10/covdata-package/', 'Covdata Package', '1586550478000',  15, '<figure>
    <img src="https://kieranhealy.org/files/misc/hex-covdata.png"
         alt="The covdata logo"/> <figcaption>
            <p>The covdata logo</p>
        </figcaption>
</figure>
<p>Partly because it grew out of a few code-throughs I was doing٫ but mostly as a classroom exercise٫ I pulled together a small data package for R called <a href="https://kjhealy.github.io/covdata/index.html">covdata</a>٫ available at <a href="https://kjhealy.github.io/covdata/">https://kjhealy.github.io/covdata/</a>. It contains COVID-19 data from three sources:</p>
<ul>
<li>National level data from the <a href="https://www.ecdc.europa.eu/en">European Centers for Disease Control</a>.</li>
<li>State-level data for the United States from the <a href="https://covidtracking.com">COVID Tracking Project</a>.</li>
<li>State-level and county-level data for the United States from the <a href="https://github.com/nytimes/covid-19-data"><em>New York Times</em></a>.</li>
</ul>
<p>I&rsquo;ll keep it up to date for at least the near future. If I get a chance I&rsquo;ll write up a little walkthrough about the process of making a package like this. I find that making data packages for R is both intrinsically useful for data that will be used more than once٫ and also generally a very accessible and handy way to introduce students to the mechanics of R packaging. It&rsquo;s much more common for regular users of R to have some data that would benefit from packaging than for them to have some set of functions that might usefully be packaged up for other people.</p>
<p>Here are what the three tables look like٫ plus a figure at the end.</p>
<h3 id="country-level-data-from-the-ecdc">Country-Level Data from the ECDC</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">covdata</span><span class="p">)</span>

<span class="n">covnat</span>
<span class="c1">#&gt; # A tibble: 9٫858 x 8</span>
<span class="c1">#&gt; # Groups:   iso3 [205]</span>
<span class="c1">#&gt;    date       cname       iso3  cases deaths  pop_2018 cu_cases cu_deaths</span>
<span class="c1">#&gt;    &lt;date&gt;     &lt;chr&gt;       &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;</span>
<span class="c1">#&gt;  1 2019-12-31 Afghanistan AFG       0      0  37172386        0         0</span>
<span class="c1">#&gt;  2 2019-12-31 Algeria     DZA       0      0  42228429        0         0</span>
<span class="c1">#&gt;  3 2019-12-31 Armenia     ARM       0      0   2951776        0         0</span>
<span class="c1">#&gt;  4 2019-12-31 Australia   AUS       0      0  24992369        0         0</span>
<span class="c1">#&gt;  5 2019-12-31 Austria     AUT       0      0   8847037        0         0</span>
<span class="c1">#&gt;  6 2019-12-31 Azerbaijan  AZE       0      0   9942334        0         0</span>
<span class="c1">#&gt;  7 2019-12-31 Bahrain     BHR       0      0   1569439        0         0</span>
<span class="c1">#&gt;  8 2019-12-31 Belarus     BLR       0      0   9485386        0         0</span>
<span class="c1">#&gt;  9 2019-12-31 Belgium     BEL       0      0  11422068        0         0</span>
<span class="c1">#&gt; 10 2019-12-31 Brazil      BRA       0      0 209469333        0         0</span>
<span class="c1">#&gt; # … with 9٫848 more rows</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="us-state-level-data-from-the-covid-tracking-project">US State-Level Data from the COVID Tracking Project</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">covus</span>
<span class="c1">#&gt; # A tibble: 27٫216 x 11</span>
<span class="c1">#&gt;    date       state fips  measure count pos_neg death_increase hospitalized_in… negative_increa… positive_increa…</span>
<span class="c1">#&gt;    &lt;date&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;</span>
<span class="c1">#&gt;  1 2020-04-09 AK    02    positi…   235    7223              0                0              146                9</span>
<span class="c1">#&gt;  2 2020-04-09 AK    02    negati…  6988    7223              0                0              146                9</span>
<span class="c1">#&gt;  3 2020-04-09 AK    02    pending    NA    7223              0                0              146                9</span>
<span class="c1">#&gt;  4 2020-04-09 AK    02    hospit…    NA    7223              0                0              146                9</span>
<span class="c1">#&gt;  5 2020-04-09 AK    02    hospit…    27    7223              0                0              146                9</span>
<span class="c1">#&gt;  6 2020-04-09 AK    02    in_icu…    NA    7223              0                0              146                9</span>
<span class="c1">#&gt;  7 2020-04-09 AK    02    in_icu…    NA    7223              0                0              146                9</span>
<span class="c1">#&gt;  8 2020-04-09 AK    02    on_ven…    NA    7223              0                0              146                9</span>
<span class="c1">#&gt;  9 2020-04-09 AK    02    on_ven…    NA    7223              0                0              146                9</span>
<span class="c1">#&gt; 10 2020-04-09 AK    02    recove…    49    7223              0                0              146                9</span>
<span class="c1">#&gt; # … with 27٫206 more rows٫ and 1 more variable: total_test_results_increase &lt;dbl&gt;</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="state-level-and-county-level-cumulative-data-from-the-_new-york-times_">State-Level and County-Level (Cumulative) Data from the <em>New York Times</em></h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">nytcovstate</span>
<span class="c1">#&gt; # A tibble: 2٫105 x 5</span>
<span class="c1">#&gt;    date       state      fips  cases deaths</span>
<span class="c1">#&gt;    &lt;date&gt;     &lt;chr&gt;      &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;</span>
<span class="c1">#&gt;  1 2020-01-21 Washington 53        1      0</span>
<span class="c1">#&gt;  2 2020-01-22 Washington 53        1      0</span>
<span class="c1">#&gt;  3 2020-01-23 Washington 53        1      0</span>
<span class="c1">#&gt;  4 2020-01-24 Illinois   17        1      0</span>
<span class="c1">#&gt;  5 2020-01-24 Washington 53        1      0</span>
<span class="c1">#&gt;  6 2020-01-25 California 06        1      0</span>
<span class="c1">#&gt;  7 2020-01-25 Illinois   17        1      0</span>
<span class="c1">#&gt;  8 2020-01-25 Washington 53        1      0</span>
<span class="c1">#&gt;  9 2020-01-26 Arizona    04        1      0</span>
<span class="c1">#&gt; 10 2020-01-26 California 06        2      0</span>
<span class="c1">#&gt; # … with 2٫095 more rows</span>
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">nytcovcounty</span>
<span class="c1">#&gt; # A tibble: 45٫880 x 6</span>
<span class="c1">#&gt;    date       county      state      fips  cases deaths</span>
<span class="c1">#&gt;    &lt;date&gt;     &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;</span>
<span class="c1">#&gt;  1 2020-01-21 Snohomish   Washington 53061     1      0</span>
<span class="c1">#&gt;  2 2020-01-22 Snohomish   Washington 53061     1      0</span>
<span class="c1">#&gt;  3 2020-01-23 Snohomish   Washington 53061     1      0</span>
<span class="c1">#&gt;  4 2020-01-24 Cook        Illinois   17031     1      0</span>
<span class="c1">#&gt;  5 2020-01-24 Snohomish   Washington 53061     1      0</span>
<span class="c1">#&gt;  6 2020-01-25 Orange      California 06059     1      0</span>
<span class="c1">#&gt;  7 2020-01-25 Cook        Illinois   17031     1      0</span>
<span class="c1">#&gt;  8 2020-01-25 Snohomish   Washington 53061     1      0</span>
<span class="c1">#&gt;  9 2020-01-26 Maricopa    Arizona    04013     1      0</span>
<span class="c1">#&gt; 10 2020-01-26 Los Angeles California 06037     1      0</span>
<span class="c1">#&gt; # … with 45٫870 more rows</span>
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r"><span class="n">nytcovcounty</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">uniq_name</span> <span class="o">=</span> <span class="nf">paste</span><span class="p">(</span><span class="n">county</span><span class="p">٫</span> <span class="n">state</span><span class="p">))</span> <span class="o">%&gt;%</span> <span class="c1"># Can&#39;t use FIPS because of how the NYT bundled cities</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">uniq_name</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">days_elapsed</span> <span class="o">=</span> <span class="n">date</span> <span class="o">-</span> <span class="nf">min</span><span class="p">(</span><span class="n">date</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">ggplot</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">days_elapsed</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="n">cases</span><span class="p">٫</span> <span class="n">group</span> <span class="o">=</span> <span class="n">uniq_name</span><span class="p">))</span> <span class="o">+</span> 
  <span class="nf">geom_line</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="m">0.25</span><span class="p">٫</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;gray20&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">scale_y_log10</span><span class="p">(</span><span class="n">labels</span> <span class="o">=</span> <span class="n">scales</span><span class="o">::</span><span class="nf">label_number_si</span><span class="p">())</span> <span class="o">+</span> 
  <span class="nf">guides</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">facet_wrap</span><span class="p">(</span><span class="o">~</span> <span class="n">state</span><span class="p">٫</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">5</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">labs</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s">&#34;COVID-19 Cumulative Recorded Cases by US County&#34;</span><span class="p">٫</span>
       <span class="n">subtitle</span> <span class="o">=</span> <span class="nf">paste</span><span class="p">(</span><span class="s">&#34;New York is bundled into a single area in this data.\nData as of&#34;</span><span class="p">٫</span> <span class="nf">format</span><span class="p">(</span><span class="nf">max</span><span class="p">(</span><span class="n">nytcovcounty</span><span class="o">$</span><span class="n">date</span><span class="p">)٫</span> <span class="s">&#34;%A٫ %B %e٫ %Y&#34;</span><span class="p">))٫</span>
       <span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Days since first case&#34;</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Count of Cases (log 10 scale)&#34;</span><span class="p">٫</span> 
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Data: The New York Times | Graph: @kjhealy&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">theme_minimal</span><span class="p">()</span>
<span class="c1">#&gt; Don&#39;t know how to automatically pick scale for object of type difftime. Defaulting to continuous.</span>
<span class="c1">#&gt; Warning: Transformation introduced infinite values in continuous y-axis</span>
</code></pre></td></tr></table>
</div>
</div><figure>
    <img src="https://kieranhealy.org/files/misc/nyt-covid-county-sm.png"
         alt="County-level plot faceted by state٫ from the New York Times data."/> <figcaption>
            <p>County-level plot faceted by state٫ from the New York Times data.</p>
        </figcaption>
</figure>
'),('https://kieranhealy.org/blog/archives/2020/03/28/this-is-just-to-try-to-say/', 'This Is Just to Try to Say', '1585407255000',  15, '<p>This is Just to Say</p>
<p>I have … nnn ;<br>
the … u…s<br>
that —— in<br>
e—bo٫ ٫ ; ~ ~</p>
<p>and w—&lt;…<br>
you /– /– /–<br>
saving<br>
; :       :      ~ ~ ~</p>
<p>Forgive me<br>
th[ — @ r—]<br>
so … ~<br>
… so cold</p>
'),('https://kieranhealy.org/blog/archives/2020/03/27/a-covid-small-multiple/', 'A COVID Small Multiple', '1585321358000',  15, '<p>John Burn-Murdoch has been doing <a href="https://www.ft.com/coronavirus-latest">very good work at the Financial Times</a> producing various visualizations of the progress of COVID-19. One of his recent images is a small-multiple plot of cases by country٫ showing the trajectory of the outbreak for a large number of countries٫ with a the background of each small-multiple panel also showing (in grey) the trajectory of every other country for comparison. It&rsquo;s a useful technique. In this example٫ I&rsquo;ll draw a version of it in R and ggplot. The main difference is that instead of ordering the panels alphabetically by country٫ I&rsquo;ll order them from highest to lowest current reported cases.</p>
<p>Here&rsquo;s the figure we&rsquo;ll end up with:</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/cov_case_sm.png"
         alt="covid small multiple"/> <figcaption>
            <p>Cumulative reported COVID-19 cases to date٫ top 50 Countries</p>
        </figcaption>
</figure>
<p>There are two small tricks. First٫ getting <em>all</em> the data to show (in grey) in each panel while highlighting just <em>one</em> country. Second٫ for reasons of space٫ moving the panel labels (in ggplot&rsquo;s terminology٫ the strip labels) inside the panels٫ in order to tighten up the space a bit. Doing this is really the same trick both times٫ viz٫ creating a some mini-datasets to use for particular layers of the plot.</p>
<p>The code for this (including code to pull the data) is in <a href="https://github.com/kjhealy/covid">my COVID GitHub repository</a>. See the <a href="https://github.com/kjhealy/covid">repo</a> for details on downloading and cleaning it. Just this morning the ECDC changed how it&rsquo;s supplying its data٫ moving from an Excel file to your choice of JSON٫ CSV٫ or XML٫ so <a href="https://kieranhealy.org/blog/archives/2020/03/21/covid-19-tracking/">this earlier post walking through the process for the Excel file</a> is already out of date for the downloading step. There&rsquo;s a new function in the repo٫ though.</p>
<p>We&rsquo;ll start with the data mostly cleaned and organized.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="o">&gt;</span> <span class="n">covid</span>
<span class="c1"># A tibble: 7٫320 x 14</span>
   <span class="n">date_rep</span>     <span class="n">day</span> <span class="n">month</span>  <span class="n">year</span> <span class="n">cases</span> <span class="n">deaths</span> <span class="n">countries_and_territories</span> <span class="n">geo_id</span> <span class="n">countryterritory_code</span> <span class="n">pop_data2018</span> <span class="n">date</span>       <span class="n">iso2</span>  <span class="n">iso3</span>  <span class="n">cname</span>      
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>      <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>                     <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>                        <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">date</span><span class="o">&gt;</span>     <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>      
 <span class="m">1</span> <span class="m">28</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">28</span>     <span class="m">3</span>  <span class="m">2020</span>    <span class="m">16</span>      <span class="m">1</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-28</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">2</span> <span class="m">27</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">27</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-27</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">3</span> <span class="m">26</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">26</span>     <span class="m">3</span>  <span class="m">2020</span>    <span class="m">33</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-26</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">4</span> <span class="m">25</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">25</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">2</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-25</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">5</span> <span class="m">24</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">24</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">6</span>      <span class="m">1</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-24</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">6</span> <span class="m">23</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">23</span>     <span class="m">3</span>  <span class="m">2020</span>    <span class="m">10</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-23</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">7</span> <span class="m">22</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">22</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-22</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">8</span> <span class="m">21</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">21</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">2</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-21</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
 <span class="m">9</span> <span class="m">20</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">20</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-20</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
<span class="m">10</span> <span class="m">19</span><span class="o">/</span><span class="m">03</span><span class="o">/</span><span class="m">2020</span>    <span class="m">19</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>               <span class="n">AF</span>     <span class="n">AFG</span>                       <span class="m">37172386</span> <span class="m">2020-03-19</span> <span class="n">AF</span>    <span class="n">AFG</span>   <span class="n">Afghanistan</span>
<span class="c1"># … with 7٫310 more rows</span>
</code></pre></td></tr></table>
</div>
</div>

<p>This is the data as we get it from the ECDC٫ with some cleaning of the country codes and the date format. We&rsquo;ll calculate some cumulative totals and do some final recoding of the country labels.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">cov_case_curve</span> <span class="o">&lt;-</span> <span class="n">covid</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">date</span><span class="p">٫</span> <span class="n">cname</span><span class="p">٫</span> <span class="n">iso3</span><span class="p">٫</span> <span class="n">cases</span><span class="p">٫</span> <span class="n">deaths</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">drop_na</span><span class="p">(</span><span class="n">iso3</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">iso3</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">arrange</span><span class="p">(</span><span class="n">date</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">cu_cases</span> <span class="o">=</span> <span class="nf">cumsum</span><span class="p">(</span><span class="n">cases</span><span class="p">)٫</span> 
         <span class="n">cu_deaths</span> <span class="o">=</span> <span class="nf">cumsum</span><span class="p">(</span><span class="n">deaths</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">cu_cases</span> <span class="o">&gt;</span> <span class="m">99</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">days_elapsed</span> <span class="o">=</span> <span class="n">date</span> <span class="o">-</span> <span class="nf">min</span><span class="p">(</span><span class="n">date</span><span class="p">)٫</span>
          <span class="n">end_label</span> <span class="o">=</span> <span class="nf">ifelse</span><span class="p">(</span><span class="n">date</span> <span class="o">==</span> <span class="nf">max</span><span class="p">(</span><span class="n">date</span><span class="p">)٫</span> <span class="n">cname</span><span class="p">٫</span> <span class="kc">NA</span><span class="p">)٫</span>
          <span class="n">end_label</span> <span class="o">=</span> <span class="nf">recode</span><span class="p">(</span><span class="n">end_label</span><span class="p">٫</span> <span class="n">`United States`</span> <span class="o">=</span> <span class="s">&#34;USA&#34;</span><span class="p">٫</span>
                        <span class="n">`Iran٫ Islamic Republic of`</span> <span class="o">=</span> <span class="s">&#34;Iran&#34;</span><span class="p">٫</span> 
                        <span class="n">`Korea٫ Republic of`</span> <span class="o">=</span> <span class="s">&#34;South Korea&#34;</span><span class="p">٫</span> 
                        <span class="n">`United Kingdom`</span> <span class="o">=</span> <span class="s">&#34;UK&#34;</span><span class="p">)٫</span>
         <span class="n">cname</span> <span class="o">=</span> <span class="nf">recode</span><span class="p">(</span><span class="n">cname</span><span class="p">٫</span> <span class="n">`United States`</span> <span class="o">=</span> <span class="s">&#34;USA&#34;</span><span class="p">٫</span>
                        <span class="n">`Iran٫ Islamic Republic of`</span> <span class="o">=</span> <span class="s">&#34;Iran&#34;</span><span class="p">٫</span> 
                        <span class="n">`Korea٫ Republic of`</span> <span class="o">=</span> <span class="s">&#34;South Korea&#34;</span><span class="p">٫</span> 
                        <span class="n">`United Kingdom`</span> <span class="o">=</span> <span class="s">&#34;UK&#34;</span><span class="p">))</span>
                        
<span class="o">&gt;</span> <span class="n">cov_case_curve</span>
<span class="c1"># A tibble: 1٫262 x 9</span>
<span class="c1"># Groups:   iso3 [97]</span>
   <span class="n">date</span>       <span class="n">cname</span> <span class="n">iso3</span>  <span class="n">cases</span> <span class="n">deaths</span> <span class="n">cu_cases</span> <span class="n">cu_deaths</span> <span class="n">days_elapsed</span> <span class="n">end_label</span>
   <span class="o">&lt;</span><span class="n">date</span><span class="o">&gt;</span>     <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>    <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>     <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">drtn</span><span class="o">&gt;</span>       <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>    
 <span class="m">1</span> <span class="m">2020-01-19</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">136</span>      <span class="m">1</span>      <span class="m">216</span>         <span class="m">3</span> <span class="m">0</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">2</span> <span class="m">2020-01-20</span> <span class="n">China</span> <span class="n">CHN</span>      <span class="m">19</span>      <span class="m">0</span>      <span class="m">235</span>         <span class="m">3</span> <span class="m">1</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">3</span> <span class="m">2020-01-21</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">151</span>      <span class="m">3</span>      <span class="m">386</span>         <span class="m">6</span> <span class="m">2</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">4</span> <span class="m">2020-01-22</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">140</span>     <span class="m">11</span>      <span class="m">526</span>        <span class="m">17</span> <span class="m">3</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">5</span> <span class="m">2020-01-23</span> <span class="n">China</span> <span class="n">CHN</span>      <span class="m">97</span>      <span class="m">0</span>      <span class="m">623</span>        <span class="m">17</span> <span class="m">4</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">6</span> <span class="m">2020-01-24</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">259</span>      <span class="m">9</span>      <span class="m">882</span>        <span class="m">26</span> <span class="m">5</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">7</span> <span class="m">2020-01-25</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">441</span>     <span class="m">15</span>     <span class="m">1323</span>        <span class="m">41</span> <span class="m">6</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">8</span> <span class="m">2020-01-26</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">665</span>     <span class="m">15</span>     <span class="m">1988</span>        <span class="m">56</span> <span class="m">7</span> <span class="n">days</span>       <span class="kc">NA</span>       
 <span class="m">9</span> <span class="m">2020-01-27</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">787</span>     <span class="m">25</span>     <span class="m">2775</span>        <span class="m">81</span> <span class="m">8</span> <span class="n">days</span>       <span class="kc">NA</span>       
<span class="m">10</span> <span class="m">2020-01-28</span> <span class="n">China</span> <span class="n">CHN</span>    <span class="m">1753</span>     <span class="m">25</span>     <span class="m">4528</span>       <span class="m">106</span> <span class="m">9</span> <span class="n">days</span>       <span class="kc">NA</span>       
<span class="c1"># … with 1٫252 more rows                        </span>

</code></pre></td></tr></table>
</div>
</div>

<p>Then we pick out the top 50 countries٫ isolating their maximum case value.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="c1">## Top 50 countries by &gt;&gt; 100 cases٫ let&#39;s say. </span>
<span class="n">top_50</span> <span class="o">&lt;-</span> <span class="n">cov_case_curve</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">cname</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">cu_cases</span> <span class="o">==</span> <span class="nf">max</span><span class="p">(</span><span class="n">cu_cases</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">ungroup</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">top_n</span><span class="p">(</span><span class="m">50</span><span class="p">٫</span> <span class="n">cu_cases</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">iso3</span><span class="p">٫</span> <span class="n">cname</span><span class="p">٫</span> <span class="n">cu_cases</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">days_elapsed</span> <span class="o">=</span> <span class="m">1</span><span class="p">٫</span> 
             <span class="n">cu_cases</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">cov_case_curve</span><span class="o">$</span><span class="n">cu_cases</span><span class="p">)</span> <span class="o">-</span> <span class="m">1e4</span><span class="p">)</span> 


<span class="o">&gt;</span> <span class="n">top_50</span>

<span class="c1"># A tibble: 50 x 4</span>
   <span class="n">iso3</span>  <span class="n">cname</span>     <span class="n">cu_cases</span> <span class="n">days_elapsed</span>
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>        <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>        <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>
 <span class="m">1</span> <span class="n">PAK</span>   <span class="n">Pakistan</span>     <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">2</span> <span class="n">THA</span>   <span class="n">Thailand</span>     <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">3</span> <span class="n">ARG</span>   <span class="n">Argentina</span>    <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">4</span> <span class="n">AUS</span>   <span class="n">Australia</span>    <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">5</span> <span class="n">AUT</span>   <span class="n">Austria</span>      <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">6</span> <span class="n">BEL</span>   <span class="n">Belgium</span>      <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">7</span> <span class="n">BRA</span>   <span class="n">Brazil</span>       <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">8</span> <span class="n">CAN</span>   <span class="n">Canada</span>       <span class="m">94686</span>            <span class="m">1</span>
 <span class="m">9</span> <span class="n">CHL</span>   <span class="n">Chile</span>        <span class="m">94686</span>            <span class="m">1</span>
<span class="m">10</span> <span class="n">CHN</span>   <span class="n">China</span>        <span class="m">94686</span>            <span class="m">1</span>
<span class="c1"># … with 40 more rows</span>
</code></pre></td></tr></table>
</div>
</div>

<p>This gives us our label layer. We&rsquo;ve set <code>days_elapsed</code> and <code>cu_cases</code> values to the same thing for every country٫ because these are the x and y locations where the country labels will go.</p>
<p>Next٫ a data layer for the grey line traces and a data layer for the little endpoints at the current case-count value.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">cov_case_curve_bg</span> <span class="o">&lt;-</span> <span class="n">cov_case_curve</span> <span class="o">%&gt;%</span> 
  <span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">cname</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">iso3</span> <span class="o">%in%</span> <span class="n">top_50</span><span class="o">$</span><span class="n">iso3</span><span class="p">)</span> 

<span class="n">cov_case_curve_endpoints</span> <span class="o">&lt;-</span> <span class="n">cov_case_curve</span> <span class="o">%&gt;%</span> 
  <span class="nf">filter</span><span class="p">(</span><span class="n">iso3</span> <span class="o">%in%</span> <span class="n">top_50</span><span class="o">$</span><span class="n">iso3</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">iso3</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">cu_cases</span> <span class="o">==</span> <span class="nf">max</span><span class="p">(</span><span class="n">cu_cases</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">cname</span><span class="p">٫</span> <span class="n">iso3</span><span class="p">٫</span> <span class="n">days_elapsed</span><span class="p">٫</span> <span class="n">cu_cases</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">ungroup</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div>

<p>We drop <code>cname</code> in the <code>cov_case_curve_bg</code> layer٫ because we&rsquo;re going to facet by that value with the main dataset in a moment. That&rsquo;s the trick that allows the traces for all the countries to appear in each panel.</p>
<p>And now we can draw the plot.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="hl"><span class="lnt"> 5
</span></span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="hl"><span class="lnt"> 9
</span></span><span class="lnt">10
</span><span class="lnt">11
</span><span class="hl"><span class="lnt">12
</span></span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="hl"><span class="lnt">19
</span></span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="hl"><span class="lnt">27
</span></span><span class="lnt">28
</span><span class="hl"><span class="lnt">29
</span></span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="hl"><span class="lnt">39
</span></span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">cov_case_sm</span> <span class="o">&lt;-</span> <span class="n">cov_case_curve</span>  <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">iso3</span> <span class="o">%in%</span> <span class="n">top_50</span><span class="o">$</span><span class="n">iso3</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">ggplot</span><span class="p">(</span><span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">days_elapsed</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="n">cu_cases</span><span class="p">))</span> <span class="o">+</span> 
<span class="hl">  <span class="c1"># The line traces for every country٫ in every panel</span>
</span>  <span class="nf">geom_line</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">cov_case_curve_bg</span><span class="p">٫</span> 
            <span class="nf">aes</span><span class="p">(</span><span class="n">group</span> <span class="o">=</span> <span class="n">iso3</span><span class="p">)٫</span>
            <span class="n">size</span> <span class="o">=</span> <span class="m">0.15</span><span class="p">٫</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;gray80&#34;</span><span class="p">)</span> <span class="o">+</span> 
<span class="hl">  <span class="c1"># The line trace in red٫ for the country in any given panel</span>
</span>  <span class="nf">geom_line</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="s">&#34;firebrick&#34;</span><span class="p">٫</span>
            <span class="n">lineend</span> <span class="o">=</span> <span class="s">&#34;round&#34;</span><span class="p">)</span> <span class="o">+</span> 
<span class="hl">  <span class="c1"># The point at the end. Bonus trick: some points can have fills!</span>
</span>  <span class="nf">geom_point</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">cov_case_curve_endpoints</span><span class="p">٫</span> 
             <span class="n">size</span> <span class="o">=</span> <span class="m">1.1</span><span class="p">٫</span> 
             <span class="n">shape</span> <span class="o">=</span> <span class="m">21</span><span class="p">٫</span> 
             <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;firebrick&#34;</span><span class="p">٫</span>
             <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;firebrick2&#34;</span>
             <span class="p">)</span> <span class="o">+</span> 
<span class="hl">  <span class="c1"># The country label inside the panel٫ in lieu of the strip label</span>
</span>  <span class="nf">geom_text</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">top_50</span><span class="p">٫</span> 
             <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">label</span> <span class="o">=</span> <span class="n">cname</span><span class="p">)٫</span> 
             <span class="n">vjust</span> <span class="o">=</span> <span class="s">&#34;inward&#34;</span><span class="p">٫</span> 
             <span class="n">hjust</span> <span class="o">=</span> <span class="s">&#34;inward&#34;</span><span class="p">٫</span>
             <span class="n">fontface</span> <span class="o">=</span> <span class="s">&#34;bold&#34;</span><span class="p">٫</span> 
             <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;firebrick&#34;</span><span class="p">٫</span> 
             <span class="n">size</span> <span class="o">=</span> <span class="m">2.1</span><span class="p">)</span> <span class="o">+</span> 
<span class="hl">  <span class="c1"># Log transform and friendly labels</span>
</span>  <span class="nf">scale_y_log10</span><span class="p">(</span><span class="n">labels</span> <span class="o">=</span> <span class="n">scales</span><span class="o">::</span><span class="nf">label_number_si</span><span class="p">())</span> <span class="o">+</span> 
<span class="hl">  <span class="c1"># Facet by country٫ order from high to low</span>
</span>  <span class="nf">facet_wrap</span><span class="p">(</span><span class="o">~</span> <span class="nf">reorder</span><span class="p">(</span><span class="n">cname</span><span class="p">٫</span> <span class="o">-</span><span class="n">cu_cases</span><span class="p">)٫</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">5</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Days Since 100th Confirmed Case&#34;</span><span class="p">٫</span> 
       <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Cumulative Number of Cases (log10 scale)&#34;</span><span class="p">٫</span> 
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Cumulative Number of Reported Cases of COVID-19: Top 50 Countries&#34;</span><span class="p">٫</span> 
       <span class="n">subtitle</span> <span class="o">=</span> <span class="nf">paste</span><span class="p">(</span><span class="s">&#34;Data as of&#34;</span><span class="p">٫</span> <span class="nf">format</span><span class="p">(</span><span class="nf">max</span><span class="p">(</span><span class="n">cov_curve</span><span class="o">$</span><span class="n">date</span><span class="p">)٫</span> <span class="s">&#34;%A٫ %B %e٫ %Y&#34;</span><span class="p">))٫</span> 
        <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Kieran Healy @kjhealy / Data: https://www.ecdc.europa.eu/&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">theme</span><span class="p">(</span><span class="n">plot.title</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1</span><span class="p">)٫</span> <span class="n">face</span> <span class="o">=</span> <span class="s">&#34;bold&#34;</span><span class="p">)٫</span>
          <span class="n">plot.subtitle</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">0.7</span><span class="p">))٫</span>
          <span class="n">plot.caption</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1</span><span class="p">))٫</span>
<span class="hl">          <span class="c1"># turn off the strip label and tighten the panel spacing</span>
</span>          <span class="n">strip.text</span> <span class="o">=</span> <span class="nf">element_blank</span><span class="p">()٫</span>
          <span class="n">panel.spacing.x</span> <span class="o">=</span> <span class="nf">unit</span><span class="p">(</span><span class="m">-0.05</span><span class="p">٫</span> <span class="s">&#34;lines&#34;</span><span class="p">)٫</span>
          <span class="n">panel.spacing.y</span> <span class="o">=</span> <span class="nf">unit</span><span class="p">(</span><span class="m">0.3</span><span class="p">٫</span> <span class="s">&#34;lines&#34;</span><span class="p">)٫</span>
          <span class="n">axis.text.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">0.5</span><span class="p">))٫</span>
          <span class="n">axis.title.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1</span><span class="p">))٫</span>
          <span class="n">axis.title.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1</span><span class="p">))٫</span>
          <span class="n">axis.text.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">0.5</span><span class="p">))٫</span>
          <span class="n">legend.text</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1</span><span class="p">)))</span>

<span class="nf">ggsave</span><span class="p">(</span><span class="s">&#34;figures/cov_case_sm.png&#34;</span><span class="p">٫</span> 
       <span class="n">cov_case_sm</span><span class="p">٫</span> <span class="n">width</span> <span class="o">=</span> <span class="m">10</span><span class="p">٫</span> <span class="n">height</span> <span class="o">=</span> <span class="m">12</span><span class="p">٫</span> <span class="n">dpi</span> <span class="o">=</span> <span class="m">300</span><span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div>'),('https://kieranhealy.org/blog/archives/2020/03/21/covid-19-tracking/', 'Covid 19 Tracking', '1584819904000',  15, '<h2 id="get-your-epidemiology-from-epidemiologists">Get Your Epidemiology from Epidemiologists</h2>
<p>The COVID-19 pandemic continues to rage. I&rsquo;m strongly committed to what should be the uncontroversial view that we should listen to the recommendations of those institutions and individuals with strong expertise in the relevant fields of Public Health٫ Epidemiology٫ Disease Control٫ and Infection Modeling. I also think that the open availability of data٫ and the free availability of methods to look at data٫ is generally a good thing. The tricky part is when these potentially conflict. For example٫ in a period of crisis it is reasonable to want to find out what&rsquo;s happening and to inform yourself as much as possible about how events are unfolding. People who work with data of some sort will naturally want to look at the available trends themselves. But maybe those same people don&rsquo;t know a great deal about how disease works٫ or how information about it is collected and processed٫ or what is likely to happen in a situation like the one we&rsquo;re experiencing. At such times٫ there&rsquo;s a balance to be struck between using the available tools to come to an informed opinion and recklessly mucking about with data when you don&rsquo;t really know what you&rsquo;re doing. This is especially important when٫ as is the case now٫ the Executive response to the crisis in the United States (and in several other countries) has been criminally irresponsible٫ to the point where even elementary facts about the spread of the disease over the past few months are being distorted.</p>
<p>Speaking for myself٫ I definitely want look at what the trends are and I prefer to do so by working directly with the data that official agencies and reliable reporting produces. So in this post I&rsquo;ll show how I&rsquo;m doing that. But I definitely <em>don&rsquo;t</em> want to publicly mess around beyond this. While I might idly fit some models or play with various extrapolations of the data in the privacy of my own home٫ I&rsquo;m very conscious that I am not in a position to do this in a professional capacity. So I will firmly set that aside here. There are already many well-qualified people working publicly to actually analyze and model the data٫ as opposed to looking descriptively at what is happening. For a very good overview of some of the challenges and standard approaches to modeling and forecasting epidemics٫ read <a href="https://robjhyndman.com/hyndsight/forecasting-covid19/">Rob Hyndman&rsquo;s excellent post</a>. His summary is particularly useful (and cautionary) for anyone coming to the data from e.g. an Econometric or Time Series point of view where it&rsquo;s natural to think in terms of forecasting with lagged variables.</p>
<p>Anyway٫ I just want to get an overview of best-available counts of deaths. I&rsquo;m going to show you how to get the data to draw this graph.</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/covid_cumulative_22-03-20.png"
         alt="Cumulative COVID-19 Deaths"/> <figcaption>
            <p>Cumulative COVID-19 Deaths</p>
        </figcaption>
</figure>
<h2 id="looking-at-covid-19-data-from-the-european-centers-for-disease-control">Looking at COVID-19 Data from the European Centers for Disease Control</h2>
<p>Each day٫ the <a href="https://www.ecdc.europa.eu">ECDC</a> publishes a <a href="https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide">a summary spreadsheet of global case and death counts</a> since the beginning of the epidemic. This is good data collated by an EU-wide agency٫ and it&rsquo;s what I&rsquo;ve been using to keep up with the trends. There are other reliable sources٫ too٫ most notably the <a href="https://coronavirus.jhu.edu/map.html">Johns Hopkins Coronavirus Dashboard</a>. Here&rsquo;s what I&rsquo;ve been doing to get it into R. Again my principal reason for sharing this code is <em>not</em> to add much of anything on the public side. It&rsquo;s much more of a pedagogical exercise. If you want to look at this data٫ here&rsquo;s one way to do that. Along the way I&rsquo;ll talk about a few of the things needed to work with the data in a reasonably clean way. Then I&rsquo;ll end up drawing the plot that everyone draws&mdash;showing cumulative trends by country in deaths٫ counted in days since a threshold level of fatalities.</p>
<h2 id="preparation">Preparation</h2>
<p>First we load some libraries to help us out.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">lubridate</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">here</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">janitor</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">socviz</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">ggrepel</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">paletteer</span><span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Next٫ we set things up by writing some functions that will help us grab and clean the data. In reality٫ of course٫ these functions got written piecemeal and were then cleaned up and moved to the front of the file. I didn&rsquo;t sit down and write them off the top of my head.</p>
<p>The first one is going to grab the spreadsheet from the ECDC and both save the <code>.xlsx</code> file to our <code>data/</code> folder and create a tibble of the results.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="c1">## Download today&#39;s excel file٫ saving it to data/ and reading it in</span>
<span class="n">get_ecdc_data</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">url</span> <span class="o">=</span> <span class="s">&#34;https://www.ecdc.europa.eu/sites/default/files/documents/&#34;</span><span class="p">٫</span>
                          <span class="n">fname</span> <span class="o">=</span> <span class="s">&#34;COVID-19-geographic-distribution-worldwide-&#34;</span><span class="p">٫</span> 
                          <span class="n">date</span> <span class="o">=</span> <span class="n">lubridate</span><span class="o">::</span><span class="nf">today</span><span class="p">()٫</span> 
                          <span class="n">ext</span> <span class="o">=</span> <span class="s">&#34;xlsx&#34;</span><span class="p">٫</span> 
                          <span class="n">dest</span> <span class="o">=</span> <span class="s">&#34;data&#34;</span><span class="p">)</span> <span class="p">{</span>
  
  <span class="n">target</span> <span class="o">&lt;-</span>  <span class="nf">paste0</span><span class="p">(</span><span class="n">url</span><span class="p">٫</span> <span class="n">fname</span><span class="p">٫</span> <span class="n">date</span><span class="p">٫</span> <span class="s">&#34;.&#34;</span><span class="p">٫</span> <span class="n">ext</span><span class="p">)</span>
  <span class="nf">message</span><span class="p">(</span><span class="s">&#34;target: &#34;</span><span class="p">٫</span> <span class="n">target</span><span class="p">)</span>

  <span class="n">destination</span> <span class="o">&lt;-</span> <span class="n">fs</span><span class="o">::</span><span class="nf">path</span><span class="p">(</span><span class="n">here</span><span class="o">::</span><span class="nf">here</span><span class="p">(</span><span class="s">&#34;data&#34;</span><span class="p">)٫</span> <span class="nf">paste0</span><span class="p">(</span><span class="n">fname</span><span class="p">٫</span> <span class="n">date</span><span class="p">)٫</span> <span class="n">ext</span> <span class="o">=</span> <span class="n">ext</span><span class="p">)</span>
  <span class="nf">message</span><span class="p">(</span><span class="s">&#34;saving to: &#34;</span><span class="p">٫</span> <span class="n">destination</span><span class="p">)</span>
  
  <span class="n">tf</span> <span class="o">&lt;-</span> <span class="nf">tempfile</span><span class="p">(</span><span class="n">fileext</span> <span class="o">=</span> <span class="n">ext</span><span class="p">)</span>
  <span class="n">curl</span><span class="o">::</span><span class="nf">curl_download</span><span class="p">(</span><span class="n">target</span><span class="p">٫</span> <span class="n">tf</span><span class="p">)</span>
  <span class="n">fs</span><span class="o">::</span><span class="nf">file_copy</span><span class="p">(</span><span class="n">tf</span><span class="p">٫</span> <span class="n">destination</span><span class="p">)</span>
  
  <span class="nf">switch</span><span class="p">(</span><span class="n">ext</span><span class="p">٫</span> 
  <span class="n">xls</span> <span class="o">=</span> <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">(</span><span class="n">readxl</span><span class="o">::</span><span class="nf">read_xls</span><span class="p">(</span><span class="n">tf</span><span class="p">))٫</span>
  <span class="n">xlsx</span> <span class="o">=</span> <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">(</span><span class="n">readxl</span><span class="o">::</span><span class="nf">read_xlsx</span><span class="p">(</span><span class="n">tf</span><span class="p">))</span>
  <span class="p">)</span>
<span class="p">}</span>                          

</code></pre></td></tr></table>
</div>
</div>

<p>Things to notice: We have to  use <code>curl_download()</code> to get the file٫ because <code>read_xls</code> cannot directly grab an Excel file from a URL in the way that e.g. <code>read_csv()</code> can for a <code>.csv</code> file. So we create a temporary file handle and use <code>curl</code> to download the data file to it. Then we copy the file to its permanent home in our <code>data/</code> folder٫ and we read the target file into R with the appropriate <code>readxl</code> function.</p>
<p>As we&rsquo;ll see in a moment٫ the country codes contained in the ECDC data are not quite standard. It will be useful in the long run to make sure that every country has standardized two- and three-letter abbreviations. Some of the countries in the ECDC&rsquo;s <code>geo_id</code> variable are missing these. This is a very common situation in data cleaning٫ where we have a big table with some data we know is missing (e.g.٫ a country code)٫ <em>and</em> we know for sure which cases the data are missing for٫ <em>and</em> we have a little lookup table that can fill in the blanks. The operation we will need to perform here is called a <em>coalescing join</em>. Before I knew that&rsquo;s what it was called٫ I used to do this manually (I&rsquo;ll show you below). But a little googling eventually revealed both the proper name for this operation and also a very useful function٫ written by <a href="https://alistaire.rbind.io">Edward Visel</a> that does <a href="https://alistaire.rbind.io/blog/coalescing-joins/">exactly what I want</a>:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">coalesce_join</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">٫</span> <span class="n">y</span><span class="p">٫</span> 
                          <span class="n">by</span> <span class="o">=</span> <span class="kc">NULL</span><span class="p">٫</span> <span class="n">suffix</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;.x&#34;</span><span class="p">٫</span> <span class="s">&#34;.y&#34;</span><span class="p">)٫</span> 
                          <span class="n">join</span> <span class="o">=</span> <span class="n">dplyr</span><span class="o">::</span><span class="n">full_join</span><span class="p">٫</span> <span class="kc">...</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">joined</span> <span class="o">&lt;-</span> <span class="nf">join</span><span class="p">(</span><span class="n">x</span><span class="p">٫</span> <span class="n">y</span><span class="p">٫</span> <span class="n">by</span> <span class="o">=</span> <span class="n">by</span><span class="p">٫</span> <span class="n">suffix</span> <span class="o">=</span> <span class="n">suffix</span><span class="p">٫</span> <span class="kc">...</span><span class="p">)</span>
    <span class="c1"># names of desired output</span>
    <span class="n">cols</span> <span class="o">&lt;-</span> <span class="n">dplyr</span><span class="o">::</span><span class="nf">union</span><span class="p">(</span><span class="nf">names</span><span class="p">(</span><span class="n">x</span><span class="p">)٫</span> <span class="nf">names</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    
    <span class="n">to_coalesce</span> <span class="o">&lt;-</span> <span class="nf">names</span><span class="p">(</span><span class="n">joined</span><span class="p">)</span><span class="n">[</span><span class="o">!</span><span class="nf">names</span><span class="p">(</span><span class="n">joined</span><span class="p">)</span> <span class="o">%in%</span> <span class="n">cols]</span>
    <span class="n">suffix_used</span> <span class="o">&lt;-</span> <span class="n">suffix</span><span class="nf">[ifelse</span><span class="p">(</span><span class="nf">endsWith</span><span class="p">(</span><span class="n">to_coalesce</span><span class="p">٫</span> <span class="n">suffix[1]</span><span class="p">)٫</span> <span class="m">1</span><span class="p">٫</span> <span class="m">2</span><span class="p">)</span><span class="n">]</span>
    <span class="c1"># remove suffixes and deduplicate</span>
    <span class="n">to_coalesce</span> <span class="o">&lt;-</span> <span class="nf">unique</span><span class="p">(</span><span class="nf">substr</span><span class="p">(</span>
        <span class="n">to_coalesce</span><span class="p">٫</span> 
        <span class="m">1</span><span class="p">٫</span> 
        <span class="nf">nchar</span><span class="p">(</span><span class="n">to_coalesce</span><span class="p">)</span> <span class="o">-</span> <span class="nf">nchar</span><span class="p">(</span><span class="n">suffix_used</span><span class="p">)</span>
    <span class="p">))</span>
    
    <span class="n">coalesced</span> <span class="o">&lt;-</span> <span class="n">purrr</span><span class="o">::</span><span class="nf">map_dfc</span><span class="p">(</span><span class="n">to_coalesce</span><span class="p">٫</span> <span class="o">~</span><span class="n">dplyr</span><span class="o">::</span><span class="nf">coalesce</span><span class="p">(</span>
        <span class="n">joined[</span><span class="nf">[paste0</span><span class="p">(</span><span class="n">.x</span><span class="p">٫</span> <span class="n">suffix[1]</span><span class="p">)</span><span class="n">]]</span><span class="p">٫</span> 
        <span class="n">joined[</span><span class="nf">[paste0</span><span class="p">(</span><span class="n">.x</span><span class="p">٫</span> <span class="n">suffix[2]</span><span class="p">)</span><span class="n">]]</span>
    <span class="p">))</span>
    <span class="nf">names</span><span class="p">(</span><span class="n">coalesced</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="n">to_coalesce</span>
    
    <span class="n">dplyr</span><span class="o">::</span><span class="nf">bind_cols</span><span class="p">(</span><span class="n">joined</span><span class="p">٫</span> <span class="n">coalesced</span><span class="p">)</span><span class="n">[cols]</span>
<span class="p">}</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Next we set up some country codes using ISO2 and ISO3 abbreviations.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">iso3_cnames</span> <span class="o">&lt;-</span> <span class="nf">read_csv</span><span class="p">(</span><span class="s">&#34;data/countries_iso3.csv&#34;</span><span class="p">)</span>
<span class="n">iso2_to_iso3</span> <span class="o">&lt;-</span> <span class="nf">read_csv</span><span class="p">(</span><span class="s">&#34;data/iso2_to_iso3.csv&#34;</span><span class="p">)</span>

<span class="n">cname_table</span> <span class="o">&lt;-</span> <span class="nf">left_join</span><span class="p">(</span><span class="n">iso3_cnames</span><span class="p">٫</span> <span class="n">iso2_to_iso3</span><span class="p">)</span>

<span class="n">cname_table</span>

<span class="c1"># A tibble: 249 x 3</span>
   <span class="n">iso3</span>  <span class="n">cname</span>               <span class="n">iso2</span> 
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>               <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>
 <span class="m">1</span> <span class="n">AFG</span>   <span class="n">Afghanistan</span>         <span class="n">AF</span>   
 <span class="m">2</span> <span class="n">ALA</span>   Å<span class="n">land</span> <span class="n">Islands</span>       <span class="n">AX</span>   
 <span class="m">3</span> <span class="n">ALB</span>   <span class="n">Albania</span>             <span class="n">AL</span>   
 <span class="m">4</span> <span class="n">DZA</span>   <span class="n">Algeria</span>             <span class="n">DZ</span>   
 <span class="m">5</span> <span class="n">ASM</span>   <span class="n">American</span> <span class="n">Samoa</span>      <span class="n">AS</span>   
 <span class="m">6</span> <span class="n">AND</span>   <span class="n">Andorra</span>             <span class="n">AD</span>   
 <span class="m">7</span> <span class="n">AGO</span>   <span class="n">Angola</span>              <span class="n">AO</span>   
 <span class="m">8</span> <span class="n">AIA</span>   <span class="n">Anguilla</span>            <span class="n">AI</span>   
 <span class="m">9</span> <span class="n">ATA</span>   <span class="n">Antarctica</span>          <span class="n">AQ</span>   
<span class="m">10</span> <span class="n">ATG</span>   <span class="n">Antigua</span> <span class="n">and</span> <span class="n">Barbuda</span> <span class="n">AG</span>   
<span class="c1"># … with 239 more rows</span>
<span class="n">eu</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;AUT&#34;</span><span class="p">٫</span> <span class="s">&#34;BEL&#34;</span><span class="p">٫</span> <span class="s">&#34;BGR&#34;</span><span class="p">٫</span> <span class="s">&#34;HRV&#34;</span><span class="p">٫</span> <span class="s">&#34;CYP&#34;</span><span class="p">٫</span> <span class="s">&#34;CZE&#34;</span><span class="p">٫</span> <span class="s">&#34;DNK&#34;</span><span class="p">٫</span> <span class="s">&#34;EST&#34;</span><span class="p">٫</span> <span class="s">&#34;FIN&#34;</span><span class="p">٫</span> <span class="s">&#34;FRA&#34;</span><span class="p">٫</span>
        <span class="s">&#34;DEU&#34;</span><span class="p">٫</span> <span class="s">&#34;GRC&#34;</span><span class="p">٫</span> <span class="s">&#34;HUN&#34;</span><span class="p">٫</span> <span class="s">&#34;IRL&#34;</span><span class="p">٫</span> <span class="s">&#34;ITA&#34;</span><span class="p">٫</span> <span class="s">&#34;LVA&#34;</span><span class="p">٫</span> <span class="s">&#34;LTU&#34;</span><span class="p">٫</span> <span class="s">&#34;LUX&#34;</span><span class="p">٫</span> <span class="s">&#34;MLT&#34;</span><span class="p">٫</span> <span class="s">&#34;NLD&#34;</span><span class="p">٫</span>
        <span class="s">&#34;POL&#34;</span><span class="p">٫</span> <span class="s">&#34;PRT&#34;</span><span class="p">٫</span> <span class="s">&#34;ROU&#34;</span><span class="p">٫</span> <span class="s">&#34;SVK&#34;</span><span class="p">٫</span> <span class="s">&#34;SVN&#34;</span><span class="p">٫</span> <span class="s">&#34;ESP&#34;</span><span class="p">٫</span> <span class="s">&#34;SWE&#34;</span><span class="p">٫</span> <span class="s">&#34;GBR&#34;</span><span class="p">)</span>

<span class="n">europe</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;ALB&#34;</span><span class="p">٫</span> <span class="s">&#34;AND&#34;</span><span class="p">٫</span> <span class="s">&#34;AUT&#34;</span><span class="p">٫</span> <span class="s">&#34;BLR&#34;</span><span class="p">٫</span> <span class="s">&#34;BEL&#34;</span><span class="p">٫</span> <span class="s">&#34;BIH&#34;</span><span class="p">٫</span> <span class="s">&#34;BGR&#34;</span><span class="p">٫</span> <span class="s">&#34;HRV&#34;</span><span class="p">٫</span> <span class="s">&#34;CYP&#34;</span><span class="p">٫</span> <span class="s">&#34;CZE&#34;</span><span class="p">٫</span>
        <span class="s">&#34;DNK&#34;</span><span class="p">٫</span> <span class="s">&#34;EST&#34;</span><span class="p">٫</span> <span class="s">&#34;FRO&#34;</span><span class="p">٫</span> <span class="s">&#34;FIN&#34;</span><span class="p">٫</span> <span class="s">&#34;FRA&#34;</span><span class="p">٫</span> <span class="s">&#34;DEU&#34;</span><span class="p">٫</span> <span class="s">&#34;GIB&#34;</span><span class="p">٫</span> <span class="s">&#34;GRC&#34;</span><span class="p">٫</span> <span class="s">&#34;HUN&#34;</span><span class="p">٫</span> <span class="s">&#34;ISL&#34;</span><span class="p">٫</span>
        <span class="s">&#34;IRL&#34;</span><span class="p">٫</span> <span class="s">&#34;ITA&#34;</span><span class="p">٫</span> <span class="s">&#34;LVA&#34;</span><span class="p">٫</span> <span class="s">&#34;LIE&#34;</span><span class="p">٫</span> <span class="s">&#34;LTU&#34;</span><span class="p">٫</span> <span class="s">&#34;LUX&#34;</span><span class="p">٫</span> <span class="s">&#34;MKD&#34;</span><span class="p">٫</span> <span class="s">&#34;MLT&#34;</span><span class="p">٫</span> <span class="s">&#34;MDA&#34;</span><span class="p">٫</span> <span class="s">&#34;MCO&#34;</span><span class="p">٫</span>
        <span class="s">&#34;NLD&#34;</span><span class="p">٫</span> <span class="s">&#34;NOR&#34;</span><span class="p">٫</span> <span class="s">&#34;POL&#34;</span><span class="p">٫</span> <span class="s">&#34;PRT&#34;</span><span class="p">٫</span> <span class="s">&#34;ROU&#34;</span><span class="p">٫</span> <span class="s">&#34;RUS&#34;</span><span class="p">٫</span> <span class="s">&#34;SMR&#34;</span><span class="p">٫</span> <span class="s">&#34;SRB&#34;</span><span class="p">٫</span> <span class="s">&#34;SVK&#34;</span><span class="p">٫</span> <span class="s">&#34;SVN&#34;</span><span class="p">٫</span>
        <span class="s">&#34;ESP&#34;</span><span class="p">٫</span> <span class="s">&#34;SWE&#34;</span><span class="p">٫</span> <span class="s">&#34;CHE&#34;</span><span class="p">٫</span> <span class="s">&#34;UKR&#34;</span><span class="p">٫</span> <span class="s">&#34;GBR&#34;</span><span class="p">٫</span> <span class="s">&#34;VAT&#34;</span><span class="p">٫</span> <span class="s">&#34;RSB&#34;</span><span class="p">٫</span> <span class="s">&#34;IMN&#34;</span><span class="p">٫</span> <span class="s">&#34;MNE&#34;</span><span class="p">)</span>

<span class="n">north_america</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;AIA&#34;</span><span class="p">٫</span> <span class="s">&#34;ATG&#34;</span><span class="p">٫</span> <span class="s">&#34;ABW&#34;</span><span class="p">٫</span> <span class="s">&#34;BHS&#34;</span><span class="p">٫</span> <span class="s">&#34;BRB&#34;</span><span class="p">٫</span> <span class="s">&#34;BLZ&#34;</span><span class="p">٫</span> <span class="s">&#34;BMU&#34;</span><span class="p">٫</span> <span class="s">&#34;VGB&#34;</span><span class="p">٫</span> <span class="s">&#34;CAN&#34;</span><span class="p">٫</span> <span class="s">&#34;CYM&#34;</span><span class="p">٫</span>
        <span class="s">&#34;CRI&#34;</span><span class="p">٫</span> <span class="s">&#34;CUB&#34;</span><span class="p">٫</span> <span class="s">&#34;CUW&#34;</span><span class="p">٫</span> <span class="s">&#34;DMA&#34;</span><span class="p">٫</span> <span class="s">&#34;DOM&#34;</span><span class="p">٫</span> <span class="s">&#34;SLV&#34;</span><span class="p">٫</span> <span class="s">&#34;GRL&#34;</span><span class="p">٫</span> <span class="s">&#34;GRD&#34;</span><span class="p">٫</span> <span class="s">&#34;GLP&#34;</span><span class="p">٫</span> <span class="s">&#34;GTM&#34;</span><span class="p">٫</span>
        <span class="s">&#34;HTI&#34;</span><span class="p">٫</span> <span class="s">&#34;HND&#34;</span><span class="p">٫</span> <span class="s">&#34;JAM&#34;</span><span class="p">٫</span> <span class="s">&#34;MTQ&#34;</span><span class="p">٫</span> <span class="s">&#34;MEX&#34;</span><span class="p">٫</span> <span class="s">&#34;SPM&#34;</span><span class="p">٫</span> <span class="s">&#34;MSR&#34;</span><span class="p">٫</span> <span class="s">&#34;ANT&#34;</span><span class="p">٫</span> <span class="s">&#34;KNA&#34;</span><span class="p">٫</span> <span class="s">&#34;NIC&#34;</span><span class="p">٫</span>
        <span class="s">&#34;PAN&#34;</span><span class="p">٫</span> <span class="s">&#34;PRI&#34;</span><span class="p">٫</span> <span class="s">&#34;KNA&#34;</span><span class="p">٫</span> <span class="s">&#34;LCA&#34;</span><span class="p">٫</span> <span class="s">&#34;SPM&#34;</span><span class="p">٫</span> <span class="s">&#34;VCT&#34;</span><span class="p">٫</span> <span class="s">&#34;TTO&#34;</span><span class="p">٫</span> <span class="s">&#34;TCA&#34;</span><span class="p">٫</span> <span class="s">&#34;VIR&#34;</span><span class="p">٫</span> <span class="s">&#34;USA&#34;</span><span class="p">٫</span>
        <span class="s">&#34;SXM&#34;</span><span class="p">)</span>

<span class="n">south_america</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;ARG&#34;</span><span class="p">٫</span> <span class="s">&#34;BOL&#34;</span><span class="p">٫</span> <span class="s">&#34;BRA&#34;</span><span class="p">٫</span> <span class="s">&#34;CHL&#34;</span><span class="p">٫</span> <span class="s">&#34;COL&#34;</span><span class="p">٫</span> <span class="s">&#34;ECU&#34;</span><span class="p">٫</span> <span class="s">&#34;FLK&#34;</span><span class="p">٫</span> <span class="s">&#34;GUF&#34;</span><span class="p">٫</span> <span class="s">&#34;GUY&#34;</span><span class="p">٫</span> <span class="s">&#34;PRY&#34;</span><span class="p">٫</span>
                   <span class="s">&#34;PER&#34;</span><span class="p">٫</span> <span class="s">&#34;SUR&#34;</span><span class="p">٫</span> <span class="s">&#34;URY&#34;</span><span class="p">٫</span> <span class="s">&#34;VEN&#34;</span><span class="p">)</span>


<span class="n">africa</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;DZA&#34;</span><span class="p">٫</span> <span class="s">&#34;AGO&#34;</span><span class="p">٫</span> <span class="s">&#34;SHN&#34;</span><span class="p">٫</span> <span class="s">&#34;BEN&#34;</span><span class="p">٫</span> <span class="s">&#34;BWA&#34;</span><span class="p">٫</span> <span class="s">&#34;BFA&#34;</span><span class="p">٫</span> <span class="s">&#34;BDI&#34;</span><span class="p">٫</span> <span class="s">&#34;CMR&#34;</span><span class="p">٫</span> <span class="s">&#34;CPV&#34;</span><span class="p">٫</span> <span class="s">&#34;CAF&#34;</span><span class="p">٫</span>
        <span class="s">&#34;TCD&#34;</span><span class="p">٫</span> <span class="s">&#34;COM&#34;</span><span class="p">٫</span> <span class="s">&#34;COG&#34;</span><span class="p">٫</span> <span class="s">&#34;DJI&#34;</span><span class="p">٫</span> <span class="s">&#34;EGY&#34;</span><span class="p">٫</span> <span class="s">&#34;GNQ&#34;</span><span class="p">٫</span> <span class="s">&#34;ERI&#34;</span><span class="p">٫</span> <span class="s">&#34;ETH&#34;</span><span class="p">٫</span> <span class="s">&#34;GAB&#34;</span><span class="p">٫</span> <span class="s">&#34;GMB&#34;</span><span class="p">٫</span>
        <span class="s">&#34;GHA&#34;</span><span class="p">٫</span> <span class="s">&#34;GNB&#34;</span><span class="p">٫</span> <span class="s">&#34;GIN&#34;</span><span class="p">٫</span> <span class="s">&#34;CIV&#34;</span><span class="p">٫</span> <span class="s">&#34;KEN&#34;</span><span class="p">٫</span> <span class="s">&#34;LSO&#34;</span><span class="p">٫</span> <span class="s">&#34;LBR&#34;</span><span class="p">٫</span> <span class="s">&#34;LBY&#34;</span><span class="p">٫</span> <span class="s">&#34;MDG&#34;</span><span class="p">٫</span> <span class="s">&#34;MWI&#34;</span><span class="p">٫</span>
        <span class="s">&#34;MLI&#34;</span><span class="p">٫</span> <span class="s">&#34;MRT&#34;</span><span class="p">٫</span> <span class="s">&#34;MUS&#34;</span><span class="p">٫</span> <span class="s">&#34;MYT&#34;</span><span class="p">٫</span> <span class="s">&#34;MAR&#34;</span><span class="p">٫</span> <span class="s">&#34;MOZ&#34;</span><span class="p">٫</span> <span class="s">&#34;NAM&#34;</span><span class="p">٫</span> <span class="s">&#34;NER&#34;</span><span class="p">٫</span> <span class="s">&#34;NGA&#34;</span><span class="p">٫</span> <span class="s">&#34;STP&#34;</span><span class="p">٫</span>
        <span class="s">&#34;REU&#34;</span><span class="p">٫</span> <span class="s">&#34;RWA&#34;</span><span class="p">٫</span> <span class="s">&#34;STP&#34;</span><span class="p">٫</span> <span class="s">&#34;SEN&#34;</span><span class="p">٫</span> <span class="s">&#34;SYC&#34;</span><span class="p">٫</span> <span class="s">&#34;SLE&#34;</span><span class="p">٫</span> <span class="s">&#34;SOM&#34;</span><span class="p">٫</span> <span class="s">&#34;ZAF&#34;</span><span class="p">٫</span> <span class="s">&#34;SHN&#34;</span><span class="p">٫</span> <span class="s">&#34;SDN&#34;</span><span class="p">٫</span>
        <span class="s">&#34;SWZ&#34;</span><span class="p">٫</span> <span class="s">&#34;TZA&#34;</span><span class="p">٫</span> <span class="s">&#34;TGO&#34;</span><span class="p">٫</span> <span class="s">&#34;TUN&#34;</span><span class="p">٫</span> <span class="s">&#34;UGA&#34;</span><span class="p">٫</span> <span class="s">&#34;COD&#34;</span><span class="p">٫</span> <span class="s">&#34;ZMB&#34;</span><span class="p">٫</span> <span class="s">&#34;TZA&#34;</span><span class="p">٫</span> <span class="s">&#34;ZWE&#34;</span><span class="p">٫</span> <span class="s">&#34;SSD&#34;</span><span class="p">٫</span>
        <span class="s">&#34;COD&#34;</span><span class="p">)</span>

<span class="n">asia</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;AFG&#34;</span><span class="p">٫</span> <span class="s">&#34;ARM&#34;</span><span class="p">٫</span> <span class="s">&#34;AZE&#34;</span><span class="p">٫</span> <span class="s">&#34;BHR&#34;</span><span class="p">٫</span> <span class="s">&#34;BGD&#34;</span><span class="p">٫</span> <span class="s">&#34;BTN&#34;</span><span class="p">٫</span> <span class="s">&#34;BRN&#34;</span><span class="p">٫</span> <span class="s">&#34;KHM&#34;</span><span class="p">٫</span> <span class="s">&#34;CHN&#34;</span><span class="p">٫</span> <span class="s">&#34;CXR&#34;</span><span class="p">٫</span>
        <span class="s">&#34;CCK&#34;</span><span class="p">٫</span> <span class="s">&#34;IOT&#34;</span><span class="p">٫</span> <span class="s">&#34;GEO&#34;</span><span class="p">٫</span> <span class="s">&#34;HKG&#34;</span><span class="p">٫</span> <span class="s">&#34;IND&#34;</span><span class="p">٫</span> <span class="s">&#34;IDN&#34;</span><span class="p">٫</span> <span class="s">&#34;IRN&#34;</span><span class="p">٫</span> <span class="s">&#34;IRQ&#34;</span><span class="p">٫</span> <span class="s">&#34;ISR&#34;</span><span class="p">٫</span> <span class="s">&#34;JPN&#34;</span><span class="p">٫</span>
        <span class="s">&#34;JOR&#34;</span><span class="p">٫</span> <span class="s">&#34;KAZ&#34;</span><span class="p">٫</span> <span class="s">&#34;PRK&#34;</span><span class="p">٫</span> <span class="s">&#34;KOR&#34;</span><span class="p">٫</span> <span class="s">&#34;KWT&#34;</span><span class="p">٫</span> <span class="s">&#34;KGZ&#34;</span><span class="p">٫</span> <span class="s">&#34;LAO&#34;</span><span class="p">٫</span> <span class="s">&#34;LBN&#34;</span><span class="p">٫</span> <span class="s">&#34;MAC&#34;</span><span class="p">٫</span> <span class="s">&#34;MYS&#34;</span><span class="p">٫</span>
        <span class="s">&#34;MDV&#34;</span><span class="p">٫</span> <span class="s">&#34;MNG&#34;</span><span class="p">٫</span> <span class="s">&#34;MMR&#34;</span><span class="p">٫</span> <span class="s">&#34;NPL&#34;</span><span class="p">٫</span> <span class="s">&#34;OMN&#34;</span><span class="p">٫</span> <span class="s">&#34;PAK&#34;</span><span class="p">٫</span> <span class="s">&#34;PHL&#34;</span><span class="p">٫</span> <span class="s">&#34;QAT&#34;</span><span class="p">٫</span> <span class="s">&#34;SAU&#34;</span><span class="p">٫</span> <span class="s">&#34;SGP&#34;</span><span class="p">٫</span>
        <span class="s">&#34;LKA&#34;</span><span class="p">٫</span> <span class="s">&#34;SYR&#34;</span><span class="p">٫</span> <span class="s">&#34;TWN&#34;</span><span class="p">٫</span> <span class="s">&#34;TJK&#34;</span><span class="p">٫</span> <span class="s">&#34;THA&#34;</span><span class="p">٫</span> <span class="s">&#34;TUR&#34;</span><span class="p">٫</span> <span class="s">&#34;TKM&#34;</span><span class="p">٫</span> <span class="s">&#34;ARE&#34;</span><span class="p">٫</span> <span class="s">&#34;UZB&#34;</span><span class="p">٫</span> <span class="s">&#34;VNM&#34;</span><span class="p">٫</span>
        <span class="s">&#34;YEM&#34;</span><span class="p">٫</span> <span class="s">&#34;PSE&#34;</span><span class="p">)</span>

<span class="n">oceania</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;ASM&#34;</span><span class="p">٫</span> <span class="s">&#34;AUS&#34;</span><span class="p">٫</span> <span class="s">&#34;NZL&#34;</span><span class="p">٫</span> <span class="s">&#34;COK&#34;</span><span class="p">٫</span> <span class="s">&#34;FJI&#34;</span><span class="p">٫</span> <span class="s">&#34;PYF&#34;</span><span class="p">٫</span> <span class="s">&#34;GUM&#34;</span><span class="p">٫</span> <span class="s">&#34;KIR&#34;</span><span class="p">٫</span> <span class="s">&#34;MNP&#34;</span><span class="p">٫</span> <span class="s">&#34;MHL&#34;</span><span class="p">٫</span>
        <span class="s">&#34;FSM&#34;</span><span class="p">٫</span> <span class="s">&#34;UMI&#34;</span><span class="p">٫</span> <span class="s">&#34;NRU&#34;</span><span class="p">٫</span> <span class="s">&#34;NCL&#34;</span><span class="p">٫</span> <span class="s">&#34;NZL&#34;</span><span class="p">٫</span> <span class="s">&#34;NIU&#34;</span><span class="p">٫</span> <span class="s">&#34;NFK&#34;</span><span class="p">٫</span> <span class="s">&#34;PLW&#34;</span><span class="p">٫</span> <span class="s">&#34;PNG&#34;</span><span class="p">٫</span> <span class="s">&#34;MNP&#34;</span><span class="p">٫</span>
        <span class="s">&#34;SLB&#34;</span><span class="p">٫</span> <span class="s">&#34;TKL&#34;</span><span class="p">٫</span> <span class="s">&#34;TON&#34;</span><span class="p">٫</span> <span class="s">&#34;TUV&#34;</span><span class="p">٫</span> <span class="s">&#34;VUT&#34;</span><span class="p">٫</span> <span class="s">&#34;UMI&#34;</span><span class="p">٫</span> <span class="s">&#34;WLF&#34;</span><span class="p">٫</span> <span class="s">&#34;WSM&#34;</span><span class="p">٫</span> <span class="s">&#34;TLS&#34;</span><span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div>

<h2 id="now-actually-get-the-data">Now Actually Get the Data</h2>
<p>The next step is to read the data. The file <em>should</em> be called <code>COVID-19-geographic-distribution-worldwide-</code> with the date appended and the extension <code>.xlsx</code>. But as it turns out there is a typo in the filename. The <code>distribution</code> part is misspelled <code>disbtribution</code>. I think it must have been introduced early on in the data collection process and so far&mdash;possibly by accident٫ but also possibly so as not to break a thousand scripts like this one&mdash;they have not been fixing the typo.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">covid_raw</span> <span class="o">&lt;-</span> <span class="nf">get_ecdc_data</span><span class="p">(</span><span class="n">url</span> <span class="o">=</span> <span class="s">&#34;https://www.ecdc.europa.eu/sites/default/files/documents/&#34;</span><span class="p">٫</span>
                           <span class="n">fname</span> <span class="o">=</span> <span class="s">&#34;COVID-19-geographic-disbtribution-worldwide-&#34;</span><span class="p">٫</span>
                           <span class="n">ext</span> <span class="o">=</span> <span class="s">&#34;xlsx&#34;</span><span class="p">)</span>
<span class="n">covid_raw</span>

<span class="c1"># A tibble: 6٫012 x 8</span>
   <span class="n">date_rep</span>              <span class="n">day</span> <span class="n">month</span>  <span class="n">year</span> <span class="n">cases</span> <span class="n">deaths</span> <span class="n">countries_and_t</span>…
   <span class="o">&lt;</span><span class="n">dttm</span><span class="o">&gt;</span>              <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>           
 <span class="m">1</span> <span class="m">2020-03-21</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">21</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">2</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">2</span> <span class="m">2020-03-20</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">20</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">3</span> <span class="m">2020-03-19</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">19</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">4</span> <span class="m">2020-03-18</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">18</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">1</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">5</span> <span class="m">2020-03-17</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">17</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">5</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">6</span> <span class="m">2020-03-16</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">16</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">6</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">7</span> <span class="m">2020-03-15</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">15</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">3</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">8</span> <span class="m">2020-03-11</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">11</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">3</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">9</span> <span class="m">2020-03-08</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>     <span class="m">8</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">3</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
<span class="m">10</span> <span class="m">2020-03-02</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>     <span class="m">2</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
<span class="c1"># … with 6٫002 more rows٫ and 1 more variable: geo_id &lt;chr&gt;</span>


</code></pre></td></tr></table>
</div>
</div>

<p>That&rsquo;s our base data. The <code>get_ecdc_data()</code> function uses <code>file_copy()</code> from the <code>fs</code> library to move the temporary file to the <code>data/</code> folder. It will not overwrite a file if it finds one with that name already there. So if you grab the data more than once a day٫ you&rsquo;ll need to decide what to do with the file you already downloaded.</p>
<p>The <code>geo_id</code> country code column isn&rsquo;t visible here. We&rsquo;re going to duplicate it (naming it <code>iso2</code>) and then join our table of two- and three-letter country codes. It has an <code>iso2</code> column as well.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">covid</span> <span class="o">&lt;-</span> <span class="n">covid_raw</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">date</span> <span class="o">=</span> <span class="n">lubridate</span><span class="o">::</span><span class="nf">ymd</span><span class="p">(</span><span class="n">date_rep</span><span class="p">)٫</span>
         <span class="n">iso2</span> <span class="o">=</span> <span class="n">geo_id</span><span class="p">)</span>

<span class="c1">## merge in the iso country names</span>
<span class="n">covid</span> <span class="o">&lt;-</span> <span class="nf">left_join</span><span class="p">(</span><span class="n">covid</span><span class="p">٫</span> <span class="n">cname_table</span><span class="p">)</span>

<span class="n">covid</span>

<span class="c1"># A tibble: 6٫012 x 12</span>
   <span class="n">date_rep</span>              <span class="n">day</span> <span class="n">month</span>  <span class="n">year</span> <span class="n">cases</span> <span class="n">deaths</span> <span class="n">countries_and_t</span>…
   <span class="o">&lt;</span><span class="n">dttm</span><span class="o">&gt;</span>              <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>           
 <span class="m">1</span> <span class="m">2020-03-21</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">21</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">2</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">2</span> <span class="m">2020-03-20</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">20</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">3</span> <span class="m">2020-03-19</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">19</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">4</span> <span class="m">2020-03-18</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">18</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">1</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">5</span> <span class="m">2020-03-17</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">17</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">5</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">6</span> <span class="m">2020-03-16</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">16</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">6</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">7</span> <span class="m">2020-03-15</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">15</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">3</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">8</span> <span class="m">2020-03-11</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">11</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">3</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
 <span class="m">9</span> <span class="m">2020-03-08</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>     <span class="m">8</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">3</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
<span class="m">10</span> <span class="m">2020-03-02</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>     <span class="m">2</span>     <span class="m">3</span>  <span class="m">2020</span>     <span class="m">0</span>      <span class="m">0</span> <span class="n">Afghanistan</span>     
<span class="c1"># … with 6٫002 more rows٫ and 5 more variables: geo_id &lt;chr&gt;٫</span>
<span class="c1">#   date &lt;date&gt;٫ iso2 &lt;chr&gt;٫ iso3 &lt;chr&gt;٫ cname &lt;chr&gt;</span>

</code></pre></td></tr></table>
</div>
</div>

<p>At this point we can notice a couple of things about the dataset. For example٫ not everything in the dataset is a country. This one&rsquo;s a cruise ship:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="c1">## Looks like a missing data code</span>
<span class="n">covid</span> <span class="o">%&gt;%</span> 
  <span class="nf">filter</span><span class="p">(</span><span class="n">cases</span> <span class="o">==</span> <span class="m">-9</span><span class="p">)</span>

<span class="c1"># A tibble: 1 x 12</span>
  <span class="n">date_rep</span>              <span class="n">day</span> <span class="n">month</span>  <span class="n">year</span> <span class="n">cases</span> <span class="n">deaths</span> <span class="n">countries_and_t</span>…
  <span class="o">&lt;</span><span class="n">dttm</span><span class="o">&gt;</span>              <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>           
<span class="m">1</span> <span class="m">2020-03-10</span> <span class="m">00</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">00</span>    <span class="m">10</span>     <span class="m">3</span>  <span class="m">2020</span>    <span class="m">-9</span>      <span class="m">1</span> <span class="n">Cases_on_an_int</span>…
<span class="c1"># … with 5 more variables: geo_id &lt;chr&gt;٫ date &lt;date&gt;٫ iso2 &lt;chr&gt;٫</span>
<span class="c1">#   iso3 &lt;chr&gt;٫ cname &lt;chr&gt;</span>

</code></pre></td></tr></table>
</div>
</div>

<p>We can also learn٫ using an <code>anti_join()</code> that not all the ECDC&rsquo;s <code>geo_id</code> country codes match up with the ISO codes:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="nf">anti_join</span><span class="p">(</span><span class="n">covid</span><span class="p">٫</span> <span class="n">cname_table</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">geo_id</span><span class="p">٫</span> <span class="n">countries_and_territories</span><span class="p">٫</span> <span class="n">iso2</span><span class="p">٫</span> <span class="n">iso3</span><span class="p">٫</span> <span class="n">cname</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">distinct</span><span class="p">()</span>

<span class="c1"># A tibble: 7 x 5</span>
  <span class="n">geo_id</span>   <span class="n">countries_and_territories</span>               <span class="n">iso2</span>    <span class="n">iso3</span>  <span class="n">cname</span>
  <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>    <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>                                   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>
<span class="m">1</span> <span class="n">JPG11668</span> <span class="n">Cases_on_an_international_conveyance_J</span>… <span class="n">JPG116</span>… <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> 
<span class="m">2</span> <span class="n">PYF</span>      <span class="n">French_Polynesia</span>                        <span class="n">PYF</span>     <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> 
<span class="m">3</span> <span class="n">EL</span>       <span class="n">Greece</span>                                  <span class="n">EL</span>      <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> 
<span class="m">4</span> <span class="n">XK</span>       <span class="n">Kosovo</span>                                  <span class="n">XK</span>      <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> 
<span class="m">5</span> <span class="kc">NA</span>       <span class="n">Namibia</span>                                 <span class="kc">NA</span>      <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> 
<span class="m">6</span> <span class="n">AN</span>       <span class="n">Netherlands_Antilles</span>                    <span class="n">AN</span>      <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> 
<span class="m">7</span> <span class="n">UK</span>       <span class="n">United_Kingdom</span>                          <span class="n">UK</span>      <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> 

</code></pre></td></tr></table>
</div>
</div>

<p>Let&rsquo;s fix this. I made a small crosswalk file that can be coalesced into the missing values. In an added little wrinkle٫ we need to specify the <code>na</code> argument in <code>read_csv</code> explicity because the missing country codes include Namibia٫ which has an ISO country code of &ldquo;NA&rdquo;! This is different from the missing data code <code>NA</code> but <code>read_csv()</code> won&rsquo;t know this by default.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">cname_xwalk</span> <span class="o">&lt;-</span> <span class="nf">read_csv</span><span class="p">(</span><span class="s">&#34;data/ecdc_to_iso2_xwalk.csv&#34;</span><span class="p">٫</span>
                        <span class="n">na</span> <span class="o">=</span> <span class="s">&#34;&#34;</span><span class="p">)</span>

<span class="n">cname_xwalk</span>

<span class="c1"># A tibble: 4 x 3</span>
  <span class="n">geo_id</span> <span class="n">iso3</span>  <span class="n">cname</span>         
  <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>         
<span class="m">1</span> <span class="n">UK</span>     <span class="n">GBR</span>   <span class="n">United</span> <span class="n">Kingdom</span>
<span class="m">2</span> <span class="n">EL</span>     <span class="n">GRC</span>   <span class="n">Greece</span>        
<span class="m">3</span> <span class="kc">NA</span>     <span class="n">NAM</span>   <span class="n">Namibia</span>       
<span class="m">4</span> <span class="n">XK</span>     <span class="n">XKV</span>   <span class="n">Kosovo</span>        

</code></pre></td></tr></table>
</div>
</div>

<p>I used to do coalescing like this:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="c1"># covid &lt;- covid %&gt;%</span>
<span class="c1">#   left_join(cname_xwalk٫ by = &#34;geo_id&#34;) %&gt;% </span>
<span class="c1">#   mutate(iso3 = coalesce(iso3.x٫ iso3.y)٫</span>
<span class="c1">#          cname = coalesce(cname.x٫ cname.y)) %&gt;% </span>
<span class="c1">#   select(-iso3.x٫ -iso3.y٫ cname.x٫ cname.y)</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Actually٫ I <em>used</em> to do it using <code>match()</code> and some index vectors٫ like an animal. But now I can use Edward Visel&rsquo;s handy function instead.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">covid</span> <span class="o">&lt;-</span> <span class="nf">coalesce_join</span><span class="p">(</span><span class="n">covid</span><span class="p">٫</span> <span class="n">cname_xwalk</span><span class="p">٫</span> 
                       <span class="n">by</span> <span class="o">=</span> <span class="s">&#34;geo_id&#34;</span><span class="p">٫</span> <span class="n">join</span> <span class="o">=</span> <span class="n">dplyr</span><span class="o">::</span><span class="n">left_join</span><span class="p">)</span>

<span class="c1">## Take a look again</span>
<span class="nf">anti_join</span><span class="p">(</span><span class="n">covid</span><span class="p">٫</span> <span class="n">cname_table</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">geo_id</span><span class="p">٫</span> <span class="n">countries_and_territories</span><span class="p">٫</span> <span class="n">iso2</span><span class="p">٫</span> <span class="n">iso3</span><span class="p">٫</span> <span class="n">cname</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">distinct</span><span class="p">()</span>

<span class="c1"># A tibble: 7 x 5</span>
  <span class="n">geo_id</span>   <span class="n">countries_and_territories</span>         <span class="n">iso2</span>    <span class="n">iso3</span>  <span class="n">cname</span>      
  <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>    <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>                             <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>      
<span class="m">1</span> <span class="n">JPG11668</span> <span class="n">Cases_on_an_international_convey</span>… <span class="n">JPG116</span>… <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>       
<span class="m">2</span> <span class="n">PYF</span>      <span class="n">French_Polynesia</span>                  <span class="n">PYF</span>     <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>       
<span class="m">3</span> <span class="n">EL</span>       <span class="n">Greece</span>                            <span class="n">EL</span>      <span class="n">GRC</span>   <span class="n">Greece</span>     
<span class="m">4</span> <span class="n">XK</span>       <span class="n">Kosovo</span>                            <span class="n">XK</span>      <span class="n">XKV</span>   <span class="n">Kosovo</span>     
<span class="m">5</span> <span class="kc">NA</span>       <span class="n">Namibia</span>                           <span class="kc">NA</span>      <span class="n">NAM</span>   <span class="n">Namibia</span>    
<span class="m">6</span> <span class="n">AN</span>       <span class="n">Netherlands_Antilles</span>              <span class="n">AN</span>      <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span>       
<span class="m">7</span> <span class="n">UK</span>       <span class="n">United_Kingdom</span>                    <span class="n">UK</span>      <span class="n">GBR</span>   <span class="n">United</span> <span class="n">Kin</span>…

</code></pre></td></tr></table>
</div>
</div>

<p>Looks like a couple of new territories have been added to the ECDC file since I made the crosswalk file. I&rsquo;ll have to update that soon.</p>
<h2 id="calculate-and-plot-cumulative-mortality">Calculate and Plot Cumulative Mortality</h2>
<p>Now we can actually analyze the data (in the privacy of our own home). Let&rsquo;s draw the plot that everyone draws٫ looking at cumulative counts. We&rsquo;ll take an arbitrary threshold for number of deaths٫ let&rsquo;s say ten٫ start every country from zero days when they hit ten deaths٫ and count the cumulative deaths since that day. Again٫ note that we are not modeling or extrapolating from the data here٫ we&rsquo;re just focusing on getting a count of deaths attributed to the disease. The numbers are definitely undercounts because not all deaths directly attributable to COVID-19 have been counted as such at this point. Not everyone who died from it was tested for it٫ and so e.g. a chunk of direct COVID-19 deaths will have been mis-classified as flu deaths.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">cov_curve</span> <span class="o">&lt;-</span> <span class="n">covid</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">date</span><span class="p">٫</span> <span class="n">cname</span><span class="p">٫</span> <span class="n">iso3</span><span class="p">٫</span> <span class="n">cases</span><span class="p">٫</span> <span class="n">deaths</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">drop_na</span><span class="p">(</span><span class="n">iso3</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">iso3</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">arrange</span><span class="p">(</span><span class="n">date</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">cu_cases</span> <span class="o">=</span> <span class="nf">cumsum</span><span class="p">(</span><span class="n">cases</span><span class="p">)٫</span> 
         <span class="n">cu_deaths</span> <span class="o">=</span> <span class="nf">cumsum</span><span class="p">(</span><span class="n">deaths</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">cu_deaths</span> <span class="o">&gt;</span> <span class="m">9</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">days_elapsed</span> <span class="o">=</span> <span class="n">date</span> <span class="o">-</span> <span class="nf">min</span><span class="p">(</span><span class="n">date</span><span class="p">)٫</span>
         <span class="n">end_label</span> <span class="o">=</span> <span class="nf">ifelse</span><span class="p">(</span><span class="n">date</span> <span class="o">==</span> <span class="nf">max</span><span class="p">(</span><span class="n">date</span><span class="p">)٫</span> <span class="n">cname</span><span class="p">٫</span> <span class="kc">NA</span><span class="p">))</span>

<span class="n">cov_curve</span>

<span class="c1"># A tibble: 245 x 9</span>
<span class="c1"># Groups:   iso3 [21]</span>
   <span class="n">date</span>       <span class="n">cname</span> <span class="n">iso3</span>  <span class="n">cases</span> <span class="n">deaths</span> <span class="n">cu_cases</span> <span class="n">cu_deaths</span> <span class="n">days_elapsed</span>
   <span class="o">&lt;</span><span class="n">date</span><span class="o">&gt;</span>     <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>    <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>     <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">drtn</span><span class="o">&gt;</span>      
 <span class="m">1</span> <span class="m">2020-01-22</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">140</span>     <span class="m">11</span>      <span class="m">526</span>        <span class="m">17</span> <span class="m">0</span> <span class="n">days</span>      
 <span class="m">2</span> <span class="m">2020-01-23</span> <span class="n">China</span> <span class="n">CHN</span>      <span class="m">97</span>      <span class="m">0</span>      <span class="m">623</span>        <span class="m">17</span> <span class="m">1</span> <span class="n">days</span>      
 <span class="m">3</span> <span class="m">2020-01-24</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">259</span>      <span class="m">9</span>      <span class="m">882</span>        <span class="m">26</span> <span class="m">2</span> <span class="n">days</span>      
 <span class="m">4</span> <span class="m">2020-01-25</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">441</span>     <span class="m">15</span>     <span class="m">1323</span>        <span class="m">41</span> <span class="m">3</span> <span class="n">days</span>      
 <span class="m">5</span> <span class="m">2020-01-26</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">665</span>     <span class="m">15</span>     <span class="m">1988</span>        <span class="m">56</span> <span class="m">4</span> <span class="n">days</span>      
 <span class="m">6</span> <span class="m">2020-01-27</span> <span class="n">China</span> <span class="n">CHN</span>     <span class="m">787</span>     <span class="m">25</span>     <span class="m">2775</span>        <span class="m">81</span> <span class="m">5</span> <span class="n">days</span>      
 <span class="m">7</span> <span class="m">2020-01-28</span> <span class="n">China</span> <span class="n">CHN</span>    <span class="m">1753</span>     <span class="m">25</span>     <span class="m">4528</span>       <span class="m">106</span> <span class="m">6</span> <span class="n">days</span>      
 <span class="m">8</span> <span class="m">2020-01-29</span> <span class="n">China</span> <span class="n">CHN</span>    <span class="m">1466</span>     <span class="m">26</span>     <span class="m">5994</span>       <span class="m">132</span> <span class="m">7</span> <span class="n">days</span>      
 <span class="m">9</span> <span class="m">2020-01-30</span> <span class="n">China</span> <span class="n">CHN</span>    <span class="m">1740</span>     <span class="m">38</span>     <span class="m">7734</span>       <span class="m">170</span> <span class="m">8</span> <span class="n">days</span>      
<span class="m">10</span> <span class="m">2020-01-31</span> <span class="n">China</span> <span class="n">CHN</span>    <span class="m">1980</span>     <span class="m">43</span>     <span class="m">9714</span>       <span class="m">213</span> <span class="m">9</span> <span class="n">days</span>      
<span class="c1"># … with 235 more rows٫ and 1 more variable: end_label &lt;chr&gt;</span>


</code></pre></td></tr></table>
</div>
</div>

<p>See how at the end there we create an <code>end_label</code> variable for use in the plot. It only has values for the most recent day in the dataset (i.e. the country name if <code>date</code> is <code>max(date)</code>٫ otherwise <code>NA</code>).</p>
<p>Now we&rsquo;ll narrow our focus to a few countries and make the plot.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">focus_cn</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;CHN&#34;</span><span class="p">٫</span> <span class="s">&#34;GBR&#34;</span><span class="p">٫</span> <span class="s">&#34;USA&#34;</span><span class="p">٫</span> <span class="s">&#34;IRN&#34;</span><span class="p">٫</span> <span class="s">&#34;JPN&#34;</span><span class="p">٫</span>
              <span class="s">&#34;KOR&#34;</span><span class="p">٫</span> <span class="s">&#34;ITA&#34;</span><span class="p">٫</span> <span class="s">&#34;FRA&#34;</span><span class="p">٫</span> <span class="s">&#34;ESP&#34;</span><span class="p">)</span>


<span class="n">cov_curve</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">iso3</span> <span class="o">%in%</span> <span class="n">focus_cn</span><span class="p">)</span> <span class="o">%&gt;%</span> <span class="c1">## focus on just a few countries٫ defined above</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">end_label</span> <span class="o">=</span> <span class="nf">recode</span><span class="p">(</span><span class="n">end_label</span><span class="p">٫</span> <span class="n">`United States`</span> <span class="o">=</span> <span class="s">&#34;USA&#34;</span><span class="p">٫</span>
                        <span class="n">`Iran٫ Islamic Republic of`</span> <span class="o">=</span> <span class="s">&#34;Iran&#34;</span><span class="p">٫</span> 
                        <span class="n">`Korea٫ Republic of`</span> <span class="o">=</span> <span class="s">&#34;South Korea&#34;</span><span class="p">٫</span> 
                        <span class="n">`United Kingdom`</span> <span class="o">=</span> <span class="s">&#34;UK&#34;</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">ggplot</span><span class="p">(</span><span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">days_elapsed</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="n">cu_deaths</span><span class="p">٫</span> 
         <span class="n">color</span> <span class="o">=</span> <span class="n">cname</span><span class="p">٫</span> <span class="n">label</span> <span class="o">=</span> <span class="n">end_label</span><span class="p">٫</span> 
         <span class="n">group</span> <span class="o">=</span> <span class="n">cname</span><span class="p">))</span> <span class="o">+</span> 
  <span class="nf">geom_line</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="m">0.8</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">geom_text_repel</span><span class="p">(</span><span class="n">nudge_x</span> <span class="o">=</span> <span class="m">1.1</span><span class="p">٫</span>
                  <span class="n">nudge_y</span> <span class="o">=</span> <span class="m">0.1</span><span class="p">٫</span> 
                  <span class="n">segment.color</span> <span class="o">=</span> <span class="kc">NA</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">guides</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="n">prismatic</span><span class="o">::</span><span class="nf">clr_darken</span><span class="p">(</span><span class="nf">paletteer_d</span><span class="p">(</span><span class="s">&#34;ggsci::category20_d3&#34;</span><span class="p">)٫</span> <span class="m">0.2</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">scale_y_continuous</span><span class="p">(</span><span class="n">labels</span> <span class="o">=</span> <span class="n">scales</span><span class="o">::</span><span class="nf">comma_format</span><span class="p">(</span><span class="n">accuracy</span> <span class="o">=</span> <span class="m">1</span><span class="p">)٫</span> 
                     <span class="n">breaks</span> <span class="o">=</span> <span class="m">2</span><span class="nf">^seq</span><span class="p">(</span><span class="m">4</span><span class="p">٫</span> <span class="m">12</span><span class="p">)٫</span>
                     <span class="n">trans</span> <span class="o">=</span> <span class="s">&#34;log2&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Days Since 10th Confirmed Death&#34;</span><span class="p">٫</span> 
       <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Cumulative Number of Deaths (log scale)&#34;</span><span class="p">٫</span> 
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Cumulative Deaths from COVID-19٫ Selected Countries&#34;</span><span class="p">٫</span> 
       <span class="n">subtitle</span> <span class="o">=</span> <span class="nf">paste</span><span class="p">(</span><span class="s">&#34;Data as of&#34;</span><span class="p">٫</span> <span class="nf">format</span><span class="p">(</span><span class="nf">max</span><span class="p">(</span><span class="n">cov_curve</span><span class="o">$</span><span class="n">date</span><span class="p">)٫</span> <span class="s">&#34;%A٫ %B %e٫ %Y&#34;</span><span class="p">))٫</span> 
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Kieran Healy @kjhealy / Data: ECDC&#34;</span><span class="p">)</span> <span class="o">+</span> 
    <span class="nf">theme</span><span class="p">(</span><span class="n">plot.title</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">)٫</span> <span class="n">face</span> <span class="o">=</span> <span class="s">&#34;bold&#34;</span><span class="p">)٫</span>
          <span class="n">plot.subtitle</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1.5</span><span class="p">))٫</span>
          <span class="n">axis.text.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">))٫</span>
          <span class="n">axis.title.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1.5</span><span class="p">))٫</span>
          <span class="n">axis.title.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">1.5</span><span class="p">))٫</span>
          <span class="n">axis.text.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">))٫</span>
          <span class="n">legend.text</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">))</span>
          <span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Again٫ a few small details polish the plot. We do a quick bit of recoding on the <code>end_label</code> to shorten some country names٫ and use <code>geom_text_repel()</code> to put the labels at the end of the line. We get our y-axis breaks with <code>2^seq(4٫ 12)</code>٫ which (as case numbers rise) will be easier to extend than manually typing all the numbers. I use a base 2 log scale for the reasons <a href="https://leancrew.com/all-this/2020/03/exponential-growth-and-log-scales/">Dr Drang gives here</a>. It&rsquo;s useful to look at the doubling time٫ which base 2 helps you see٫ rather than powers of ten. (The graphs won&rsquo;t look any different.) Finally on the thematic side we can date-stamp the title of the graph using the opaque but standard <a href="https://gist.github.com/nikreiman/1408399">UNIX date formatting codes</a>٫ with <code>paste(&quot;Data as of&quot;٫ format(max(cov_curve$date)٫ &quot;%A٫ %B %e٫ %Y&quot;))</code>.</p>
<p>And here&rsquo;s our figure.</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/covid_cumulative_22-03-20.png"
         alt="Cumulative COVID-19 Deaths"/> <figcaption>
            <p>Cumulative COVID-19 Deaths</p>
        </figcaption>
</figure>
<p>The <a href="https://github.com/kjhealy/covid">GitHub repository</a> for this post also has some code to pull U.S. data from the <a href="https://covidtracking.com/">COVID Tracking Project</a> currently being run by a group of volunteers.</p>
'),('https://kieranhealy.org/blog/archives/2020/03/15/u.s.-census-counts-data/', 'U.S. Census Counts Data', '1584324764000',  15, '<p>As <a href="https://kieranhealy.org/blog/archives/2020/03/14/animating-u.s.-population-distributions/">promised previously</a>٫ I packaged up the U.S. Census data that I pulled together to make the population density and pyramid animations. The package is called <a href="https://kjhealy.github.io/uscenpops/">uscenpops</a> and it&rsquo;s available to install via GitHub or with <code>install.packages()</code> if you set up <a href="http://eddelbuettel.github.io/drat/">drat</a> first. The instructions are on the <a href="https://kjhealy.github.io/uscenpops/">package homepage</a>.</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/us-pop-smallmult.png"
         alt="A small multiple of population pyramids in selected years"/> <figcaption>
            <p>A small multiple plot of selected population pyramids</p>
        </figcaption>
</figure>
<p>Instead of an animation٫ let&rsquo;s make the less-flashy but٫ frankly٫ in all likelihood more useful small multiple plot seen here. With the package installed we can produce it as follows:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">uscenpops</span><span class="p">)</span>

<span class="n">uscenpops</span>
<span class="c1">#&gt; # A tibble: 10٫520 x 5</span>
<span class="c1">#&gt;     year   age     pop   male female</span>
<span class="c1">#&gt;    &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;</span>
<span class="c1">#&gt;  1  1900     0 1811000 919000 892000</span>
<span class="c1">#&gt;  2  1900     1 1835000 928000 907000</span>
<span class="c1">#&gt;  3  1900     2 1846000 932000 914000</span>
<span class="c1">#&gt;  4  1900     3 1848000 932000 916000</span>
<span class="c1">#&gt;  5  1900     4 1841000 928000 913000</span>
<span class="c1">#&gt;  6  1900     5 1827000 921000 906000</span>
<span class="c1">#&gt;  7  1900     6 1806000 911000 895000</span>
<span class="c1">#&gt;  8  1900     7 1780000 899000 881000</span>
<span class="c1">#&gt;  9  1900     8 1750000 884000 866000</span>
<span class="c1">#&gt; 10  1900     9 1717000 868000 849000</span>
<span class="c1">#&gt; # … with 10٫510 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>That&rsquo;s what the dataset looks like. We&rsquo;ll lengthen it٫ calculate a relative frequency (that we won&rsquo;t use in this particular plot) and add a base value that we&rsquo;ll use for the ribbon boundaries below.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">pop_pyr</span> <span class="o">&lt;-</span> <span class="n">uscenpops</span> <span class="o">%&gt;%</span> <span class="nf">select</span><span class="p">(</span><span class="n">year</span><span class="p">٫</span> <span class="n">age</span><span class="p">٫</span> <span class="n">male</span><span class="p">٫</span> <span class="n">female</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_longer</span><span class="p">(</span><span class="n">male</span><span class="o">:</span><span class="n">female</span><span class="p">٫</span> <span class="n">names_to</span> <span class="o">=</span> <span class="s">&#34;group&#34;</span><span class="p">٫</span> <span class="n">values_to</span> <span class="o">=</span> <span class="s">&#34;count&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">year</span><span class="p">٫</span> <span class="n">group</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">total</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">count</span><span class="p">)٫</span> 
         <span class="n">pct</span> <span class="o">=</span> <span class="p">(</span><span class="n">count</span><span class="o">/</span><span class="n">total</span><span class="p">)</span><span class="o">*</span><span class="m">100</span><span class="p">٫</span> 
         <span class="n">base</span> <span class="o">=</span> <span class="m">0</span><span class="p">)</span> 

<span class="n">pop_pyr</span>

<span class="c1">#&gt; # A tibble: 21٫040 x 7</span>
<span class="c1">#&gt; # Groups:   year٫ group [240]</span>
<span class="c1">#&gt;     year   age group   count    total   pct  base</span>
<span class="c1">#&gt;    &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;</span>
<span class="c1">#&gt;  1  1900     0 male   919000 38867000  2.36     0</span>
<span class="c1">#&gt;  2  1900     0 female 892000 37227000  2.40     0</span>
<span class="c1">#&gt;  3  1900     1 male   928000 38867000  2.39     0</span>
<span class="c1">#&gt;  4  1900     1 female 907000 37227000  2.44     0</span>
<span class="c1">#&gt;  5  1900     2 male   932000 38867000  2.40     0</span>
<span class="c1">#&gt;  6  1900     2 female 914000 37227000  2.46     0</span>
<span class="c1">#&gt;  7  1900     3 male   932000 38867000  2.40     0</span>
<span class="c1">#&gt;  8  1900     3 female 916000 37227000  2.46     0</span>
<span class="c1">#&gt;  9  1900     4 male   928000 38867000  2.39     0</span>
<span class="c1">#&gt; 10  1900     4 female 913000 37227000  2.45     0</span>
<span class="c1">#&gt; # … with 21٫030 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Next we set up some little vectors of labels and colors٫ and then make a mini-dataframe of what we&rsquo;ll use as labels in the plot area٫ rather than using the default strip labels in <code>facet_wrap()</code>.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="c1">## Axis labels</span>
<span class="n">mbreaks</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;1M&#34;</span><span class="p">٫</span> <span class="s">&#34;2M&#34;</span><span class="p">٫</span> <span class="s">&#34;3M&#34;</span><span class="p">)</span>

<span class="c1">## colors</span>
<span class="n">pop_colors</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;#E69F00&#34;</span><span class="p">٫</span> <span class="s">&#34;#0072B2&#34;</span><span class="p">)</span>

<span class="c1">## In-plot year labels</span>
<span class="n">dat_text</span> <span class="o">&lt;-</span> <span class="nf">data.frame</span><span class="p">(</span>
  <span class="n">label</span> <span class="o">=</span>  <span class="nf">c</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">1900</span><span class="p">٫</span> <span class="m">2015</span><span class="p">٫</span> <span class="m">5</span><span class="p">)٫</span> <span class="m">2019</span><span class="p">)٫</span>
  <span class="n">year</span>  <span class="o">=</span>  <span class="nf">c</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">1900</span><span class="p">٫</span> <span class="m">2015</span><span class="p">٫</span> <span class="m">5</span><span class="p">)٫</span> <span class="m">2019</span><span class="p">)٫</span>
  <span class="n">age</span> <span class="o">=</span> <span class="nf">rep</span><span class="p">(</span><span class="m">95</span><span class="p">٫</span> <span class="m">25</span><span class="p">)٫</span> 
  <span class="n">count</span> <span class="o">=</span> <span class="nf">rep</span><span class="p">(</span><span class="m">-2.75e6</span><span class="p">٫</span> <span class="m">25</span><span class="p">)</span>
<span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div>

<p>As before٫ the trick to making the pyramid is to set all the values for one category (here٫ males) to negative numbers.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">pop_pyr</span><span class="o">$</span><span class="n">count[pop_pyr</span><span class="o">$</span><span class="n">group</span> <span class="o">==</span> <span class="s">&#34;male&#34;</span><span class="n">]</span> <span class="o">&lt;-</span> <span class="o">-</span><span class="n">pop_pyr</span><span class="o">$</span><span class="n">count[pop_pyr</span><span class="o">$</span><span class="n">group</span> <span class="o">==</span> <span class="s">&#34;male&#34;</span><span class="n">]</span>

<span class="n">p</span> <span class="o">&lt;-</span> <span class="n">pop_pyr</span> <span class="o">%&gt;%</span> 
  <span class="nf">filter</span><span class="p">(</span><span class="n">year</span> <span class="o">%in%</span> <span class="nf">c</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">1900</span><span class="p">٫</span> <span class="m">2015</span><span class="p">٫</span> <span class="m">5</span><span class="p">)٫</span> <span class="m">2019</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">ggplot</span><span class="p">(</span><span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">age</span><span class="p">٫</span> <span class="n">ymin</span> <span class="o">=</span> <span class="n">base</span><span class="p">٫</span>
                       <span class="n">ymax</span> <span class="o">=</span> <span class="n">count</span><span class="p">٫</span> <span class="n">fill</span> <span class="o">=</span> <span class="n">group</span><span class="p">))</span>

<span class="n">p</span> <span class="o">+</span> <span class="nf">geom_ribbon</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="m">0.9</span><span class="p">٫</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;black&#34;</span><span class="p">٫</span> <span class="n">size</span> <span class="o">=</span> <span class="m">0.1</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_label</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">dat_text</span><span class="p">٫</span> 
             <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">age</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="n">count</span><span class="p">٫</span> 
                           <span class="n">label</span> <span class="o">=</span> <span class="n">label</span><span class="p">)٫</span> <span class="n">inherit.aes</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">٫</span> 
             <span class="n">vjust</span> <span class="o">=</span> <span class="s">&#34;inward&#34;</span><span class="p">٫</span> <span class="n">hjust</span> <span class="o">=</span> <span class="s">&#34;inward&#34;</span><span class="p">٫</span>
             <span class="n">fontface</span> <span class="o">=</span> <span class="s">&#34;bold&#34;</span><span class="p">٫</span> 
             <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;gray40&#34;</span><span class="p">٫</span> 
             <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;gray95&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">scale_y_continuous</span><span class="p">(</span><span class="n">labels</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">rev</span><span class="p">(</span><span class="n">mbreaks</span><span class="p">)٫</span> <span class="s">&#34;0&#34;</span><span class="p">٫</span> <span class="n">mbreaks</span><span class="p">)٫</span> 
                     <span class="n">breaks</span> <span class="o">=</span> <span class="nf">seq</span><span class="p">(</span><span class="m">-3e6</span><span class="p">٫</span> <span class="m">3e6</span><span class="p">٫</span> <span class="m">1e6</span><span class="p">)٫</span> 
                     <span class="n">limits</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">-3e6</span><span class="p">٫</span> <span class="m">3e6</span><span class="p">))</span> <span class="o">+</span> 
  <span class="nf">scale_x_continuous</span><span class="p">(</span><span class="n">breaks</span> <span class="o">=</span> <span class="nf">seq</span><span class="p">(</span><span class="m">10</span><span class="p">٫</span> <span class="m">100</span><span class="p">٫</span> <span class="m">10</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">scale_fill_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="n">pop_colors</span><span class="p">٫</span> <span class="n">labels</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;Females&#34;</span><span class="p">٫</span> <span class="s">&#34;Males&#34;</span><span class="p">))</span> <span class="o">+</span> 
  <span class="nf">guides</span><span class="p">(</span><span class="n">fill</span> <span class="o">=</span> <span class="nf">guide_legend</span><span class="p">(</span><span class="n">reverse</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Age&#34;</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Population in Millions&#34;</span><span class="p">٫</span>
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Age Distribution of the U.S. Population٫ 1900-2019&#34;</span><span class="p">٫</span>
       <span class="n">subtitle</span> <span class="o">=</span> <span class="s">&#34;Age is top-coded at 75 until 1939٫ at 85 until 1979٫ and at 100 since then&#34;</span><span class="p">٫</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Kieran Healy / kieranhealy.org / Data: US Census Bureau.&#34;</span><span class="p">٫</span>
       <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;bottom&#34;</span><span class="p">٫</span>
        <span class="n">plot.title</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">)٫</span> <span class="n">face</span> <span class="o">=</span> <span class="s">&#34;bold&#34;</span><span class="p">)٫</span>
        <span class="n">strip.background</span> <span class="o">=</span> <span class="nf">element_blank</span><span class="p">()٫</span>  
        <span class="n">strip.text.x</span> <span class="o">=</span> <span class="nf">element_blank</span><span class="p">())</span> <span class="o">+</span>
  <span class="nf">coord_flip</span><span class="p">()</span> <span class="o">+</span> 
  <span class="nf">facet_wrap</span><span class="p">(</span><span class="o">~</span> <span class="n">year</span><span class="p">٫</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">5</span><span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div>

<p>The calls to <code>geom_ribbon()</code> and <code>geom_label()</code> draw the actual plots٫ and everything else is just a little attention to detail in order to make it come out nicely.</p>
'),('https://kieranhealy.org/blog/archives/2020/03/14/animating-u.s.-population-distributions/', 'Animating U.S. Population Distributions', '1584219472000',  15, '<p>With the 2020 U.S. Census in motion already٫ I&rsquo;ve been looking at various pieces of data from the <a href="http://census.gov">Census Bureau</a>. I decided I wanted to draw some population pyramids for the U.S. over as long a time series as I could. What&rsquo;s needed for that are tables for٫ say٫ as many years as possible that show the number of males and females alive at every year of age from zero to the highest age you&rsquo;re willing to track. This sort of data <em>is</em> available on the Census website. But it tuned out to be somewhat tedious to assemble into a single usable series. (Perhaps it&rsquo;s available in an easy-to-digest form elsewhere٫ but I couldn&rsquo;t find it.) I initially worked with a couple of the excellent R packages that talk to the Census API (<code>tidycensus</code> and <code>censusapi</code>)٫ hoping they&rsquo;d give me what I needed. But in the end I wrangled an annual year-of-age series from 1900 to 2019 by grabbing the data from the Census and cleaning it myself. As always٫ 95% of data analysis is in fact data acquisition and data cleaning.</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/us_pyramid_1980.png"/> 
</figure>
<p>First we get ourselves set up as usual.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">here</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">janitor</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">socviz</span><span class="p">)</span>

<span class="nf">library</span><span class="p">(</span><span class="n">gganimate</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">transformr</span><span class="p">)</span>

<span class="c1">## --------------------------------------------------------------------</span>
<span class="c1">## Custom font and theme٫ omit if you don&#39;t have the myriad library</span>
<span class="c1">## (https://github.com/kjhealy/myriad) and associated Adobe fonts.</span>
<span class="c1">## --------------------------------------------------------------------</span>
<span class="nf">library</span><span class="p">(</span><span class="n">showtext</span><span class="p">)</span>
<span class="nf">showtext_auto</span><span class="p">()</span>
<span class="nf">library</span><span class="p">(</span><span class="n">myriad</span><span class="p">)</span>
<span class="nf">import_myriad_semi</span><span class="p">()</span>

<span class="nf">theme_set</span><span class="p">(</span><span class="nf">theme_myriad_semi</span><span class="p">())</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Now٫ the data. What we want are the decennial and intercensal estimates by year٫ sex٫ and year of age. These aren&rsquo;t all in the same place. Moreover٫ they aren&rsquo;t all in the same format. The estimates for 1900 to 1979 are available <a href="https://www2.census.gov/programs-surveys/popest/tables/1900-1980/national/asrh/?C=N;O=D">at this link</a>٫ but (as quickly became clear)٫ the format of the CSV file changes slightly. Subsequent decades vary their format and expand the range of measures counted. Some of the formats are rather difficult to work with. For example٫ here&rsquo;s part of the description of the 1980-89 files:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">The 1990 monthly postcensal national population estimate data files have
an identical layout.  All records contain 222 characters.  All data fields
are right-justified.

Location            Type        Data

1-2                 Character   Series
3-4                 Numeric     Month
5-8                 Numeric     Year
9-11                Numeric     Age (years)
12                  (blank)     (blank)
13-22               Numeric     Total population
23-32               Numeric     Total male population
33-42               Numeric     Total female population
43-52               Numeric     White male population
53-62               Numeric     White female population
63-72               Numeric     Black male population
73-82               Numeric     Black female population

</code></pre></td></tr></table>
</div>
</div><p>And then:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">Within each file٫ the records are first sorted by the reference date
(Month-Year) in chronological order.  For each reference date٫ the first
record lists the population counts for all ages combined.  The remaining
records list the population counts by single year of age in ascending
order.
</code></pre></td></tr></table>
</div>
</div><p>That means that the data file for any particular year during this period looks something like this:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">2I 780 98      14234      3485 
2I 780 99       9652      2409 
2I 780100      15099      3244 
2I1080999  227924215 110746612 
2I1080  0    3582352   1832733 
2I1080  1    3360607   1718828 
2I1080  2    3217219   1645162 
</code></pre></td></tr></table>
</div>
</div><p>Not so nice. The cleanest way to work with stuff like this would be to write a spec to read in the data by column position. In the end I wrote a series of short scripts using some old-fashioned Unix tools٫ especially <code>sed</code>٫ to do the slicing and dicing for me. They looked like this:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash">
<span class="c1">## Extract every row between the first</span>
<span class="c1">## July estimate (^2I 7) to oct (2I10)</span>
<span class="k">for</span> filename in *.TXT<span class="p">;</span> <span class="k">do</span>
    gsed -i.bak -n <span class="s1">&#39;/^2I 7/٫/2I10/p;/^\+/p&#39;</span> <span class="s2">&#34;</span><span class="nv">$filename</span><span class="s2">&#34;</span> 
<span class="k">done</span>

<span class="c1">## cut away the first 7 columns</span>
<span class="k">for</span> filename in *.TXT<span class="p">;</span> <span class="k">do</span>
   cut -c7- &lt;<span class="s2">&#34;</span><span class="nv">$filename</span><span class="s2">&#34;</span> &gt;<span class="s2">&#34;</span><span class="si">${</span><span class="nv">filename</span><span class="p">%.TXT</span><span class="si">}</span><span class="s2">.new&#34;</span>
<span class="k">done</span>

<span class="c1">## trim the first and last lines</span>
<span class="k">for</span> filename in *.new<span class="p">;</span> <span class="k">do</span>
    gsed -i <span class="s1">&#39;1d;$d&#39;</span> <span class="s2">&#34;</span><span class="nv">$filename</span><span class="s2">&#34;</span>
<span class="k">done</span>
</code></pre></td></tr></table>
</div>
</div>

<p>In the end I had some fairly clean delimited files that I could work with that needed only a little more cleaning in R. For each batch of files I&rsquo;d do something like this: get a list of the files needed from the directory٫ read the contents into a tibble and harmonize the column names if needed. Here&rsquo;s the segment for the 1980s files٫ for example:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">target</span> <span class="o">&lt;-</span> <span class="s">&#34;1980_1989&#34;</span>
<span class="n">path</span> <span class="o">&lt;-</span> <span class="nf">paste0</span><span class="p">(</span><span class="s">&#34;data/&#34;</span><span class="p">٫</span><span class="n">target</span><span class="p">)</span>

<span class="n">filenames</span> <span class="o">&lt;-</span> <span class="nf">dir</span><span class="p">(</span><span class="n">path</span> <span class="o">=</span> <span class="nf">here</span><span class="p">(</span><span class="n">path</span><span class="p">)٫</span>
                 <span class="n">pattern</span> <span class="o">=</span> <span class="s">&#34;*.new$&#34;</span><span class="p">٫</span>
                 <span class="n">full.names</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>

<span class="n">pop_1980_1989</span> <span class="o">&lt;-</span> <span class="nf">tibble</span><span class="p">(</span>
  <span class="n">year</span> <span class="o">=</span> <span class="nf">get_80syr</span><span class="p">(</span><span class="n">filenames</span><span class="p">)٫</span>
  <span class="n">path</span> <span class="o">=</span> <span class="n">filenames</span><span class="p">٫</span> 
  <span class="n">data</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span><span class="n">filenames</span><span class="p">٫</span> <span class="o">~</span> <span class="nf">read_delim</span><span class="p">(</span><span class="n">.٫</span> <span class="n">delim</span> <span class="o">=</span> <span class="s">&#34; &#34;</span><span class="p">))</span>
  <span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span><span class="n">data</span><span class="p">٫</span> <span class="o">~</span> 
                       <span class="n">.x</span> <span class="o">%&gt;%</span> 
                         <span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.character</span><span class="p">٫</span> <span class="n">as.numeric</span><span class="p">)))</span>

<span class="n">pop_1980_1989</span>

<span class="c1"># A tibble: 10 x 3</span>
   <span class="n">year</span>  <span class="n">path</span>                                           <span class="n">data</span>          
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>                                          <span class="o">&lt;</span><span class="n">list</span><span class="o">&gt;</span>        
 <span class="m">1</span> <span class="m">1980</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>… <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> …
 <span class="m">2</span> <span class="m">1981</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>… <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> …
 <span class="m">3</span> <span class="m">1982</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>… <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> …
 <span class="m">4</span> <span class="m">1983</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>… <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> …
 <span class="m">5</span> <span class="m">1984</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>… <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> …
 <span class="m">6</span> <span class="m">1985</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>… <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> …
 <span class="m">7</span> <span class="m">1986</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>… <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> …
 <span class="m">8</span> <span class="m">1987</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>… <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> …
 <span class="m">9</span> <span class="m">1988</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>… <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> …
<span class="m">10</span> <span class="m">1989</span>  <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">census_pop</span>… <span class="o">&lt;</span><span class="n">tibble</span> <span class="n">[101</span> …
</code></pre></td></tr></table>
</div>
</div>

<p>Eventually all the series are read in and can be bound together and the year٫ age٫ and population counts extracted.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="c1"># Now we&#39;re suckin&#39; diesel</span>
<span class="n">pop_data</span> <span class="o">&lt;-</span> <span class="nf">bind_rows</span><span class="p">(</span><span class="n">pop_1900_1959</span><span class="p">٫</span> 
                      <span class="n">pop_1960_1979</span><span class="p">٫</span> 
                      <span class="n">pop_1980_1989</span><span class="p">٫</span>
                      <span class="n">pop_1990_1999</span><span class="p">٫</span> 
                      <span class="n">pop_2000_2009</span><span class="p">٫</span> 
                      <span class="n">pop_2010_2019</span><span class="p">)</span>

<span class="n">pop_series</span> <span class="o">&lt;-</span> <span class="nf">unnest</span><span class="p">(</span><span class="n">pop_data</span><span class="p">٫</span> <span class="n">cols</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">path</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">year</span><span class="p">٫</span> <span class="n">age</span><span class="p">٫</span> <span class="n">pop</span><span class="p">٫</span> <span class="n">male</span><span class="p">٫</span> <span class="n">female</span><span class="p">)</span> 

<span class="n">pop_series</span>

<span class="c1"># A tibble: 10٫520 x 5</span>
   <span class="n">year</span>    <span class="n">age</span>     <span class="n">pop</span>   <span class="n">male</span> <span class="n">female</span>
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>  <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>
 <span class="m">1</span> <span class="m">1900</span>      <span class="m">0</span> <span class="m">1811000</span> <span class="m">919000</span> <span class="m">892000</span>
 <span class="m">2</span> <span class="m">1900</span>      <span class="m">1</span> <span class="m">1835000</span> <span class="m">928000</span> <span class="m">907000</span>
 <span class="m">3</span> <span class="m">1900</span>      <span class="m">2</span> <span class="m">1846000</span> <span class="m">932000</span> <span class="m">914000</span>
 <span class="m">4</span> <span class="m">1900</span>      <span class="m">3</span> <span class="m">1848000</span> <span class="m">932000</span> <span class="m">916000</span>
 <span class="m">5</span> <span class="m">1900</span>      <span class="m">4</span> <span class="m">1841000</span> <span class="m">928000</span> <span class="m">913000</span>
 <span class="m">6</span> <span class="m">1900</span>      <span class="m">5</span> <span class="m">1827000</span> <span class="m">921000</span> <span class="m">906000</span>
 <span class="m">7</span> <span class="m">1900</span>      <span class="m">6</span> <span class="m">1806000</span> <span class="m">911000</span> <span class="m">895000</span>
 <span class="m">8</span> <span class="m">1900</span>      <span class="m">7</span> <span class="m">1780000</span> <span class="m">899000</span> <span class="m">881000</span>
 <span class="m">9</span> <span class="m">1900</span>      <span class="m">8</span> <span class="m">1750000</span> <span class="m">884000</span> <span class="m">866000</span>
<span class="m">10</span> <span class="m">1900</span>      <span class="m">9</span> <span class="m">1717000</span> <span class="m">868000</span> <span class="m">849000</span>
<span class="c1"># … with 10٫510 more rows</span>
</code></pre></td></tr></table>
</div>
</div>

<p>From there we pivot series to long format:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">pop_lon</span> <span class="o">&lt;-</span> <span class="n">pop_series</span> <span class="o">%&gt;%</span> <span class="nf">select</span><span class="p">(</span><span class="n">year</span><span class="p">٫</span> <span class="n">age</span><span class="p">٫</span> <span class="n">male</span><span class="p">٫</span> <span class="n">female</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_longer</span><span class="p">(</span><span class="n">male</span><span class="o">:</span><span class="n">female</span><span class="p">٫</span> <span class="n">names_to</span> <span class="o">=</span> <span class="s">&#34;group&#34;</span><span class="p">٫</span> <span class="n">values_to</span> <span class="o">=</span> <span class="s">&#34;count&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">year</span><span class="p">٫</span> <span class="n">group</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">total</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">count</span><span class="p">)٫</span> 
         <span class="n">pct</span> <span class="o">=</span> <span class="p">(</span><span class="n">count</span><span class="o">/</span><span class="n">total</span><span class="p">)</span><span class="o">*</span><span class="m">100</span><span class="p">٫</span> 
         <span class="n">base</span> <span class="o">=</span> <span class="m">0</span><span class="p">)</span> 

<span class="n">pop_lon</span>

<span class="c1"># A tibble: 21٫040 x 7</span>
<span class="c1"># Groups:   year٫ group [240]</span>
   <span class="n">year</span>    <span class="n">age</span> <span class="n">group</span>   <span class="n">count</span>    <span class="n">total</span>   <span class="n">pct</span>  <span class="n">base</span>
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>    <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>
 <span class="m">1</span> <span class="m">1900</span>      <span class="m">0</span> <span class="n">male</span>   <span class="m">919000</span> <span class="m">38867000</span>  <span class="m">2.36</span>     <span class="m">0</span>
 <span class="m">2</span> <span class="m">1900</span>      <span class="m">0</span> <span class="n">female</span> <span class="m">892000</span> <span class="m">37227000</span>  <span class="m">2.40</span>     <span class="m">0</span>
 <span class="m">3</span> <span class="m">1900</span>      <span class="m">1</span> <span class="n">male</span>   <span class="m">928000</span> <span class="m">38867000</span>  <span class="m">2.39</span>     <span class="m">0</span>
 <span class="m">4</span> <span class="m">1900</span>      <span class="m">1</span> <span class="n">female</span> <span class="m">907000</span> <span class="m">37227000</span>  <span class="m">2.44</span>     <span class="m">0</span>
 <span class="m">5</span> <span class="m">1900</span>      <span class="m">2</span> <span class="n">male</span>   <span class="m">932000</span> <span class="m">38867000</span>  <span class="m">2.40</span>     <span class="m">0</span>
 <span class="m">6</span> <span class="m">1900</span>      <span class="m">2</span> <span class="n">female</span> <span class="m">914000</span> <span class="m">37227000</span>  <span class="m">2.46</span>     <span class="m">0</span>
 <span class="m">7</span> <span class="m">1900</span>      <span class="m">3</span> <span class="n">male</span>   <span class="m">932000</span> <span class="m">38867000</span>  <span class="m">2.40</span>     <span class="m">0</span>
 <span class="m">8</span> <span class="m">1900</span>      <span class="m">3</span> <span class="n">female</span> <span class="m">916000</span> <span class="m">37227000</span>  <span class="m">2.46</span>     <span class="m">0</span>
 <span class="m">9</span> <span class="m">1900</span>      <span class="m">4</span> <span class="n">male</span>   <span class="m">928000</span> <span class="m">38867000</span>  <span class="m">2.39</span>     <span class="m">0</span>
<span class="m">10</span> <span class="m">1900</span>      <span class="m">4</span> <span class="n">female</span> <span class="m">913000</span> <span class="m">37227000</span>  <span class="m">2.45</span>     <span class="m">0</span>
<span class="c1"># … with 21٫030 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Here٫ within each  year and for males and females٫ we calculate the percentage of the total population that is of any particular age. As I mentioned٫ one feature of the Census data is that over the years the top-code for age&mdash;the highest age the Census tables report&mdash;gradually increases. We can see what those limits are and when they change:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">pop_series</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">year</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">summarize</span><span class="p">(</span><span class="n">max_age</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">age</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">max_age</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">summarize</span><span class="p">(</span><span class="n">minyr</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">year</span><span class="p">)٫</span> 
            <span class="n">maxyr</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">year</span><span class="p">))</span>

<span class="c1"># A tibble: 3 x 3</span>
  <span class="n">max_age</span> <span class="n">minyr</span> <span class="n">maxyr</span>
    <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>
<span class="m">1</span>      <span class="m">75</span> <span class="m">1900</span>  <span class="m">1939</span> 
<span class="m">2</span>      <span class="m">85</span> <span class="m">1940</span>  <span class="m">1979</span> 
<span class="m">3</span>     <span class="m">100</span> <span class="m">1980</span>  <span class="m">2019</span> 
</code></pre></td></tr></table>
</div>
</div>

<p>Now we can make some animations. First٫ rather than a population pyramid٫ we&rsquo;ll use <code>geom_density()</code> to produce kernel density estimates of the age distribution for every year٫ for both males and females. In cases like this٫ when we have a variable like <code>year</code> and a summary count for each age in that year (but not individual-level observations)٫ the way to get the density is to put <code>age</code> on the x-axis and use the proportion (<code>pct/100</code>) to weight each year-of-age. (Weights need to sum to 1٫ hence the use of proportions rather than percents.) Here we&rsquo;re using the <code>after_stat()</code> function that&rsquo;s new in the <code>scales</code> package and <code>ggplot2</code> version 3.3.0. This way of expressing what we want to do replaces earlier syntaxes like the double-period <code>..density..</code> convention.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">p_dens</span> <span class="o">&lt;-</span> <span class="n">pop_lon</span> <span class="o">%&gt;%</span>
  <span class="nf">ggplot</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">age</span><span class="p">٫</span> 
           <span class="n">y</span> <span class="o">=</span> <span class="nf">after_stat</span><span class="p">(</span><span class="n">density</span><span class="p">)٫</span>
           <span class="n">weight</span> <span class="o">=</span> <span class="n">pct</span><span class="o">/</span><span class="m">100</span><span class="p">٫</span>
           <span class="n">fill</span> <span class="o">=</span> <span class="n">group</span><span class="p">٫</span> 
           <span class="n">group</span> <span class="o">=</span> <span class="n">group</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">geom_density</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="s">&#34;black&#34;</span><span class="p">٫</span> <span class="n">alpha</span> <span class="o">=</span> <span class="m">0.5</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">scale_fill_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">)٫</span> 
                    <span class="n">labels</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;Female&#34;</span><span class="p">٫</span> <span class="s">&#34;Male&#34;</span><span class="p">))</span> <span class="o">+</span> 
  <span class="nf">scale_x_continuous</span><span class="p">(</span><span class="n">breaks</span> <span class="o">=</span> <span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">٫</span> <span class="m">100</span><span class="p">٫</span> <span class="m">10</span><span class="p">)٫</span> 
                    <span class="n">labels</span> <span class="o">=</span> <span class="nf">as.character</span><span class="p">(</span><span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">٫</span> <span class="m">100</span><span class="p">٫</span> <span class="m">10</span><span class="p">)))</span> <span class="o">+</span>
  <span class="nf">guides</span><span class="p">(</span><span class="n">fill</span> <span class="o">=</span> <span class="nf">guide_legend</span><span class="p">(</span><span class="n">label.position</span> <span class="o">=</span> <span class="s">&#34;bottom&#34;</span><span class="p">٫</span> <span class="n">keywidth</span> <span class="o">=</span> <span class="m">2</span><span class="p">)٫</span>
               <span class="n">color</span> <span class="o">=</span> <span class="nf">guide_legend</span><span class="p">(</span><span class="n">label.position</span> <span class="o">=</span> <span class="s">&#34;bottom&#34;</span><span class="p">٫</span> <span class="n">keywidth</span> <span class="o">=</span> <span class="m">2</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Age&#34;</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Estimated Density&#34;</span><span class="p">٫</span> 
      <span class="n">color</span> <span class="o">=</span> <span class="kc">NULL</span><span class="p">٫</span> <span class="n">fill</span> <span class="o">=</span> <span class="kc">NULL</span><span class="p">٫</span> 
       <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;{frame_time}. Relative Age Distribution of the U.S. Population by Sex&#34;</span><span class="p">٫</span> 
       <span class="n">subtitle</span> <span class="o">=</span> <span class="s">&#34;Age is top-coded at 75 until 1939٫ at 85 until 1979٫ and at 100 since 1980.&#34;</span><span class="p">٫</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;@kjhealy / http://kieranhealy.org.&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;bottom&#34;</span><span class="p">٫</span>
          <span class="n">plot.title</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">)٫</span> <span class="n">face</span> <span class="o">=</span> <span class="s">&#34;bold&#34;</span><span class="p">)٫</span>
          <span class="n">plot.subtitle</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))٫</span>
          <span class="n">plot.caption</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">))٫</span>
          <span class="n">axis.text.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))٫</span>
          <span class="n">axis.title.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))٫</span>
          <span class="n">axis.title.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))٫</span>
          <span class="n">axis.text.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))٫</span>
          <span class="n">legend.text</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">)))</span> <span class="o">+</span>
  <span class="nf">transition_time</span><span class="p">(</span><span class="nf">as.integer</span><span class="p">(</span><span class="nf">year</span><span class="p">(</span><span class="n">year</span><span class="p">)))</span> <span class="o">+</span> 
  <span class="nf">ease_aes</span><span class="p">(</span><span class="s">&#34;linear&#34;</span><span class="p">)</span> <span class="o">+</span> 
    <span class="nf">transition_time</span><span class="p">(</span><span class="nf">as.integer</span><span class="p">(</span><span class="n">year</span><span class="p">))</span> <span class="o">+</span> 
    <span class="nf">ease_aes</span><span class="p">(</span><span class="s">&#34;cubic-in-out&#34;</span><span class="p">)</span>
    
<span class="nf">animate</span><span class="p">(</span><span class="n">p_dens</span><span class="p">٫</span> <span class="n">fps</span> <span class="o">=</span> <span class="m">25</span><span class="p">٫</span> <span class="n">duration</span> <span class="o">=</span> <span class="m">30</span><span class="p">٫</span> <span class="n">width</span> <span class="o">=</span> <span class="m">1024</span><span class="p">٫</span> <span class="n">height</span> <span class="o">=</span> <span class="m">1024</span><span class="p">٫</span> <span class="n">renderer</span> <span class="o">=</span> <span class="nf">ffmpeg_renderer</span><span class="p">())</span>

</code></pre></td></tr></table>
</div>
</div>

<p>The <code>theme()</code> calls are all about making the default label text larger٫ using the handy <code>rel()</code> function to boost size in relative terms rather than worrying about units. We get the animation almost for free٫ thanks to Thomas Lin Pedersen&rsquo;s <code>gganimate</code> package. Just the two functions٫ <code>transition_time()</code> and <code>ease_aes()</code> do all the work. Then we use <code>animate()</code> to actually render the animation. After saving the results as an <code>mp4</code> file٫ here&rsquo;s what we get.</p>
<figure>
<video controls src="https://kieranhealy.org/files/misc/census_density_anim.mp4"></video>
</figure>
<p>The curves here are estimated kernel densities. A more conventional way to represent the demographic data we have is with a <em>population pyramid</em>٫ where we put ages on the x axis and population counts (or percentages) on the y axis٫ and then put males on the left and females on the right. To accomplish this in R we&rsquo;ll use <code>geom_ribbon()</code> and cheat a little bit by making the ages for males all be negative. Then we&rsquo;ll set the base of the male and female ribbons to be zero. Here&rsquo;s how that works. We&rsquo;re going to show the absolute rather than the relative population distribution٫ so we can watch the size of the pyramid grow over time as well as see its shape change.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">pop_pyr</span> <span class="o">&lt;-</span> <span class="n">pop_lon</span>

<span class="c1">## Make all the Male ages negative</span>
<span class="n">pop_pyr</span><span class="o">$</span><span class="n">count[pop_pyr</span><span class="o">$</span><span class="n">group</span> <span class="o">==</span> <span class="s">&#34;male&#34;</span><span class="n">]</span> <span class="o">&lt;-</span> <span class="o">-</span><span class="n">pop_pyr</span><span class="o">$</span><span class="n">count[pop_pyr</span><span class="o">$</span><span class="n">group</span> <span class="o">==</span> <span class="s">&#34;male&#34;</span><span class="n">]</span>
</code></pre></td></tr></table>
</div>
</div>

<p>The code for the plot is very similar to before:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">mbreaks</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;1M&#34;</span><span class="p">٫</span> <span class="s">&#34;2M&#34;</span><span class="p">٫</span> <span class="s">&#34;3M&#34;</span><span class="p">)</span>

<span class="n">p</span> <span class="o">&lt;-</span> <span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">pop_pyr</span><span class="p">٫</span>
            <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">age</span><span class="p">٫</span> <span class="n">ymin</span> <span class="o">=</span> <span class="n">base</span><span class="p">٫</span>
                          <span class="n">ymax</span> <span class="o">=</span> <span class="n">count</span><span class="p">٫</span> <span class="n">fill</span> <span class="o">=</span> <span class="n">group</span><span class="p">))</span>

<span class="n">p_pyr_count</span> <span class="o">&lt;-</span> <span class="n">p</span> <span class="o">+</span> <span class="nf">geom_ribbon</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="m">0.5</span><span class="p">)</span> <span class="o">+</span>
    <span class="nf">scale_y_continuous</span><span class="p">(</span><span class="n">labels</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">rev</span><span class="p">(</span><span class="n">mbreaks</span><span class="p">)٫</span> <span class="s">&#34;0&#34;</span><span class="p">٫</span> <span class="n">mbreaks</span><span class="p">)٫</span> 
                       <span class="n">breaks</span> <span class="o">=</span> <span class="nf">seq</span><span class="p">(</span><span class="m">-3e6</span><span class="p">٫</span> <span class="m">3e6</span><span class="p">٫</span> <span class="m">1e6</span><span class="p">)٫</span> 
                       <span class="n">limits</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">-3e6</span><span class="p">٫</span> <span class="m">3e6</span><span class="p">))</span> <span class="o">+</span> 
    <span class="nf">scale_x_continuous</span><span class="p">(</span><span class="n">breaks</span> <span class="o">=</span> <span class="nf">seq</span><span class="p">(</span><span class="m">10</span><span class="p">٫</span> <span class="m">100</span><span class="p">٫</span> <span class="m">10</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">scale_fill_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="nf">my.colors</span><span class="p">(</span><span class="s">&#34;bly&#34;</span><span class="p">)٫</span> <span class="n">labels</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;Female&#34;</span><span class="p">٫</span> <span class="s">&#34;Male&#34;</span><span class="p">))</span> <span class="o">+</span> 
    <span class="nf">guides</span><span class="p">(</span><span class="n">fill</span> <span class="o">=</span> <span class="nf">guide_legend</span><span class="p">(</span><span class="n">reverse</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">))</span> <span class="o">+</span>
    <span class="nf">labs</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Age&#34;</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Number of People&#34;</span><span class="p">٫</span>
         <span class="n">title</span> <span class="o">=</span> <span class="s">&#34;{frame_time}. Absolute Age Distribution of the U.S. Population by Sex&#34;</span><span class="p">٫</span>
         <span class="n">subtitle</span> <span class="o">=</span> <span class="s">&#34;Age is top-coded at 75 until 1939٫ at 85 until 1979٫ and at 100 since 1980.&#34;</span><span class="p">٫</span>
         <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;Kieran Healy / kieranhealy.org / Data: US Census Bureau.&#34;</span><span class="p">٫</span>
         <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;&#34;</span><span class="p">)</span> <span class="o">+</span>
    <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;bottom&#34;</span><span class="p">٫</span>
          <span class="n">plot.title</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">)٫</span> <span class="n">face</span> <span class="o">=</span> <span class="s">&#34;bold&#34;</span><span class="p">)٫</span>
          <span class="n">plot.subtitle</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))٫</span>
          <span class="n">plot.caption</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">2</span><span class="p">))٫</span>
          <span class="n">axis.text.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))٫</span>
          <span class="n">axis.text.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))٫</span>
          <span class="n">axis.title.x</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))٫</span>
          <span class="n">axis.title.y</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">))٫</span>
          <span class="n">legend.text</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="nf">rel</span><span class="p">(</span><span class="m">3</span><span class="p">)))</span> <span class="o">+</span>
    <span class="nf">coord_flip</span><span class="p">()</span> <span class="o">+</span> 
    <span class="nf">transition_time</span><span class="p">(</span><span class="nf">as.integer</span><span class="p">(</span><span class="n">year</span><span class="p">))</span> <span class="o">+</span> 
    <span class="nf">ease_aes</span><span class="p">(</span><span class="s">&#34;cubic-in-out&#34;</span><span class="p">)</span>
    
    
<span class="nf">animate</span><span class="p">(</span><span class="n">p_pyr_count</span><span class="p">٫</span> <span class="n">fps</span> <span class="o">=</span> <span class="m">25</span><span class="p">٫</span> <span class="n">duration</span> <span class="o">=</span> <span class="m">60</span><span class="p">٫</span> <span class="n">width</span> <span class="o">=</span> <span class="m">1024</span><span class="p">٫</span> <span class="n">height</span> <span class="o">=</span> <span class="m">1024</span><span class="p">٫</span> <span class="n">renderer</span> <span class="o">=</span> <span class="nf">ffmpeg_renderer</span><span class="p">())</span>
</code></pre></td></tr></table>
</div>
</div>

<p>The main changes are in the labeling. <code>geom_ribbon</code> needs a <code>ymin</code> and a <code>ymax</code> value. The former will always be zero. The latter will be the population count for that age. We make a little vector of population labels٫ <code>mbreaks</code>٫ for the x-axis٫ and join it up first in reverse٫ and then in regular order on either side of zero: <code>labels = c(rev(mbreaks)٫ &quot;0&quot;٫ mbreaks)</code>. We also set the breaks between -3 million and 3 millon in steps of 1 millon: <code>breaks = seq(-3e6٫ 3e6٫ 1e6)</code>. The <code>cubic-in-out</code> easing function makes for a better-looking step-by-step animation than the default <code>linear</code>٫ which bobbles around too much.</p>
<p>And here&rsquo;s the result.</p>
<figure>
<video controls src="https://kieranhealy.org/files/misc/census_abs_anim.mp4"></video
</figure>
<p>Just look at those Boomers go after 1946.</p>
<p>I&rsquo;ve been a little sketchy about the details of the cleaning process above because what I want to do is package up the clean dataset shortly so that other people don&rsquo;t have to experience the thrill of learning about the many virtues of <a href="https://www.gnu.org/software/sed/manual/sed.html">sed</a>.</p>
'),('https://kieranhealy.org/blog/archives/2020/03/07/this-be-the-kirsch/', 'This Be the Kirsch', '1583632066000',  15, '<blockquote>
They pluck your plums٫ your mum and dad<br />
They eat them for their supper٫ too<br />
They gobble all the fruit you had<br />
And leave some bullshit note for you<br />
<br />
But they were robbed blind in their day<br />
Of damsons٫ prunes٫ and blackthorn sloes<br />
Their breakfast treats were poached away<br />
And justified with old-style prose<br />
<br />
“Forgive us” both your parents moan<br />
“They were delicious٫ sweet٫ and cold”<br />
They wonder why I never phone<br />
And from them my own kids withhold<br />
</blockquote>
<p>(<a href="https://kieranhealy.org/blog/archives/2014/07/19/this-is-just-to-say-he-wishes/">See also</a>)</p>
'),('https://kieranhealy.org/blog/archives/2020/03/05/spanish-flu/', 'Spanish Flu', '1583458107000',  15, '<p>I was teaching some dplyr and ggplot today. Because Coronavirus is in the٫ uh٫ air٫ I decided to work with the mortality data from <a href="http://mortality.org">http://mortality.org</a> and have the students practice getting a bunch of data files into R and then plotting the resulting data quickly and informatively. We took a look at the years around the 1918 Influenza Epidemic and٫ after poking at the data for a little while٫ came to realize why it was called the <em>Spanish</em> Flu. Here&rsquo;s some code you can run if you download the (freely available) 1x1 mortality files from &lt;mortality.org&gt;.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="nf">library</span><span class="p">(</span><span class="n">here</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">janitor</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>

<span class="c1">## Where the data is locally</span>
<span class="n">path</span> <span class="o">&lt;-</span> <span class="s">&#34;data/Mx_1x1/&#34;</span>

<span class="c1">## Colors for later</span>
<span class="n">my_colors</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;#0072B2&#34;</span><span class="p">٫</span> <span class="s">&#34;#E69F00&#34;</span><span class="p">)</span>

<span class="c1">## Some utility functions for cleaning</span>
<span class="n">get_country_name</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">){</span>
  <span class="nf">read_lines</span><span class="p">(</span><span class="n">x</span><span class="p">٫</span> <span class="n">n_max</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="nf">str_extract</span><span class="p">(</span><span class="s">&#34;.+?٫&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="nf">str_remove</span><span class="p">(</span><span class="s">&#34;٫&#34;</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">shorten_name</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">){</span>
  <span class="nf">str_replace_all</span><span class="p">(</span><span class="n">x</span><span class="p">٫</span> <span class="s">&#34; -- &#34;</span><span class="p">٫</span> <span class="s">&#34; &#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="nf">str_replace</span><span class="p">(</span><span class="s">&#34;The United States of America&#34;</span><span class="p">٫</span> <span class="s">&#34;USA&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="n">snakecase</span><span class="o">::</span><span class="nf">to_any_case</span><span class="p">()</span>
<span class="p">}</span>

<span class="n">make_ccode</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">){</span>
  <span class="nf">str_extract</span><span class="p">(</span><span class="n">x</span><span class="p">٫</span> <span class="s">&#34;[:upper:]+((?=\\.))&#34;</span><span class="p">)</span>
<span class="p">}</span>

</code></pre></td></tr></table>
</div>
</div>

<p>First we&rsquo;re going to make a little tibble of country codes٫ names٫ and associated file paths.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">filenames</span> <span class="o">&lt;-</span> <span class="nf">dir</span><span class="p">(</span><span class="n">path</span> <span class="o">=</span> <span class="nf">here</span><span class="p">(</span><span class="n">path</span><span class="p">)٫</span>
                 <span class="n">pattern</span> <span class="o">=</span> <span class="s">&#34;*.txt&#34;</span><span class="p">٫</span>
                 <span class="n">full.names</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>

<span class="n">countries</span> <span class="o">&lt;-</span> <span class="nf">tibble</span><span class="p">(</span><span class="n">country</span> <span class="o">=</span> <span class="nf">map_chr</span><span class="p">(</span><span class="n">filenames</span><span class="p">٫</span> <span class="n">get_country_name</span><span class="p">)٫</span>
                    <span class="n">cname</span> <span class="o">=</span> <span class="nf">map_chr</span><span class="p">(</span><span class="n">country</span><span class="p">٫</span> <span class="n">shorten_name</span><span class="p">)٫</span>
                    <span class="n">ccode</span> <span class="o">=</span> <span class="nf">map_chr</span><span class="p">(</span><span class="n">filenames</span><span class="p">٫</span> <span class="n">make_ccode</span><span class="p">)٫</span>
                    <span class="n">path</span> <span class="o">=</span> <span class="n">filenames</span><span class="p">)</span>

<span class="n">countries</span>

<span class="c1"># A tibble: 49 x 4</span>
   <span class="n">country</span>    <span class="n">cname</span>     <span class="n">ccode</span> <span class="n">path</span>                                    
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>      <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>     <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>                                   
 <span class="m">1</span> <span class="n">Australia</span>  <span class="n">australia</span> <span class="n">AUS</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>…
 <span class="m">2</span> <span class="n">Austria</span>    <span class="n">austria</span>   <span class="n">AUT</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>…
 <span class="m">3</span> <span class="n">Belgium</span>    <span class="n">belgium</span>   <span class="n">BEL</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>…
 <span class="m">4</span> <span class="n">Bulgaria</span>   <span class="n">bulgaria</span>  <span class="n">BGR</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>…
 <span class="m">5</span> <span class="n">Belarus</span>    <span class="n">belarus</span>   <span class="n">BLR</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>…
 <span class="m">6</span> <span class="n">Canada</span>     <span class="n">canada</span>    <span class="n">CAN</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>…
 <span class="m">7</span> <span class="n">Switzerla</span>… <span class="n">switzerl</span>… <span class="n">CHE</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>…
 <span class="m">8</span> <span class="n">Chile</span>      <span class="n">chile</span>     <span class="n">CHL</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>…
 <span class="m">9</span> <span class="n">Czechia</span>    <span class="n">czechia</span>   <span class="n">CZE</span>   <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>…
<span class="m">10</span> <span class="n">East</span> <span class="n">Germ</span>… <span class="n">east_ger</span>… <span class="n">DEUTE</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">kjhealy</span><span class="o">/</span><span class="n">Documents</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">misc</span><span class="o">/</span><span class="n">lexi</span>…
<span class="c1"># … with 39 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Next we ingest the data as a nested column٫ clean it a little٫ and subset it to those countries that we actually have mortality data for from the relevant time period.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">mortality</span> <span class="o">&lt;-</span> <span class="n">countries</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span><span class="n">path</span><span class="p">٫</span>
                    <span class="o">~</span> <span class="nf">read_table</span><span class="p">(</span><span class="n">.٫</span> <span class="n">skip</span> <span class="o">=</span> <span class="m">2</span><span class="p">٫</span> <span class="n">na</span> <span class="o">=</span> <span class="s">&#34;.&#34;</span><span class="p">)))</span> <span class="o">%&gt;%</span>
  <span class="nf">unnest</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">age</span> <span class="o">=</span> <span class="nf">as.integer</span><span class="p">(</span><span class="nf">recode</span><span class="p">(</span><span class="n">age</span><span class="p">٫</span> <span class="s">&#34;110+&#34;</span> <span class="o">=</span> <span class="s">&#34;110&#34;</span><span class="p">)))</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">path</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">nest</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">year</span><span class="o">:</span><span class="n">total</span><span class="p">))</span>

<span class="c1">## Subset to flu years / countries</span>
<span class="n">flu</span> <span class="o">&lt;-</span> <span class="n">mortality</span> <span class="o">%&gt;%</span> 
  <span class="nf">unnest</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">country</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="nf">min</span><span class="p">(</span><span class="n">year</span><span class="p">)</span> <span class="o">&lt;</span> <span class="m">1918</span><span class="p">)</span>

<span class="n">flu</span>

<span class="c1"># A tibble: 298٫923 x 8</span>
<span class="c1"># Groups:   country [14]</span>
   <span class="n">country</span> <span class="n">cname</span>   <span class="n">ccode</span>  <span class="n">year</span>   <span class="n">age</span>  <span class="n">female</span>    <span class="n">male</span>   <span class="n">total</span>
   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">chr</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">int</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>   <span class="o">&lt;</span><span class="n">dbl</span><span class="o">&gt;</span>
 <span class="m">1</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">0</span> <span class="m">0.152</span>   <span class="m">0.187</span>   <span class="m">0.169</span>  
 <span class="m">2</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">1</span> <span class="m">0.0749</span>  <span class="m">0.0741</span>  <span class="m">0.0745</span> 
 <span class="m">3</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">2</span> <span class="m">0.0417</span>  <span class="m">0.0398</span>  <span class="m">0.0408</span> 
 <span class="m">4</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">3</span> <span class="m">0.0255</span>  <span class="m">0.0233</span>  <span class="m">0.0244</span> 
 <span class="m">5</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">4</span> <span class="m">0.0185</span>  <span class="m">0.0171</span>  <span class="m">0.0178</span> 
 <span class="m">6</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">5</span> <span class="m">0.0139</span>  <span class="m">0.0124</span>  <span class="m">0.0132</span> 
 <span class="m">7</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">6</span> <span class="m">0.0128</span>  <span class="m">0.0102</span>  <span class="m">0.0115</span> 
 <span class="m">8</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">7</span> <span class="m">0.0109</span>  <span class="m">0.00800</span> <span class="m">0.00944</span>
 <span class="m">9</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">8</span> <span class="m">0.00881</span> <span class="m">0.00701</span> <span class="m">0.00789</span>
<span class="m">10</span> <span class="n">Belgium</span> <span class="n">belgium</span> <span class="n">BEL</span>    <span class="m">1841</span>     <span class="m">9</span> <span class="m">0.00814</span> <span class="m">0.00696</span> <span class="m">0.00754</span>
<span class="c1"># … with 298٫913 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>For the purposes of labeling an upcoming plot٫ we&rsquo;re going to make a little dummy dataset.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">dat_text</span> <span class="o">&lt;-</span> <span class="nf">data.frame</span><span class="p">(</span>
  <span class="n">label</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;1918&#34;</span><span class="p">٫</span> <span class="nf">rep</span><span class="p">(</span><span class="kc">NA</span><span class="p">٫</span> <span class="m">5</span><span class="p">))٫</span>
  <span class="n">agegrp</span> <span class="o">=</span> <span class="nf">factor</span><span class="p">(</span><span class="nf">paste</span><span class="p">(</span><span class="s">&#34;Age&#34;</span><span class="p">٫</span> <span class="nf">seq</span><span class="p">(</span><span class="m">10</span><span class="p">٫</span> <span class="m">60</span><span class="p">٫</span> <span class="m">10</span><span class="p">)))٫</span>
  <span class="n">year</span>     <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">1920</span><span class="p">٫</span> <span class="nf">rep</span><span class="p">(</span><span class="kc">NA</span><span class="p">٫</span> <span class="m">5</span><span class="p">))٫</span>
  <span class="n">female</span>     <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">0.04</span><span class="p">٫</span> <span class="nf">rep</span><span class="p">(</span><span class="kc">NA</span><span class="p">٫</span> <span class="m">5</span><span class="p">))٫</span> 
  <span class="n">flag</span> <span class="o">=</span> <span class="nf">rep</span><span class="p">(</span><span class="kc">NA</span><span class="p">٫</span> <span class="m">6</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">dat_text</span>

<span class="n">label</span> <span class="n">agegrp</span> <span class="n">year</span> <span class="n">female</span> <span class="n">flag</span>
<span class="m">1</span>  <span class="m">1918</span> <span class="n">Age</span> <span class="m">10</span> <span class="m">1920</span>   <span class="m">0.04</span>   <span class="kc">NA</span>
<span class="m">2</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> <span class="n">Age</span> <span class="m">20</span>   <span class="kc">NA</span>     <span class="kc">NA</span>   <span class="kc">NA</span>
<span class="m">3</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> <span class="n">Age</span> <span class="m">30</span>   <span class="kc">NA</span>     <span class="kc">NA</span>   <span class="kc">NA</span>
<span class="m">4</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> <span class="n">Age</span> <span class="m">40</span>   <span class="kc">NA</span>     <span class="kc">NA</span>   <span class="kc">NA</span>
<span class="m">5</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> <span class="n">Age</span> <span class="m">50</span>   <span class="kc">NA</span>     <span class="kc">NA</span>   <span class="kc">NA</span>
<span class="m">6</span>  <span class="o">&lt;</span><span class="kc">NA</span><span class="o">&gt;</span> <span class="n">Age</span> <span class="m">60</span>   <span class="kc">NA</span>     <span class="kc">NA</span>   <span class="kc">NA</span>


</code></pre></td></tr></table>
</div>
</div>

<p>And now we filter the data to look only at female mortality between 1900 and 1929 for a series of specific ages: every decade from 10 years old to 60 years old. We&rsquo;ll use that dummy dataset to label the first (but only the first) panel in the faceted plot we&rsquo;re going to draw.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">p0</span> <span class="o">&lt;-</span> <span class="n">flu</span> <span class="o">%&gt;%</span>
  <span class="nf">group_by</span><span class="p">(</span><span class="n">country</span><span class="p">٫</span> <span class="n">year</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">filter</span><span class="p">(</span><span class="n">year</span> <span class="o">&gt;</span> <span class="m">1899</span> <span class="o">&amp;</span> <span class="n">year</span> <span class="o">&lt;</span> <span class="m">1930</span><span class="p">٫</span> <span class="n">age</span> <span class="o">%in%</span> <span class="nf">seq</span><span class="p">(</span><span class="m">10</span><span class="p">٫</span> <span class="m">60</span><span class="p">٫</span> <span class="n">by</span> <span class="o">=</span> <span class="m">10</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">flag</span> <span class="o">=</span> <span class="n">country</span> <span class="o">%in%</span> <span class="s">&#34;Spain&#34;</span><span class="p">٫</span> 
         <span class="n">agegrp</span> <span class="o">=</span> <span class="nf">paste</span><span class="p">(</span><span class="s">&#34;Age&#34;</span><span class="p">٫</span> <span class="n">age</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">ggplot</span><span class="p">(</span><span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">year</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="n">female</span><span class="p">٫</span> <span class="n">color</span> <span class="o">=</span> <span class="n">flag</span><span class="p">))</span> <span class="o">+</span> 
  <span class="nf">geom_vline</span><span class="p">(</span><span class="n">xintercept</span> <span class="o">=</span> <span class="m">1918</span><span class="p">٫</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;gray80&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">geom_line</span><span class="p">(</span><span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">group</span> <span class="o">=</span> <span class="n">country</span><span class="p">))</span> 

<span class="n">p1</span> <span class="o">&lt;-</span> <span class="n">p0</span> <span class="o">+</span>  <span class="nf">geom_text</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">dat_text</span><span class="p">٫</span> 
                <span class="n">mapping</span> <span class="o">=</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">year</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="n">female</span><span class="p">٫</span> <span class="n">label</span> <span class="o">=</span> <span class="n">label</span><span class="p">)٫</span> 
                <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;black&#34;</span><span class="p">٫</span> 
                <span class="n">show.legend</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">٫</span> 
                <span class="n">group</span> <span class="o">=</span> <span class="m">1</span><span class="p">٫</span> 
                <span class="n">size</span> <span class="o">=</span> <span class="m">3</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="n">my_colors</span><span class="p">٫</span> 
                     <span class="n">labels</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;Other Countries&#34;</span><span class="p">٫</span> <span class="s">&#34;Spain&#34;</span><span class="p">))</span> <span class="o">+</span> 
  <span class="nf">scale_y_continuous</span><span class="p">(</span><span class="n">labels</span> <span class="o">=</span> <span class="n">scales</span><span class="o">::</span><span class="n">percent</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">labs</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s">&#34;Female Mortality٫ Selected Ages and Countries 1900-1929&#34;</span><span class="p">٫</span> 
       <span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Year&#34;</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="s">&#34;Female Mortality Rate&#34;</span><span class="p">٫</span> <span class="n">color</span> <span class="o">=</span> <span class="kc">NULL</span><span class="p">٫</span>
       <span class="n">caption</span> <span class="o">=</span> <span class="s">&#34;@kjhealy / Data: mortality.org&#34;</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">facet_wrap</span><span class="p">(</span><span class="o">~</span> <span class="n">agegrp</span><span class="p">٫</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span> <span class="o">+</span> 
  <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;top&#34;</span><span class="p">)</span>
  
<span class="n">p1</span>

</code></pre></td></tr></table>
</div>
</div>

<figure>
    <img src="https://kieranhealy.org/files/misc/spanish-flu.png"/> 
</figure>
<p>And thus٫ Spanish Flu. Though it looks like it was no joke to be an older woman in Spain during any part of the early 20th century.</p>
'),('https://kieranhealy.org/blog/archives/2020/02/26/a-new-baby-boom-poster/', 'A New Baby Boom Poster', '1582748242000',  15, '<p>I wanted to work through a few examples of more polished graphics done mostly but perhaps not entirely in R. So٫ I revisited the Baby Boom visualizations I made a while ago and made a new poster with them. This allowed me to play around with a few packages that I either hadn&rsquo;t made use of or that weren&rsquo;t available the first time around. The most notable additions are <a href="https://robjhyndman.com/software/">Rob Hyndman&rsquo;s suite of tidy tools for time series analysis</a> and Thomas Lin Pedersen&rsquo;s packages <a href="https://ggforce.data-imaginist.com">ggforce</a> and <a href="https://patchwork.data-imaginist.com">patchwork</a>. These are all fantastic resources. The time series decomposition was done with the <code>tsibble</code> family of tools. Meanwhile <code>ggforce</code> and <code>patchwork</code> allow for a tremendous degree of flexibility in laying out multiple plots while still being very straightforward to use. Here&rsquo;s a preview of the result:</p>
<figure>
    <img src="https://kieranhealy.org/files/misc/okboomer_composite_poster-300-01.png"
         alt="OK boomer"/> <figcaption>
            <p>OK Boomer</p>
        </figcaption>
</figure>
<p>For now٫ the annotations were done in post-production (as they say in the movie biz) rather than in R٫ but I think I&rsquo;ll be looking to see whether it&rsquo;s worth taking advantage of some other packages to do those in R as well.</p>
<p>The time series decomposition takes the births series and separates it into trend٫ seasonal٫ and remainder components. (It&rsquo;s an STL decomposition; there are a bunch of other alternatives.) Often٫ the seasonal and remainder components will end up on quite different scales from the trend. The default plotting methods for decompositions will often show variably-sized vertical bars to the left of each panel٫ to remind the viewer that the scales are different. But <code>ggforce</code> has a <code>facet_col()</code> function that allows the space taken up by a facet to vary in the same way that one can allow the scales on an ordinary facet&rsquo;s axes to vary. Usually٫ variable scaling isn&rsquo;t desirable in a small-multiple٫ because the point is to make comparisons across panels. But in this case the combination of free scales and free spacing is very helpful.</p>
<p>Here&rsquo;s the snippet of code that makes the time series line graphs:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">p_trends</span> <span class="o">&lt;-</span> <span class="nf">ggplot</span><span class="p">(</span><span class="n">data_lon</span><span class="p">٫</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">date</span><span class="p">٫</span> <span class="n">y</span> <span class="o">=</span> <span class="n">value</span><span class="p">))</span> <span class="o">+</span> 
    <span class="nf">geom_line</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="s">&#34;gray20&#34;</span><span class="p">)</span> <span class="o">+</span> 
    <span class="nf">scale_x_date</span><span class="p">(</span><span class="n">breaks</span> <span class="o">=</span> <span class="n">break_vec</span><span class="p">٫</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">break_labs</span><span class="p">٫</span> <span class="n">expand</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">٫</span><span class="m">0</span><span class="p">))</span> <span class="o">+</span> 
    <span class="nf">facet_col</span><span class="p">(</span><span class="o">~</span> <span class="n">name</span><span class="p">٫</span> <span class="n">space</span> <span class="o">=</span> <span class="s">&#34;free&#34;</span><span class="p">٫</span> <span class="n">scales</span> <span class="o">=</span> <span class="s">&#34;free_y&#34;</span><span class="p">)</span> <span class="o">+</span> 
    <span class="nf">theme</span><span class="p">(</span>  <span class="n">strip.background</span> <span class="o">=</span> <span class="nf">element_blank</span><span class="p">()٫</span>
            <span class="n">strip.text.x</span> <span class="o">=</span> <span class="nf">element_blank</span><span class="p">())</span> <span class="o">+</span> 
    <span class="nf">labs</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="kc">NULL</span><span class="p">٫</span> <span class="n">x</span> <span class="o">=</span> <span class="s">&#34;Year&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div>

<p>Meanwhile combining the trends plot with the tiled heatmap (called <code>p_tile</code>) is a piece of cake with <code>patchwork</code>:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="p">(</span><span class="n">p_tile</span> <span class="o">/</span> <span class="n">p_trends</span><span class="p">)</span> <span class="o">+</span> <span class="nf">plot_layout</span><span class="p">(</span><span class="n">heights</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">30</span><span class="p">٫</span> <span class="m">70</span><span class="p">))</span> 
</code></pre></td></tr></table>
</div>
</div>

<p>The <code>/</code> convention means stack the plot objects٫ and <code>plot_layout()</code> proportionally divides the available space.</p>
<p>Chances are that I&rsquo;ll make some posters of these and other recent visualizations. Because people often ask٫ I&rsquo;ve been looking into options for making them available for sale in various formats &hellip; hopefully that&rsquo;ll be sorted out soon and I can join e.g. <em>Waterlilies</em>٫ <em>The Kiss</em>٫ and John Belushi on dorm room walls everywhere.</p>
<p>The code for the decomposition and the core plots is <a href="https://github.com/kjhealy/us_births">on GitHub</a>.</p>
'),('https://kieranhealy.org/blog/archives/2020/02/18/dataviz-workshop-at-rstudioconf/', 'Dataviz Workshop at RStudio::conf', '1582046991000',  15, '<blockquote>
<p>Workshop materials are available here:  <a href="https://rstd.io/conf20-dataviz">https://rstd.io/conf20-dataviz</a> <br>
Consider buying the book; it&rsquo;s good: <a href="http://socviz.co">Data Visualization: A Practical Introduction</a> / <a href="https://www.amazon.com/Data-Visualization-Introduction-Kieran-Healy/dp/0691181624">Buy on Amazon</a></p>
</blockquote>
<p>I was delighted to have the opportunity to teach a two-day workshop on Data Visualization using ggplot2 at this year&rsquo;s <a href="https://rstudio.com/conference/">rstudio::conf(2020)</a> in January. It was my first time attending the conference and it was a terrific experience. I particularly appreciated the friendly and constructive atmosphere that RStudio so clearly goes out of its way to encourage and sustain.</p>
<p>The workshop focused on learning how to think about good data visualization in principle٫ and how to do it in practice. After many years of trying and often failing to learn how to make good visualizations myself٫ I became convinced of two things. First٫ there is a real need for an approach that effectively combines the <em>why</em> of visualization with the <em>how</em>. A lot of otherwise excellent introductions to data visualization will teach you why some visualizations work better than others٫ and will present a series of mouth-watering examples of fabulous graphics. Then you sit down in front of an empty <code>.Rmarkdown</code> file and &hellip; now what? How do I <em>do</em> that?</p>
<p>Meanwhile٫ many very good٫ detailed introductions to writing ggplot2 code may be a little out of reach for beginners or&mdash;perhaps more often&mdash;will tend to get picked up by users in a recipe-like or piecemeal way. People cast around to find out how to more or less solve a particular problem they are having. But they leave without really having a good grasp on why the code they are using looks the way it does. The result is that even people who are pretty used to working in R and who regularly make graphs from data end up with a hazy idea of what they&rsquo;re doing when they use ggplot.</p>
<p>The second thing I became convinced of as I developed this material was that data visualization is a <em>fantastic</em> way to introduce people to the world of data analysis with R generally. When visualizing data with R and ggplot٫ it&rsquo;s possible to produce satisfying results almost right away. That makes it easier to introduce other tidyverse principles and tools in an organic fashion.</p>
<p>For both of those reasons٫ I ended up <a href="http://socviz.co">writing a book</a> that approached things in just the way I wanted: a practical introduction to data visualization using ggplot2 that kept both the ideas and the code in view٫ and tried to do so in an engaging and approachable way. It was this text that formed the core of the workshop.</p>
<p>While teaching over the two days٫ I was assisted by four TAs:</p>
<ul>
<li><a href="http://www.twitter.com/dataandme/">Mara Averick</a></li>
<li><a href="https://www.twitter.com/paleolimbot/">Dewey Dunnington</a></li>
<li><a href="https://www.twitter.com/ariespirgel/">Ari Spirgel</a></li>
<li><a href="https://www.twitter.com/thomasp85">Thomas Lin Pedersen</a></li>
</ul>
<p>When I saw the roster٫ my first reaction was that mine was the only name I didn&rsquo;t recognize. Having Thomas as a TA٫ in particular٫ did rather threaten to cross the line from the merely embarrassing to the faintly absurd. It was a real treat to meet and work with everyone for the first time.</p>
<p>The materials from the workshop are available at the <a href="https://rstd.io/conf20-dataviz">GitHub repository for the course</a>. The repo contains all the code we went through as well as PDFs of all of the slides. The code and the slides also include additional examples and other extensions that we did not have time to cover in over the two days٫ or that I just mentioned in passing.</p>
<p>One of the benefits of teaching a short course like this is that I get a (sometimes sharp!) reminder of what works best and what needs tweaking across the various topics covered. Revisiting the code٫ in particular٫ is always necessary just because the best way to do something will change over time. For example٫ a few of the small tricks and workarounds that I show for dealing with boxplots will shortly become unneccessary٫ thanks to the work of Thomas٫ Dewey٫ and others on the next version of ggplot. I&rsquo;m looking forward to incorporating those elements and more into the next version of the workshop.</p>
<p>Data visualization is a powerful way to explore your own data and communicate your results to other people. One of the themes of the book٫ and the workshop٫ is that it is in most ways a tool like any other. It won&rsquo;t magically render you immune to error or make it impossible for you to fool others٫ or fool yourself. But once you get a feel for how to work with it٫ it makes your work easier and better in many ways. The great strength of the approach taken by the grammar of graphics in general and ggplot in particular is that it gives people a powerful &ldquo;flow of action&rdquo; to follow. It provides a set of concepts&mdash;mappings٫ geoms٫ scales٫ facets٫ layers٫ and so on&mdash;that let you look at other people&rsquo;s graphics and really see how their component pieces fit together. And it implements those concepts as a series of functions that let you coherently assemble graphics yourself. The goal of the workshop was to bring people to the point where they could comfortably write code that would clearly say what they wanted to see.</p>
'),('https://kieranhealy.org/blog/archives/2019/11/10/cleaning-the-table/', 'Cleaning the Table', '1573405973000',  15, '<p>While I&rsquo;m talking about <a href="https://kieranhealy.org/blog/archives/2019/11/09/reading-in-data/">getting data into R</a> this weekend٫ here&rsquo;s another quick example that came up in class this week. The mortality data in the <a href="https://kieranhealy.org/blog/archives/2019/11/09/reading-in-data/">previous example</a> were nice and clean coming in the door. That&rsquo;s usually not the case. Data can be and usually is messy in all kinds of ways. One of the most common٫ particularly in the case of summary tables obtained from some source or other٫ is that the values aren&rsquo;t directly usable. The following summary table was copied and pasted into Excel from an external source٫ saved as a CSV file٫ and arrived looking like this:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>

<span class="n">rfm_tbl</span> <span class="o">&lt;-</span> <span class="nf">read_csv</span><span class="p">(</span><span class="s">&#34;data/rfm_table.csv&#34;</span><span class="p">)</span>


<span class="c1">## Parsed with column specification:</span>
<span class="c1">## cols(</span>
<span class="c1">##   SEGMENT = col_character()٫</span>
<span class="c1">##   DESCRIPTION = col_character()٫</span>
<span class="c1">##   R = col_character()٫</span>
<span class="c1">##   F = col_character()٫</span>
<span class="c1">##   M = col_character()</span>
<span class="c1">## )</span>


<span class="n">rfm_tbl</span> 


<span class="c1">## # A tibble: 23 x 5</span>
<span class="c1">##    SEGMENT        DESCRIPTION                             R     F     M    </span>
<span class="c1">##    &lt;chr&gt;          &lt;chr&gt;                                   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;</span>
<span class="c1">##  1 &lt;NA&gt;           &lt;NA&gt;                                    &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; </span>
<span class="c1">##  2 Champions      Bought recently٫ buy often and spend t… 4– 5  4– 5  4– 5 </span>
<span class="c1">##  3 &lt;NA&gt;           &lt;NA&gt;                                    &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; </span>
<span class="c1">##  4 Loyal Custome… Spend good money. Responsive to promot… 2– 5  3– 5  3– 5 </span>
<span class="c1">##  5 &lt;NA&gt;           &lt;NA&gt;                                    &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; </span>
<span class="c1">##  6 Potential Loy… Recent customers٫ spent good amount٫ b… 3– 5  1– 3  1– 3 </span>
<span class="c1">##  7 &lt;NA&gt;           &lt;NA&gt;                                    &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; </span>
<span class="c1">##  8 New Customers  Bought more recently٫ but not often     4– 5  &lt;= 1  &lt;= 1 </span>
<span class="c1">##  9 &lt;NA&gt;           &lt;NA&gt;                                    &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; </span>
<span class="c1">## 10 Promising      Recent shoppers٫ but haven’t spent much 3– 4  &lt;= 1  &lt;= 1 </span>
<span class="c1">## # … with 13 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>This is messy and we can&rsquo;t do anything with the values in <code>R</code>٫ <code>F</code>٫ and <code>M</code>. Ultimately we want a table with separate columns containing the low and high values for these variables. If no lower bound is shown٫ the lower bound is zero. We&rsquo;re going to use a few tools٫ notably <code>separate()</code> to get where we want to be. I&rsquo;ll step through this pipeline one piece at a time٫ so you can see how the table is being changed from start to finish.</p>
<p>First let&rsquo;s clean clean the variable names and remove the entirely blank lines.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">rfm_tbl</span> <span class="o">%&gt;%</span> 
  <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">filter_all</span><span class="p">(</span><span class="nf">any_vars</span><span class="p">(</span><span class="o">!</span><span class="nf">is.na</span><span class="p">(</span><span class="n">.)</span><span class="p">))</span> 


<span class="c1">## # A tibble: 11 x 5</span>
<span class="c1">##    segment        description                             r     f     m    </span>
<span class="c1">##    &lt;chr&gt;          &lt;chr&gt;                                   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;</span>
<span class="c1">##  1 Champions      Bought recently٫ buy often and spend t… 4– 5  4– 5  4– 5 </span>
<span class="c1">##  2 Loyal Custome… Spend good money. Responsive to promot… 2– 5  3– 5  3– 5 </span>
<span class="c1">##  3 Potential Loy… Recent customers٫ spent good amount٫ b… 3– 5  1– 3  1– 3 </span>
<span class="c1">##  4 New Customers  Bought more recently٫ but not often     4– 5  &lt;= 1  &lt;= 1 </span>
<span class="c1">##  5 Promising      Recent shoppers٫ but haven’t spent much 3– 4  &lt;= 1  &lt;= 1 </span>
<span class="c1">##  6 Need Attention Above average recency٫ frequency &amp; mon… 2– 3  2– 3  2– 3 </span>
<span class="c1">##  7 About To Sleep Below average recency٫ frequency &amp; mon… 2– 3  &lt;= 2  &lt;= 2 </span>
<span class="c1">##  8 At Risk        Spent big money٫ purchased often but l… &lt;= 2  2– 5  2– 5 </span>
<span class="c1">##  9 Can’t Lose Th… Made big purchases and often٫ but long… &lt;= 1  4– 5  4– 5 </span>
<span class="c1">## 10 Hibernating    Low spenders٫ low frequency٫ purchased… 1– 2  1– 2  1– 2 </span>
<span class="c1">## 11 Lost           Lowest recency٫ frequency &amp; monetary s… &lt;= 2  &lt;= 2  &lt;= 2</span>
</code></pre></td></tr></table>
</div>
</div>

<p>Next we start work on the values. I thought about different ways of doing this٫ notably working out a way to apply or map <code>separate()</code> to each of the columns I want to change. I got slightly bogged down doing this٫ and instead decided to lengthen the <code>r</code>٫ <code>f</code>٫ and <code>m</code> variables into a single key-value pair٫ do the recoding there٫ and then widen the result again. First٫ lengthen the data:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">rfm_tbl</span> <span class="o">%&gt;%</span> 
  <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">filter_all</span><span class="p">(</span><span class="nf">any_vars</span><span class="p">(</span><span class="o">!</span><span class="nf">is.na</span><span class="p">(</span><span class="n">.)</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_longer</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="n">r</span><span class="o">:</span><span class="n">m</span><span class="p">)</span>


<span class="c1">## # A tibble: 33 x 4</span>
<span class="c1">##    segment         description                                  name  value</span>
<span class="c1">##    &lt;chr&gt;           &lt;chr&gt;                                        &lt;chr&gt; &lt;chr&gt;</span>
<span class="c1">##  1 Champions       Bought recently٫ buy often and spend the mo… r     4– 5 </span>
<span class="c1">##  2 Champions       Bought recently٫ buy often and spend the mo… f     4– 5 </span>
<span class="c1">##  3 Champions       Bought recently٫ buy often and spend the mo… m     4– 5 </span>
<span class="c1">##  4 Loyal Customers Spend good money. Responsive to promotions   r     2– 5 </span>
<span class="c1">##  5 Loyal Customers Spend good money. Responsive to promotions   f     3– 5 </span>
<span class="c1">##  6 Loyal Customers Spend good money. Responsive to promotions   m     3– 5 </span>
<span class="c1">##  7 Potential Loya… Recent customers٫ spent good amount٫ bought… r     3– 5 </span>
<span class="c1">##  8 Potential Loya… Recent customers٫ spent good amount٫ bought… f     1– 3 </span>
<span class="c1">##  9 Potential Loya… Recent customers٫ spent good amount٫ bought… m     1– 3 </span>
<span class="c1">## 10 New Customers   Bought more recently٫ but not often          r     4– 5 </span>
<span class="c1">## # … with 23 more rows</span>
</code></pre></td></tr></table>
</div>
</div>

<p>I&rsquo;m quite sure that there&rsquo;s an elegant way to use one of the <code>map()</code> functions to process the <code>r</code>٫ <code>f</code>٫ and <code>m</code> columns in sequence. But seeing as I couldn&rsquo;t quickly figure it out٫ this alternative strategy works just fine. In fact٫ as a general approach I think it&rsquo;s always worth remembering that the tidyverse really &ldquo;wants&rdquo; your data to be in long form٫ and lots of things that are awkward or conceptually tricky can suddenly become <em>much</em> easier if you get the data into the shape that the function toolbox wants it to be in. Lengthening the data you&rsquo;re working with is very often the right approach٫ and you know you can widen it later on once you&rsquo;re done cleaning or otherwise manipulating it.</p>
<p>With our table in long format we can now use <code>separate()</code> on the value column. The <code>separate()</code> function is very handy for pulling apart variables that should be in different columns. Its defaults are good٫ too. In this case I didn&rsquo;t have to write a regular expression to specify the characters that are dividing up the values. In the function call we use <code>convert = TRUE</code> to turn the results into integers٫ and <code>fill = &quot;left&quot;</code> because there&rsquo;s an implicit zero on the left of each entry that looks like e.g. <code>&lt;= 2</code>.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">rfm_tbl</span> <span class="o">%&gt;%</span> 
  <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">filter_all</span><span class="p">(</span><span class="nf">any_vars</span><span class="p">(</span><span class="o">!</span><span class="nf">is.na</span><span class="p">(</span><span class="n">.)</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_longer</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="n">r</span><span class="o">:</span><span class="n">m</span><span class="p">)</span> <span class="o">%&gt;%</span> 
  <span class="nf">separate</span><span class="p">(</span><span class="n">col</span> <span class="o">=</span> <span class="n">value</span><span class="p">٫</span> <span class="n">into</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;lo&#34;</span><span class="p">٫</span> <span class="s">&#34;hi&#34;</span><span class="p">)٫</span> 
           <span class="n">remove</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">٫</span> <span class="n">convert</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">٫</span> 
           <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;left&#34;</span><span class="p">)</span> 


<span class="c1">## # A tibble: 33 x 6</span>
<span class="c1">##    segment       description                        name  value    lo    hi</span>
<span class="c1">##    &lt;chr&gt;         &lt;chr&gt;                              &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt;</span>
<span class="c1">##  1 Champions     Bought recently٫ buy often and sp… r     4– 5      4     5</span>
<span class="c1">##  2 Champions     Bought recently٫ buy often and sp… f     4– 5      4     5</span>
<span class="c1">##  3 Champions     Bought recently٫ buy often and sp… m     4– 5      4     5</span>
<span class="c1">##  4 Loyal Custom… Spend good money. Responsive to p… r     2– 5      2     5</span>
<span class="c1">##  5 Loyal Custom… Spend good money. Responsive to p… f     3– 5      3     5</span>
<span class="c1">##  6 Loyal Custom… Spend good money. Responsive to p… m     3– 5      3     5</span>
<span class="c1">##  7 Potential Lo… Recent customers٫ spent good amou… r     3– 5      3     5</span>
<span class="c1">##  8 Potential Lo… Recent customers٫ spent good amou… f     1– 3      1     3</span>
<span class="c1">##  9 Potential Lo… Recent customers٫ spent good amou… m     1– 3      1     3</span>
<span class="c1">## 10 New Customers Bought more recently٫ but not oft… r     4– 5      4     5</span>
<span class="c1">## # … with 23 more rows</span>
</code></pre></td></tr></table>
</div>
</div>

<p>Before widening the data again we drop the <code>value</code> column. We don&rsquo;t need it anymore. (It will mess up the widening if we keep it٫ too: try it and see what happens.)</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">rfm_tbl</span> <span class="o">%&gt;%</span> 
  <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">filter_all</span><span class="p">(</span><span class="nf">any_vars</span><span class="p">(</span><span class="o">!</span><span class="nf">is.na</span><span class="p">(</span><span class="n">.)</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_longer</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="n">r</span><span class="o">:</span><span class="n">m</span><span class="p">)</span> <span class="o">%&gt;%</span> 
  <span class="nf">separate</span><span class="p">(</span><span class="n">col</span> <span class="o">=</span> <span class="n">value</span><span class="p">٫</span> <span class="n">into</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;lo&#34;</span><span class="p">٫</span> <span class="s">&#34;hi&#34;</span><span class="p">)٫</span> 
           <span class="n">remove</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">٫</span> <span class="n">convert</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">٫</span> 
           <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;left&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">value</span><span class="p">)</span> 


<span class="c1">## # A tibble: 33 x 5</span>
<span class="c1">##    segment        description                             name     lo    hi</span>
<span class="c1">##    &lt;chr&gt;          &lt;chr&gt;                                   &lt;chr&gt; &lt;int&gt; &lt;int&gt;</span>
<span class="c1">##  1 Champions      Bought recently٫ buy often and spend t… r         4     5</span>
<span class="c1">##  2 Champions      Bought recently٫ buy often and spend t… f         4     5</span>
<span class="c1">##  3 Champions      Bought recently٫ buy often and spend t… m         4     5</span>
<span class="c1">##  4 Loyal Custome… Spend good money. Responsive to promot… r         2     5</span>
<span class="c1">##  5 Loyal Custome… Spend good money. Responsive to promot… f         3     5</span>
<span class="c1">##  6 Loyal Custome… Spend good money. Responsive to promot… m         3     5</span>
<span class="c1">##  7 Potential Loy… Recent customers٫ spent good amount٫ b… r         3     5</span>
<span class="c1">##  8 Potential Loy… Recent customers٫ spent good amount٫ b… f         1     3</span>
<span class="c1">##  9 Potential Loy… Recent customers٫ spent good amount٫ b… m         1     3</span>
<span class="c1">## 10 New Customers  Bought more recently٫ but not often     r         4     5</span>
<span class="c1">## # … with 23 more rows</span>
</code></pre></td></tr></table>
</div>
</div>

<p>Now we can widen the data٫ with <code>pivot_wider()</code>.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">rfm_tbl</span> <span class="o">%&gt;%</span> 
  <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">filter_all</span><span class="p">(</span><span class="nf">any_vars</span><span class="p">(</span><span class="o">!</span><span class="nf">is.na</span><span class="p">(</span><span class="n">.)</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_longer</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="n">r</span><span class="o">:</span><span class="n">m</span><span class="p">)</span> <span class="o">%&gt;%</span> 
  <span class="nf">separate</span><span class="p">(</span><span class="n">col</span> <span class="o">=</span> <span class="n">value</span><span class="p">٫</span> <span class="n">into</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;lo&#34;</span><span class="p">٫</span> <span class="s">&#34;hi&#34;</span><span class="p">)٫</span> 
           <span class="n">remove</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">٫</span> <span class="n">convert</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">٫</span> 
           <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;left&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">value</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_wider</span><span class="p">(</span><span class="n">names_from</span> <span class="o">=</span> <span class="n">name</span><span class="p">٫</span> 
              <span class="n">values_from</span> <span class="o">=</span> <span class="n">lo</span><span class="o">:</span><span class="n">hi</span><span class="p">)</span> 


<span class="c1">## # A tibble: 11 x 8</span>
<span class="c1">##    segment     description               lo_r  lo_f  lo_m  hi_r  hi_f  hi_m</span>
<span class="c1">##    &lt;chr&gt;       &lt;chr&gt;                    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;</span>
<span class="c1">##  1 Champions   Bought recently٫ buy of…     4     4     4     5     5     5</span>
<span class="c1">##  2 Loyal Cust… Spend good money. Respo…     2     3     3     5     5     5</span>
<span class="c1">##  3 Potential … Recent customers٫ spent…     3     1     1     5     3     3</span>
<span class="c1">##  4 New Custom… Bought more recently٫ b…     4    NA    NA     5     1     1</span>
<span class="c1">##  5 Promising   Recent shoppers٫ but ha…     3    NA    NA     4     1     1</span>
<span class="c1">##  6 Need Atten… Above average recency٫ …     2     2     2     3     3     3</span>
<span class="c1">##  7 About To S… Below average recency٫ …     2    NA    NA     3     2     2</span>
<span class="c1">##  8 At Risk     Spent big money٫ purcha…    NA     2     2     2     5     5</span>
<span class="c1">##  9 Can’t Lose… Made big purchases and …    NA     4     4     1     5     5</span>
<span class="c1">## 10 Hibernating Low spenders٫ low frequ…     1     1     1     2     2     2</span>
<span class="c1">## 11 Lost        Lowest recency٫ frequen…    NA    NA    NA     2     2     2</span>
</code></pre></td></tr></table>
</div>
</div>

<p>Finally we put back those implicit zeros using <code>replace_na()</code> and reorder the columns to our liking. Using <code>replace_na()</code> is fine here because we know that every missing value should in fact be a zero.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">rfm_tbl</span> <span class="o">%&gt;%</span> 
  <span class="n">janitor</span><span class="o">::</span><span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
  <span class="nf">filter_all</span><span class="p">(</span><span class="nf">any_vars</span><span class="p">(</span><span class="o">!</span><span class="nf">is.na</span><span class="p">(</span><span class="n">.)</span><span class="p">))</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_longer</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="n">r</span><span class="o">:</span><span class="n">m</span><span class="p">)</span> <span class="o">%&gt;%</span> 
  <span class="nf">separate</span><span class="p">(</span><span class="n">col</span> <span class="o">=</span> <span class="n">value</span><span class="p">٫</span> <span class="n">into</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;lo&#34;</span><span class="p">٫</span> <span class="s">&#34;hi&#34;</span><span class="p">)٫</span> 
           <span class="n">remove</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">٫</span> <span class="n">convert</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">٫</span> 
           <span class="n">fill</span> <span class="o">=</span> <span class="s">&#34;left&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">value</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">pivot_wider</span><span class="p">(</span><span class="n">names_from</span> <span class="o">=</span> <span class="n">name</span><span class="p">٫</span> 
              <span class="n">values_from</span> <span class="o">=</span> <span class="n">lo</span><span class="o">:</span><span class="n">hi</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate_if</span><span class="p">(</span><span class="n">is.integer</span><span class="p">٫</span> <span class="n">replace_na</span><span class="p">٫</span> <span class="m">0</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">select</span><span class="p">(</span><span class="n">segment</span><span class="p">٫</span> 
         <span class="n">lo_r</span><span class="p">٫</span> <span class="n">hi_r</span><span class="p">٫</span> 
         <span class="n">lo_f</span><span class="p">٫</span> <span class="n">hi_f</span><span class="p">٫</span> 
         <span class="n">lo_m</span><span class="p">٫</span> <span class="n">hi_m</span><span class="p">٫</span> 
         <span class="n">description</span><span class="p">)</span>


<span class="c1">## # A tibble: 11 x 8</span>
<span class="c1">##    segment      lo_r  hi_r  lo_f  hi_f  lo_m  hi_m description             </span>
<span class="c1">##    &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                   </span>
<span class="c1">##  1 Champions       4     5     4     5     4     5 Bought recently٫ buy of…</span>
<span class="c1">##  2 Loyal Cust…     2     5     3     5     3     5 Spend good money. Respo…</span>
<span class="c1">##  3 Potential …     3     5     1     3     1     3 Recent customers٫ spent…</span>
<span class="c1">##  4 New Custom…     4     5     0     1     0     1 Bought more recently٫ b…</span>
<span class="c1">##  5 Promising       3     4     0     1     0     1 Recent shoppers٫ but ha…</span>
<span class="c1">##  6 Need Atten…     2     3     2     3     2     3 Above average recency٫ …</span>
<span class="c1">##  7 About To S…     2     3     0     2     0     2 Below average recency٫ …</span>
<span class="c1">##  8 At Risk         0     2     2     5     2     5 Spent big money٫ purcha…</span>
<span class="c1">##  9 Can’t Lose…     0     1     4     5     4     5 Made big purchases and …</span>
<span class="c1">## 10 Hibernating     1     2     1     2     1     2 Low spenders٫ low frequ…</span>
<span class="c1">## 11 Lost            0     2     0     2     0     2 Lowest recency٫ frequen…</span>
</code></pre></td></tr></table>
</div>
</div>

<p>Much nicer.</p>
'),('https://kieranhealy.org/blog/archives/2019/11/09/reading-in-data/', 'Reading in Data', '1573320912000',  15, '<p>Here&rsquo;s a common situation: you have a folder full of similarly-formatted CSV or otherwise structured text files that you want to get into R quickly and easily. Reading data into R is one of those tasks that can be a real source of frustration for beginners٫ so I like collecting real-life examples of the many ways it&rsquo;s become much easier.</p>
<p>This week in class I was working with country-level historical mortality rate estimates. These are available from <a href="http://mortality.org">mortality.org</a>٫ a fabulous resource. They have a variety of data available but I was interested in the 1x1 year estimates of mortality for all available countries. By &ldquo;1x1&rdquo; I mean that the tables show (for men٫ women٫ and in total) age-specific morality rate estimates for yearly ages from 0 to 110 and above٫ for every available historical year (e.g. from 1850 to 2016 or what have you). So you can have an estimate of the mortality rate for٫ say٫ 28 year olds in France in 1935.</p>
<p>Downloading this data gives me a folder of text files٫ one for each country. (Or rather٫ country-like unit: there are separate series for٫ e.g. East Germany٫ West Germany٫ and Germany as a whole٫ for example٫ along with some countries where sub-populations are broken out historically.) The names of the files are consistently formatted٫ as is the data inside them٫ and they have a <code>.txt</code> extension. What I wanted to do was get each one of these files into R٫ ideally putting them all into a single big table that could be the jumping-off point for subsetting and further analysis.</p>
<p>I know from the documentation provided by <a href="http://mortality.org">mortality.org</a> that the files all have the same basic format٫ which of course makes things much easier. The data is already clean. It&rsquo;s just a matter of loading it all in efficiently٫ or &ldquo;ingesting&rdquo; it٫ to use the charming image that seems to be preferred at present.</p>
<p>Here we go. First٫ some libraries.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="nf">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">janitor</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">here</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div>


<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="c1">## here() starts at /Users/kjhealy/Source/demog</span>
</code></pre></td></tr></table>
</div>
</div>

<p>We get a list of the filenames in our raw data folder٫ along with their full paths. Then we take a look at them.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="n">filenames</span> <span class="o">&lt;-</span> <span class="nf">dir</span><span class="p">(</span><span class="n">path</span> <span class="o">=</span> <span class="nf">here</span><span class="p">(</span><span class="s">&#34;rawdata&#34;</span><span class="p">)٫</span>
                 <span class="n">pattern</span> <span class="o">=</span> <span class="s">&#34;*.txt&#34;</span><span class="p">٫</span>
                 <span class="n">full.names</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>

<span class="n">filenames</span>

<span class="c1">##  [1] &#34;/Users/kjhealy/Source/demog/rawdata/AUS.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [2] &#34;/Users/kjhealy/Source/demog/rawdata/AUT.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [3] &#34;/Users/kjhealy/Source/demog/rawdata/BEL.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [4] &#34;/Users/kjhealy/Source/demog/rawdata/BGR.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [5] &#34;/Users/kjhealy/Source/demog/rawdata/BLR.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [6] &#34;/Users/kjhealy/Source/demog/rawdata/CAN.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [7] &#34;/Users/kjhealy/Source/demog/rawdata/CHE.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [8] &#34;/Users/kjhealy/Source/demog/rawdata/CHL.Mx_1x1.txt&#34;    </span>
<span class="c1">##  [9] &#34;/Users/kjhealy/Source/demog/rawdata/CZE.Mx_1x1.txt&#34;    </span>
<span class="c1">## [10] &#34;/Users/kjhealy/Source/demog/rawdata/DEUTE.Mx_1x1.txt&#34;  </span>
<span class="c1">## [11] &#34;/Users/kjhealy/Source/demog/rawdata/DEUTNP.Mx_1x1.txt&#34; </span>
<span class="c1">## [12] &#34;/Users/kjhealy/Source/demog/rawdata/DEUTW.Mx_1x1.txt&#34;  </span>
<span class="c1">## [13] &#34;/Users/kjhealy/Source/demog/rawdata/DNK.Mx_1x1.txt&#34;    </span>
<span class="c1">## [14] &#34;/Users/kjhealy/Source/demog/rawdata/ESP.Mx_1x1.txt&#34;    </span>
<span class="c1">## [15] &#34;/Users/kjhealy/Source/demog/rawdata/EST.Mx_1x1.txt&#34;    </span>
<span class="c1">## [16] &#34;/Users/kjhealy/Source/demog/rawdata/FIN.Mx_1x1.txt&#34;    </span>
<span class="c1">## [17] &#34;/Users/kjhealy/Source/demog/rawdata/FRACNP.Mx_1x1.txt&#34; </span>
<span class="c1">## [18] &#34;/Users/kjhealy/Source/demog/rawdata/FRATNP.Mx_1x1.txt&#34; </span>
<span class="c1">## [19] &#34;/Users/kjhealy/Source/demog/rawdata/GBR_NIR.Mx_1x1.txt&#34;</span>
<span class="c1">## [20] &#34;/Users/kjhealy/Source/demog/rawdata/GBR_NP.Mx_1x1.txt&#34; </span>
<span class="c1">## [21] &#34;/Users/kjhealy/Source/demog/rawdata/GBR_SCO.Mx_1x1.txt&#34;</span>
<span class="c1">## [22] &#34;/Users/kjhealy/Source/demog/rawdata/GBRCENW.Mx_1x1.txt&#34;</span>
<span class="c1">## [23] &#34;/Users/kjhealy/Source/demog/rawdata/GBRTENW.Mx_1x1.txt&#34;</span>
<span class="c1">## [24] &#34;/Users/kjhealy/Source/demog/rawdata/GRC.Mx_1x1.txt&#34;    </span>
<span class="c1">## [25] &#34;/Users/kjhealy/Source/demog/rawdata/HRV.Mx_1x1.txt&#34;    </span>
<span class="c1">## [26] &#34;/Users/kjhealy/Source/demog/rawdata/HUN.Mx_1x1.txt&#34;    </span>
<span class="c1">## [27] &#34;/Users/kjhealy/Source/demog/rawdata/IRL.Mx_1x1.txt&#34;    </span>
<span class="c1">## [28] &#34;/Users/kjhealy/Source/demog/rawdata/ISL.Mx_1x1.txt&#34;    </span>
<span class="c1">## [29] &#34;/Users/kjhealy/Source/demog/rawdata/ISR.Mx_1x1.txt&#34;    </span>
<span class="c1">## [30] &#34;/Users/kjhealy/Source/demog/rawdata/ITA.Mx_1x1.txt&#34;    </span>
<span class="c1">## [31] &#34;/Users/kjhealy/Source/demog/rawdata/JPN.Mx_1x1.txt&#34;    </span>
<span class="c1">## [32] &#34;/Users/kjhealy/Source/demog/rawdata/KOR.Mx_1x1.txt&#34;    </span>
<span class="c1">## [33] &#34;/Users/kjhealy/Source/demog/rawdata/LTU.Mx_1x1.txt&#34;    </span>
<span class="c1">## [34] &#34;/Users/kjhealy/Source/demog/rawdata/LUX.Mx_1x1.txt&#34;    </span>
<span class="c1">## [35] &#34;/Users/kjhealy/Source/demog/rawdata/LVA.Mx_1x1.txt&#34;    </span>
<span class="c1">## [36] &#34;/Users/kjhealy/Source/demog/rawdata/NLD.Mx_1x1.txt&#34;    </span>
<span class="c1">## [37] &#34;/Users/kjhealy/Source/demog/rawdata/NOR.Mx_1x1.txt&#34;    </span>
<span class="c1">## [38] &#34;/Users/kjhealy/Source/demog/rawdata/NZL_MA.Mx_1x1.txt&#34; </span>
<span class="c1">## [39] &#34;/Users/kjhealy/Source/demog/rawdata/NZL_NM.Mx_1x1.txt&#34; </span>
<span class="c1">## [40] &#34;/Users/kjhealy/Source/demog/rawdata/NZL_NP.Mx_1x1.txt&#34; </span>
<span class="c1">## [41] &#34;/Users/kjhealy/Source/demog/rawdata/POL.Mx_1x1.txt&#34;    </span>
<span class="c1">## [42] &#34;/Users/kjhealy/Source/demog/rawdata/PRT.Mx_1x1.txt&#34;    </span>
<span class="c1">## [43] &#34;/Users/kjhealy/Source/demog/rawdata/RUS.Mx_1x1.txt&#34;    </span>
<span class="c1">## [44] &#34;/Users/kjhealy/Source/demog/rawdata/SVK.Mx_1x1.txt&#34;    </span>
<span class="c1">## [45] &#34;/Users/kjhealy/Source/demog/rawdata/SVN.Mx_1x1.txt&#34;    </span>
<span class="c1">## [46] &#34;/Users/kjhealy/Source/demog/rawdata/SWE.Mx_1x1.txt&#34;    </span>
<span class="c1">## [47] &#34;/Users/kjhealy/Source/demog/rawdata/TWN.Mx_1x1.txt&#34;    </span>
<span class="c1">## [48] &#34;/Users/kjhealy/Source/demog/rawdata/UKR.Mx_1x1.txt&#34;    </span>
<span class="c1">## [49] &#34;/Users/kjhealy/Source/demog/rawdata/USA.Mx_1x1.txt&#34;</span>

</code></pre></td></tr></table>
</div>
</div>

<p>What does each of these files look like? Let&rsquo;s take a look at the first one٫ using <code>read_lines()</code> to show us the top of the file.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">
<span class="nf">read_lines</span><span class="p">(</span><span class="n">filenames[1]</span><span class="p">٫</span> <span class="n">n_max</span> <span class="o">=</span> <span class="m">5</span><span class="p">)</span>

<span class="c1">## [1] &#34;Australia٫ Death rates (period 1x1)٫ \tLast modified: 26 Sep 2017;  Methods Protocol: v6 (2017)&#34;</span>
<span class="c1">## [2] &#34;&#34;                                                                                               </span>
<span class="c1">## [3] &#34;  Year          Age             Female            Male           Total&#34;                         </span>
<span class="c1">## [4] &#34;  1921           0             0.059987        0.076533        0.068444&#34;                        </span>
<span class="c1">## [5] &#34;  1921           1             0.012064        0.014339        0.013225&#34;</span>

</code></pre></td></tr></table>
</div>
</div>

<p>All the files have a header section like this. When we read the data in we&rsquo;ll want to ignore that and go straight to the data. But seeing as it&rsquo;s there٫ we can make use of it to grab the name of the country. It saves us typing it ourselves. Let&rsquo;s say we&rsquo;d also like to have a code-friendly version of those names (i.e.٫ in lower-case with underscores instead of spaces). And finally&mdash;while we&rsquo;re at it&mdash;let&rsquo;s grab those all-caps country codes used in the file names٫ too. We write three functions:</p>
<ul>
<li><code>get_country_name()</code> grabs the first word or words on the first line of each file٫ up to the first comma. That&rsquo;s our country name.</li>
<li><code>shorten_name()</code> makes the names lower-case and replaces spaces with underscores٫ and also shortens &ldquo;The United States of America&rdquo; to &ldquo;USA&rdquo;.</li>
<li><code>make_ccode()</code> wraps a regular expression that finds and extracts the capitalized country codes in the file names.</li>
</ul>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">get_country_name</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">){</span>
    <span class="nf">read_lines</span><span class="p">(</span><span class="n">x</span><span class="p">٫</span> <span class="n">n_max</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span> <span class="o">%&gt;%</span>
        <span class="nf">str_extract</span><span class="p">(</span><span class="s">&#34;.+?٫&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
        <span class="nf">str_remove</span><span class="p">(</span><span class="s">&#34;٫&#34;</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">shorten_name</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">){</span>
    <span class="nf">str_replace_all</span><span class="p">(</span><span class="n">x</span><span class="p">٫</span> <span class="s">&#34; -- &#34;</span><span class="p">٫</span> <span class="s">&#34; &#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
        <span class="nf">str_replace</span><span class="p">(</span><span class="s">&#34;The United States of America&#34;</span><span class="p">٫</span> <span class="s">&#34;USA&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span>
        <span class="n">snakecase</span><span class="o">::</span><span class="nf">to_any_case</span><span class="p">()</span>
<span class="p">}</span>

<span class="n">make_ccode</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">){</span>
    <span class="nf">str_extract</span><span class="p">(</span><span class="n">x</span><span class="p">٫</span> <span class="s">&#34;[:upper:]+((?=\\.))&#34;</span><span class="p">)</span>
<span class="p">}</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Now we create a tibble of summary information by mapping the functions to the filenames.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">countries</span> <span class="o">&lt;-</span> <span class="nf">tibble</span><span class="p">(</span><span class="n">country</span> <span class="o">=</span> <span class="nf">map_chr</span><span class="p">(</span><span class="n">filenames</span><span class="p">٫</span> <span class="n">get_country_name</span><span class="p">)٫</span>
                        <span class="n">cname</span> <span class="o">=</span> <span class="nf">map_chr</span><span class="p">(</span><span class="n">country</span><span class="p">٫</span> <span class="n">shorten_name</span><span class="p">)٫</span>
                        <span class="n">ccode</span> <span class="o">=</span> <span class="nf">map_chr</span><span class="p">(</span><span class="n">filenames</span><span class="p">٫</span> <span class="n">make_ccode</span><span class="p">)٫</span>
                        <span class="n">path</span> <span class="o">=</span> <span class="n">filenames</span><span class="p">)</span>

<span class="n">countries</span>

<span class="c1">## # A tibble: 49 x 4</span>
<span class="c1">##    country     cname       ccode path                                      </span>
<span class="c1">##    &lt;chr&gt;       &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;                                     </span>
<span class="c1">##  1 Australia   australia   AUS   /Users/kjhealy/Source/demog/rawdata/AUS.M…</span>
<span class="c1">##  2 Austria     austria     AUT   /Users/kjhealy/Source/demog/rawdata/AUT.M…</span>
<span class="c1">##  3 Belgium     belgium     BEL   /Users/kjhealy/Source/demog/rawdata/BEL.M…</span>
<span class="c1">##  4 Bulgaria    bulgaria    BGR   /Users/kjhealy/Source/demog/rawdata/BGR.M…</span>
<span class="c1">##  5 Belarus     belarus     BLR   /Users/kjhealy/Source/demog/rawdata/BLR.M…</span>
<span class="c1">##  6 Canada      canada      CAN   /Users/kjhealy/Source/demog/rawdata/CAN.M…</span>
<span class="c1">##  7 Switzerland switzerland CHE   /Users/kjhealy/Source/demog/rawdata/CHE.M…</span>
<span class="c1">##  8 Chile       chile       CHL   /Users/kjhealy/Source/demog/rawdata/CHL.M…</span>
<span class="c1">##  9 Czechia     czechia     CZE   /Users/kjhealy/Source/demog/rawdata/CZE.M…</span>
<span class="c1">## 10 East Germa… east_germa… DEUTE /Users/kjhealy/Source/demog/rawdata/DEUTE…</span>
<span class="c1">## # … with 39 more rows</span>


</code></pre></td></tr></table>
</div>
</div>

<p>Nice. We could have written each of those operations as anonymous functions directly inside of <code>map_chr()</code>. This would have been more compact. But often it can be useful to break out the steps as shown here٫ for clarity&mdash;especially if <code>map()</code> operations have a tendency to break your brain٫ as they do mine.</p>
<p>We still haven&rsquo;t touched the actual data files٫ of course. But now we can just use this <code>countries</code> table as the basis for reading in٫ I mean <em>ingesting</em>٫ everything in the files. We&rsquo;re going to just add a list column named <code>data</code> to the end of the table and put the data for each country in it. We&rsquo;ll temporarily unnest it to clean the column names and recode the <code>age</code> variable٫ then drop the file paths column and nest the data again.</p>
<p>The hard work is done by the <code>map()</code> call. This time we will use <code>~</code> formula notation inside <code>map()</code> to write what we want to do. We&rsquo;re going to feed every filename in <code>path</code> to <code>read_table()</code>٫ one at a time. We tell <code>read_table()</code> to skip the first two lines of every file it reads٫ and also tell it that in these files missing data are represented by a <code>.</code> character. Everything read in ends up in a new list column named <code>data</code>.</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">mortality</span> <span class="o">&lt;-</span> <span class="n">countries</span> <span class="o">%&gt;%</span>
    <span class="nf">mutate</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span><span class="n">path</span><span class="p">٫</span>
                      <span class="o">~</span> <span class="nf">read_table</span><span class="p">(</span><span class="n">.٫</span> <span class="n">skip</span> <span class="o">=</span> <span class="m">2</span><span class="p">٫</span> <span class="n">na</span> <span class="o">=</span> <span class="s">&#34;.&#34;</span><span class="p">)))</span> <span class="o">%&gt;%</span>
    <span class="nf">unnest</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">%&gt;%</span>
    <span class="nf">clean_names</span><span class="p">()</span> <span class="o">%&gt;%</span>
    <span class="nf">mutate</span><span class="p">(</span><span class="n">age</span> <span class="o">=</span> <span class="nf">as.integer</span><span class="p">(</span><span class="nf">recode</span><span class="p">(</span><span class="n">age</span><span class="p">٫</span> <span class="s">&#34;110+&#34;</span> <span class="o">=</span> <span class="s">&#34;110&#34;</span><span class="p">)))</span> <span class="o">%&gt;%</span>
    <span class="nf">select</span><span class="p">(</span><span class="o">-</span><span class="n">path</span><span class="p">)</span> <span class="o">%&gt;%</span>
    <span class="nf">nest</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">year</span><span class="o">:</span><span class="n">total</span><span class="p">))</span>

<span class="n">mortality</span>


<span class="c1">## # A tibble: 49 x 4</span>
<span class="c1">##    country      cname        ccode           data</span>
<span class="c1">##    &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt; &lt;list&lt;df[٫5]&gt;&gt;</span>
<span class="c1">##  1 Australia    australia    AUS     [10٫434 × 5]</span>
<span class="c1">##  2 Austria      austria      AUT      [7٫881 × 5]</span>
<span class="c1">##  3 Belgium      belgium      BEL     [19٫425 × 5]</span>
<span class="c1">##  4 Bulgaria     bulgaria     BGR      [7٫104 × 5]</span>
<span class="c1">##  5 Belarus      belarus      BLR      [6٫438 × 5]</span>
<span class="c1">##  6 Canada       canada       CAN     [10٫101 × 5]</span>
<span class="c1">##  7 Switzerland  switzerland  CHE     [15٫651 × 5]</span>
<span class="c1">##  8 Chile        chile        CHL      [1٫887 × 5]</span>
<span class="c1">##  9 Czechia      czechia      CZE      [7٫437 × 5]</span>
<span class="c1">## 10 East Germany east_germany DEUTE    [6٫660 × 5]</span>
<span class="c1">## # … with 39 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>And we&rsquo;re done. Forty nine tables of data smoothly imported and bundled together. Each of the country-level data tables is a row in <code>data</code> that we can take a look at as we like:</p>

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-r" data-lang="r">

<span class="n">mortality</span> <span class="o">%&gt;%</span> 
  <span class="nf">filter</span><span class="p">(</span><span class="n">country</span> <span class="o">==</span> <span class="s">&#34;Austria&#34;</span><span class="p">)</span> <span class="o">%&gt;%</span> 
  <span class="nf">unnest</span><span class="p">(</span><span class="n">cols</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>


<span class="c1">## # A tibble: 7٫881 x 8</span>
<span class="c1">##    country cname   ccode  year   age   female     male    total</span>
<span class="c1">##    &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;</span>
<span class="c1">##  1 Austria austria AUT    1947     0 0.0798   0.0994   0.0899  </span>
<span class="c1">##  2 Austria austria AUT    1947     1 0.00657  0.00845  0.00753 </span>
<span class="c1">##  3 Austria austria AUT    1947     2 0.00425  0.00469  0.00447 </span>
<span class="c1">##  4 Austria austria AUT    1947     3 0.00337  0.00340  0.00339 </span>
<span class="c1">##  5 Austria austria AUT    1947     4 0.00235  0.00270  0.00253 </span>
<span class="c1">##  6 Austria austria AUT    1947     5 0.00174  0.00195  0.00184 </span>
<span class="c1">##  7 Austria austria AUT    1947     6 0.00131  0.00152  0.00142 </span>
<span class="c1">##  8 Austria austria AUT    1947     7 0.00132  0.00169  0.00151 </span>
<span class="c1">##  9 Austria austria AUT    1947     8 0.00115  0.00149  0.00132 </span>
<span class="c1">## 10 Austria austria AUT    1947     9 0.000836 0.000997 0.000918</span>
<span class="c1">## # … with 7٫871 more rows</span>

</code></pre></td></tr></table>
</div>
</div>

<p>Now you can get on with the actual analysis.</p>
<p>There isn&rsquo;t anything especially unusual in the steps shown here. It&rsquo;s just a pretty common operation that&rsquo;s worth knowing how to do cleanly. One nice thing about this approach is that it&rsquo;s immediately applicable to٫ say٫ a folder containing the 5-year mortality estimates rather than the 1 year estimates. You don&rsquo;t have to do anything new٫ and there&rsquo;s no mucking around with manually naming files and so on.</p>
'),('https://www.youtube.com/watch?v=kNVuTAVYxpM', 'Vendor Locking AMD EPYC CPUs Great for Security at a Cost', '1599614809000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/AgreeableLandscape">AgreeableLandscape</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>4 points | <a href="https://dev.lemmy.ml/post/40229">6 comments</a>'),('https://blog.mozilla.org/blog/2020/09/07/mozilla-ceo-mitchell-baker-urges-european-commission-to-seize-once-in-a-generation-opportunity/', 'Mozilla CEO Mitchell Baker urges European Commission to seize ‘once-in-a-generation’ opportunity – The Mozilla Blog', '1599560219000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/ajz">ajz</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>8 points | <a href="https://dev.lemmy.ml/post/40196">2 comments</a>'),('invalid', 'Anyway to block certain domains/websites from appearing in search results?', '1599587640000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/Stayawesome">Stayawesome</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>3 points | <a href="https://dev.lemmy.ml/post/40218">0 comments</a><p>I have heard of this (one)[https://addons.mozilla.org/en-US/firefox/addon/personal-blocklist/]  but that only applies to google and not other search engines i.e duckduckgo.</p>
'),('https://proarea.co/blog/how-to-design-a-banking-application/', 'How to design a banking application', '1599565799000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/yuliaproarea">yuliaproarea</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>1 points | <a href="https://dev.lemmy.ml/post/40201">0 comments</a><p>If your banking application doesn’t meet the market requirements٫ it will be too difficult to stay on it.</p>
'),('https://www.engadget.com/tiktok-suicide-video-221041082.html', 'TikTok is trying to stop a suicide video from spreading', '1599553372000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/QuentinCallaghan">QuentinCallaghan</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>2 points | <a href="https://dev.lemmy.ml/post/40192">0 comments</a>'),('https://the-evolving-web.blogspot.com/2020/09/the-art-of-finishing-incomplete.html', 'The art of finishing incomplete projects and tasks', '1599550256000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/noble_pleb">noble_pleb</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>2 points | <a href="https://dev.lemmy.ml/post/40191">0 comments</a>'),('https://www.debugpoint.com/2020/09/vivaldi-browser-3-3/', 'Vivaldi Browser 3.3 Brings Break Mode to Pause Internet', '1599560397000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/ajz">ajz</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>0 points | <a href="https://dev.lemmy.ml/post/40198">1 comments</a>'),('https://www.youtube.com/watch?v=DWWU-8_4wu0', 'NEWater: A Singapore Success Story', '1599534030000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/AgreeableLandscape">AgreeableLandscape</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>2 points | <a href="https://dev.lemmy.ml/post/40182">0 comments</a>'),('https://www.youtube.com/watch?v=nS_HgfanRjA', 'A solar water heater and greywater treatment system in one', '1599533948000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/AgreeableLandscape">AgreeableLandscape</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>1 points | <a href="https://dev.lemmy.ml/post/40178">0 comments</a>'),('http://yarh.io/yarh-io-mki.html', '800x480 Touchscreen Raspberry Pi 3B+ Hackable Linux Handheld', '1599509116000',  16, 'submitted by <a href="https://dev.lemmy.ml/u/yogthos">yogthos</a> to <a href="https://dev.lemmy.ml/c/technology">technology</a><br>4 points | <a href="https://dev.lemmy.ml/post/40161">0 comments</a>'),,,('https://www.debugbear.com/blog/front-end-javascript-performance', 'Front-end JavaScript performance', '1599609600000',  24, 'invalid'),('https://www.debugbear.com/blog/is-the-web-getting-slower', 'Is the web getting slower?', '1598227200000',  24, 'invalid'),('https://www.debugbear.com/blog/gpt-3-on-web-performance', 'GPT-3 on web performance', '1596153600000',  24, 'invalid'),('https://www.debugbear.com/blog/improve-server-response-time', 'How to improve server response time (TTFB)?', '1594166400000',  24, 'invalid'),('https://www.debugbear.com/blog/counting-chrome-extensions', 'Counting Chrome Extensions – Statistics on the Chrome Web Store', '1593475200000',  24, 'invalid'),('https://www.debugbear.com/blog/2020-chrome-extension-performance-report', '2020 Chrome Extension Performance Report', '1592179200000',  24, 'invalid'),('https://www.debugbear.com/blog/save-data-adoption', 'How many websites support the Save-Data header?', '1583712000000',  24, 'invalid'),('https://www.debugbear.com/blog/performant-front-end-architecture', 'Performant front-end architecture', '1581292800000',  24, 'invalid'),('https://www.debugbear.com/blog/intermittent-compression', 'What"s causing intermittent gzip compression?', '1579996800000',  24, 'invalid'),('https://www.debugbear.com/blog/how-does-browser-support-impact-bundle-size', 'How does browser support impact JavaScript bundle size?', '1573603200000',  24, 'invalid'),('https://www.debugbear.com/blog/web-performance-metrics-lab-vs-rum', 'Monitoring web performance: lab-based testing vs collecting field data', '1568160000000',  24, 'invalid'),('https://www.debugbear.com/blog/lazy-loading-angular-components-without-a-router', 'Lazy loading Angular components without a router', '1567468800000',  24, 'invalid'),('https://www.debugbear.com/blog/why-is-my-lighthouse-score-different-from-pagespeed-insights', 'Why is my Lighthouse score different from PageSpeed Insights?', '1566345600000',  24, 'invalid'),('https://www.debugbear.com/blog/chat-widget-site-performance', 'How do different chat widgets impact site performance?', '1563148800000',  24, 'invalid'),('https://www.debugbear.com/blog/measuring-react-app-performance', 'Measuring React app performance', '1561507200000',  24, 'invalid'),('https://www.debugbear.com/blog/resource-hints-rel-preload-prefetch-preconnect', 'Browser Resource Hints: preload٫ prefetch٫ and preconnect', '1557705600000',  24, 'invalid'),('https://www.debugbear.com/blog/image-element-timing', 'Measuring when images are displayed with the experimental Element Timing API', '1556496000000',  24, 'invalid'),('https://www.debugbear.com/blog/custom-front-end-performance-metrics', 'Custom front-end performance metrics with the User Timing API', '1554076800000',  24, 'invalid'),('https://www.debugbear.com/blog/network-throttling-methods', 'Understanding network throttling: DevTools vs. Lighthouse vs. Netem', '1552435200000',  24, 'invalid'),('https://www.debugbear.com/blog/bundle-splitting-components-with-webpack-and-react', 'Bundle splitting components with Webpack and React', '1547510400000',  24, 'invalid'),('https://www.debugbear.com/blog/measuring-the-performance-impact-of-chrome-extensions', 'Measuring the performance impact of Chrome extensions', '1543968000000',  24, 'invalid'),('https://www.debugbear.com/blog/reducing-javascript-bundle-size', 'Keeping your JavaScript bundle size in check', '1540252800000',  24, 'invalid');
SQLITE_ERROR: near ",": syntax error
